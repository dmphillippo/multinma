[{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Atrial fibrillation","text":"Whilst data patient-years risk study (E), ignore follow analysis Cooper et al. (2009), instead analysing number patients stroke (r) total (n) arm. use function set_agd_arm() set network, making sure specify treatment classes trt_class. remove WASPO study network arms zero events, study therefore contributes information. (better analysis, accounting differences patient-years risk studies, can performed specifying rate outcome r E set_agd_arm() . following code remains identical.) Plot network plot() method:","code":"af_net <- set_agd_arm(atrial_fibrillation[atrial_fibrillation$studyc != \"WASPO\", ],                        study = studyc,                       trt = trtc,                       r = r,                        n = n,                       trt_class = trt_class) af_net #> A network with 25 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                                                  #>  ACTIVE-W      2: Standard adjusted dose anti-coagulant | Low dose aspirin + copidogrel        #>  AFASAK 1      3: Standard adjusted dose anti-coagulant | Low dose aspirin | Placebo/Standa... #>  AFASAK 2      4: Standard adjusted dose anti-coagulant | Fixed dose warfarin | Fixed dose ... #>  BAATAF        2: Low adjusted dose anti-coagulant | Placebo/Standard care                     #>  BAFTA         2: Standard adjusted dose anti-coagulant | Low dose aspirin                     #>  CAFA          2: Standard adjusted dose anti-coagulant | Placebo/Standard care                #>  Chinese ATAFS 2: Standard adjusted dose anti-coagulant | Low dose aspirin                     #>  EAFT          3: Standard adjusted dose anti-coagulant | Medium dose aspirin | Placebo/Sta... #>  ESPS 2        4: Dipyridamole | Low dose aspirin | Low dose aspirin + dipyridamole | Place... #>  JAST          2: Low dose aspirin | Placebo/Standard care                                     #>  ... plus 15 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 17, in 4 classes #> Total number of studies: 25 #> Reference treatment is: Standard adjusted dose anti-coagulant #> Network is connected plot(af_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE) +    ggplot2::theme(legend.position = \"bottom\", legend.box = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Atrial fibrillation","text":"fit two (random effects) models: standard NMA model without covariates (model 1 Cooper et al. (2009)); meta-regression model adjusting proportion individuals study prior stroke, shared interaction coefficients treatment class (model 4b Cooper et al. (2009)).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"nma-with-no-covariates","dir":"Articles","previous_headings":"Meta-analysis models","what":"NMA with no covariates","title":"Example: Atrial fibrillation","text":"fit random effects model using nma() function trt_effects = \"random\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting model nma() function. increase target acceptance rate adapt_delta = 0.99 minimise divergent transition warnings. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  can compute relative effects placebo/standard care relative_effects() function trt_ref argument: estimates can easily plotted plot() method:  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. af_fit_1 <- nma(af_net,                  trt_effects = \"random\",                 prior_intercept = normal(scale = 100),                 prior_trt = normal(scale = 100),                 prior_het = half_normal(scale = 5),                 adapt_delta = 0.99) #> Note: Setting \"Standard adjusted dose anti-coagulant\" as the network reference treatment. af_fit_1 #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                  mean se_mean   sd     2.5%      25%      50% #> d[Acenocoumarol]                                -0.78    0.01 0.84    -2.58    -1.29    -0.75 #> d[Alternate day aspirin]                        -1.02    0.02 1.39    -4.28    -1.79    -0.86 #> d[Dipyridamole]                                  0.60    0.01 0.43    -0.25     0.32     0.60 #> d[Fixed dose warfarin]                           0.93    0.01 0.42     0.11     0.65     0.93 #> d[Fixed dose warfarin + low dose aspirin]        0.49    0.01 0.46    -0.42     0.21     0.49 #> d[Fixed dose warfarin + medium dose aspirin]     0.89    0.01 0.32     0.24     0.68     0.89 #> d[High dose aspirin]                             0.51    0.01 0.77    -1.04     0.02     0.53 #> d[Indobufen]                                     0.25    0.01 0.46    -0.65    -0.05     0.25 #> d[Low adjusted dose anti-coagulant]             -0.29    0.01 0.39    -1.07    -0.55    -0.29 #> d[Low dose aspirin]                              0.62    0.00 0.22     0.18     0.48     0.62 #> d[Low dose aspirin + copidogrel]                 0.51    0.01 0.35    -0.19     0.31     0.51 #> d[Low dose aspirin + dipyridamole]               0.26    0.01 0.46    -0.68    -0.03     0.27 #> d[Medium dose aspirin]                           0.39    0.00 0.20    -0.01     0.26     0.40 #> d[Placebo/Standard care]                         0.76    0.00 0.20     0.35     0.64     0.76 #> d[Triflusal]                                     0.65    0.01 0.62    -0.52     0.23     0.64 #> d[Ximelagatran]                                 -0.08    0.00 0.27    -0.63    -0.24    -0.07 #> lp__                                         -4771.38    0.24 7.18 -4786.45 -4776.08 -4771.09 #> tau                                              0.28    0.01 0.14     0.03     0.19     0.28 #>                                                   75%    97.5% n_eff Rhat #> d[Acenocoumarol]                                -0.21     0.76  4052 1.00 #> d[Alternate day aspirin]                        -0.07     1.17  4050 1.00 #> d[Dipyridamole]                                  0.88     1.43  3737 1.00 #> d[Fixed dose warfarin]                           1.20     1.76  4174 1.00 #> d[Fixed dose warfarin + low dose aspirin]        0.77     1.41  3320 1.00 #> d[Fixed dose warfarin + medium dose aspirin]     1.09     1.49  3847 1.00 #> d[High dose aspirin]                             1.01     1.99  5034 1.00 #> d[Indobufen]                                     0.54     1.16  4806 1.00 #> d[Low adjusted dose anti-coagulant]             -0.02     0.49  3802 1.00 #> d[Low dose aspirin]                              0.76     1.04  2316 1.00 #> d[Low dose aspirin + copidogrel]                 0.72     1.22  3567 1.00 #> d[Low dose aspirin + dipyridamole]               0.57     1.14  3840 1.00 #> d[Medium dose aspirin]                           0.51     0.76  3049 1.00 #> d[Placebo/Standard care]                         0.89     1.16  2129 1.00 #> d[Triflusal]                                     1.06     1.91  4312 1.00 #> d[Ximelagatran]                                  0.08     0.45  3389 1.00 #> lp__                                         -4766.44 -4758.03   889 1.01 #> tau                                              0.37     0.58   598 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:38:22 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(af_fit_1, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(af_fit_1, prior = c(\"trt\", \"het\")) (af_1_releff <- relative_effects(af_fit_1, trt_ref = \"Placebo/Standard care\")) #>                                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> d[Standard adjusted dose anti-coagulant]     -0.76 0.20 -1.16 -0.89 -0.76 -0.64 -0.35     2172 #> d[Acenocoumarol]                             -1.54 0.87 -3.41 -2.06 -1.51 -0.95  0.06     3934 #> d[Alternate day aspirin]                     -1.78 1.38 -5.03 -2.55 -1.60 -0.82  0.39     5297 #> d[Dipyridamole]                              -0.16 0.41 -0.98 -0.42 -0.17  0.09  0.64     5155 #> d[Fixed dose warfarin]                        0.17 0.45 -0.74 -0.13  0.17  0.46  1.06     3945 #> d[Fixed dose warfarin + low dose aspirin]    -0.27 0.41 -1.11 -0.51 -0.27 -0.02  0.52     4940 #> d[Fixed dose warfarin + medium dose aspirin]  0.13 0.36 -0.65 -0.09  0.13  0.36  0.84     3772 #> d[High dose aspirin]                         -0.25 0.75 -1.78 -0.73 -0.24  0.24  1.19     6034 #> d[Indobufen]                                 -0.51 0.50 -1.48 -0.84 -0.50 -0.19  0.48     4173 #> d[Low adjusted dose anti-coagulant]          -1.05 0.37 -1.75 -1.29 -1.05 -0.81 -0.32     6755 #> d[Low dose aspirin]                          -0.14 0.21 -0.56 -0.27 -0.14  0.00  0.27     5319 #> d[Low dose aspirin + copidogrel]             -0.25 0.39 -1.02 -0.49 -0.25 -0.01  0.58     3507 #> d[Low dose aspirin + dipyridamole]           -0.50 0.44 -1.40 -0.77 -0.49 -0.21  0.35     5462 #> d[Medium dose aspirin]                       -0.37 0.23 -0.85 -0.52 -0.36 -0.22  0.06     3407 #> d[Triflusal]                                 -0.11 0.66 -1.37 -0.56 -0.12  0.32  1.20     3865 #> d[Ximelagatran]                              -0.84 0.33 -1.50 -1.04 -0.84 -0.63 -0.18     2811 #>                                              Tail_ESS Rhat #> d[Standard adjusted dose anti-coagulant]         2437    1 #> d[Acenocoumarol]                                 2996    1 #> d[Alternate day aspirin]                         2811    1 #> d[Dipyridamole]                                  2750    1 #> d[Fixed dose warfarin]                           2779    1 #> d[Fixed dose warfarin + low dose aspirin]        3160    1 #> d[Fixed dose warfarin + medium dose aspirin]     3013    1 #> d[High dose aspirin]                             3449    1 #> d[Indobufen]                                     2592    1 #> d[Low adjusted dose anti-coagulant]              3839    1 #> d[Low dose aspirin]                              3028    1 #> d[Low dose aspirin + copidogrel]                 3010    1 #> d[Low dose aspirin + dipyridamole]               3294    1 #> d[Medium dose aspirin]                           2692    1 #> d[Triflusal]                                     3180    1 #> d[Ximelagatran]                                  2448    1 plot(af_1_releff, ref_line = 0) (af_1_ranks <- posterior_ranks(af_fit_1)) #>                                                  mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS #> rank[Standard adjusted dose anti-coagulant]      5.26 1.42    3   4   5   6     8     2942 #> rank[Acenocoumarol]                              3.08 3.12    1   1   2   3    13     3884 #> rank[Alternate day aspirin]                      3.69 4.24    1   1   2   4    16     5131 #> rank[Dipyridamole]                              11.34 3.66    4   9  12  14    17     4453 #> rank[Fixed dose warfarin]                       14.03 3.12    6  12  15  16    17     3975 #> rank[Fixed dose warfarin + low dose aspirin]    10.21 3.85    3   7  10  13    17     4246 #> rank[Fixed dose warfarin + medium dose aspirin] 14.11 2.65    8  13  15  16    17     3333 #> rank[High dose aspirin]                         10.26 5.28    1   6  10  16    17     5592 #> rank[Indobufen]                                  8.06 4.03    2   5   7  11    16     4386 #> rank[Low adjusted dose anti-coagulant]           3.80 2.27    1   2   3   5    10     4041 #> rank[Low dose aspirin]                          11.73 2.26    7  10  12  13    16     3889 #> rank[Low dose aspirin + copidogrel]             10.49 3.42    4   8  10  13    17     3811 #> rank[Low dose aspirin + dipyridamole]            8.13 3.88    2   5   8  11    16     4832 #> rank[Medium dose aspirin]                        9.12 2.15    5   8   9  10    14     4171 #> rank[Placebo/Standard care]                     13.41 1.82    9  12  14  15    17     3999 #> rank[Triflusal]                                 11.38 4.67    3   8  12  16    17     4064 #> rank[Ximelagatran]                               4.90 2.28    2   3   4   6    10     2912 #>                                                 Tail_ESS Rhat #> rank[Standard adjusted dose anti-coagulant]         2799    1 #> rank[Acenocoumarol]                                 3321    1 #> rank[Alternate day aspirin]                         3632    1 #> rank[Dipyridamole]                                    NA    1 #> rank[Fixed dose warfarin]                             NA    1 #> rank[Fixed dose warfarin + low dose aspirin]        2789    1 #> rank[Fixed dose warfarin + medium dose aspirin]       NA    1 #> rank[High dose aspirin]                               NA    1 #> rank[Indobufen]                                     3090    1 #> rank[Low adjusted dose anti-coagulant]              3293    1 #> rank[Low dose aspirin]                              3265    1 #> rank[Low dose aspirin + copidogrel]                 3033    1 #> rank[Low dose aspirin + dipyridamole]               3194    1 #> rank[Medium dose aspirin]                           3233    1 #> rank[Placebo/Standard care]                         3689    1 #> rank[Triflusal]                                       NA    1 #> rank[Ximelagatran]                                  2161    1 plot(af_1_ranks) (af_1_rankprobs <- posterior_rank_probs(af_fit_1)) #>                                              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[Standard adjusted dose anti-coagulant]          0.00      0.02      0.08      0.20      0.29 #> d[Acenocoumarol]                                  0.37      0.29      0.10      0.06      0.04 #> d[Alternate day aspirin]                          0.47      0.17      0.07      0.04      0.03 #> d[Dipyridamole]                                   0.00      0.00      0.01      0.02      0.03 #> d[Fixed dose warfarin]                            0.00      0.00      0.00      0.00      0.01 #> d[Fixed dose warfarin + low dose aspirin]         0.00      0.02      0.02      0.04      0.04 #> d[Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00      0.00      0.00 #> d[High dose aspirin]                              0.03      0.05      0.07      0.05      0.05 #> d[Indobufen]                                      0.01      0.05      0.07      0.09      0.08 #> d[Low adjusted dose anti-coagulant]               0.08      0.25      0.25      0.14      0.10 #> d[Low dose aspirin]                               0.00      0.00      0.00      0.00      0.00 #> d[Low dose aspirin + copidogrel]                  0.00      0.01      0.02      0.02      0.03 #> d[Low dose aspirin + dipyridamole]                0.01      0.04      0.07      0.08      0.07 #> d[Medium dose aspirin]                            0.00      0.00      0.00      0.01      0.02 #> d[Placebo/Standard care]                          0.00      0.00      0.00      0.00      0.00 #> d[Triflusal]                                      0.00      0.02      0.04      0.04      0.04 #> d[Ximelagatran]                                   0.02      0.08      0.19      0.21      0.17 #>                                              p_rank[6] p_rank[7] p_rank[8] p_rank[9] #> d[Standard adjusted dose anti-coagulant]          0.23      0.12      0.04      0.02 #> d[Acenocoumarol]                                  0.03      0.03      0.02      0.01 #> d[Alternate day aspirin]                          0.03      0.03      0.02      0.01 #> d[Dipyridamole]                                   0.04      0.06      0.07      0.09 #> d[Fixed dose warfarin]                            0.01      0.02      0.03      0.03 #> d[Fixed dose warfarin + low dose aspirin]         0.05      0.08      0.09      0.10 #> d[Fixed dose warfarin + medium dose aspirin]      0.01      0.01      0.02      0.03 #> d[High dose aspirin]                              0.05      0.05      0.05      0.05 #> d[Indobufen]                                      0.10      0.10      0.09      0.07 #> d[Low adjusted dose anti-coagulant]               0.07      0.05      0.04      0.02 #> d[Low dose aspirin]                               0.01      0.02      0.05      0.09 #> d[Low dose aspirin + copidogrel]                  0.05      0.08      0.10      0.11 #> d[Low dose aspirin + dipyridamole]                0.09      0.11      0.10      0.09 #> d[Medium dose aspirin]                            0.07      0.11      0.17      0.20 #> d[Placebo/Standard care]                          0.00      0.00      0.01      0.02 #> d[Triflusal]                                      0.05      0.05      0.06      0.05 #> d[Ximelagatran]                                   0.12      0.08      0.05      0.03 #>                                              p_rank[10] p_rank[11] p_rank[12] p_rank[13] #> d[Standard adjusted dose anti-coagulant]           0.00       0.00       0.00       0.00 #> d[Acenocoumarol]                                   0.01       0.01       0.01       0.01 #> d[Alternate day aspirin]                           0.02       0.01       0.01       0.01 #> d[Dipyridamole]                                    0.09       0.09       0.08       0.08 #> d[Fixed dose warfarin]                             0.04       0.06       0.06       0.07 #> d[Fixed dose warfarin + low dose aspirin]          0.09       0.09       0.08       0.08 #> d[Fixed dose warfarin + medium dose aspirin]       0.05       0.05       0.06       0.08 #> d[High dose aspirin]                               0.05       0.04       0.05       0.04 #> d[Indobufen]                                       0.07       0.06       0.05       0.04 #> d[Low adjusted dose anti-coagulant]                0.01       0.01       0.00       0.00 #> d[Low dose aspirin]                                0.12       0.16       0.18       0.15 #> d[Low dose aspirin + copidogrel]                   0.11       0.10       0.09       0.08 #> d[Low dose aspirin + dipyridamole]                 0.07       0.06       0.06       0.04 #> d[Medium dose aspirin]                             0.17       0.12       0.07       0.03 #> d[Placebo/Standard care]                           0.04       0.08       0.14       0.21 #> d[Triflusal]                                       0.06       0.06       0.05       0.06 #> d[Ximelagatran]                                    0.02       0.01       0.00       0.00 #>                                              p_rank[14] p_rank[15] p_rank[16] p_rank[17] #> d[Standard adjusted dose anti-coagulant]           0.00       0.00       0.00       0.00 #> d[Acenocoumarol]                                   0.01       0.01       0.01       0.00 #> d[Alternate day aspirin]                           0.01       0.02       0.02       0.02 #> d[Dipyridamole]                                    0.10       0.09       0.08       0.07 #> d[Fixed dose warfarin]                             0.09       0.13       0.21       0.24 #> d[Fixed dose warfarin + low dose aspirin]          0.06       0.06       0.06       0.05 #> d[Fixed dose warfarin + medium dose aspirin]       0.13       0.18       0.21       0.17 #> d[High dose aspirin]                               0.05       0.06       0.08       0.17 #> d[Indobufen]                                       0.04       0.04       0.03       0.02 #> d[Low adjusted dose anti-coagulant]                0.00       0.00       0.00       0.00 #> d[Low dose aspirin]                                0.11       0.07       0.03       0.01 #> d[Low dose aspirin + copidogrel]                   0.07       0.06       0.05       0.03 #> d[Low dose aspirin + dipyridamole]                 0.04       0.03       0.03       0.01 #> d[Medium dose aspirin]                             0.02       0.01       0.00       0.00 #> d[Placebo/Standard care]                           0.22       0.17       0.09       0.03 #> d[Triflusal]                                       0.06       0.08       0.11       0.17 #> d[Ximelagatran]                                    0.00       0.00       0.00       0.00 plot(af_1_rankprobs) (af_1_cumrankprobs <- posterior_rank_probs(af_fit_1, cumulative = TRUE)) #>                                              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[Standard adjusted dose anti-coagulant]          0.00      0.02      0.10      0.30      0.59 #> d[Acenocoumarol]                                  0.37      0.66      0.75      0.81      0.85 #> d[Alternate day aspirin]                          0.47      0.64      0.71      0.75      0.78 #> d[Dipyridamole]                                   0.00      0.01      0.02      0.04      0.06 #> d[Fixed dose warfarin]                            0.00      0.00      0.00      0.01      0.02 #> d[Fixed dose warfarin + low dose aspirin]         0.00      0.02      0.04      0.08      0.12 #> d[Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00      0.00      0.00 #> d[High dose aspirin]                              0.03      0.08      0.15      0.20      0.25 #> d[Indobufen]                                      0.01      0.06      0.13      0.22      0.30 #> d[Low adjusted dose anti-coagulant]               0.08      0.33      0.57      0.71      0.81 #> d[Low dose aspirin]                               0.00      0.00      0.00      0.00      0.00 #> d[Low dose aspirin + copidogrel]                  0.00      0.01      0.02      0.04      0.07 #> d[Low dose aspirin + dipyridamole]                0.01      0.05      0.13      0.20      0.28 #> d[Medium dose aspirin]                            0.00      0.00      0.01      0.01      0.04 #> d[Placebo/Standard care]                          0.00      0.00      0.00      0.00      0.00 #> d[Triflusal]                                      0.00      0.02      0.07      0.11      0.15 #> d[Ximelagatran]                                   0.02      0.10      0.29      0.51      0.68 #>                                              p_rank[6] p_rank[7] p_rank[8] p_rank[9] #> d[Standard adjusted dose anti-coagulant]          0.82      0.94      0.98      1.00 #> d[Acenocoumarol]                                  0.88      0.90      0.93      0.94 #> d[Alternate day aspirin]                          0.81      0.84      0.87      0.88 #> d[Dipyridamole]                                   0.11      0.16      0.24      0.32 #> d[Fixed dose warfarin]                            0.03      0.05      0.08      0.11 #> d[Fixed dose warfarin + low dose aspirin]         0.18      0.25      0.35      0.44 #> d[Fixed dose warfarin + medium dose aspirin]      0.01      0.02      0.05      0.07 #> d[High dose aspirin]                              0.29      0.35      0.40      0.45 #> d[Indobufen]                                      0.40      0.50      0.59      0.66 #> d[Low adjusted dose anti-coagulant]               0.88      0.92      0.96      0.97 #> d[Low dose aspirin]                               0.01      0.03      0.08      0.17 #> d[Low dose aspirin + copidogrel]                  0.12      0.20      0.30      0.40 #> d[Low dose aspirin + dipyridamole]                0.37      0.47      0.57      0.66 #> d[Medium dose aspirin]                            0.11      0.22      0.39      0.58 #> d[Placebo/Standard care]                          0.00      0.00      0.01      0.03 #> d[Triflusal]                                      0.20      0.24      0.30      0.35 #> d[Ximelagatran]                                   0.79      0.87      0.93      0.96 #>                                              p_rank[10] p_rank[11] p_rank[12] p_rank[13] #> d[Standard adjusted dose anti-coagulant]           1.00       1.00       1.00       1.00 #> d[Acenocoumarol]                                   0.95       0.96       0.97       0.98 #> d[Alternate day aspirin]                           0.90       0.91       0.92       0.93 #> d[Dipyridamole]                                    0.41       0.50       0.58       0.67 #> d[Fixed dose warfarin]                             0.14       0.20       0.26       0.34 #> d[Fixed dose warfarin + low dose aspirin]          0.53       0.62       0.70       0.78 #> d[Fixed dose warfarin + medium dose aspirin]       0.12       0.17       0.23       0.32 #> d[High dose aspirin]                               0.50       0.55       0.59       0.63 #> d[Indobufen]                                       0.73       0.78       0.83       0.87 #> d[Low adjusted dose anti-coagulant]                0.98       0.99       0.99       1.00 #> d[Low dose aspirin]                                0.29       0.45       0.62       0.78 #> d[Low dose aspirin + copidogrel]                   0.51       0.61       0.70       0.78 #> d[Low dose aspirin + dipyridamole]                 0.73       0.79       0.84       0.88 #> d[Medium dose aspirin]                             0.75       0.87       0.94       0.97 #> d[Placebo/Standard care]                           0.06       0.15       0.28       0.49 #> d[Triflusal]                                       0.41       0.47       0.52       0.58 #> d[Ximelagatran]                                    0.98       0.99       0.99       1.00 #>                                              p_rank[14] p_rank[15] p_rank[16] p_rank[17] #> d[Standard adjusted dose anti-coagulant]           1.00       1.00       1.00          1 #> d[Acenocoumarol]                                   0.99       0.99       1.00          1 #> d[Alternate day aspirin]                           0.95       0.96       0.98          1 #> d[Dipyridamole]                                    0.76       0.85       0.93          1 #> d[Fixed dose warfarin]                             0.42       0.55       0.76          1 #> d[Fixed dose warfarin + low dose aspirin]          0.83       0.89       0.95          1 #> d[Fixed dose warfarin + medium dose aspirin]       0.44       0.62       0.83          1 #> d[High dose aspirin]                               0.68       0.75       0.83          1 #> d[Indobufen]                                       0.91       0.95       0.98          1 #> d[Low adjusted dose anti-coagulant]                1.00       1.00       1.00          1 #> d[Low dose aspirin]                                0.89       0.96       0.99          1 #> d[Low dose aspirin + copidogrel]                   0.85       0.92       0.97          1 #> d[Low dose aspirin + dipyridamole]                 0.92       0.96       0.99          1 #> d[Medium dose aspirin]                             0.99       1.00       1.00          1 #> d[Placebo/Standard care]                           0.71       0.88       0.97          1 #> d[Triflusal]                                       0.64       0.72       0.83          1 #> d[Ximelagatran]                                    1.00       1.00       1.00          1 plot(af_1_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"network-meta-regression-adjusting-for-proportion-of-prior-stroke","dir":"Articles","previous_headings":"Meta-analysis models","what":"Network meta-regression adjusting for proportion of prior stroke","title":"Example: Atrial fibrillation","text":"now consider meta-regression model adjusting proportion individuals study prior stroke, shared interaction coefficients treatment class. regression model specified nma() function using formula regression argument. formula ~ .trt:stroke means interactions prior stroke treatment included; .trt special variable indicates treatment, stroke original data set. specify class_interactions = \"common\" denote interaction parameters common (.e. shared) treatments within class. (Setting class_interactions = \"independent\" fit model 2 Cooper et al. (2009) separate interactions treatment, data permitting.) use prior distributions , additionally require prior distribution regression coefficients prior_reg; use \\(\\mathrm{N}(0, 100^2)\\) prior distribution. QR decomposition can greatly improve efficiency sampling regression models decorrelating sampling space; specify used QR = TRUE, increase target acceptance rate adapt_delta = 0.99 minimise divergent transition warnings. Basic parameter summaries given print() method: estimated treatment effects d[] shown correspond relative effects reference level covariate, proportion prior stroke centered network mean value 0.296. default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  can compute relative effects placebo/standard care relative_effects() function trt_ref argument, default produces relative effects observed proportions prior stroke study: can produce estimated treatment effects particular covariate values using newdata argument. example, treatment effects individuals individuals prior stroke produced  estimated class interactions (reference “Mixed” class) uncertain.  interactions straightforward interpret transform interaction coefficients (using consistency equations) control class:  evidence effect anti-coagulants increases (compared control) prior stroke. little evidence effect anti-platelets reduces prior stroke, although point estimate represents substantial reduction effectiveness, 95% Credible Interval includes values correspond substantial increases treatment effect. interaction effect stroke mixed treatments uncertain, potentially indicates substantial reduction treatment effects prior stroke. can also produce treatment rankings, rank probabilities, cumulative rank probabilities. default (without newdata argument specified), produced value stroke study network turn. instead produce rankings individuals individuals prior stroke, specify newdata argument.","code":"af_fit_4b <- nma(af_net,                   trt_effects = \"random\",                  regression = ~ .trt:stroke,                  class_interactions = \"common\",                  QR = TRUE,                  prior_intercept = normal(scale = 100),                  prior_trt = normal(scale = 100),                  prior_reg = normal(scale = 100),                  prior_het = half_normal(scale = 5),                  adapt_delta = 0.99) #> Note: Setting \"Standard adjusted dose anti-coagulant\" as the network reference treatment. #> Warning: There were 1 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems af_fit_4b #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:stroke. #> Centred covariates at the following overall mean values: #>    stroke  #> 0.2957377  #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                  mean se_mean   sd     2.5%      25%      50% #> beta[.trtclassControl:stroke]                    0.70    0.01 0.44    -0.15     0.42     0.69 #> beta[.trtclassAnti-platelet:stroke]              0.93    0.01 0.41     0.13     0.66     0.93 #> beta[.trtclassMixed:stroke]                      3.89    0.03 2.08    -0.18     2.49     3.86 #> d[Acenocoumarol]                                 0.35    0.02 1.01    -1.67    -0.29     0.36 #> d[Alternate day aspirin]                        -0.87    0.03 1.34    -4.00    -1.60    -0.72 #> d[Dipyridamole]                                  0.57    0.01 0.40    -0.25     0.32     0.58 #> d[Fixed dose warfarin]                           0.65    0.01 0.39    -0.10     0.40     0.64 #> d[Fixed dose warfarin + low dose aspirin]        1.46    0.01 0.73     0.03     0.98     1.44 #> d[Fixed dose warfarin + medium dose aspirin]     1.00    0.00 0.31     0.42     0.80     1.00 #> d[High dose aspirin]                             0.43    0.01 0.74    -1.10    -0.06     0.42 #> d[Indobufen]                                    -0.42    0.01 0.48    -1.37    -0.73    -0.42 #> d[Low adjusted dose anti-coagulant]             -0.42    0.01 0.37    -1.16    -0.66    -0.42 #> d[Low dose aspirin]                              0.72    0.00 0.19     0.34     0.59     0.72 #> d[Low dose aspirin + copidogrel]                 0.65    0.01 0.28     0.09     0.49     0.65 #> d[Low dose aspirin + dipyridamole]               0.26    0.01 0.43    -0.59    -0.03     0.26 #> d[Medium dose aspirin]                           0.35    0.00 0.18     0.00     0.24     0.35 #> d[Placebo/Standard care]                         0.79    0.00 0.18     0.42     0.67     0.79 #> d[Triflusal]                                     0.91    0.01 0.58    -0.19     0.52     0.90 #> d[Ximelagatran]                                 -0.08    0.00 0.22    -0.51    -0.21    -0.09 #> lp__                                         -4771.61    0.21 7.10 -4786.55 -4776.15 -4771.26 #> tau                                              0.17    0.01 0.12     0.01     0.08     0.15 #>                                                   75%    97.5% n_eff Rhat #> beta[.trtclassControl:stroke]                    0.98     1.60  4767    1 #> beta[.trtclassAnti-platelet:stroke]              1.20     1.72  4720    1 #> beta[.trtclassMixed:stroke]                      5.25     8.03  4247    1 #> d[Acenocoumarol]                                 1.02     2.31  3861    1 #> d[Alternate day aspirin]                         0.05     1.26  2410    1 #> d[Dipyridamole]                                  0.83     1.34  5374    1 #> d[Fixed dose warfarin]                           0.91     1.42  4926    1 #> d[Fixed dose warfarin + low dose aspirin]        1.94     2.92  4677    1 #> d[Fixed dose warfarin + medium dose aspirin]     1.20     1.62  4666    1 #> d[High dose aspirin]                             0.93     1.85  5403    1 #> d[Indobufen]                                    -0.11     0.54  4945    1 #> d[Low adjusted dose anti-coagulant]             -0.18     0.29  4561    1 #> d[Low dose aspirin]                              0.85     1.09  4895    1 #> d[Low dose aspirin + copidogrel]                 0.81     1.21  2614    1 #> d[Low dose aspirin + dipyridamole]               0.54     1.11  5733    1 #> d[Medium dose aspirin]                           0.47     0.69  3690    1 #> d[Placebo/Standard care]                         0.91     1.15  4550    1 #> d[Triflusal]                                     1.28     2.08  4781    1 #> d[Ximelagatran]                                  0.05     0.34  2758    1 #> lp__                                         -4766.66 -4758.76  1160    1 #> tau                                              0.25     0.46   507    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:38:58 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(af_fit_4b, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(af_fit_4b, prior = c(\"reg\", \"het\")) # Not run (af_4b_releff <- relative_effects(af_fit_4b, trt_ref = \"Placebo/Standard care\")) plot(af_4b_releff, ref_line = 0) (af_4b_releff_01 <- relative_effects(af_fit_4b,                                       trt_ref = \"Placebo/Standard care\",                                      newdata = data.frame(stroke = c(0, 1),                                                            label = c(\"stroke = 0\", \"stroke = 1\")),                                      study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                           mean   sd  2.5%   25%   50%   75% #> d[stroke = 0: Standard adjusted dose anti-coagulant]     -0.58 0.23 -1.04 -0.74 -0.59 -0.44 #> d[stroke = 0: Acenocoumarol]                             -1.38 0.82 -3.07 -1.90 -1.34 -0.84 #> d[stroke = 0: Alternate day aspirin]                     -1.73 1.34 -4.82 -2.43 -1.56 -0.81 #> d[stroke = 0: Dipyridamole]                              -0.29 0.43 -1.12 -0.56 -0.28  0.00 #> d[stroke = 0: Fixed dose warfarin]                        0.07 0.44 -0.75 -0.23  0.07  0.35 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]    -0.27 0.32 -0.89 -0.48 -0.27 -0.06 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin] -0.73 0.64 -1.98 -1.16 -0.72 -0.30 #> d[stroke = 0: High dose aspirin]                         -0.43 0.77 -1.94 -0.97 -0.42  0.10 #> d[stroke = 0: Indobufen]                                 -1.27 0.55 -2.36 -1.63 -1.27 -0.92 #> d[stroke = 0: Low adjusted dose anti-coagulant]          -1.01 0.34 -1.69 -1.23 -1.00 -0.78 #> d[stroke = 0: Low dose aspirin]                          -0.14 0.22 -0.57 -0.29 -0.14  0.01 #> d[stroke = 0: Low dose aspirin + copidogrel]             -0.21 0.35 -0.91 -0.42 -0.21  0.00 #> d[stroke = 0: Low dose aspirin + dipyridamole]           -0.60 0.45 -1.48 -0.89 -0.60 -0.31 #> d[stroke = 0: Medium dose aspirin]                       -0.51 0.26 -1.01 -0.68 -0.51 -0.34 #> d[stroke = 0: Triflusal]                                  0.05 0.62 -1.11 -0.36  0.03  0.45 #> d[stroke = 0: Ximelagatran]                              -0.66 0.32 -1.27 -0.88 -0.67 -0.47 #>                                                          97.5% Bulk_ESS Tail_ESS Rhat #> d[stroke = 0: Standard adjusted dose anti-coagulant]     -0.12     4438     2874    1 #> d[stroke = 0: Acenocoumarol]                              0.16     3761     2744    1 #> d[stroke = 0: Alternate day aspirin]                      0.42     3053     1962    1 #> d[stroke = 0: Dipyridamole]                               0.53     5439     3209    1 #> d[stroke = 0: Fixed dose warfarin]                        0.95     5396     2552    1 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]     0.36     4362     2148    1 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]  0.50     3981     3114    1 #> d[stroke = 0: High dose aspirin]                          1.04     5021     2868    1 #> d[stroke = 0: Indobufen]                                 -0.19     4908     2889    1 #> d[stroke = 0: Low adjusted dose anti-coagulant]          -0.35     4985     2679    1 #> d[stroke = 0: Low dose aspirin]                           0.29     4910     3105    1 #> d[stroke = 0: Low dose aspirin + copidogrel]              0.51     3024     2637    1 #> d[stroke = 0: Low dose aspirin + dipyridamole]            0.31     5246     2980    1 #> d[stroke = 0: Medium dose aspirin]                        0.02     4677     2870    1 #> d[stroke = 0: Triflusal]                                  1.29     4794     3213    1 #> d[stroke = 0: Ximelagatran]                              -0.04     3367     2296    1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                           mean   sd  2.5%   25%   50%   75% #> d[stroke = 1: Standard adjusted dose anti-coagulant]     -1.28 0.34 -1.96 -1.50 -1.28 -1.06 #> d[stroke = 1: Acenocoumarol]                              1.81 2.28 -2.56  0.27  1.80  3.30 #> d[stroke = 1: Alternate day aspirin]                     -1.50 1.36 -4.69 -2.21 -1.35 -0.56 #> d[stroke = 1: Dipyridamole]                              -0.06 0.38 -0.83 -0.31 -0.05  0.20 #> d[stroke = 1: Fixed dose warfarin]                       -0.63 0.52 -1.69 -0.96 -0.63 -0.30 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]     2.91 2.15 -1.36  1.47  2.90  4.33 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]  2.46 1.62 -0.73  1.39  2.42  3.51 #> d[stroke = 1: High dose aspirin]                         -0.20 0.73 -1.69 -0.68 -0.17  0.30 #> d[stroke = 1: Indobufen]                                 -1.04 0.51 -2.07 -1.36 -1.04 -0.72 #> d[stroke = 1: Low adjusted dose anti-coagulant]          -1.71 0.51 -2.73 -2.04 -1.71 -1.36 #> d[stroke = 1: Low dose aspirin]                           0.09 0.28 -0.47 -0.10  0.09  0.28 #> d[stroke = 1: Low dose aspirin + copidogrel]              0.02 0.38 -0.74 -0.22  0.03  0.25 #> d[stroke = 1: Low dose aspirin + dipyridamole]           -0.37 0.41 -1.18 -0.64 -0.36 -0.10 #> d[stroke = 1: Medium dose aspirin]                       -0.28 0.24 -0.77 -0.43 -0.27 -0.12 #> d[stroke = 1: Triflusal]                                  0.28 0.65 -1.01 -0.13  0.27  0.71 #> d[stroke = 1: Ximelagatran]                              -1.36 0.40 -2.18 -1.61 -1.36 -1.11 #>                                                          97.5% Bulk_ESS Tail_ESS Rhat #> d[stroke = 1: Standard adjusted dose anti-coagulant]     -0.63     5129     3011    1 #> d[stroke = 1: Acenocoumarol]                              6.27     4208     2963    1 #> d[stroke = 1: Alternate day aspirin]                      0.68     2938     2012    1 #> d[stroke = 1: Dipyridamole]                               0.69     5597     2667    1 #> d[stroke = 1: Fixed dose warfarin]                        0.38     4827     2940    1 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]     7.19     4308     2942    1 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]  5.68     4445     2967    1 #> d[stroke = 1: High dose aspirin]                          1.21     5555     2891    1 #> d[stroke = 1: Indobufen]                                 -0.05     5112     3013    1 #> d[stroke = 1: Low adjusted dose anti-coagulant]          -0.71     4948     3241    1 #> d[stroke = 1: Low dose aspirin]                           0.63     5591     2324    1 #> d[stroke = 1: Low dose aspirin + copidogrel]              0.75     3633     2397    1 #> d[stroke = 1: Low dose aspirin + dipyridamole]            0.42     5889     2875    1 #> d[stroke = 1: Medium dose aspirin]                        0.18     4732     2293    1 #> d[stroke = 1: Triflusal]                                  1.60     5321     2956    1 #> d[stroke = 1: Ximelagatran]                              -0.58     4083     2765    1 plot(af_4b_releff_01, ref_line = 0) plot(af_fit_4b, pars = \"beta\", stat = \"halfeye\", ref_line = 0) af_4b_beta <- as.array(af_fit_4b, pars = \"beta\")  # Subtract beta[Control:stroke] from the other class interactions af_4b_beta[ , , 2:3] <- sweep(af_4b_beta[ , , 2:3], 1:2,                                af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"], FUN = \"-\")  # Set beta[Anti-coagulant:stroke] = -beta[Control:stroke] af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"] <- -af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"] names(af_4b_beta)[1] <- \"beta[.trtclassAnti-coagulant:stroke]\"  # Summarise summary(af_4b_beta) #>                                       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> beta[.trtclassAnti-coagulant:stroke] -0.70 0.44 -1.60 -0.98 -0.69 -0.42  0.15     4565 #> beta[.trtclassAnti-platelet:stroke]   0.23 0.33 -0.44  0.02  0.23  0.44  0.85     4783 #> beta[.trtclassMixed:stroke]           3.19 2.12 -0.92  1.76  3.16  4.57  7.47     4203 #>                                      Tail_ESS Rhat #> beta[.trtclassAnti-coagulant:stroke]     2820    1 #> beta[.trtclassAnti-platelet:stroke]      3224    1 #> beta[.trtclassMixed:stroke]              2981    1 plot(summary(af_4b_beta), stat = \"halfeye\", ref_line = 0) (af_4b_ranks <- posterior_ranks(af_fit_4b,                                 newdata = data.frame(stroke = c(0, 1),                                                       label = c(\"stroke = 0\", \"stroke = 1\")),                                  study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                              mean   sd 2.5% 25% 50% 75% 97.5% #> rank[stroke = 0: Standard adjusted dose anti-coagulant]      7.69 1.82    4   6   8   9 11.00 #> rank[stroke = 0: Acenocoumarol]                              3.89 3.59    1   1   2   5 15.00 #> rank[stroke = 0: Alternate day aspirin]                      4.02 4.41    1   1   2   5 17.00 #> rank[stroke = 0: Dipyridamole]                              11.10 3.69    4   9  11  14 17.00 #> rank[stroke = 0: Fixed dose warfarin]                       14.20 2.82    7  13  15  16 17.00 #> rank[stroke = 0: Fixed dose warfarin + low dose aspirin]    11.13 3.66    4   8  12  14 17.00 #> rank[stroke = 0: Fixed dose warfarin + medium dose aspirin]  7.20 4.53    1   3   6  11 17.00 #> rank[stroke = 0: High dose aspirin]                          9.65 5.31    1   5  10  15 17.00 #> rank[stroke = 0: Indobufen]                                  3.58 2.69    1   2   3   4 11.03 #> rank[stroke = 0: Low adjusted dose anti-coagulant]           4.53 2.45    1   3   4   5 11.00 #> rank[stroke = 0: Low dose aspirin]                          12.88 1.96    9  12  13  14 16.00 #> rank[stroke = 0: Low dose aspirin + copidogrel]             12.00 2.85    6  10  12  14 17.00 #> rank[stroke = 0: Low dose aspirin + dipyridamole]            7.92 3.77    2   5   7  11 16.00 #> rank[stroke = 0: Medium dose aspirin]                        8.62 2.22    4   7   9  10 13.00 #> rank[stroke = 0: Placebo/Standard care]                     14.29 1.88   10  13  15  16 17.00 #> rank[stroke = 0: Triflusal]                                 13.37 3.98    4  11  15  17 17.00 #> rank[stroke = 0: Ximelagatran]                               6.92 2.58    3   5   7   8 13.00 #>                                                             Bulk_ESS Tail_ESS Rhat #> rank[stroke = 0: Standard adjusted dose anti-coagulant]         3984     3557    1 #> rank[stroke = 0: Acenocoumarol]                                 3501     3086    1 #> rank[stroke = 0: Alternate day aspirin]                         3727     3072    1 #> rank[stroke = 0: Dipyridamole]                                  5287       NA    1 #> rank[stroke = 0: Fixed dose warfarin]                           5051       NA    1 #> rank[stroke = 0: Fixed dose warfarin + low dose aspirin]        4152     3026    1 #> rank[stroke = 0: Fixed dose warfarin + medium dose aspirin]     3988     3065    1 #> rank[stroke = 0: High dose aspirin]                             5438       NA    1 #> rank[stroke = 0: Indobufen]                                     3994     2745    1 #> rank[stroke = 0: Low adjusted dose anti-coagulant]              4406     3269    1 #> rank[stroke = 0: Low dose aspirin]                              4232     3456    1 #> rank[stroke = 0: Low dose aspirin + copidogrel]                 2751     2517    1 #> rank[stroke = 0: Low dose aspirin + dipyridamole]               5268     3274    1 #> rank[stroke = 0: Medium dose aspirin]                           4577     3199    1 #> rank[stroke = 0: Placebo/Standard care]                         3211       NA    1 #> rank[stroke = 0: Triflusal]                                     4826       NA    1 #> rank[stroke = 0: Ximelagatran]                                  3271     2196    1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                              mean   sd 2.5% 25% 50% 75% 97.5% #> rank[stroke = 1: Standard adjusted dose anti-coagulant]      3.64 1.11 2.00   3   4   4     6 #> rank[stroke = 1: Acenocoumarol]                             13.15 4.44 1.00  14  15  16    17 #> rank[stroke = 1: Alternate day aspirin]                      4.51 3.98 1.00   1   3   7    14 #> rank[stroke = 1: Dipyridamole]                              10.56 2.72 5.98   9  11  13    15 #> rank[stroke = 1: Fixed dose warfarin]                        7.16 2.73 3.00   5   6   8    14 #> rank[stroke = 1: Fixed dose warfarin + low dose aspirin]    15.77 2.95 5.00  16  17  17    17 #> rank[stroke = 1: Fixed dose warfarin + medium dose aspirin] 15.42 1.94 8.00  15  16  16    17 #> rank[stroke = 1: High dose aspirin]                          9.50 4.04 2.00   6   9  13    17 #> rank[stroke = 1: Indobufen]                                  4.93 2.12 1.00   4   5   6    10 #> rank[stroke = 1: Low adjusted dose anti-coagulant]           2.00 1.31 1.00   1   2   2     5 #> rank[stroke = 1: Low dose aspirin]                          11.88 1.79 8.00  11  12  13    15 #> rank[stroke = 1: Low dose aspirin + copidogrel]             11.15 2.39 6.00  10  11  13    15 #> rank[stroke = 1: Low dose aspirin + dipyridamole]            8.26 2.70 3.00   6   8  10    14 #> rank[stroke = 1: Medium dose aspirin]                        8.64 1.70 6.00   7   8  10    12 #> rank[stroke = 1: Placebo/Standard care]                     11.15 1.94 7.00  10  11  12    15 #> rank[stroke = 1: Triflusal]                                 12.13 3.09 5.00  10  13  14    17 #> rank[stroke = 1: Ximelagatran]                               3.15 1.43 1.00   2   3   4     6 #>                                                             Bulk_ESS Tail_ESS Rhat #> rank[stroke = 1: Standard adjusted dose anti-coagulant]         3124     2939    1 #> rank[stroke = 1: Acenocoumarol]                                 3919       NA    1 #> rank[stroke = 1: Alternate day aspirin]                         3876     3094    1 #> rank[stroke = 1: Dipyridamole]                                  4918     3420    1 #> rank[stroke = 1: Fixed dose warfarin]                           3914     3256    1 #> rank[stroke = 1: Fixed dose warfarin + low dose aspirin]        3086       NA    1 #> rank[stroke = 1: Fixed dose warfarin + medium dose aspirin]     3233       NA    1 #> rank[stroke = 1: High dose aspirin]                             5325     2987    1 #> rank[stroke = 1: Indobufen]                                     4176     3151    1 #> rank[stroke = 1: Low adjusted dose anti-coagulant]              3253     2927    1 #> rank[stroke = 1: Low dose aspirin]                              4181     3710    1 #> rank[stroke = 1: Low dose aspirin + copidogrel]                 3166     3193    1 #> rank[stroke = 1: Low dose aspirin + dipyridamole]               5215     3428    1 #> rank[stroke = 1: Medium dose aspirin]                           3871     3071    1 #> rank[stroke = 1: Placebo/Standard care]                         4463     3184    1 #> rank[stroke = 1: Triflusal]                                     4486     2954    1 #> rank[stroke = 1: Ximelagatran]                                  3014     2418    1 plot(af_4b_ranks) (af_4b_rankprobs <- posterior_rank_probs(af_fit_4b,                                          newdata = data.frame(stroke = c(0, 1),                                                                label = c(\"stroke = 0\", \"stroke = 1\")),                                           study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.00      0.00      0.00 #> d[stroke = 0: Acenocoumarol]                                  0.27      0.24      0.13 #> d[stroke = 0: Alternate day aspirin]                          0.43      0.15      0.08 #> d[stroke = 0: Dipyridamole]                                   0.00      0.00      0.01 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.00      0.00 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.01 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.05      0.10      0.11 #> d[stroke = 0: High dose aspirin]                              0.03      0.07      0.06 #> d[stroke = 0: Indobufen]                                      0.17      0.25      0.22 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.04      0.13      0.22 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.01      0.03      0.07 #> d[stroke = 0: Medium dose aspirin]                            0.00      0.00      0.01 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.00      0.00      0.01 #> d[stroke = 0: Ximelagatran]                                   0.00      0.01      0.05 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.02      0.08      0.16 #> d[stroke = 0: Acenocoumarol]                                  0.09      0.05      0.04 #> d[stroke = 0: Alternate day aspirin]                          0.06      0.04      0.03 #> d[stroke = 0: Dipyridamole]                                   0.03      0.04      0.05 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.01      0.01 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.03      0.04      0.05 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.10      0.10      0.07 #> d[stroke = 0: High dose aspirin]                              0.08      0.07      0.05 #> d[stroke = 0: Indobufen]                                      0.13      0.07      0.04 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.21      0.15      0.08 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.01      0.01      0.02 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.10      0.11      0.10 #> d[stroke = 0: Medium dose aspirin]                            0.02      0.05      0.10 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.02      0.03      0.03 #> d[stroke = 0: Ximelagatran]                                   0.10      0.15      0.16 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.20      0.21      0.16 #> d[stroke = 0: Acenocoumarol]                                  0.03      0.03      0.02 #> d[stroke = 0: Alternate day aspirin]                          0.03      0.02      0.02 #> d[stroke = 0: Dipyridamole]                                   0.05      0.06      0.08 #> d[stroke = 0: Fixed dose warfarin]                            0.01      0.02      0.02 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.06      0.06      0.07 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.06      0.05      0.05 #> d[stroke = 0: High dose aspirin]                              0.05      0.04      0.04 #> d[stroke = 0: Indobufen]                                      0.03      0.02      0.02 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.05      0.04      0.03 #> d[stroke = 0: Low dose aspirin]                               0.01      0.01      0.02 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.03      0.05      0.06 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.09      0.07      0.08 #> d[stroke = 0: Medium dose aspirin]                            0.14      0.16      0.19 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.01 #> d[stroke = 0: Triflusal]                                      0.03      0.03      0.03 #> d[stroke = 0: Ximelagatran]                                   0.15      0.12      0.09 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.10       0.04       0.01 #> d[stroke = 0: Acenocoumarol]                                   0.02       0.01       0.01 #> d[stroke = 0: Alternate day aspirin]                           0.02       0.02       0.01 #> d[stroke = 0: Dipyridamole]                                    0.09       0.10       0.10 #> d[stroke = 0: Fixed dose warfarin]                             0.04       0.06       0.07 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.08       0.10       0.10 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.05       0.05       0.04 #> d[stroke = 0: High dose aspirin]                               0.05       0.05       0.05 #> d[stroke = 0: Indobufen]                                       0.01       0.01       0.01 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.02       0.02       0.01 #> d[stroke = 0: Low dose aspirin]                                0.07       0.12       0.18 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.10       0.12       0.14 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.08       0.06       0.05 #> d[stroke = 0: Medium dose aspirin]                             0.15       0.09       0.05 #> d[stroke = 0: Placebo/Standard care]                           0.02       0.04       0.08 #> d[stroke = 0: Triflusal]                                       0.04       0.05       0.06 #> d[stroke = 0: Ximelagatran]                                    0.06       0.04       0.03 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.00       0.00       0.00 #> d[stroke = 0: Acenocoumarol]                                   0.01       0.01       0.01 #> d[stroke = 0: Alternate day aspirin]                           0.01       0.02       0.02 #> d[stroke = 0: Dipyridamole]                                    0.09       0.08       0.08 #> d[stroke = 0: Fixed dose warfarin]                             0.09       0.10       0.14 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.09       0.10       0.09 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.04       0.03       0.03 #> d[stroke = 0: High dose aspirin]                               0.04       0.04       0.06 #> d[stroke = 0: Indobufen]                                       0.01       0.00       0.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.01       0.00       0.00 #> d[stroke = 0: Low dose aspirin]                                0.19       0.20       0.13 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.14       0.12       0.10 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.04       0.04       0.03 #> d[stroke = 0: Medium dose aspirin]                             0.03       0.01       0.01 #> d[stroke = 0: Placebo/Standard care]                           0.14       0.18       0.23 #> d[stroke = 0: Triflusal]                                       0.06       0.07       0.08 #> d[stroke = 0: Ximelagatran]                                    0.01       0.01       0.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.00       0.00 #> d[stroke = 0: Acenocoumarol]                                   0.01       0.00 #> d[stroke = 0: Alternate day aspirin]                           0.01       0.03 #> d[stroke = 0: Dipyridamole]                                    0.08       0.05 #> d[stroke = 0: Fixed dose warfarin]                             0.20       0.24 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.07       0.05 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.04       0.03 #> d[stroke = 0: High dose aspirin]                               0.08       0.14 #> d[stroke = 0: Indobufen]                                       0.00       0.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.00       0.00 #> d[stroke = 0: Low dose aspirin]                                0.06       0.02 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.07       0.03 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.02       0.01 #> d[stroke = 0: Medium dose aspirin]                             0.00       0.00 #> d[stroke = 0: Placebo/Standard care]                           0.20       0.09 #> d[stroke = 0: Triflusal]                                       0.14       0.31 #> d[stroke = 0: Ximelagatran]                                    0.00       0.00 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.12      0.34 #> d[stroke = 1: Acenocoumarol]                                  0.04      0.02      0.02 #> d[stroke = 1: Alternate day aspirin]                          0.36      0.11      0.05 #> d[stroke = 1: Dipyridamole]                                   0.00      0.00      0.00 #> d[stroke = 1: Fixed dose warfarin]                            0.00      0.01      0.02 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.02      0.03      0.02 #> d[stroke = 1: Indobufen]                                      0.03      0.09      0.11 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.45      0.32      0.11 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.00      0.01      0.02 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.00      0.00 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 1: Triflusal]                                      0.00      0.00      0.00 #> d[stroke = 1: Ximelagatran]                                   0.09      0.27      0.30 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.34      0.14      0.03 #> d[stroke = 1: Acenocoumarol]                                  0.01      0.02      0.02 #> d[stroke = 1: Alternate day aspirin]                          0.06      0.09      0.08 #> d[stroke = 1: Dipyridamole]                                   0.01      0.01      0.05 #> d[stroke = 1: Fixed dose warfarin]                            0.06      0.17      0.25 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.03      0.06      0.09 #> d[stroke = 1: Indobufen]                                      0.19      0.26      0.16 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.06      0.04      0.01 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.01      0.02 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.03      0.07      0.14 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.01      0.06 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.01 #> d[stroke = 1: Triflusal]                                      0.01      0.02      0.03 #> d[stroke = 1: Ximelagatran]                                   0.19      0.11      0.03 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.00      0.00 #> d[stroke = 1: Acenocoumarol]                                  0.02      0.02      0.01 #> d[stroke = 1: Alternate day aspirin]                          0.06      0.04      0.03 #> d[stroke = 1: Dipyridamole]                                   0.07      0.10      0.12 #> d[stroke = 1: Fixed dose warfarin]                            0.16      0.09      0.06 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.01      0.01      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.01      0.01      0.01 #> d[stroke = 1: High dose aspirin]                              0.10      0.07      0.07 #> d[stroke = 1: Indobufen]                                      0.08      0.03      0.02 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin]                               0.01      0.03      0.06 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.04      0.07      0.10 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.18      0.15      0.11 #> d[stroke = 1: Medium dose aspirin]                            0.18      0.25      0.23 #> d[stroke = 1: Placebo/Standard care]                          0.02      0.06      0.12 #> d[stroke = 1: Triflusal]                                      0.05      0.05      0.05 #> d[stroke = 1: Ximelagatran]                                   0.01      0.00      0.00 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.01       0.01       0.01 #> d[stroke = 1: Alternate day aspirin]                           0.02       0.02       0.02 #> d[stroke = 1: Dipyridamole]                                    0.13       0.12       0.11 #> d[stroke = 1: Fixed dose warfarin]                             0.05       0.04       0.03 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.01       0.01       0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.01       0.01       0.01 #> d[stroke = 1: High dose aspirin]                               0.06       0.06       0.06 #> d[stroke = 1: Indobufen]                                       0.01       0.01       0.01 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.11       0.18       0.24 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.12       0.14       0.17 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.09       0.07       0.05 #> d[stroke = 1: Medium dose aspirin]                             0.13       0.08       0.04 #> d[stroke = 1: Placebo/Standard care]                           0.18       0.20       0.18 #> d[stroke = 1: Triflusal]                                       0.06       0.07       0.07 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00       0.00 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.02       0.05       0.44 #> d[stroke = 1: Alternate day aspirin]                           0.03       0.03       0.01 #> d[stroke = 1: Dipyridamole]                                    0.13       0.10       0.03 #> d[stroke = 1: Fixed dose warfarin]                             0.02       0.02       0.01 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.01       0.01       0.05 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.01       0.02       0.26 #> d[stroke = 1: High dose aspirin]                               0.09       0.13       0.04 #> d[stroke = 1: Indobufen]                                       0.00       0.00       0.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.20       0.12       0.04 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.18       0.09       0.03 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.04       0.03       0.01 #> d[stroke = 1: Medium dose aspirin]                             0.01       0.00       0.00 #> d[stroke = 1: Placebo/Standard care]                           0.13       0.07       0.03 #> d[stroke = 1: Triflusal]                                       0.12       0.33       0.06 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00       0.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.19       0.07 #> d[stroke = 1: Alternate day aspirin]                           0.00       0.00 #> d[stroke = 1: Dipyridamole]                                    0.01       0.01 #> d[stroke = 1: Fixed dose warfarin]                             0.01       0.00 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.19       0.66 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.50       0.16 #> d[stroke = 1: High dose aspirin]                               0.02       0.03 #> d[stroke = 1: Indobufen]                                       0.00       0.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.02       0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.01       0.01 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.00       0.00 #> d[stroke = 1: Medium dose aspirin]                             0.00       0.00 #> d[stroke = 1: Placebo/Standard care]                           0.01       0.00 #> d[stroke = 1: Triflusal]                                       0.04       0.05 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00  # Modify the default output with ggplot2 functionality library(ggplot2) plot(af_4b_rankprobs) +    facet_grid(Treatment~Study, labeller = label_wrap_gen(20)) +    theme(strip.text.y = element_text(angle = 0)) (af_4b_cumrankprobs <- posterior_rank_probs(af_fit_4b, cumulative = TRUE,                                             newdata = data.frame(stroke = c(0, 1),                                                                   label = c(\"stroke = 0\", \"stroke = 1\")),                                              study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.00      0.00      0.01 #> d[stroke = 0: Acenocoumarol]                                  0.27      0.50      0.64 #> d[stroke = 0: Alternate day aspirin]                          0.43      0.58      0.66 #> d[stroke = 0: Dipyridamole]                                   0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.00      0.00 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.05      0.15      0.26 #> d[stroke = 0: High dose aspirin]                              0.03      0.10      0.16 #> d[stroke = 0: Indobufen]                                      0.17      0.42      0.64 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.04      0.17      0.40 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.01      0.04      0.11 #> d[stroke = 0: Medium dose aspirin]                            0.00      0.00      0.01 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.00      0.00      0.02 #> d[stroke = 0: Ximelagatran]                                   0.00      0.02      0.07 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.03      0.11      0.27 #> d[stroke = 0: Acenocoumarol]                                  0.73      0.78      0.82 #> d[stroke = 0: Alternate day aspirin]                          0.73      0.76      0.80 #> d[stroke = 0: Dipyridamole]                                   0.05      0.09      0.14 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.04      0.09      0.13 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.36      0.46      0.53 #> d[stroke = 0: High dose aspirin]                              0.24      0.31      0.36 #> d[stroke = 0: Indobufen]                                      0.77      0.84      0.88 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.61      0.75      0.83 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.01      0.02      0.04 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.21      0.32      0.42 #> d[stroke = 0: Medium dose aspirin]                            0.03      0.08      0.17 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.03      0.06      0.09 #> d[stroke = 0: Ximelagatran]                                   0.17      0.32      0.48 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.47      0.68      0.84 #> d[stroke = 0: Acenocoumarol]                                  0.85      0.88      0.90 #> d[stroke = 0: Alternate day aspirin]                          0.82      0.84      0.86 #> d[stroke = 0: Dipyridamole]                                   0.18      0.25      0.33 #> d[stroke = 0: Fixed dose warfarin]                            0.03      0.05      0.07 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.19      0.25      0.32 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.59      0.64      0.70 #> d[stroke = 0: High dose aspirin]                              0.41      0.45      0.49 #> d[stroke = 0: Indobufen]                                      0.91      0.93      0.95 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.88      0.92      0.95 #> d[stroke = 0: Low dose aspirin]                               0.01      0.02      0.04 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.07      0.12      0.18 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.51      0.59      0.67 #> d[stroke = 0: Medium dose aspirin]                            0.31      0.47      0.66 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.01      0.02 #> d[stroke = 0: Triflusal]                                      0.12      0.15      0.19 #> d[stroke = 0: Ximelagatran]                                   0.63      0.75      0.84 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.94       0.98       1.00 #> d[stroke = 0: Acenocoumarol]                                   0.92       0.94       0.95 #> d[stroke = 0: Alternate day aspirin]                           0.88       0.90       0.91 #> d[stroke = 0: Dipyridamole]                                    0.41       0.52       0.61 #> d[stroke = 0: Fixed dose warfarin]                             0.11       0.17       0.24 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.40       0.50       0.60 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.74       0.79       0.83 #> d[stroke = 0: High dose aspirin]                               0.54       0.59       0.64 #> d[stroke = 0: Indobufen]                                       0.96       0.98       0.98 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.97       0.98       0.99 #> d[stroke = 0: Low dose aspirin]                                0.11       0.23       0.41 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.28       0.40       0.54 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.75       0.81       0.86 #> d[stroke = 0: Medium dose aspirin]                             0.81       0.90       0.96 #> d[stroke = 0: Placebo/Standard care]                           0.04       0.08       0.17 #> d[stroke = 0: Triflusal]                                       0.23       0.28       0.34 #> d[stroke = 0: Ximelagatran]                                    0.90       0.94       0.97 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 0: Acenocoumarol]                                   0.96       0.97       0.99 #> d[stroke = 0: Alternate day aspirin]                           0.93       0.94       0.96 #> d[stroke = 0: Dipyridamole]                                    0.70       0.78       0.87 #> d[stroke = 0: Fixed dose warfarin]                             0.33       0.43       0.57 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.69       0.79       0.88 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.88       0.90       0.94 #> d[stroke = 0: High dose aspirin]                               0.68       0.72       0.78 #> d[stroke = 0: Indobufen]                                       0.99       0.99       1.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 0: Low dose aspirin]                                0.60       0.79       0.92 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.68       0.80       0.90 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.90       0.94       0.96 #> d[stroke = 0: Medium dose aspirin]                             0.98       0.99       1.00 #> d[stroke = 0: Placebo/Standard care]                           0.30       0.48       0.71 #> d[stroke = 0: Triflusal]                                       0.40       0.47       0.55 #> d[stroke = 0: Ximelagatran]                                    0.99       0.99       1.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           1.00          1 #> d[stroke = 0: Acenocoumarol]                                   1.00          1 #> d[stroke = 0: Alternate day aspirin]                           0.97          1 #> d[stroke = 0: Dipyridamole]                                    0.95          1 #> d[stroke = 0: Fixed dose warfarin]                             0.76          1 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.95          1 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.97          1 #> d[stroke = 0: High dose aspirin]                               0.86          1 #> d[stroke = 0: Indobufen]                                       1.00          1 #> d[stroke = 0: Low adjusted dose anti-coagulant]                1.00          1 #> d[stroke = 0: Low dose aspirin]                                0.98          1 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.97          1 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.99          1 #> d[stroke = 0: Medium dose aspirin]                             1.00          1 #> d[stroke = 0: Placebo/Standard care]                           0.91          1 #> d[stroke = 0: Triflusal]                                       0.69          1 #> d[stroke = 0: Ximelagatran]                                    1.00          1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.13      0.47 #> d[stroke = 1: Acenocoumarol]                                  0.04      0.06      0.08 #> d[stroke = 1: Alternate day aspirin]                          0.36      0.46      0.51 #> d[stroke = 1: Dipyridamole]                                   0.00      0.00      0.00 #> d[stroke = 1: Fixed dose warfarin]                            0.00      0.02      0.04 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.02 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.02      0.05      0.07 #> d[stroke = 1: Indobufen]                                      0.03      0.12      0.23 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.45      0.77      0.88 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.00      0.01      0.03 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.00      0.00 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 1: Triflusal]                                      0.00      0.00      0.01 #> d[stroke = 1: Ximelagatran]                                   0.09      0.36      0.65 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.81      0.95      0.99 #> d[stroke = 1: Acenocoumarol]                                  0.09      0.11      0.13 #> d[stroke = 1: Alternate day aspirin]                          0.58      0.66      0.75 #> d[stroke = 1: Dipyridamole]                                   0.01      0.03      0.07 #> d[stroke = 1: Fixed dose warfarin]                            0.10      0.26      0.51 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.02      0.03      0.04 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.01      0.01      0.01 #> d[stroke = 1: High dose aspirin]                              0.10      0.17      0.26 #> d[stroke = 1: Indobufen]                                      0.42      0.68      0.83 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.94      0.98      0.99 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.01      0.03 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.06      0.13      0.26 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.02      0.07 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.01 #> d[stroke = 1: Triflusal]                                      0.02      0.03      0.06 #> d[stroke = 1: Ximelagatran]                                   0.84      0.95      0.98 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          1.00      1.00      1.00 #> d[stroke = 1: Acenocoumarol]                                  0.15      0.17      0.18 #> d[stroke = 1: Alternate day aspirin]                          0.80      0.84      0.87 #> d[stroke = 1: Dipyridamole]                                   0.14      0.24      0.36 #> d[stroke = 1: Fixed dose warfarin]                            0.67      0.76      0.82 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.05      0.06      0.06 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.02      0.03      0.04 #> d[stroke = 1: High dose aspirin]                              0.37      0.44      0.51 #> d[stroke = 1: Indobufen]                                      0.91      0.95      0.97 #> d[stroke = 1: Low adjusted dose anti-coagulant]               1.00      1.00      1.00 #> d[stroke = 1: Low dose aspirin]                               0.01      0.04      0.10 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.07      0.15      0.25 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.44      0.60      0.71 #> d[stroke = 1: Medium dose aspirin]                            0.25      0.51      0.74 #> d[stroke = 1: Placebo/Standard care]                          0.03      0.08      0.20 #> d[stroke = 1: Triflusal]                                      0.11      0.16      0.21 #> d[stroke = 1: Ximelagatran]                                   0.99      1.00      1.00 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 1: Acenocoumarol]                                   0.20       0.21       0.22 #> d[stroke = 1: Alternate day aspirin]                           0.89       0.91       0.93 #> d[stroke = 1: Dipyridamole]                                    0.49       0.61       0.72 #> d[stroke = 1: Fixed dose warfarin]                             0.88       0.91       0.94 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.07       0.08       0.09 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.04       0.05       0.06 #> d[stroke = 1: High dose aspirin]                               0.58       0.63       0.69 #> d[stroke = 1: Indobufen]                                       0.98       0.99       0.99 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 1: Low dose aspirin]                                0.21       0.39       0.63 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.37       0.51       0.68 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.79       0.86       0.92 #> d[stroke = 1: Medium dose aspirin]                             0.86       0.94       0.98 #> d[stroke = 1: Placebo/Standard care]                           0.38       0.57       0.75 #> d[stroke = 1: Triflusal]                                       0.27       0.34       0.41 #> d[stroke = 1: Ximelagatran]                                    1.00       1.00       1.00 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 1: Acenocoumarol]                                   0.24       0.29       0.73 #> d[stroke = 1: Alternate day aspirin]                           0.96       0.98       0.99 #> d[stroke = 1: Dipyridamole]                                    0.85       0.95       0.98 #> d[stroke = 1: Fixed dose warfarin]                             0.96       0.98       0.99 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.10       0.11       0.16 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.07       0.08       0.34 #> d[stroke = 1: High dose aspirin]                               0.78       0.91       0.95 #> d[stroke = 1: Indobufen]                                       1.00       1.00       1.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 1: Low dose aspirin]                                0.83       0.94       0.98 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.86       0.95       0.98 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.96       0.99       0.99 #> d[stroke = 1: Medium dose aspirin]                             0.99       1.00       1.00 #> d[stroke = 1: Placebo/Standard care]                           0.89       0.96       0.99 #> d[stroke = 1: Triflusal]                                       0.53       0.85       0.92 #> d[stroke = 1: Ximelagatran]                                    1.00       1.00       1.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00          1 #> d[stroke = 1: Acenocoumarol]                                   0.93          1 #> d[stroke = 1: Alternate day aspirin]                           1.00          1 #> d[stroke = 1: Dipyridamole]                                    0.99          1 #> d[stroke = 1: Fixed dose warfarin]                             1.00          1 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.34          1 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.84          1 #> d[stroke = 1: High dose aspirin]                               0.97          1 #> d[stroke = 1: Indobufen]                                       1.00          1 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00          1 #> d[stroke = 1: Low dose aspirin]                                1.00          1 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.99          1 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 1.00          1 #> d[stroke = 1: Medium dose aspirin]                             1.00          1 #> d[stroke = 1: Placebo/Standard care]                           1.00          1 #> d[stroke = 1: Triflusal]                                       0.95          1 #> d[stroke = 1: Ximelagatran]                                    1.00          1  plot(af_4b_cumrankprobs) +    facet_grid(Treatment~Study, labeller = label_wrap_gen(20)) +    theme(strip.text.y = element_text(angle = 0))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: Atrial fibrillation","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC slightly lower meta-regression model, although couple points (substantial differences usually considered 3-5 points). estimated heterogeneity standard deviation much lower meta-regression model, suggesting adjusting proportion patients prior stroke explaining heterogeneity data. can also examine residual deviance contributions corresponding plot() method.","code":"(af_dic_1 <- dic(af_fit_1)) #> Residual deviance: 60 (on 61 data points) #>                pD: 48.4 #>               DIC: 108.4 (af_dic_4b <- dic(af_fit_4b)) #> Residual deviance: 58.5 (on 61 data points) #>                pD: 48.1 #>               DIC: 106.6 plot(af_dic_1) plot(af_dic_4b)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: BCG vaccine for tuberculosis","text":"data giving number diagnosed TB trial follow-(r) total (n) arm, use function set_agd_arm() set network. set “unvaccinated” network reference treatment. latitude variable bcg_vaccine data frame automatically available use meta-regression model.","code":"bcg_net <- set_agd_arm(bcg_vaccine,                         study = studyn,                        trt = trtc,                        r = r,                         n = n,                        trt_ref = \"Unvaccinated\") bcg_net #> A network with 13 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms               #>  1     2: Unvaccinated | Vaccinated #>  2     2: Unvaccinated | Vaccinated #>  3     2: Unvaccinated | Vaccinated #>  4     2: Unvaccinated | Vaccinated #>  5     2: Unvaccinated | Vaccinated #>  6     2: Unvaccinated | Vaccinated #>  7     2: Unvaccinated | Vaccinated #>  8     2: Unvaccinated | Vaccinated #>  9     2: Unvaccinated | Vaccinated #>  10    2: Unvaccinated | Vaccinated #>  ... plus 3 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 13 #> Reference treatment is: Unvaccinated #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: BCG vaccine for tuberculosis","text":"fit random effects (RE) models, firstly without covariates, meta-regression continuous covariate latitude.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"re-meta-analysis-no-covariate","dir":"Articles","previous_headings":"Meta-analysis models","what":"RE meta-analysis (no covariate)","title":"Example: BCG vaccine for tuberculosis","text":"start fitting standard RE model without covariates. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Vaccine}\\) study-specific intercepts \\(\\mu_j\\), \\(\\textrm{half-N}(0, 5^2)\\) prior distribution heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: model fitted nma() function, random effects model specified trt_effects = \"random\". Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) random effects \\(\\delta_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. bcg_fit_unadj <- nma(bcg_net,                       trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = half_normal(scale = 5)) bcg_fit_unadj #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                    mean se_mean   sd      2.5%       25%       50%       75%     97.5% n_eff #> d[Vaccinated]     -0.75    0.01 0.22     -1.21     -0.89     -0.75     -0.61     -0.31  1392 #> lp__          -13453.80    0.14 4.57 -13463.88 -13456.60 -13453.51 -13450.65 -13445.84  1036 #> tau                0.69    0.01 0.21      0.39      0.54      0.65      0.79      1.19  1456 #>               Rhat #> d[Vaccinated]    1 #> lp__             1 #> tau              1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:39:38 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(bcg_fit_unadj, pars = c(\"d\", \"mu\", \"delta\", \"tau\")) plot_prior_posterior(bcg_fit_unadj, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"re-meta-regression-with-covariate-latitude","dir":"Articles","previous_headings":"Meta-analysis models","what":"RE meta-regression with covariate latitude","title":"Example: BCG vaccine for tuberculosis","text":"now fit RE meta-regression model, adjusting latitude. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Vaccine}\\), study-specific intercepts \\(\\mu_j\\), regression coefficient \\(\\beta\\). use \\(\\text{half-N}(0, 5^2)\\) prior distribution heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: , model fitted nma() function. regression formula ~ .trt:latitude means interaction latitude treatment included; .trt special variable indicates treatment, latitude original data set. increase adapt_delta 0.99 remove small number divergent transition errors (default RE models set 0.95). Basic parameter summaries given print() method: Note latitude automatically centered 33.46, mean value studies network. default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. bcg_fit_lat <- nma(bcg_net,                     trt_effects = \"random\",                    regression = ~.trt:latitude,                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_reg = normal(scale = 100),                    prior_het = half_normal(scale = 5),                    adapt_delta = 0.99) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. bcg_fit_lat #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:latitude. #> Centred covariates at the following overall mean values: #> latitude  #> 33.46154  #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                    mean se_mean   sd      2.5%       25%       50%       75% #> beta[.trtVaccinated:latitude]     -0.03    0.00 0.01     -0.05     -0.04     -0.03     -0.03 #> d[Vaccinated]                     -0.76    0.00 0.13     -1.03     -0.83     -0.75     -0.69 #> lp__                          -13457.42    0.19 5.18 -13468.10 -13460.81 -13457.14 -13453.79 #> tau                                0.29    0.01 0.19      0.02      0.15      0.26      0.39 #>                                   97.5% n_eff Rhat #> beta[.trtVaccinated:latitude]     -0.01  1979 1.00 #> d[Vaccinated]                     -0.51  1809 1.00 #> lp__                          -13448.05   758 1.01 #> tau                                0.75   795 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:39:52 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(bcg_fit_lat, pars = c(\"d\", \"beta\", \"mu\", \"delta\", \"tau\")) plot_prior_posterior(bcg_fit_lat, prior = c(\"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: BCG vaccine for tuberculosis","text":"Model fit can checked using dic() function: DIC similar two models, might first choose unadjusted model. posterior mean residual deviance larger model covariate, model also lower effective number parameters \\(p_D\\) allowing shrinkage random treatment effects. Moreover, model covariate much lower estimated heterogeneity standard deviation: Adjusting latitude explaining substantial amount heterogeneity data. 95% Credible Interval regression coefficient also excludes zero:  Altogether, might prefer model adjustment latitude. considering covariates random effects models important just look DIC (Dias et al. 2011). also consider reductions heterogeneity, estimated regression coefficients standard error. DIC sensitive changes heterogeneity, RE models flexible can fit data well whatever level heterogeneity.","code":"(bcg_dic_unadj <- dic(bcg_fit_unadj)) #> Residual deviance: 25.8 (on 26 data points) #>                pD: 23.4 #>               DIC: 49.2 (bcg_dic_lat <- dic(bcg_fit_lat)) #> Residual deviance: 30.8 (on 26 data points) #>                pD: 21.4 #>               DIC: 52.2 summary(bcg_fit_unadj, pars = \"tau\") #>     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau 0.69 0.21 0.39 0.54 0.65 0.79  1.19     1414     2154    1 summary(bcg_fit_lat, pars = \"tau\") #>     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau 0.29 0.19 0.02 0.15 0.26 0.39  0.75      708     1021 1.01 summary(bcg_fit_lat, pars = \"beta\") #>                                mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> beta[.trtVaccinated:latitude] -0.03 0.01 -0.05 -0.04 -0.03 -0.03 -0.01     2122     1894    1  plot(bcg_fit_lat,       pars = \"beta\",       ref_line = 0,      stat = \"halfeye\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: BCG vaccine for tuberculosis","text":"can produce estimates relative effect vaccination latitude using relative_effects() function. newdata argument specifies data frame containing values covariate latitude interested , study argument used specify column newdata informative label. plot() method may used visually compare estimates:  sophisticated plot shows regression line confidence band effect latitude, overlaid observed log odds ratios study:  presence heterogeneity, argued decision makers consider predictive distribution relative effects new study, instead posterior distribution mean treatment effects, reflects uncertainty due heterogeneity may better represent uncertainty future roll-treatment (see Dias et al. 2011). can produce predictive distributions using predictive_distribution = TRUE argument relative_effects(). Dias et al. (2018, sec. 8.3.2) consider predictive distributions BCG vaccine analysis. unadjusted analysis, whilst substantial evidence vaccination effective average essentially zero probability harm based mean effect, predictive distribution effectiveness new study wide covers range harmful effects: predictive probability new trial showing harmful effect : analysis adjusting latitude, predictive distribution relative effects now depends latitude; calculate increments 10 degrees equator: predictive probabilities new trial carried given latitude showing harmful effect can calculated : predictive probability new trial carried equator shows harmful effect around 80%, whereas 50 degrees latitude predictive probability 0.7%.","code":"bcg_releff_lat <- relative_effects(bcg_fit_lat,                                    newdata = tibble::tibble(latitude = seq(10, 50, by = 10),                                                             label = paste0(latitude, \"\\u00B0 latitude\")),                                    study = label)  bcg_releff_lat #> ----------------------------------------------------------- Study: 10° latitude ----  #>  #> Covariate values: #>  latitude #>        10 #>  #>                              mean   sd  2.5%   25% 50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[10° latitude: Vaccinated] -0.01 0.23 -0.54 -0.13   0 0.11  0.44     1825     1947    1 #>  #> ----------------------------------------------------------- Study: 20° latitude ----  #>  #> Covariate values: #>  latitude #>        20 #>  #>                              mean   sd 2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[20° latitude: Vaccinated] -0.33 0.16 -0.7 -0.41 -0.32 -0.24 -0.01     1769     1786    1 #>  #> ----------------------------------------------------------- Study: 30° latitude ----  #>  #> Covariate values: #>  latitude #>        30 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[30° latitude: Vaccinated] -0.65 0.13 -0.93 -0.72 -0.64 -0.58 -0.41     1832     1813    1 #>  #> ----------------------------------------------------------- Study: 40° latitude ----  #>  #> Covariate values: #>  latitude #>        40 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[40° latitude: Vaccinated] -0.97 0.14 -1.27 -1.05 -0.96 -0.89 -0.68     2030     1917    1 #>  #> ----------------------------------------------------------- Study: 50° latitude ----  #>  #> Covariate values: #>  latitude #>        50 #>  #>                              mean  sd  2.5%  25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[50° latitude: Vaccinated] -1.29 0.2 -1.68 -1.4 -1.29 -1.18 -0.88     2139     1993    1 plot(bcg_releff_lat,       ref_line = 0) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2)  # Get data for regression line lat_range <- range(bcg_vaccine$latitude) lat_dat <- tibble(latitude = seq(lat_range[1], lat_range[2], by = 1))  bcg_lat_reg <- relative_effects(bcg_fit_lat,                                  newdata = lat_dat) %>%    as_tibble() %>%    bind_cols(lat_dat)  # Get study log odds ratios bcg_lor <- bcg_vaccine %>%    group_by(studyn) %>%    mutate(lor = log(r / (n - r)) - log(first(r) / (first(n) - first(r))),          sample_size = sum(n)) %>%    slice(-1)  # Plot ggplot(aes(x = latitude), data = bcg_lor) +   geom_hline(yintercept = 0, colour = \"grey60\") +   geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), data = bcg_lat_reg,               fill = \"darkred\", alpha = 0.3) +   geom_line(aes(y = mean), data = bcg_lat_reg,             colour = \"darkred\") +   geom_point(aes(y = lor, size = sample_size), alpha = 0.6) +   coord_cartesian(xlim = c(0, 60)) +   xlab(\"Degrees Latitude\") + ylab(\"log Odds Ratio\") +   scale_size(\"Sample Size\") +   theme_multinma() (bcg_predeff_unadj <- relative_effects(bcg_fit_unadj, predictive_distribution = TRUE)) #>                        mean   sd 2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> delta_new[Vaccinated] -0.76 0.75 -2.3 -1.22 -0.76 -0.31  0.73     3623     3487    1 mean(as.matrix(bcg_predeff_unadj) > 0) #> [1] 0.1425 bcg_predeff_lat <- relative_effects(bcg_fit_lat,                                    newdata = tibble::tibble(latitude = seq(0, 50, by = 10),                                                             label = paste0(latitude, \"\\u00B0 latitude\")),                                    study = label,                                    predictive_distribution = TRUE)  bcg_predeff_lat #> ------------------------------------------------------------ Study: 0° latitude ----  #>  #> Covariate values: #>  latitude #>         0 #>  #>                                    mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> delta_new[0° latitude: Vaccinated]  0.3 0.47 -0.73 0.08 0.33 0.53  1.23     2598     2673    1 #>  #> ----------------------------------------------------------- Study: 10° latitude ----  #>  #> Covariate values: #>  latitude #>        10 #>  #>                                      mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> delta_new[10° latitude: Vaccinated] -0.02 0.42 -0.95 -0.21 0.01 0.18  0.82     2807     2820 #>                                     Rhat #> delta_new[10° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 20° latitude ----  #>  #> Covariate values: #>  latitude #>        20 #>  #>                                      mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[20° latitude: Vaccinated] -0.34 0.39 -1.18 -0.51 -0.32 -0.16  0.43     3128     2940 #>                                     Rhat #> delta_new[20° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 30° latitude ----  #>  #> Covariate values: #>  latitude #>        30 #>  #>                                      mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[30° latitude: Vaccinated] -0.65 0.37 -1.46 -0.82 -0.64 -0.48  0.09     3504     2676 #>                                     Rhat #> delta_new[30° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 40° latitude ----  #>  #> Covariate values: #>  latitude #>        40 #>  #>                                      mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS #> delta_new[40° latitude: Vaccinated] -0.97 0.37 -1.77 -1.14 -0.96 -0.8  -0.2     3578     2661 #>                                     Rhat #> delta_new[40° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 50° latitude ----  #>  #> Covariate values: #>  latitude #>        50 #>  #>                                      mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[50° latitude: Vaccinated] -1.29 0.39 -2.13 -1.47 -1.29 -1.09 -0.48     3389     2445 #>                                     Rhat #> delta_new[50° latitude: Vaccinated]    1 colMeans(as.matrix(bcg_predeff_lat) > 0) #>  delta_new[0° latitude: Vaccinated] delta_new[10° latitude: Vaccinated]  #>                             0.80375                             0.50975  #> delta_new[20° latitude: Vaccinated] delta_new[30° latitude: Vaccinated]  #>                             0.13375                             0.03700  #> delta_new[40° latitude: Vaccinated] delta_new[50° latitude: Vaccinated]  #>                             0.01325                             0.00425"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Beta blockers","text":"begin setting network - just pairwise meta-analysis. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). set “Control” reference treatment.","code":"blocker_net <- set_agd_arm(blocker,                             study = studyn,                            trt = trtc,                            r = r,                             n = n,                            trt_ref = \"Control\") blocker_net #> A network with 22 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms            #>  1     2: Control | Beta Blocker #>  2     2: Control | Beta Blocker #>  3     2: Control | Beta Blocker #>  4     2: Control | Beta Blocker #>  5     2: Control | Beta Blocker #>  6     2: Control | Beta Blocker #>  7     2: Control | Beta Blocker #>  8     2: Control | Beta Blocker #>  9     2: Control | Beta Blocker #>  10    2: Control | Beta Blocker #>  ... plus 12 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 22 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Beta blockers","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Beta blockers","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. blocker_fit_FE <- nma(blocker_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) blocker_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                     mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff Rhat #> d[Beta Blocker]    -0.26    0.00 0.05    -0.36    -0.30    -0.26    -0.23    -0.17  3103    1 #> lp__            -5960.39    0.08 3.37 -5967.60 -5962.45 -5960.10 -5957.98 -5954.76  1582    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:40:11 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(blocker_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(blocker_fit_FE, prior = \"trt\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Beta blockers","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. blocker_fit_RE <- nma(blocker_net,                     trt_effects = \"random\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_het = half_normal(scale = 5)) blocker_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                     mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff Rhat #> d[Beta Blocker]    -0.25    0.00 0.07    -0.38    -0.29    -0.25    -0.21    -0.11  2726    1 #> lp__            -5970.57    0.18 5.42 -5982.08 -5974.11 -5970.41 -5966.78 -5960.67   955    1 #> tau                 0.14    0.00 0.08     0.01     0.08     0.13     0.19     0.32   975    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:40:21 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(blocker_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(blocker_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Beta blockers","text":"Model fit can checked using dic() function: residual deviance lower RE model, expected model flexible. However, comes increased effective number parameters (note increase \\(p_D\\)). result, DIC models similar FE model may preferred parsimony. can also examine residual deviance contributions corresponding plot() method.   number points well fit FE model, posterior mean residual deviance contributions greater 1. Study 14 particularly poor fit FE model, residual deviance reduced (although still high) RE model. evidence given careful examination, consideration given issues potential effect-modifying covariates (Dias et al. 2011).","code":"(dic_FE <- dic(blocker_fit_FE)) #> Residual deviance: 46.8 (on 44 data points) #>                pD: 23.2 #>               DIC: 70 (dic_RE <- dic(blocker_fit_RE)) #> Residual deviance: 41.9 (on 44 data points) #>                pD: 28.4 #>               DIC: 70.3 plot(dic_FE) plot(dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Beta blockers","text":"Dias et al. (2011) produce absolute predictions probability mortality beta blockers control, assuming Normal distribution baseline logit-probability mortality mean \\(-2.2\\) precision \\(3.3\\). can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted probabilities (type = \"link\" produce predicted log odds).   instead information baseline logit-probability mortality event counts, can use construct Beta distribution baseline probability mortality. example, 4 36 individuals died control treatment target population interest, appropriate Beta distribution probability \\(\\textrm{Beta}(4, 36-4)\\). can specify Beta distribution baseline response using baseline_type = \"reponse\" argument (default \"link\", used baseline logit-probability).   Notice results nearly equivalent calculated using Normal distribution baseline logit-probability, since event counts correspond approximately distribution logit-probability.","code":"pred_FE <- predict(blocker_fit_FE,                     baseline = distr(qnorm, mean = -2.2, sd = 3.3^-0.5),                     type = \"response\") pred_FE #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.04 0.07 0.10 0.14  0.24     3955     3888    1 #> pred[Beta Blocker] 0.09 0.05 0.03 0.06 0.08 0.11  0.20     3956     3928    1 plot(pred_FE) pred_RE <- predict(blocker_fit_RE,                     baseline = distr(qnorm, mean = -2.2, sd = 3.3^-0.5),                     type = \"response\") pred_RE #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.03 0.07 0.10 0.14  0.24     4110     3689    1 #> pred[Beta Blocker] 0.09 0.05 0.03 0.06 0.08 0.11  0.20     4153     4045    1 plot(pred_RE) pred_FE_beta <- predict(blocker_fit_FE,                          baseline = distr(qbeta, 4, 36-4),                         baseline_type = \"response\",                         type = \"response\") pred_FE_beta #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.03 0.07 0.10 0.14  0.23     4141     3875    1 #> pred[Beta Blocker] 0.09 0.04 0.02 0.06 0.08 0.11  0.19     4155     3798    1 plot(pred_FE_beta) pred_RE_beta <- predict(blocker_fit_RE,                          baseline = distr(qbeta, 4, 36-4),                         baseline_type = \"response\",                         type = \"response\") pred_RE_beta #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.03 0.07 0.11 0.14  0.23     3987     3716    1 #> pred[Beta Blocker] 0.09 0.04 0.02 0.06 0.08 0.12  0.19     3953     3539    1 plot(pred_RE_beta)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Diabetes","text":"begin setting network. arm-level count data giving number new cases diabetes (r) total (n) arm, use function set_agd_arm(). computational efficiency, let “Beta Blocker” set network reference treatment default. Elliott Meyer (2007) Dias et al. (2011) use “Diuretic” reference, simple matter transform results fitting NMA model.1 also details length follow-years trial (time), use offset cloglog link function model data rates. specify function set_agd_arm(): additional columns data (e.g. offsets covariates, column time) automatically made available network. Plot network structure.","code":"db_net <- set_agd_arm(diabetes,                        study = studyc,                       trt = trtc,                       r = r,                        n = n) db_net #> A network with 22 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study  Treatment arms                        #>  AASK   3: Beta Blocker | ACE Inhibitor | CCB #>  ALLHAT 3: ACE Inhibitor | CCB | Diuretic     #>  ALPINE 2: ARB | Diuretic                     #>  ANBP-2 2: ACE Inhibitor | Diuretic           #>  ASCOT  2: Beta Blocker | CCB                 #>  CAPPP  2: Beta Blocker | ACE Inhibitor       #>  CHARM  2: ARB | Placebo                      #>  DREAM  2: ACE Inhibitor | Placebo            #>  EWPH   2: Diuretic | Placebo                 #>  FEVER  2: CCB | Placebo                      #>  ... plus 12 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6 #> Total number of studies: 22 #> Reference treatment is: Beta Blocker #> Network is connected plot(db_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Diabetes","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Diabetes","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. specify cloglog link used link = \"cloglog\" (Binomial likelihood default data), specify log follow-time offset using regression formula regression = ~offset(log(time)). Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. db_fit_FE <- nma(db_net,                   trt_effects = \"fixed\",                  link = \"cloglog\",                  regression = ~offset(log(time)),                  prior_intercept = normal(scale = 100),                  prior_trt = normal(scale = 100)) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. #> Note: Setting \"Beta Blocker\" as the network reference treatment. db_fit_FE #> A fixed effects NMA with a binomial likelihood (cloglog link). #> Regression model: ~offset(log(time)). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                       mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[ACE Inhibitor]     -0.30    0.00 0.04     -0.39     -0.33     -0.30     -0.27     -0.22 #> d[ARB]               -0.40    0.00 0.05     -0.48     -0.43     -0.40     -0.37     -0.31 #> d[CCB]               -0.20    0.00 0.03     -0.26     -0.22     -0.20     -0.18     -0.14 #> d[Diuretic]           0.06    0.00 0.05     -0.05      0.02      0.06      0.09      0.16 #> d[Placebo]           -0.19    0.00 0.05     -0.29     -0.22     -0.19     -0.16     -0.10 #> lp__             -37970.12    0.08 3.61 -37978.04 -37972.33 -37969.84 -37967.52 -37963.98 #>                  n_eff Rhat #> d[ACE Inhibitor]  1584    1 #> d[ARB]            2014    1 #> d[CCB]            1865    1 #> d[Diuretic]       1707    1 #> d[Placebo]        1475    1 #> lp__              1884    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:40:46 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(db_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(db_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Diabetes","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. db_fit_RE <- nma(db_net,                   trt_effects = \"random\",                  link = \"cloglog\",                  regression = ~offset(log(time)),                  prior_intercept = normal(scale = 10),                  prior_trt = normal(scale = 10),                  prior_het = half_normal(scale = 5),                  init_r = 0.5) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. #> Note: Setting \"Beta Blocker\" as the network reference treatment. db_fit_RE #> A random effects NMA with a binomial likelihood (cloglog link). #> Regression model: ~offset(log(time)). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                       mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[ACE Inhibitor]     -0.33    0.00 0.08     -0.49     -0.38     -0.32     -0.28     -0.18 #> d[ARB]               -0.40    0.00 0.09     -0.60     -0.46     -0.40     -0.34     -0.23 #> d[CCB]               -0.17    0.00 0.06     -0.29     -0.21     -0.17     -0.13     -0.05 #> d[Diuretic]           0.07    0.00 0.08     -0.09      0.02      0.07      0.13      0.24 #> d[Placebo]           -0.21    0.00 0.08     -0.38     -0.27     -0.21     -0.16     -0.06 #> lp__             -37980.95    0.22 6.71 -37994.68 -37985.24 -37980.80 -37976.28 -37968.66 #> tau                   0.13    0.00 0.04      0.05      0.10      0.12      0.15      0.22 #>                  n_eff Rhat #> d[ACE Inhibitor]  1767 1.00 #> d[ARB]            2187 1.00 #> d[CCB]            1997 1.00 #> d[Diuretic]       2212 1.00 #> d[Placebo]        1671 1.00 #> lp__               935 1.00 #> tau                770 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:41:12 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(db_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(db_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Diabetes","text":"Model fit can checked using dic() function: FE model poor fit data, residual deviance much higher number data points. RE model fits data better, much lower DIC; prefer RE model. can also examine residual deviance contributions corresponding plot() method.","code":"(dic_FE <- dic(db_fit_FE)) #> Residual deviance: 77.8 (on 48 data points) #>                pD: 26.6 #>               DIC: 104.5 (dic_RE <- dic(db_fit_RE)) #> Residual deviance: 53.8 (on 48 data points) #>                pD: 37.9 #>               DIC: 91.7 plot(dic_FE) plot(dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Diabetes","text":"comparison Elliott Meyer (2007) Dias et al. (2011), can produce relative effects “Diuretic” using relative_effects() function trt_ref = \"Diuretic\":   Dias et al. (2011) produce absolute predictions probability developing diabetes three years, assuming Normal distribution baseline cloglog probability developing diabetes diuretic treatment mean \\(-4.2\\) precision \\(1.11\\). can replicate results using predict() method. specify data frame newdata, containing time offset(s) produce predictions (3 years). baseline argument takes distr() distribution object specify corresponding Normal distribution baseline cloglog probability, set trt_ref = \"Diuretic\" indicate baseline distribution corresponds “Diuretic” rather network reference “Beta Blocker”. set type = \"response\" produce predicted event probabilities (type = \"link\" produce predicted cloglog probabilities).   baseline newdata arguments omitted, predicted probabilities produced every study network based follow-times estimated baseline cloglog probabilities \\(\\mu_j\\):  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(db_releff_FE <- relative_effects(db_fit_FE, trt_ref = \"Diuretic\")) #>                   mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Beta Blocker]  -0.06 0.05 -0.16 -0.09 -0.06 -0.02  0.05     1723     2312    1 #> d[ACE Inhibitor] -0.36 0.05 -0.46 -0.39 -0.36 -0.32 -0.26     4257     3705    1 #> d[ARB]           -0.45 0.06 -0.57 -0.49 -0.45 -0.41 -0.33     3582     3144    1 #> d[CCB]           -0.25 0.05 -0.35 -0.29 -0.25 -0.22 -0.15     3035     3090    1 #> d[Placebo]       -0.25 0.06 -0.36 -0.28 -0.25 -0.21 -0.14     3937     3342    1 plot(db_releff_FE, ref_line = 0) (db_releff_RE <- relative_effects(db_fit_RE, trt_ref = \"Diuretic\")) #>                   mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Beta Blocker]  -0.07 0.08 -0.24 -0.13 -0.07 -0.02  0.09     2234     2486    1 #> d[ACE Inhibitor] -0.40 0.09 -0.57 -0.46 -0.40 -0.34 -0.24     4469     3248    1 #> d[ARB]           -0.47 0.11 -0.69 -0.54 -0.47 -0.40 -0.27     4368     2985    1 #> d[CCB]           -0.24 0.08 -0.40 -0.29 -0.24 -0.19 -0.08     3995     3036    1 #> d[Placebo]       -0.29 0.09 -0.47 -0.34 -0.29 -0.23 -0.12     4328     3383    1 plot(db_releff_RE, ref_line = 0) db_pred_FE <- predict(db_fit_FE,                        newdata = data.frame(time = 3),                       baseline = distr(qnorm, mean = -4.2, sd = 1.11^-0.5),                        trt_ref = \"Diuretic\",                       type = \"response\") db_pred_FE #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: Beta Blocker]  0.06 0.06 0.01 0.02 0.04 0.08  0.24     4049     4100    1 #> pred[New 1: ACE Inhibitor] 0.05 0.05 0.00 0.02 0.03 0.06  0.19     4050     4143    1 #> pred[New 1: ARB]           0.04 0.05 0.00 0.01 0.03 0.05  0.17     4058     4188    1 #> pred[New 1: CCB]           0.05 0.05 0.01 0.02 0.03 0.07  0.20     4058     4143    1 #> pred[New 1: Diuretic]      0.07 0.07 0.01 0.02 0.04 0.08  0.25     4063     4098    1 #> pred[New 1: Placebo]       0.05 0.05 0.01 0.02 0.03 0.07  0.20     4055     4143    1 plot(db_pred_FE) db_pred_RE <- predict(db_fit_RE,                        newdata = data.frame(time = 3),                       baseline = distr(qnorm, mean = -4.2, sd = 1.11^-0.5),                        trt_ref = \"Diuretic\",                       type = \"response\") db_pred_RE #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: Beta Blocker]  0.06 0.06 0.01 0.02 0.04 0.08  0.23     3907     3680    1 #> pred[New 1: ACE Inhibitor] 0.04 0.05 0.00 0.02 0.03 0.06  0.18     3908     3681    1 #> pred[New 1: ARB]           0.04 0.05 0.00 0.01 0.03 0.05  0.16     3920     3790    1 #> pred[New 1: CCB]           0.05 0.06 0.00 0.02 0.03 0.07  0.20     3920     3644    1 #> pred[New 1: Diuretic]      0.06 0.07 0.01 0.02 0.04 0.08  0.24     3924     3752    1 #> pred[New 1: Placebo]       0.05 0.05 0.00 0.02 0.03 0.06  0.20     3949     3750    1 plot(db_pred_RE) db_pred_RE_studies <- predict(db_fit_RE, type = \"response\") db_pred_RE_studies #> ------------------------------------------------------------------- Study: AASK ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[AASK: Beta Blocker]  0.17 0.02 0.14 0.16 0.17 0.18  0.20     6111     2986    1 #> pred[AASK: ACE Inhibitor] 0.12 0.01 0.10 0.12 0.12 0.13  0.15     4255     2757    1 #> pred[AASK: ARB]           0.12 0.01 0.09 0.11 0.12 0.13  0.15     4910     3289    1 #> pred[AASK: CCB]           0.14 0.01 0.12 0.13 0.14 0.15  0.17     5803     3139    1 #> pred[AASK: Diuretic]      0.18 0.02 0.14 0.17 0.18 0.19  0.22     4993     3108    1 #> pred[AASK: Placebo]       0.14 0.02 0.11 0.13 0.14 0.15  0.17     4010     3096    1 #>  #> ----------------------------------------------------------------- Study: ALLHAT ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ALLHAT: Beta Blocker]  0.04 0.01 0.03 0.04 0.04 0.05  0.06     2909     2149    1 #> pred[ALLHAT: ACE Inhibitor] 0.03 0.00 0.02 0.03 0.03 0.03  0.04     4390     2499    1 #> pred[ALLHAT: ARB]           0.03 0.00 0.02 0.03 0.03 0.03  0.04     4117     2982    1 #> pred[ALLHAT: CCB]           0.04 0.00 0.03 0.03 0.04 0.04  0.05     4209     2672    1 #> pred[ALLHAT: Diuretic]      0.05 0.01 0.04 0.04 0.05 0.05  0.06     4545     2539    1 #> pred[ALLHAT: Placebo]       0.03 0.00 0.03 0.03 0.03 0.04  0.04     4419     2785    1 #>  #> ----------------------------------------------------------------- Study: ALPINE ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ALPINE: Beta Blocker]  0.03 0.01 0.01 0.02 0.03 0.03  0.05     6488     2992    1 #> pred[ALPINE: ACE Inhibitor] 0.02 0.01 0.01 0.01 0.02 0.02  0.03     7557     2785    1 #> pred[ALPINE: ARB]           0.02 0.01 0.01 0.01 0.02 0.02  0.03     7607     3046    1 #> pred[ALPINE: CCB]           0.02 0.01 0.01 0.02 0.02 0.03  0.04     7077     2934    1 #> pred[ALPINE: Diuretic]      0.03 0.01 0.01 0.02 0.03 0.03  0.05     7778     3033    1 #> pred[ALPINE: Placebo]       0.02 0.01 0.01 0.02 0.02 0.03  0.04     7731     2994    1 #>  #> ----------------------------------------------------------------- Study: ANBP-2 ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ANBP-2: Beta Blocker]  0.07 0.01 0.05 0.06 0.07 0.07  0.09     2974     2280    1 #> pred[ANBP-2: ACE Inhibitor] 0.05 0.01 0.04 0.04 0.05 0.05  0.06     4539     3116    1 #> pred[ANBP-2: ARB]           0.05 0.01 0.03 0.04 0.05 0.05  0.06     4516     2971    1 #> pred[ANBP-2: CCB]           0.06 0.01 0.04 0.05 0.06 0.06  0.08     3963     2917    1 #> pred[ANBP-2: Diuretic]      0.07 0.01 0.06 0.07 0.07 0.08  0.09     4864     3178    1 #> pred[ANBP-2: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     4691     3026    1 #>  #> ------------------------------------------------------------------ Study: ASCOT ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ASCOT: Beta Blocker]  0.11 0.00 0.10 0.11 0.11 0.11  0.12     4240     3059    1 #> pred[ASCOT: ACE Inhibitor] 0.08 0.01 0.07 0.08 0.08 0.09  0.10     2216     2393    1 #> pred[ASCOT: ARB]           0.08 0.01 0.06 0.07 0.08 0.08  0.09     2684     2278    1 #> pred[ASCOT: CCB]           0.10 0.01 0.08 0.09 0.10 0.10  0.11     2266     2720    1 #> pred[ASCOT: Diuretic]      0.12 0.01 0.10 0.11 0.12 0.13  0.14     2452     2873    1 #> pred[ASCOT: Placebo]       0.09 0.01 0.08 0.09 0.09 0.10  0.11     2106     2539    1 #>  #> ------------------------------------------------------------------ Study: CAPPP ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[CAPPP: Beta Blocker]  0.07 0.00 0.07 0.07 0.07 0.08  0.08     5495     3027    1 #> pred[CAPPP: ACE Inhibitor] 0.05 0.00 0.05 0.05 0.05 0.06  0.06     2127     2408    1 #> pred[CAPPP: ARB]           0.05 0.01 0.04 0.05 0.05 0.05  0.06     2672     2332    1 #> pred[CAPPP: CCB]           0.06 0.00 0.05 0.06 0.06 0.07  0.07     3043     2628    1 #> pred[CAPPP: Diuretic]      0.08 0.01 0.07 0.08 0.08 0.08  0.10     2856     2476    1 #> pred[CAPPP: Placebo]       0.06 0.01 0.05 0.06 0.06 0.06  0.07     1941     2042    1 #>  #> ------------------------------------------------------------------ Study: CHARM ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[CHARM: Beta Blocker]  0.09 0.01 0.07 0.08 0.09 0.10  0.12     2730     1651    1 #> pred[CHARM: ACE Inhibitor] 0.07 0.01 0.05 0.06 0.07 0.07  0.09     4335     2201    1 #> pred[CHARM: ARB]           0.06 0.01 0.05 0.06 0.06 0.07  0.08     4945     2150    1 #> pred[CHARM: CCB]           0.08 0.01 0.06 0.07 0.08 0.08  0.10     3813     1949    1 #> pred[CHARM: Diuretic]      0.10 0.01 0.07 0.09 0.10 0.10  0.13     4400     2307    1 #> pred[CHARM: Placebo]       0.07 0.01 0.06 0.07 0.07 0.08  0.10     5054     2422    1 #>  #> ------------------------------------------------------------------ Study: DREAM ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[DREAM: Beta Blocker]  0.23 0.03 0.18 0.21 0.23 0.24  0.29     2525     2293    1 #> pred[DREAM: ACE Inhibitor] 0.17 0.02 0.13 0.16 0.17 0.18  0.21     3983     2724    1 #> pred[DREAM: ARB]           0.16 0.02 0.12 0.14 0.16 0.17  0.20     4206     2918    1 #> pred[DREAM: CCB]           0.20 0.02 0.15 0.18 0.19 0.21  0.25     3503     2640    1 #> pred[DREAM: Diuretic]      0.24 0.03 0.19 0.22 0.24 0.26  0.31     3951     2760    1 #> pred[DREAM: Placebo]       0.19 0.02 0.15 0.17 0.19 0.20  0.23     4483     3116    1 #>  #> ------------------------------------------------------------------- Study: EWPH ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[EWPH: Beta Blocker]  0.06 0.01 0.04 0.05 0.06 0.07  0.09     4107     3100    1 #> pred[EWPH: ACE Inhibitor] 0.05 0.01 0.03 0.04 0.04 0.05  0.06     5734     2894    1 #> pred[EWPH: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     5520     2896    1 #> pred[EWPH: CCB]           0.05 0.01 0.03 0.05 0.05 0.06  0.08     5194     3131    1 #> pred[EWPH: Diuretic]      0.07 0.01 0.05 0.06 0.07 0.07  0.09     5649     3319    1 #> pred[EWPH: Placebo]       0.05 0.01 0.03 0.04 0.05 0.06  0.07     5855     2921    1 #>  #> ------------------------------------------------------------------ Study: FEVER ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[FEVER: Beta Blocker]  0.04 0.01 0.03 0.04 0.04 0.04  0.05     3024     2293    1 #> pred[FEVER: ACE Inhibitor] 0.03 0.00 0.02 0.03 0.03 0.03  0.04     4535     2541    1 #> pred[FEVER: ARB]           0.03 0.00 0.02 0.03 0.03 0.03  0.04     4482     2203    1 #> pred[FEVER: CCB]           0.04 0.00 0.03 0.03 0.03 0.04  0.05     4288     2805    1 #> pred[FEVER: Diuretic]      0.04 0.01 0.03 0.04 0.04 0.05  0.06     4295     2592    1 #> pred[FEVER: Placebo]       0.03 0.00 0.03 0.03 0.03 0.04  0.04     4224     2645    1 #>  #> ----------------------------------------------------------------- Study: HAPPHY ----  #>  #>                             mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[HAPPHY: Beta Blocker]  0.02  0 0.02 0.02 0.02 0.03  0.03     5587     3285    1 #> pred[HAPPHY: ACE Inhibitor] 0.02  0 0.01 0.02 0.02 0.02  0.02     4320     2626    1 #> pred[HAPPHY: ARB]           0.02  0 0.01 0.02 0.02 0.02  0.02     4109     2831    1 #> pred[HAPPHY: CCB]           0.02  0 0.02 0.02 0.02 0.02  0.03     4585     3059    1 #> pred[HAPPHY: Diuretic]      0.03  0 0.02 0.02 0.03 0.03  0.03     4177     3393    1 #> pred[HAPPHY: Placebo]       0.02  0 0.02 0.02 0.02 0.02  0.02     4143     3021    1 #>  #> ------------------------------------------------------------------- Study: HOPE ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[HOPE: Beta Blocker]  0.06 0.01 0.04 0.05 0.06 0.06  0.08     2751     2229    1 #> pred[HOPE: ACE Inhibitor] 0.04 0.01 0.03 0.04 0.04 0.05  0.05     4754     2807    1 #> pred[HOPE: ARB]           0.04 0.01 0.03 0.04 0.04 0.04  0.05     4458     2763    1 #> pred[HOPE: CCB]           0.05 0.01 0.04 0.04 0.05 0.05  0.07     3915     2923    1 #> pred[HOPE: Diuretic]      0.06 0.01 0.05 0.06 0.06 0.07  0.08     4724     2861    1 #> pred[HOPE: Placebo]       0.05 0.01 0.04 0.04 0.05 0.05  0.06     4721     2700    1 #>  #> ---------------------------------------------------------------- Study: INSIGHT ----  #>  #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[INSIGHT: Beta Blocker]  0.07 0.01 0.05 0.06 0.06 0.07  0.09     3510     2362    1 #> pred[INSIGHT: ACE Inhibitor] 0.05 0.01 0.03 0.04 0.05 0.05  0.06     4434     2923    1 #> pred[INSIGHT: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     4464     2806    1 #> pred[INSIGHT: CCB]           0.06 0.01 0.04 0.05 0.05 0.06  0.07     4654     2748    1 #> pred[INSIGHT: Diuretic]      0.07 0.01 0.05 0.06 0.07 0.07  0.09     4948     2733    1 #> pred[INSIGHT: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     4294     2614    1 #>  #> ----------------------------------------------------------------- Study: INVEST ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[INVEST: Beta Blocker]  0.08 0.00 0.08 0.08 0.08 0.08  0.09     6899     2715    1 #> pred[INVEST: ACE Inhibitor] 0.06 0.00 0.05 0.06 0.06 0.06  0.07     2082     2506    1 #> pred[INVEST: ARB]           0.06 0.01 0.05 0.05 0.06 0.06  0.07     2558     2106    1 #> pred[INVEST: CCB]           0.07 0.00 0.06 0.07 0.07 0.07  0.08     2447     2339    1 #> pred[INVEST: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.09  0.10     2538     2933    1 #> pred[INVEST: Placebo]       0.07 0.01 0.06 0.06 0.07 0.07  0.08     1962     2308    1 #>  #> ------------------------------------------------------------------- Study: LIFE ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[LIFE: Beta Blocker]  0.08 0.00 0.07 0.08 0.08 0.08  0.09     6473     3064    1 #> pred[LIFE: ACE Inhibitor] 0.06 0.01 0.05 0.06 0.06 0.06  0.07     2509     2526    1 #> pred[LIFE: ARB]           0.06 0.01 0.05 0.05 0.06 0.06  0.07     2661     2569    1 #> pred[LIFE: CCB]           0.07 0.01 0.06 0.07 0.07 0.07  0.08     3203     2977    1 #> pred[LIFE: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.09  0.10     2977     3001    1 #> pred[LIFE: Placebo]       0.07 0.01 0.05 0.06 0.07 0.07  0.08     2156     2137    1 #>  #> ------------------------------------------------------------------ Study: MRC-E ----  #>  #>                            mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[MRC-E: Beta Blocker]  0.03  0 0.02 0.03 0.03 0.03  0.04     4333     2920    1 #> pred[MRC-E: ACE Inhibitor] 0.02  0 0.02 0.02 0.02 0.02  0.03     5029     2904    1 #> pred[MRC-E: ARB]           0.02  0 0.01 0.02 0.02 0.02  0.03     4773     3342    1 #> pred[MRC-E: CCB]           0.03  0 0.02 0.02 0.02 0.03  0.03     4585     2935    1 #> pred[MRC-E: Diuretic]      0.03  0 0.02 0.03 0.03 0.03  0.04     4494     2961    1 #> pred[MRC-E: Placebo]       0.02  0 0.02 0.02 0.02 0.03  0.03     4987     2722    1 #>  #> ----------------------------------------------------------------- Study: NORDIL ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[NORDIL: Beta Blocker]  0.05 0.00 0.04 0.05 0.05 0.05  0.06     7618     3487    1 #> pred[NORDIL: ACE Inhibitor] 0.04 0.00 0.03 0.03 0.04 0.04  0.04     2844     2580    1 #> pred[NORDIL: ARB]           0.03 0.00 0.03 0.03 0.03 0.04  0.04     3075     2132    1 #> pred[NORDIL: CCB]           0.04 0.00 0.04 0.04 0.04 0.04  0.05     3486     2861    1 #> pred[NORDIL: Diuretic]      0.05 0.01 0.04 0.05 0.05 0.06  0.06     3163     3006    1 #> pred[NORDIL: Placebo]       0.04 0.00 0.03 0.04 0.04 0.04  0.05     2452     2459    1 #>  #> ------------------------------------------------------------------ Study: PEACE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[PEACE: Beta Blocker]  0.14 0.02 0.10 0.13 0.14 0.15  0.18     2899     2316    1 #> pred[PEACE: ACE Inhibitor] 0.10 0.01 0.08 0.09 0.10 0.11  0.13     4087     2440    1 #> pred[PEACE: ARB]           0.09 0.01 0.07 0.09 0.09 0.10  0.12     3903     2530    1 #> pred[PEACE: CCB]           0.12 0.02 0.09 0.11 0.12 0.13  0.15     3852     2740    1 #> pred[PEACE: Diuretic]      0.15 0.02 0.11 0.13 0.15 0.16  0.19     4167     2805    1 #> pred[PEACE: Placebo]       0.11 0.01 0.09 0.10 0.11 0.12  0.14     4231     2751    1 #>  #> ------------------------------------------------------------------ Study: SCOPE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[SCOPE: Beta Blocker]  0.06 0.01 0.05 0.06 0.06 0.07  0.09     3622     2721    1 #> pred[SCOPE: ACE Inhibitor] 0.05 0.01 0.03 0.04 0.05 0.05  0.06     4942     3158    1 #> pred[SCOPE: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     4989     2891    1 #> pred[SCOPE: CCB]           0.06 0.01 0.04 0.05 0.05 0.06  0.07     4315     2809    1 #> pred[SCOPE: Diuretic]      0.07 0.01 0.05 0.06 0.07 0.08  0.09     4639     3112    1 #> pred[SCOPE: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     5050     3080    1 #>  #> ------------------------------------------------------------------- Study: SHEP ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[SHEP: Beta Blocker]  0.09 0.01 0.06 0.08 0.09 0.09  0.11     3296     2453    1 #> pred[SHEP: ACE Inhibitor] 0.06 0.01 0.05 0.06 0.06 0.07  0.08     4811     2811    1 #> pred[SHEP: ARB]           0.06 0.01 0.04 0.05 0.06 0.06  0.08     4641     2833    1 #> pred[SHEP: CCB]           0.07 0.01 0.05 0.07 0.07 0.08  0.10     4600     2787    1 #> pred[SHEP: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.10  0.12     4935     2936    1 #> pred[SHEP: Placebo]       0.07 0.01 0.05 0.06 0.07 0.08  0.09     4863     2721    1 #>  #> ----------------------------------------------------------------- Study: STOP-2 ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[STOP-2: Beta Blocker]  0.05 0.00 0.05 0.05 0.05 0.06  0.06     4680     3011    1 #> pred[STOP-2: ACE Inhibitor] 0.04 0.00 0.03 0.04 0.04 0.04  0.05     2577     2308    1 #> pred[STOP-2: ARB]           0.04 0.00 0.03 0.03 0.04 0.04  0.04     3140     2367    1 #> pred[STOP-2: CCB]           0.05 0.00 0.04 0.04 0.05 0.05  0.05     3884     2566    1 #> pred[STOP-2: Diuretic]      0.06 0.01 0.05 0.05 0.06 0.06  0.07     3531     2649    1 #> pred[STOP-2: Placebo]       0.04 0.00 0.03 0.04 0.04 0.05  0.05     2463     2681    1 #>  #> ------------------------------------------------------------------ Study: VALUE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[VALUE: Beta Blocker]  0.20 0.02 0.15 0.18 0.19 0.21  0.25     2973     2364    1 #> pred[VALUE: ACE Inhibitor] 0.15 0.02 0.11 0.13 0.15 0.16  0.19     3752     2472    1 #> pred[VALUE: ARB]           0.14 0.02 0.10 0.13 0.14 0.14  0.17     4160     2299    1 #> pred[VALUE: CCB]           0.17 0.02 0.13 0.16 0.17 0.18  0.21     4000     2600    1 #> pred[VALUE: Diuretic]      0.21 0.03 0.16 0.19 0.21 0.22  0.27     3875     2418    1 #> pred[VALUE: Placebo]       0.16 0.02 0.12 0.15 0.16 0.17  0.21     3927     2250    1 plot(db_pred_RE_studies) (db_ranks <- posterior_ranks(db_fit_RE)) #>                     mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[Beta Blocker]  5.18 0.41    5   5   5   5     6     2251       NA    1 #> rank[ACE Inhibitor] 1.86 0.53    1   2   2   2     3     3690     3063    1 #> rank[ARB]           1.25 0.49    1   1   1   1     2     3486     3190    1 #> rank[CCB]           3.69 0.52    3   3   4   4     4     3904     3212    1 #> rank[Diuretic]      5.81 0.40    5   6   6   6     6     2429       NA    1 #> rank[Placebo]       3.22 0.59    2   3   3   4     4     3244     3055    1 plot(db_ranks) (db_rankprobs <- posterior_rank_probs(db_fit_RE)) #>                  p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[Beta Blocker]       0.00      0.00      0.00      0.01      0.80      0.19 #> d[ACE Inhibitor]      0.22      0.71      0.06      0.01      0.00      0.00 #> d[ARB]                0.78      0.20      0.02      0.00      0.00      0.00 #> d[CCB]                0.00      0.02      0.28      0.69      0.01      0.00 #> d[Diuretic]           0.00      0.00      0.00      0.00      0.18      0.81 #> d[Placebo]            0.00      0.07      0.64      0.28      0.01      0.00 plot(db_rankprobs) (db_cumrankprobs <- posterior_rank_probs(db_fit_RE, cumulative = TRUE)) #>                  p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[Beta Blocker]       0.00      0.00      0.00      0.01      0.81         1 #> d[ACE Inhibitor]      0.22      0.93      0.99      1.00      1.00         1 #> d[ARB]                0.78      0.98      1.00      1.00      1.00         1 #> d[CCB]                0.00      0.02      0.30      0.99      1.00         1 #> d[Diuretic]           0.00      0.00      0.00      0.00      0.19         1 #> d[Placebo]            0.00      0.07      0.71      0.99      1.00         1 plot(db_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Dietary fat","text":"begin setting network - just pairwise meta-analysis. arm-level rate data giving number deaths (r) person-years risk (E) arm, use function set_agd_arm(). set “Control” reference treatment. also specify optional sample_size argument, although strictly necessary . case sample_size required produce network plot nodes weighted sample size, network plot particularly informative meta-analysis two treatments. (sample_size argument important regression model specified, since also enables automatic centering predictors production predictions studies network, see ?set_agd_arm.)","code":"diet_net <- set_agd_arm(dietary_fat,                          study = studyc,                         trt = trtc,                         r = r,                          E = E,                         trt_ref = \"Control\",                         sample_size = n) diet_net #> A network with 10 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study                   Treatment arms                         #>  DART                    2: Control | Reduced Fat               #>  London Corn/Olive       3: Control | Reduced Fat | Reduced Fat #>  London Low Fat          2: Control | Reduced Fat               #>  Minnesota Coronary      2: Control | Reduced Fat               #>  MRC Soya                2: Control | Reduced Fat               #>  Oslo Diet-Heart         2: Control | Reduced Fat               #>  STARS                   2: Control | Reduced Fat               #>  Sydney Diet-Heart       2: Control | Reduced Fat               #>  Veterans Administration 2: Control | Reduced Fat               #>  Veterans Diet & Skin CA 2: Control | Reduced Fat               #>  #>  Outcome type: rate #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 10 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Dietary fat","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Dietary fat","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Poisson likelihood log link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. diet_fit_FE <- nma(diet_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) diet_fit_FE #> A fixed effects NMA with a poisson likelihood (log link). #> Inference for Stan model: poisson. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Reduced Fat]   -0.01    0.00 0.05   -0.11   -0.04   -0.01    0.03    0.10  2889    1 #> lp__           5386.22    0.06 2.34 5380.85 5384.87 5386.55 5387.91 5389.85  1711    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:41:45 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(diet_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(diet_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Dietary fat","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. diet_fit_RE <- nma(diet_net,                     trt_effects = \"random\",                    prior_intercept = normal(scale = 10),                    prior_trt = normal(scale = 10),                    prior_het = half_normal(scale = 5)) diet_fit_RE #> A random effects NMA with a poisson likelihood (log link). #> Inference for Stan model: poisson. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Reduced Fat]   -0.01    0.00 0.09   -0.19   -0.07   -0.01    0.04    0.16  1841    1 #> lp__           5378.66    0.12 3.87 5370.58 5376.14 5378.91 5381.33 5385.66  1124    1 #> tau               0.13    0.00 0.11    0.00    0.05    0.10    0.18    0.42   966    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:41:55 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(diet_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(diet_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Dietary fat","text":"Model fit can checked using dic() function: models appear fit data well, residual deviance close number data points. DIC similar models, FE model may preferred parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(dic_FE <- dic(diet_fit_FE)) #> Residual deviance: 22.4 (on 21 data points) #>                pD: 11.1 #>               DIC: 33.5 (dic_RE <- dic(diet_fit_RE)) #> Residual deviance: 21.5 (on 21 data points) #>                pD: 13.5 #>               DIC: 35 plot(dic_FE) plot(dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Dietary fat","text":"Dias et al. (2011) produce absolute predictions mortality rates reduced fat control diets, assuming Normal distribution baseline log rate mortality mean \\(-3\\) precision \\(1.77\\). can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted rates (type = \"link\" produce predicted log rates).   baseline argument omitted, predicted rates produced every study network based estimated baseline log rate \\(\\mu_j\\):","code":"pred_FE <- predict(diet_fit_FE,                     baseline = distr(qnorm, mean = -3, sd = 1.77^-0.5),                     type = \"response\") pred_FE #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]     0.07 0.06 0.01 0.03 0.05 0.08  0.21     4156     3799    1 #> pred[Reduced Fat] 0.07 0.06 0.01 0.03 0.05 0.08  0.21     4155     3844    1 plot(pred_FE) pred_RE <- predict(diet_fit_RE,                     baseline = distr(qnorm, mean = -3, sd = 1.77^-0.5),                     type = \"response\") pred_RE #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]     0.07 0.06 0.01 0.03 0.05 0.08  0.22     3936     3771    1 #> pred[Reduced Fat] 0.07 0.06 0.01 0.03 0.05 0.08  0.22     3918     3647    1 plot(pred_RE) pred_FE_studies <- predict(diet_fit_FE, type = \"response\") pred_FE_studies #> ------------------------------------------------------------------- Study: DART ----  #>  #>                         mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[DART: Control]     0.06  0 0.05 0.06 0.06 0.06  0.07     5474     3176    1 #> pred[DART: Reduced Fat] 0.06  0 0.05 0.06 0.06 0.06  0.07     7835     3434    1 #>  #> ------------------------------------------------------ Study: London Corn/Olive ----  #>  #>                                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[London Corn/Olive: Control]     0.07 0.02 0.03 0.06 0.07 0.09  0.13     6279     2342 #> pred[London Corn/Olive: Reduced Fat] 0.07 0.02 0.03 0.06 0.07 0.09  0.13     6540     2413 #>                                      Rhat #> pred[London Corn/Olive: Control]        1 #> pred[London Corn/Olive: Reduced Fat]    1 #>  #> --------------------------------------------------------- Study: London Low Fat ----  #>  #>                                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[London Low Fat: Control]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     7256     3194    1 #> pred[London Low Fat: Reduced Fat] 0.06 0.01 0.04 0.05 0.06 0.06  0.08     8918     3363    1 #>  #> ----------------------------------------------------- Study: Minnesota Coronary ----  #>  #>                                       mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Minnesota Coronary: Control]     0.05  0 0.05 0.05 0.05 0.06  0.06     4411     3609    1 #> pred[Minnesota Coronary: Reduced Fat] 0.05  0 0.05 0.05 0.05 0.06  0.06     6160     3299    1 #>  #> --------------------------------------------------------------- Study: MRC Soya ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[MRC Soya: Control]     0.04 0.01 0.03 0.04 0.04 0.04  0.05     6332     3107    1 #> pred[MRC Soya: Reduced Fat] 0.04 0.01 0.03 0.04 0.04 0.04  0.05     7830     3352    1 #>  #> -------------------------------------------------------- Study: Oslo Diet-Heart ----  #>  #>                                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Oslo Diet-Heart: Control]     0.06 0.01 0.05 0.06 0.06 0.07  0.08     6375     3110    1 #> pred[Oslo Diet-Heart: Reduced Fat] 0.06 0.01 0.05 0.06 0.06 0.07  0.08     7865     2890    1 #>  #> ------------------------------------------------------------------ Study: STARS ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[STARS: Control]     0.02 0.01 0.01 0.01 0.02 0.03  0.05     7289     2939    1 #> pred[STARS: Reduced Fat] 0.02 0.01 0.01 0.01 0.02 0.03  0.05     7317     2883    1 #>  #> ------------------------------------------------------ Study: Sydney Diet-Heart ----  #>  #>                                      mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Sydney Diet-Heart: Control]     0.03  0 0.03 0.03 0.03 0.04  0.04     6811     3250    1 #> pred[Sydney Diet-Heart: Reduced Fat] 0.03  0 0.03 0.03 0.03 0.04  0.04     8001     3517    1 #>  #> ------------------------------------------------ Study: Veterans Administration ----  #>  #>                                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Veterans Administration: Control]     0.11 0.01  0.1 0.11 0.11 0.12  0.13     4711 #> pred[Veterans Administration: Reduced Fat] 0.11 0.01  0.1 0.11 0.11 0.12  0.13     7731 #>                                            Tail_ESS Rhat #> pred[Veterans Administration: Control]         3414    1 #> pred[Veterans Administration: Reduced Fat]     2796    1 #>  #> ------------------------------------------------ Study: Veterans Diet & Skin CA ----  #>  #>                                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Veterans Diet & Skin CA: Control]     0.01 0.01    0 0.01 0.01 0.02  0.03     7737 #> pred[Veterans Diet & Skin CA: Reduced Fat] 0.01 0.01    0 0.01 0.01 0.02  0.03     7699 #>                                            Tail_ESS Rhat #> pred[Veterans Diet & Skin CA: Control]         2531    1 #> pred[Veterans Diet & Skin CA: Reduced Fat]     2481    1 plot(pred_FE_studies) + ggplot2::facet_grid(Study~., labeller = ggplot2::label_wrap_gen(width = 10))"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Plaque psoriasis HTA report","text":"begin setting network. arm-level ordered multinomial count data, use function set_agd_arm(). function multi() helps us specify ordered outcomes correctly. Plot network structure.","code":"pso_net <- set_agd_arm(hta_psoriasis,                         study = paste(studyc, year),                         trt = trtc,                         r = multi(r0 = sample_size - rowSums(cbind(PASI50, PASI75, PASI90), na.rm = TRUE),                                   PASI50, PASI75, PASI90,                                  inclusive = FALSE,                                   type = \"ordered\")) pso_net #> A network with 16 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                           #>  ACD2058g 2004 2: Supportive care | Efalizumab                          #>  ACD2600g 2004 2: Supportive care | Efalizumab                          #>  Altmeyer 1994 2: Supportive care | Fumaderm                            #>  Chaudari 2001 2: Supportive care | Infliximab                          #>  Elewski 2004  3: Supportive care | Etanercept 25 mg | Etanercept 50 mg #>  Ellis 1991    3: Supportive care | Ciclosporin | Ciclosporin           #>  Gordon 2003   2: Supportive care | Efalizumab                          #>  Gottlieb 2003 2: Supportive care | Etanercept 25 mg                    #>  Gottlieb 2004 3: Supportive care | Infliximab | Infliximab             #>  Guenther 1991 2: Supportive care | Ciclosporin                         #>  ... plus 6 more studies #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 8 #> Total number of studies: 16 #> Reference treatment is: Supportive care #> Network is connected plot(pso_net, weight_edges = TRUE, weight_nodes = TRUE) +    # Nudge the legend over   ggplot2::theme(legend.box.spacing = ggplot2::unit(0.75, \"in\"),                  plot.margin = ggplot2::margin(0.1, 0, 0.1, 0.75, \"in\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Plaque psoriasis HTA report","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Plaque psoriasis HTA report","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\", using probit link function link = \"probit\". use \\(\\mathrm{N}(0, 10^2)\\) prior distributions treatment effects \\(d_k\\), \\(\\mathrm{N}(0, 100^2)\\) prior distributions study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: also need specify prior distributions latent cutpoints \\(c_\\textrm{PASI75}\\) \\(c_\\textrm{PASI90}\\) underlying scale - PASI standardised mean difference due probit link (cutpoint \\(c_\\textrm{PASI50}=0\\)). make easier reason , actually specify priors differences adjacent cutpoints, e.g. \\(c_\\textrm{PASI90} - c_\\textrm{PASI75}\\) \\(c_\\textrm{PASI75} - c_\\textrm{PASI50}\\). can given positive-valued prior distribution, Stan automatically impose necessary ordering constraints behind scenes. choose give implicit flat priors flat(). model fitted using nma() function. Basic parameter summaries given print() method: Note: treatment effects opposite sign TSD 2 (Dias et al. 2011). parameterise linear predictor \\(\\mu_j + d_k + c_m\\), rather \\(\\mu_j + d_k - c_m\\). interpretation thus follows standard binomial probit (logit) regression; SMDs (log ORs) greater zero mean treatment increases probability event compared comparator (less zero mean reduction probability). higher outcomes positive, active treatments estimated increase response (.e. greater reduction) PASI scale compared network reference (supportive care). default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Focusing specifically cutpoints see highly identified data, implicit flat priors work parameters.","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10),                   prior_aux = flat()) #> Note: Setting \"Supportive care\" as the network reference treatment. pso_fit_FE #> A fixed effects NMA with a ordered likelihood (probit link). #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff #> d[Ciclosporin]          1.92    0.01 0.34     1.28     1.68     1.90     2.14     2.64  1627 #> d[Efalizumab]           1.19    0.00 0.06     1.08     1.15     1.19     1.23     1.30  2127 #> d[Etanercept 25 mg]     1.51    0.00 0.10     1.32     1.45     1.51     1.57     1.70  2232 #> d[Etanercept 50 mg]     1.92    0.00 0.10     1.72     1.86     1.92     1.99     2.11  2119 #> d[Fumaderm]             1.50    0.01 0.49     0.62     1.16     1.46     1.79     2.52  2554 #> d[Infliximab]           2.33    0.01 0.26     1.85     2.15     2.32     2.51     2.86  2596 #> d[Methotrexate]         1.61    0.01 0.45     0.74     1.31     1.60     1.90     2.53  1926 #> lp__                -3405.08    0.08 3.57 -3412.88 -3407.32 -3404.80 -3402.43 -3399.20  1765 #> cc[PASI50]              0.00     NaN 0.00     0.00     0.00     0.00     0.00     0.00   NaN #> cc[PASI75]              0.76    0.00 0.03     0.70     0.74     0.76     0.78     0.82  5825 #> cc[PASI90]              1.57    0.00 0.05     1.46     1.53     1.57     1.60     1.67  6099 #>                     Rhat #> d[Ciclosporin]         1 #> d[Efalizumab]          1 #> d[Etanercept 25 mg]    1 #> d[Etanercept 50 mg]    1 #> d[Fumaderm]            1 #> d[Infliximab]          1 #> d[Methotrexate]        1 #> lp__                   1 #> cc[PASI50]           NaN #> cc[PASI75]             1 #> cc[PASI90]             1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:42:19 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_FE, pars = c(\"d\", \"mu\", \"cc\")) plot_prior_posterior(pso_fit_FE) plot_prior_posterior(pso_fit_FE, prior = \"aux\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Plaque psoriasis HTA report","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 10^2)\\) prior distributions treatment effects \\(d_k\\), \\(\\mathrm{N}(0, 100^2)\\) prior distributions study-specific intercepts \\(\\mu_j\\), implicit flat prior distributions latent cutpoints, additionally use \\(\\textrm{half-N}(2.5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 2.5)) #> A half-Normal prior distribution: location = 0, scale = 2.5. #> 50% of the prior density lies between 0 and 1.69. #> 95% of the prior density lies between 0 and 4.9. pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10),                   prior_aux = flat(),                   prior_het = half_normal(scale = 2.5),                   adapt_delta = 0.99) #> Note: Setting \"Supportive care\" as the network reference treatment. pso_fit_RE #> A random effects NMA with a ordered likelihood (probit link). #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=5000; warmup=2500; thin=1;  #> post-warmup draws per chain=2500, total post-warmup draws=10000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff #> d[Ciclosporin]          2.04    0.01 0.44     1.28     1.74     1.99     2.29     3.00  2717 #> d[Efalizumab]           1.19    0.00 0.18     0.81     1.11     1.19     1.27     1.56  5020 #> d[Etanercept 25 mg]     1.53    0.00 0.23     1.06     1.40     1.52     1.65     2.01  5016 #> d[Etanercept 50 mg]     1.93    0.00 0.27     1.34     1.79     1.92     2.06     2.49  5135 #> d[Fumaderm]             1.48    0.01 0.61     0.34     1.08     1.46     1.87     2.73  6855 #> d[Infliximab]           2.32    0.00 0.38     1.56     2.09     2.32     2.55     3.06  7156 #> d[Methotrexate]         1.72    0.01 0.65     0.55     1.31     1.70     2.10     3.09  3912 #> lp__                -3410.84    0.19 6.80 -3424.69 -3415.46 -3410.57 -3405.96 -3398.62  1306 #> tau                     0.30    0.01 0.22     0.02     0.15     0.26     0.41     0.83   932 #> cc[PASI50]              0.00     NaN 0.00     0.00     0.00     0.00     0.00     0.00   NaN #> cc[PASI75]              0.76    0.00 0.03     0.70     0.74     0.76     0.78     0.82 16361 #> cc[PASI90]              1.56    0.00 0.05     1.46     1.53     1.56     1.60     1.67 19302 #>                     Rhat #> d[Ciclosporin]      1.00 #> d[Efalizumab]       1.00 #> d[Etanercept 25 mg] 1.00 #> d[Etanercept 50 mg] 1.00 #> d[Fumaderm]         1.00 #> d[Infliximab]       1.00 #> d[Methotrexate]     1.00 #> lp__                1.00 #> tau                 1.01 #> cc[PASI50]           NaN #> cc[PASI75]          1.00 #> cc[PASI90]          1.00 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:44:22 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_RE, pars = c(\"d\", \"cc\", \"mu\", \"delta\")) plot_prior_posterior(pso_fit_RE, prior = c(\"trt\", \"aux\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Plaque psoriasis HTA report","text":"Model fit can checked using dic() function: random effects model lower DIC residual deviance closer number data points, preferred case. can also examine residual deviance contributions corresponding plot() method.   data points fit well, posterior mean residual deviances close degrees freedom. Meffert 1997 study substantially higher residual deviance contribution, investigated see study appears outlier.","code":"(dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 74.8 (on 58 data points) #>                pD: 25.4 #>               DIC: 100.1 (dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 63.1 (on 58 data points) #>                pD: 33.4 #>               DIC: 96.6 plot(dic_FE) plot(dic_RE)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"predicted-probabilities-of-response","dir":"Articles","previous_headings":"Further results","what":"Predicted probabilities of response","title":"Example: Plaque psoriasis HTA report","text":"Dias et al. (2011) produce absolute predictions probability achieving responses PASI cutoff, assuming Normal distribution baseline probit probability PASI50 response supportive care mean \\(-1.097\\) precision \\(123\\). can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted probabilities (type = \"link\" produce predicted probit probabilities).   instead information baseline PASI 50 response probit probability PASI 50 event counts, can use construct Beta distribution baseline probability PASI 50 response. example, 56 408 individuals achieved PASI 50 response supportive care target population interest, appropriate Beta distribution response probability \\(\\textrm{Beta}(56, 408-56)\\). can specify Beta distribution baseline response using baseline_type = \"reponse\" argument (default \"link\", used baseline probit probability).  (Notice results equivalent calculated using Normal distribution baseline probit probability, since event counts correspond probit probability.) can modify plots using standard ggplot2 functions. example, plot cutpoints together colour coding (instead split facets):  baseline argument omitted, predicted probabilities produced every study network based estimated baseline probit probability \\(\\mu_j\\).","code":"pred_FE <- predict(pso_fit_FE,                     baseline = distr(qnorm, mean = -1.097, sd = 123^-0.5),                     type = \"response\") pred_FE #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.18     3631     3432    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05     3789     3232    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01     4246     3776    1 #> pred[Ciclosporin, PASI50]      0.78 0.10 0.57 0.72 0.79 0.85  0.94     1707     1890    1 #> pred[Ciclosporin, PASI75]      0.52 0.13 0.28 0.43 0.52 0.62  0.80     1721     1983    1 #> pred[Ciclosporin, PASI90]      0.24 0.11 0.08 0.16 0.22 0.31  0.50     1721     1992    1 #> pred[Efalizumab, PASI50]       0.54 0.04 0.46 0.51 0.54 0.56  0.62     3152     3231    1 #> pred[Efalizumab, PASI75]       0.25 0.04 0.19 0.23 0.25 0.28  0.33     3313     3733    1 #> pred[Efalizumab, PASI90]       0.07 0.02 0.04 0.06 0.07 0.08  0.11     3565     3866    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.05 0.56 0.63 0.66 0.69  0.75     2562     3057    1 #> pred[Etanercept 25 mg, PASI75] 0.37 0.05 0.27 0.33 0.37 0.40  0.47     2665     2973    1 #> pred[Etanercept 25 mg, PASI90] 0.13 0.03 0.08 0.11 0.13 0.14  0.19     2829     2993    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.04 0.71 0.77 0.80 0.82  0.86     2556     2742    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.05 0.42 0.49 0.53 0.56  0.63     2697     2753    1 #> pred[Etanercept 50 mg, PASI90] 0.23 0.04 0.16 0.20 0.23 0.26  0.32     2852     2966    1 #> pred[Fumaderm, PASI50]         0.64 0.16 0.31 0.53 0.64 0.76  0.93     2721     2454    1 #> pred[Fumaderm, PASI75]         0.37 0.17 0.10 0.24 0.35 0.48  0.76     2739     2467    1 #> pred[Fumaderm, PASI90]         0.15 0.12 0.02 0.07 0.12 0.20  0.45     2705     2500    1 #> pred[Infliximab, PASI50]       0.88 0.05 0.76 0.85 0.89 0.92  0.96     2671     2514    1 #> pred[Infliximab, PASI75]       0.68 0.10 0.48 0.61 0.68 0.75  0.85     2662     2568    1 #> pred[Infliximab, PASI90]       0.37 0.10 0.19 0.30 0.37 0.44  0.59     2692     2683    1 #> pred[Methotrexate, PASI50]     0.68 0.15 0.36 0.58 0.69 0.79  0.92     2001     2264    1 #> pred[Methotrexate, PASI75]     0.41 0.16 0.13 0.29 0.40 0.52  0.76     2007     2264    1 #> pred[Methotrexate, PASI90]     0.17 0.11 0.03 0.09 0.14 0.23  0.45     2003     2292    1 plot(pred_FE) pred_RE <- predict(pso_fit_RE,                     baseline = distr(qnorm, mean = -1.097, sd = 123^-0.5),                     type = \"response\") pred_RE #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.18     9886     9993    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05    10478    10203    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01    11429     9859    1 #> pred[Ciclosporin, PASI50]      0.80 0.11 0.57 0.74 0.82 0.89  0.97     3358     2722    1 #> pred[Ciclosporin, PASI75]      0.56 0.16 0.28 0.45 0.56 0.67  0.87     3362     2728    1 #> pred[Ciclosporin, PASI90]      0.28 0.14 0.08 0.18 0.25 0.36  0.63     3363     2722    1 #> pred[Efalizumab, PASI50]       0.54 0.08 0.38 0.49 0.54 0.58  0.69     5752     4812    1 #> pred[Efalizumab, PASI75]       0.26 0.06 0.14 0.22 0.25 0.29  0.40     5869     4726    1 #> pred[Efalizumab, PASI90]       0.07 0.03 0.03 0.06 0.07 0.09  0.15     5994     4979    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.09 0.48 0.61 0.67 0.72  0.83     5738     4407    1 #> pred[Etanercept 25 mg, PASI75] 0.38 0.09 0.21 0.32 0.37 0.43  0.58     5787     4541    1 #> pred[Etanercept 25 mg, PASI90] 0.14 0.06 0.05 0.10 0.13 0.16  0.27     5868     4792    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.08 0.59 0.75 0.80 0.84  0.92     5779     4609    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.11 0.30 0.47 0.53 0.59  0.75     5790     4548    1 #> pred[Etanercept 50 mg, PASI90] 0.24 0.09 0.09 0.19 0.23 0.28  0.44     5816     4549    1 #> pred[Fumaderm, PASI50]         0.63 0.20 0.22 0.49 0.64 0.78  0.95     7087     5940    1 #> pred[Fumaderm, PASI75]         0.37 0.20 0.06 0.22 0.35 0.51  0.81     7075     5952    1 #> pred[Fumaderm, PASI90]         0.16 0.14 0.01 0.06 0.11 0.22  0.54     7082     5962    1 #> pred[Infliximab, PASI50]       0.87 0.08 0.67 0.84 0.89 0.93  0.98     7492     6191    1 #> pred[Infliximab, PASI75]       0.67 0.13 0.38 0.59 0.68 0.76  0.89     7499     6050    1 #> pred[Infliximab, PASI90]       0.37 0.14 0.13 0.28 0.36 0.46  0.67     7510     6112    1 #> pred[Methotrexate, PASI50]     0.70 0.18 0.29 0.58 0.72 0.84  0.98     4442     3866    1 #> pred[Methotrexate, PASI75]     0.45 0.21 0.09 0.29 0.44 0.60  0.89     4430     3914    1 #> pred[Methotrexate, PASI90]     0.21 0.17 0.02 0.09 0.17 0.29  0.67     4434     3710    1 plot(pred_RE) pred_FE_beta <- predict(pso_fit_FE,                          baseline = distr(qbeta, 56, 408-56),                         baseline_type = \"response\",                         type = \"response\") pred_FE_beta #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.17     3940     4002    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05     4192     4134    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01     4512     3920    1 #> pred[Ciclosporin, PASI50]      0.78 0.10 0.57 0.72 0.79 0.85  0.94     1695     2060    1 #> pred[Ciclosporin, PASI75]      0.52 0.13 0.28 0.43 0.52 0.62  0.79     1712     2023    1 #> pred[Ciclosporin, PASI90]      0.24 0.11 0.08 0.16 0.22 0.31  0.50     1703     2084    1 #> pred[Efalizumab, PASI50]       0.54 0.04 0.46 0.51 0.54 0.56  0.61     3296     3831    1 #> pred[Efalizumab, PASI75]       0.25 0.03 0.19 0.23 0.25 0.28  0.32     3470     4016    1 #> pred[Efalizumab, PASI90]       0.07 0.02 0.05 0.06 0.07 0.08  0.10     3717     3772    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.04 0.57 0.63 0.66 0.69  0.75     2975     3241    1 #> pred[Etanercept 25 mg, PASI75] 0.37 0.05 0.28 0.34 0.37 0.40  0.46     3157     3445    1 #> pred[Etanercept 25 mg, PASI90] 0.13 0.03 0.08 0.11 0.13 0.14  0.19     3214     3665    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.04 0.72 0.77 0.80 0.82  0.86     2713     3184    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.05 0.43 0.49 0.53 0.56  0.63     2961     3599    1 #> pred[Etanercept 50 mg, PASI90] 0.23 0.04 0.16 0.20 0.23 0.26  0.31     3067     3553    1 #> pred[Fumaderm, PASI50]         0.64 0.16 0.31 0.52 0.64 0.76  0.93     2796     2365    1 #> pred[Fumaderm, PASI75]         0.37 0.17 0.11 0.24 0.35 0.48  0.75     2810     2452    1 #> pred[Fumaderm, PASI90]         0.15 0.11 0.02 0.07 0.12 0.19  0.45     2764     2423    1 #> pred[Infliximab, PASI50]       0.88 0.05 0.76 0.85 0.89 0.92  0.96     2794     2668    1 #> pred[Infliximab, PASI75]       0.68 0.10 0.48 0.61 0.68 0.75  0.85     2779     2647    1 #> pred[Infliximab, PASI90]       0.37 0.10 0.20 0.30 0.37 0.44  0.59     2791     2648    1 #> pred[Methotrexate, PASI50]     0.68 0.15 0.36 0.58 0.69 0.79  0.93     1980     2457    1 #> pred[Methotrexate, PASI75]     0.41 0.16 0.13 0.29 0.40 0.52  0.76     1990     2294    1 #> pred[Methotrexate, PASI90]     0.17 0.11 0.03 0.09 0.14 0.23  0.46     1980     2306    1 plot(pred_FE_beta) pred_RE_beta <- predict(pso_fit_RE,                          baseline = distr(qbeta, 56, 408-56),                         baseline_type = \"response\",                         type = \"response\") pred_RE_beta #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.11 0.13 0.14 0.15  0.17     9843     9606    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05    10708     9495    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01    11922     9653    1 #> pred[Ciclosporin, PASI50]      0.80 0.11 0.57 0.74 0.82 0.88  0.97     3308     2748    1 #> pred[Ciclosporin, PASI75]      0.56 0.15 0.28 0.45 0.56 0.67  0.88     3321     2697    1 #> pred[Ciclosporin, PASI90]      0.28 0.14 0.08 0.18 0.25 0.36  0.64     3312     2733    1 #> pred[Efalizumab, PASI50]       0.54 0.07 0.38 0.50 0.54 0.58  0.69     6090     4709    1 #> pred[Efalizumab, PASI75]       0.26 0.06 0.14 0.22 0.25 0.29  0.40     6255     4548    1 #> pred[Efalizumab, PASI90]       0.07 0.03 0.03 0.06 0.07 0.09  0.14     6451     4860    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.09 0.48 0.61 0.67 0.72  0.83     5726     4571    1 #> pred[Etanercept 25 mg, PASI75] 0.38 0.09 0.21 0.32 0.37 0.43  0.57     5787     4746    1 #> pred[Etanercept 25 mg, PASI90] 0.14 0.06 0.05 0.10 0.13 0.16  0.27     5881     4625    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.08 0.59 0.75 0.80 0.84  0.92     5680     4343    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.10 0.30 0.47 0.53 0.59  0.75     5693     4284    1 #> pred[Etanercept 50 mg, PASI90] 0.24 0.09 0.09 0.19 0.23 0.28  0.45     5736     4212    1 #> pred[Fumaderm, PASI50]         0.63 0.20 0.22 0.49 0.64 0.78  0.95     7115     5685    1 #> pred[Fumaderm, PASI75]         0.37 0.20 0.06 0.22 0.35 0.50  0.81     7110     5892    1 #> pred[Fumaderm, PASI90]         0.16 0.14 0.01 0.06 0.11 0.21  0.53     7121     5758    1 #> pred[Infliximab, PASI50]       0.87 0.08 0.68 0.84 0.89 0.93  0.98     7535     6008    1 #> pred[Infliximab, PASI75]       0.67 0.13 0.38 0.59 0.68 0.76  0.89     7549     6255    1 #> pred[Infliximab, PASI90]       0.37 0.14 0.13 0.28 0.36 0.46  0.66     7583     6152    1 #> pred[Methotrexate, PASI50]     0.70 0.18 0.29 0.58 0.73 0.84  0.98     4370     3753    1 #> pred[Methotrexate, PASI75]     0.45 0.21 0.09 0.29 0.44 0.60  0.89     4369     3774    1 #> pred[Methotrexate, PASI90]     0.21 0.17 0.02 0.09 0.17 0.29  0.67     4368     3769    1 plot(pred_RE_beta) library(ggplot2) plot(pred_RE, position = position_dodge(width = 0.75)) +   facet_null() +   aes(colour = Category) +   scale_colour_brewer(palette = \"Blues\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"ranks-and-rank-probabilities","dir":"Articles","previous_headings":"Further results","what":"Ranks and rank probabilities","title":"Example: Plaque psoriasis HTA report","text":"Treatment rankings, rank probabilities, cumulative rank probabilities can also produced. set lower_better = FALSE since higher outcome categories better (outcomes positive).","code":"(pso_ranks <- posterior_ranks(pso_fit_RE, lower_better = FALSE)) #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[Supportive care]  7.99 0.11    8   8   8   8     8     5526       NA    1 #> rank[Ciclosporin]      2.76 1.27    1   2   3   4     5     6613     6428    1 #> rank[Efalizumab]       6.34 0.81    4   6   7   7     7     5629       NA    1 #> rank[Etanercept 25 mg] 4.92 1.06    3   4   5   6     7     6871     5862    1 #> rank[Etanercept 50 mg] 3.05 1.21    1   2   3   4     5     5194     5158    1 #> rank[Fumaderm]         4.92 1.95    1   3   5   7     7     6876     6057    1 #> rank[Infliximab]       1.81 1.18    1   1   1   2     5     3839     4463    1 #> rank[Methotrexate]     4.21 1.89    1   3   4   6     7     5652     5599    1 plot(pso_ranks) (pso_rankprobs <- posterior_rank_probs(pso_fit_RE, lower_better = FALSE)) #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] #> d[Supportive care]       0.00      0.00      0.00      0.00      0.00      0.00      0.01 #> d[Ciclosporin]           0.18      0.28      0.28      0.17      0.08      0.02      0.00 #> d[Efalizumab]            0.00      0.00      0.00      0.02      0.10      0.36      0.51 #> d[Etanercept 25 mg]      0.00      0.01      0.09      0.21      0.39      0.26      0.04 #> d[Etanercept 50 mg]      0.07      0.30      0.26      0.25      0.09      0.02      0.01 #> d[Fumaderm]              0.07      0.09      0.09      0.11      0.16      0.19      0.27 #> d[Infliximab]            0.58      0.19      0.13      0.06      0.03      0.01      0.00 #> d[Methotrexate]          0.10      0.12      0.15      0.18      0.16      0.14      0.15 #>                     p_rank[8] #> d[Supportive care]       0.99 #> d[Ciclosporin]           0.00 #> d[Efalizumab]            0.00 #> d[Etanercept 25 mg]      0.00 #> d[Etanercept 50 mg]      0.00 #> d[Fumaderm]              0.01 #> d[Infliximab]            0.00 #> d[Methotrexate]          0.00 plot(pso_rankprobs) (pso_cumrankprobs <- posterior_rank_probs(pso_fit_RE, lower_better = FALSE, cumulative = TRUE)) #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] #> d[Supportive care]       0.00      0.00      0.00      0.00      0.00      0.00      0.01 #> d[Ciclosporin]           0.18      0.46      0.73      0.90      0.98      1.00      1.00 #> d[Efalizumab]            0.00      0.00      0.01      0.03      0.13      0.49      1.00 #> d[Etanercept 25 mg]      0.00      0.01      0.10      0.31      0.70      0.96      1.00 #> d[Etanercept 50 mg]      0.07      0.38      0.64      0.89      0.98      0.99      1.00 #> d[Fumaderm]              0.07      0.16      0.25      0.37      0.53      0.72      0.99 #> d[Infliximab]            0.58      0.77      0.90      0.96      0.99      1.00      1.00 #> d[Methotrexate]          0.10      0.22      0.37      0.55      0.71      0.85      1.00 #>                     p_rank[8] #> d[Supportive care]          1 #> d[Ciclosporin]              1 #> d[Efalizumab]               1 #> d[Etanercept 25 mg]         1 #> d[Etanercept 50 mg]         1 #> d[Fumaderm]                 1 #> d[Infliximab]               1 #> d[Methotrexate]             1 plot(pso_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"study-data","dir":"Articles","previous_headings":"","what":"Study data","title":"Example: Newly diagnosed multiple myeloma","text":"First, let us look Kaplan-Meier plots data study:  consider adjustment following covariates: Age Sex ISS stage, -II vs. III Response post-ASCT, complete good partial response vs. lesser response summary distributions characteristics study follows:","code":"kmdat <- bind_rows(ndmm_ipd, ndmm_agd) %>%   group_by(studyf, trtf) %>%   # KM estimate within each study   group_modify(~with(survfit(Surv(eventtime, event = status) ~ 1, data = .),                      tibble(time, n.censor, estimate = surv, std.err, upper, lower))) %>%   # Add S(0) = 1   group_modify(~add_row(., time = 0, n.censor = 0, estimate = 1, std.err = 0, upper = 1, lower = 1, .before = 0)) %>%   arrange(studyf, trtf, time)  ggplot(kmdat, aes(x = time, y = estimate, colour = trtf)) +   geom_step() +   geom_point(shape = 3, data = function(x) filter(x, n.censor >= 1)) +   facet_wrap(~studyf) +   labs(y = \"Survival probability\", x = \"Time\") +   coord_cartesian(ylim = c(0, 1)) +   theme_multinma() +   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\")) bind_rows(   summarise(ndmm_ipd,             N = n(),             age_mean = mean(age), age_sd = sd(age),             iss_stage3 = mean(iss_stage3),             response_cr_vgpr = mean(response_cr_vgpr),             male = mean(male),             .by = c(studyf, trtf)),   transmute(ndmm_agd_covs,             studyf, trtf,             N = sample_size,             age_mean, age_sd, iss_stage3, response_cr_vgpr, male) ) %>%   mutate(across(where(is.double), ~round(., digits = 2))) #>          studyf trtf    N age_mean age_sd iss_stage3 response_cr_vgpr male #> 1  McCarthy2012  Pbo  229    57.39   5.56       0.18             0.71 0.55 #> 2  McCarthy2012  Len  231    57.93   6.33       0.27             0.62 0.52 #> 3     Attal2012  Pbo  307    54.22   5.24       0.16             0.54 0.58 #> 4     Attal2012  Len  307    54.35   6.06       0.24             0.55 0.55 #> 5   Palumbo2014  Pbo  125    54.44   8.98       0.12             0.38 0.63 #> 6   Palumbo2014  Len  126    53.90   9.69       0.10             0.42 0.46 #> 7   Jackson2019  Len 1137    65.17   8.94       0.25             0.83 0.62 #> 8   Jackson2019  Pbo  864    64.63   9.40       0.19             0.83 0.62 #> 9    Morgan2012  Pbo  410    63.92   9.01       0.36             0.72 0.62 #> 10   Morgan2012 Thal  408    65.59   8.38       0.32             0.75 0.62"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"preparing-treatment-classes","dir":"Articles","previous_headings":"Setup","what":"Preparing treatment classes","title":"Example: Newly diagnosed multiple myeloma","text":"start setting network analysis. Since IPD placebo vs. lenalidomide comparison, one AgD study placebo vs. thalidomide comparison, make shared effect modifier assumption two active treatments order estimate effect modifying treatment-covariate interactions thalidomide Phillippo et al. (2020). Since lenalidomide thalidomide class treatments, assumption may reasonable. impose assumption, create treatment class variable active treatments vs. placebo.","code":"ndmm_ipd$trtclass <- case_match(ndmm_ipd$trtf,                                 \"Pbo\" ~ \"Placebo\",                                 c(\"Len\", \"Thal\") ~ \"Active\")  ndmm_agd$trtclass <- case_match(ndmm_agd$trtf,                                 \"Pbo\" ~ \"Placebo\",                                 c(\"Len\", \"Thal\") ~ \"Active\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"Setup","what":"Setting up the network","title":"Example: Newly diagnosed multiple myeloma","text":"set network using set_ipd(), set_agd_surv(), combine_network() functions. Since survival data form event/censoring times censoring indicators, use Surv argument set_*() functions set outcome data using usual survival::Surv() function. AgD set similar fashion IPD, except summary covariate information (data frame ndmm_agd_covs) included using covariates argument. data frame passed covariates must matching study treatment columns outcome data set (ndmm_agd), case studyf trtf respectively, one row per arm, covariate information can matched corresponding arms outcome data. IPD AgD combined single network using combine_network().","code":"ndmm_net <- combine_network(   set_ipd(ndmm_ipd,           study = studyf,           trt = trtf,           trt_class = trtclass,           Surv = Surv(eventtime, status)),   set_agd_surv(ndmm_agd,                study = studyf,                trt = trtf,                trt_class = trtclass,                Surv = Surv(eventtime, status),                covariates = ndmm_agd_covs) )"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"adding-numerical-integration-for-ml-nmr","dir":"Articles","previous_headings":"Setup","what":"Adding numerical integration for ML-NMR","title":"Example: Newly diagnosed multiple myeloma","text":"perform ML-NMR, need create numerical integration points joint covariate distributions AgD study. used integrate (.e. average) individual-level model joint covariate distribution form aggregate-level model. done using add_integration() function, covariate specify marginal distribution using distr() function. Since age skewed, use gamma distribution covariate; remaining covariates binary given Bernoulli distributions. procedure also requires information correlations covariates. known, can specified using cor argument. However, default weighted average correlations IPD studies used.","code":"ndmm_net <- add_integration(ndmm_net,                             age = distr(qgamma, mean = age_mean, sd = age_sd),                             iss_stage3 = distr(qbern, iss_stage3),                             response_cr_vgpr = distr(qbern, response_cr_vgpr),                             male = distr(qbern, male)) #> Using weighted average correlation matrix computed from IPD studies.  ndmm_net #> A network with 3 IPD studies, and 2 AgD studies (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study        Treatment arms #>  Attal2012    2: Pbo | Len   #>  McCarthy2012 2: Pbo | Len   #>  Palumbo2014  2: Pbo | Len   #>  #>  Outcome type: survival #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study       Treatment arms #>  Jackson2019 2: Pbo | Len   #>  Morgan2012  2: Pbo | Thal  #>  #>  Outcome type: survival #> ------------------------------------------------------------------------------------ #> Total number of treatments: 3, in 2 classes #> Total number of studies: 5 #> Reference treatment is: Pbo #> Network is connected #>  #> --------------------------------------------------------- Numerical integration ----  #> Numerical integration points available for 4 covariates:  #>   age iss_stage3 response_cr_vgpr male #> Number of numerical integration points: 64"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"network-plot","dir":"Articles","previous_headings":"Setup","what":"Network plot","title":"Example: Newly diagnosed multiple myeloma","text":"can plot network diagram using plot() method.","code":"plot(ndmm_net,     weight_nodes = TRUE,     weight_edges = TRUE,     # Nudge treatment labels away from nodes     nudge = 0.1,     # Manual layout     layout = data.frame(x = c(0, -1, 1),                         y = c(-0.5, 0, 0))) +   guides(edge_colour = guide_legend(override.aes = list(edge_width = 2))) +   theme(legend.position = \"bottom\", legend.direction = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"ml-nmr-models-with-m-spline-baseline-hazards","dir":"Articles","previous_headings":"","what":"ML-NMR models with M-spline baseline hazards","title":"Example: Newly diagnosed multiple myeloma","text":"fit proportional hazards survival model cubic M-splines baseline hazard Phillippo et al. (n.d.). allows baseline hazard flexibly follow shape baseline hazard may take.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"choosing-the-number-of-knots","dir":"Articles","previous_headings":"ML-NMR models with M-spline baseline hazards","what":"Choosing the number of knots","title":"Example: Newly diagnosed multiple myeloma","text":"ML-NMR models fit using nma() function, specify M-spline baseline hazard used likelihood = \"mspline\". Fitting spline models requires user specify number location knots. default, three internal knots used (n_knots = 3) placed evenly spaced quantiles observed event times within study (.e. 25%, 50%, 75% quantiles 3 internal knots). number knots can changed using n_knots argument, custom knot locations can specified using knots argument. nma() function always place boundary knots earliest entry time study (0 delayed entry) maximum event/censoring time. default, nma() function fit cubic M-spline (mspline_degree = 3). Piecewise-constant hazards (.e. piecewise exponential hazards) special case degree 0 splines, specified using likelihood = \"pexp\" (equivalent mspline_degree = 0). specify regression model using regression argument includes main effects covariates (prognostic effects) treatment-covariate interactions (effect modifier interactions) covariate. place vague \\(\\operatorname{N}(0, 100^2)\\) priors parameters linear predictor, \\(\\operatorname{Dirichlet}(1)\\) prior distribution spline coefficients uniform unit simplex. Using QR decomposition (QR = TRUE) can greatly increase sampling efficiency regression models, also reduce max_treedepth Stan sampler speed warm-time. fit models 1, 2, 3 internal knots, choose number knots using leave-one-information criterion (LOOIC). compare LOOIC, using loo package. model single internal knot median uncensored survival time lowest LOOIC (highest ELPD). Increasing number knots improve overall model fit case. also important check model fit within study, check single study better fit larger number knots washed increased model complexity studies. conclude 1 knot sufficient studies.","code":"ndmm_fit_1kt <- nma(ndmm_net,                     regression = ~(age + iss_stage3 + response_cr_vgpr + male)*.trt,                     likelihood = \"mspline\",                     n_knots = 1,                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_reg = normal(0, 100),                     prior_aux = dirichlet(1),                     QR = TRUE,                     # Reducing max_treedepth can speed up warm-up, but                     # increase if max_treedepth errors occur                     control = list(max_treedepth = 6)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_1kt #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Regression model: ~(age + iss_stage3 + response_cr_vgpr + male) * .trt. #> Centred covariates at the following overall mean values: #>              age       iss_stage3 response_cr_vgpr             male  #>       61.6558571        0.2297184        0.7314265        0.6020451  #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd      2.5%       25%       50% #> beta[age]                                   0.08    0.00 0.01      0.06      0.07      0.08 #> beta[iss_stage3]                            0.36    0.00 0.13      0.09      0.27      0.36 #> beta[response_cr_vgpr]                     -0.14    0.00 0.10     -0.33     -0.20     -0.14 #> beta[male]                                  0.01    0.00 0.10     -0.19     -0.06      0.01 #> beta[age:.trtclassActive]                  -0.02    0.00 0.01     -0.03     -0.02     -0.02 #> beta[iss_stage3:.trtclassActive]            0.20    0.00 0.17     -0.14      0.08      0.20 #> beta[response_cr_vgpr:.trtclassActive]      0.20    0.00 0.14     -0.07      0.10      0.20 #> beta[male:.trtclassActive]                  0.13    0.00 0.15     -0.17      0.03      0.13 #> d[Len]                                     -0.67    0.00 0.05     -0.77     -0.71     -0.67 #> d[Thal]                                    -0.20    0.00 0.11     -0.42     -0.27     -0.20 #> lp__                                   -12422.83    0.12 4.54 -12432.71 -12425.68 -12422.41 #> scoef[Attal2012, 1]                         0.03    0.00 0.01      0.01      0.02      0.03 #> scoef[Attal2012, 2]                         0.18    0.00 0.05      0.07      0.14      0.17 #> scoef[Attal2012, 3]                         0.38    0.00 0.10      0.19      0.32      0.38 #> scoef[Attal2012, 4]                         0.20    0.00 0.09      0.03      0.13      0.19 #> scoef[Attal2012, 5]                         0.22    0.00 0.05      0.13      0.19      0.22 #> scoef[McCarthy2012, 1]                      0.01    0.00 0.01      0.00      0.00      0.00 #> scoef[McCarthy2012, 2]                      0.28    0.00 0.04      0.20      0.25      0.28 #> scoef[McCarthy2012, 3]                      0.17    0.00 0.09      0.02      0.10      0.16 #> scoef[McCarthy2012, 4]                      0.31    0.00 0.11      0.08      0.23      0.31 #> scoef[McCarthy2012, 5]                      0.23    0.00 0.07      0.09      0.18      0.23 #> scoef[Palumbo2014, 1]                       0.01    0.00 0.01      0.00      0.00      0.01 #> scoef[Palumbo2014, 2]                       0.39    0.00 0.07      0.26      0.34      0.39 #> scoef[Palumbo2014, 3]                       0.20    0.00 0.11      0.02      0.12      0.20 #> scoef[Palumbo2014, 4]                       0.18    0.00 0.11      0.01      0.09      0.17 #> scoef[Palumbo2014, 5]                       0.21    0.00 0.08      0.06      0.15      0.21 #> scoef[Jackson2019, 1]                       0.04    0.00 0.01      0.03      0.03      0.04 #> scoef[Jackson2019, 2]                       0.32    0.00 0.03      0.25      0.29      0.32 #> scoef[Jackson2019, 3]                       0.23    0.00 0.06      0.11      0.18      0.23 #> scoef[Jackson2019, 4]                       0.22    0.00 0.07      0.09      0.18      0.22 #> scoef[Jackson2019, 5]                       0.20    0.00 0.04      0.12      0.17      0.20 #> scoef[Morgan2012, 1]                        0.02    0.00 0.01      0.01      0.02      0.02 #> scoef[Morgan2012, 2]                        0.45    0.00 0.04      0.37      0.43      0.45 #> scoef[Morgan2012, 3]                        0.10    0.00 0.07      0.00      0.05      0.09 #> scoef[Morgan2012, 4]                        0.34    0.00 0.08      0.16      0.29      0.35 #> scoef[Morgan2012, 5]                        0.08    0.00 0.05      0.01      0.04      0.08 #>                                              75%     97.5% n_eff Rhat #> beta[age]                                   0.08      0.09  4125 1.00 #> beta[iss_stage3]                            0.45      0.60  8460 1.00 #> beta[response_cr_vgpr]                     -0.07      0.06  7319 1.00 #> beta[male]                                  0.07      0.21  9061 1.00 #> beta[age:.trtclassActive]                  -0.01      0.00  4984 1.00 #> beta[iss_stage3:.trtclassActive]            0.32      0.54 10231 1.00 #> beta[response_cr_vgpr:.trtclassActive]      0.30      0.48  6680 1.00 #> beta[male:.trtclassActive]                  0.23      0.43  6211 1.00 #> d[Len]                                     -0.63     -0.56  4645 1.00 #> d[Thal]                                    -0.13      0.01  4208 1.01 #> lp__                                   -12419.56 -12415.14  1403 1.00 #> scoef[Attal2012, 1]                         0.04      0.06  3835 1.00 #> scoef[Attal2012, 2]                         0.21      0.28  3107 1.00 #> scoef[Attal2012, 3]                         0.45      0.57  2743 1.00 #> scoef[Attal2012, 4]                         0.26      0.39  2986 1.00 #> scoef[Attal2012, 5]                         0.25      0.31  3693 1.00 #> scoef[McCarthy2012, 1]                      0.01      0.02  6817 1.00 #> scoef[McCarthy2012, 2]                      0.31      0.37  3650 1.00 #> scoef[McCarthy2012, 3]                      0.24      0.36  2881 1.00 #> scoef[McCarthy2012, 4]                      0.39      0.52  2946 1.00 #> scoef[McCarthy2012, 5]                      0.28      0.38  3514 1.00 #> scoef[Palumbo2014, 1]                       0.02      0.04  5219 1.00 #> scoef[Palumbo2014, 2]                       0.44      0.53  4516 1.00 #> scoef[Palumbo2014, 3]                       0.27      0.41  3449 1.00 #> scoef[Palumbo2014, 4]                       0.27      0.42  3763 1.00 #> scoef[Palumbo2014, 5]                       0.27      0.38  4682 1.00 #> scoef[Jackson2019, 1]                       0.04      0.05  1789 1.01 #> scoef[Jackson2019, 2]                       0.34      0.38  3085 1.00 #> scoef[Jackson2019, 3]                       0.27      0.35  2521 1.00 #> scoef[Jackson2019, 4]                       0.27      0.35  2601 1.00 #> scoef[Jackson2019, 5]                       0.22      0.27  3485 1.00 #> scoef[Morgan2012, 1]                        0.03      0.04  6058 1.00 #> scoef[Morgan2012, 2]                        0.49      0.54  3772 1.00 #> scoef[Morgan2012, 3]                        0.14      0.26  3793 1.00 #> scoef[Morgan2012, 4]                        0.40      0.48  4936 1.00 #> scoef[Morgan2012, 5]                        0.11      0.18  5093 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Fri Aug 25 18:49:17 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1).  ndmm_fit_2kt <- nma(ndmm_net,                     regression = ~(age + iss_stage3 + response_cr_vgpr + male)*.trt,                     likelihood = \"mspline\",                     n_knots = 2,                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_reg = normal(0, 100),                     prior_aux = dirichlet(1),                     QR = TRUE,                     # Reducing max_treedepth can speed up warm-up, but                     # increase if max_treedepth errors occur                     control = list(max_treedepth = 6)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_2kt #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Regression model: ~(age + iss_stage3 + response_cr_vgpr + male) * .trt. #> Centred covariates at the following overall mean values: #>              age       iss_stage3 response_cr_vgpr             male  #>       61.6558571        0.2297184        0.7314265        0.6020451  #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd      2.5%       25%       50% #> beta[age]                                   0.08    0.00 0.01      0.06      0.07      0.08 #> beta[iss_stage3]                            0.35    0.00 0.13      0.08      0.26      0.35 #> beta[response_cr_vgpr]                     -0.13    0.00 0.10     -0.33     -0.20     -0.13 #> beta[male]                                  0.01    0.00 0.10     -0.20     -0.07      0.01 #> beta[age:.trtclassActive]                  -0.02    0.00 0.01     -0.03     -0.02     -0.02 #> beta[iss_stage3:.trtclassActive]            0.20    0.00 0.18     -0.15      0.07      0.20 #> beta[response_cr_vgpr:.trtclassActive]      0.20    0.00 0.14     -0.07      0.11      0.20 #> beta[male:.trtclassActive]                  0.13    0.00 0.15     -0.16      0.03      0.13 #> d[Len]                                     -0.67    0.00 0.05     -0.77     -0.70     -0.67 #> d[Thal]                                    -0.20    0.00 0.11     -0.40     -0.27     -0.20 #> lp__                                   -12438.01    0.14 4.81 -12448.46 -12441.00 -12437.62 #> scoef[Attal2012, 1]                         0.02    0.00 0.01      0.00      0.01      0.01 #> scoef[Attal2012, 2]                         0.11    0.00 0.03      0.05      0.08      0.11 #> scoef[Attal2012, 3]                         0.21    0.00 0.07      0.08      0.16      0.21 #> scoef[Attal2012, 4]                         0.39    0.00 0.08      0.22      0.34      0.39 #> scoef[Attal2012, 5]                         0.10    0.00 0.06      0.00      0.05      0.09 #> scoef[Attal2012, 6]                         0.19    0.00 0.04      0.11      0.16      0.19 #> scoef[McCarthy2012, 1]                      0.00    0.00 0.00      0.00      0.00      0.00 #> scoef[McCarthy2012, 2]                      0.12    0.00 0.03      0.07      0.10      0.12 #> scoef[McCarthy2012, 3]                      0.20    0.00 0.07      0.07      0.15      0.19 #> scoef[McCarthy2012, 4]                      0.30    0.00 0.09      0.11      0.24      0.30 #> scoef[McCarthy2012, 5]                      0.17    0.00 0.10      0.02      0.09      0.16 #> scoef[McCarthy2012, 6]                      0.21    0.00 0.07      0.07      0.16      0.21 #> scoef[Palumbo2014, 1]                       0.01    0.00 0.01      0.00      0.00      0.00 #> scoef[Palumbo2014, 2]                       0.15    0.00 0.04      0.09      0.12      0.15 #> scoef[Palumbo2014, 3]                       0.27    0.00 0.09      0.10      0.20      0.26 #> scoef[Palumbo2014, 4]                       0.27    0.00 0.11      0.04      0.19      0.27 #> scoef[Palumbo2014, 5]                       0.12    0.00 0.09      0.00      0.05      0.10 #> scoef[Palumbo2014, 6]                       0.19    0.00 0.08      0.05      0.14      0.19 #> scoef[Jackson2019, 1]                       0.02    0.00 0.00      0.01      0.02      0.02 #> scoef[Jackson2019, 2]                       0.11    0.00 0.01      0.08      0.10      0.11 #> scoef[Jackson2019, 3]                       0.29    0.00 0.04      0.21      0.26      0.28 #> scoef[Jackson2019, 4]                       0.23    0.00 0.06      0.12      0.20      0.24 #> scoef[Jackson2019, 5]                       0.18    0.00 0.06      0.07      0.14      0.18 #> scoef[Jackson2019, 6]                       0.16    0.00 0.03      0.10      0.14      0.16 #> scoef[Morgan2012, 1]                        0.01    0.00 0.01      0.00      0.01      0.01 #> scoef[Morgan2012, 2]                        0.13    0.00 0.02      0.09      0.12      0.13 #> scoef[Morgan2012, 3]                        0.37    0.00 0.05      0.26      0.33      0.37 #> scoef[Morgan2012, 4]                        0.15    0.00 0.08      0.01      0.09      0.14 #> scoef[Morgan2012, 5]                        0.28    0.00 0.08      0.12      0.23      0.29 #> scoef[Morgan2012, 6]                        0.06    0.00 0.04      0.00      0.03      0.06 #>                                              75%     97.5% n_eff Rhat #> beta[age]                                   0.08      0.09  4785    1 #> beta[iss_stage3]                            0.44      0.61  9636    1 #> beta[response_cr_vgpr]                     -0.07      0.06  7143    1 #> beta[male]                                  0.08      0.21 11638    1 #> beta[age:.trtclassActive]                  -0.01      0.00  5969    1 #> beta[iss_stage3:.trtclassActive]            0.33      0.55  9439    1 #> beta[response_cr_vgpr:.trtclassActive]      0.29      0.48  6518    1 #> beta[male:.trtclassActive]                  0.23      0.42  9271    1 #> d[Len]                                     -0.63     -0.56  6105    1 #> d[Thal]                                    -0.13      0.01  6436    1 #> lp__                                   -12434.68 -12429.63  1236    1 #> scoef[Attal2012, 1]                         0.02      0.04  3682    1 #> scoef[Attal2012, 2]                         0.13      0.17  2921    1 #> scoef[Attal2012, 3]                         0.25      0.34  2594    1 #> scoef[Attal2012, 4]                         0.44      0.53  2511    1 #> scoef[Attal2012, 5]                         0.14      0.24  3383    1 #> scoef[Attal2012, 6]                         0.21      0.27  4507    1 #> scoef[McCarthy2012, 1]                      0.00      0.01  6677    1 #> scoef[McCarthy2012, 2]                      0.14      0.18  3644    1 #> scoef[McCarthy2012, 3]                      0.24      0.33  2551    1 #> scoef[McCarthy2012, 4]                      0.36      0.47  2414    1 #> scoef[McCarthy2012, 5]                      0.23      0.39  3211    1 #> scoef[McCarthy2012, 6]                      0.26      0.35  4569    1 #> scoef[Palumbo2014, 1]                       0.01      0.02  6325    1 #> scoef[Palumbo2014, 2]                       0.17      0.22  5110    1 #> scoef[Palumbo2014, 3]                       0.33      0.44  3219    1 #> scoef[Palumbo2014, 4]                       0.34      0.48  2887    1 #> scoef[Palumbo2014, 5]                       0.17      0.32  4497    1 #> scoef[Palumbo2014, 6]                       0.25      0.35  5667    1 #> scoef[Jackson2019, 1]                       0.02      0.03  6003    1 #> scoef[Jackson2019, 2]                       0.12      0.14  3181    1 #> scoef[Jackson2019, 3]                       0.31      0.36  3327    1 #> scoef[Jackson2019, 4]                       0.27      0.35  2815    1 #> scoef[Jackson2019, 5]                       0.22      0.30  3409    1 #> scoef[Jackson2019, 6]                       0.19      0.23  4284    1 #> scoef[Morgan2012, 1]                        0.01      0.02  4714    1 #> scoef[Morgan2012, 2]                        0.14      0.17  4716    1 #> scoef[Morgan2012, 3]                        0.40      0.46  3378    1 #> scoef[Morgan2012, 4]                        0.20      0.32  3326    1 #> scoef[Morgan2012, 5]                        0.34      0.42  3824    1 #> scoef[Morgan2012, 6]                        0.09      0.16  4608    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Aug 25 19:38:00 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1).  ndmm_fit_3kt <- nma(ndmm_net,                     regression = ~(age + iss_stage3 + response_cr_vgpr + male)*.trt,                     likelihood = \"mspline\",                     n_knots = 3,                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_reg = normal(0, 100),                     prior_aux = dirichlet(1),                     QR = TRUE,                     # Reducing max_treedepth can speed up warm-up, but                     # increase if max_treedepth errors occur                     control = list(max_treedepth = 6)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_3kt #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Regression model: ~(age + iss_stage3 + response_cr_vgpr + male) * .trt. #> Centred covariates at the following overall mean values: #>              age       iss_stage3 response_cr_vgpr             male  #>       61.6558571        0.2297184        0.7314265        0.6020451  #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd      2.5%       25%       50% #> beta[age]                                   0.08    0.00 0.01      0.06      0.07      0.08 #> beta[iss_stage3]                            0.35    0.00 0.13      0.08      0.26      0.35 #> beta[response_cr_vgpr]                     -0.14    0.00 0.10     -0.33     -0.20     -0.14 #> beta[male]                                  0.01    0.00 0.10     -0.19     -0.06      0.01 #> beta[age:.trtclassActive]                  -0.02    0.00 0.01     -0.03     -0.02     -0.02 #> beta[iss_stage3:.trtclassActive]            0.20    0.00 0.17     -0.13      0.08      0.20 #> beta[response_cr_vgpr:.trtclassActive]      0.20    0.00 0.14     -0.07      0.11      0.20 #> beta[male:.trtclassActive]                  0.13    0.00 0.15     -0.16      0.02      0.13 #> d[Len]                                     -0.67    0.00 0.05     -0.77     -0.70     -0.67 #> d[Thal]                                    -0.19    0.00 0.11     -0.40     -0.27     -0.19 #> lp__                                   -12455.31    0.14 5.25 -12466.37 -12458.71 -12454.92 #> scoef[Attal2012, 1]                         0.01    0.00 0.01      0.00      0.01      0.01 #> scoef[Attal2012, 2]                         0.07    0.00 0.03      0.02      0.05      0.07 #> scoef[Attal2012, 3]                         0.13    0.00 0.04      0.04      0.10      0.13 #> scoef[Attal2012, 4]                         0.29    0.00 0.06      0.17      0.25      0.29 #> scoef[Attal2012, 5]                         0.25    0.00 0.07      0.11      0.20      0.25 #> scoef[Attal2012, 6]                         0.09    0.00 0.06      0.01      0.04      0.08 #> scoef[Attal2012, 7]                         0.16    0.00 0.04      0.09      0.13      0.16 #> scoef[McCarthy2012, 1]                      0.00    0.00 0.00      0.00      0.00      0.00 #> scoef[McCarthy2012, 2]                      0.05    0.00 0.02      0.01      0.04      0.05 #> scoef[McCarthy2012, 3]                      0.18    0.00 0.04      0.10      0.15      0.18 #> scoef[McCarthy2012, 4]                      0.15    0.00 0.06      0.03      0.10      0.15 #> scoef[McCarthy2012, 5]                      0.32    0.00 0.08      0.16      0.26      0.32 #> scoef[McCarthy2012, 6]                      0.10    0.00 0.07      0.00      0.04      0.08 #> scoef[McCarthy2012, 7]                      0.21    0.00 0.07      0.08      0.16      0.21 #> scoef[Palumbo2014, 1]                       0.00    0.00 0.00      0.00      0.00      0.00 #> scoef[Palumbo2014, 2]                       0.08    0.00 0.03      0.03      0.07      0.08 #> scoef[Palumbo2014, 3]                       0.13    0.00 0.05      0.03      0.09      0.13 #> scoef[Palumbo2014, 4]                       0.29    0.00 0.09      0.10      0.23      0.29 #> scoef[Palumbo2014, 5]                       0.19    0.00 0.10      0.02      0.12      0.19 #> scoef[Palumbo2014, 6]                       0.11    0.00 0.08      0.00      0.05      0.10 #> scoef[Palumbo2014, 7]                       0.18    0.00 0.08      0.04      0.12      0.18 #> scoef[Jackson2019, 1]                       0.01    0.00 0.00      0.01      0.01      0.01 #> scoef[Jackson2019, 2]                       0.07    0.00 0.01      0.05      0.06      0.07 #> scoef[Jackson2019, 3]                       0.13    0.00 0.02      0.09      0.11      0.13 #> scoef[Jackson2019, 4]                       0.29    0.00 0.04      0.22      0.26      0.29 #> scoef[Jackson2019, 5]                       0.18    0.00 0.05      0.07      0.14      0.18 #> scoef[Jackson2019, 6]                       0.18    0.00 0.05      0.08      0.15      0.18 #> scoef[Jackson2019, 7]                       0.13    0.00 0.03      0.08      0.11      0.13 #> scoef[Morgan2012, 1]                        0.01    0.00 0.00      0.00      0.00      0.01 #> scoef[Morgan2012, 2]                        0.07    0.00 0.01      0.04      0.06      0.07 #> scoef[Morgan2012, 3]                        0.16    0.00 0.03      0.11      0.14      0.16 #> scoef[Morgan2012, 4]                        0.32    0.00 0.05      0.21      0.28      0.32 #> scoef[Morgan2012, 5]                        0.15    0.00 0.08      0.02      0.10      0.15 #> scoef[Morgan2012, 6]                        0.24    0.00 0.07      0.10      0.20      0.25 #> scoef[Morgan2012, 7]                        0.05    0.00 0.04      0.00      0.02      0.05 #>                                              75%     97.5% n_eff Rhat #> beta[age]                                   0.08      0.09  4506    1 #> beta[iss_stage3]                            0.44      0.61  6426    1 #> beta[response_cr_vgpr]                     -0.07      0.07  7209    1 #> beta[male]                                  0.07      0.21  8857    1 #> beta[age:.trtclassActive]                  -0.01      0.00  5260    1 #> beta[iss_stage3:.trtclassActive]            0.32      0.55  6366    1 #> beta[response_cr_vgpr:.trtclassActive]      0.30      0.48  6422    1 #> beta[male:.trtclassActive]                  0.23      0.42  8144    1 #> d[Len]                                     -0.63     -0.56  5030    1 #> d[Thal]                                    -0.12      0.02  5503    1 #> lp__                                   -12451.50 -12446.12  1382    1 #> scoef[Attal2012, 1]                         0.02      0.03  3352    1 #> scoef[Attal2012, 2]                         0.09      0.12  2388    1 #> scoef[Attal2012, 3]                         0.15      0.21  2194    1 #> scoef[Attal2012, 4]                         0.34      0.42  2340    1 #> scoef[Attal2012, 5]                         0.30      0.37  2473    1 #> scoef[Attal2012, 6]                         0.13      0.22  3104    1 #> scoef[Attal2012, 7]                         0.19      0.24  4230    1 #> scoef[McCarthy2012, 1]                      0.00      0.01  6289    1 #> scoef[McCarthy2012, 2]                      0.06      0.09  2993    1 #> scoef[McCarthy2012, 3]                      0.21      0.26  2593    1 #> scoef[McCarthy2012, 4]                      0.19      0.28  2638    1 #> scoef[McCarthy2012, 5]                      0.37      0.46  2649    1 #> scoef[McCarthy2012, 6]                      0.14      0.27  3040    1 #> scoef[McCarthy2012, 7]                      0.25      0.33  5255    1 #> scoef[Palumbo2014, 1]                       0.01      0.02  6677    1 #> scoef[Palumbo2014, 2]                       0.10      0.14  4492    1 #> scoef[Palumbo2014, 3]                       0.17      0.25  3415    1 #> scoef[Palumbo2014, 4]                       0.36      0.47  2937    1 #> scoef[Palumbo2014, 5]                       0.26      0.40  2979    1 #> scoef[Palumbo2014, 6]                       0.17      0.30  4765    1 #> scoef[Palumbo2014, 7]                       0.23      0.34  5738    1 #> scoef[Jackson2019, 1]                       0.02      0.02  4062    1 #> scoef[Jackson2019, 2]                       0.08      0.09  3391    1 #> scoef[Jackson2019, 3]                       0.14      0.17  2978    1 #> scoef[Jackson2019, 4]                       0.31      0.36  3043    1 #> scoef[Jackson2019, 5]                       0.22      0.28  2885    1 #> scoef[Jackson2019, 6]                       0.22      0.29  3491    1 #> scoef[Jackson2019, 7]                       0.15      0.20  4055    1 #> scoef[Morgan2012, 1]                        0.01      0.02  4940    1 #> scoef[Morgan2012, 2]                        0.08      0.10  3823    1 #> scoef[Morgan2012, 3]                        0.18      0.22  3920    1 #> scoef[Morgan2012, 4]                        0.35      0.42  3178    1 #> scoef[Morgan2012, 5]                        0.20      0.31  2888    1 #> scoef[Morgan2012, 6]                        0.29      0.37  3457    1 #> scoef[Morgan2012, 7]                        0.07      0.13  5032    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Aug 25 20:28:03 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). (ndmm_fit_1kt_loo <- loo(ndmm_fit_1kt)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12385.5 116.2 #> p_loo        31.8   0.8 #> looic     24770.9 232.5 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  (ndmm_fit_2kt_loo <- loo(ndmm_fit_2kt)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12386.1 116.2 #> p_loo        35.9   0.9 #> looic     24772.2 232.4 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  (ndmm_fit_3kt_loo <- loo(ndmm_fit_3kt)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12388.2 116.2 #> p_loo        40.1   0.9 #> looic     24776.3 232.5 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  loo_compare(list(\"1 knot\" = ndmm_fit_1kt_loo,                  \"2 knots\" = ndmm_fit_2kt_loo,                  \"3 knots\" = ndmm_fit_3kt_loo)) #>         elpd_diff se_diff #> 1 knot   0.0       0.0    #> 2 knots -0.7       2.1    #> 3 knots -2.7       2.7 studies_all <- c(ndmm_ipd$study, ndmm_agd$study) cbind(   `1 knot` = by(ndmm_fit_1kt_loo$pointwise[, \"looic\"], studies_all, sum),   `2 knots` = by(ndmm_fit_2kt_loo$pointwise[, \"looic\"], studies_all, sum),   `3 knots` = by(ndmm_fit_3kt_loo$pointwise[, \"looic\"], studies_all, sum) ) #>                 1 knot   2 knots   3 knots #> Attal2012     3342.043  3341.188  3342.966 #> Jackson2019  12394.107 12395.073 12396.222 #> McCarthy2012  2723.239  2724.039  2723.232 #> Morgan2012    4981.445  4981.976  4983.157 #> Palumbo2014   1330.072  1329.954  1330.747"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"ploting-hazards","dir":"Articles","previous_headings":"ML-NMR models with M-spline baseline hazards","what":"Ploting hazards","title":"Example: Newly diagnosed multiple myeloma","text":"Let us look estimated hazard functions model increasing numbers knots. default, predict() function type = \"hazard\" produce plots population-average marginal hazards (level = \"aggregate\", default). can plotted using plot() function. combine plots one grid using patchwork package.  see increasing numbers knots marginal hazards become increasingly “wiggly”, case overfitting. can also look individual-level baseline hazards. possible using predict() function, time level = \"individual\". Since want show baseline hazard reference level covariates, ’ll create data frame pass predict() newdata. Since providing new data frame prediction, also need provide times predict distributions baseline (intercept) auxiliary (spline coefficient) parameters. predict evenly spaced times time 0 last event/censoring time study. specify named list study names baseline aux, use posterior distributions study parameters. produce predictions, plot combine using patchwork.  , see number knots increases baseline hazards get “wiggly”. noted , based LOOIC model 1 internal knot sufficient .","code":"mhp1 <- plot(predict(ndmm_fit_1kt, type = \"hazard\", level = \"aggregate\"))  mhp2 <- plot(predict(ndmm_fit_2kt, type = \"hazard\", level = \"aggregate\"))  mhp3 <- plot(predict(ndmm_fit_3kt, type = \"hazard\", level = \"aggregate\"))  # Combining these into a single plot using patchwork mhp1 + facet_grid(rows = vars(\"1 knot\"), cols = vars(Study)) +   mhp2 + facet_grid(rows = vars(\"2 knots\"), cols = vars(Study)) +   mhp3 + facet_grid(rows = vars(\"3 knots\"), cols = vars(Study)) +   plot_layout(ncol = 1, guides = \"collect\") &   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\")) refdat <- tibble(study = ndmm_net$studies,                  age = ndmm_fit_1kt$xbar[\"age\"],                  iss_stage3 = 0,                  response_cr_vgpr = 0,                  male = 0) # At evenly spaced times between the boundary knots tdat <- purrr::imap_dfr(ndmm_fit_1kt$basis,                         ~tibble(study = factor(.y, levels = ndmm_net$studies),                                 lower = attr(.x, \"Boundary.knots\")[1],                                 upper = attr(.x, \"Boundary.knots\")[2],                                 times = seq(lower, upper, length = 50)))  refdat <- left_join(refdat, tdat, by = \"study\")  studies <- as.list(setNames(nm = levels(ndmm_net$studies))) bhp1 <- plot(predict(ndmm_fit_1kt, type = \"hazard\", level = \"individual\",                     newdata = refdat, study = study, times = times,                     baseline = studies, aux = studies))  bhp2 <- plot(predict(ndmm_fit_2kt, type = \"hazard\", level = \"individual\",                     newdata = refdat, study = study, times = times,                     baseline = studies, aux = studies))  bhp3 <- plot(predict(ndmm_fit_3kt, type = \"hazard\", level = \"individual\",                     newdata = refdat, study = study, times = times,                     baseline = studies, aux = studies))  # Combining these into a single plot using patchwork bhp1 + facet_grid(rows = vars(\"1 knot\"), cols = vars(Study)) +   bhp2 + facet_grid(rows = vars(\"2 knots\"), cols = vars(Study)) +   bhp3 + facet_grid(rows = vars(\"3 knots\"), cols = vars(Study)) +   plot_layout(ncol = 1, guides = \"collect\") &   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"assessing-the-proportional-hazards-assumption","dir":"Articles","previous_headings":"","what":"Assessing the proportional hazards assumption","title":"Example: Newly diagnosed multiple myeloma","text":"can relax assess proportional hazards (PH) assumption allowing spline coefficients vary treatment arms within study. achieved using aux_by argument, aux_by = c(.study, .trt). Technically, aux_by = .study always assumed order respect randomisation (analogous stratifying intercept terms NMA study), simply write aux_by = .trt; choose make stratification study explicit instance. compare model fit models without PH using LOOIC. overall fit proportional hazards model better (substantially). , check single study better fit non-PH model. LOOIC slightly lower non-PH model Jackson2019 Palumbo2014 studies, substantially . studies LOOIC lower PH model. Overall, little evidence suggest proportional hazards assumption invalid .","code":"ndmm_fit_nph <- nma(ndmm_net,                     regression = ~(age + iss_stage3 + response_cr_vgpr + male)*.trt,                     likelihood = \"mspline\",                     n_knots = 1,                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_reg = normal(0, 100),                     prior_aux = dirichlet(1),                     aux_by = c(.study, .trt),                     QR = TRUE,                     # Reducing max_treedepth can speed up warm-up, but                     # increase if max_treedepth errors occur                     control = list(max_treedepth = 6)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nph #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Regression model: ~(age + iss_stage3 + response_cr_vgpr + male) * .trt. #> Centred covariates at the following overall mean values: #>              age       iss_stage3 response_cr_vgpr             male  #>       61.6558571        0.2297184        0.7314265        0.6020451  #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd      2.5%       25%       50% #> beta[age]                                   0.07    0.00 0.01      0.06      0.07      0.07 #> beta[iss_stage3]                            0.33    0.00 0.13      0.07      0.24      0.34 #> beta[response_cr_vgpr]                     -0.11    0.00 0.10     -0.29     -0.17     -0.11 #> beta[male]                                  0.00    0.00 0.10     -0.21     -0.07      0.00 #> beta[age:.trtclassActive]                  -0.01    0.00 0.01     -0.03     -0.02     -0.01 #> beta[iss_stage3:.trtclassActive]            0.24    0.00 0.18     -0.11      0.11      0.24 #> beta[response_cr_vgpr:.trtclassActive]      0.15    0.00 0.14     -0.12      0.06      0.15 #> beta[male:.trtclassActive]                  0.15    0.00 0.15     -0.14      0.05      0.15 #> d[Len]                                     -0.61    0.00 0.07     -0.75     -0.66     -0.61 #> d[Thal]                                    -0.27    0.00 0.13     -0.53     -0.35     -0.27 #> lp__                                   -12473.08    0.16 5.68 -12485.07 -12476.69 -12472.77 #> scoef[Attal2012: Pbo, 1]                    0.03    0.00 0.02      0.01      0.02      0.03 #> scoef[Attal2012: Pbo, 2]                    0.17    0.00 0.07      0.05      0.13      0.17 #> scoef[Attal2012: Pbo, 3]                    0.46    0.00 0.11      0.21      0.39      0.47 #> scoef[Attal2012: Pbo, 4]                    0.15    0.00 0.10      0.01      0.06      0.13 #> scoef[Attal2012: Pbo, 5]                    0.19    0.00 0.06      0.08      0.15      0.19 #> scoef[Attal2012: Len, 1]                    0.03    0.00 0.02      0.00      0.01      0.03 #> scoef[Attal2012: Len, 2]                    0.18    0.00 0.07      0.04      0.13      0.18 #> scoef[Attal2012: Len, 3]                    0.26    0.00 0.13      0.03      0.16      0.25 #> scoef[Attal2012: Len, 4]                    0.31    0.00 0.12      0.07      0.22      0.31 #> scoef[Attal2012: Len, 5]                    0.23    0.00 0.06      0.11      0.18      0.22 #> scoef[McCarthy2012: Pbo, 1]                 0.01    0.00 0.01      0.00      0.00      0.01 #> scoef[McCarthy2012: Pbo, 2]                 0.30    0.00 0.06      0.18      0.26      0.30 #> scoef[McCarthy2012: Pbo, 3]                 0.20    0.00 0.12      0.02      0.11      0.19 #> scoef[McCarthy2012: Pbo, 4]                 0.30    0.00 0.14      0.04      0.20      0.31 #> scoef[McCarthy2012: Pbo, 5]                 0.19    0.00 0.11      0.01      0.10      0.18 #> scoef[McCarthy2012: Len, 1]                 0.01    0.00 0.01      0.00      0.00      0.01 #> scoef[McCarthy2012: Len, 2]                 0.26    0.00 0.06      0.13      0.22      0.26 #> scoef[McCarthy2012: Len, 3]                 0.20    0.00 0.12      0.01      0.11      0.19 #> scoef[McCarthy2012: Len, 4]                 0.30    0.00 0.13      0.04      0.20      0.30 #> scoef[McCarthy2012: Len, 5]                 0.23    0.00 0.08      0.08      0.18      0.23 #> scoef[Palumbo2014: Pbo, 1]                  0.02    0.00 0.02      0.00      0.01      0.02 #> scoef[Palumbo2014: Pbo, 2]                  0.47    0.00 0.09      0.29      0.41      0.47 #> scoef[Palumbo2014: Pbo, 3]                  0.13    0.00 0.09      0.01      0.05      0.11 #> scoef[Palumbo2014: Pbo, 4]                  0.15    0.00 0.10      0.01      0.07      0.13 #> scoef[Palumbo2014: Pbo, 5]                  0.23    0.00 0.10      0.06      0.17      0.23 #> scoef[Palumbo2014: Len, 1]                  0.02    0.00 0.01      0.00      0.00      0.01 #> scoef[Palumbo2014: Len, 2]                  0.23    0.00 0.09      0.07      0.16      0.22 #> scoef[Palumbo2014: Len, 3]                  0.38    0.00 0.16      0.07      0.27      0.38 #> scoef[Palumbo2014: Len, 4]                  0.20    0.00 0.14      0.01      0.08      0.17 #> scoef[Palumbo2014: Len, 5]                  0.18    0.00 0.10      0.02      0.11      0.18 #> scoef[Jackson2019: Pbo, 1]                  0.06    0.00 0.01      0.04      0.05      0.06 #> scoef[Jackson2019: Pbo, 2]                  0.30    0.00 0.05      0.21      0.27      0.30 #> scoef[Jackson2019: Pbo, 3]                  0.26    0.00 0.08      0.10      0.21      0.27 #> scoef[Jackson2019: Pbo, 4]                  0.13    0.00 0.09      0.01      0.06      0.12 #> scoef[Jackson2019: Pbo, 5]                  0.25    0.00 0.06      0.13      0.22      0.26 #> scoef[Jackson2019: Len, 1]                  0.02    0.00 0.01      0.01      0.02      0.02 #> scoef[Jackson2019: Len, 2]                  0.36    0.00 0.04      0.27      0.33      0.36 #> scoef[Jackson2019: Len, 3]                  0.17    0.00 0.08      0.03      0.12      0.17 #> scoef[Jackson2019: Len, 4]                  0.28    0.00 0.08      0.13      0.23      0.28 #> scoef[Jackson2019: Len, 5]                  0.16    0.00 0.04      0.09      0.14      0.16 #> scoef[Morgan2012: Pbo, 1]                   0.03    0.00 0.01      0.01      0.02      0.03 #> scoef[Morgan2012: Pbo, 2]                   0.40    0.00 0.06      0.29      0.36      0.40 #> scoef[Morgan2012: Pbo, 3]                   0.12    0.00 0.08      0.01      0.05      0.10 #> scoef[Morgan2012: Pbo, 4]                   0.30    0.00 0.11      0.08      0.23      0.31 #> scoef[Morgan2012: Pbo, 5]                   0.15    0.00 0.08      0.02      0.09      0.14 #> scoef[Morgan2012: Thal, 1]                  0.02    0.00 0.01      0.00      0.01      0.02 #> scoef[Morgan2012: Thal, 2]                  0.48    0.00 0.06      0.36      0.44      0.48 #> scoef[Morgan2012: Thal, 3]                  0.15    0.00 0.10      0.01      0.08      0.14 #> scoef[Morgan2012: Thal, 4]                  0.28    0.00 0.10      0.06      0.22      0.29 #> scoef[Morgan2012: Thal, 5]                  0.07    0.00 0.05      0.00      0.03      0.06 #>                                              75%     97.5% n_eff Rhat #> beta[age]                                   0.08      0.09  2216 1.00 #> beta[iss_stage3]                            0.42      0.58  6138 1.00 #> beta[response_cr_vgpr]                     -0.04      0.08  5661 1.00 #> beta[male]                                  0.06      0.19  6871 1.00 #> beta[age:.trtclassActive]                  -0.01      0.01  2534 1.00 #> beta[iss_stage3:.trtclassActive]            0.36      0.59  5870 1.00 #> beta[response_cr_vgpr:.trtclassActive]      0.25      0.43  5511 1.00 #> beta[male:.trtclassActive]                  0.25      0.45  5021 1.00 #> d[Len]                                     -0.57     -0.48  3125 1.00 #> d[Thal]                                    -0.18     -0.02  3754 1.00 #> lp__                                   -12469.06 -12462.95  1240 1.00 #> scoef[Attal2012: Pbo, 1]                    0.04      0.07  3057 1.00 #> scoef[Attal2012: Pbo, 2]                    0.22      0.31  2162 1.00 #> scoef[Attal2012: Pbo, 3]                    0.54      0.65  2063 1.00 #> scoef[Attal2012: Pbo, 4]                    0.21      0.37  2671 1.00 #> scoef[Attal2012: Pbo, 5]                    0.23      0.31  4213 1.00 #> scoef[Attal2012: Len, 1]                    0.04      0.08  3132 1.00 #> scoef[Attal2012: Len, 2]                    0.23      0.32  2367 1.00 #> scoef[Attal2012: Len, 3]                    0.35      0.52  2260 1.00 #> scoef[Attal2012: Len, 4]                    0.40      0.54  2831 1.00 #> scoef[Attal2012: Len, 5]                    0.27      0.36  3702 1.00 #> scoef[McCarthy2012: Pbo, 1]                 0.01      0.03  5235 1.00 #> scoef[McCarthy2012: Pbo, 2]                 0.34      0.42  3670 1.00 #> scoef[McCarthy2012: Pbo, 3]                 0.28      0.45  3512 1.00 #> scoef[McCarthy2012: Pbo, 4]                 0.41      0.56  3277 1.00 #> scoef[McCarthy2012: Pbo, 5]                 0.27      0.41  3494 1.00 #> scoef[McCarthy2012: Len, 1]                 0.02      0.04  4684 1.00 #> scoef[McCarthy2012: Len, 2]                 0.30      0.38  3049 1.00 #> scoef[McCarthy2012: Len, 3]                 0.28      0.45  2374 1.00 #> scoef[McCarthy2012: Len, 4]                 0.40      0.55  3123 1.00 #> scoef[McCarthy2012: Len, 5]                 0.29      0.39  4068 1.00 #> scoef[Palumbo2014: Pbo, 1]                  0.03      0.07  4681 1.00 #> scoef[Palumbo2014: Pbo, 2]                  0.53      0.64  3988 1.00 #> scoef[Palumbo2014: Pbo, 3]                  0.18      0.34  4258 1.00 #> scoef[Palumbo2014: Pbo, 4]                  0.21      0.38  5324 1.00 #> scoef[Palumbo2014: Pbo, 5]                  0.30      0.42  5781 1.00 #> scoef[Palumbo2014: Len, 1]                  0.02      0.05  5708 1.00 #> scoef[Palumbo2014: Len, 2]                  0.29      0.41  3657 1.00 #> scoef[Palumbo2014: Len, 3]                  0.49      0.67  3305 1.00 #> scoef[Palumbo2014: Len, 4]                  0.29      0.52  3535 1.00 #> scoef[Palumbo2014: Len, 5]                  0.25      0.39  5333 1.00 #> scoef[Jackson2019: Pbo, 1]                  0.06      0.08  2324 1.01 #> scoef[Jackson2019: Pbo, 2]                  0.33      0.40  2500 1.00 #> scoef[Jackson2019: Pbo, 3]                  0.32      0.41  2483 1.00 #> scoef[Jackson2019: Pbo, 4]                  0.18      0.33  2635 1.00 #> scoef[Jackson2019: Pbo, 5]                  0.29      0.37  3039 1.00 #> scoef[Jackson2019: Len, 1]                  0.03      0.04  3353 1.00 #> scoef[Jackson2019: Len, 2]                  0.39      0.44  1886 1.00 #> scoef[Jackson2019: Len, 3]                  0.23      0.33  1757 1.00 #> scoef[Jackson2019: Len, 4]                  0.34      0.43  2340 1.00 #> scoef[Jackson2019: Len, 5]                  0.19      0.24  3382 1.00 #> scoef[Morgan2012: Pbo, 1]                   0.04      0.06  3363 1.00 #> scoef[Morgan2012: Pbo, 2]                   0.44      0.52  2588 1.00 #> scoef[Morgan2012: Pbo, 3]                   0.17      0.31  2850 1.00 #> scoef[Morgan2012: Pbo, 4]                   0.37      0.49  3817 1.00 #> scoef[Morgan2012: Pbo, 5]                   0.20      0.31  3731 1.00 #> scoef[Morgan2012: Thal, 1]                  0.02      0.04  4551 1.00 #> scoef[Morgan2012: Thal, 2]                  0.52      0.60  3293 1.00 #> scoef[Morgan2012: Thal, 3]                  0.22      0.36  2756 1.00 #> scoef[Morgan2012: Thal, 4]                  0.35      0.45  3444 1.00 #> scoef[Morgan2012: Thal, 5]                  0.10      0.19  3985 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Fri Aug 25 21:49:33 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). (ndmm_fit_nph_loo <- loo(ndmm_fit_nph)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12389.4 116.2 #> p_loo        44.5   1.1 #> looic     24778.8 232.5 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  # Compare to PH model loo_compare(ndmm_fit_1kt_loo, ndmm_fit_nph_loo) #>        elpd_diff se_diff #> model1  0.0       0.0    #> model2 -3.9       4.4 cbind(   PH = by(ndmm_fit_1kt_loo$pointwise[, \"looic\"], studies_all, sum),   `non-PH` = by(ndmm_fit_nph_loo$pointwise[, \"looic\"], studies_all, sum) ) #>                     PH    non-PH #> Attal2012     3342.043  3344.800 #> Jackson2019  12394.107 12391.884 #> McCarthy2012  2723.239  2728.845 #> Morgan2012    4981.445  4984.381 #> Palumbo2014   1330.072  1328.877"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"comparison-to-unadjusted-nma","dir":"Articles","previous_headings":"Assessing the proportional hazards assumption","what":"Comparison to unadjusted NMA","title":"Example: Newly diagnosed multiple myeloma","text":"comparison, also fit NMA models without covariate adjustment, without proportional hazards assumption. , compare model fit using LOOIC, overall within study. Whilst little difference overall model fit, non-PH model preferred Jackson2019 study substantially lower LOOIC. Including covariates ML-NMR model sufficient remove PH violation, even though covariates fixed time-varying, ML-NMR model much better fit overall.","code":"ndmm_fit_nma <- nma(ndmm_net,                     likelihood = \"mspline\",                     n_knots = 1,                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_aux = dirichlet(1)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nma #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                             mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[Len]                     -0.52    0.00 0.04     -0.61     -0.55     -0.52     -0.49     -0.43 #> d[Thal]                    -0.10    0.00 0.09     -0.27     -0.16     -0.10     -0.04      0.06 #> lp__                   -12503.23    0.11 4.05 -12511.77 -12505.82 -12502.95 -12500.28 -12496.36 #> scoef[Attal2012, 1]         0.03    0.00 0.01      0.01      0.02      0.03      0.04      0.06 #> scoef[Attal2012, 2]         0.20    0.00 0.06      0.09      0.16      0.20      0.24      0.32 #> scoef[Attal2012, 3]         0.39    0.00 0.10      0.19      0.33      0.40      0.46      0.58 #> scoef[Attal2012, 4]         0.18    0.00 0.09      0.03      0.11      0.17      0.23      0.36 #> scoef[Attal2012, 5]         0.20    0.00 0.04      0.12      0.17      0.20      0.23      0.28 #> scoef[McCarthy2012, 1]      0.01    0.00 0.01      0.00      0.00      0.00      0.01      0.02 #> scoef[McCarthy2012, 2]      0.32    0.00 0.05      0.23      0.29      0.32      0.35      0.41 #> scoef[McCarthy2012, 3]      0.16    0.00 0.09      0.02      0.09      0.16      0.23      0.35 #> scoef[McCarthy2012, 4]      0.30    0.00 0.11      0.09      0.22      0.30      0.37      0.50 #> scoef[McCarthy2012, 5]      0.21    0.00 0.07      0.08      0.16      0.21      0.26      0.35 #> scoef[Palumbo2014, 1]       0.02    0.00 0.02      0.00      0.01      0.01      0.03      0.06 #> scoef[Palumbo2014, 2]       0.46    0.00 0.07      0.31      0.41      0.46      0.51      0.60 #> scoef[Palumbo2014, 3]       0.18    0.00 0.10      0.01      0.10      0.17      0.25      0.39 #> scoef[Palumbo2014, 4]       0.17    0.00 0.10      0.01      0.08      0.16      0.24      0.39 #> scoef[Palumbo2014, 5]       0.18    0.00 0.07      0.04      0.13      0.18      0.23      0.33 #> scoef[Jackson2019, 1]       0.06    0.00 0.01      0.04      0.05      0.06      0.06      0.07 #> scoef[Jackson2019, 2]       0.39    0.00 0.03      0.33      0.37      0.39      0.42      0.46 #> scoef[Jackson2019, 3]       0.19    0.00 0.06      0.06      0.15      0.19      0.23      0.31 #> scoef[Jackson2019, 4]       0.20    0.00 0.06      0.08      0.16      0.20      0.24      0.32 #> scoef[Jackson2019, 5]       0.16    0.00 0.03      0.10      0.14      0.16      0.18      0.22 #> scoef[Morgan2012, 1]        0.03    0.00 0.01      0.01      0.03      0.03      0.04      0.06 #> scoef[Morgan2012, 2]        0.54    0.00 0.04      0.46      0.51      0.54      0.57      0.62 #> scoef[Morgan2012, 3]        0.07    0.00 0.06      0.00      0.03      0.06      0.11      0.21 #> scoef[Morgan2012, 4]        0.29    0.00 0.06      0.15      0.25      0.29      0.33      0.40 #> scoef[Morgan2012, 5]        0.06    0.00 0.04      0.01      0.03      0.06      0.09      0.15 #>                        n_eff Rhat #> d[Len]                  2978    1 #> d[Thal]                 4013    1 #> lp__                    1395    1 #> scoef[Attal2012, 1]     3007    1 #> scoef[Attal2012, 2]     2364    1 #> scoef[Attal2012, 3]     2346    1 #> scoef[Attal2012, 4]     2882    1 #> scoef[Attal2012, 5]     3828    1 #> scoef[McCarthy2012, 1]  6595    1 #> scoef[McCarthy2012, 2]  3449    1 #> scoef[McCarthy2012, 3]  3024    1 #> scoef[McCarthy2012, 4]  3374    1 #> scoef[McCarthy2012, 5]  3625    1 #> scoef[Palumbo2014, 1]   5315    1 #> scoef[Palumbo2014, 2]   4138    1 #> scoef[Palumbo2014, 3]   3389    1 #> scoef[Palumbo2014, 4]   4881    1 #> scoef[Palumbo2014, 5]   5368    1 #> scoef[Jackson2019, 1]   4388    1 #> scoef[Jackson2019, 2]   2848    1 #> scoef[Jackson2019, 3]   2470    1 #> scoef[Jackson2019, 4]   2915    1 #> scoef[Jackson2019, 5]   3695    1 #> scoef[Morgan2012, 1]    5208    1 #> scoef[Morgan2012, 2]    3911    1 #> scoef[Morgan2012, 3]    3425    1 #> scoef[Morgan2012, 4]    4896    1 #> scoef[Morgan2012, 5]    5102    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Aug 25 21:55:07 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1).  ndmm_fit_nma_nph <- nma(ndmm_net,                         likelihood = \"mspline\",                         n_knots = 1,                         prior_intercept = normal(0, 100),                         prior_trt = normal(0, 100),                         prior_aux = dirichlet(1),                         aux_by = c(.study, .trt)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nma_nph #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                  mean se_mean   sd      2.5%       25%       50%       75% #> d[Len]                          -0.46    0.00 0.05     -0.56     -0.50     -0.46     -0.43 #> d[Thal]                         -0.13    0.00 0.10     -0.33     -0.20     -0.13     -0.06 #> lp__                        -12548.70    0.15 5.42 -12560.09 -12552.11 -12548.29 -12544.91 #> scoef[Attal2012: Pbo, 1]         0.04    0.00 0.02      0.01      0.02      0.03      0.05 #> scoef[Attal2012: Pbo, 2]         0.21    0.00 0.07      0.07      0.16      0.21      0.26 #> scoef[Attal2012: Pbo, 3]         0.45    0.00 0.11      0.21      0.38      0.46      0.53 #> scoef[Attal2012: Pbo, 4]         0.13    0.00 0.09      0.01      0.06      0.11      0.18 #> scoef[Attal2012: Pbo, 5]         0.17    0.00 0.05      0.07      0.13      0.17      0.21 #> scoef[Attal2012: Len, 1]         0.03    0.00 0.02      0.00      0.02      0.03      0.05 #> scoef[Attal2012: Len, 2]         0.19    0.00 0.07      0.04      0.14      0.19      0.24 #> scoef[Attal2012: Len, 3]         0.28    0.00 0.13      0.05      0.19      0.28      0.37 #> scoef[Attal2012: Len, 4]         0.28    0.00 0.12      0.05      0.20      0.28      0.37 #> scoef[Attal2012: Len, 5]         0.21    0.00 0.06      0.10      0.17      0.21      0.25 #> scoef[McCarthy2012: Pbo, 1]      0.01    0.00 0.01      0.00      0.00      0.01      0.02 #> scoef[McCarthy2012: Pbo, 2]      0.33    0.00 0.07      0.20      0.29      0.33      0.38 #> scoef[McCarthy2012: Pbo, 3]      0.20    0.00 0.12      0.02      0.11      0.19      0.28 #> scoef[McCarthy2012: Pbo, 4]      0.28    0.00 0.14      0.03      0.18      0.28      0.38 #> scoef[McCarthy2012: Pbo, 5]      0.17    0.00 0.11      0.01      0.09      0.16      0.25 #> scoef[McCarthy2012: Len, 1]      0.01    0.00 0.01      0.00      0.00      0.01      0.02 #> scoef[McCarthy2012: Len, 2]      0.29    0.00 0.07      0.16      0.24      0.29      0.34 #> scoef[McCarthy2012: Len, 3]      0.19    0.00 0.12      0.01      0.10      0.18      0.28 #> scoef[McCarthy2012: Len, 4]      0.28    0.00 0.13      0.04      0.19      0.28      0.38 #> scoef[McCarthy2012: Len, 5]      0.22    0.00 0.08      0.08      0.17      0.22      0.27 #> scoef[Palumbo2014: Pbo, 1]       0.04    0.00 0.03      0.00      0.02      0.03      0.06 #> scoef[Palumbo2014: Pbo, 2]       0.54    0.00 0.09      0.34      0.48      0.54      0.60 #> scoef[Palumbo2014: Pbo, 3]       0.11    0.00 0.09      0.00      0.04      0.09      0.16 #> scoef[Palumbo2014: Pbo, 4]       0.13    0.00 0.09      0.01      0.06      0.12      0.19 #> scoef[Palumbo2014: Pbo, 5]       0.18    0.00 0.08      0.04      0.12      0.18      0.24 #> scoef[Palumbo2014: Len, 1]       0.02    0.00 0.02      0.00      0.01      0.01      0.03 #> scoef[Palumbo2014: Len, 2]       0.25    0.00 0.10      0.07      0.18      0.25      0.32 #> scoef[Palumbo2014: Len, 3]       0.37    0.00 0.16      0.06      0.26      0.37      0.48 #> scoef[Palumbo2014: Len, 4]       0.18    0.00 0.13      0.01      0.07      0.15      0.27 #> scoef[Palumbo2014: Len, 5]       0.18    0.00 0.10      0.02      0.11      0.18      0.25 #> scoef[Jackson2019: Pbo, 1]       0.08    0.00 0.01      0.06      0.07      0.08      0.09 #> scoef[Jackson2019: Pbo, 2]       0.38    0.00 0.05      0.29      0.35      0.38      0.42 #> scoef[Jackson2019: Pbo, 3]       0.22    0.00 0.07      0.07      0.17      0.22      0.27 #> scoef[Jackson2019: Pbo, 4]       0.11    0.00 0.07      0.01      0.05      0.10      0.16 #> scoef[Jackson2019: Pbo, 5]       0.20    0.00 0.05      0.11      0.17      0.20      0.24 #> scoef[Jackson2019: Len, 1]       0.03    0.00 0.01      0.01      0.02      0.03      0.03 #> scoef[Jackson2019: Len, 2]       0.42    0.00 0.04      0.33      0.39      0.42      0.45 #> scoef[Jackson2019: Len, 3]       0.16    0.00 0.08      0.02      0.10      0.15      0.21 #> scoef[Jackson2019: Len, 4]       0.26    0.00 0.07      0.11      0.22      0.27      0.32 #> scoef[Jackson2019: Len, 5]       0.14    0.00 0.03      0.07      0.11      0.13      0.16 #> scoef[Morgan2012: Pbo, 1]        0.05    0.00 0.02      0.02      0.04      0.05      0.06 #> scoef[Morgan2012: Pbo, 2]        0.48    0.00 0.06      0.36      0.44      0.48      0.52 #> scoef[Morgan2012: Pbo, 3]        0.10    0.00 0.08      0.00      0.04      0.09      0.15 #> scoef[Morgan2012: Pbo, 4]        0.25    0.00 0.09      0.05      0.19      0.25      0.31 #> scoef[Morgan2012: Pbo, 5]        0.12    0.00 0.06      0.02      0.07      0.11      0.16 #> scoef[Morgan2012: Thal, 1]       0.02    0.00 0.01      0.00      0.01      0.02      0.03 #> scoef[Morgan2012: Thal, 2]       0.56    0.00 0.06      0.44      0.52      0.56      0.60 #> scoef[Morgan2012: Thal, 3]       0.12    0.00 0.08      0.01      0.06      0.11      0.17 #> scoef[Morgan2012: Thal, 4]       0.24    0.00 0.08      0.06      0.19      0.25      0.30 #> scoef[Morgan2012: Thal, 5]       0.06    0.00 0.04      0.00      0.03      0.05      0.09 #>                                 97.5% n_eff Rhat #> d[Len]                          -0.36  3061    1 #> d[Thal]                          0.07  3427    1 #> lp__                        -12539.10  1292    1 #> scoef[Attal2012: Pbo, 1]         0.08  3716    1 #> scoef[Attal2012: Pbo, 2]         0.36  2527    1 #> scoef[Attal2012: Pbo, 3]         0.65  2431    1 #> scoef[Attal2012: Pbo, 4]         0.34  2795    1 #> scoef[Attal2012: Pbo, 5]         0.28  3952    1 #> scoef[Attal2012: Len, 1]         0.09  3219    1 #> scoef[Attal2012: Len, 2]         0.33  2734    1 #> scoef[Attal2012: Len, 3]         0.54  2558    1 #> scoef[Attal2012: Len, 4]         0.51  2982    1 #> scoef[Attal2012: Len, 5]         0.33  4146    1 #> scoef[McCarthy2012: Pbo, 1]      0.04  5654    1 #> scoef[McCarthy2012: Pbo, 2]      0.47  3260    1 #> scoef[McCarthy2012: Pbo, 3]      0.45  3526    1 #> scoef[McCarthy2012: Pbo, 4]      0.53  3302    1 #> scoef[McCarthy2012: Pbo, 5]      0.40  3313    1 #> scoef[McCarthy2012: Len, 1]      0.05  5359    1 #> scoef[McCarthy2012: Len, 2]      0.42  3494    1 #> scoef[McCarthy2012: Len, 3]      0.44  2615    1 #> scoef[McCarthy2012: Len, 4]      0.52  3389    1 #> scoef[McCarthy2012: Len, 5]      0.37  4228    1 #> scoef[Palumbo2014: Pbo, 1]       0.11  4909    1 #> scoef[Palumbo2014: Pbo, 2]       0.70  4223    1 #> scoef[Palumbo2014: Pbo, 3]       0.31  3717    1 #> scoef[Palumbo2014: Pbo, 4]       0.34  4973    1 #> scoef[Palumbo2014: Pbo, 5]       0.34  6107    1 #> scoef[Palumbo2014: Len, 1]       0.06  5491    1 #> scoef[Palumbo2014: Len, 2]       0.45  4035    1 #> scoef[Palumbo2014: Len, 3]       0.66  3294    1 #> scoef[Palumbo2014: Len, 4]       0.48  3538    1 #> scoef[Palumbo2014: Len, 5]       0.38  5038    1 #> scoef[Jackson2019: Pbo, 1]       0.11  4284    1 #> scoef[Jackson2019: Pbo, 2]       0.48  2761    1 #> scoef[Jackson2019: Pbo, 3]       0.36  2322    1 #> scoef[Jackson2019: Pbo, 4]       0.27  2512    1 #> scoef[Jackson2019: Pbo, 5]       0.30  3455    1 #> scoef[Jackson2019: Len, 1]       0.05  4152    1 #> scoef[Jackson2019: Len, 2]       0.50  3220    1 #> scoef[Jackson2019: Len, 3]       0.32  2662    1 #> scoef[Jackson2019: Len, 4]       0.39  2987    1 #> scoef[Jackson2019: Len, 5]       0.21  4141    1 #> scoef[Morgan2012: Pbo, 1]        0.09  4143    1 #> scoef[Morgan2012: Pbo, 2]        0.59  3575    1 #> scoef[Morgan2012: Pbo, 3]        0.28  3103    1 #> scoef[Morgan2012: Pbo, 4]        0.41  4253    1 #> scoef[Morgan2012: Pbo, 5]        0.25  4940    1 #> scoef[Morgan2012: Thal, 1]       0.05  5500    1 #> scoef[Morgan2012: Thal, 2]       0.67  4790    1 #> scoef[Morgan2012: Thal, 3]       0.30  3678    1 #> scoef[Morgan2012: Thal, 4]       0.39  4719    1 #> scoef[Morgan2012: Thal, 5]       0.16  4992    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Aug 25 22:00:38 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Compare overall model fit (ndmm_fit_nma_loo <- loo(ndmm_fit_nma)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12461.3 115.4 #> p_loo        22.6   0.6 #> looic     24922.7 230.8 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  (ndmm_fit_nma_nph_loo <- loo(ndmm_fit_nma_nph)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12460.3 115.4 #> p_loo        35.1   1.0 #> looic     24920.5 230.9 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  loo_compare(ndmm_fit_nma_loo, ndmm_fit_nma_nph_loo) #>        elpd_diff se_diff #> model2  0.0       0.0    #> model1 -1.1       5.3     # Compare model fit by study cbind(   PH = by(ndmm_fit_nma_loo$pointwise[, \"looic\"], studies_all, sum),   `non-PH` = by(ndmm_fit_nma_nph_loo$pointwise[, \"looic\"], studies_all, sum) ) #>                     PH    non-PH #> Attal2012     3406.395  3408.744 #> Jackson2019  12401.491 12391.276 #> McCarthy2012  2766.946  2771.886 #> Morgan2012    4981.328  4984.390 #> Palumbo2014   1366.513  1364.247"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"producing-population-average-estimates","dir":"Articles","previous_headings":"","what":"Producing population-average estimates","title":"Example: Newly diagnosed multiple myeloma","text":"now produce population-average estimates several different quantities interest. usual array posterior summary functions available, including relative_effects(), predict(), posterior_ranks() posterior_rank_probs(). predict() function particular numerous options working survival models, selected using type argument: \"survival\" survival probabilities \"hazard\" hazards \"cumhaz\" cumulative hazards \"rmst\" restricted mean survival times \"mean\" mean survival times (equivalent type = \"rmst\" time = Inf) \"quantile\" quantiles survival time distribution \"median\" median survival times (equivalent type = \"quantile\" quantiles = 0.5) \"link\" linear predictor producing population-average predictions (default level = \"aggregate\"), quantities corresponds population-average marginal survival function; see ?predict.stan_nma details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-survival-probabilities","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average survival probabilities","title":"Example: Newly diagnosed multiple myeloma","text":"produce population-average survival curves use predict() function type = \"survival\". marginal standardised survival curves.","code":"sp <- plot(predict(ndmm_fit_1kt, type = \"survival\"))  # Overlay the KM data kmdat <- bind_rows(ndmm_ipd, ndmm_agd) %>%   group_by(studyf, trtf) %>%   group_modify(~with(survfit(Surv(eventtime, event = status) ~ 1, data = .),                      tibble(time, n.censor, estimate = surv, std.err, upper, lower))) %>%   # Add S(0) = 1   group_modify(~add_row(., time = 0, n.censor = 0, estimate = 1, std.err = 0, upper = 1, lower = 1, .before = 0)) %>%   mutate(Treatment = trtf, Study = studyf)  sp +   geom_step(aes(x = time, y = estimate, colour = Treatment), linewidth = 0.15, data = kmdat) +   geom_point(aes(x = time, y = estimate, colour = Treatment), stroke = 0.15, shape = 3,              data = filter(kmdat, n.censor >= 1)) +   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-median-survival-times","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average median survival times","title":"Example: Newly diagnosed multiple myeloma","text":"predict() function can produce range absolute effect summaries, example population-average median survival times:","code":"(medsurv <- predict(ndmm_fit_1kt, type = \"median\")) #> Warning: Evaluating M-spline at times beyond the boundary knots. #> Evaluating M-spline at times beyond the boundary knots. #> Evaluating M-spline at times beyond the boundary knots. #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Attal2012: Pbo]  28.70 1.58 25.71 27.61 28.66 29.78 31.89     4745     3841 1.00 #> pred[Attal2012: Len]  46.73 2.44 42.11 45.04 46.67 48.22 51.76     9315     3365 1.00 #> pred[Attal2012: Thal] 32.09 3.64 25.61 29.58 31.82 34.32 40.13     3745     3106 1.01 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                           mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[McCarthy2012: Pbo]  33.38 2.24 29.20 31.82 33.31 34.82 37.97     3962     3084 1.00 #> pred[McCarthy2012: Len]  56.00 3.14 50.08 53.83 55.87 58.05 62.39     5489     3362 1.00 #> pred[McCarthy2012: Thal] 38.53 4.49 30.22 35.47 38.41 41.43 47.67     3274     3168 1.01 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Palumbo2014: Pbo]  21.13 2.30 17.08 19.48 21.01 22.62 26.03     5413     3337    1 #> pred[Palumbo2014: Len]  45.00 5.10 35.93 41.48 44.80 48.07 54.91     6004     3412    1 #> pred[Palumbo2014: Thal] 26.60 4.76 18.58 23.22 26.15 29.44 37.10     4761     3278    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Jackson2019: Pbo]  24.15 1.33 21.67 23.23 24.11 25.04 26.87     2566     3327 1.01 #> pred[Jackson2019: Len]  50.99 2.52 46.06 49.28 50.96 52.67 55.99       88     3022 1.03 #> pred[Jackson2019: Thal] 31.10 3.87 24.30 28.36 30.82 33.41 39.59     6238     3128 1.00 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                         mean    sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Morgan2012: Pbo]  20.73  1.91 17.26 19.39 20.62 21.96 24.76     2535     3344 1.01 #> pred[Morgan2012: Len]  49.95 70.67 37.84 44.01 47.84 52.12 64.21      770     3185 1.01 #> pred[Morgan2012: Thal] 27.34  2.43 22.93 25.65 27.22 28.89 32.42     5881     3470 1.00  plot(medsurv)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-conditional-log-hazard-ratios","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average conditional log hazard ratios","title":"Example: Newly diagnosed multiple myeloma","text":"Relative effects produced using relative_effects() function. ML-NMR model (IPD meta-regression), population-average conditional log hazard ratios (log survival time ratios AFT models).","code":"(loghr <- relative_effects(ndmm_fit_1kt, all_contrasts = TRUE)) #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  54.29        0.2             0.54 0.57 #>  #>                             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Attal2012: Len vs. Pbo]  -0.59 0.07 -0.74 -0.64 -0.59 -0.54 -0.45     6206     3113 1.00 #> d[Attal2012: Thal vs. Pbo] -0.12 0.13 -0.39 -0.21 -0.12 -0.03  0.14     4379     3188 1.01 #> d[Attal2012: Thal vs. Len]  0.47 0.12  0.23  0.39  0.47  0.55  0.70     1026     3072 1.01 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  57.66       0.23             0.67 0.54 #>  #>                                mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[McCarthy2012: Len vs. Pbo]  -0.62 0.06 -0.74 -0.66 -0.62 -0.58 -0.51     5733     3240 1.00 #> d[McCarthy2012: Thal vs. Pbo] -0.15 0.12 -0.39 -0.23 -0.15 -0.07  0.08     4199     2973 1.01 #> d[McCarthy2012: Thal vs. Len]  0.47 0.12  0.23  0.39  0.47  0.55  0.70     1026     3072 1.01 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  54.17       0.11              0.4 0.55 #>  #>                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Palumbo2014: Len vs. Pbo]  -0.64 0.08 -0.80 -0.69 -0.64 -0.58 -0.48     6475     3111 1.00 #> d[Palumbo2014: Thal vs. Pbo] -0.17 0.14 -0.45 -0.26 -0.17 -0.08  0.11     4947     3204 1.01 #> d[Palumbo2014: Thal vs. Len]  0.47 0.12  0.23  0.39  0.47  0.55  0.70     1026     3072 1.01 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  64.63       0.21             0.84 0.62 #>  #>                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Jackson2019: Len vs. Pbo]  -0.70 0.06 -0.82 -0.74 -0.70 -0.65 -0.57     4415     3352 1.01 #> d[Jackson2019: Thal vs. Pbo] -0.23 0.11 -0.45 -0.30 -0.23 -0.15 -0.02     5473     2863 1.00 #> d[Jackson2019: Thal vs. Len]  0.47 0.12  0.23  0.39  0.47  0.55  0.70     1026     3072 1.01 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  64.46       0.33             0.73 0.62 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Morgan2012: Len vs. Pbo]  -0.69 0.06 -0.82 -0.74 -0.70 -0.65 -0.57     4724     3265 1.01 #> d[Morgan2012: Thal vs. Pbo] -0.22 0.10 -0.44 -0.29 -0.22 -0.15 -0.02     5072     2969 1.00 #> d[Morgan2012: Thal vs. Len]  0.47 0.12  0.23  0.39  0.47  0.55  0.70     1026     3072 1.01  plot(loghr)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-arm-based-data","dir":"Articles","previous_headings":"","what":"Analysis of arm-based data","title":"Example: Parkinson's disease","text":"begin analysis arm-based data - means standard errors.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"arm-level continuous data giving mean -time reduction (y) standard error (se) arm. use function set_agd_arm() set network. let treatment 4 set default network reference treatment, since results considerably improved sampling efficiency choosing treatment 1 network reference. sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"arm_net <- set_agd_arm(parkinsons,                        study = studyn,                       trt = trtn,                       y = y,                        se = se,                       sample_size = n) arm_net #> A network with 7 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(arm_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. arm_fit_FE <- nma(arm_net,                    trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10)) #> Note: Setting \"4\" as the network reference treatment. arm_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>       mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat #> d[1]  0.54    0.01 0.48  -0.40  0.21  0.54  0.86  1.50  1400    1 #> d[2] -1.28    0.01 0.53  -2.28 -1.65 -1.27 -0.92 -0.25  1525    1 #> d[3]  0.05    0.01 0.33  -0.61 -0.17  0.05  0.28  0.69  1930    1 #> d[5] -0.30    0.00 0.21  -0.73 -0.44 -0.30 -0.16  0.09  2683    1 #> lp__ -6.73    0.06 2.43 -12.38 -8.12 -6.36 -4.98 -3.12  1570    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:45:12 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(arm_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(arm_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. arm_fit_RE <- nma(arm_net,                    seed = 379394727,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = half_normal(scale = 5),                   adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. #> Warning: There were 3 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems pairs(arm_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\")) arm_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75% 97.5% n_eff Rhat #> d[1]   0.51    0.02 0.63  -0.67   0.11   0.52   0.91  1.70  1684    1 #> d[2]  -1.33    0.02 0.69  -2.72  -1.75  -1.30  -0.89 -0.07  1690    1 #> d[3]   0.02    0.01 0.45  -0.89  -0.25   0.03   0.28  0.88  2148    1 #> d[5]  -0.30    0.01 0.44  -1.21  -0.50  -0.29  -0.09  0.56  1346    1 #> lp__ -12.81    0.10 3.59 -20.80 -15.10 -12.52 -10.20 -6.61  1234    1 #> tau    0.38    0.01 0.37   0.01   0.13   0.27   0.51  1.41   877    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:45:23 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(arm_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(arm_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(arm_dic_FE <- dic(arm_fit_FE)) #> Residual deviance: 13.4 (on 15 data points) #>                pD: 11.1 #>               DIC: 24.6 (arm_dic_RE <- dic(arm_fit_RE)) #> Residual deviance: 13.6 (on 15 data points) #>                pD: 12.4 #>               DIC: 26.1 plot(arm_dic_FE) plot(arm_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean \\(-0.73\\) precision \\(21\\). use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify trt_ref = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted, predictions mean -time reduction produced every study network based estimated baseline response \\(\\mu_j\\):  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(arm_releff_FE <- relative_effects(arm_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.54 0.48 -1.50 -0.86 -0.54 -0.21  0.40     1416     1936    1 #> d[2] -1.82 0.33 -2.48 -2.04 -1.82 -1.60 -1.15     5879     2894    1 #> d[3] -0.49 0.49 -1.44 -0.81 -0.49 -0.17  0.47     2074     2425    1 #> d[5] -0.84 0.53 -1.85 -1.20 -0.85 -0.49  0.18     1574     2462    1 plot(arm_releff_FE, ref_line = 0) (arm_releff_RE <- relative_effects(arm_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.51 0.63 -1.70 -0.91 -0.52 -0.11  0.67     1804     1484    1 #> d[2] -1.84 0.51 -2.86 -2.12 -1.83 -1.54 -0.86     3748     2408    1 #> d[3] -0.49 0.66 -1.80 -0.90 -0.48 -0.08  0.74     2657     1956    1 #> d[5] -0.81 0.78 -2.36 -1.25 -0.82 -0.36  0.66     1737     1588    1 plot(arm_releff_RE, ref_line = 0) arm_pred_FE <- predict(arm_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) arm_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.27 0.53 -2.33 -1.62 -1.27 -0.91 -0.21     1636     2297    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.58 -0.29     3910     3936    1 #> pred[2] -2.55 0.40 -3.32 -2.82 -2.54 -2.28 -1.79     5087     3341    1 #> pred[3] -1.22 0.54 -2.27 -1.57 -1.22 -0.85 -0.18     2382     2516    1 #> pred[5] -1.57 0.57 -2.67 -1.95 -1.57 -1.18 -0.44     1741     2657    1 plot(arm_pred_FE) arm_pred_RE <- predict(arm_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) arm_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.24 0.67 -2.51 -1.66 -1.25 -0.81  0.04     1938     1999    1 #> pred[1] -0.73 0.22 -1.16 -0.87 -0.73 -0.58 -0.30     3976     3867    1 #> pred[2] -2.56 0.56 -3.69 -2.90 -2.56 -2.23 -1.50     3593     2853    1 #> pred[3] -1.22 0.70 -2.63 -1.66 -1.22 -0.78  0.09     2838     2008    1 #> pred[5] -1.54 0.82 -3.11 -2.03 -1.55 -1.05 -0.02     1807     1581    1 plot(arm_pred_RE) arm_pred_FE_studies <- predict(arm_fit_FE, type = \"response\") arm_pred_FE_studies #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[1: 4] -1.65 0.46 -2.57 -1.97 -1.65 -1.34 -0.76     1967     2359    1 #> pred[1: 1] -1.12 0.43 -1.96 -1.41 -1.12 -0.82 -0.29     3358     3179    1 #> pred[1: 2] -2.93 0.52 -3.98 -3.28 -2.93 -2.58 -1.94     3558     3007    1 #> pred[1: 3] -1.60 0.39 -2.36 -1.87 -1.60 -1.35 -0.85     3563     3476    1 #> pred[1: 5] -1.95 0.50 -2.95 -2.30 -1.95 -1.61 -0.97     2112     2518    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[2: 4] -1.18 0.52 -2.19 -1.51 -1.18 -0.83 -0.19     1403     2042    1 #> pred[2: 1] -0.64 0.26 -1.16 -0.82 -0.64 -0.46 -0.11     5099     3542    1 #> pred[2: 2] -2.45 0.24 -2.93 -2.62 -2.45 -2.29 -1.99     4938     3308    1 #> pred[2: 3] -1.13 0.53 -2.19 -1.48 -1.13 -0.76 -0.10     2020     2243    1 #> pred[2: 5] -1.48 0.56 -2.56 -1.85 -1.48 -1.10 -0.38     1549     2294    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[3: 4] -1.12 0.43 -1.96 -1.40 -1.13 -0.84 -0.30     1896     2287    1 #> pred[3: 1] -0.59 0.36 -1.30 -0.83 -0.58 -0.34  0.10     4295     2625    1 #> pred[3: 2] -2.40 0.39 -3.18 -2.66 -2.41 -2.14 -1.66     4336     2898    1 #> pred[3: 3] -1.07 0.48 -2.00 -1.39 -1.08 -0.75 -0.14     2678     2607    1 #> pred[3: 5] -1.42 0.48 -2.36 -1.74 -1.42 -1.12 -0.49     2069     2750    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4: 4] -0.40 0.30 -0.97 -0.61 -0.40 -0.20  0.18     2383     2650    1 #> pred[4: 1]  0.14 0.51 -0.84 -0.20  0.13  0.48  1.12     1909     2492    1 #> pred[4: 2] -1.68 0.56 -2.78 -2.05 -1.68 -1.31 -0.59     2009     2493    1 #> pred[4: 3] -0.35 0.24 -0.83 -0.51 -0.35 -0.18  0.11     5241     3305    1 #> pred[4: 5] -0.70 0.37 -1.43 -0.94 -0.71 -0.45  0.01     2615     2737    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[5: 4] -0.57 0.35 -1.25 -0.80 -0.56 -0.33  0.12     2455     2826    1 #> pred[5: 1] -0.03 0.53 -1.05 -0.38 -0.04  0.33  1.04     2141     2659    1 #> pred[5: 2] -1.84 0.58 -2.95 -2.24 -1.85 -1.45 -0.70     2219     2457    1 #> pred[5: 3] -0.52 0.30 -1.11 -0.71 -0.52 -0.32  0.09     5196     3264    1 #> pred[5: 5] -0.87 0.41 -1.68 -1.14 -0.86 -0.59 -0.09     2708     3075    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[6: 4] -2.20 0.18 -2.54 -2.32 -2.20 -2.08 -1.85     2978     3062    1 #> pred[6: 1] -1.66 0.52 -2.66 -2.01 -1.66 -1.31 -0.66     1536     2365    1 #> pred[6: 2] -3.48 0.56 -4.55 -3.86 -3.47 -3.09 -2.43     1652     2716    1 #> pred[6: 3] -2.15 0.37 -2.89 -2.40 -2.15 -1.90 -1.43     2192     2486    1 #> pred[6: 5] -2.50 0.17 -2.84 -2.62 -2.50 -2.38 -2.17     5107     2797    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[7: 4] -1.80 0.18 -2.15 -1.92 -1.80 -1.68 -1.46     3338     2985    1 #> pred[7: 1] -1.26 0.51 -2.25 -1.60 -1.26 -0.92 -0.25     1542     2379    1 #> pred[7: 2] -3.08 0.55 -4.14 -3.46 -3.07 -2.69 -2.03     1657     2473    1 #> pred[7: 3] -1.75 0.37 -2.47 -2.00 -1.75 -1.49 -1.02     2156     2604    1 #> pred[7: 5] -2.10 0.20 -2.49 -2.23 -2.10 -1.96 -1.71     4689     3469    1 plot(arm_pred_FE_studies) (arm_ranks <- posterior_ranks(arm_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.49 0.70    2   3   3   4     5     2073       NA    1 #> rank[1] 4.65 0.76    2   5   5   5     5     2172       NA    1 #> rank[2] 1.05 0.28    1   1   1   1     2     2948     3006    1 #> rank[3] 3.53 0.92    2   3   4   4     5     2867       NA    1 #> rank[5] 2.27 0.66    1   2   2   2     4     2558     2626    1 plot(arm_ranks) (arm_rankprobs <- posterior_rank_probs(arm_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.51      0.37      0.08 #> d[1]      0.00      0.04      0.06      0.12      0.79 #> d[2]      0.96      0.04      0.01      0.00      0.00 #> d[3]      0.00      0.16      0.25      0.46      0.12 #> d[5]      0.04      0.72      0.18      0.05      0.01 plot(arm_rankprobs) (arm_cumrankprobs <- posterior_rank_probs(arm_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.55      0.92         1 #> d[1]      0.00      0.04      0.10      0.21         1 #> d[2]      0.96      0.99      1.00      1.00         1 #> d[3]      0.00      0.17      0.42      0.88         1 #> d[5]      0.04      0.76      0.94      0.99         1 plot(arm_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-contrast-based-data","dir":"Articles","previous_headings":"","what":"Analysis of contrast-based data","title":"Example: Parkinson's disease","text":"now perform analysis using contrast-based data (mean differences standard errors).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"contrast-level data giving mean difference -time reduction (diff) standard error (se_diff), use function set_agd_contrast() set network. sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"contr_net <- set_agd_contrast(parkinsons,                                study = studyn,                               trt = trtn,                               y = diff,                                se = se_diff,                               sample_size = n) contr_net #> A network with 7 AgD studies (contrast-based). #>  #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(contr_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. contr_fit_FE <- nma(contr_net,                      trt_effects = \"fixed\",                     prior_trt = normal(scale = 100)) #> Note: Setting \"4\" as the network reference treatment. contr_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>       mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat #> d[1]  0.54    0.01 0.48 -0.40  0.21  0.54  0.85  1.48  2216    1 #> d[2] -1.27    0.01 0.52 -2.30 -1.61 -1.27 -0.93 -0.25  2325    1 #> d[3]  0.07    0.01 0.33 -0.58 -0.16  0.06  0.29  0.74  3070    1 #> d[5] -0.30    0.00 0.21 -0.71 -0.44 -0.30 -0.16  0.12  3359    1 #> lp__ -3.16    0.03 1.46 -6.87 -3.86 -2.82 -2.09 -1.38  1762    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:45:42 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). plot_prior_posterior(contr_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. contr_fit_RE <- nma(contr_net,                      seed = 1150676438,                     trt_effects = \"random\",                     prior_trt = normal(scale = 100),                     prior_het = half_normal(scale = 5),                     adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. #> Warning: There were 1 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems pairs(contr_fit_RE, pars = c(\"d[3]\", \"delta[4: 4 vs. 3]\", \"tau\")) contr_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>       mean se_mean   sd   2.5%    25%   50%   75% 97.5% n_eff Rhat #> d[1]  0.51    0.01 0.61  -0.69   0.13  0.50  0.89  1.71  2022    1 #> d[2] -1.33    0.01 0.68  -2.74  -1.74 -1.34 -0.90 -0.04  2369    1 #> d[3]  0.04    0.01 0.45  -0.86  -0.24  0.04  0.31  0.90  2730    1 #> d[5] -0.31    0.01 0.39  -1.09  -0.51 -0.31 -0.10  0.51  1861    1 #> lp__ -8.38    0.08 2.83 -14.87 -10.07 -8.13 -6.32 -3.71  1338    1 #> tau   0.37    0.01 0.38   0.01   0.12  0.27  0.50  1.29   982    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:45:48 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(contr_fit_RE, pars = c(\"d\", \"delta\")) plot_prior_posterior(contr_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(contr_dic_FE <- dic(contr_fit_FE)) #> Residual deviance: 6.3 (on 8 data points) #>                pD: 4 #>               DIC: 10.4 (contr_dic_RE <- dic(contr_fit_RE)) #> Residual deviance: 6.7 (on 8 data points) #>                pD: 5.5 #>               DIC: 12.1 plot(contr_dic_FE) plot(contr_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean \\(-0.73\\) precision \\(21\\). use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify trt_ref = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted error raised, study baselines estimated network. can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(contr_releff_FE <- relative_effects(contr_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.54 0.48 -1.48 -0.85 -0.54 -0.21  0.40     2233     2368    1 #> d[2] -1.80 0.33 -2.45 -2.03 -1.80 -1.59 -1.16     5522     3140    1 #> d[3] -0.47 0.47 -1.42 -0.78 -0.47 -0.16  0.45     3080     3086    1 #> d[5] -0.84 0.52 -1.88 -1.18 -0.84 -0.49  0.17     2381     2347    1 plot(contr_releff_FE, ref_line = 0) (contr_releff_RE <- relative_effects(contr_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.51 0.61 -1.71 -0.89 -0.50 -0.13  0.69     2200     1943    1 #> d[2] -1.84 0.49 -2.81 -2.12 -1.83 -1.55 -0.90     3668     2552    1 #> d[3] -0.47 0.64 -1.73 -0.86 -0.48 -0.08  0.80     3062     2332    1 #> d[5] -0.82 0.74 -2.25 -1.27 -0.82 -0.38  0.63     1967     1595    1 plot(contr_releff_RE, ref_line = 0) contr_pred_FE <- predict(contr_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) contr_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.27 0.52 -2.31 -1.61 -1.27 -0.92 -0.24     2393     2512    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.58 -0.30     3988     3629    1 #> pred[2] -2.53 0.39 -3.33 -2.80 -2.53 -2.27 -1.77     4851     3791    1 #> pred[3] -1.20 0.52 -2.23 -1.56 -1.20 -0.84 -0.18     3333     3328    1 #> pred[5] -1.57 0.56 -2.69 -1.94 -1.57 -1.19 -0.51     2506     2533    1 plot(contr_pred_FE) contr_pred_RE <- predict(contr_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) contr_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.24 0.65 -2.49 -1.65 -1.23 -0.85  0.06     2175     1866    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.59 -0.31     3715     3592    1 #> pred[2] -2.57 0.54 -3.67 -2.89 -2.57 -2.24 -1.52     3848     2953    1 #> pred[3] -1.21 0.68 -2.48 -1.63 -1.21 -0.79  0.10     2974     2324    1 #> pred[5] -1.55 0.77 -3.00 -2.03 -1.55 -1.08 -0.05     1929     1677    1 plot(contr_pred_RE) # Not run predict(contr_fit_FE, type = \"response\") (contr_ranks <- posterior_ranks(contr_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.47 0.72    2   3   3   4     5     2606       NA    1 #> rank[1] 4.65 0.75    2   5   5   5     5     2701       NA    1 #> rank[2] 1.06 0.30    1   1   1   1     2     2204     2244    1 #> rank[3] 3.55 0.91    2   3   4   4     5     3781       NA    1 #> rank[5] 2.27 0.66    1   2   2   2     4     2718     2809    1 plot(contr_ranks) (contr_rankprobs <- posterior_rank_probs(contr_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.05      0.51      0.36      0.08 #> d[1]      0.00      0.04      0.06      0.12      0.79 #> d[2]      0.96      0.03      0.01      0.00      0.00 #> d[3]      0.00      0.16      0.25      0.47      0.12 #> d[5]      0.04      0.72      0.17      0.06      0.01 plot(contr_rankprobs) (contr_cumrankprobs <- posterior_rank_probs(contr_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.05      0.56      0.92         1 #> d[1]      0.00      0.04      0.10      0.21         1 #> d[2]      0.96      0.99      1.00      1.00         1 #> d[3]      0.00      0.16      0.41      0.88         1 #> d[5]      0.04      0.76      0.94      0.99         1 plot(contr_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-mixed-arm-based-and-contrast-based-data","dir":"Articles","previous_headings":"","what":"Analysis of mixed arm-based and contrast-based data","title":"Example: Parkinson's disease","text":"now perform analysis studies contribute arm-based data, contribute contrast-based data. Replicating Dias et al. (2011), consider arm-based data studies 1-3, contrast-based data studies 4-7.","code":"studies <- parkinsons$studyn (parkinsons_arm <- parkinsons[studies %in% 1:3, ]) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718 #> 7      3    4 -1.20 0.478  81 -0.90   0.695 (parkinsons_contr <- parkinsons[studies %in% 4:7, ]) #>    studyn trtn     y    se   n  diff se_diff #> 8       4    3 -0.24 0.265 128    NA   0.265 #> 9       4    4 -0.59 0.354  72 -0.35   0.442 #> 10      5    3 -0.73 0.335  80    NA   0.335 #> 11      5    4 -0.18 0.442  46  0.55   0.555 #> 12      6    4 -2.20 0.197 137    NA   0.197 #> 13      6    5 -2.50 0.190 131 -0.30   0.274 #> 14      7    4 -1.80 0.200 154    NA   0.200 #> 15      7    5 -2.10 0.250 143 -0.30   0.320"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"use functions set_agd_arm() set_agd_contrast() set respective data sources within network, combine together combine_network(). sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"mix_arm_net <- set_agd_arm(parkinsons_arm,                             study = studyn,                            trt = trtn,                            y = y,                             se = se,                            sample_size = n)  mix_contr_net <- set_agd_contrast(parkinsons_contr,                                    study = studyn,                                   trt = trtn,                                   y = diff,                                    se = se_diff,                                   sample_size = n)  mix_net <- combine_network(mix_arm_net, mix_contr_net) mix_net #> A network with 3 AgD studies (arm-based), and 4 AgD studies (contrast-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  #>  Outcome type: continuous #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(mix_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. mix_fit_FE <- nma(mix_net,                    trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100)) #> Note: Setting \"4\" as the network reference treatment. mix_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>       mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat #> d[1]  0.52    0.01 0.47 -0.40  0.20  0.52  0.84  1.43  1517    1 #> d[2] -1.29    0.01 0.51 -2.32 -1.62 -1.29 -0.96 -0.29  1641    1 #> d[3]  0.05    0.01 0.32 -0.58 -0.16  0.04  0.26  0.67  2753    1 #> d[5] -0.30    0.00 0.20 -0.71 -0.44 -0.30 -0.16  0.10  2836    1 #> lp__ -4.61    0.04 1.87 -9.22 -5.57 -4.28 -3.26 -2.00  1833    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:46:02 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(mix_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(mix_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. mix_fit_RE <- nma(mix_net,                    seed = 437219664,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = half_normal(scale = 5),                   adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. #> Warning: There were 2 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: There were 3 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See #> https://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded #> Warning: Examine the pairs() plot to diagnose sampling problems pairs(mix_fit_RE, pars = c(\"d[3]\", \"delta[4: 4 vs. 3]\", \"tau\")) mix_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%   75% 97.5% n_eff Rhat #> d[1]   0.51    0.02 0.66  -0.86   0.15   0.52  0.89  1.74  1629 1.00 #> d[2]  -1.34    0.02 0.75  -2.90  -1.75  -1.32 -0.91  0.04  1537 1.00 #> d[3]   0.02    0.01 0.54  -1.05  -0.26   0.02  0.32  0.99  2249 1.00 #> d[5]  -0.30    0.01 0.43  -1.21  -0.51  -0.30 -0.09  0.61  2295 1.00 #> lp__ -10.72    0.08 3.23 -17.78 -12.71 -10.44 -8.45 -5.15  1444 1.00 #> tau    0.42    0.02 0.46   0.01   0.13   0.28  0.54  1.67   533 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:46:13 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(mix_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(mix_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(mix_dic_FE <- dic(mix_fit_FE)) #> Residual deviance: 9.2 (on 11 data points) #>                pD: 6.9 #>               DIC: 16.2 (mix_dic_RE <- dic(mix_fit_RE)) #> Residual deviance: 9.6 (on 11 data points) #>                pD: 8.5 #>               DIC: 18.1 plot(mix_dic_FE) plot(mix_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean \\(-0.73\\) precision \\(21\\). use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify trt_ref = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted, predictions mean -time reduction produced every arm-based study network based estimated baseline response \\(\\mu_j\\):  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(mix_releff_FE <- relative_effects(mix_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.52 0.47 -1.43 -0.84 -0.52 -0.20  0.40     1542     2165    1 #> d[2] -1.81 0.33 -2.47 -2.03 -1.81 -1.59 -1.17     6740     3205    1 #> d[3] -0.47 0.49 -1.41 -0.81 -0.48 -0.14  0.48     2302     2692    1 #> d[5] -0.82 0.52 -1.81 -1.17 -0.82 -0.48  0.19     1755     2427    1 plot(mix_releff_FE, ref_line = 0) (mix_releff_RE <- relative_effects(mix_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.51 0.66 -1.74 -0.89 -0.52 -0.15  0.86     1814     1594    1 #> d[2] -1.85 0.58 -2.96 -2.13 -1.85 -1.56 -0.84     4001     2109    1 #> d[3] -0.50 0.69 -1.82 -0.89 -0.50 -0.12  0.89     2965     2206    1 #> d[5] -0.81 0.79 -2.32 -1.27 -0.82 -0.38  0.82     1866     1679    1 plot(mix_releff_RE, ref_line = 0) mix_pred_FE <- predict(mix_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) mix_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.24 0.52 -2.24 -1.61 -1.25 -0.89 -0.22     1674     2447    1 #> pred[1] -0.72 0.22 -1.14 -0.87 -0.72 -0.58 -0.29     3556     3638    1 #> pred[2] -2.53 0.39 -3.31 -2.80 -2.53 -2.27 -1.73     4609     3417    1 #> pred[3] -1.19 0.53 -2.21 -1.57 -1.20 -0.83 -0.15     2345     2871    1 #> pred[5] -1.54 0.56 -2.65 -1.92 -1.57 -1.15 -0.46     1866     2434    1 plot(mix_pred_FE) mix_pred_RE <- predict(mix_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) mix_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.24 0.69 -2.54 -1.66 -1.25 -0.85  0.17     1920     1707    1 #> pred[1] -0.73 0.22 -1.17 -0.88 -0.73 -0.58 -0.31     4051     3817    1 #> pred[2] -2.58 0.62 -3.75 -2.91 -2.57 -2.24 -1.52     3816     2164    1 #> pred[3] -1.22 0.73 -2.60 -1.65 -1.22 -0.82  0.18     3082     2578    1 #> pred[5] -1.54 0.82 -3.08 -2.03 -1.56 -1.07  0.09     1963     1709    1 plot(mix_pred_RE) mix_pred_FE_studies <- predict(mix_fit_FE, type = \"response\") mix_pred_FE_studies #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[1: 4] -1.64 0.45 -2.53 -1.95 -1.64 -1.34 -0.75     2293     2590    1 #> pred[1: 1] -1.12 0.43 -1.98 -1.41 -1.12 -0.84 -0.27     3653     3131    1 #> pred[1: 2] -2.93 0.52 -3.94 -3.29 -2.93 -2.58 -1.91     3566     2944    1 #> pred[1: 3] -1.60 0.40 -2.38 -1.87 -1.59 -1.34 -0.81     3534     2565    1 #> pred[1: 5] -1.94 0.49 -2.91 -2.27 -1.95 -1.61 -0.96     2424     2445    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[2: 4] -1.16 0.50 -2.13 -1.50 -1.17 -0.83 -0.15     1495     2084    1 #> pred[2: 1] -0.64 0.26 -1.14 -0.82 -0.64 -0.47 -0.11     5710     3476    1 #> pred[2: 2] -2.45 0.24 -2.91 -2.61 -2.45 -2.29 -1.97     5095     3528    1 #> pred[2: 3] -1.11 0.53 -2.13 -1.47 -1.12 -0.76 -0.08     2107     2349    1 #> pred[2: 5] -1.46 0.54 -2.53 -1.83 -1.46 -1.09 -0.39     1693     2292    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[3: 4] -1.11 0.41 -1.89 -1.38 -1.12 -0.85 -0.27     1920     2608    1 #> pred[3: 1] -0.59 0.37 -1.32 -0.84 -0.58 -0.34  0.11     4354     3105    1 #> pred[3: 2] -2.40 0.38 -3.16 -2.65 -2.41 -2.15 -1.63     4350     3240    1 #> pred[3: 3] -1.07 0.47 -1.98 -1.38 -1.07 -0.75 -0.15     2796     2796    1 #> pred[3: 5] -1.41 0.46 -2.29 -1.72 -1.42 -1.11 -0.50     2130     2646    1 plot(mix_pred_FE_studies) (mix_ranks <- posterior_ranks(mix_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.50 0.71    2   3   3   4     5     2062       NA    1 #> rank[1] 4.63 0.78    2   5   5   5     5     1963       NA    1 #> rank[2] 1.05 0.26    1   1   1   1     2     2608     2767    1 #> rank[3] 3.54 0.92    2   3   4   4     5     3151       NA    1 #> rank[5] 2.28 0.66    1   2   2   2     4     2615     2603    1 plot(mix_ranks) (mix_rankprobs <- posterior_rank_probs(mix_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.49      0.38      0.08 #> d[1]      0.00      0.04      0.06      0.12      0.78 #> d[2]      0.96      0.03      0.01      0.00      0.00 #> d[3]      0.00      0.16      0.25      0.45      0.13 #> d[5]      0.04      0.72      0.19      0.05      0.01 plot(mix_rankprobs) (mix_cumrankprobs <- posterior_rank_probs(mix_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.54      0.92         1 #> d[1]      0.00      0.04      0.10      0.22         1 #> d[2]      0.96      0.99      1.00      1.00         1 #> d[3]      0.00      0.17      0.42      0.87         1 #> d[5]      0.04      0.75      0.94      0.99         1 plot(mix_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"initial_analysis","dir":"Articles","previous_headings":"","what":"Initial analysis","title":"Example: Plaque psoriasis ML-NMR","text":"start recreating analysis presented Phillippo et al. (2020). analyse IPD three studies, UNCOVER-1, UNCOVER-2, UNCOVER-3 (Griffiths et al. 2015; Gordon et al. 2016), AgD one study, FIXTURE (Langley et al. 2014). consider running ML-NMR adjusting five potential effect-modifying covariates: duration psoriasis durnpso, weight weight, previous systemic treatment prevsys, body surface area bsa, psoriatic arthritis psa.","code":"pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0  male bsa #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2  TRUE  18 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4  TRUE  33 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8  TRUE  33 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 FALSE  50 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 FALSE  35 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2  TRUE  29 #>   weight durnpso prevsys   psa #> 1   98.1     6.7    TRUE  TRUE #> 2  129.6    14.5   FALSE  TRUE #> 3   78.0    26.5    TRUE FALSE #> 4  139.9    25.0    TRUE  TRUE #> 5   54.2    11.9    TRUE FALSE #> 6   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n pasi100_r #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323        14 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324         0 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327        47 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323        78 #>   pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd pasi_w0_mean pasi_w0_sd male #> 1       323            326     43.8   13.0     28.7    5.9         23.2        9.8 71.2 #> 2       324            326     44.1   12.6     27.9    6.1         24.1       10.5 72.7 #> 3       327            327     45.4   12.9     28.4    5.9         23.7       10.5 72.2 #> 4       323            327     44.5   13.2     28.4    6.4         23.9        9.9 68.5 #>   bsa_mean bsa_sd weight_mean weight_sd durnpso_mean durnpso_sd prevsys  psa #> 1     33.6   18.0        84.6      20.5         16.4       12.0    65.6 13.5 #> 2     35.2   19.1        82.0      20.4         16.6       11.6    62.6 15.0 #> 3     34.5   19.4        83.6      20.8         17.3       12.2    64.8 15.0 #> 4     34.3   19.2        83.0      21.6         15.8       12.3    63.0 15.3"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"preparing-the-data","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Preparing the data","title":"Example: Plaque psoriasis ML-NMR","text":"need prepare data acceptable format run ML-NMR model. Firstly, need handle binary covariates prevsys psa. IPD, coded TRUE FALSE, AgD coded percentages (100). need transform sets variables numeric lie interval \\([0,1]\\), variables compatible across data sources. Whilst , also transform body surface area bsa (percentage) lie \\([0,1]\\), since make specifying appropriate marginal distribution easier later, rescale weight duration aid interpretation regression coefficients (terms 10 kilos 10 years respectively). also add trtclass variable, indicating treatments belong classes. Finally, check missing values IPD. small number individuals missing covariates: Since proportion missing data small, simply exclude individuals analysis.","code":"pso_ipd <- pso_ipd %>%    mutate(# Variable transformations          bsa = bsa / 100,          prevsys = as.numeric(prevsys),          psa = as.numeric(psa),          weight = weight / 10,          durnpso = durnpso / 10,          # Treatment classes          trtclass = case_when(trtn == 1 ~ \"Placebo\",                               trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                               trtn == 4 ~ \"TNFa blocker\"),          # Check complete cases for covariates of interest          complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%    mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                               trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                               trtn == 4 ~ \"TNFa blocker\")   ) sum(!pso_ipd$complete) #> [1] 4 mean(!pso_ipd$complete) #> [1] 0.001036807 pso_ipd <- filter(pso_ipd, complete)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"creating-the-network","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Creating the network","title":"Example: Plaque psoriasis ML-NMR","text":"Set network, setting IPD set_ipd(), AgD (arm-based) set_agd_arm(), combining together using combine_network(). specify binary pasi75 outcome r IPD, count outcome pasi75_r denominator pasi75_n r n AgD. specify treatment classes trt_class = trtclass. can produce network plot plot() method:","code":"pso_net <- combine_network(   set_ipd(pso_ipd,            study = studyc,            trt = trtc,            r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,                study = studyc,                trt = trtc,                r = pasi75_r,                n = pasi75_n,               trt_class = trtclass) )  pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE) +    ggplot2::theme(legend.position = \"bottom\", legend.box = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"numerical-integration-for-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Numerical integration for ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"ML-NMR models define meta-regression model individual level, exactly manner full-IPD meta-regression. ML-NMR incorporates AgD model integrating individual-level model covariate distribution AgD study (Phillippo et al. 2020; Phillippo 2019). Using integration, instead simply “plugging-” mean covariate values AgD studies, avoids aggregation bias link function identity function. package utilises numerical integration incorporate aggregate data - specifically, quasi-Monte Carlo (QMC) integration Gaussian copula (Phillippo et al. 2020; Phillippo 2019). QMC integration general flexible integration approach, typically requires far fewer integration points standard (pseudo-random) Monte-Carlo integration achieve numerical accuracy.1 Gaussian copula allows us account correlations covariates, may specified marginal distributions. now set numerical integration network. five covariates consider adjusting body surface area bsa, duration psoriasis durnpso, previous systemic treatment prevsys, psoriatic arthritis psa, weight weight. need choose suitable marginal distributions covariates draw integration points . prevsys psa binary covariates, given Bernoulli distribution. bsa percentage, choose logit-Normal distribution (note, requires logitnorm package installed). choose Gamma distributions durnpso weight account skewness. choices seem match well marginal distributions observed IPD:  add integration points AgD studies network using add_integration() function. Marginal distributions covariate specified using distr() function, takes cumulative distribution function corresponding chosen marginal distribution, arguments distribution column names aggregate data. Since know correlations covariates AgD studies, impute weighted mean correlations IPD studies (default option). Note: package provides several convenience functions specifying distributions, including qgamma() allows parameterisation Gamma distribution terms mean standard deviation, qbern() provides Bernoulli distribution, qlogitnorm() provides logit-Normal distribution allowing parameterisation terms mean standard deviation (requires logitnorm package installed).","code":"# Get mean and sd of covariates in each study ipd_summary <- pso_ipd %>%    group_by(studyc) %>%    summarise_at(vars(weight, durnpso, bsa), list(mean = mean, sd = sd, min = min, max = max)) %>%    pivot_longer(weight_mean:bsa_max, names_sep = \"_\", names_to = c(\"covariate\", \".value\")) %>%    # Assign distributions   mutate(dist = recode(covariate,                        bsa = \"dlogitnorm\",                        durnpso = \"dgamma\",                        weight = \"dgamma\")) %>%    # Compute density curves   group_by(studyc, covariate) %>%    mutate(value = if_else(dist == \"dlogitnorm\",                          list(seq(0, 1, length.out = 101)),                          list(seq(min*0.8, max*1.2, length.out = 101)))) %>%    unnest(cols = value) %>%    mutate(dens = eval(call(first(dist), x = value, mean = first(mean), sd = first(sd))))  # Plot histograms and assumed densities pso_ipd %>%    pivot_longer(c(weight, durnpso, bsa), names_to = \"covariate\", values_to = \"value\") %>%  ggplot(aes(x = value)) +   geom_histogram(aes(y = after_stat(density)),                   binwidth = function(x) diff(range(x)) / nclass.Sturges(x),                  boundary = 0,                  fill = \"grey50\") +   geom_line(aes(y = dens), data = ipd_summary,             colour = \"darkred\", linewidth = 0.5) +   facet_wrap(~studyc + covariate, scales = \"free\", ncol = 3) +   theme_multinma() pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64 ) #> Using weighted average correlation matrix computed from IPD studies."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"ml-nmr-models","dir":"Articles","previous_headings":"Initial analysis","what":"ML-NMR models","title":"Example: Plaque psoriasis ML-NMR","text":"fit fixed effect (FE) random effects (RE) ML-NMR models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"fixed-effect-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > ML-NMR models","what":"Fixed effect ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"First, fit FE ML-NMR model using function nma(). Following (Phillippo et al. 2020) specify weakly-informative \\(N(0, 10^2)\\) priors parameter. range parameter values implied prior distributions can checked using summary() method: regression model specified regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt, include main (prognostic) effects covariate well interactions treatment. use probit link function (link = \"probit\"), specify two-parameter Binomial approximation aggregate-level likelihood used (likelihood = \"bernoulli2\", “bernoulli” refers individual-level likelihood, “2” denotes two-parameter adjustment aggregate-level likelihood) (Phillippo et al. 2020). utilise shared effect modifier assumption help identify model, setting treatment-covariate interactions equal within class (class_interactions = \"common\"). narrow possible range random initial values init_r = 0.1 (default init_r = 2), since probit models particular often hard initialise. Using QR decomposition (QR = TRUE) greatly improves sampling efficiency , often case regression models. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  now recommend assessing sufficient accuracy numerical integration running half chains n_int / 2 integration points half full n_int. Rhat n_eff diagnostic warnings can either attributed insufficient MCMC iterations (argument iter nma()) insufficient integration points (n_int add_integration()), depending whether occur within two groups chains chains combined. feature enabled default (int_check = TRUE). case, warnings content number iterations number integration points. (Phillippo et al. (2020) used alternative approach based saving cumulative integration points plotting empirical integration error, can achieved setting int_thin nma() using plot_integration_error() function.)","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                    likelihood = \"bernoulli2\",                   regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   init_r = 0.1,                   QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. print(pso_fit_FE) #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                           0.04    0.00 0.06    -0.08     0.00     0.04     0.08 #> beta[prevsys]                          -0.14    0.00 0.16    -0.45    -0.25    -0.14    -0.03 #> beta[bsa]                              -0.06    0.01 0.45    -1.01    -0.36    -0.06     0.25 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02     0.04     0.06 #> beta[psa]                              -0.08    0.00 0.17    -0.43    -0.20    -0.08     0.03 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08    -0.03     0.02 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.14    -0.06    -0.01     0.03 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.19    -0.19     0.07     0.20     0.31 #> beta[prevsys:.trtclassIL blocker]       0.07    0.00 0.18    -0.28    -0.05     0.07     0.18 #> beta[bsa:.trtclassTNFa blocker]         0.05    0.01 0.53    -0.97    -0.30     0.05     0.40 #> beta[bsa:.trtclassIL blocker]           0.29    0.01 0.50    -0.65    -0.06     0.28     0.63 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.19    -0.17    -0.14 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12    -0.10    -0.08 #> beta[psa:.trtclassTNFa blocker]        -0.05    0.00 0.21    -0.46    -0.19    -0.05     0.09 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.18    -0.34    -0.11     0.01     0.13 #> d[ETN]                                  1.55    0.00 0.08     1.40     1.50     1.55     1.61 #> d[IXE_Q2W]                              2.96    0.00 0.08     2.80     2.90     2.95     3.01 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.38     2.49     2.54     2.60 #> d[SEC_150]                              2.15    0.00 0.11     1.93     2.07     2.14     2.22 #> d[SEC_300]                              2.45    0.00 0.12     2.23     2.37     2.45     2.53 #> lp__                                -1576.50    0.10 3.61 -1584.50 -1578.78 -1576.09 -1573.88 #>                                        97.5% n_eff Rhat #> beta[durnpso]                           0.16  6407    1 #> beta[prevsys]                           0.18  5541    1 #> beta[bsa]                               0.80  6530    1 #> beta[weight]                            0.10  5565    1 #> beta[psa]                               0.23  5985    1 #> beta[durnpso:.trtclassTNFa blocker]     0.12  6842    1 #> beta[durnpso:.trtclassIL blocker]       0.12  7760    1 #> beta[prevsys:.trtclassTNFa blocker]     0.57  5749    1 #> beta[prevsys:.trtclassIL blocker]       0.42  6304    1 #> beta[bsa:.trtclassTNFa blocker]         1.11  6616    1 #> beta[bsa:.trtclassIL blocker]           1.27  8355    1 #> beta[weight:.trtclassTNFa blocker]     -0.10  6264    1 #> beta[weight:.trtclassIL blocker]       -0.04  6699    1 #> beta[psa:.trtclassTNFa blocker]         0.37  6311    1 #> beta[psa:.trtclassIL blocker]           0.38  8041    1 #> d[ETN]                                  1.71  4458    1 #> d[IXE_Q2W]                              3.12  5338    1 #> d[IXE_Q4W]                              2.70  5011    1 #> d[SEC_150]                              2.37  5388    1 #> d[SEC_300]                              2.68  5664    1 #> lp__                                -1570.59  1299    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:47:14 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_FE, pars = c(\"d\", \"beta\", \"mu\")) plot_prior_posterior(pso_fit_FE, prior = c(\"intercept\", \"trt\", \"reg\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"random-effects-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > ML-NMR models","what":"Random effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"now fit RE model. , specify weakly-informative \\(N(0, 10^2)\\) priors parameter, now specify \\(\\textrm{half-N}(0, 2.5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). range parameter values implied prior distributions can checked using summary() method: Fitting model uses call nma() , except now trt_effects = \"random\". Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: number divergent transitions, can investigate using pairs() method:  divergent transition errors (red crosses) seem concentrated upper tail heterogeneity standard deviation parameter. suggests information identify heterogeneity parameter weak - four studies network - informative prior distribution might aid estimation. prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(half_normal(scale = 2.5)) #> A half-Normal prior distribution: location = 0, scale = 2.5. #> 50% of the prior density lies between 0 and 1.69. #> 95% of the prior density lies between 0 and 4.9. pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                    likelihood = \"bernoulli2\",                   regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_het = half_normal(scale = 2.5),                   init_r = 0.1,                   QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. #> Warning: There were 10 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems print(pso_fit_RE) #> A random effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                           0.05    0.00 0.06    -0.07     0.01     0.05     0.09 #> beta[prevsys]                          -0.13    0.00 0.16    -0.43    -0.23    -0.13    -0.03 #> beta[bsa]                              -0.09    0.01 0.44    -0.98    -0.38    -0.09     0.22 #> beta[weight]                            0.04    0.00 0.03    -0.01     0.02     0.04     0.06 #> beta[psa]                              -0.06    0.00 0.17    -0.39    -0.17    -0.06     0.05 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08    -0.04     0.02 #> beta[durnpso:.trtclassIL blocker]      -0.02    0.00 0.07    -0.14    -0.06    -0.02     0.03 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.18    -0.18     0.07     0.19     0.31 #> beta[prevsys:.trtclassIL blocker]       0.06    0.00 0.17    -0.29    -0.06     0.06     0.17 #> beta[bsa:.trtclassTNFa blocker]         0.08    0.01 0.51    -0.89    -0.28     0.08     0.42 #> beta[bsa:.trtclassIL blocker]           0.32    0.01 0.49    -0.63     0.00     0.33     0.64 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.03    -0.24    -0.20    -0.17    -0.15 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12    -0.10    -0.08 #> beta[psa:.trtclassTNFa blocker]        -0.07    0.00 0.21    -0.48    -0.21    -0.07     0.06 #> beta[psa:.trtclassIL blocker]          -0.01    0.00 0.19    -0.38    -0.14    -0.01     0.11 #> d[ETN]                                  1.55    0.00 0.14     1.26     1.47     1.55     1.64 #> d[IXE_Q2W]                              2.97    0.00 0.15     2.67     2.88     2.97     3.06 #> d[IXE_Q4W]                              2.56    0.00 0.15     2.25     2.47     2.56     2.64 #> d[SEC_150]                              2.13    0.01 0.23     1.69     2.00     2.13     2.25 #> d[SEC_300]                              2.43    0.01 0.24     1.94     2.30     2.43     2.56 #> lp__                                -1580.31    0.15 4.77 -1590.43 -1583.31 -1579.98 -1576.92 #> tau                                     0.18    0.00 0.12     0.02     0.10     0.16     0.24 #>                                        97.5% n_eff Rhat #> beta[durnpso]                           0.16  5429    1 #> beta[prevsys]                           0.18  5210    1 #> beta[bsa]                               0.75  4673    1 #> beta[weight]                            0.10  4993    1 #> beta[psa]                               0.26  4337    1 #> beta[durnpso:.trtclassTNFa blocker]     0.11  5697    1 #> beta[durnpso:.trtclassIL blocker]       0.11  6264    1 #> beta[prevsys:.trtclassTNFa blocker]     0.56  5239    1 #> beta[prevsys:.trtclassIL blocker]       0.39  5552    1 #> beta[bsa:.trtclassTNFa blocker]         1.07  4864    1 #> beta[bsa:.trtclassIL blocker]           1.30  5147    1 #> beta[weight:.trtclassTNFa blocker]     -0.10  5362    1 #> beta[weight:.trtclassIL blocker]       -0.04  5790    1 #> beta[psa:.trtclassTNFa blocker]         0.33  4648    1 #> beta[psa:.trtclassIL blocker]           0.37  4690    1 #> d[ETN]                                  1.85  1802    1 #> d[IXE_Q2W]                              3.26  1674    1 #> d[IXE_Q4W]                              2.86  1768    1 #> d[SEC_150]                              2.58  1928    1 #> d[SEC_300]                              2.93  1732    1 #> lp__                                -1572.09  1045    1 #> tau                                     0.48   646    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:52:04 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_RE, pars = c(\"d\", \"beta\", \"tau\", \"mu\", \"delta\")) pairs(pso_fit_RE, pars = c(\"delta[UNCOVER-2: ETN]\", \"d[ETN]\", \"tau\", \"lp__\")) plot_prior_posterior(pso_fit_RE, prior = c(\"intercept\", \"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"model-comparison","dir":"Articles","previous_headings":"Initial analysis","what":"Model comparison","title":"Example: Plaque psoriasis ML-NMR","text":"model fit FE RE models can checked using dic() function. DIC similar FE RE models, suggesting little evidence residual heterogeneity.","code":"(pso_dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 3129.8 (on 3858 data points) #>                pD: 24.5 #>               DIC: 3154.3 (pso_dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 3123.5 (on 3858 data points) #>                pD: 27.9 #>               DIC: 3151.4"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"producing-relative-effects-and-event-probabilities","dir":"Articles","previous_headings":"Initial analysis","what":"Producing relative effects and event probabilities","title":"Example: Plaque psoriasis ML-NMR","text":"Parameter estimates can plotted using plot() method, example examine estimated regression coefficients:  Plots posterior summaries based ggdist package, allows great degree flexibility, can customised using ggplot2 commands. command specify \"halfeye\" plot, shows posterior density along posterior medians (points) 95% Credible Intervals (thin line) 66% inner bands (thicker line) default. details plotting options see ?plot.nma_summary. can produce population-adjusted relative effects study population network using relative_effects() function.  Predicted probabilities achieving PASI 75 study population treatment produced using predict() method. argument type = \"reponse\" specifies want predicted probabilities, rather probit probabilities.  can produce population-adjusted ranks, rank probabilities, cumulative rank probabilities study population using posterior_ranks() posterior_rank_probs() functions (although ranks unchanged populations, distributions effect modifiers similar). specify lower_better = FALSE, since higher outcome better (higher chance achieving PASI 75).    estimates (relative effects, predictions, rankings) can also produced specific target population populations providing suitable newdata argument function (baseline distribution predict()). produce population-adjusted relative effects (corresponding rankings) chosen target population, require mean covariate values population. example, newdata provide following mean covariate values: Population-adjusted relative effects target population calculated using relative_effects() function, can plotted corresponding plot() method:  absolute predictions, require information full covariate distribution target population, just mean values. IPD available target population, newdata simply data frame IPD. AgD available target population, newdata must data frame added integration points created using add_integration() function. example, suppose aggregate target population introduced following covariate means standard deviations (continuous covariates) proportions (discrete covariates): add integration points data frame similar manner . , need supply correlation matrix joint covariate distribution; use weighted mean correlation matrix computed earlier IPD network, stored network object int_cor. Predicted probabilities achieving PASI 75 target population, given \\(N(-1.75, 0.08^2)\\) distribution baseline probit-probability response Placebo (reference levels covariates), produced using predict() method:","code":"plot(pso_fit_FE,      pars = \"beta\",      stat = \"halfeye\",      ref_line = 0) (pso_releff_FE <- relative_effects(pso_fit_FE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[FIXTURE: ETN]     1.66 0.09 1.49 1.60 1.66 1.72  1.84     4676     3373    1 #> d[FIXTURE: IXE_Q2W] 3.03 0.10 2.84 2.96 3.03 3.10  3.22     5927     3418    1 #> d[FIXTURE: IXE_Q4W] 2.62 0.09 2.43 2.56 2.62 2.68  2.80     5436     3275    1 #> d[FIXTURE: SEC_150] 2.22 0.12 2.00 2.14 2.22 2.29  2.46     5219     3082    1 #> d[FIXTURE: SEC_300] 2.52 0.12 2.29 2.44 2.52 2.60  2.76     5412     3731    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-1: ETN]     1.51 0.08 1.35 1.45 1.51 1.57  1.68     4601     3301    1 #> d[UNCOVER-1: IXE_Q2W] 2.93 0.09 2.77 2.87 2.93 2.98  3.10     5292     3000    1 #> d[UNCOVER-1: IXE_Q4W] 2.51 0.08 2.36 2.46 2.51 2.57  2.68     4831     3172    1 #> d[UNCOVER-1: SEC_150] 2.12 0.12 1.89 2.04 2.11 2.19  2.35     5439     3497    1 #> d[UNCOVER-1: SEC_300] 2.42 0.12 2.19 2.33 2.42 2.51  2.67     5669     3652    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-2: ETN]     1.51 0.08 1.35 1.46 1.51 1.56  1.67     4675     3334    1 #> d[UNCOVER-2: IXE_Q2W] 2.93 0.08 2.77 2.87 2.92 2.98  3.10     5411     3293    1 #> d[UNCOVER-2: IXE_Q4W] 2.51 0.08 2.36 2.46 2.51 2.57  2.67     5032     3449    1 #> d[UNCOVER-2: SEC_150] 2.12 0.12 1.89 2.04 2.11 2.19  2.35     5615     3313    1 #> d[UNCOVER-2: SEC_300] 2.42 0.12 2.19 2.33 2.42 2.50  2.66     5753     3802    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-3: ETN]     1.53 0.08 1.38 1.48 1.53 1.58  1.69     4636     3601    1 #> d[UNCOVER-3: IXE_Q2W] 2.94 0.08 2.78 2.89 2.94 3.00  3.11     5604     3501    1 #> d[UNCOVER-3: IXE_Q4W] 2.53 0.08 2.37 2.48 2.53 2.58  2.69     5330     3431    1 #> d[UNCOVER-3: SEC_150] 2.13 0.11 1.92 2.06 2.13 2.21  2.36     5359     3437    1 #> d[UNCOVER-3: SEC_300] 2.44 0.12 2.21 2.35 2.44 2.52  2.67     5724     3798    1 plot(pso_releff_FE, ref_line = 0) (pso_pred_FE <- predict(pso_fit_FE, type = \"response\")) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[FIXTURE: PBO]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     4467     3589    1 #> pred[FIXTURE: ETN]     0.46 0.03 0.41 0.44 0.46 0.47  0.51     8524     2978    1 #> pred[FIXTURE: IXE_Q2W] 0.89 0.02 0.85 0.88 0.89 0.90  0.92     6499     3406    1 #> pred[FIXTURE: IXE_Q4W] 0.80 0.03 0.74 0.78 0.80 0.81  0.85     6875     3162    1 #> pred[FIXTURE: SEC_150] 0.67 0.03 0.62 0.65 0.67 0.69  0.72    11477     3243    1 #> pred[FIXTURE: SEC_300] 0.77 0.02 0.72 0.75 0.77 0.79  0.81     8979     2602    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-1: PBO]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     5572     3050    1 #> pred[UNCOVER-1: ETN]     0.46 0.03 0.40 0.44 0.46 0.48  0.52     7665     3239    1 #> pred[UNCOVER-1: IXE_Q2W] 0.90 0.01 0.88 0.89 0.90 0.91  0.92     7619     2708    1 #> pred[UNCOVER-1: IXE_Q4W] 0.81 0.02 0.78 0.80 0.81 0.82  0.84     9026     2632    1 #> pred[UNCOVER-1: SEC_150] 0.69 0.04 0.60 0.66 0.69 0.72  0.77     7932     3243    1 #> pred[UNCOVER-1: SEC_300] 0.78 0.04 0.71 0.76 0.79 0.81  0.85     8368     3620    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-2: PBO]     0.05 0.01 0.03 0.04 0.05 0.05  0.06     5688     3021    1 #> pred[UNCOVER-2: ETN]     0.42 0.02 0.38 0.41 0.42 0.43  0.46     8615     3026    1 #> pred[UNCOVER-2: IXE_Q2W] 0.88 0.01 0.86 0.87 0.88 0.89  0.90     6832     3139    1 #> pred[UNCOVER-2: IXE_Q4W] 0.78 0.02 0.75 0.77 0.78 0.79  0.81     8349     3085    1 #> pred[UNCOVER-2: SEC_150] 0.65 0.04 0.57 0.62 0.65 0.68  0.73     9166     3176    1 #> pred[UNCOVER-2: SEC_300] 0.75 0.04 0.68 0.73 0.75 0.78  0.82     7965     3205    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-3: PBO]     0.08 0.01 0.06 0.07 0.08 0.08  0.10     5522     2738    1 #> pred[UNCOVER-3: ETN]     0.53 0.02 0.49 0.52 0.53 0.54  0.57     8762     3368    1 #> pred[UNCOVER-3: IXE_Q2W] 0.93 0.01 0.91 0.92 0.93 0.93  0.94     6809     3118    1 #> pred[UNCOVER-3: IXE_Q4W] 0.85 0.01 0.83 0.85 0.85 0.86  0.88     7650     3017    1 #> pred[UNCOVER-3: SEC_150] 0.75 0.03 0.68 0.72 0.75 0.77  0.81     8837     3443    1 #> pred[UNCOVER-3: SEC_300] 0.83 0.03 0.77 0.81 0.83 0.85  0.88     8486     3297    1 plot(pso_pred_FE, ref_line = c(0, 1)) (pso_ranks_FE <- posterior_ranks(pso_fit_FE, lower_better = FALSE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[FIXTURE: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[FIXTURE: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[FIXTURE: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[FIXTURE: IXE_Q4W] 2.23 0.42    2   2   2   2     3     4574     4021    1 #> rank[FIXTURE: SEC_150] 4.00 0.05    4   4   4   4     4     2849       NA    1 #> rank[FIXTURE: SEC_300] 2.78 0.42    2   3   3   3     3     4737     3044    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-1: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-1: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-1: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[UNCOVER-1: IXE_Q4W] 2.23 0.42    2   2   2   2     3     4574     4021    1 #> rank[UNCOVER-1: SEC_150] 4.00 0.05    4   4   4   4     4     2849       NA    1 #> rank[UNCOVER-1: SEC_300] 2.78 0.42    2   3   3   3     3     4737     3044    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-2: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-2: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-2: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[UNCOVER-2: IXE_Q4W] 2.23 0.42    2   2   2   2     3     4574     4021    1 #> rank[UNCOVER-2: SEC_150] 4.00 0.05    4   4   4   4     4     2849       NA    1 #> rank[UNCOVER-2: SEC_300] 2.78 0.42    2   3   3   3     3     4737     3044    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-3: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-3: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-3: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[UNCOVER-3: IXE_Q4W] 2.23 0.42    2   2   2   2     3     4574     4021    1 #> rank[UNCOVER-3: SEC_150] 4.00 0.05    4   4   4   4     4     2849       NA    1 #> rank[UNCOVER-3: SEC_300] 2.78 0.42    2   3   3   3     3     4737     3044    1 plot(pso_ranks_FE) (pso_rankprobs_FE <- posterior_rank_probs(pso_fit_FE, lower_better = FALSE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             0      0.00      0.00         0         0         1 #> d[FIXTURE: ETN]             0      0.00      0.00         0         1         0 #> d[FIXTURE: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[FIXTURE: IXE_Q4W]         0      0.77      0.22         0         0         0 #> d[FIXTURE: SEC_150]         0      0.00      0.00         1         0         0 #> d[FIXTURE: SEC_300]         0      0.23      0.77         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-1: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-1: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-1: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-1: IXE_Q4W]         0      0.77      0.22         0         0         0 #> d[UNCOVER-1: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-1: SEC_300]         0      0.23      0.77         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-2: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-2: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-2: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-2: IXE_Q4W]         0      0.77      0.22         0         0         0 #> d[UNCOVER-2: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-2: SEC_300]         0      0.23      0.77         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-3: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-3: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-3: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-3: IXE_Q4W]         0      0.77      0.22         0         0         0 #> d[UNCOVER-3: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-3: SEC_300]         0      0.23      0.77         0         0         0 plot(pso_rankprobs_FE) (pso_cumrankprobs_FE <- posterior_rank_probs(pso_fit_FE, lower_better = FALSE, cumulative = TRUE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             0      0.00         0         0         0         1 #> d[FIXTURE: ETN]             0      0.00         0         0         1         1 #> d[FIXTURE: IXE_Q2W]         1      1.00         1         1         1         1 #> d[FIXTURE: IXE_Q4W]         0      0.77         1         1         1         1 #> d[FIXTURE: SEC_150]         0      0.00         0         1         1         1 #> d[FIXTURE: SEC_300]         0      0.23         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-1: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-1: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-1: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-1: IXE_Q4W]         0      0.77         1         1         1         1 #> d[UNCOVER-1: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-1: SEC_300]         0      0.23         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-2: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-2: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-2: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-2: IXE_Q4W]         0      0.77         1         1         1         1 #> d[UNCOVER-2: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-2: SEC_300]         0      0.23         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-3: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-3: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-3: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-3: IXE_Q4W]         0      0.77         1         1         1         1 #> d[UNCOVER-3: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-3: SEC_300]         0      0.23         1         1         1         1 plot(pso_cumrankprobs_FE) new_agd_means <- tibble(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3) (pso_releff_FE_new <- relative_effects(pso_fit_FE, newdata = new_agd_means)) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[New 1: ETN]     1.26 0.23 0.80 1.10 1.26 1.41  1.72     6609     3216    1 #> d[New 1: IXE_Q2W] 2.89 0.22 2.46 2.74 2.89 3.04  3.33     8855     3098    1 #> d[New 1: IXE_Q4W] 2.48 0.22 2.06 2.33 2.47 2.63  2.91     8487     3026    1 #> d[New 1: SEC_150] 2.08 0.23 1.65 1.92 2.08 2.23  2.54     7723     2992    1 #> d[New 1: SEC_300] 2.38 0.23 1.94 2.23 2.38 2.53  2.84     8156     3275    1 plot(pso_releff_FE_new, ref_line = 0) new_agd_int <- tibble(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1 ) new_agd_int <- add_integration(new_agd_int,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   cor = pso_net$int_cor,   n_int = 64) (pso_pred_FE_new <- predict(pso_fit_FE,                              type = \"response\",                             newdata = new_agd_int,                             baseline = distr(qnorm, -1.75, 0.08))) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: PBO]     0.06 0.03 0.03 0.04 0.06 0.08  0.12     5624     3243    1 #> pred[New 1: ETN]     0.37 0.06 0.26 0.33 0.37 0.41  0.49     4930     3345    1 #> pred[New 1: IXE_Q2W] 0.90 0.03 0.84 0.88 0.90 0.92  0.94     5373     3794    1 #> pred[New 1: IXE_Q4W] 0.81 0.04 0.73 0.78 0.81 0.83  0.87     5142     3914    1 #> pred[New 1: SEC_150] 0.68 0.06 0.57 0.65 0.68 0.72  0.78     5344     3748    1 #> pred[New 1: SEC_300] 0.78 0.05 0.68 0.75 0.78 0.81  0.86     5346     3990    1 plot(pso_pred_FE_new, ref_line = c(0, 1))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"extended_analysis","dir":"Articles","previous_headings":"","what":"Extended analysis","title":"Example: Plaque psoriasis ML-NMR","text":"now extend network include five studies (four AgD one IPD), recreating analysis Phillippo et al. (2022). larger network allows us assess key assumptions underlying population adjustment.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"preparing-the-data-1","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Preparing the data","title":"Example: Plaque psoriasis ML-NMR","text":"begin, , data transformations covariates set treatment class variable trtclass. small number individuals missing values IPD, simply exclude analysis.","code":"# IPD studies pso_ipd <- plaque_psoriasis_ipd %>%    mutate(     # Variable transformations     bsa = bsa / 100,     weight = weight / 10,     durnpso = durnpso / 10,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL-17 blocker\",                          trtn == 4 ~ \"TNFa blocker\",                          trtn == 7 ~ \"IL-12/23 blocker\"),     # Check complete cases for covariates of interest     is_complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   ) %>%    arrange(studyc, trtn)  # AgD studies pso_agd <- plaque_psoriasis_agd %>%    mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,      bsa_sd = bsa_sd / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     prevsys = prevsys / 100,     psa = psa / 100,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL-17 blocker\",                          trtn == 4 ~ \"TNFa blocker\",                          trtn == 7 ~ \"IL-12/23 blocker\")     ) %>%    arrange(studyc, trtn) pso_ipd %>%    group_by(studyc) %>%    summarise(n_total = n(),             n_missing = sum(!is_complete),              pct_missing = mean(!is_complete) * 100) #> # A tibble: 4 × 4 #>   studyc    n_total n_missing pct_missing #>   <chr>       <int>     <int>       <dbl> #> 1 IXORA-S       260         0       0     #> 2 UNCOVER-1    1296         0       0     #> 3 UNCOVER-2    1221         2       0.164 #> 4 UNCOVER-3    1341         2       0.149  pso_ipd <- filter(pso_ipd, is_complete)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"creating-the-network-1","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Creating the network","title":"Example: Plaque psoriasis ML-NMR","text":"Next set network. set IPD set_ipd() AgD (arm-based) set_agd_arm(), combine together using combine_network(). specify ordered categorical (multinomial) outcome using multi() helper function. outcome data “inclusive” format, .e. lowest category sample size (1 IPD), second category counts achieving PASI 75 greater (\\(\\ge 75\\%\\) reduction symptoms), third counts achieving PASI 90 greater (\\(\\ge 90\\%\\) reduction), final category counts achieving PASI 100 (\\(100\\%\\) reduction).2 specify treatment classes trt_class = trtclass. create network plot using plot() function applied pso_net network object, choosing scale edges nodes number studies/sample size (weight_edges weight_nodes = TRUE), colour treatment nodes class (show_trt_class = TRUE), nudge treatment names away nodes (nudge = 0.1). customise plot using ggplot syntax alter colour scheme.","code":"pso_net <- combine_network(   set_ipd(pso_ipd,     study = studyc,     trt = trtc,     r = multi(r0 = 1,                PASI75 = pasi75,               PASI90 = pasi90,               PASI100 = pasi100,               type = \"ordered\", inclusive = TRUE),     trt_class = trtclass),   set_agd_arm(pso_agd,     study = studyc,     trt = trtc,     r = multi(r0 = pasi75_n,                PASI75 = pasi75_r,               PASI90 = pasi90_r,               PASI100 = pasi100_r,               type = \"ordered\", inclusive = TRUE),     trt_class = trtclass) )  pso_net #> A network with 4 IPD studies, and 5 AgD studies (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: PBO | IXE_Q2W | IXE_Q4W       #>  UNCOVER-2 4: PBO | IXE_Q2W | IXE_Q4W | ETN #>  UNCOVER-3 4: PBO | IXE_Q2W | IXE_Q4W | ETN #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study    Treatment arms                   #>  CLEAR    2: SEC_300 | UST                 #>  ERASURE  3: PBO | SEC_150 | SEC_300       #>  FEATURE  3: PBO | SEC_150 | SEC_300       #>  FIXTURE  4: PBO | ETN | SEC_150 | SEC_300 #>  JUNCTURE 3: PBO | SEC_150 | SEC_300       #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 7, in 4 classes #> Total number of studies: 9 #> Reference treatment is: PBO #> Network is connected class_pal <- c(\"#D95F02\", \"#7570B3\", \"#E7298A\", \"#E6AB02\")  plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE, nudge = 0.1) +   ggraph::scale_edge_colour_manual(\"Data\",                                     values = c(AgD = \"#113259\", IPD = \"#55A480\"),                                    guide = guide_legend(override.aes = list(edge_width = 2))) +   scale_fill_manual(\"Treatment class\",                      values = class_pal,                     aesthetics = c(\"fill\", \"colour\"),                     guide = guide_legend(override.aes = list(size = 2))) #> Scale for edge_colour is already present. #> Adding another scale for edge_colour, which will replace the existing scale. #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale. #> Warning: Duplicated `override.aes` is ignored."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"numerical-integration-for-ml-nmr-models","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Numerical integration for ML-NMR models","title":"Example: Plaque psoriasis ML-NMR","text":"add integration points AgD studies network using add_integration() function, specifying chosen marginal distribution covariate using distr() function. , specify Gamma distributions weight duration psoriasis, logit-Normal distribution body surface area, Bernoulli distributions previous systemic treatment psoriatic arthritis binary covariates. Since know correlations covariates AgD studies, impute weighted mean correlations IPD studies (default option).","code":"pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"ml-nmr-model","dir":"Articles","previous_headings":"Extended analysis","what":"ML-NMR model","title":"Example: Plaque psoriasis ML-NMR","text":"Using nma() function, fit (fixed effect) ML-NMR model includes main effects (prognostic terms) covariate-treatment interactions (effect-modifying terms) five covariates. Ideally, fit independent interaction terms treatment; however, requires either IPD several AgD studies range covariate values treatment. data insufficient fit independent interaction terms treatment, make shared effect modifier assumption within class treatments (Phillippo et al. 2016) specify common interaction terms within treatment class (class_interactions = \"common\"). , specify \\(\\mathrm{N}(0, 10^2)\\) prior distributions study-specific intercepts, treatment effects, regression parameters. However, since now ordered multinomial likelihood also need specify priors differences latent cutoffs outcome category; choose improper flat prior \\(\\mathrm{U}(-\\infty,\\infty)\\) automatically truncated meet ordering constraints (prior_aux = flat()).","code":"pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                    regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_aux = flat(),                   QR = TRUE,                   init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit_FE #> A fixed effects ML-NMR with a ordered likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8159830 0.6576489 0.2987820 8.9097263 0.2104826  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.03    0.00 0.06    -0.08    -0.01     0.03     0.08 #> beta[prevsys]                              -0.17    0.00 0.16    -0.49    -0.28    -0.17    -0.06 #> beta[bsa]                                  -0.10    0.01 0.45    -1.01    -0.40    -0.08     0.21 #> beta[weight]                                0.04    0.00 0.03    -0.01     0.02     0.04     0.06 #> beta[psa]                                  -0.08    0.00 0.17    -0.42    -0.20    -0.08     0.03 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.16    -0.07    -0.02     0.03 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.06    0.00 0.10    -0.26    -0.13    -0.07     0.00 #> beta[durnpso:.trtclassIL-17 blocker]       -0.02    0.00 0.06    -0.14    -0.07    -0.02     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.19    0.00 0.19    -0.18     0.07     0.19     0.32 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.45    0.01 0.34    -0.24     0.24     0.47     0.68 #> beta[prevsys:.trtclassIL-17 blocker]        0.16    0.00 0.17    -0.17     0.05     0.16     0.28 #> beta[bsa:.trtclassTNFa blocker]             0.24    0.01 0.51    -0.73    -0.11     0.22     0.57 #> beta[bsa:.trtclassIL-12/23 blocker]         0.61    0.01 0.68    -0.71     0.14     0.61     1.07 #> beta[bsa:.trtclassIL-17 blocker]            0.27    0.01 0.47    -0.63    -0.06     0.26     0.58 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.18    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.18    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.05    0.00 0.20    -0.43    -0.18    -0.04     0.08 #> beta[psa:.trtclassIL-12/23 blocker]         0.12    0.01 0.33    -0.51    -0.11     0.12     0.36 #> beta[psa:.trtclassIL-17 blocker]            0.10    0.00 0.18    -0.24    -0.02     0.10     0.21 #> d[ETN]                                      1.58    0.00 0.07     1.44     1.53     1.58     1.63 #> d[IXE_Q2W]                                  2.91    0.00 0.07     2.76     2.86     2.91     2.96 #> d[IXE_Q4W]                                  2.69    0.00 0.08     2.54     2.64     2.69     2.74 #> d[SEC_150]                                  2.19    0.00 0.08     2.03     2.13     2.19     2.24 #> d[SEC_300]                                  2.60    0.00 0.08     2.45     2.54     2.60     2.65 #> d[UST]                                      2.13    0.00 0.11     1.91     2.06     2.13     2.20 #> lp__                                    -7640.27    0.11 4.31 -7649.63 -7642.96 -7639.97 -7637.16 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.65     0.68     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.49     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.15  2512    1 #> beta[prevsys]                               0.14  2701    1 #> beta[bsa]                                   0.77  2254    1 #> beta[weight]                                0.10  2331    1 #> beta[psa]                                   0.24  3019    1 #> beta[durnpso:.trtclassTNFa blocker]         0.12  2678    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.14  3490    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.10  2899    1 #> beta[prevsys:.trtclassTNFa blocker]         0.55  2824    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.11  4293    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.48  3128    1 #> beta[bsa:.trtclassTNFa blocker]             1.27  2433    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.93  2921    1 #> beta[bsa:.trtclassIL-17 blocker]            1.25  2728    1 #> beta[weight:.trtclassTNFa blocker]         -0.10  2590    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.01  3473    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  2731    1 #> beta[psa:.trtclassTNFa blocker]             0.33  2990    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.77  3967    1 #> beta[psa:.trtclassIL-17 blocker]            0.46  3516    1 #> d[ETN]                                      1.72  1969    1 #> d[IXE_Q2W]                                  3.06  2104    1 #> d[IXE_Q4W]                                  2.84  2327    1 #> d[SEC_150]                                  2.36  2267    1 #> d[SEC_300]                                  2.76  2396    1 #> d[UST]                                      2.34  3215    1 #> lp__                                    -7632.94  1664    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  3323    1 #> cc[PASI100]                                 1.58  2862    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Aug 28 12:56:36 2022. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1)."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-assumptions","dir":"Articles","previous_headings":"Extended analysis","what":"Assessing assumptions","title":"Example: Plaque psoriasis ML-NMR","text":"first analysis, small network made assessing assumptions difficult. larger network (although still nine studies) greater opportunity assess key assumptions. key assumption made ML-NMR (indeed population adjustment methods connected networks) conditional constancy relative effects assumption (Phillippo et al. 2016). means unobserved effect modifiers, relative effects constant given included effect-modifying covariates. assumption implies residual heterogeneity inconsistency, can assessed using standard network meta-analysis techniques. assess residual heterogeneity using random effects model, residual inconsistency using unrelated mean effects (UME) model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-residual-heterogeneity-with-a-random-effects-ml-nmr","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Assessing residual heterogeneity with a random effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"First, fit random effects model assess residual heterogeneity. call nma() function identical fixed effect model , except now specify trt_effects = \"random\" need provide prior -study heterogeneity (choose \\(\\textrm{half-N}(0, 2.5^2)\\) prior prior_het = half_normal(scale = 2.5). estimated -study heterogeneity standard deviation tau small compared relative treatment effects. compare model fit using DIC: DIC lower RE model, indicating may residual heterogeneity network conditional constancy relative effects assumption may invalid—may additional effect modifiers accounted . result different actual analysis reported Phillippo et al. (2022), since using synthetic IPD simulated closely resemble original IPD. actual analysis DIC similar FE RE models, might choose parsimonious FE model based DIC alone, evidence residual heterogeneity network.","code":"pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                    regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_aux = flat(),                   prior_het = half_normal(scale = 2.5),                   QR = TRUE,                   init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. #> Warning: There were 1 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems pso_fit_RE #> A random effects ML-NMR with a ordered likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8159830 0.6576489 0.2987820 8.9097263 0.2104826  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.04    0.00 0.06    -0.08    -0.01     0.04     0.08 #> beta[prevsys]                              -0.16    0.00 0.16    -0.46    -0.26    -0.15    -0.06 #> beta[bsa]                                  -0.14    0.01 0.46    -1.09    -0.45    -0.13     0.17 #> beta[weight]                                0.05    0.00 0.03    -0.01     0.03     0.05     0.07 #> beta[psa]                                  -0.07    0.00 0.17    -0.40    -0.18    -0.06     0.04 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.17    -0.07    -0.02     0.03 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.07    0.00 0.10    -0.27    -0.14    -0.07     0.01 #> beta[durnpso:.trtclassIL-17 blocker]       -0.03    0.00 0.06    -0.15    -0.07    -0.02     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.19    0.00 0.18    -0.17     0.07     0.19     0.31 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.43    0.00 0.35    -0.27     0.20     0.44     0.67 #> beta[prevsys:.trtclassIL-17 blocker]        0.15    0.00 0.16    -0.18     0.04     0.15     0.26 #> beta[bsa:.trtclassTNFa blocker]             0.27    0.01 0.53    -0.73    -0.08     0.25     0.61 #> beta[bsa:.trtclassIL-12/23 blocker]         0.66    0.01 0.66    -0.65     0.21     0.67     1.09 #> beta[bsa:.trtclassIL-17 blocker]            0.32    0.01 0.48    -0.58    -0.01     0.31     0.63 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.19    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.18    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.06    0.00 0.20    -0.46    -0.20    -0.06     0.07 #> beta[psa:.trtclassIL-12/23 blocker]         0.11    0.00 0.33    -0.53    -0.10     0.11     0.34 #> beta[psa:.trtclassIL-17 blocker]            0.08    0.00 0.18    -0.27    -0.04     0.08     0.20 #> d[ETN]                                      1.59    0.00 0.11     1.38     1.52     1.59     1.66 #> d[IXE_Q2W]                                  2.93    0.00 0.11     2.73     2.86     2.93     3.00 #> d[IXE_Q4W]                                  2.71    0.00 0.12     2.49     2.64     2.71     2.78 #> d[SEC_150]                                  2.21    0.00 0.12     1.99     2.13     2.21     2.28 #> d[SEC_300]                                  2.64    0.00 0.12     2.42     2.56     2.63     2.71 #> d[UST]                                      2.17    0.00 0.17     1.85     2.06     2.16     2.27 #> lp__                                    -7646.77    0.21 6.32 -7660.09 -7650.88 -7646.44 -7642.40 #> tau                                         0.13    0.00 0.07     0.02     0.09     0.13     0.17 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.66     0.68     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.49     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.16  3817    1 #> beta[prevsys]                               0.16  4212    1 #> beta[bsa]                                   0.73  3325    1 #> beta[weight]                                0.10  3585    1 #> beta[psa]                                   0.27  4167    1 #> beta[durnpso:.trtclassTNFa blocker]         0.12  3797    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.13  5280    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.10  4181    1 #> beta[prevsys:.trtclassTNFa blocker]         0.54  4064    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.06  5604    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.46  4509    1 #> beta[bsa:.trtclassTNFa blocker]             1.31  3573    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.98  4347    1 #> beta[bsa:.trtclassIL-17 blocker]            1.29  3634    1 #> beta[weight:.trtclassTNFa blocker]         -0.10  3833    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.00  5021    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  4493    1 #> beta[psa:.trtclassTNFa blocker]             0.35  4225    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.75  6190    1 #> beta[psa:.trtclassIL-17 blocker]            0.43  4403    1 #> d[ETN]                                      1.81  2805    1 #> d[IXE_Q2W]                                  3.15  3031    1 #> d[IXE_Q4W]                                  2.95  2966    1 #> d[SEC_150]                                  2.47  2726    1 #> d[SEC_300]                                  2.88  2575    1 #> d[UST]                                      2.52  2667    1 #> lp__                                    -7635.39   899    1 #> tau                                         0.29   620    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  5665    1 #> cc[PASI100]                                 1.58  6212    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Aug 28 14:09:25 2022. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). (pso_dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 8811.4 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.4 (pso_dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 8800.1 (on 12387 data points) #>                pD: 42.3 #>               DIC: 8842.4"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-residual-inconsistency-with-an-unrelated-mean-effects-ml-nmr","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Assessing residual inconsistency with an unrelated mean effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"assess residual inconsistency using unrelated mean effects model (Dias et al. 2011). , call nma() function identical, except time specify consistency = \"ume\". Node-splitting also possibility (consistency = \"nodesplit\"), takes substantially longer since model re-run node-split comparison. proceed analysis Phillippo et al. (2022) fit fixed effect UME model (since evidence heterogeneity actual analysis); however, recreated analysis using synthetic IPD evidence heterogeneity really fit random effects UME model instead. compare model fit FE ML-NMR model using DIC. DIC values similar FE model (assuming consistency) UME (inconsistency) model, suggests evidence inconsistency overall. also important compare residual deviance contributions model see whether points fit better UME model, can also indicate inconsistency. Using plot() function produces “dev-dev” plot residual deviance contributions either model.  points lie line equality, evidence inconsistency. random effects models fitted heterogeneity estimates also compared drop tau UME model can also indicate inconsistency.","code":"pso_fit_UME <- nma(pso_net,                     trt_effects = \"fixed\",                    consistency = \"ume\",                    link = \"probit\",                     regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                    class_interactions = \"common\",                    prior_intercept = normal(scale = 10),                    prior_trt = normal(scale = 10),                    prior_reg = normal(scale = 10),                    prior_aux = flat(),                    QR = TRUE,                    init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit_UME #> A fixed effects ML-NMR with a ordered likelihood (probit link). #> An inconsistency model ('ume') was fitted. #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8159830 0.6576489 0.2987820 8.9097263 0.2104826  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.03    0.00 0.06    -0.09    -0.01     0.03     0.07 #> beta[prevsys]                              -0.17    0.00 0.16    -0.47    -0.27    -0.17    -0.06 #> beta[bsa]                                  -0.09    0.01 0.44    -0.98    -0.38    -0.08     0.21 #> beta[weight]                                0.04    0.00 0.03    -0.01     0.02     0.04     0.06 #> beta[psa]                                  -0.08    0.00 0.17    -0.42    -0.20    -0.08     0.03 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.16    -0.07    -0.02     0.03 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.06    0.00 0.10    -0.26    -0.13    -0.06     0.01 #> beta[durnpso:.trtclassIL-17 blocker]       -0.02    0.00 0.06    -0.14    -0.06    -0.02     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.19    0.00 0.18    -0.16     0.07     0.19     0.31 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.45    0.01 0.35    -0.24     0.21     0.46     0.70 #> beta[prevsys:.trtclassIL-17 blocker]        0.16    0.00 0.16    -0.16     0.05     0.16     0.27 #> beta[bsa:.trtclassTNFa blocker]             0.22    0.01 0.50    -0.76    -0.12     0.20     0.56 #> beta[bsa:.trtclassIL-12/23 blocker]         0.59    0.01 0.67    -0.72     0.13     0.60     1.05 #> beta[bsa:.trtclassIL-17 blocker]            0.26    0.01 0.46    -0.64    -0.05     0.25     0.56 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.18    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.18    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.05    0.00 0.20    -0.44    -0.18    -0.05     0.09 #> beta[psa:.trtclassIL-12/23 blocker]         0.12    0.01 0.35    -0.54    -0.12     0.12     0.36 #> beta[psa:.trtclassIL-17 blocker]            0.10    0.00 0.18    -0.26    -0.03     0.09     0.22 #> d[ETN vs. PBO]                              1.58    0.00 0.07     1.44     1.53     1.58     1.63 #> d[IXE_Q2W vs. PBO]                          2.91    0.00 0.07     2.77     2.86     2.91     2.96 #> d[IXE_Q4W vs. PBO]                          2.69    0.00 0.07     2.54     2.64     2.69     2.74 #> d[SEC_150 vs. PBO]                          2.19    0.00 0.08     2.02     2.13     2.19     2.25 #> d[SEC_300 vs. PBO]                          2.60    0.00 0.08     2.44     2.54     2.60     2.65 #> d[UST vs. IXE_Q2W]                         -0.78    0.00 0.16    -1.09    -0.89    -0.78    -0.68 #> d[UST vs. SEC_300]                         -0.47    0.00 0.09    -0.65    -0.53    -0.47    -0.41 #> lp__                                    -7640.40    0.10 4.39 -7650.22 -7643.16 -7639.97 -7637.34 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.65     0.68     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.49     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.15  2591    1 #> beta[prevsys]                               0.14  2698    1 #> beta[bsa]                                   0.74  2778    1 #> beta[weight]                                0.10  2854    1 #> beta[psa]                                   0.25  2997    1 #> beta[durnpso:.trtclassTNFa blocker]         0.12  2850    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.13  3732    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.11  3146    1 #> beta[prevsys:.trtclassTNFa blocker]         0.54  2803    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.09  4034    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.48  3191    1 #> beta[bsa:.trtclassTNFa blocker]             1.20  2846    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.91  3889    1 #> beta[bsa:.trtclassIL-17 blocker]            1.19  3282    1 #> beta[weight:.trtclassTNFa blocker]         -0.09  3169    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.00  4218    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  3421    1 #> beta[psa:.trtclassTNFa blocker]             0.35  3036    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.81  4680    1 #> beta[psa:.trtclassIL-17 blocker]            0.45  3454    1 #> d[ETN vs. PBO]                              1.73  2815    1 #> d[IXE_Q2W vs. PBO]                          3.05  2892    1 #> d[IXE_Q4W vs. PBO]                          2.84  3286    1 #> d[SEC_150 vs. PBO]                          2.36  2992    1 #> d[SEC_300 vs. PBO]                          2.76  3203    1 #> d[UST vs. IXE_Q2W]                         -0.47  4990    1 #> d[UST vs. SEC_300]                         -0.29  6387    1 #> lp__                                    -7633.00  1771    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  3712    1 #> cc[PASI100]                                 1.58  3257    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Aug 28 14:26:48 2022. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). pso_dic_FE #> Residual deviance: 8811.4 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.4 (pso_dic_UME <- dic(pso_fit_UME)) #> Residual deviance: 8811.7 (on 12387 data points) #>                pD: 36.3 #>               DIC: 8848 plot(pso_dic_FE, pso_dic_UME, show_uncertainty = FALSE) +   xlab(\"Residual deviance - consistency model\") +   ylab(\"Residual deviance - inconsistency (UME) model\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"relaxing-the-shared-effect-modifier-assumption","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Relaxing the shared effect modifier assumption","title":"Example: Plaque psoriasis ML-NMR","text":"treatment classes network follows: fitted common interaction terms within treatment class, shared effect modifier assumption, order make model estimable available data. Note interleukin-17 blocker class one treatment; etanercept ustekinumab classes unaffected specifying class_interactions = \"common\". assess assumption simply fit independent interaction terms treatments effect modifiers sufficient data. Instead, relax assumption one covariate time, estimating independent interactions one covariate whilst keeping shared effect modifier assumption (common interactions within treatment class) covariates. specify relaxed models, need somehow mix class_interactions = \"common\" class_interactions = \"independent\" different covariates. way .trt .trtclass specials specifying regression model. see works, first note model making shared effect modifiers assumption can written equivalently using .trtclass special .trtclass special essentially factor variable containing treatment classes, available time treatment classes specified network; regression formula therefore single interaction term covariate within treatment class (result specifying class_interactions = \"common\" ). Finally, fit independent interactions single covariate, say durnpso, split using .trt special class_interactions = \"independent\" (.e. telling model combine interactions .trt within classes): Since fitting several models, let us set list model specifications iterate . Comparing model fit using DIC models similar higher DIC original model making shared effect modifier assumption covariates, exception model independent interactions weight slightly lower DIC. also visually examine differences estimated interaction terms original model (shared effect modifier assumption covariates) relaxed models (independent interactions, one covariate time).  independent interaction estimates similar common interaction estimates, much uncertainty—particularly secukinumab regimens estimated aggregate data. exception weight, suggestion covariate may interact differently secukinumab treatment regimens ixekizumab regimens. However, credible intervals secukinumab interactions wide overlap ixekizumab regimens common interaction. Overall, weak evidence shared effect modifier assumption (class interleukin-17 blockers) may invalid weight. Since fitting multiple models mindful multiple testing possibility differences occurred chance. hand, approach likely low power detect violations shared effect modifier assumption, particularly data lacking. case, results model relaxing shared effect modifier assumption weight similar original model (see Phillippo et al. 2022).","code":"data.frame(classes = pso_net$classes, treatments = pso_net$treatments) #>            classes treatments #> 1          Placebo        PBO #> 2     TNFa blocker        ETN #> 3    IL-17 blocker    IXE_Q2W #> 4    IL-17 blocker    IXE_Q4W #> 5    IL-17 blocker    SEC_150 #> 6    IL-17 blocker    SEC_300 #> 7 IL-12/23 blocker        UST regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt, class_interactions = \"common\" regression = ~(durnpso + prevsys + bsa + weight + psa)*.trtclass regression = ~(prevsys + bsa + weight + psa)*.trtclass + durnpso*.trt, class_interactions = \"independent\" noSEM_mods <- list(   durnpso = ~(prevsys + bsa + weight + psa)*.trtclass + durnpso*.trt,   prevsys = ~(durnpso + bsa + weight + psa)*.trtclass + prevsys*.trt,   bsa = ~(durnpso + prevsys + weight + psa)*.trtclass + bsa*.trt,   weight = ~(durnpso + prevsys + bsa + psa)*.trtclass + weight*.trt,   psa = ~(durnpso + prevsys + bsa + weight)*.trtclass + psa*.trt   )  noSEM_fits <- noSEM_mods  for (m in 1:length(noSEM_mods)) {   cat(\"Fitting model with independent interactions for\", names(noSEM_mods)[m], \"\\n\")      noSEM_fits[[m]] <-      nma(pso_net,          trt_effects = \"fixed\",         link = \"probit\",          regression = noSEM_mods[[m]],         class_interactions = \"independent\",         prior_intercept = normal(scale = 10),         prior_trt = normal(scale = 10),         prior_reg = normal(scale = 10),         prior_aux = flat(),         QR = TRUE,         init_r = 0.5,         # Using save_warmup = FALSE reduces memory footprint when          # fitting many models in one session         save_warmup = FALSE) } #> Fitting model with independent interactions for durnpso #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for prevsys #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for bsa #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for weight #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for psa #> Note: Setting \"PBO\" as the network reference treatment. pso_dic_FE #> Residual deviance: 8811.4 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.4 lapply(noSEM_fits, dic) #> $durnpso #> Residual deviance: 8812.5 (on 12387 data points) #>                pD: 37.7 #>               DIC: 8850.3 #>  #> $prevsys #> Residual deviance: 8813.4 (on 12387 data points) #>                pD: 37.8 #>               DIC: 8851.2 #>  #> $bsa #> Residual deviance: 8813 (on 12387 data points) #>                pD: 37.8 #>               DIC: 8850.8 #>  #> $weight #> Residual deviance: 8807.5 (on 12387 data points) #>                pD: 37.9 #>               DIC: 8845.4 #>  #> $psa #> Residual deviance: 8812.2 (on 12387 data points) #>                pD: 37.8 #>               DIC: 8850 library(purrr) library(stringr) library(forcats)  # Extract draws from relaxed models imap_dfr(noSEM_fits,         ~as_tibble(as.matrix(.x, pars = \"beta\")) %>%             pivot_longer(cols = everything(), names_to = \"parameter\", values_to = \"value\") %>%             filter(str_detect(parameter, paste0(\"(IXE|SEC).+:\", .y))) %>%             mutate(model = .y)) %>%       # Add in draws from the original model   bind_rows(     as_tibble(as.matrix(pso_fit_FE, pars = \"beta\")) %>%      pivot_longer(cols = everything(), names_to = \"parameter\", values_to = \"value\") %>%      filter(str_detect(parameter, \":.+IL\\\\-17 blocker\")) %>%      mutate(model = \"all\")   ) %>%       mutate(     # Rescale BSA to per 10%      value = if_else(str_detect(parameter, \"bsa\"), value / 10, value),     # Create labels     covariate = str_extract(parameter, \"durnpso|prevsys|bsa|weight|psa\"),     covariatef = recode_factor(covariate,                                durnpso = \"Duration of psoriasis, per 10 years\",                                prevsys = \"Previous systemic use\",                                bsa = \"Body surface area, per 10%\",                                weight = \"Weight, per 10 kg\",                                psa = \"Psoriatic arthritis\"),     treatment = str_remove(str_extract(parameter, \"\\\\.trt(class)?.+?(?=[\\\\]:])\"),                            \"\\\\.trt(class)?\"),     Interactions = fct_collapse(factor(model),                                  Common = \"all\",                                  other_level = \"Independent\")) %>%     # Plot ggplot(aes(x = value, y = fct_rev(treatment), colour = Interactions, fill = Interactions)) +   geom_vline(xintercept = 0, colour = \"grey70\") +   ggdist::stat_halfeye(normalize = \"panels\", slab_alpha = 0.3, .width = c(0, 0.95)) +   facet_wrap(\"covariatef\", scales = \"free\") +   xlab(\"Interaction effect (SMD)\") +    ylab(\"Treatment / Class\") +   scale_colour_manual(values = c(Common = \"#7B3294\", Independent = \"#91D388\"),                       aesthetics = c(\"colour\", \"fill\")) +   theme_multinma() +   theme(legend.position = c(0.85, 0.2))"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"study-populations-included-in-the-network","dir":"Articles","previous_headings":"Extended analysis > Producing relative effects and event probabilities","what":"Study populations included in the network","title":"Example: Plaque psoriasis ML-NMR","text":"Population-average treatment effects can produced study populations represented network using relative_effects() function. relative effects can plotted using plot() function.  Similarly, average response probabilities treatment, study population, PASI cutoff can produced using predict() function. specify type = \"response\" produce predicted probabilities (rather probit-probabilities). , can plotted using plot() function.","code":"(pso_releff_FE <- relative_effects(pso_fit_FE)) plot(pso_releff_FE, ref_line = 0) (pso_pred_FE <- predict(pso_fit_FE, type = \"response\")) plot(pso_pred_FE, ref_line = c(0, 1))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"external-target-populations","dir":"Articles","previous_headings":"Extended analysis > Producing relative effects and event probabilities","what":"External target populations","title":"Example: Plaque psoriasis ML-NMR","text":"purposes decision-making crucial population-average estimates produced decision target population interest. decision target population may represented study populations network, indeed likely best represented external registry cohort study, perhaps expert knowledge (Phillippo et al. 2016). example, Phillippo et al. (2022) produce estimates three external target populations represented PsoBest registry (Reich et al. 2015; Augustin et al. 2014), PROSPECT (Thaçi et al. 2019) Chiricozzi 2019 (Chiricozzi et al. 2019) cohort studies. First , need covariate means standard deviations populations: produce estimates population-average treatment effects, use relative_effects() function data frame covariate means target populations newdata argument. need covariate means, variable names matching regression. estimates plotted using plot() function.  Estimates average event probabilities produced integrating predictions joint covariate distribution population. Since marginal summary statistics available, rather full IPD, create integration points using add_integration() function specifying forms marginal distributions correlation matrix. choose use forms marginal distributions used specifying integration points AgD studies network, weighted correlation matrix IPD studies. use predict() function produce average event probabilities (type = \"response\", level = \"aggregate\" default) target populations. , also need specify distribution baseline event probabilities (.e. probability achieving PASI 75 response) target populations. PASI 75 event counts individuals receiving secukinumab 300 mg treatment available PROSPECT (1156 achieved PASI 75 1509) Chiricozzi 2019 (243 330), use construct beta distributions baseline average response probabilities (specify baseline_level = \"aggregate\" population averages, rather specific reference individual, baseline_type = \"response\" probabilities rather transformed probit probabilities). information baseline response available PsoBest, predictions absolute response rates made. , plot estimates using plot() function, customisation using ggplot syntax.","code":"new_agd_means <- tibble::tribble(              ~study, ~covariate,  ~mean,   ~sd,           \"PsoBest\",      \"bsa\",     24,  20.5,           \"PsoBest\",  \"durnpso\",   18.2,  14.1,           \"PsoBest\",  \"prevsys\",   0.54,    NA,           \"PsoBest\",      \"psa\",  0.207,    NA,           \"PsoBest\",   \"weight\",     85,  19.1,          \"PROSPECT\",      \"bsa\",   18.7,  18.4,          \"PROSPECT\",  \"durnpso\",   19.6,  13.5,          \"PROSPECT\",  \"prevsys\", 0.9095,    NA,          \"PROSPECT\",      \"psa\",  0.202,    NA,          \"PROSPECT\",   \"weight\",   87.5,  20.3,   \"Chiricozzi 2019\",      \"bsa\",     23, 16.79,   \"Chiricozzi 2019\",  \"durnpso\",  16.93, 10.82,   \"Chiricozzi 2019\",  \"prevsys\", 0.9061,    NA,   \"Chiricozzi 2019\",      \"psa\", 0.2152,    NA,   \"Chiricozzi 2019\",   \"weight\",   78.3, 15.87   ) %>%   # Tidy up   pivot_wider(id_cols = study,                names_from = covariate,                values_from = c(mean, sd),               names_glue = \"{covariate}_{.value}\") %>%    # Rescale as per analysis   transmute(study,             bsa_mean = bsa_mean / 100,              bsa_sd = bsa_sd / 100,             weight_mean = weight_mean / 10,             weight_sd = weight_sd / 10,             durnpso_mean = durnpso_mean / 10,             durnpso_sd = durnpso_sd / 10,             prevsys = prevsys_mean,             psa = psa_mean) (pso_releff_FE_new <- relative_effects(pso_fit_FE,                                         newdata = transmute(new_agd_means,                                                            study,                                                            bsa = bsa_mean,                                                            weight = weight_mean,                                                            durnpso = durnpso_mean,                                                            prevsys,                                                            psa),                                        study = study)) #> -------------------------------------------------------- Study: Chiricozzi 2019 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.69    0.91 0.23   7.83 0.22 #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Chiricozzi 2019: ETN]     1.79 0.11 1.58 1.71 1.79 1.86  2.01     1618     2360    1 #> d[Chiricozzi 2019: IXE_Q2W] 3.07 0.10 2.87 3.00 3.07 3.14  3.28     1623     2630    1 #> d[Chiricozzi 2019: IXE_Q4W] 2.85 0.10 2.65 2.78 2.85 2.92  3.06     1782     2447    1 #> d[Chiricozzi 2019: SEC_150] 2.35 0.11 2.13 2.28 2.35 2.43  2.58     2248     2749    1 #> d[Chiricozzi 2019: SEC_300] 2.76 0.11 2.55 2.69 2.76 2.84  2.98     1883     2739    1 #> d[Chiricozzi 2019: UST]     2.30 0.15 2.02 2.20 2.30 2.40  2.58     2569     2878    1 #>  #> --------------------------------------------------------------- Study: PROSPECT ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.96    0.91 0.19   8.75 0.2 #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[PROSPECT: ETN]     1.62 0.11 1.42 1.55 1.62 1.70  1.84     2215     2573    1 #> d[PROSPECT: IXE_Q2W] 2.94 0.10 2.74 2.87 2.93 3.00  3.13     2128     2844    1 #> d[PROSPECT: IXE_Q4W] 2.72 0.10 2.52 2.65 2.72 2.78  2.92     2329     2929    1 #> d[PROSPECT: SEC_150] 2.22 0.11 2.00 2.14 2.22 2.29  2.44     2719     3321    1 #> d[PROSPECT: SEC_300] 2.63 0.11 2.41 2.55 2.63 2.70  2.85     2295     3224    1 #> d[PROSPECT: UST]     2.18 0.15 1.89 2.08 2.18 2.28  2.47     3205     3089    1 #>  #> ---------------------------------------------------------------- Study: PsoBest ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.82    0.54 0.24    8.5 0.21 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[PsoBest: ETN]     1.61 0.08 1.46 1.56 1.61 1.66  1.77     2021     2876    1 #> d[PsoBest: IXE_Q2W] 2.93 0.08 2.78 2.87 2.93 2.98  3.08     1857     2249    1 #> d[PsoBest: IXE_Q4W] 2.71 0.08 2.56 2.66 2.71 2.76  2.86     2164     2259    1 #> d[PsoBest: SEC_150] 2.21 0.09 2.04 2.15 2.21 2.27  2.39     2451     2706    1 #> d[PsoBest: SEC_300] 2.62 0.09 2.45 2.56 2.62 2.67  2.79     2016     2919    1 #> d[PsoBest: UST]     2.08 0.13 1.82 1.99 2.08 2.17  2.34     2852     3123    1 #> plot(pso_releff_FE_new, ref_line = 0) + facet_wrap(\"Study\") new_agd_int <- add_integration(filter(new_agd_means, study != \"PsoBest\"),                                durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),                                prevsys = distr(qbern, prob = prevsys),                                bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),                                weight = distr(qgamma, mean = weight_mean, sd = weight_sd),                                psa = distr(qbern, prob = psa),                                n_int = 64,                                cor = pso_net$int_cor) (pso_pred_FE_new <- predict(pso_fit_FE,          type = \"response\",          newdata = new_agd_int,         study = study,         baseline = list(PROSPECT = distr(qbeta, 1156, 1509-1156),                         \"Chiricozzi 2019\" = distr(qbeta, 243, 330-243)),         baseline_type = \"response\",         baseline_level = \"aggregate\",         trt_ref = \"SEC_300\")) #> -------------------------------------------------------- Study: Chiricozzi 2019 ----  #>  #>                                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Chiricozzi 2019: PBO, PASI75]      0.02 0.01 0.01 0.01 0.02 0.02  0.03     2564     3595    1 #> pred[Chiricozzi 2019: PBO, PASI90]      0.00 0.00 0.00 0.00 0.00 0.00  0.01     2643     3414    1 #> pred[Chiricozzi 2019: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     2763     3690    1 #> pred[Chiricozzi 2019: ETN, PASI75]      0.37 0.04 0.30 0.34 0.37 0.40  0.46     4758     3892    1 #> pred[Chiricozzi 2019: ETN, PASI90]      0.16 0.03 0.11 0.14 0.16 0.18  0.22     4762     3997    1 #> pred[Chiricozzi 2019: ETN, PASI100]     0.03 0.01 0.02 0.03 0.03 0.04  0.05     4701     3931    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI75]  0.83 0.03 0.77 0.81 0.83 0.84  0.88     4481     3929    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI90]  0.60 0.04 0.52 0.57 0.60 0.63  0.68     4458     4057    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI100] 0.28 0.04 0.21 0.26 0.28 0.31  0.36     4418     4016    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI75]  0.76 0.03 0.70 0.74 0.77 0.79  0.83     4476     3773    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI90]  0.52 0.04 0.43 0.49 0.52 0.55  0.60     4444     3737    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI100] 0.22 0.03 0.16 0.19 0.21 0.24  0.28     4393     3701    1 #> pred[Chiricozzi 2019: SEC_150, PASI75]  0.59 0.04 0.52 0.57 0.59 0.62  0.66     4949     3965    1 #> pred[Chiricozzi 2019: SEC_150, PASI90]  0.33 0.03 0.26 0.30 0.33 0.35  0.40     4810     3887    1 #> pred[Chiricozzi 2019: SEC_150, PASI100] 0.10 0.02 0.07 0.09 0.10 0.11  0.14     4741     3846    1 #> pred[Chiricozzi 2019: SEC_300, PASI75]  0.74 0.02 0.69 0.72 0.74 0.75  0.78     3923     3931    1 #> pred[Chiricozzi 2019: SEC_300, PASI90]  0.48 0.03 0.42 0.46 0.48 0.50  0.54     3912     3974    1 #> pred[Chiricozzi 2019: SEC_300, PASI100] 0.19 0.02 0.15 0.17 0.19 0.20  0.23     3885     3933    1 #> pred[Chiricozzi 2019: UST, PASI75]      0.57 0.05 0.47 0.53 0.57 0.60  0.67     5538     3835    1 #> pred[Chiricozzi 2019: UST, PASI90]      0.31 0.05 0.22 0.28 0.31 0.34  0.41     5591     3798    1 #> pred[Chiricozzi 2019: UST, PASI100]     0.10 0.02 0.06 0.08 0.09 0.11  0.15     5462     3920    1 #>  #> --------------------------------------------------------------- Study: PROSPECT ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[PROSPECT: PBO, PASI75]      0.03 0.01 0.02 0.03 0.03 0.04  0.05     2902     3561    1 #> pred[PROSPECT: PBO, PASI90]      0.01 0.00 0.00 0.00 0.01 0.01  0.01     3098     3528    1 #> pred[PROSPECT: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3269     3415    1 #> pred[PROSPECT: ETN, PASI75]      0.40 0.03 0.33 0.38 0.40 0.42  0.47     5199     3240    1 #> pred[PROSPECT: ETN, PASI90]      0.18 0.02 0.14 0.16 0.18 0.20  0.23     5147     3365    1 #> pred[PROSPECT: ETN, PASI100]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     4967     3490    1 #> pred[PROSPECT: IXE_Q2W, PASI75]  0.85 0.02 0.81 0.84 0.85 0.86  0.88     5001     3224    1 #> pred[PROSPECT: IXE_Q2W, PASI90]  0.64 0.03 0.57 0.62 0.64 0.66  0.70     4949     3615    1 #> pred[PROSPECT: IXE_Q2W, PASI100] 0.32 0.03 0.26 0.30 0.32 0.34  0.38     4883     3727    1 #> pred[PROSPECT: IXE_Q4W, PASI75]  0.79 0.02 0.74 0.78 0.79 0.81  0.84     5310     3627    1 #> pred[PROSPECT: IXE_Q4W, PASI90]  0.56 0.03 0.49 0.53 0.56 0.58  0.62     5152     3587    1 #> pred[PROSPECT: IXE_Q4W, PASI100] 0.25 0.03 0.19 0.23 0.24 0.26  0.30     4930     3584    1 #> pred[PROSPECT: SEC_150, PASI75]  0.63 0.03 0.58 0.61 0.63 0.65  0.68     5720     3577    1 #> pred[PROSPECT: SEC_150, PASI90]  0.36 0.03 0.31 0.35 0.36 0.38  0.42     5332     3598    1 #> pred[PROSPECT: SEC_150, PASI100] 0.12 0.01 0.09 0.11 0.12 0.13  0.15     5036     3554    1 #> pred[PROSPECT: SEC_300, PASI75]  0.77 0.01 0.74 0.76 0.77 0.77  0.79     3785     4056    1 #> pred[PROSPECT: SEC_300, PASI90]  0.52 0.02 0.49 0.51 0.52 0.53  0.55     3560     3888    1 #> pred[PROSPECT: SEC_300, PASI100] 0.22 0.01 0.19 0.21 0.22 0.23  0.24     3510     3811    1 #> pred[PROSPECT: UST, PASI75]      0.61 0.05 0.52 0.58 0.61 0.64  0.70     5992     3337    1 #> pred[PROSPECT: UST, PASI90]      0.35 0.04 0.27 0.32 0.35 0.38  0.44     6096     3471    1 #> pred[PROSPECT: UST, PASI100]     0.12 0.02 0.08 0.10 0.11 0.13  0.17     5841     3581    1 plot(pso_pred_FE_new, ref_line = c(0, 1)) +    facet_grid(rows = \"Study\") +    aes(colour = Category) +   scale_colour_brewer(palette = \"Blues\")"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Smoking cessation","text":"begin setting network. arm-level count data giving number quitting smoking (r) total (n) arm, use function set_agd_arm(). Treatment “intervention” set network reference treatment. Plot network structure.","code":"smknet <- set_agd_arm(smoking,                        study = studyn,                       trt = trtc,                       r = r,                        n = n,                       trt_ref = \"No intervention\") smknet #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected plot(smknet, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"random-effects-nma","dir":"Articles","previous_headings":"","what":"Random effects NMA","title":"Example: Smoking cessation","text":"Following TSD 4, fit random effects NMA model, using nma() function trt_effects = \"random\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), \\(\\textrm{half-N}(5^2)\\) prior distribution -study heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  default, displays model parameters given prior distributions (case \\(d_k\\), \\(\\mu_j\\), \\(\\tau\\)), may changed using prior argument:  Model fit can checked using dic() function residual deviance contributions examined corresponding plot() method  Overall model fit seems adequate, almost points showing good fit (mean residual deviance contribution 1). two points higher residual deviance (.e. worse fit) correspond two zero counts data:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. smkfit <- nma(smknet,                trt_effects = \"random\",               prior_intercept = normal(scale = 100),               prior_trt = normal(scale = 100),               prior_het = normal(scale = 5)) smkfit #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50%      75%    97.5% #> d[Group counselling]          1.10    0.01 0.45     0.27     0.80     1.08     1.38     2.04 #> d[Individual counselling]     0.84    0.01 0.23     0.42     0.68     0.83     0.99     1.32 #> d[Self-help]                  0.49    0.01 0.40    -0.28     0.24     0.49     0.74     1.33 #> lp__                      -5768.15    0.21 6.50 -5781.84 -5772.39 -5767.78 -5763.61 -5756.53 #> tau                           0.84    0.01 0.19     0.54     0.70     0.82     0.95     1.26 #>                           n_eff Rhat #> d[Group counselling]       2044 1.00 #> d[Individual counselling]  1333 1.00 #> d[Self-help]               2102 1.00 #> lp__                        999 1.01 #> tau                        1042 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:54:42 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(smkfit, pars = c(\"d\", \"tau\", \"mu\", \"delta\")) plot_prior_posterior(smkfit) plot_prior_posterior(smkfit, prior = \"het\") (dic_consistency <- dic(smkfit)) #> Residual deviance: 54.2 (on 50 data points) #>                pD: 43.9 #>               DIC: 98.1 plot(dic_consistency) smoking[smoking$r == 0, ] #>    studyn trtn            trtc r  n #> 13      6    1 No intervention 0 33 #> 31     15    1 No intervention 0 20"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"checking-for-inconsistency","dir":"Articles","previous_headings":"","what":"Checking for inconsistency","title":"Example: Smoking cessation","text":"Note: results inconsistency models slightly different Dias et al. (2010, 2011), although overall conclusions . due presence multi-arm trials different ordering treatments, meaning inconsistency parameterised differently within multi-arm trials. results Dias et al. obtained network instead set trtn treatment variable.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"unrelated-mean-effects","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Unrelated mean effects","title":"Example: Smoking cessation","text":"first fit unrelated mean effects (UME) model (Dias et al. 2011) assess consistency assumption. , use function nma(), now argument consistency = \"ume\". Comparing model fit statistics see little choose two models. However, also important examine individual contributions model fit data point two models (-called “dev-dev” plot). Passing two nma_dic objects produced dic() function plot() method produces dev-dev plot:  points lie roughly line equality, evidence inconsistency .","code":"smkfit_ume <- nma(smknet,                    consistency = \"ume\",                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = normal(scale = 5)) smkfit_ume #> A random effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                     mean se_mean   sd     2.5%      25% #> d[Group counselling vs. No intervention]            1.15    0.02 0.82    -0.36     0.61 #> d[Individual counselling vs. No intervention]       0.90    0.01 0.28     0.37     0.72 #> d[Self-help vs. No intervention]                    0.36    0.01 0.59    -0.82    -0.02 #> d[Individual counselling vs. Group counselling]    -0.29    0.01 0.62    -1.53    -0.68 #> d[Self-help vs. Group counselling]                 -0.62    0.02 0.73    -2.08    -1.09 #> d[Self-help vs. Individual counselling]             0.15    0.02 1.06    -2.09    -0.51 #> lp__                                            -5765.30    0.21 6.39 -5778.32 -5769.41 #> tau                                                 0.94    0.01 0.23     0.59     0.78 #>                                                      50%      75%    97.5% n_eff Rhat #> d[Group counselling vs. No intervention]            1.11     1.65     2.87  2103 1.00 #> d[Individual counselling vs. No intervention]       0.89     1.07     1.47  1034 1.00 #> d[Self-help vs. No intervention]                    0.36     0.74     1.53  1829 1.00 #> d[Individual counselling vs. Group counselling]    -0.29     0.11     0.96  2255 1.00 #> d[Self-help vs. Group counselling]                 -0.62    -0.17     0.86  2043 1.00 #> d[Self-help vs. Individual counselling]             0.16     0.84     2.24  2952 1.00 #> lp__                                            -5765.00 -5760.76 -5753.86   952 1.01 #> tau                                                 0.91     1.08     1.48   913 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:55:04 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). dic_consistency #> Residual deviance: 54.2 (on 50 data points) #>                pD: 43.9 #>               DIC: 98.1 (dic_ume <- dic(smkfit_ume)) #> Residual deviance: 53.8 (on 50 data points) #>                pD: 45.2 #>               DIC: 99 plot(dic_consistency, dic_ume, point_alpha = 0.5, interval_alpha = 0.2)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"node-splitting","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Node-splitting","title":"Example: Smoking cessation","text":"Another method assessing inconsistency node-splitting (Dias et al. 2011, 2010). Whereas UME model assesses inconsistency globally, node-splitting assesses inconsistency locally potentially inconsistent comparison (direct indirect evidence) turn. Node-splitting can performed using nma() function argument consistency = \"nodesplit\". default, possible comparisons split (determined get_nodesplits() function). Alternatively, specific comparison comparisons split can provided nodesplit argument. summary() method summarises node-splitting results, displaying direct indirect estimates \\(d_\\mathrm{dir}\\) \\(d_\\mathrm{ind}\\) node-split model, network estimate \\(d_\\mathrm{net}\\) consistency model, inconsistency factor \\(\\omega = d_\\mathrm{dir} - d_\\mathrm{ind}\\), Bayesian \\(p\\)-value inconsistency comparison. Since random effects models fitted, heterogeneity standard deviation \\(\\tau\\) node-split model consistency model also displayed. DIC model fit statistics also provided. DIC inconsistency model unchanged consistency model, node-splits result reduced heterogeneity standard deviation \\(\\tau\\) compared consistency model, Bayesian \\(p\\)-values large. evidence inconsistency. can visually compare posterior distributions direct, indirect, network estimates using plot() method. agreement; posterior densities direct indirect estimates overlap. Notice much indirect information Individual counselling vs. intervention comparison, network (consistency) estimate similar direct estimate comparison.","code":"smk_nodesplit <- nma(smknet,                       consistency = \"nodesplit\",                      trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = normal(scale = 5)) #> Fitting model 1 of 7, node-split: Group counselling vs. No intervention #> Fitting model 2 of 7, node-split: Individual counselling vs. No intervention #> Fitting model 3 of 7, node-split: Self-help vs. No intervention #> Fitting model 4 of 7, node-split: Individual counselling vs. Group counselling #> Fitting model 5 of 7, node-split: Self-help vs. Group counselling #> Fitting model 6 of 7, node-split: Self-help vs. Individual counselling #> Fitting model 7 of 7, consistency model summary(smk_nodesplit) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.11 0.44  0.25  0.82  1.10 1.39  2.01     1888     1664    1 #> d_dir            1.09 0.78 -0.34  0.55  1.05 1.58  2.78     3143     2487    1 #> d_ind            1.13 0.56  0.04  0.77  1.13 1.49  2.28     1671     1998    1 #> omega           -0.04 0.95 -1.80 -0.66 -0.08 0.52  1.88     2323     2305    1 #> tau              0.87 0.20  0.56  0.73  0.85 0.98  1.34     1082     2148    1 #> tau_consistency  0.84 0.18  0.54  0.71  0.81 0.94  1.26     1036     1800    1 #>  #> Residual deviance: 54.4 (on 50 data points) #>                pD: 44.5 #>               DIC: 99 #>  #> Bayesian p-value: 0.94 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.85 0.24  0.39  0.69 0.84 1.00  1.35     1137     1409    1 #> d_dir           0.88 0.26  0.39  0.71 0.87 1.04  1.41     1434     1581    1 #> d_ind           0.58 0.66 -0.68  0.13 0.58 1.00  1.88     1208     1735    1 #> omega           0.30 0.69 -1.11 -0.15 0.30 0.75  1.66     1221     1400    1 #> tau             0.86 0.20  0.56  0.73 0.84 0.98  1.32     1154     1842    1 #> tau_consistency 0.84 0.18  0.54  0.71 0.81 0.94  1.26     1036     1800    1 #>  #> Residual deviance: 53.9 (on 50 data points) #>                pD: 44 #>               DIC: 98 #>  #> Bayesian p-value: 0.64 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.48 0.40 -0.29  0.22  0.48 0.74  1.29     1731     2306    1 #> d_dir            0.31 0.55 -0.75 -0.05  0.30 0.65  1.42     3106     2811    1 #> d_ind            0.72 0.65 -0.54  0.29  0.70 1.13  2.07     2204     2602    1 #> omega           -0.41 0.86 -2.14 -0.97 -0.41 0.14  1.27     2165     2481    1 #> tau              0.88 0.20  0.57  0.74  0.86 1.00  1.34     1138     1956    1 #> tau_consistency  0.84 0.18  0.54  0.71  0.81 0.94  1.26     1036     1800    1 #>  #> Residual deviance: 53.5 (on 50 data points) #>                pD: 44.1 #>               DIC: 97.6 #>  #> Bayesian p-value: 0.62 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.26 0.41 -1.09 -0.53 -0.27  0.01  0.55     2582     2446 1.00 #> d_dir           -0.11 0.49 -1.10 -0.43 -0.12  0.21  0.84     3991     3498 1.00 #> d_ind           -0.56 0.63 -1.84 -0.96 -0.53 -0.14  0.63     1362     1736 1.01 #> omega            0.45 0.68 -0.91  0.01  0.45  0.89  1.82     1585     1924 1.00 #> tau              0.88 0.21  0.56  0.73  0.85  0.99  1.37     1032     1523 1.00 #> tau_consistency  0.84 0.18  0.54  0.71  0.81  0.94  1.26     1036     1800 1.00 #>  #> Residual deviance: 53.4 (on 50 data points) #>                pD: 44 #>               DIC: 97.3 #>  #> Bayesian p-value: 0.49 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.63 0.47 -1.56 -0.94 -0.63 -0.31  0.29     2702     2394    1 #> d_dir           -0.60 0.68 -1.94 -1.04 -0.59 -0.16  0.77     3898     3085    1 #> d_ind           -0.61 0.69 -1.99 -1.04 -0.60 -0.16  0.72     1897     2479    1 #> omega            0.02 0.91 -1.77 -0.55 -0.01  0.58  1.84     2163     2566    1 #> tau              0.88 0.20  0.56  0.74  0.85  0.99  1.36     1320     1810    1 #> tau_consistency  0.84 0.18  0.54  0.71  0.81  0.94  1.26     1036     1800    1 #>  #> Residual deviance: 54.2 (on 50 data points) #>                pD: 44.5 #>               DIC: 98.7 #>  #> Bayesian p-value: 0.99 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.36 0.41 -1.19 -0.64 -0.35 -0.09  0.43     2160     2373    1 #> d_dir            0.07 0.66 -1.23 -0.35  0.07  0.49  1.38     2995     2611    1 #> d_ind           -0.60 0.52 -1.63 -0.94 -0.60 -0.26  0.47     1777     2112    1 #> omega            0.67 0.83 -0.92  0.13  0.67  1.19  2.34     1907     1792    1 #> tau              0.86 0.20  0.56  0.73  0.83  0.97  1.32     1303     1848    1 #> tau_consistency  0.84 0.18  0.54  0.71  0.81  0.94  1.26     1036     1800    1 #>  #> Residual deviance: 53.7 (on 50 data points) #>                pD: 44.1 #>               DIC: 97.8 #>  #> Bayesian p-value: 0.41 plot(smk_nodesplit) +   ggplot2::theme(legend.position = \"bottom\", legend.direct = \"horizontal\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Smoking cessation","text":"Pairwise relative effects, pairwise contrasts all_contrasts = TRUE.  Treatment rankings, rank probabilities, cumulative rank probabilities. set lower_better = FALSE since higher log odds cessation better (outcome positive).","code":"(smk_releff <- relative_effects(smkfit, all_contrasts = TRUE)) #>                                                  mean   sd  2.5%   25%   50%   75% 97.5% #> d[Group counselling vs. No intervention]         1.10 0.45  0.27  0.80  1.08  1.38  2.04 #> d[Individual counselling vs. No intervention]    0.84 0.23  0.42  0.68  0.83  0.99  1.32 #> d[Self-help vs. No intervention]                 0.49 0.40 -0.28  0.24  0.49  0.74  1.33 #> d[Individual counselling vs. Group counselling] -0.26 0.42 -1.12 -0.53 -0.24  0.03  0.55 #> d[Self-help vs. Group counselling]              -0.60 0.50 -1.63 -0.92 -0.59 -0.27  0.35 #> d[Self-help vs. Individual counselling]         -0.35 0.41 -1.16 -0.61 -0.35 -0.07  0.45 #>                                                 Bulk_ESS Tail_ESS Rhat #> d[Group counselling vs. No intervention]            2148     2186    1 #> d[Individual counselling vs. No intervention]       1390     1794    1 #> d[Self-help vs. No intervention]                    2132     2302    1 #> d[Individual counselling vs. Group counselling]     2668     2446    1 #> d[Self-help vs. Group counselling]                  3171     2566    1 #> d[Self-help vs. Individual counselling]             2343     2451    1 plot(smk_releff, ref_line = 0) (smk_ranks <- posterior_ranks(smkfit, lower_better = FALSE)) #>                              mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[No intervention]        3.90 0.31    3   4   4   4     4     2597       NA    1 #> rank[Group counselling]      1.39 0.64    1   1   1   2     3     3015     3021    1 #> rank[Individual counselling] 1.92 0.63    1   2   2   2     3     2379       NA    1 #> rank[Self-help]              2.80 0.69    1   3   3   3     4     2808       NA    1 plot(smk_ranks) (smk_rankprobs <- posterior_rank_probs(smkfit, lower_better = FALSE)) #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.10       0.9 #> d[Group counselling]           0.70      0.23      0.07       0.0 #> d[Individual counselling]      0.24      0.59      0.16       0.0 #> d[Self-help]                   0.06      0.17      0.67       0.1 plot(smk_rankprobs) (smk_cumrankprobs <- posterior_rank_probs(smkfit, lower_better = FALSE, cumulative = TRUE)) #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00       0.1         1 #> d[Group counselling]           0.70      0.92       1.0         1 #> d[Individual counselling]      0.24      0.84       1.0         1 #> d[Self-help]                   0.06      0.24       0.9         1 plot(smk_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Statins for cholesterol lowering","text":"data giving number deaths (r) total (n) arm, use function set_agd_arm() set network. set placebo network reference treatment. prevention variable statins data frame automatically available use meta-regression model.","code":"statin_net <- set_agd_arm(statins,                            study = studyc,                           trt = trtc,                           r = r,                            n = n,                           trt_ref = \"Placebo\") statin_net #> A network with 19 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study     Treatment arms      #>  4S        2: Placebo | Statin #>  Bestehorn 2: Placebo | Statin #>  Brown     2: Placebo | Statin #>  CCAIT     2: Placebo | Statin #>  Downs     2: Placebo | Statin #>  EXCEL     2: Placebo | Statin #>  Furberg   2: Placebo | Statin #>  Haskell   2: Placebo | Statin #>  Jones     2: Placebo | Statin #>  KAPS      2: Placebo | Statin #>  ... plus 9 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 19 #> Reference treatment is: Placebo #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Statins for cholesterol lowering","text":"fit fixed effect (FE) random effects (RE) models, meta-regression binary covariate prevention.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"fixed-effect-meta-regression","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-regression","title":"Example: Statins for cholesterol lowering","text":"start fitting FE model. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Statin}\\), study-specific intercepts \\(\\mu_j\\), regression coefficient \\(\\beta\\). can examine range parameter values implied prior distributions summary() method: model fitted nma() function, fixed effect model specified trt_effects = \"fixed\". regression formula ~ .trt:prevention means interaction primary/secondary prevention treatment included; .trt special variable indicates treatment, prevention original data set. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. statin_fit_FE <- nma(statin_net,                       trt_effects = \"fixed\",                      regression = ~.trt:prevention,                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_reg = normal(scale = 100)) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. statin_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:prevention. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                          mean se_mean   sd     2.5%      25%      50%      75% #> beta[.trtStatin:preventionSecondary]    -0.21    0.00 0.11    -0.42    -0.29    -0.21    -0.14 #> d[Statin]                               -0.10    0.00 0.10    -0.30    -0.17    -0.11    -0.04 #> lp__                                 -7246.67    0.08 3.33 -7254.38 -7248.64 -7246.32 -7244.31 #>                                         97.5% n_eff Rhat #> beta[.trtStatin:preventionSecondary]     0.01  1973    1 #> d[Statin]                                0.09  1951    1 #> lp__                                 -7241.14  1626    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:57:28 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(statin_fit_FE, pars = c(\"d\", \"beta\", \"mu\")) plot_prior_posterior(statin_fit_FE, prior = c(\"trt\", \"reg\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"random-effects-meta-regression","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-regression","title":"Example: Statins for cholesterol lowering","text":"now fit RE model. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Statin}\\), study-specific intercepts \\(\\mu_j\\), regression coefficient \\(\\beta\\). use \\(\\textrm{half-N}(0, 5^2)\\) prior distribution heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: , model fitted nma() function, now trt_effects = \"random\". increase adapt_delta 0.99 remove small number divergent transition errors (default RE models set 0.95). Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. statin_fit_RE <- nma(statin_net,                       trt_effects = \"random\",                      regression = ~.trt:prevention,                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_reg = normal(scale = 100),                      prior_het = half_normal(scale = 5),                      adapt_delta = 0.99) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. statin_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:prevention. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                          mean se_mean   sd     2.5%      25%      50%      75% #> beta[.trtStatin:preventionSecondary]    -0.29    0.01 0.26    -0.90    -0.42    -0.27    -0.15 #> d[Statin]                               -0.07    0.01 0.21    -0.48    -0.18    -0.08     0.03 #> lp__                                 -7255.73    0.15 5.29 -7266.60 -7259.18 -7255.51 -7252.08 #> tau                                      0.25    0.01 0.22     0.01     0.10     0.20     0.36 #>                                         97.5% n_eff Rhat #> beta[.trtStatin:preventionSecondary]     0.18  1177 1.00 #> d[Statin]                                0.37  1254 1.00 #> lp__                                 -7245.96  1198 1.00 #> tau                                      0.76   672 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:57:44 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(statin_fit_RE, pars = c(\"d\", \"beta\", \"mu\", \"delta\")) plot_prior_posterior(statin_fit_RE, prior = c(\"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: Statins for cholesterol lowering","text":"Model fit can checked using dic() function: DIC similar FE RE models, might choose FE model based parsimony. residual deviance statistics larger number data points, suggesting data points fit well. can also examine residual deviance contributions corresponding plot() method.   number studies fit well either model, posterior mean residual deviance contributions greater 1, investigated see substantive differences studies.","code":"(statin_dic_FE <- dic(statin_fit_FE)) #> Residual deviance: 45.9 (on 38 data points) #>                pD: 21.7 #>               DIC: 67.6 (statin_dic_RE <- dic(statin_fit_RE)) #> Residual deviance: 42.5 (on 38 data points) #>                pD: 25.2 #>               DIC: 67.7 plot(statin_dic_FE) plot(statin_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Statins for cholesterol lowering","text":"can produce estimates relative effect statins vs. placebo either primary secondary prevention, using relative_effects() function. newdata argument specifies data frame containing levels covariate prevention interested , study argument used specify column newdata informative label. plot() method may used visually compare estimates:  Model parameters may plotted corresponding plot() method:  Whilst 95% Credible Interval includes zero, suggestion statins effective secondary prevention.","code":"statin_releff_FE <- relative_effects(statin_fit_FE,                                      newdata = data.frame(prevention = c(\"Primary\", \"Secondary\")),                                      study = prevention)  statin_releff_FE #> ---------------------------------------------------------------- Study: Primary ----  #>  #> Covariate values: #>  prevention #>     Primary #>  #>                    mean  sd 2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Primary: Statin] -0.1 0.1 -0.3 -0.17 -0.11 -0.04  0.09     1923     2231    1 #>  #> -------------------------------------------------------------- Study: Secondary ----  #>  #> Covariate values: #>  prevention #>   Secondary #>  #>                       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Secondary: Statin] -0.31 0.05 -0.41 -0.35 -0.31 -0.28 -0.21     4024     3397    1 plot(statin_releff_FE,       ref_line = 0) plot(statin_fit_FE,       pars = \"beta\",       ref_line = 0,      stat = \"halfeye\")"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Thrombolytic treatments","text":"begin setting network. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). default, SK set network reference treatment. Plot network structure.","code":"thrombo_net <- set_agd_arm(thrombolytics,                             study = studyn,                            trt = trtc,                            r = r,                             n = n) thrombo_net #> A network with 50 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms               #>  1     3: SK | Acc t-PA | SK + t-PA #>  2     2: SK | t-PA                 #>  3     2: SK | t-PA                 #>  4     2: SK | t-PA                 #>  5     2: SK | t-PA                 #>  6     3: SK | ASPAC | t-PA         #>  7     2: SK | t-PA                 #>  8     2: SK | t-PA                 #>  9     2: SK | t-PA                 #>  10    2: SK | SK + t-PA            #>  ... plus 40 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 9 #> Total number of studies: 50 #> Reference treatment is: SK #> Network is connected plot(thrombo_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"fixed-effects-nma","dir":"Articles","previous_headings":"","what":"Fixed effects NMA","title":"Example: Thrombolytic treatments","text":"Following TSD 4 (Dias et al. 2011), fit fixed effects NMA model, using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Model fit can checked using dic() function residual deviance contributions examined corresponding plot() method.  number points well fit model, posterior mean residual deviance contributions greater 1.","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. thrombo_fit <- nma(thrombo_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) #> Note: Setting \"SK\" as the network reference treatment. thrombo_fit #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd      2.5%       25%       50%       75%     97.5% n_eff #> d[Acc t-PA]      -0.18    0.00 0.04     -0.26     -0.21     -0.18     -0.15     -0.09  2428 #> d[ASPAC]          0.02    0.00 0.04     -0.06     -0.01      0.02      0.04      0.09  4692 #> d[PTCA]          -0.47    0.00 0.10     -0.68     -0.54     -0.47     -0.41     -0.27  4018 #> d[r-PA]          -0.12    0.00 0.06     -0.24     -0.17     -0.12     -0.08      0.00  3809 #> d[SK + t-PA]     -0.05    0.00 0.05     -0.14     -0.08     -0.05     -0.02      0.04  6441 #> d[t-PA]           0.00    0.00 0.03     -0.06     -0.02      0.00      0.02      0.06  4430 #> d[TNK]           -0.17    0.00 0.08     -0.32     -0.22     -0.17     -0.12     -0.02  4074 #> d[UK]            -0.20    0.00 0.22     -0.65     -0.35     -0.20     -0.05      0.22  4159 #> lp__         -43042.75    0.14 5.28 -43053.94 -43046.17 -43042.53 -43039.07 -43033.24  1515 #>              Rhat #> d[Acc t-PA]     1 #> d[ASPAC]        1 #> d[PTCA]         1 #> d[r-PA]         1 #> d[SK + t-PA]    1 #> d[t-PA]         1 #> d[TNK]          1 #> d[UK]           1 #> lp__            1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:58:07 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(thrombo_fit, pars = c(\"d\", \"mu\")) plot_prior_posterior(thrombo_fit, prior = \"trt\") (dic_consistency <- dic(thrombo_fit)) #> Residual deviance: 105.7 (on 102 data points) #>                pD: 58.5 #>               DIC: 164.1 plot(dic_consistency)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"checking-for-inconsistency","dir":"Articles","previous_headings":"","what":"Checking for inconsistency","title":"Example: Thrombolytic treatments","text":"Note: results inconsistency models slightly different Dias et al. (2010, 2011), although overall conclusions . due presence multi-arm trials different ordering treatments, meaning inconsistency parameterised differently within multi-arm trials. results Dias et al. obtained network instead set trtn treatment variable.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"unrelated-mean-effects-model","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Unrelated mean effects model","title":"Example: Thrombolytic treatments","text":"first fit unrelated mean effects (UME) model (Dias et al. 2011) assess consistency assumption. , use function nma(), now argument consistency = \"ume\". Comparing model fit statistics Whilst UME model fits data better, lower residual deviance, additional parameters UME model mean DIC similar models. However, also important examine individual contributions model fit data point two models (-called “dev-dev” plot). Passing two nma_dic objects produced dic() function plot() method produces dev-dev plot:  four points lying lower right corner plot much lower posterior mean residual deviance UME model, indicating data potentially inconsistent. points correspond trials 44 45, two trials comparing Acc t-PA ASPAC. ASPAC vs. Acc t-PA estimates different consistency model inconsistency (UME) model, suggesting two trials may systematically different others network.","code":"thrombo_fit_ume <- nma(thrombo_net,                         consistency = \"ume\",                        trt_effects = \"fixed\",                        prior_intercept = normal(scale = 100),                        prior_trt = normal(scale = 100)) #> Note: Setting \"SK\" as the network reference treatment. thrombo_fit_ume #> A fixed effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                            mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[Acc t-PA vs. SK]        -0.16    0.00 0.05     -0.25     -0.19     -0.16     -0.12     -0.06 #> d[ASPAC vs. SK]            0.01    0.00 0.04     -0.06     -0.02      0.00      0.03      0.08 #> d[PTCA vs. SK]            -0.67    0.00 0.19     -1.03     -0.79     -0.67     -0.54     -0.31 #> d[r-PA vs. SK]            -0.06    0.00 0.09     -0.24     -0.12     -0.06      0.00      0.11 #> d[SK + t-PA vs. SK]       -0.04    0.00 0.05     -0.13     -0.07     -0.04     -0.01      0.05 #> d[t-PA vs. SK]             0.00    0.00 0.03     -0.06     -0.02      0.00      0.02      0.06 #> d[UK vs. SK]              -0.36    0.01 0.51     -1.37     -0.69     -0.35     -0.03      0.62 #> d[ASPAC vs. Acc t-PA]      1.41    0.01 0.42      0.66      1.12      1.39      1.67      2.32 #> d[PTCA vs. Acc t-PA]      -0.21    0.00 0.12     -0.45     -0.29     -0.21     -0.13      0.01 #> d[r-PA vs. Acc t-PA]       0.02    0.00 0.07     -0.11     -0.02      0.02      0.06      0.15 #> d[TNK vs. Acc t-PA]        0.01    0.00 0.06     -0.12     -0.04      0.01      0.05      0.13 #> d[UK vs. Acc t-PA]         0.14    0.01 0.36     -0.57     -0.11      0.14      0.38      0.85 #> d[t-PA vs. ASPAC]          0.29    0.01 0.36     -0.40      0.04      0.29      0.53      1.02 #> d[t-PA vs. PTCA]           0.54    0.01 0.42     -0.25      0.26      0.53      0.80      1.40 #> d[UK vs. t-PA]            -0.29    0.00 0.34     -0.96     -0.53     -0.28     -0.06      0.36 #> lp__                  -43039.76    0.15 5.83 -43052.16 -43043.55 -43039.42 -43035.69 -43029.22 #>                       n_eff Rhat #> d[Acc t-PA vs. SK]     6597    1 #> d[ASPAC vs. SK]        4695    1 #> d[PTCA vs. SK]         5520    1 #> d[r-PA vs. SK]         6067    1 #> d[SK + t-PA vs. SK]    6532    1 #> d[t-PA vs. SK]         4729    1 #> d[UK vs. SK]           6313    1 #> d[ASPAC vs. Acc t-PA]  4160    1 #> d[PTCA vs. Acc t-PA]   4864    1 #> d[r-PA vs. Acc t-PA]   5289    1 #> d[TNK vs. Acc t-PA]    6282    1 #> d[UK vs. Acc t-PA]     4183    1 #> d[t-PA vs. ASPAC]      5032    1 #> d[t-PA vs. PTCA]       3373    1 #> d[UK vs. t-PA]         6165    1 #> lp__                   1563    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:58:22 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). dic_consistency #> Residual deviance: 105.7 (on 102 data points) #>                pD: 58.5 #>               DIC: 164.1 (dic_ume <- dic(thrombo_fit_ume)) #> Residual deviance: 99.7 (on 102 data points) #>                pD: 66 #>               DIC: 165.6 plot(dic_consistency, dic_ume, show_uncertainty = FALSE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"node-splitting","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Node-splitting","title":"Example: Thrombolytic treatments","text":"Another method assessing inconsistency node-splitting (Dias et al. 2011, 2010). Whereas UME model assesses inconsistency globally, node-splitting assesses inconsistency locally potentially inconsistent comparison (direct indirect evidence) turn. Node-splitting can performed using nma() function argument consistency = \"nodesplit\". default, possible comparisons split (determined get_nodesplits() function). Alternatively, specific comparison comparisons split can provided nodesplit argument. summary() method summarises node-splitting results, displaying direct indirect estimates \\(d_\\mathrm{dir}\\) \\(d_\\mathrm{ind}\\) node-split model, network estimate \\(d_\\mathrm{net}\\) consistency model, inconsistency factor \\(\\omega = d_\\mathrm{dir} - d_\\mathrm{ind}\\), Bayesian \\(p\\)-value inconsistency comparison. DIC model fit statistics also provided. (random effects model fitted, heterogeneity standard deviation \\(\\tau\\) node-split model consistency model also displayed.) Node-splitting ASPAC vs. Acc t-PA comparison results lowest DIC, lower consistency model. posterior distribution inconsistency factor \\(\\omega\\) comparison lies far 0 Bayesian \\(p\\)-value inconsistency small (< 0.01), meaning substantial disagreement direct indirect evidence comparison. can visually compare direct, indirect, network estimates using plot() method.  can also plot posterior distributions inconsistency factors \\(\\omega\\), using plot() method. , specify “halfeye” plot posterior density median credible intervals, customise plot layout standard ggplot2 functions.  Notice posterior distribution inconsistency factor ASPAC vs. Acc t-PA comparison lies far 0, indicating substantial inconsistency direct indirect evidence comparison.","code":"thrombo_nodesplit <- nma(thrombo_net,                           consistency = \"nodesplit\",                          trt_effects = \"fixed\",                          prior_intercept = normal(scale = 100),                          prior_trt = normal(scale = 100)) #> Fitting model 1 of 15, node-split: Acc t-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 2 of 15, node-split: ASPAC vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 3 of 15, node-split: PTCA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 4 of 15, node-split: r-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 5 of 15, node-split: t-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 6 of 15, node-split: UK vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 7 of 15, node-split: ASPAC vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 8 of 15, node-split: PTCA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 9 of 15, node-split: r-PA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 10 of 15, node-split: SK + t-PA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 11 of 15, node-split: UK vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 12 of 15, node-split: t-PA vs. ASPAC #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 13 of 15, node-split: t-PA vs. PTCA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 14 of 15, node-split: UK vs. t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 15 of 15, consistency model #> Note: Setting \"SK\" as the network reference treatment. summary(thrombo_nodesplit) #> Node-splitting models fitted for 14 comparisons. #>  #> ---------------------------------------------------- Node-split Acc t-PA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.18 0.04 -0.26 -0.21 -0.18 -0.15 -0.09     2844     2918    1 #> d_dir -0.16 0.05 -0.25 -0.19 -0.16 -0.13 -0.06     4267     3730    1 #> d_ind -0.25 0.09 -0.42 -0.31 -0.25 -0.19 -0.08      690     1245    1 #> omega  0.09 0.10 -0.11  0.02  0.09  0.16  0.29      815     1417    1 #>  #> Residual deviance: 106.2 (on 102 data points) #>                pD: 59.7 #>               DIC: 165.9 #>  #> Bayesian p-value: 0.35 #>  #> ------------------------------------------------------- Node-split ASPAC vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.02 0.04 -0.05 -0.01  0.02  0.04  0.09     4978     3343    1 #> d_dir  0.01 0.04 -0.07 -0.02  0.01  0.03  0.08     4396     3327    1 #> d_ind  0.42 0.25 -0.07  0.25  0.41  0.57  0.94     2644     2856    1 #> omega -0.41 0.25 -0.92 -0.57 -0.41 -0.24  0.09     2644     2855    1 #>  #> Residual deviance: 104.4 (on 102 data points) #>                pD: 59.9 #>               DIC: 164.3 #>  #> Bayesian p-value: 0.11 #>  #> -------------------------------------------------------- Node-split PTCA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.48 0.10 -0.68 -0.54 -0.48 -0.41 -0.28     3884     3098    1 #> d_dir -0.66 0.18 -1.02 -0.79 -0.66 -0.54 -0.32     4755     3680    1 #> d_ind -0.39 0.12 -0.64 -0.48 -0.39 -0.31 -0.16     3510     3358    1 #> omega -0.27 0.22 -0.69 -0.41 -0.27 -0.12  0.15     4273     2918    1 #>  #> Residual deviance: 105.6 (on 102 data points) #>                pD: 59.9 #>               DIC: 165.5 #>  #> Bayesian p-value: 0.23 #>  #> -------------------------------------------------------- Node-split r-PA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.12 0.06 -0.24 -0.17 -0.12 -0.08  0.00     3718     3067    1 #> d_dir -0.06 0.09 -0.23 -0.12 -0.06  0.00  0.11     5092     2985    1 #> d_ind -0.17 0.08 -0.33 -0.23 -0.17 -0.12 -0.01     2128     2673    1 #> omega  0.11 0.12 -0.12  0.03  0.11  0.19  0.35     2573     2873    1 #>  #> Residual deviance: 106 (on 102 data points) #>                pD: 59.7 #>               DIC: 165.8 #>  #> Bayesian p-value: 0.36 #>  #> -------------------------------------------------------- Node-split t-PA vs. SK ----  #>  #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.0 0.03 -0.06 -0.02  0.00  0.02  0.06     4454     3575    1 #> d_dir  0.0 0.03 -0.06 -0.02  0.00  0.02  0.06     3902     3218    1 #> d_ind  0.2 0.23 -0.25  0.04  0.20  0.35  0.65     1358     2321    1 #> omega -0.2 0.23 -0.65 -0.35 -0.19 -0.04  0.25     1368     2499    1 #>  #> Residual deviance: 106.3 (on 102 data points) #>                pD: 59.7 #>               DIC: 165.9 #>  #> Bayesian p-value: 0.4 #>  #> ---------------------------------------------------------- Node-split UK vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.20 0.22 -0.64 -0.35 -0.20 -0.05  0.25     4571     3501    1 #> d_dir -0.36 0.53 -1.39 -0.70 -0.36 -0.01  0.68     5390     3418    1 #> d_ind -0.17 0.25 -0.64 -0.33 -0.17  0.00  0.33     3909     2993    1 #> omega -0.20 0.59 -1.38 -0.58 -0.20  0.19  0.96     4931     3416    1 #>  #> Residual deviance: 106.7 (on 102 data points) #>                pD: 59.6 #>               DIC: 166.2 #>  #> Bayesian p-value: 0.73 #>  #> ------------------------------------------------- Node-split ASPAC vs. Acc t-PA ----  #>  #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net 0.19 0.06 0.09 0.16 0.19 0.23  0.31     3479     3360    1 #> d_dir 1.42 0.41 0.69 1.14 1.40 1.68  2.27     3848     2962    1 #> d_ind 0.17 0.06 0.06 0.12 0.17 0.20  0.28     3042     3481    1 #> omega 1.25 0.41 0.49 0.97 1.24 1.52  2.11     3706     2985    1 #>  #> Residual deviance: 97.1 (on 102 data points) #>                pD: 60 #>               DIC: 157.1 #>  #> Bayesian p-value: <0.01 #>  #> -------------------------------------------------- Node-split PTCA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.30 0.10 -0.49 -0.37 -0.30 -0.24 -0.11     5215     3448    1 #> d_dir -0.21 0.12 -0.44 -0.29 -0.22 -0.14  0.02     4212     3632    1 #> d_ind -0.48 0.18 -0.83 -0.59 -0.48 -0.36 -0.13     3056     3500    1 #> omega  0.26 0.21 -0.16  0.12  0.26  0.41  0.67     2760     3245    1 #>  #> Residual deviance: 105.2 (on 102 data points) #>                pD: 59.5 #>               DIC: 164.7 #>  #> Bayesian p-value: 0.21 #>  #> -------------------------------------------------- Node-split r-PA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.05 0.06 -0.06  0.01  0.05  0.09  0.16     6460     3636    1 #> d_dir  0.02 0.07 -0.11 -0.03  0.02  0.06  0.15     5009     3440    1 #> d_ind  0.14 0.10 -0.06  0.07  0.13  0.20  0.34     2106     2824    1 #> omega -0.12 0.12 -0.35 -0.20 -0.12 -0.04  0.11     2070     2760    1 #>  #> Residual deviance: 106.3 (on 102 data points) #>                pD: 60 #>               DIC: 166.3 #>  #> Bayesian p-value: 0.33 #>  #> --------------------------------------------- Node-split SK + t-PA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.13 0.05  0.02  0.09  0.13  0.16  0.23     5389     3657    1 #> d_dir  0.13 0.05  0.02  0.09  0.13  0.16  0.24     3921     3284    1 #> d_ind  0.64 0.70 -0.70  0.16  0.62  1.10  2.05     3001     2784    1 #> omega -0.52 0.70 -1.94 -0.98 -0.50 -0.04  0.82     2996     2712    1 #>  #> Residual deviance: 106.5 (on 102 data points) #>                pD: 59.8 #>               DIC: 166.3 #>  #> Bayesian p-value: 0.46 #>  #> ---------------------------------------------------- Node-split UK vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.02 0.23 -0.46 -0.17 -0.02 0.13  0.43     4751     3473    1 #> d_dir  0.14 0.35 -0.53 -0.10  0.14 0.38  0.84     4885     3648    1 #> d_ind -0.13 0.29 -0.71 -0.33 -0.13 0.07  0.42     4727     3584    1 #> omega  0.28 0.45 -0.61 -0.03  0.29 0.59  1.16     4231     3440    1 #>  #> Residual deviance: 106.9 (on 102 data points) #>                pD: 60 #>               DIC: 166.9 #>  #> Bayesian p-value: 0.55 #>  #> ----------------------------------------------------- Node-split t-PA vs. ASPAC ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.01 0.04 -0.08 -0.04 -0.01  0.01  0.06     6979     3179    1 #> d_dir -0.02 0.04 -0.10 -0.05 -0.02  0.00  0.05     4887     3554    1 #> d_ind  0.03 0.06 -0.10 -0.01  0.02  0.07  0.15     3447     3100    1 #> omega -0.05 0.06 -0.17 -0.09 -0.05 -0.01  0.07     3389     3020    1 #>  #> Residual deviance: 106.5 (on 102 data points) #>                pD: 59.9 #>               DIC: 166.4 #>  #> Bayesian p-value: 0.43 #>  #> ------------------------------------------------------ Node-split t-PA vs. PTCA ----  #>  #>       mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net 0.48 0.11  0.28  0.41 0.48 0.55  0.70     4048     3453    1 #> d_dir 0.55 0.41 -0.20  0.26 0.53 0.82  1.37     4409     3246    1 #> d_ind 0.47 0.11  0.26  0.40 0.47 0.55  0.69     3744     3098    1 #> omega 0.07 0.42 -0.69 -0.21 0.06 0.35  0.92     3985     2973    1 #>  #> Residual deviance: 106.5 (on 102 data points) #>                pD: 59.3 #>               DIC: 165.8 #>  #> Bayesian p-value: 0.89 #>  #> -------------------------------------------------------- Node-split UK vs. t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.20 0.23 -0.64 -0.35 -0.20 -0.05  0.24     4698     3570    1 #> d_dir -0.29 0.36 -1.00 -0.53 -0.29 -0.06  0.41     5127     3341    1 #> d_ind -0.14 0.29 -0.71 -0.33 -0.14  0.05  0.42     4697     3141    1 #> omega -0.15 0.46 -1.02 -0.46 -0.15  0.16  0.74     4770     3298    1 #>  #> Residual deviance: 107.2 (on 102 data points) #>                pD: 60.1 #>               DIC: 167.3 #>  #> Bayesian p-value: 0.73 plot(thrombo_nodesplit) plot(thrombo_nodesplit, pars = \"omega\", stat = \"halfeye\", ref_line = 0) +   ggplot2::aes(y = comparison) +   ggplot2::facet_null()"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Thrombolytic treatments","text":"Relative effects pairwise contrasts treatments can produced using relative_effects() function, all_contrasts = TRUE.  Treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(thrombo_releff <- relative_effects(thrombo_fit, all_contrasts = TRUE)) #>                            mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Acc t-PA vs. SK]        -0.18 0.04 -0.26 -0.21 -0.18 -0.15 -0.09     2471     3059    1 #> d[ASPAC vs. SK]            0.02 0.04 -0.06 -0.01  0.02  0.04  0.09     4732     3061    1 #> d[PTCA vs. SK]            -0.47 0.10 -0.68 -0.54 -0.47 -0.41 -0.27     4048     3538    1 #> d[r-PA vs. SK]            -0.12 0.06 -0.24 -0.17 -0.12 -0.08  0.00     3876     3202    1 #> d[SK + t-PA vs. SK]       -0.05 0.05 -0.14 -0.08 -0.05 -0.02  0.04     6484     3476    1 #> d[t-PA vs. SK]             0.00 0.03 -0.06 -0.02  0.00  0.02  0.06     4444     3307    1 #> d[TNK vs. SK]             -0.17 0.08 -0.32 -0.22 -0.17 -0.12 -0.02     4100     3413    1 #> d[UK vs. SK]              -0.20 0.22 -0.65 -0.35 -0.20 -0.05  0.22     4297     2989    1 #> d[ASPAC vs. Acc t-PA]      0.19 0.06  0.08  0.16  0.19  0.23  0.31     3227     3339    1 #> d[PTCA vs. Acc t-PA]      -0.30 0.10 -0.49 -0.36 -0.30 -0.23 -0.11     5402     3758    1 #> d[r-PA vs. Acc t-PA]       0.05 0.06 -0.05  0.02  0.05  0.09  0.16     6686     3423    1 #> d[SK + t-PA vs. Acc t-PA]  0.13 0.05  0.02  0.09  0.13  0.16  0.23     5033     3145    1 #> d[t-PA vs. Acc t-PA]       0.18 0.05  0.08  0.14  0.18  0.22  0.29     3005     3144    1 #> d[TNK vs. Acc t-PA]        0.01 0.06 -0.11 -0.04  0.01  0.05  0.13     6038     3555    1 #> d[UK vs. Acc t-PA]        -0.02 0.22 -0.47 -0.18 -0.02  0.13  0.40     4344     3053    1 #> d[PTCA vs. ASPAC]         -0.49 0.11 -0.70 -0.56 -0.49 -0.42 -0.28     4136     3709    1 #> d[r-PA vs. ASPAC]         -0.14 0.07 -0.28 -0.19 -0.14 -0.09  0.00     4073     2875    1 #> d[SK + t-PA vs. ASPAC]    -0.07 0.06 -0.19 -0.10 -0.07 -0.03  0.05     5734     3547    1 #> d[t-PA vs. ASPAC]         -0.01 0.04 -0.09 -0.04 -0.01  0.01  0.06     7935     3151    1 #> d[TNK vs. ASPAC]          -0.19 0.08 -0.35 -0.25 -0.19 -0.13 -0.03     4260     3360    1 #> d[UK vs. ASPAC]           -0.22 0.22 -0.67 -0.37 -0.22 -0.07  0.21     4279     3459    1 #> d[r-PA vs. PTCA]           0.35 0.11  0.13  0.27  0.35  0.42  0.57     5852     3929    1 #> d[SK + t-PA vs. PTCA]      0.43 0.11  0.21  0.35  0.42  0.50  0.63     5083     3440    1 #> d[t-PA vs. PTCA]           0.48 0.11  0.27  0.41  0.48  0.55  0.68     4113     3674    1 #> d[TNK vs. PTCA]            0.30 0.11  0.08  0.22  0.30  0.38  0.53     6575     3490    1 #> d[UK vs. PTCA]             0.27 0.24 -0.20  0.11  0.28  0.44  0.74     4922     3301    1 #> d[SK + t-PA vs. r-PA]      0.07 0.07 -0.07  0.03  0.07  0.12  0.21     6069     3123    1 #> d[t-PA vs. r-PA]           0.13 0.07 -0.01  0.08  0.13  0.17  0.26     4008     3065    1 #> d[TNK vs. r-PA]           -0.05 0.08 -0.21 -0.10 -0.05  0.01  0.12     8420     2981    1 #> d[UK vs. r-PA]            -0.08 0.23 -0.53 -0.23 -0.08  0.07  0.36     4481     3372    1 #> d[t-PA vs. SK + t-PA]      0.05 0.06 -0.06  0.02  0.05  0.09  0.16     5517     3607    1 #> d[TNK vs. SK + t-PA]      -0.12 0.08 -0.28 -0.18 -0.12 -0.07  0.04     5964     3716    1 #> d[UK vs. SK + t-PA]       -0.15 0.22 -0.60 -0.30 -0.15  0.00  0.28     4452     3262    1 #> d[TNK vs. t-PA]           -0.17 0.08 -0.33 -0.23 -0.17 -0.12 -0.01     4400     3353    1 #> d[UK vs. t-PA]            -0.20 0.22 -0.64 -0.35 -0.20 -0.06  0.23     4387     3175    1 #> d[UK vs. TNK]             -0.03 0.23 -0.50 -0.18 -0.03  0.13  0.41     4563     3048    1 plot(thrombo_releff, ref_line = 0) (thrombo_ranks <- posterior_ranks(thrombo_fit)) #>                 mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[SK]        7.46 0.95    6   7   7   8     9     3754       NA    1 #> rank[Acc t-PA]  3.18 0.81    2   3   3   4     5     4540     3643    1 #> rank[ASPAC]     7.96 1.15    5   7   8   9     9     4600       NA    1 #> rank[PTCA]      1.13 0.34    1   1   1   1     2     3699     3622    1 #> rank[r-PA]      4.42 1.22    2   4   4   5     7     5059     3367    1 #> rank[SK + t-PA] 5.96 1.24    4   5   6   6     9     5630       NA    1 #> rank[t-PA]      7.47 1.10    5   7   8   8     9     4840       NA    1 #> rank[TNK]       3.47 1.23    2   3   3   4     6     5668     3646    1 #> rank[UK]        3.95 2.71    1   2   3   5     9     4723       NA    1 plot(thrombo_ranks) (thrombo_rankprobs <- posterior_rank_probs(thrombo_fit)) #>              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] p_rank[8] #> d[SK]             0.00      0.00      0.00      0.00      0.02      0.13      0.39      0.32 #> d[Acc t-PA]       0.00      0.20      0.46      0.29      0.05      0.00      0.00      0.00 #> d[ASPAC]          0.00      0.00      0.00      0.00      0.03      0.10      0.19      0.25 #> d[PTCA]           0.87      0.12      0.00      0.00      0.00      0.00      0.00      0.00 #> d[r-PA]           0.00      0.06      0.16      0.30      0.36      0.10      0.02      0.01 #> d[SK + t-PA]      0.00      0.00      0.01      0.07      0.26      0.45      0.09      0.07 #> d[t-PA]           0.00      0.00      0.00      0.00      0.04      0.15      0.29      0.33 #> d[TNK]            0.00      0.24      0.31      0.25      0.15      0.03      0.01      0.00 #> d[UK]             0.12      0.37      0.06      0.09      0.10      0.05      0.02      0.02 #>              p_rank[9] #> d[SK]             0.15 #> d[Acc t-PA]       0.00 #> d[ASPAC]          0.44 #> d[PTCA]           0.00 #> d[r-PA]           0.01 #> d[SK + t-PA]      0.06 #> d[t-PA]           0.19 #> d[TNK]            0.00 #> d[UK]             0.15 plot(thrombo_rankprobs) (thrombo_cumrankprobs <- posterior_rank_probs(thrombo_fit, cumulative = TRUE)) #>              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] p_rank[8] #> d[SK]             0.00      0.00      0.00      0.00      0.02      0.14      0.53      0.85 #> d[Acc t-PA]       0.00      0.20      0.66      0.95      1.00      1.00      1.00      1.00 #> d[ASPAC]          0.00      0.00      0.00      0.00      0.03      0.13      0.31      0.56 #> d[PTCA]           0.87      1.00      1.00      1.00      1.00      1.00      1.00      1.00 #> d[r-PA]           0.00      0.06      0.21      0.51      0.87      0.96      0.98      0.99 #> d[SK + t-PA]      0.00      0.00      0.01      0.08      0.34      0.79      0.88      0.94 #> d[t-PA]           0.00      0.00      0.00      0.00      0.04      0.19      0.48      0.81 #> d[TNK]            0.00      0.25      0.55      0.80      0.95      0.99      0.99      1.00 #> d[UK]             0.12      0.49      0.56      0.65      0.75      0.80      0.82      0.85 #>              p_rank[9] #> d[SK]                1 #> d[Acc t-PA]          1 #> d[ASPAC]             1 #> d[PTCA]              1 #> d[r-PA]              1 #> d[SK + t-PA]         1 #> d[t-PA]              1 #> d[TNK]               1 #> d[UK]                1 plot(thrombo_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: White blood cell transfusion","text":"begin setting network - just pairwise meta-analysis. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). set “Control” reference treatment.","code":"tr_net <- set_agd_arm(transfusion,                             study = studyc,                            trt = trtc,                            r = r,                             n = n,                            trt_ref = \"Control\") tr_net #> A network with 6 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms           #>  Bow 1984      2: Control | Transfusion #>  Herzig 1977   2: Control | Transfusion #>  Higby 1975    2: Control | Transfusion #>  Scali 1978    2: Control | Transfusion #>  Vogler 1977   2: Control | Transfusion #>  Winston 1982a 2: Control | Transfusion #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 6 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: White blood cell transfusion","text":"fit two random effects models, first non-informative prior heterogeneity, using informative prior described Turner et al. (2012).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"random-effects-meta-analysis-with-non-informative-heterogeneity-prior","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis with non-informative heterogeneity prior","title":"Example: White blood cell transfusion","text":"fit random effects model using nma() function trt_effects = \"random\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), non-informative \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  posterior distribution heterogeneity variance \\(\\tau^2\\) summarised ","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. tr_fit_RE_noninf <- nma(tr_net,                          trt_effects = \"random\",                         prior_intercept = normal(scale = 100),                         prior_trt = normal(scale = 100),                         prior_het = half_normal(scale = 5)) tr_fit_RE_noninf #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Transfusion]   -1.16    0.03 1.03   -3.40   -1.71   -1.10   -0.58    0.67  1173    1 #> lp__           -134.23    0.08 3.02 -141.00 -136.13 -133.91 -132.02 -129.29  1309    1 #> tau               1.90    0.03 1.08    0.58    1.17    1.63    2.32    4.64  1538    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 15:01:21 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(tr_fit_RE_noninf, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(tr_fit_RE_noninf, prior = \"het\") noninf_tau <- as.array(tr_fit_RE_noninf, pars = \"tau\") noninf_tausq <- noninf_tau^2 names(noninf_tausq) <- \"tausq\" summary(noninf_tausq) #>       mean   sd 2.5%  25%  50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq 4.77 6.92 0.34 1.37 2.67 5.4 21.57     1526     2186    1"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"random-effects-meta-analysis-with-informative-heterogeneity-prior","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis with informative heterogeneity prior","title":"Example: White blood cell transfusion","text":"Keeping rest model setup , now use informative \\(\\textrm{log-N}(-3.93, 1.51^2)\\) prior heterogeneity variance \\(\\tau^2\\). can examine range parameter values implied prior distribution summary() method: Fitting RE model, specify log_normal prior distribution prior_het argument, set prior_het_type = \"var\" indicate prior distribution variance scale (instead standard deviation, default). Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Note: heterogeneity variance \\(\\tau^2\\) plotted since prior specified \\(\\tau^2\\). posterior distribution heterogeneity variance \\(\\tau^2\\) summarised ","code":"summary(log_normal(-3.93, 1.51)) #> A log-Normal prior distribution: location = -3.93, scale = 1.51. #> 50% of the prior density lies between 0.01 and 0.05. #> 95% of the prior density lies between 0 and 0.38. tr_fit_RE_inf <- nma(tr_net,                       trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = log_normal(-3.93, 1.51),                      prior_het_type = \"var\") #> Warning: There were 1 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems tr_fit_RE_inf #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Transfusion]   -0.78    0.01 0.44   -1.73   -1.05   -0.75   -0.49   -0.02  2140 1.00 #> lp__           -141.14    0.07 2.85 -147.58 -142.80 -140.79 -139.11 -136.56  1530 1.00 #> tau               0.50    0.01 0.37    0.05    0.21    0.43    0.70    1.36  1155 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 15:01:27 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(tr_fit_RE_inf, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(tr_fit_RE_inf, prior = \"het\") inf_tau <- as.array(tr_fit_RE_inf, pars = \"tau\") inf_tausq <- inf_tau^2 names(inf_tausq) <- \"tausq\" summary(inf_tausq) #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq 0.38 0.61    0 0.04 0.18 0.49  1.84     1196     2616 1.01"},{"path":[]},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David M. Phillippo. Author, maintainer.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Phillippo DM (2023). multinma: Bayesian Network Meta-Analysis Individual Aggregate Data. doi:10.5281/zenodo.3904454, R package version 0.5.1.9001, https://dmphillippo.github.io/multinma/. Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189-1210. doi:10.1111/rssa.12579.","code":"@Manual{,   title = {multinma: Bayesian Network Meta-Analysis of Individual and Aggregate Data},   author = {David M. Phillippo},   year = {2023},   note = {R package version 0.5.1.9001},   url = {https://dmphillippo.github.io/multinma/},   doi = {10.5281/zenodo.3904454}, } @Article{,   title = {Multilevel Network Meta-Regression for population-adjusted treatment comparisons},   author = {David M. Phillippo and Sofia Dias and A. E. Ades and Mark Belger and Alan Brnabic and Alexander Schacht and Daniel Saure and Zbigniew Kadziola and Nicky J. Welton},   year = {2020},   doi = {10.1111/rssa.12579},   journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},   volume = {183},   number = {3},   pages = {1189-1210}, }"},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"multinma-network-meta-analysis-of-individual-and-aggregate-data-in-stan-","dir":"","previous_headings":"","what":"Bayesian network meta-analysis of individual and aggregate data","title":"Bayesian network meta-analysis of individual and aggregate data","text":"multinma package implements network meta-analysis, network meta-regression, multilevel network meta-regression models combine evidence network studies treatments using either aggregate data individual patient data study (Phillippo et al. 2020; Phillippo 2019). Models estimated Bayesian framework using Stan (Carpenter et al. 2017).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian network meta-analysis of individual and aggregate data","text":"can install released version multinma CRAN : development version can installed R-universe : source GitHub : Installing source requires rstan package installed configured. See installation guide .","code":"install.packages(\"multinma\") install.packages(\"multinma\", repos = c(\"https://dmphillippo.r-universe.dev\", getOption(\"repos\"))) # install.packages(\"devtools\") devtools::install_github(\"dmphillippo/multinma\")"},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting started","title":"Bayesian network meta-analysis of individual and aggregate data","text":"good place start package vignettes walk example analyses, see vignette(\"vignette_overview\") overview. series NICE Technical Support Documents evidence synthesis gives detailed introduction network meta-analysis: Dias, S. et al. (2011). “NICE DSU Technical Support Documents 1-7: Evidence Synthesis Decision Making.” National Institute Health Care Excellence. Available https://www.sheffield.ac.uk/nice-dsu/tsds. Multilevel network meta-regression set following methods paper: Phillippo, D. M. et al. (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3):1189-1210. doi: 10.1111/rssa.12579.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"citing-multinma","dir":"","previous_headings":"","what":"Citing multinma","title":"Bayesian network meta-analysis of individual and aggregate data","text":"multinma package can cited follows: Phillippo, D. M. (2023). multinma: Bayesian Network Meta-Analysis Individual Aggregate Data. R package version 0.5.1.9000, doi: 10.5281/zenodo.3904454. fitting ML-NMR models, please cite methods paper: Phillippo, D. M. et al. (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3):1189-1210. doi: 10.1111/rssa.12579.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":null,"dir":"Reference","previous_headings":"","what":"The Bernoulli Distribution — qbern","title":"The Bernoulli Distribution — qbern","text":"quantile function qbern Bernoulli distribution, success probability prob. equivalent qbinom(p, 1, prob).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Bernoulli Distribution — qbern","text":"","code":"qbern(p, prob, lower.tail = TRUE, log.p = FALSE)  pbern(q, prob, lower.tail = TRUE, log.p = FALSE)  dbern(x, prob, log = FALSE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Bernoulli Distribution — qbern","text":"p vector probabilities prob probability success lower.tail, log.p, log see stats::Binomial x, q vector quantiles","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":null,"dir":"Reference","previous_headings":"","what":"The Gamma distribution — qgamma","title":"The Gamma distribution — qgamma","text":"provide convenient extensions [dpq]gamma functions, allow distribution specified terms mean standard deviation, instead shape rate/scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Gamma distribution — qgamma","text":"","code":"qgamma(   p,   shape,   rate = 1,   scale = 1/rate,   lower.tail = TRUE,   log.p = FALSE,   mean,   sd )  dgamma(x, shape, rate = 1, scale = 1/rate, log = FALSE, mean, sd)  pgamma(   q,   shape,   rate = 1,   scale = 1/rate,   lower.tail = TRUE,   log.p = FALSE,   mean,   sd )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Gamma distribution — qgamma","text":"p vector probabilities shape, rate, scale, log, lower.tail, log.p see stats::GammaDist mean, sd mean standard deviation, overriding shape rate scale specified x, q vector quantiles","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_pso_mlnmr.html","id":null,"dir":"Reference","previous_headings":"","what":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","title":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","text":"Calling example(\"example_pso_mlnmr\") run ML-NMR model plaque psoriasis IPD AgD, using code Examples section . resulting stan_nma object pso_fit available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_pso_mlnmr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","text":"Plaque psoriasis ML-NMR use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_pso_mlnmr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","text":"","code":"# Set up plaque psoriasis network combining IPD and AgD library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.  # \\donttest{ # Fitting a ML-NMR model. # Specify a regression model to include effect modifier interactions for five # covariates, along with main (prognostic) effects. We use a probit link and # specify that the two-parameter Binomial approximation for the aggregate-level # likelihood should be used. We set treatment-covariate interactions to be equal # within each class. We narrow the possible range for random initial values with # init_r = 0.1, since probit models in particular are often hard to initialise. # Using the QR decomposition greatly improves sampling efficiency here, as is # often the case for regression models. pso_fit <- nma(pso_net, refresh = if (interactive()) 200 else 0,                trt_effects = \"fixed\",                link = \"probit\",                likelihood = \"bernoulli2\",                regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                class_interactions = \"common\",                prior_intercept = normal(scale = 10),                prior_trt = normal(scale = 10),                prior_reg = normal(scale = 10),                init_r = 0.1,                QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25% #> beta[durnpso]                           0.04    0.00 0.06    -0.08     0.00 #> beta[prevsys]                          -0.14    0.00 0.16    -0.46    -0.25 #> beta[bsa]                              -0.05    0.01 0.44    -0.96    -0.35 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02 #> beta[psa]                              -0.08    0.00 0.18    -0.44    -0.20 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.14    -0.06 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.19    -0.19     0.07 #> beta[prevsys:.trtclassIL blocker]       0.07    0.00 0.18    -0.29    -0.05 #> beta[bsa:.trtclassTNFa blocker]         0.04    0.01 0.52    -0.96    -0.32 #> beta[bsa:.trtclassIL blocker]           0.28    0.01 0.48    -0.61    -0.06 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.19 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12 #> beta[psa:.trtclassTNFa blocker]        -0.05    0.00 0.21    -0.47    -0.19 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.19    -0.36    -0.12 #> d[ETN]                                  1.55    0.00 0.08     1.40     1.50 #> d[IXE_Q2W]                              2.95    0.00 0.08     2.79     2.90 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.39     2.49 #> d[SEC_150]                              2.14    0.00 0.12     1.92     2.06 #> d[SEC_300]                              2.45    0.00 0.12     2.22     2.37 #> lp__                                -1576.41    0.08 3.49 -1584.30 -1578.44 #>                                          50%      75%    97.5% n_eff Rhat #> beta[durnpso]                           0.04     0.09     0.16  5309    1 #> beta[prevsys]                          -0.14    -0.03     0.18  6291    1 #> beta[bsa]                              -0.04     0.25     0.77  5528    1 #> beta[weight]                            0.04     0.06     0.10  5339    1 #> beta[psa]                              -0.08     0.04     0.26  5592    1 #> beta[durnpso:.trtclassTNFa blocker]    -0.03     0.02     0.12  5373    1 #> beta[durnpso:.trtclassIL blocker]      -0.01     0.03     0.12  5920    1 #> beta[prevsys:.trtclassTNFa blocker]     0.19     0.32     0.56  6226    1 #> beta[prevsys:.trtclassIL blocker]       0.07     0.19     0.42  6892    1 #> beta[bsa:.trtclassTNFa blocker]         0.03     0.40     1.06  5619    1 #> beta[bsa:.trtclassIL blocker]           0.25     0.60     1.23  6734    1 #> beta[weight:.trtclassTNFa blocker]     -0.17    -0.14    -0.10  6692    1 #> beta[weight:.trtclassIL blocker]       -0.10    -0.08    -0.04  6270    1 #> beta[psa:.trtclassTNFa blocker]        -0.05     0.09     0.37  6337    1 #> beta[psa:.trtclassIL blocker]           0.01     0.14     0.40  6683    1 #> d[ETN]                                  1.55     1.61     1.70  4061    1 #> d[IXE_Q2W]                              2.95     3.01     3.12  5398    1 #> d[IXE_Q4W]                              2.54     2.59     2.69  4854    1 #> d[SEC_150]                              2.14     2.22     2.37  4686    1 #> d[SEC_300]                              2.44     2.52     2.69  4924    1 #> lp__                                -1576.02 -1573.88 -1570.74  1704    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:24:02 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"pso_net\", pso_net, .GlobalEnv)   assign(\"pso_fit\", pso_fit, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_fe.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking FE NMA — example_smk_fe","title":"Example smoking FE NMA — example_smk_fe","text":"Calling example(\"example_smk_fe\") run fixed effects NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_FE available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_fe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking FE NMA — example_smk_fe","text":"Smoking FE NMA use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_fe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking FE NMA — example_smk_fe","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting a fixed effect model smk_fit_FE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100))  smk_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          0.84    0.00 0.18     0.50     0.72     0.84 #> d[Individual counselling]     0.76    0.00 0.06     0.65     0.72     0.76 #> d[Self-help]                  0.22    0.00 0.12    -0.02     0.14     0.23 #> lp__                      -5859.35    0.09 3.70 -5867.27 -5861.77 -5859.02 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          0.96     1.20  1928    1 #> d[Individual counselling]     0.80     0.88  1868    1 #> d[Self-help]                  0.31     0.46  2254    1 #> lp__                      -5856.69 -5852.98  1523    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:25:44 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_FE\", smk_fit_FE, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_nodesplit.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking node-splitting — example_smk_nodesplit","title":"Example smoking node-splitting — example_smk_nodesplit","text":"Calling example(\"example_smk_nodesplit\") run node-splitting models smoking cessation data, using code Examples section . resulting nma_nodesplit_df object smk_fit_RE_nodesplit available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_nodesplit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking node-splitting — example_smk_nodesplit","text":"Smoking node-splitting use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_nodesplit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking node-splitting — example_smk_nodesplit","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting all possible node-splitting models smk_fit_RE_nodesplit <- nma(smk_net, refresh = if (interactive()) 200 else 0,                             consistency = \"nodesplit\",                             trt_effects = \"random\",                             prior_intercept = normal(scale = 100),                             prior_trt = normal(scale = 100),                             prior_het = normal(scale = 5)) #> Fitting model 1 of 7, node-split: Group counselling vs. No intervention #> Fitting model 2 of 7, node-split: Individual counselling vs. No intervention #> Fitting model 3 of 7, node-split: Self-help vs. No intervention #> Fitting model 4 of 7, node-split: Individual counselling vs. Group counselling #> Fitting model 5 of 7, node-split: Self-help vs. Group counselling #> Fitting model 6 of 7, node-split: Self-help vs. Individual counselling #> Fitting model 7 of 7, consistency model # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_RE_nodesplit\", smk_fit_RE_nodesplit, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_re.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking RE NMA — example_smk_re","title":"Example smoking RE NMA — example_smk_re","text":"Calling example(\"example_smk_re\") run random effects NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_RE available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_re.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking RE NMA — example_smk_re","text":"Smoking RE NMA use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_re.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking RE NMA — example_smk_re","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting a random effects model smk_fit_RE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = normal(scale = 5))  smk_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          1.11    0.01 0.43     0.31     0.82     1.09 #> d[Individual counselling]     0.85    0.01 0.24     0.40     0.68     0.84 #> d[Self-help]                  0.50    0.01 0.41    -0.28     0.22     0.49 #> lp__                      -5767.94    0.20 6.45 -5781.26 -5772.08 -5767.73 #> tau                           0.84    0.01 0.18     0.55     0.71     0.82 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          1.39     2.00  2226 1.00 #> d[Individual counselling]     1.00     1.32  1192 1.01 #> d[Self-help]                  0.76     1.33  1633 1.00 #> lp__                      -5763.57 -5755.99  1080 1.00 #> tau                           0.94     1.27  1126 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:28:15 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_RE\", smk_fit_RE, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_ume.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking UME NMA — example_smk_ume","title":"Example smoking UME NMA — example_smk_ume","text":"Calling example(\"example_smk_ume\") run unrelated mean effects (inconsistency) NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_RE_UME available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_ume.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking UME NMA — example_smk_ume","text":"Smoking UME NMA use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_ume.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking UME NMA — example_smk_ume","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting an unrelated mean effects (inconsistency) model smk_fit_RE_UME <- nma(smk_net, refresh = if (interactive()) 200 else 0,                       consistency = \"ume\",                       trt_effects = \"random\",                       prior_intercept = normal(scale = 100),                       prior_trt = normal(scale = 100),                       prior_het = normal(scale = 5))  smk_fit_RE_UME #> A random effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                     mean se_mean   sd     2.5% #> d[Group counselling vs. No intervention]            1.14    0.02 0.82    -0.37 #> d[Individual counselling vs. No intervention]       0.91    0.01 0.28     0.39 #> d[Self-help vs. No intervention]                    0.34    0.01 0.59    -0.84 #> d[Individual counselling vs. Group counselling]    -0.28    0.01 0.63    -1.51 #> d[Self-help vs. Group counselling]                 -0.63    0.01 0.71    -2.05 #> d[Self-help vs. Individual counselling]             0.18    0.02 1.04    -1.86 #> lp__                                            -5764.77    0.21 6.27 -5777.99 #> tau                                                 0.94    0.01 0.23     0.59 #>                                                      25%      50%      75% #> d[Group counselling vs. No intervention]            0.60     1.12     1.65 #> d[Individual counselling vs. No intervention]       0.73     0.90     1.08 #> d[Self-help vs. No intervention]                   -0.02     0.34     0.71 #> d[Individual counselling vs. Group counselling]    -0.69    -0.28     0.13 #> d[Self-help vs. Group counselling]                 -1.10    -0.63    -0.16 #> d[Self-help vs. Individual counselling]            -0.49     0.18     0.85 #> lp__                                            -5768.71 -5764.55 -5760.32 #> tau                                                 0.78     0.91     1.08 #>                                                    97.5% n_eff Rhat #> d[Group counselling vs. No intervention]            2.87  2721    1 #> d[Individual counselling vs. No intervention]       1.50  1029    1 #> d[Self-help vs. No intervention]                    1.56  2235    1 #> d[Individual counselling vs. Group counselling]     0.99  2402    1 #> d[Self-help vs. Group counselling]                  0.74  2667    1 #> d[Self-help vs. Individual counselling]             2.25  3381    1 #> lp__                                            -5753.55   875    1 #> tau                                                 1.45   974    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:28:30 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_RE_UME\", smk_fit_RE_UME, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/adapt_delta.html","id":null,"dir":"Reference","previous_headings":"","what":"Target average acceptance probability — adapt_delta","title":"Target average acceptance probability — adapt_delta","text":"Stan control argument adapt_delta sets target average acceptance probability -U-Turn Sampler (NUTS) used Stan.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/adapt_delta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Target average acceptance probability — adapt_delta","text":"default value adapt_delta used nma() 0.8 fixed effect models, 0.95 random effects models. need change adapt_delta unless see warning message divergent transitions. Increasing adapt_delta default value closer 1 means Stan use smaller step size, making sampling slower robust, resulting fewer divergent transitions. details see Stan documentation available https://mc-stan.org/users/documentation/.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":null,"dir":"Reference","previous_headings":"","what":"Add numerical integration points to aggregate data — add_integration","title":"Add numerical integration points to aggregate data — add_integration","text":"add_integration() generic creates Quasi-Monte Carlo numerical integration points using Gaussian copula Sobol' sequences, described Phillippo et al. (2020) . Methods available networks stored nma_data objects, data frames. function unnest_integration() unnests integration points stored data frame, aid plotting exploration.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add numerical integration points to aggregate data — add_integration","text":"","code":"add_integration(x, ...)  # S3 method for default add_integration(x, ...)  # S3 method for data.frame add_integration(   x,   ...,   cor = NULL,   cor_adjust = NULL,   n_int = 64L,   int_args = list() )  # S3 method for nma_data add_integration(   x,   ...,   cor = NULL,   cor_adjust = NULL,   n_int = 64L,   int_args = list() )  unnest_integration(data)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add numerical integration points to aggregate data — add_integration","text":"x nma_data object, created set_*() functions combine_network(), data frame ... Distributions covariates, see \"Details\" cor Correlation matrix use generating integration points. default, takes weighted correlation matrix IPD studies. Rows columns match order covariates specified .... cor_adjust Adjustment apply correlation matrix given cor (computed IPD cor = NULL) obtain Gaussian copula correlations, either \"spearman\", \"pearson\", \"none\", see \"Details\". default cor = NULL \"spearman\", otherwise default \"pearson\". n_int Number integration points generate, default 64. Powers 2 recommended, expected particularly efficient QMC integration. int_args named list arguments pass sobol() data Data frame nested integration points, stored list columns .int_<variable name>","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add numerical integration points to aggregate data — add_integration","text":"nma_data method, object class nma_data. data.frame method, input data frame returned (tibble) added column covariate (prefixed \".int_\"), containing numerical integration points nested length-n_int vectors within row. unnest_integration(), data frame integration points unnested.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add numerical integration points to aggregate data — add_integration","text":"arguments passed ... specify distributions covariates. Argument names specify name covariate, match covariate name IPD (IPD present). required marginal distribution specified using function distr(). argument cor_adjust specifies correlation matrix given cor (computed IPD cor = NULL) adjusted obtain correlation matrix Gaussian copula, using formulae Xiao Zhou (2018) . cor_adjust = \"spearman\" used correlations cor computed using Spearman's rank correlation. Correlations continuous covariates reproduced exactly integration points. Correlations discrete covariates reproduced approximately. default cor = NULL correlations calculated IPD studies. cor_adjust = \"pearson\" used correlations cor computed using Pearson's product-moment correlation. Correlations Normal covariates reproduced exactly integration points, others reproduced approximately. Correlations discrete covariates reproduced approximately (identically cor_adjust   = \"spearman\"). default cor provided user, since cor() defaults method = \"pearson\" Pearson correlations likely reported published data. However, recommend providing Spearman correlations (e.g. cor(., method = \"spearman\")) using cor_adjust = \"spearman\" possible. cor_adjust = \"none\" allows user specify correlation matrix Gaussian copula directly; adjustment applied. cor_adjust = \"legacy\" also available, reproduces exactly behaviour version 0.3.0 earlier. similar cor_adjust =   \"none\", unadjusted Spearman correlations used cor = NULL. adding integration points network object correlation matrix used stored $int_cor, copula correlation matrix adjustment used stored attributes $int_cor. correlation matrix passed add_integration() (e.g. reuse correlations external target population) detected, correct setting cor_adjust automatically applied.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Add numerical integration points to aggregate data — add_integration","text":"Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 . Xiao Q, Zhou S (2018). “Matching correlation coefficient Gaussian copula.” Communications Statistics - Theory Methods, 48(7), 1728--1747. doi:10.1080/03610926.2018.1439962 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add numerical integration points to aggregate data — add_integration","text":"","code":"## Plaque psoriasis ML-NMR - network setup and adding integration points # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.   ## Adding integration points to a data frame, e.g. for prediction # Define a data frame of covariate summaries new_agd_int <- data.frame(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1)  # Adding integration points, using the weighted average correlation matrix # computed for the plaque psoriasis network new_agd_int <- add_integration(new_agd_int,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   cor = pso_net$int_cor,   n_int = 64)  # Here, since we reused the correlation matrix pso_net$int_cor from the # network, the correct setting of cor_adjust = \"spearman\" is automatically # applied  new_agd_int #> # A tibble: 1 × 13 #>   bsa_mean bsa_sd prevsys   psa weight_mean weight_sd durnpso_mean durnpso_sd #>      <dbl>  <dbl>   <dbl> <dbl>       <dbl>     <dbl>        <dbl>      <dbl> #> 1      0.6    0.3     0.1   0.2          10         1            3          1 #> # ℹ 5 more variables: .int_durnpso <list>, .int_prevsys <list>, #> #   .int_bsa <list>, .int_weight <list>, .int_psa <list>"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"Samples (post warm-) stan_nma model object can coerced array, matrix, data frame.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"","code":"# S3 method for stan_nma as.array(x, ..., pars, include = TRUE)  # S3 method for stan_nma as.data.frame(x, ..., pars, include = TRUE)  # S3 method for stan_nma as.matrix(x, ..., pars, include = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"x stan_nma object ... Additional arguments passed .array.stanfit() pars Optional character vector parameter names include output. specified, parameters used. include Logical, parameters pars included (TRUE, default) excluded (FALSE)?","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":".array() method produces 3D array [Iteration, Chain, Parameter] containing posterior samples parameter (class mcmc_array). side effect enabling bayesplot functions seamlessly work stan_nma objects. .data.frame() method produces data frame containing posterior samples parameter, combined chains. .matrix() method produces matrix containing posterior samples parameter, combined chains.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":null,"dir":"Reference","previous_headings":"","what":"as.stanfit — as.stanfit","title":"as.stanfit — as.stanfit","text":"Attempt turn object stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"as.stanfit — as.stanfit","text":"","code":"as.stanfit(x, ...)  # S3 method for stan_nma as.stanfit(x, ...)  # S3 method for default as.stanfit(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"as.stanfit — as.stanfit","text":"x object ... additional arguments","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"as.stanfit — as.stanfit","text":"stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":null,"dir":"Reference","previous_headings":"","what":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"Data frame containing results 26 trials comparing 17 treatments 4 classes prevention stroke patients atrial fibrillation (Cooper et al. 2009) . data corrected versions given van Valkenhoef Kuiper (2016) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"","code":"atrial_fibrillation"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"data frame 63 rows 11 variables: studyc study name studyn numeric study ID trtc treatment name trtn numeric treatment code trt_class treatment class r number events n sample size E person-years risk stroke proportion individuals prior stroke year year study publication followup mean length follow-(years)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"Cooper NJ, Sutton AJ, Morris D, Ades AE, Welton NJ (2009). “Addressing -study heterogeneity inconsistency mixed treatment comparisons: Application stroke prevention treatments individuals non-rheumatic atrial fibrillation.” Statistics Medicine, 28(14), 1861--1881. doi:10.1002/sim.3594 . van Valkenhoef G, Kuiper J (2016). gemtc: Network Meta-Analysis Using Bayesian Methods. R package version 0.8-2, https://CRAN.R-project.org/package=gemtc.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":null,"dir":"Reference","previous_headings":"","what":"BCG vaccination — bcg_vaccine","title":"BCG vaccination — bcg_vaccine","text":"Data frame containing results 13 trials comparing BCG vaccination vaccination preventing tuberculosis (TB) (Dias et al. 2011; Berkey et al. 1995) . numbers individuals diagnosed TB arm study follow-period recorded. absolute degrees latitude study conducted also recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BCG vaccination — bcg_vaccine","text":"","code":"bcg_vaccine"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"BCG vaccination — bcg_vaccine","text":"data frame 26 rows 6 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name latitude absolute degrees latitude r number diagnosed TB n sample size","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"BCG vaccination — bcg_vaccine","text":"Berkey CS, Hoaglin DC, Mosteller F, Colditz GA (1995). “random-effects regression model meta-analysis.” Statistics Medicine, 14(4), 395--411. doi:10.1002/sim.4780140406 . Dias S, Sutton AJ, Welton NJ, Ades AE (2011). “NICE DSU Technical Support Document 3: Heterogeneity: subgroups, meta-regression, bias bias-adjustment.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":null,"dir":"Reference","previous_headings":"","what":"Beta blockers to prevent mortality after MI — blocker","title":"Beta blockers to prevent mortality after MI — blocker","text":"Data frame containing number deaths 22 trials comparing beta blockers vs. control preventing mortality myocardial infarction (Carlin 1992; Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Beta blockers to prevent mortality after MI — blocker","text":"","code":"blocker"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Beta blockers to prevent mortality after MI — blocker","text":"data frame 44 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Beta blockers to prevent mortality after MI — blocker","text":"Carlin JB (1992). “Meta-analysis 2 x 2 tables: bayesian approach.” Statistics Medicine, 11(2), 141--158. doi:10.1002/sim.4780110202 . Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine multiple data sources into one network — combine_network","title":"Combine multiple data sources into one network — combine_network","text":"Multiple data sources created using set_ipd(), set_agd_arm(), set_agd_contrast() can combined single network analysis.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine multiple data sources into one network — combine_network","text":"","code":"combine_network(..., trt_ref)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine multiple data sources into one network — combine_network","text":"... multiple data sources, defined using set_* functions trt_ref reference treatment entire network, string (coerced ) referring levels treatment factor variable","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine multiple data sources into one network — combine_network","text":"object class nma_data","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine multiple data sources into one network — combine_network","text":"","code":"## Parkinson's - combining contrast- and arm-based data studies <- parkinsons$studyn (parkinsons_arm <- parkinsons[studies %in% 1:3, ]) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718 #> 7      3    4 -1.20 0.478  81 -0.90   0.695 (parkinsons_contr <- parkinsons[studies %in% 4:7, ]) #>    studyn trtn     y    se   n  diff se_diff #> 8       4    3 -0.24 0.265 128    NA   0.265 #> 9       4    4 -0.59 0.354  72 -0.35   0.442 #> 10      5    3 -0.73 0.335  80    NA   0.335 #> 11      5    4 -0.18 0.442  46  0.55   0.555 #> 12      6    4 -2.20 0.197 137    NA   0.197 #> 13      6    5 -2.50 0.190 131 -0.30   0.274 #> 14      7    4 -1.80 0.200 154    NA   0.200 #> 15      7    5 -2.10 0.250 143 -0.30   0.320  park_arm_net <- set_agd_arm(parkinsons_arm,                             study = studyn,                             trt = trtn,                             y = y,                             se = se,                             sample_size = n)  park_contr_net <- set_agd_contrast(parkinsons_contr,                                    study = studyn,                                    trt = trtn,                                    y = diff,                                    se = se_diff,                                    sample_size = n)  park_net <- combine_network(park_arm_net, park_contr_net)  # Print network details park_net #> A network with 3 AgD studies (arm-based), and 4 AgD studies (contrast-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  #>  Outcome type: continuous #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected  # Plot network plot(park_net, weight_edges = TRUE, weight_nodes = TRUE)   ## Plaque Psoriasis - combining IPD and AgD in a network # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected   # Plot network plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Set default values — .default","title":"Set default values — .default","text":".default() function used internally mark certain values default, user may notified default values used. example, choosing default reference treatment network, using default prior distributions. function .is_default() checks whether argument/object set default value. Neither functions intended called user.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set default values — .default","text":"","code":".default(x = list())  .is_default(x)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set default values — .default","text":"x object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set default values — .default","text":".default(), identical object additional attribute .default. .is_default(), logical value (TRUE FALSE).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":null,"dir":"Reference","previous_headings":"","what":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"Data frame containing number new cases diabetes 22 trials 6 antihypertensive drugs (Elliott Meyer 2007; Dias et al. 2011) . trial duration (years) also recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"","code":"diabetes"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"data frame 48 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name r total number events n total number individuals time trial follow-(years)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Elliott WJ, Meyer PM (2007). “Incident diabetes clinical trials antihypertensive drugs: network meta-analysis.” Lancet, 369(9557), 201--207. doi:10.1016/s0140-6736(07)60108-1 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Deviance Information Criterion (DIC) — dic","title":"Deviance Information Criterion (DIC) — dic","text":"Calculate DIC model fitted using nma() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deviance Information Criterion (DIC) — dic","text":"","code":"dic(x, penalty = c(\"pD\", \"pV\"), ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deviance Information Criterion (DIC) — dic","text":"x fitted model object, inheriting class stan_nma penalty method estimating effective number parameters, used penalise model fit DIC. Either \"pD\" (default), \"pV\". survival likelihoods \"pV\" currently available. ... arguments (used)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deviance Information Criterion (DIC) — dic","text":"nma_dic object.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deviance Information Criterion (DIC) — dic","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking FE NMA example if not already available if (!exists(\"smk_fit_FE\")) example(\"example_smk_fe\", run.donttest = TRUE) # } # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC of FE and RE models (smk_dic_FE <- dic(smk_fit_FE)) #> Residual deviance: 267.1 (on 50 data points) #>                pD: 27 #>               DIC: 294.1 (smk_dic_RE <- dic(smk_fit_RE))   # substantially better fit #> Residual deviance: 53.9 (on 50 data points) #>                pD: 43.8 #>               DIC: 97.8  # Plot residual deviance contributions under RE model plot(smk_dic_RE)   # Check for inconsistency using UME model # } # \\donttest{ # Run smoking UME NMA example if not already available if (!exists(\"smk_fit_RE_UME\")) example(\"example_smk_ume\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC smk_dic_RE #> Residual deviance: 53.9 (on 50 data points) #>                pD: 43.8 #>               DIC: 97.8 (smk_dic_RE_UME <- dic(smk_fit_RE_UME))  # no difference in fit #> Residual deviance: 53 (on 50 data points) #>                pD: 44.4 #>               DIC: 97.4  # Compare residual deviance contributions plot(smk_dic_RE, smk_dic_RE_UME, show_uncertainty = FALSE)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduced dietary fat to prevent mortality — dietary_fat","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"Data frame containing number deaths person-years risk 10 trials comparing reduced fat diets vs. control (non-reduced fat diet) preventing mortality (Hooper et al. 2000; Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"","code":"dietary_fat"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"data frame 21 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name r number events n number randomised E person-years risk","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Hooper L, Summerbell CD, Higgins JPT, Thompson RL, Clements G, Capps N, Davey Smith G, Riemersma R, Ebrahim S (2000). “Reduced modified dietary fat preventing cardiovascular disease.” Cochrane Database Systematic Reviews. ISSN 1465-1858, doi:10.1002/14651858.CD002137 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":null,"dir":"Reference","previous_headings":"","what":"Specify a general marginal distribution — distr","title":"Specify a general marginal distribution — distr","text":"distr() used within function add_integration() specify marginal distributions covariates, via corresponding inverse CDF. also used predict.stan_nma() specify distribution baseline response (intercept) predicting absolute outcomes.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specify a general marginal distribution — distr","text":"","code":"distr(qfun, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specify a general marginal distribution — distr","text":"qfun inverse CDF, either function name string ... parameters distribution arguments qfun, quoted evaluated later context aggregate data sources","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specify a general marginal distribution — distr","text":"object class distr.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Specify a general marginal distribution — distr","text":"function qfun formal argument called p. restriction serves crude check inverse CDFs (e.g. error given dnorm used instead qnorm). user-written CDF supplied, must argument p takes vector probabilities.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Specify a general marginal distribution — distr","text":"","code":"## Specifying marginal distributions for integration  df <- data.frame(x1_mean = 2, x1_sd = 0.5, x2 = 0.8)  # Distribution parameters are evaluated in the context of the data frame add_integration(df,                 x1 = distr(qnorm, mean = x1_mean, sd = x1_sd),                 x2 = distr(qbern, prob = x2),                 cor = diag(2)) #> # A tibble: 1 × 5 #>   x1_mean x1_sd    x2 .int_x1    .int_x2    #>     <dbl> <dbl> <dbl> <list>     <list>     #> 1       2   0.5   0.8 <dbl [64]> <dbl [64]>"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalised Student's t distribution (with location and scale) — dgent","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"Density, distribution, quantile function generalised t distribution degrees freedom df, shifted location scaled scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"","code":"dgent(x, df, location = 0, scale = 1)  pgent(q, df, location = 0, scale = 1)  qgent(p, df, location = 0, scale = 1)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"x, q Vector quantiles df Degrees freedom, greater zero location Location parameter scale Scale parameter, greater zero p Vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"dgent() gives density, pgent() gives distribution function, qgent() gives quantile function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":null,"dir":"Reference","previous_headings":"","what":"Direct and indirect evidence — get_nodesplits","title":"Direct and indirect evidence — get_nodesplits","text":"Determine whether two treatments network connected direct /indirect evidence, generate list comparisons direct indirect evidence (.e. potential inconsistency) node-splitting.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Direct and indirect evidence — get_nodesplits","text":"","code":"get_nodesplits(network, include_consistency = FALSE)  has_direct(network, trt1, trt2)  has_indirect(network, trt1, trt2)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Direct and indirect evidence — get_nodesplits","text":"network nma_data object, created functions set_*() combine_network(). include_consistency Logical, whether include row NAs indicate consistency model (.e. model node-splitting) also fitted nma() function. Default FALSE calling get_nodesplits() hand, nma() sets TRUE default. trt1, trt2 Treatments, single integer, string, factor","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Direct and indirect evidence — get_nodesplits","text":"has_direct() has_indirect(), single logical value. get_nodesplits(), data frame two columns giving comparisons node-splitting.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Direct and indirect evidence — get_nodesplits","text":"list comparisons node-splitting generated following algorithm van Valkenhoef et al. (2016) . comparison two treatments potential inconsistency, thus considered node-splitting, comparison direct evidence independent indirect evidence. notion independent indirect evidence necessary multi-arm trials present, since design trials internally consistent. comparison two treatments independent indirect evidence , removing studies comparing two treatments network, two treatments still connected path evidence. criterion considered has_indirect() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Direct and indirect evidence — get_nodesplits","text":"van Valkenhoef G, Dias S, Ades AE, Welton NJ (2016). “Automated generation node-splitting models assessment inconsistency network meta-analysis.” Research Synthesis Methods, 7(1), 80--93. doi:10.1002/jrsm.1167 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Direct and indirect evidence — get_nodesplits","text":"","code":"# Parkinsons example park_net <- set_agd_arm(parkinsons,                         study = studyn,                         trt = trtn,                         y = y,                         se = se,                         trt_ref = 1) #> Note: Optional argument `sample_size` not provided, some features may not be available (see ?set_agd_arm).  # View the network plot plot(park_net)   # The 4 vs. 5 comparison is a spur on the network has_direct(park_net, 4, 5) #> [1] TRUE has_indirect(park_net, 4, 5) #> [1] FALSE  # 1 and 5 are not directly connected has_direct(park_net, 1, 5) #> [1] FALSE has_indirect(park_net, 1, 5) #> [1] TRUE  # The 1 vs. 2 comparison does not have independent indirect evidence, since # the 1-2-4 loop is a multi-arm study has_indirect(park_net, 1, 2) #> [1] FALSE  # Get a list of comparisons with potential inconsistency for node-splitting get_nodesplits(park_net) #> # A tibble: 4 × 2 #>   trt1  trt2  #>   <fct> <fct> #> 1 1     3     #> 2 1     4     #> 3 2     4     #> 4 3     4      # See van Valkenhoef (2016) for a discussion of this example"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert networks to graph objects — as.igraph.nma_data","title":"Convert networks to graph objects — as.igraph.nma_data","text":"method .igraph() converts nma_data objects form used igraph package. method as_tbl_graph() converts nma_data objects form used ggraph tidygraph packages.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert networks to graph objects — as.igraph.nma_data","text":"","code":"# S3 method for nma_data as.igraph(x, ..., collapse = TRUE)  # S3 method for nma_data as_tbl_graph(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert networks to graph objects — as.igraph.nma_data","text":"x nma_data object convert ... Additional arguments collapse Logical, collapse edges studies? Default TRUE, one edge produced comparison (IPD AgD study type) .nstudy attribute giving number studies making comparison. FALSE, repeated edges added study making comparison.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert networks to graph objects — as.igraph.nma_data","text":"igraph object .igraph(), tbl_graph object as_tbl_graph().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert networks to graph objects — as.igraph.nma_data","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # Convert to igraph object igraph::as.igraph(smk_net)  # Edges combined by default #> IGRAPH 0d816e5 UN-- 4 6 --  #> + attr: name (v/c), .sample_size (v/n), .nstudy (e/n), .type (e/c) #> + edges from 0d816e5 (vertex names): #> [1] No intervention       --Group counselling      #> [2] No intervention       --Individual counselling #> [3] Group counselling     --Individual counselling #> [4] No intervention       --Self-help              #> [5] Group counselling     --Self-help              #> [6] Individual counselling--Self-help              igraph::as.igraph(smk_net, collapse = FALSE)  # Without combining edges #> IGRAPH 4d73d20 UN-- 4 28 --  #> + attr: name (v/c), .sample_size (v/n), .study (e/c), .type (e/c) #> + edges from 4d73d20 (vertex names): #>  [1] No intervention       --Group counselling      #>  [2] No intervention       --Individual counselling #>  [3] Group counselling     --Individual counselling #>  [4] Group counselling     --Individual counselling #>  [5] Group counselling     --Self-help              #>  [6] Individual counselling--Self-help              #>  [7] No intervention       --Individual counselling #>  [8] No intervention       --Individual counselling #> + ... omitted several edges  # Convert to tbl_graph object tidygraph::as_tbl_graph(smk_net)  # Edges combined by default #> # A tbl_graph: 4 nodes and 6 edges #> # #> # An undirected simple graph with 1 component #> # #> # A tibble: 4 × 2 #>   name                   .sample_size #>   <chr>                         <dbl> #> 1 No intervention                7231 #> 2 Group counselling               555 #> 3 Individual counselling         7383 #> 4 Self-help                      1571 #> # #> # A tibble: 6 × 4 #>    from    to .nstudy .type #>   <int> <int>   <int> <chr> #> 1     1     2       2 AgD   #> 2     1     3      15 AgD   #> 3     2     3       4 AgD   #> # ℹ 3 more rows tidygraph::as_tbl_graph(smk_net, collapse = FALSE)  # Without combining edges #> # A tbl_graph: 4 nodes and 28 edges #> # #> # An undirected multigraph with 1 component #> # #> # A tibble: 4 × 2 #>   name                   .sample_size #>   <chr>                         <dbl> #> 1 No intervention                7231 #> 2 Group counselling               555 #> 3 Individual counselling         7383 #> 4 Self-help                      1571 #> # #> # A tibble: 28 × 4 #>    from    to .study .type #>   <int> <int> <chr>  <chr> #> 1     1     2 1      AgD   #> 2     1     3 1      AgD   #> 3     2     3 1      AgD   #> # ℹ 25 more rows"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":null,"dir":"Reference","previous_headings":"","what":"HTA Plaque Psoriasis — hta_psoriasis","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"Data frame containing results 16 trials comparing 8 treatments moderate--severe plaque psoriasis HTA report (Woolacott et al. 2006) , analysed TSD2 (Dias et al. 2011) . Outcomes success/failure achieve 50%, 75%, 90% reduction symptoms Psoriasis Area Severity Index (PASI) scale. studies report three ordered outcomes, others one two. latter coded missing values (see details).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"","code":"hta_psoriasis"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"data frame 36 rows 9 variables: studyn numeric study ID studyc study name year year publication trtn numeric treatment code trtc treatment name sample_size sample size arm PASI50, PASI75, PASI90 ordered multinomial outcome counts (exclusive, see details)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"Outcome counts \"exclusive\"; , study reporting outcomes, counts represent categories 50 < PASI < 75, 75 < PASI < 90, 90 < PASI < 100, named lower end interval. (opposed \"inclusive\" counts, represent overlapping categories PASI > 50, PASI > 70, PASI > 90.) count fourth category (lowest), 0 < PASI < 50, equal sample_size - PASI50 - PASI75 - PASI90. Missing values used studies report subset outcomes. study reporting two outcomes, say 50 75, counts represent 50 < PASI < 75 75 < PASI < 100. study reporting one outcome, say PASI 75, count represents 75 < PASI < 100.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Woolacott N, Hawkins N, Mason , Kainth , Khadjesari Z, Bravo Vergel Y, Misso K, Light K, Chalmers R, Sculpher M, Riemsma R (2006). “Etanercept efalizumab treatment psoriasis: systematic review.” Health Technology Assessment, 10(46). doi:10.3310/hta10460 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":null,"dir":"Reference","previous_headings":"","what":"Check network connectedness — is_network_connected","title":"Check network connectedness — is_network_connected","text":"Check whether network connected - whether path study evidence linking every pair treatments network.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check network connectedness — is_network_connected","text":"","code":"is_network_connected(network)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check network connectedness — is_network_connected","text":"network nma_data object, created functions set_*() combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check network connectedness — is_network_connected","text":"Logical TRUE FALSE","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check network connectedness — is_network_connected","text":"Models still run disconnected networks. However, estimated relative effects treatments across disconnected parts network entirely based prior distribution (typically uncertain), information update prior distribution. Relative effects within connected sub-network estimated sub-network analysed separately.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check network connectedness — is_network_connected","text":"","code":"## Smoking cessation # Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  is_network_connected(smk_net)  # TRUE, network is connected #> [1] TRUE ## A disconnected network disc_net <- set_agd_arm(smoking[smoking$studyn %in% c(15, 21), ],                         study = studyn,                         trt = trtc,                         r = r,                         n = n) is_network_connected(disc_net)  # FALSE, network is disconnected #> [1] FALSE disc_net #> A network with 2 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                         #>  15    2: Group counselling | No intervention #>  21    2: Individual counselling | Self-help  #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 2 #> Reference treatment is: Group counselling #> Network is disconnected plot(disc_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Student's t distribution — dlogt","title":"Log Student's t distribution — dlogt","text":"Density, distribution, quantile function log t distribution, whose logarithm degrees freedom df, mean location, standard deviation scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Student's t distribution — dlogt","text":"","code":"dlogt(x, df, location = 0, scale = 1)  plogt(q, df, location = 0, scale = 1)  qlogt(p, df, location = 0, scale = 1)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Student's t distribution — dlogt","text":"x, q Vector quantiles df Degrees freedom, greater zero location Location parameter scale Scale parameter, greater zero p Vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Student's t distribution — dlogt","text":"dlogt() gives density, plogt() gives distribution function, qlogt() gives quantile function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log Student's t distribution — dlogt","text":"\\(\\log(Y) \\sim t_\\nu(\\mu, \\sigma^2)\\), \\(Y\\) log t distribution location \\(\\mu\\), scale \\(\\sigma\\), df \\(\\nu\\). mean higher moments log t distribution undefined infinite. df = 1 distribution log Cauchy distribution. df tends infinity, approaches log Normal distribution.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":null,"dir":"Reference","previous_headings":"","what":"The logit Normal distribution — qlogitnorm","title":"The logit Normal distribution — qlogitnorm","text":"provide convenient extensions [dpq]logitnorm functions package logitnorm, allow distribution specified terms mean standard deviation, instead logit-mean logit-sd.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The logit Normal distribution — qlogitnorm","text":"","code":"qlogitnorm(p, mu = 0, sigma = 1, ..., mean, sd)  dlogitnorm(x, mu = 0, sigma = 1, ..., mean, sd)  plogitnorm(q, mu = 0, sigma = 1, ..., mean, sd)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The logit Normal distribution — qlogitnorm","text":"p, x vector quantiles mu, sigma, ... see logitnorm mean, sd mean standard deviation, overriding mu sigma specified q vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":null,"dir":"Reference","previous_headings":"","what":"Model comparison using the loo package — loo.stan_nma","title":"Model comparison using the loo package — loo.stan_nma","text":"loo() waic() functions loo package may called directly stan_nma stan_mlnmr objects.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model comparison using the loo package — loo.stan_nma","text":"","code":"# S3 method for stan_nma loo(x, ...)  # S3 method for stan_nma waic(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model comparison using the loo package — loo.stan_nma","text":"x object class stan_nma stan_mlnmr ... arguments loo() waic()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Working with 3D MCMC arrays — mcmc_array-class","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"3D MCMC arrays (Iterations, Chains, Parameters) produced .array() methods applied stan_nma nma_summary objects.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"","code":"# S3 method for mcmc_array summary(object, ..., probs = c(0.025, 0.25, 0.5, 0.75, 0.975))  # S3 method for mcmc_array print(x, ...)  # S3 method for mcmc_array names(x)  # S3 method for mcmc_array names(x) <- value"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"... arguments passed methods probs Numeric vector quantiles interest x, object 3D MCMC array class mcmc_array value Character vector replacement parameter names","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"summary() method returns nma_summary object, print() method returns x invisibly. names() method returns character vector parameter names, names()<- returns object updated parameter names.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Working with arrays of posterior draws (as mcmc_array objects) is # convenient when transforming parameters  # Transforming log odds ratios to odds ratios LOR_array <- as.array(relative_effects(smk_fit_RE)) OR_array <- exp(LOR_array)  # mcmc_array objects can be summarised to produce a nma_summary object smk_OR_RE <- summary(OR_array)  # This can then be printed or plotted smk_OR_RE #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling]      3.33 1.60 1.36 2.27 2.97 4.01  7.38     2253     2603 #> d[Individual counselling] 2.40 0.59 1.49 1.98 2.32 2.71  3.73     1214     1881 #> d[Self-help]              1.78 0.78 0.76 1.24 1.64 2.13  3.80     1655     2194 #>                           Rhat #> d[Group counselling]      1.00 #> d[Individual counselling] 1.01 #> d[Self-help]              1.00 plot(smk_OR_RE, ref_line = 1)   # Transforming heterogeneity SD to variance tau_array <- as.array(smk_fit_RE, pars = \"tau\") tausq_array <- tau_array^2  # Correct parameter names names(tausq_array) <- \"tausq\"  # Summarise summary(tausq_array) #>       mean   sd 2.5% 25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq 0.74 0.34 0.31 0.5 0.67 0.89  1.62     1141     1905    1 # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":null,"dir":"Reference","previous_headings":"","what":"Distribution functions for M-spline baseline hazards — dmspline","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"Density, distribution, quantile, hazard, cumulative hazard, restricted mean survival time functions M-spline baseline hazards model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"","code":"dmspline(x, basis, scoef, rate, log = FALSE)  pmspline(q, basis, scoef, rate, lower.tail = TRUE, log.p = FALSE)  qmspline(p, basis, scoef, rate, lower.tail = TRUE, log.p = FALSE)  hmspline(x, basis, scoef, rate, log = FALSE)  Hmspline(x, basis, scoef, rate, log = FALSE)  rmst_mspline(t, basis, scoef, rate, start = 0)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"x, q Vector quantiles basis M-spline basis produced splines2::mSpline() scoef Vector (matrix) spline coefficients length (number columns) equal dimension basis rate Vector rate parameters log, log.p Logical; TRUE, probabilities p given \\(\\log(p)\\) lower.tail Logical; TRUE (default), probabilities \\(P(X \\le x)\\), otherwise \\(P(X > x)\\) p Vector probabilities t Vector times restricted mean survival time calculated start Optional left-truncation time times. returned restricted mean survival conditioned survival time","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"dmspline() gives density, pmspline() gives distribution function (CDF), qmspline() gives quantile function (inverse-CDF), hmspline() gives hazard function, Hmspline() gives cumulative hazard function, rmst_mspline() gives restricted mean survival times.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"Survival models flexible M-spline baseline hazard described Brilleman et al. (2020) . Piecewise-exponential baseline hazards special case degree M-spline polynomial 0. d/p/h/H functions calculated definitions. qmspline() uses numerical inversion via flexsurv::qgeneric(). rmst_mspline()uses numerical integration via flexsurv::rmst_generic(), except special case piecewise-exponential hazard (.e. degree 0 M-splines) uses explicit formula Royston Parmar (2013) . Beyond boundary knots, hazard assumed constant. (differs approach splines2::mSpline() extrapolates polynomial basis functions, numerically unstable highly dependent data just boundary knots.) extrapolation, care taken evaluating splines times beyond boundary knots (either directly d/p/h/H/rmst functions, indirectly requesting quantiles qmspline() correspond times beyond boundary knots). reason evaluating (unrestricted) mean survival time generally recommended requires integrating infinite time horizon (.e. rmst_mspline() t = Inf).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"Brilleman SL, Elci EM, Novik JB, Wolfe R (2020). “Bayesian Survival Analysis Using rstanarm R Package.” arXiv. doi:10.48550/arXiv.2002.09633 , 2002.09633. Royston P, Parmar MKB (2013). “Restricted mean survival time: alternative hazard ratio design analysis randomized trials time--event outcome.” BMC Medical Research Methodology, 13(1). doi:10.1186/1471-2288-13-152 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial outcome data — multi","title":"Multinomial outcome data — multi","text":"function aids specification multinomial outcome data setting network set_agd_arm() set_ipd(). takes set columns (, generally, numeric vectors length) outcome counts category, binds together produce matrix.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multinomial outcome data — multi","text":"","code":"multi(..., inclusive = FALSE, type = c(\"ordered\", \"competing\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multinomial outcome data — multi","text":"... Two numeric columns (vectors) category counts. Argument names (optional) used label categories. inclusive Logical, ordered category counts inclusive (TRUE) exclusive (FALSE)? Default FALSE. used ordered = TRUE. See details. type String, indicating whether categories \"ordered\" \"competing\". Currently ordered categorical outcomes supported modelling functions package.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multinomial outcome data — multi","text":"matrix (exclusive) category counts","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multinomial outcome data — multi","text":"specifying ordered categorical counts, can either given exclusive counts (inclusive = FALSE, default) individuals counted highest category achieve, inclusive counts (inclusive = TRUE) individuals counted every category including highest category achieved. (Competing outcomes, nature, always specified exclusive counts.) NA values can used indicate categories/cutpoints measured.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multinomial outcome data — multi","text":"","code":"# These two data sets specify the same ordered categorical data for outcomes # r0 < r1 < r2, but the first uses the \"inclusive\" format and the second the # \"exclusive\" format. df_inclusive <- tibble::tribble(~r0, ~r1, ~r2,                                 1, 1, 1,                                 5, 4, 1,                                 5, 2, 2,                                 10, 5, 0,                                 5, 5, 0,                                 7, NA, 6,   # Achieved r2 or not (no r1)                                 10, 4, NA)  # Achieved r1 or not (no r2)  df_exclusive <- tibble::tribble(~r0, ~r1, ~r2,                                 0, 0, 1,                                 1, 3, 1,                                 3, 0, 2,                                 5, 5, 0,                                 0, 5, 0,                                 1, NA, 6,   # Achieved r2 or not (no r1)                                 6, 4, NA)   # Achieved r1 or not (no r2)  (r_inclusive <- with(df_inclusive, multi(r0, r1, r2, inclusive = TRUE))) #>      r0 r1 r2 #> [1,]  0  0  1 #> [2,]  1  3  1 #> [3,]  3  0  2 #> [4,]  5  5  0 #> [5,]  0  5  0 #> [6,]  1 NA  6 #> [7,]  6  4 NA #> attr(,\"class\") #> [1] \"multi_ordered\" \"matrix\"        \"array\"         (r_exclusive <- with(df_exclusive, multi(r0, r1, r2, inclusive = FALSE))) #>      r0 r1 r2 #> [1,]  0  0  1 #> [2,]  1  3  1 #> [3,]  3  0  2 #> [4,]  5  5  0 #> [5,]  0  5  0 #> [6,]  1 NA  6 #> [7,]  6  4 NA #> attr(,\"class\") #> [1] \"multi_ordered\" \"matrix\"        \"array\"          # Counts are always stored in exclusive format stopifnot(isTRUE(all.equal(r_inclusive, r_exclusive)))   ## HTA Plaque Psoriasis library(dplyr)  # Ordered outcomes here are given as \"exclusive\" counts head(hta_psoriasis) #>   studyn   studyc year trtn             trtc sample_size PASI50 PASI75 PASI90 #> 1      1  Elewski 2004    1  Supportive care         193     12      5      1 #> 2      1  Elewski 2004    2 Etanercept 25 mg         196     59     46     21 #> 3      1  Elewski 2004    3 Etanercept 50 mg         194     54     56     40 #> 4      2 Gottlieb 2003    1  Supportive care          55      5      1      0 #> 5      2 Gottlieb 2003    2 Etanercept 25 mg          57     23     11      6 #> 6      3  Lebwohl 2003    1  Supportive care         122     13      5      1  # Calculate lowest category count (failure to achieve PASI 50) pso_dat <- hta_psoriasis %>%   mutate(`PASI<50` = sample_size - rowSums(cbind(PASI50, PASI75, PASI90), na.rm = TRUE))  # Set up network pso_net <- set_agd_arm(pso_dat,                        study = paste(studyc, year),                        trt = trtc,                        r = multi(`PASI<50`, PASI50, PASI75, PASI90,                                  inclusive = FALSE,                                  type = \"ordered\"))  pso_net #> A network with 16 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                           #>  ACD2058g 2004 2: Supportive care | Efalizumab                          #>  ACD2600g 2004 2: Supportive care | Efalizumab                          #>  Altmeyer 1994 2: Supportive care | Fumaderm                            #>  Chaudari 2001 2: Supportive care | Infliximab                          #>  Elewski 2004  3: Supportive care | Etanercept 25 mg | Etanercept 50 mg #>  Ellis 1991    3: Supportive care | Ciclosporin | Ciclosporin           #>  Gordon 2003   2: Supportive care | Efalizumab                          #>  Gottlieb 2003 2: Supportive care | Etanercept 25 mg                    #>  Gottlieb 2004 3: Supportive care | Infliximab | Infliximab             #>  Guenther 1991 2: Supportive care | Ciclosporin                         #>  ... plus 6 more studies #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 8 #> Total number of studies: 16 #> Reference treatment is: Supportive care #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":null,"dir":"Reference","previous_headings":"","what":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"R package performing network meta-analysis network meta-regression aggregate data, individual patient data, mixtures .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"Network meta-analysis (NMA) combines (aggregate) data multiple studies multiple treatments order produce consistent estimates relative treatment effects pair treatments network (Dias et al. 2011) . Network meta-regression (NMR) extends NMA include covariates, allowing adjustment differences effect-modifying variables studies (Dias et al. 2011) . NMR typically performed using aggregate data (AgD), lacks power prone ecological bias. NMR individual patient data (IPD) gold standard, data available. Multilevel network meta-regression (ML-NMR) allows IPD AgD incorporated together network meta-regression (Phillippo et al. 2020; Phillippo 2019) . IPD NMR, individual-level regression model defined. AgD studies fitted integrating individual-level model respective covariate distributions. correctly links two levels model (instead \"plugging \" mean covariate values), avoiding aggregation bias. Population-adjusted treatment effects (Phillippo et al. 2016)  can produced study population network, external target population. Models estimated Bayesian framework using Stan (Carpenter et al. 2017) . Quasi-Monte Carlo numerical integration based Sobol' sequences used integration ML-NMR models, Gaussian copula account correlations covariates (Phillippo et al. 2020; Phillippo 2019) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"getting-started","dir":"Reference","previous_headings":"","what":"Getting Started","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"good place start package vignettes walk example analyses, see vignette(\"vignette_overview\") overview. series NICE Technical Support Documents evidence synthesis gives detailed introduction network meta-analysis: Dias S, Welton NJ, Sutton AJ, Caldwell DM, Lu G, Reken S, Ades AE (2011). “NICE DSU Technical Support Documents 1-7: Evidence Synthesis Decision Making.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Multilevel network meta-regression set following methods paper: Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"Carpenter B, Gelman , Hoffman MD, Lee D, Goodrich B, Betancourt M, Brubaker M, Guo J, Li P, Riddell (2017). “Stan: Probabilistic Programming Language.” Journal Statistical Software, 76(1). doi:10.18637/jss.v076.i01 . Dias S, Sutton AJ, Welton NJ, Ades AE (2011). “NICE DSU Technical Support Document 3: Heterogeneity: subgroups, meta-regression, bias bias-adjustment.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Phillippo DM (2019). Calibration Treatment Effects Network Meta-Analysis using Individual Patient Data. Ph.D. thesis, University Bristol. Available https://research-information.bris.ac.uk/. Phillippo DM, Ades AE, Dias S, Palmer S, Abrams KR, Welton NJ (2016). “NICE DSU Technical Support Document 18: Methods population-adjusted indirect comparisons submission NICE.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Newly diagnosed multiple myeloma — ndmm_ipd","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"Three data frames, ndmm_ipd, ndmm_agd, ndmm_agd_covs containing (simulated) individual patient data (IPD) three studies aggregate data (AgD) two studies newly diagnosed multiple myeloma. outcome interest progression-free survival autologous stem cell transplant. IPD studies ndmm_ipd provide event/censoring times covariate values individual. AgD studies provide reconstructed event/censoring times digitized Kaplan-Meier curves ndmm_agd covariate summaries ndmm_agd_covs, obtained published trial reports. data constructed resemble used Leahy Walsh (2019) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"","code":"ndmm_ipd  ndmm_agd  ndmm_agd_covs"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"individual patient data contained data frame ndmm_ipd 1325 rows, one per individual, 10 variables: study, studyf study name trt, trtf treatment name eventtime event/censoring time status censoring indicator (0 = censored, 1 = event) age age (years) iss_stage3 ISS stage 3 (0 = , 1 = yes) response_cr_vgpr complete good partial response (0 = , 1 = yes) male male sex (0 = , 1 = yes) reconstructed Kaplan-Meier data aggregate studies contained data frame ndmm_agd 2819 rows 6 variables: study, studyf study name trt, trtf treatment name eventtime event/censoring time status censoring indicator (0 = censored, 1 = event) covariate summaries extracted published reportes aggregate studies contained data frame ndmm_agd_covs 4 rows, one per study arm, 15 columns: study, studyf study name trt, trtf treatment name sample_size sample size arm age_min, age_iqr_l, age_median, age_iqr_h, age_max, age_mean, age_sd summary statistics age (years) iss_stage3 proportion participants ISS stage 3 response_cr_vgpr proportion participants complete good partial response male proportion male participants","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"Leahy J, Walsh C (2019). “Assessing impact matching-adjusted indirect comparison Bayesian network meta-analysis.” Research Synthesis Methods, 10(4), 546--568. doi:10.1002/jrsm.1372 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Network meta-analysis models — nma","title":"Network meta-analysis models — nma","text":"nma function fits network meta-analysis (multilevel) network meta-regression models Stan.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Network meta-analysis models — nma","text":"","code":"nma(   network,   consistency = c(\"consistency\", \"ume\", \"nodesplit\"),   trt_effects = c(\"fixed\", \"random\"),   regression = NULL,   class_interactions = c(\"common\", \"exchangeable\", \"independent\"),   likelihood = NULL,   link = NULL,   ...,   nodesplit = get_nodesplits(network, include_consistency = TRUE),   prior_intercept = .default(normal(scale = 100)),   prior_trt = .default(normal(scale = 10)),   prior_het = .default(half_normal(scale = 5)),   prior_het_type = c(\"sd\", \"var\", \"prec\"),   prior_reg = .default(normal(scale = 10)),   prior_aux = .default(),   aux_by = NULL,   QR = FALSE,   center = TRUE,   adapt_delta = NULL,   int_thin = 0,   int_check = TRUE,   mspline_degree = 3,   n_knots = 3,   knots = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Network meta-analysis models — nma","text":"network nma_data object, created functions set_*(), combine_network(), add_integration() consistency Character string specifying type ()consistency model fit, either \"consistency\", \"ume\", \"nodesplit\" trt_effects Character string specifying either \"fixed\" \"random\" effects regression one-sided model formula, specifying prognostic effect-modifying terms regression model. references treatment use .trt special variable, example specifying effect modifier interactions variable:.trt (see details). class_interactions Character string specifying whether effect modifier interactions specified \"common\", \"exchangeable\", \"independent\". likelihood Character string specifying likelihood, unspecified inferred data (see details) link Character string specifying link function, unspecified default canonical link (see details) ... arguments passed sampling(), iter, chains, cores, etc. nodesplit consistency = \"nodesplit\", comparison(s) split node-splitting model(s). Either length 2 vector giving treatments single comparison, 2 column data frame listing multiple treatment comparisons split turn. default, possible comparisons chosen (see get_nodesplits()). prior_intercept Specification prior distribution intercept prior_trt Specification prior distribution treatment effects prior_het Specification prior distribution heterogeneity (trt_effects = \"random\") prior_het_type Character string specifying whether prior distribution prior_het placed heterogeneity standard deviation \\(\\tau\\) (\"sd\", default), variance \\(\\tau^2\\) (\"var\"), precision \\(1/\\tau^2\\) (\"prec\"). prior_reg Specification prior distribution regression coefficients (regression formula specified) prior_aux Specification prior distribution auxiliary parameter, applicable (see details). likelihood = \"gengamma\" list prior distributions elements sigma k. aux_by Vector variable names listing variables stratify auxiliary parameters . Currently used survival models, see details. QR Logical scalar (default FALSE), whether apply QR decomposition model design matrix center Logical scalar (default TRUE), whether center (numeric) regression terms overall means adapt_delta See adapt_delta details int_thin single integer value, thinning factor returning cumulative estimates integration error. Saving cumulative estimates disabled int_thin = 0, default. int_check Logical, check sufficient accuracy numerical integration fitting half chains n_int/2? TRUE, Rhat n_eff diagnostic warnings given numerical integration sufficiently converged (suggesting increasing n_int add_integration()). Default TRUE, disabled (FALSE) int_thin > 0. mspline_degree Non-negative integer giving degree M-spline polynomial likelihood = \"mspline\". Piecewise exponential hazards (likelihood = \"pexp\") special case mspline_degree = 0. n_knots mspline pexp likelihoods, non-negative integer giving number internal knots partitioning baseline hazard intervals. knot locations within study determined corresponding quantiles observed event times, plus boundary knots earliest entry time (0 delayed entry) maximum event/censoring time. example, default n_knots = 3, internal knot locations 25%, 50%, 75% quantiles observed event times. Ignored knots specified. knots mspline pexp likelihoods, named list numeric vectors internal knot locations studies network. Currently, vector must length (.e. study must use number knots). unspecified (default), knots chosen based n_knots described .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Network meta-analysis models — nma","text":"nma() returns stan_nma object, except consistency = \"nodesplit\" nma_nodesplit nma_nodesplit_df object returned. nma.fit() returns stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Network meta-analysis models — nma","text":"specifying model formula regression argument, usual formula syntax available (interpreted model.matrix()). additional requirement special variable .trt used refer treatment. example, effect modifier interactions specified variable:.trt. Prognostic (main) effects interactions can included together compactly variable*.trt, expands variable + variable:.trt (plus .trt, already NMA model). advanced user, additional specials .study .trtclass also available, refer studies (specified) treatment classes respectively. node-splitting models fitted (consistency = \"nodesplit\") special .omega available, indicating arms node-splitting inconsistency factor added. See ?priors details prior specification. Default prior distributions available, may appropriate particular setting raise warning used. attempt made tailor defaults data provided. Please consider appropriate prior distributions particular setting, accounting scales outcomes covariates, etc. function plot_prior_posterior() may useful examining influence chosen prior distributions posterior distributions, summary() method nma_prior objects prints prior intervals.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"likelihoods-and-link-functions","dir":"Reference","previous_headings":"","what":"Likelihoods and link functions","title":"Network meta-analysis models — nma","text":"Currently, following likelihoods link functions supported data type: bernoulli2 binomial2 likelihoods correspond two-parameter Binomial likelihood arm-based AgD, closely matches underlying Poisson Binomial distribution summarised aggregate outcomes ML-NMR model typical (one parameter) Binomial distribution (see Phillippo et al. 2020) . cloglog link used, including offset log follow-time (.e. regression = ~offset(log(time))) results model log hazard (see Dias et al. 2011) . survival data, accelerated failure time models (exponential-aft, weibull-aft, lognormal, loglogistic, gamma, gengamma) parameterised treatment effects regression parameters log Survival Time Ratios (.e. coefficient \\(\\log(2)\\) means treatment covariate associated doubling expected survival time). can converted log Acceleration Factors using relation \\(\\log(\\mathrm{AF}) = -\\log(\\mathrm{STR})\\) (equivalently \\(\\mathrm{AF} = 1/\\mathrm{STR}\\)). details likelihood link function given Dias et al. (2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"auxiliary-parameters","dir":"Reference","previous_headings":"","what":"Auxiliary parameters","title":"Network meta-analysis models — nma","text":"Auxiliary parameters present following models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"normal-likelihood-with-ipd","dir":"Reference","previous_headings":"","what":"Normal likelihood with IPD","title":"Network meta-analysis models — nma","text":"Normal likelihood fitted IPD, auxiliary parameters arm-level standard deviations \\(\\sigma_{jk}\\) treatment \\(k\\) study \\(j\\).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"ordered-multinomial-likelihood","dir":"Reference","previous_headings":"","what":"Ordered multinomial likelihood","title":"Network meta-analysis models — nma","text":"fitting model \\(M\\) ordered outcomes, auxiliary parameters latent cutoffs category, \\(c_0 < c_1 < \\dots <   c_M\\). \\(c_2\\) \\(c_{M-1}\\) estimated; fix \\(c_0 =   -\\infty\\), \\(c_1 = 0\\), \\(c_M = \\infty\\). specifying priors latent cutoffs, choose specify priors differences \\(c_{m+1} - c_m\\). Stan automatically truncates priors ordering constraints satisfied.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"survival-time-to-event-likelihoods","dir":"Reference","previous_headings":"","what":"Survival (time-to-event) likelihoods","title":"Network meta-analysis models — nma","text":"survival likelihoods except exponential exponential-aft likelihoods auxiliary parameters. typically study-specific shape parameters \\(\\gamma_j>0\\), except lognormal likelihood auxiliary parameters study-specific standard deviations log scale \\(\\sigma_j>0\\). gengamma likelihood two sets auxiliary parameters, study-specific scale parameters \\(\\sigma_j>0\\) shape parameters \\(k_j\\), following parameterisation Lawless (1980) , permits range behaviours baseline hazard including increasing, decreasing, bathtub arc-shaped hazards. parameterisation related discussed Cox et al. (2007)  implemented flexsurv package \\(Q = k^{-0.5}\\). parameterisation used effectively bounds shape parameter \\(k\\) away numerical instabilities \\(k \\rightarrow \\infty\\) (.e. away \\(Q   \\rightarrow 0\\), log-Normal distribution) via prior distribution. Implicitly, parameterisation restricted \\(Q > 0\\) certain survival distributions like inverse-Gamma inverse-Weibull part parameter space; however, \\(Q > 0\\) still encompasses survival distributions implemented package. mspline pexp likelihoods, auxiliary parameters spline coefficients study. form unit simplex (.e. lie 0 1, sum 1), given dirichlet() prior distribution. auxiliary parameters can stratified additional factors aux_by argument. example, allow shape baseline hazard vary treatment arms well studies, use aux_by = c(\".study\", \".trt\"). (Technically, .study always included stratification even omitted aux_by, choose make stratification explicit.) common way relaxing proportional hazards assumption. default equivalent aux_by = \".study\" stratifies auxiliary parameters study, described .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Network meta-analysis models — nma","text":"Cox C, Chu H, Schneider MF, Mu~noz (2007). “Parametric survival analysis taxonomy hazard functions generalized gamma distribution.” Statistics Medicine, 26(23), 4352--4374. doi:10.1002/sim.2836 . Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Lawless JF (1980). “Inference Generalized Gamma Log Gamma Distributions.” Technometrics, 22(3), 409--419. doi:10.1080/00401706.1980.10486173 . Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Network meta-analysis models — nma","text":"","code":"## Smoking cessation NMA # Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting a fixed effect model smk_fit_FE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100))  smk_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          0.83    0.00 0.18     0.49     0.72     0.83 #> d[Individual counselling]     0.76    0.00 0.06     0.65     0.72     0.76 #> d[Self-help]                  0.22    0.00 0.13    -0.02     0.14     0.22 #> lp__                      -5859.22    0.09 3.60 -5867.18 -5861.50 -5858.95 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          0.95     1.18  2307    1 #> d[Individual counselling]     0.80     0.87  2155    1 #> d[Self-help]                  0.31     0.47  2708    1 #> lp__                      -5856.60 -5853.07  1716    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:29:05 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\donttest{ # Fitting a random effects model smk_fit_RE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = normal(scale = 5))  smk_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          1.10    0.01 0.43     0.29     0.82     1.09 #> d[Individual counselling]     0.84    0.01 0.23     0.40     0.69     0.84 #> d[Self-help]                  0.49    0.01 0.39    -0.30     0.23     0.48 #> lp__                      -5768.13    0.19 6.50 -5781.53 -5772.54 -5767.80 #> tau                           0.83    0.00 0.18     0.54     0.70     0.81 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          1.36     1.96  2053 1.00 #> d[Individual counselling]     1.00     1.30  1430 1.01 #> d[Self-help]                  0.73     1.32  2007 1.00 #> lp__                      -5763.40 -5756.41  1223 1.00 #> tau                           0.93     1.23  1409 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:29:21 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\donttest{ # Fitting an unrelated mean effects (inconsistency) model smk_fit_RE_UME <- nma(smk_net, refresh = if (interactive()) 200 else 0,                       consistency = \"ume\",                       trt_effects = \"random\",                       prior_intercept = normal(scale = 100),                       prior_trt = normal(scale = 100),                       prior_het = normal(scale = 5))  smk_fit_RE_UME #> A random effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                     mean se_mean   sd     2.5% #> d[Group counselling vs. No intervention]            1.14    0.02 0.81    -0.34 #> d[Individual counselling vs. No intervention]       0.90    0.01 0.27     0.38 #> d[Self-help vs. No intervention]                    0.34    0.01 0.58    -0.78 #> d[Individual counselling vs. Group counselling]    -0.29    0.01 0.60    -1.51 #> d[Self-help vs. Group counselling]                 -0.60    0.01 0.71    -1.98 #> d[Self-help vs. Individual counselling]             0.14    0.02 1.05    -1.98 #> lp__                                            -5765.06    0.19 6.21 -5777.81 #> tau                                                 0.93    0.01 0.22     0.59 #>                                                      25%      50%      75% #> d[Group counselling vs. No intervention]            0.61     1.11     1.64 #> d[Individual counselling vs. No intervention]       0.72     0.89     1.07 #> d[Self-help vs. No intervention]                   -0.03     0.34     0.70 #> d[Individual counselling vs. Group counselling]    -0.68    -0.29     0.10 #> d[Self-help vs. Group counselling]                 -1.05    -0.60    -0.18 #> d[Self-help vs. Individual counselling]            -0.56     0.14     0.82 #> lp__                                            -5769.22 -5764.88 -5760.60 #> tau                                                 0.77     0.90     1.07 #>                                                    97.5% n_eff Rhat #> d[Group counselling vs. No intervention]            2.85  2363    1 #> d[Individual counselling vs. No intervention]       1.48  1167    1 #> d[Self-help vs. No intervention]                    1.50  2249    1 #> d[Individual counselling vs. Group counselling]     0.89  2250    1 #> d[Self-help vs. Group counselling]                  0.81  2295    1 #> d[Self-help vs. Individual counselling]             2.19  3855    1 #> lp__                                            -5753.77  1093    1 #> tau                                                 1.46   988    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:29:35 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\donttest{ # Fitting all possible node-splitting models smk_fit_RE_nodesplit <- nma(smk_net, refresh = if (interactive()) 200 else 0,                             consistency = \"nodesplit\",                             trt_effects = \"random\",                             prior_intercept = normal(scale = 100),                             prior_trt = normal(scale = 100),                             prior_het = normal(scale = 5)) #> Fitting model 1 of 7, node-split: Group counselling vs. No intervention #> Fitting model 2 of 7, node-split: Individual counselling vs. No intervention #> Fitting model 3 of 7, node-split: Self-help vs. No intervention #> Fitting model 4 of 7, node-split: Individual counselling vs. Group counselling #> Fitting model 5 of 7, node-split: Self-help vs. Group counselling #> Fitting model 6 of 7, node-split: Self-help vs. Individual counselling #> Fitting model 7 of 7, consistency model # }  # \\donttest{ # Summarise the node-splitting results summary(smk_fit_RE_nodesplit) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.10 0.45  0.20  0.80  1.10 1.39  2.02     2049     2334    1 #> d_dir            1.04 0.73 -0.33  0.57  1.02 1.49  2.55     3237     2713    1 #> d_ind            1.13 0.54  0.09  0.78  1.12 1.47  2.20     1631     1843    1 #> omega           -0.09 0.87 -1.75 -0.67 -0.10 0.48  1.67     2322     2527    1 #> tau              0.86 0.19  0.55  0.72  0.84 0.97  1.29     1328     2240    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.81 0.95  1.28     1412     2007    1 #>  #> Residual deviance: 54.4 (on 50 data points) #>                pD: 44.4 #>               DIC: 98.8 #>  #> Bayesian p-value: 0.92 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.84 0.24  0.38  0.68 0.84 0.99  1.34     1309     1864    1 #> d_dir           0.88 0.25  0.41  0.71 0.87 1.04  1.39     1708     2082    1 #> d_ind           0.56 0.68 -0.73  0.11 0.55 0.99  1.94     1820     2411    1 #> omega           0.32 0.71 -1.13 -0.13 0.31 0.78  1.71     1763     2167    1 #> tau             0.85 0.19  0.55  0.72 0.83 0.96  1.31     1260     1619    1 #> tau_consistency 0.84 0.19  0.54  0.71 0.81 0.95  1.28     1412     2007    1 #>  #> Residual deviance: 54.7 (on 50 data points) #>                pD: 44.5 #>               DIC: 99.2 #>  #> Bayesian p-value: 0.63 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.48 0.41 -0.32  0.21  0.47 0.74  1.33     1899     2329    1 #> d_dir            0.34 0.55 -0.73 -0.01  0.33 0.70  1.45     2648     2584    1 #> d_ind            0.71 0.65 -0.58  0.29  0.71 1.14  1.99     1748     2274    1 #> omega           -0.36 0.85 -2.04 -0.91 -0.35 0.20  1.34     1738     2054    1 #> tau              0.88 0.20  0.56  0.74  0.85 0.98  1.35     1222     1594    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.81 0.95  1.28     1412     2007    1 #>  #> Residual deviance: 53.7 (on 50 data points) #>                pD: 44.2 #>               DIC: 97.9 #>  #> Bayesian p-value: 0.65 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.26 0.44 -1.14 -0.53 -0.25  0.03  0.60     2690     2251    1 #> d_dir           -0.11 0.49 -1.10 -0.43 -0.11  0.22  0.85     3438     3024    1 #> d_ind           -0.54 0.63 -1.83 -0.94 -0.53 -0.13  0.66     1610     2154    1 #> omega            0.43 0.68 -0.93  0.01  0.43  0.86  1.84     1610     1954    1 #> tau              0.87 0.20  0.55  0.73  0.84  0.98  1.32     1143     1767    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.81  0.95  1.28     1412     2007    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44 #>               DIC: 97.6 #>  #> Bayesian p-value: 0.49 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.62 0.50 -1.65 -0.95 -0.62 -0.28  0.36     3158     2781    1 #> d_dir           -0.62 0.67 -1.97 -1.06 -0.61 -0.18  0.73     3778     2966    1 #> d_ind           -0.61 0.69 -1.97 -1.04 -0.61 -0.16  0.77     1605     1978    1 #> omega           -0.02 0.93 -1.88 -0.62 -0.01  0.59  1.79     2019     2153    1 #> tau              0.87 0.20  0.56  0.73  0.84  0.98  1.32     1130     1948    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.81  0.95  1.28     1412     2007    1 #>  #> Residual deviance: 54.3 (on 50 data points) #>                pD: 44.5 #>               DIC: 98.8 #>  #> Bayesian p-value: 0.99 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.36 0.42 -1.22 -0.64 -0.36 -0.09  0.48     2100     2403 1.00 #> d_dir            0.07 0.65 -1.17 -0.37  0.08  0.50  1.33     3012     2576 1.00 #> d_ind           -0.62 0.53 -1.67 -0.96 -0.61 -0.29  0.41     1873     2282 1.00 #> omega            0.69 0.83 -0.90  0.16  0.68  1.23  2.34     2067     2287 1.00 #> tau              0.85 0.20  0.55  0.71  0.82  0.96  1.30     1112     1792 1.01 #> tau_consistency  0.84 0.19  0.54  0.71  0.81  0.95  1.28     1412     2007 1.00 #>  #> Residual deviance: 54 (on 50 data points) #>                pD: 44.2 #>               DIC: 98.2 #>  #> Bayesian p-value: 0.38 # }  ## Plaque psoriasis ML-NMR # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.  # \\donttest{ # Fitting a ML-NMR model. # Specify a regression model to include effect modifier interactions for five # covariates, along with main (prognostic) effects. We use a probit link and # specify that the two-parameter Binomial approximation for the aggregate-level # likelihood should be used. We set treatment-covariate interactions to be equal # within each class. We narrow the possible range for random initial values with # init_r = 0.1, since probit models in particular are often hard to initialise. # Using the QR decomposition greatly improves sampling efficiency here, as is # often the case for regression models. pso_fit <- nma(pso_net, refresh = if (interactive()) 200 else 0,                trt_effects = \"fixed\",                link = \"probit\",                likelihood = \"bernoulli2\",                regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                class_interactions = \"common\",                prior_intercept = normal(scale = 10),                prior_trt = normal(scale = 10),                prior_reg = normal(scale = 10),                init_r = 0.1,                QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25% #> beta[durnpso]                           0.04    0.00 0.06    -0.08     0.00 #> beta[prevsys]                          -0.13    0.00 0.16    -0.44    -0.25 #> beta[bsa]                              -0.06    0.01 0.44    -0.96    -0.34 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02 #> beta[psa]                              -0.08    0.00 0.17    -0.42    -0.19 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.14    -0.06 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.19    -0.19     0.06 #> beta[prevsys:.trtclassIL blocker]       0.06    0.00 0.18    -0.28    -0.06 #> beta[bsa:.trtclassTNFa blocker]         0.05    0.01 0.51    -0.91    -0.29 #> beta[bsa:.trtclassIL blocker]           0.29    0.01 0.48    -0.64    -0.03 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.03    -0.24    -0.19 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12 #> beta[psa:.trtclassTNFa blocker]        -0.06    0.00 0.20    -0.43    -0.20 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.19    -0.36    -0.12 #> d[ETN]                                  1.55    0.00 0.08     1.39     1.50 #> d[IXE_Q2W]                              2.95    0.00 0.09     2.78     2.89 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.38     2.49 #> d[SEC_150]                              2.14    0.00 0.11     1.93     2.06 #> d[SEC_300]                              2.45    0.00 0.12     2.22     2.37 #> lp__                                -1576.39    0.09 3.57 -1584.60 -1578.52 #>                                          50%      75%    97.5% n_eff Rhat #> beta[durnpso]                           0.04     0.08     0.16  5171    1 #> beta[prevsys]                          -0.13    -0.02     0.19  4845    1 #> beta[bsa]                              -0.05     0.23     0.76  5025    1 #> beta[weight]                            0.04     0.06     0.10  5657    1 #> beta[psa]                              -0.08     0.04     0.25  4933    1 #> beta[durnpso:.trtclassTNFa blocker]    -0.03     0.02     0.12  5756    1 #> beta[durnpso:.trtclassIL blocker]      -0.01     0.03     0.13  6394    1 #> beta[prevsys:.trtclassTNFa blocker]     0.19     0.32     0.55  5072    1 #> beta[prevsys:.trtclassIL blocker]       0.06     0.19     0.40  6076    1 #> beta[bsa:.trtclassTNFa blocker]         0.04     0.38     1.12  5595    1 #> beta[bsa:.trtclassIL blocker]           0.28     0.60     1.27  5988    1 #> beta[weight:.trtclassTNFa blocker]     -0.17    -0.14    -0.10  6383    1 #> beta[weight:.trtclassIL blocker]       -0.10    -0.08    -0.04  6947    1 #> beta[psa:.trtclassTNFa blocker]        -0.06     0.09     0.34  5649    1 #> beta[psa:.trtclassIL blocker]           0.00     0.13     0.37  6083    1 #> d[ETN]                                  1.55     1.60     1.71  4252    1 #> d[IXE_Q2W]                              2.95     3.01     3.12  5053    1 #> d[IXE_Q4W]                              2.54     2.60     2.70  5317    1 #> d[SEC_150]                              2.14     2.22     2.37  4630    1 #> d[SEC_300]                              2.45     2.53     2.67  5112    1 #> lp__                                -1576.07 -1573.81 -1570.43  1638    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:32:26 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_data-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_data class — nma_data-class","title":"The nma_data class — nma_data-class","text":"nma_data class contains data NMA standard format, created using functions set_ipd(), set_agd_arm(), set_agd_contrast(), set_agd_surv(), combine_network(). sub-class mlnmr_data created function add_integration(), contains numerical integration points aggregate data.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_data-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_data class — nma_data-class","text":"Objects class nma_data following components: agd_arm data studies aggregate data (arm format) agd_contrast data studies aggregate data (contrast format) ipd data studies individual patient data treatments treatment coding factor entire network classes treatment class coding factor (length treatments entire network) studies study coding factor entire network outcome outcome type data source, named list agd_arm, agd_contrast, ipd components tibbles following columns: .study study (factor) .trt treatment (factor) .trtclass treatment class (factor), specified .y continuous outcome .se standard error (continuous) .r event count (discrete) .n event count denominator (discrete, agd_arm ) .E time risk (discrete) .Surv survival outcome type Surv (time--event), nested study arm .sample_size sample size (agd_* ) ... columns (typically covariates) original data frame Objects class mlnmr_data additionally components: n_int number numerical integration points int_names names covariates numerical integration points int_cor correlation matrix covariates used generate numerical integration points agd_arm agd_contrast tibbles additional list columns prefix .int_, one covariate, contain numerical integration points nested length-n_int vectors within row.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_dic-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_dic class — nma_dic-class","title":"The nma_dic class — nma_dic-class","text":"nma_dic class contains details Deviance Information Criterion (DIC), produced using dic() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_dic-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_dic class — nma_dic-class","text":"Objects class nma_dic following components: dic DIC value pd, pv effective number parameters resdev total residual deviance pointwise list data frames containing pointwise contributions IPD AgD. resdev_array 3D MCMC array [Iterations, Chains, Parameters] posterior residual deviance samples.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_nodesplit-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_nodesplit class — nma_nodesplit-class","title":"The nma_nodesplit class — nma_nodesplit-class","text":"nma_nodesplit nma_nodesplit_df classes contains results running node-splitting model function nma().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_nodesplit-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_nodesplit class — nma_nodesplit-class","text":"Objects class nma_nodesplit inherit stan_nma class, contain results fitting single node-split model. one additional component, nodesplit, gives comparison node-split length 2 vector. Objects class nma_nodesplit_df tibble data frames one row node-split comparison columns: trt1, trt2 Treatments forming comparison model list column containing results model nma_nodesplit object Optionally, additional row consistency model fitted (e.g. get_nodesplits(., include_consistency = TRUE)) trt1 trt2 NA.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_prior-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_prior class — nma_prior-class","title":"The nma_prior class — nma_prior-class","text":"nma_prior class used specify prior distributions.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_prior-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_prior class — nma_prior-class","text":"Objects class nma_prior following components: dist Distribution name fun Name constructor function, string (e.g. \"normal\") ... Parameters distribution distribution parameters, specified named components ..., match constructor functions (see priors).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_summary class — nma_summary-class","title":"The nma_summary class — nma_summary-class","text":"nma_summary class contains posterior summary statistics model parameters quantities interest, draws used obtain statistics.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_summary class — nma_summary-class","text":"Objects class nma_summary following components: summary data frame containing computed summary statistics. Column .trt indicates corresponding treatment, columns .trta .trtb indicate corresponding contrast (.trtb vs. .trta). regression model fitted effect modifier interactions treatment, summaries study-specific. case, corresponding study population indicated .study column. multinomial model fitted, .category column indicates corresponding category. sims 3D array [Iteration, Chain, Parameter] MCMC simulations studies (Optional) data frame containing study information, printed along corresponding summary statistics summary contains .study column. matching .study column. following attributes may also set: xlab Label x axis plots, usually either \"Treatment\" \"Contrast\". ylab Label y axis plots, usually used scale e.g. \"log Odds Ratio\". subclass nma_rank_probs used function posterior_rank_probs(), contains posterior rank probabilities. subclass sims component, rank probabilities posterior summaries ranks (.e. posterior distribution). posterior ranks rank probabilities calculated may obtained posterior_ranks().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for nma_summary objects — print.nma_summary","title":"Methods for nma_summary objects — print.nma_summary","text":".data.frame(), as_tibble(), .tibble() methods return posterior summary statistics data frame tibble. .matrix() method returns matrix posterior draws. .array() method returns 3D array [Iteration, Chain, Parameter] posterior draws (class mcmc_array).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for nma_summary objects — print.nma_summary","text":"","code":"# S3 method for nma_summary print(x, ..., digits = 2, pars, include = TRUE)  # S3 method for nma_summary as.data.frame(x, ...)  # S3 method for nma_summary as.tibble(x, ...)  # S3 method for nma_summary as_tibble(x, ...)  # S3 method for nma_summary as.array(x, ...)  # S3 method for nma_summary as.matrix(x, ...)  # S3 method for nma_rank_probs as.array(x, ...)  # S3 method for nma_rank_probs as.matrix(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for nma_summary objects — print.nma_summary","text":"x nma_summary object ... Additional arguments passed methods digits Integer number digits display pars Character vector parameters display printed summary include Logical, parameters named pars included (TRUE) excluded (FALSE)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for nma_summary objects — print.nma_summary","text":"data.frame .data.frame(), tbl_df .tibble() as_tibble(), matrix .matrix(), mcmc_array .array(). print() method returns x invisibly.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nodesplit_summary class — nodesplit_summary-class","title":"The nodesplit_summary class — nodesplit_summary-class","text":"nodesplit_summary class contains posterior summary statistics node-splitting models, result calling summary() nma_nodesplit nma_nodesplit_df object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nodesplit_summary class — nodesplit_summary-class","text":"Objects class nodesplit_summary tibble data frames, one row node-split comparison columns: trt1, trt2 Treatments forming comparison summary list column containing nma_summary objects posterior summaries draws node-splitting parameters p_value Bayesian p-value inconsistency dic list column containing nma_dic objects, giving model fit statistics parameters included summary : d_net Network estimate corresponding consistency model, available d_dir Direct estimate node-splitting model d_ind Indirect estimate node-splitting model omega Inconsistency factor \\(\\omega = d_\\mathrm{dir} -   d_\\mathrm{ind}\\) tau Heterogeneity standard deviation node-splitting model, random effects model fitted tau_consistency Heterogeneity standard deviation corresponding consistency model, available random effects model fitted","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for nodesplit_summary objects — print.nodesplit_summary","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":".data.frame(), as_tibble(), .tibble() methods return node-splitting summaries data frame tibble.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"","code":"# S3 method for nodesplit_summary print(x, ..., digits = 2)  # S3 method for nodesplit_summary as_tibble(x, ..., nest = FALSE)  as.tibble.nodesplit_summary(x, ..., nest = FALSE)  # S3 method for nodesplit_summary as.data.frame(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"x nodesplit_summary object ... Additional arguments passed methods digits Integer number digits display nest Whether return nested tibble, full nma_summary nma_dic objects, unnest summaries, default FALSE","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"data.frame .data.frame(), tbl_df .tibble() as_tibble(). print() method returns x invisibly.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix of plots for a stan_nma object — pairs.stan_nma","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"pairs() method stan_nma objects, calls bayesplot::mcmc_pairs() underlying stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"","code":"# S3 method for stan_nma pairs(x, ..., pars, include = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"x object class stan_nma ... arguments passed bayesplot::mcmc_pairs() pars Optional character vector parameter names include output. specified, parameters used. include Logical, parameters pars included (TRUE, default) excluded (FALSE)?","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"grid ggplot objects produced bayesplot::mcmc_pairs().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"","code":"if (FALSE) { ## Parkinson's mean off time reduction park_net <- set_agd_arm(parkinsons,                         study = studyn,                         trt = trtn,                         y = y,                         se = se,                         sample_size = n)  # Fitting a RE model park_fit_RE <- nma(park_net,                    trt_effects = \"random\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_het = half_normal(scale = 5))  # We see a small number of divergent transition errors # These do not go away entirely when adapt_delta is increased  # Try to diagnose with a pairs plot pairs(park_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\"))  # Transforming tau onto log scale pairs(park_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\"),       transformations = list(tau = \"log\"))  # The divergent transitions occur in the upper tail of the heterogeneity # standard deviation. In this case, with only a small number of studies, there # is not very much information to estimate the heterogeneity standard deviation # and the prior distribution may be too heavy-tailed. We could consider a more # informative prior distribution for the heterogeneity variance to aid # estimation. }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean off-time reduction in Parkison's disease — parkinsons","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"Data frame containing mean -time reduction patients given dopamine agonists adjunct therapy Parkinson's disease, 7 trials comparing four active drugs placebo (Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"","code":"parkinsons"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"data frame 15 rows 7 variables: studyn numeric study ID trtn numeric treatment code (placebo = 1) y mean -time reduction se standard error n sample size diff mean difference vs. treatment reference arm se_diff standard error mean difference, see details","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"dataset may analysed using either arm-based likelihood using y se, contrast-based likelihood using diff se_diff (combination two across different studies). contrast-based data formatted described set_agd_contrast(). , chosen reference arm study, mean difference diff set NA, se_diff set standard error se outcome reference arm.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":null,"dir":"Reference","previous_headings":"","what":"Plaque psoriasis data — plaque_psoriasis_ipd","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"Two data frames, plaque_psoriasis_ipd plaque_psoriasis_agd, containing (simulated) individual patient data four studies aggregate data five studies (Phillippo 2019) . Outcomes binary success/failure achieve 75%, 90%, 100% reduction symptoms Psoriasis Area Severity Index (PASI) scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"","code":"plaque_psoriasis_ipd  plaque_psoriasis_agd"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"individual patient data contained data frame plaque_psoriasis_ipd 4118 rows, one per individual, 16 variables: studyc study name trtc_long treatment name (long format) trtc treatment name trtn numeric treatment code pasi75 binary PASI 75 outcome pasi90 binary PASI 90 outcome pasi100 binary PASI 100 outcome age age (years) bmi body mass index (BMI) pasi_w0 PASI score week 0 male male sex (TRUE FALSE) bsa body surface area (percent) weight weight (kilograms) durnpso duration psoriasis (years) prevsys previous systemic treatment (TRUE FALSE) psa psoriatic arthritis (TRUE FALSE) aggregate data contained data frame plaque_psoriasis_agd 15 rows, one per study arm, 26 variables: studyc study name trtc_long treatment name (long format) trtc treatment name trtn numeric treatment code pasi75_r, pasi75_n PASI 75 outcome count denominator pasi90_r, pasi90_n PASI 75 outcome count denominator pasi100_r, pasi100_n PASI 75 outcome count denominator sample_size_w0 sample size week zero age_mean, age_sd mean standard deviation age (years) bmi_mean, bmi_sd mean standard deviation BMI pasi_w0_mean, pasi_w0_sd mean standard deviation PASI score week 0 male percentage males bsa_mean, bsa_sd mean standard deviation body surface area (percent) weight_mean, weight_sd mean standard deviation weight (kilograms) durnpso_mean, durnpso_sd mean standard deviation duration psoriasis (years) prevsys percentage individuals previous systemic treatment psa percentage individuals psoriatic arthritis object class data.frame 15 rows 26 columns.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"Phillippo DM (2019). Calibration Treatment Effects Network Meta-Analysis using Individual Patient Data. Ph.D. thesis, University Bristol. Available https://research-information.bris.ac.uk/.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Network plots — plot.nma_data","title":"Network plots — plot.nma_data","text":"Create network plot nma_data network object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Network plots — plot.nma_data","text":"","code":"# S3 method for nma_data plot(   x,   ...,   layout,   circular,   weight_edges = TRUE,   weight_nodes = FALSE,   show_trt_class = FALSE,   nudge = 0 )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Network plots — plot.nma_data","text":"x nma_data object plot ... Additional arguments passed ggraph() layout function layout type layout create. layout accepted ggraph() may used, including layout functions provided igraph. circular Whether use circular representation. See ggraph(). weight_edges Weight edges number studies? Default TRUE. weight_nodes Weight nodes total sample size? Default FALSE. show_trt_class Colour treatment nodes class, trt_class set? Default FALSE. nudge Numeric value nudge treatment labels away nodes weight_nodes = TRUE. Default 0 (adjustment label position). small value like 0.1 usually sufficient.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Network plots — plot.nma_data","text":"ggplot object, produced ggraph().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Network plots — plot.nma_data","text":"default equivalent layout = \"linear\" circular = TRUE, places treatment nodes circle order defined treatment factor variable. alternative layout may give good results simple networks \"sugiyama\", attempts minimise number edge crossings. weight_nodes = TRUE requires sample sizes specified aggregate data network, using sample_size option set_agd_*().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Network plots — plot.nma_data","text":"","code":"## Stroke prevention in atrial fibrillation # Setting up the network af_net <- set_agd_arm(atrial_fibrillation,                       study = studyc,                       trt = abbreviate(trtc, minlength = 3),                       r = r,                       n = n,                       trt_class = trt_class) af_net #> A network with 26 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                #>  ACTIVE-W      2: Sada | Lda+c               #>  AFASAK 1      3: Sada | Lda | P/c           #>  AFASAK 2      4: Sada | Fdw | Fdw+mda | Mda #>  BAATAF        2: Lada | P/c                 #>  BAFTA         2: Sada | Lda                 #>  CAFA          2: Sada | P/c                 #>  Chinese ATAFS 2: Sada | Lda                 #>  EAFT          3: Sada | Mda | P/c           #>  ESPS 2        4: Dpy | Lda | Lda+d | P/c    #>  JAST          2: Lda | P/c                  #>  ... plus 16 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 17, in 4 classes #> Total number of studies: 26 #> Reference treatment is: Sada #> Network is connected  # Basic plot plot(af_net)   # Turn off weighting edges by number of studies plot(af_net, weight_edges = FALSE)   # Turn on weighting nodes by sample size plot(af_net, weight_nodes = TRUE)   # Colour treatment nodes by class plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE)   # Nudge the treatment labels away from the nodes plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE, nudge = 0.1)   # Output may be customised using standard ggplot commands # For example, to display the legends below the plot: plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE) +   ggplot2::theme(legend.position = \"bottom\",                  legend.box = \"vertical\",                  legend.margin = ggplot2::margin(0, 0, 0, 0),                  legend.spacing = ggplot2::unit(0.5, \"lines\"))   # Choosing a different ggraph layout, hiding some legends plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE,      layout = \"star\") +   ggplot2::guides(edge_width = \"none\", size = \"none\")"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of model fit diagnostics — plot.nma_dic","title":"Plots of model fit diagnostics — plot.nma_dic","text":"plot() method nma_dic objects produced dic() produces several useful diagnostic plots checking model fit model comparison. detail plots interpretation given Dias et al. (2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of model fit diagnostics — plot.nma_dic","text":"","code":"# S3 method for nma_dic plot(   x,   y,   ...,   show_uncertainty = TRUE,   stat = \"pointinterval\",   orientation = c(\"vertical\", \"horizontal\", \"x\", \"y\") )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of model fit diagnostics — plot.nma_dic","text":"x nma_dic object y (Optional) second nma_dic object, produce \"dev-dev\" plots model comparison. ... Additional arguments passed methods show_uncertainty Logical, show uncertainty ggdist plot stat? Default TRUE. stat Character string specifying ggdist plot stat use show_uncertainty = TRUE, default \"pointinterval\". y provided, currently \"pointinterval\" supported. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"). used residual deviance plots, default \"vertical\".","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of model fit diagnostics — plot.nma_dic","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of model fit diagnostics — plot.nma_dic","text":"single nma_dic object given, plot residual deviance contribution data point produced. good fitting model, data point expected residual deviance 1; larger values indicate data points fit poorly model. two nma_dic objects given, \"dev-dev\" plot comparing residual deviance contributions model produced. Data points residual deviance contributions lying line equality fit equally well either model. Data points lying line equality indicate better fit second model (y); conversely, data points lying line equality indicate better fit first model (x). common use case compare standard consistency model (fitted using nma() consistency = \"consistency\") unrelated mean effects (UME) inconsistency model (fitted using nma() consistency = \"ume\"), check potential inconsistency. See Dias et al. (2011)  details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plots of model fit diagnostics — plot.nma_dic","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of model fit diagnostics — plot.nma_dic","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking FE NMA example if not already available if (!exists(\"smk_fit_FE\")) example(\"example_smk_fe\", run.donttest = TRUE) # } # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC of FE and RE models (smk_dic_FE <- dic(smk_fit_FE)) #> Residual deviance: 267.1 (on 50 data points) #>                pD: 27 #>               DIC: 294.1 (smk_dic_RE <- dic(smk_fit_RE))   # substantially better fit #> Residual deviance: 53.9 (on 50 data points) #>                pD: 43.8 #>               DIC: 97.8  # Plot residual deviance contributions under RE model plot(smk_dic_RE)   # Further customisation is possible using ggplot commands # For example, highlighting data points with residual deviance above a certain threshold plot(smk_dic_RE) +   ggplot2::aes(colour = ggplot2::after_stat(ifelse(y > 1.5, \"darkorange\", \"black\"))) +   ggplot2::scale_colour_identity()   # Or by posterior probability, for example here a central probability of 0.6 # corresponds to a lower tail probability of (1 - 0.6)/2 = 0.2 plot(smk_dic_RE, .width = c(0.6, 0.95)) +   ggplot2::aes(colour = ggplot2::after_stat(ifelse(ymin > 1, \"darkorange\", \"black\"))) +   ggplot2::scale_colour_identity()   # Check for inconsistency using UME model # } # \\donttest{ # Run smoking UME NMA example if not already available if (!exists(\"smk_fit_RE_UME\")) example(\"example_smk_ume\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC smk_dic_RE #> Residual deviance: 53.9 (on 50 data points) #>                pD: 43.8 #>               DIC: 97.8 (smk_dic_RE_UME <- dic(smk_fit_RE_UME))  # no difference in fit #> Residual deviance: 53 (on 50 data points) #>                pD: 44.4 #>               DIC: 97.4  # Compare residual deviance contributions with a \"dev-dev\" plot plot(smk_dic_RE, smk_dic_RE_UME)   # By default the dev-dev plot can be a little cluttered # Hiding the credible intervals plot(smk_dic_RE, smk_dic_RE_UME, show_uncertainty = FALSE)   # Changing transparency plot(smk_dic_RE, smk_dic_RE_UME, point_alpha = 0.5, interval_alpha = 0.1)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of summary results — plot.nma_summary","title":"Plots of summary results — plot.nma_summary","text":"plot method nma_summary objects used produce plots parameter estimates (called stan_nma object summary), relative effects (called output relative_effects()), absolute predictions (called output predict.stan_nma()), posterior ranks rank probabilities (called output posterior_ranks() posterior_rank_probs()).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of summary results — plot.nma_summary","text":"","code":"# S3 method for nma_summary plot(   x,   ...,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )  # S3 method for nma_parameter_summary plot(   x,   ...,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )  # S3 method for nma_rank_probs plot(x, ...)  # S3 method for surv_nma_summary plot(x, ..., stat = \"lineribbon\")"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of summary results — plot.nma_summary","text":"x nma_summary object ... Additional arguments passed underlying ggdist plot stat, see Details stat Character string specifying ggdist plot stat use, default \"pointinterval\", except plotting estimated survival/hazard/cumulative hazard curves survival models default \"lineribbon\" orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\" ref_line Numeric vector positions reference lines, default reference lines drawn","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of summary results — plot.nma_summary","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of summary results — plot.nma_summary","text":"Plotting handled ggplot2 stats geoms provided ggdist package. result, output flexible. plotting stats provided ggdist may used, via argument stat. default uses ggdist::stat_pointinterval(), produce medians 95% Credible Intervals 66% inner bands. Additional arguments ... passed ggdist stat, customise output. example, produce means Credible Intervals, specify point_interval = \"mean_qi\". produce 80% Credible Interval inner band, specify .width = c(0, 0.8). Alternative stats can specified produce different summaries. example, specify stat = \"[half]eye\" produce (half) eye plots, stat = \"histinterval\" produce histograms intervals. full list options examples found ggdist vignette vignette(\"slabinterval\", package = \"ggdist\"). survival/hazard/cumulative hazard curves estimated survival models, default uses ggdist::stat_lineribbon() produces curves posterior medians 50%, 80%, 95% Credible Interval bands. , additional arguments ... passed ggdist stat. example, produce posterior means 95% Credible bands, specify point_interval = \"mean_qi\" .width = 0.95. ggplot object returned can modified usual ggplot2 functions add aesthetics, geoms, themes, etc.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of summary results — plot.nma_summary","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce relative effects smk_releff_RE <- relative_effects(smk_fit_RE) plot(smk_releff_RE, ref_line = 0)   # Customise plot options plot(smk_releff_RE, ref_line = 0, stat = \"halfeye\")   # Further customisation is possible with ggplot commands plot(smk_releff_RE, ref_line = 0, stat = \"halfeye\", slab_alpha = 0.6) +   ggplot2::aes(slab_fill = ggplot2::after_stat(ifelse(x < 0, \"darkred\", \"grey60\")))   # Produce posterior ranks smk_rank_RE <- posterior_ranks(smk_fit_RE, lower_better = FALSE) plot(smk_rank_RE)   # Produce rank probabilities smk_rankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE) plot(smk_rankprob_RE)   # Produce cumulative rank probabilities smk_cumrankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE,                                            cumulative = TRUE) plot(smk_cumrankprob_RE)   # Further customisation is possible with ggplot commands plot(smk_cumrankprob_RE) +   ggplot2::facet_null() +   ggplot2::aes(colour = Treatment)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of node-splitting models — plot.nodesplit_summary","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"Produce summary plots node-splitting models","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"","code":"# S3 method for nodesplit_summary plot(   x,   ...,   pars = \"d\",   stat = \"dens_overlay\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"x nodesplit_summary object. ... Additional arguments passed underlying ggdist plot stat, see Details. pars Character vector specifying parameters include plot, choices include \"d\" direct, indirect, network estimates relative effects, \"omega\" inconsistency factor, \"tau\" heterogeneity standard deviation random effects models. Default \"d\". stat Character string specifying ggdist plot stat use. default \"dens_overlay\" special case, producing overlaid density plot. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\". ref_line Numeric vector positions reference lines, default reference lines drawn.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"Plotting handled ggplot2 stats geoms provided ggdist package. result, output flexible. plotting stats provided ggdist may used, via argument stat. default \"dens_overlay\" special exception, uses ggplot2::geom_density(), plot overlaid densities. Additional arguments ... passed ggdist stat, customise output. Alternative stats can specified produce different summaries. example, specify stat = \"[half]eye\" produce (half) eye plots, stat = \"pointinterval\" produce point estimates credible intervals. full list options examples found ggdist vignette vignette(\"slabinterval\", package = \"ggdist\"). ggplot object returned can modified usual ggplot2 functions add aesthetics, geoms, themes, etc.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"","code":"# \\donttest{ # Run smoking node-splitting example if not already available if (!exists(\"smk_fit_RE_nodesplit\")) example(\"example_smk_nodesplit\", run.donttest = TRUE) # } # \\donttest{ # Summarise the node-splitting results (smk_nodesplit_summary <- summary(smk_fit_RE_nodesplit)) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.11 0.44  0.30  0.81  1.09 1.38  2.01     1550     2236 1.00 #> d_dir            1.04 0.75 -0.37  0.56  1.01 1.51  2.65     3290     2892 1.00 #> d_ind            1.13 0.54  0.10  0.77  1.11 1.48  2.19     2003     2397 1.00 #> omega           -0.08 0.89 -1.79 -0.67 -0.10 0.48  1.77     2575     2533 1.00 #> tau              0.86 0.20  0.55  0.72  0.84 0.98  1.33      911     1859 1.01 #> tau_consistency  0.84 0.19  0.54  0.70  0.81 0.94  1.28     1139     1813 1.00 #>  #> Residual deviance: 54.3 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.6 #>  #> Bayesian p-value: 0.91 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.85 0.25  0.38  0.69 0.84 1.00  1.36     1141     1891    1 #> d_dir           0.87 0.25  0.39  0.71 0.87 1.03  1.40     2059     2549    1 #> d_ind           0.57 0.66 -0.69  0.13 0.56 0.99  1.92     1789     1980    1 #> omega           0.31 0.68 -1.09 -0.13 0.30 0.75  1.63     1749     1998    1 #> tau             0.85 0.19  0.55  0.72 0.83 0.96  1.27     1251     1951    1 #> tau_consistency 0.84 0.19  0.54  0.70 0.81 0.94  1.28     1139     1813    1 #>  #> Residual deviance: 54.3 (on 50 data points) #>                pD: 44.1 #>               DIC: 98.3 #>  #> Bayesian p-value: 0.63 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.49 0.40 -0.26  0.22  0.47 0.76  1.30     2152     2404 1.00 #> d_dir            0.34 0.56 -0.73 -0.02  0.35 0.70  1.46     3022     2635 1.00 #> d_ind            0.70 0.62 -0.52  0.31  0.69 1.10  1.99     1817     2356 1.00 #> omega           -0.36 0.82 -2.03 -0.89 -0.36 0.16  1.25     1706     2114 1.00 #> tau              0.88 0.21  0.56  0.73  0.85 0.99  1.37      891     1904 1.01 #> tau_consistency  0.84 0.19  0.54  0.70  0.81 0.94  1.28     1139     1813 1.00 #>  #> Residual deviance: 53.5 (on 50 data points) #>                pD: 44 #>               DIC: 97.6 #>  #> Bayesian p-value: 0.65 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.25 0.41 -1.09 -0.51 -0.25  0.01  0.54     2461     2011    1 #> d_dir           -0.12 0.49 -1.06 -0.43 -0.11  0.20  0.83     3334     3008    1 #> d_ind           -0.55 0.62 -1.80 -0.95 -0.55 -0.13  0.62     1602     2006    1 #> omega            0.43 0.68 -0.91 -0.04  0.43  0.88  1.79     1475     1944    1 #> tau              0.87 0.20  0.55  0.73  0.84  0.98  1.34     1023     1759    1 #> tau_consistency  0.84 0.19  0.54  0.70  0.81  0.94  1.28     1139     1813    1 #>  #> Residual deviance: 53.7 (on 50 data points) #>                pD: 44 #>               DIC: 97.7 #>  #> Bayesian p-value: 0.53 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.62 0.49 -1.60 -0.93 -0.61 -0.30  0.33     2759     2629 1.00 #> d_dir           -0.64 0.66 -1.92 -1.09 -0.63 -0.20  0.65     3824     2942 1.00 #> d_ind           -0.62 0.66 -1.95 -1.05 -0.62 -0.18  0.63     1886     2020 1.00 #> omega           -0.02 0.87 -1.75 -0.60 -0.03  0.56  1.67     2343     2870 1.00 #> tau              0.87 0.20  0.56  0.73  0.85  0.98  1.36      939     1635 1.01 #> tau_consistency  0.84 0.19  0.54  0.70  0.81  0.94  1.28     1139     1813 1.00 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.5 #>               DIC: 98.6 #>  #> Bayesian p-value: 0.98 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.36 0.42 -1.18 -0.63 -0.37 -0.10  0.46     2448     2165    1 #> d_dir            0.08 0.65 -1.23 -0.33  0.09  0.50  1.36     3826     3039    1 #> d_ind           -0.61 0.52 -1.64 -0.94 -0.61 -0.28  0.39     1827     2096    1 #> omega            0.70 0.79 -0.85  0.16  0.70  1.21  2.27     2413     2497    1 #> tau              0.85 0.20  0.55  0.71  0.83  0.96  1.33     1156     1659    1 #> tau_consistency  0.84 0.19  0.54  0.70  0.81  0.94  1.28     1139     1813    1 #>  #> Residual deviance: 54.6 (on 50 data points) #>                pD: 44.8 #>               DIC: 99.3 #>  #> Bayesian p-value: 0.37  # Plot the node-splitting results plot(smk_nodesplit_summary)   # Plot the inconsistency factors instead, change the plot stat to half-eye, # and add a reference line at 0 plot(smk_nodesplit_summary, pars = \"omega\", stat = \"halfeye\", ref_line = 0)   # Plot a comparison of the heterogeneity under the node-split models vs. # the consistency model plot(smk_nodesplit_summary, pars = \"tau\")  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot numerical integration error — plot_integration_error","title":"Plot numerical integration error — plot_integration_error","text":"ML-NMR models, plot estimated numerical integration error entire posterior distribution, number integration points increases. See (Phillippo et al. 2020; Phillippo 2019)  details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot numerical integration error — plot_integration_error","text":"","code":"plot_integration_error(   x,   ...,   stat = \"violin\",   orientation = c(\"vertical\", \"horizontal\", \"x\", \"y\"),   show_expected_rate = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot numerical integration error — plot_integration_error","text":"x object type stan_mlnmr ... Additional arguments passed ggdist plot stat. stat Character string specifying ggdist plot stat used summarise integration error posterior. Default \"violin\", equivalent \"eye\" cosmetic tweaks. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"vertical\" show_expected_rate Logical, show typical convergence rate \\(1/N\\)? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot numerical integration error — plot_integration_error","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot numerical integration error — plot_integration_error","text":"total number integration points set n_int argument add_integration(), intervals integration error estimated set int_thin argument nma(). typical convergence rate Quasi-Monte Carlo integration (used ) \\(1/N\\), default displayed plot output. integration error thinning interval \\(N_\\mathrm{thin}\\) estimated point posterior distribution subtracting final estimate (using n_int points) estimate using first \\(N_\\mathrm{thin}\\) points.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"note-for-survival-models","dir":"Reference","previous_headings":"","what":"Note for survival models","title":"Plot numerical integration error — plot_integration_error","text":"function supported survival/time--event models. save cumulative integration points efficiency reasons (time memory).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot numerical integration error — plot_integration_error","text":"","code":"## Plaque psoriasis ML-NMR # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.  # \\donttest{ # Fit the ML-NMR model pso_fit <- nma(pso_net, refresh = if (interactive()) 200 else 0,                trt_effects = \"fixed\",                link = \"probit\",                likelihood = \"bernoulli2\",                regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                class_interactions = \"common\",                prior_intercept = normal(scale = 10),                prior_trt = normal(scale = 10),                prior_reg = normal(scale = 10),                init_r = 0.1,                QR = TRUE,                # Set the thinning factor for saving the cumulative results                # (This also sets int_check = FALSE)                int_thin = 8) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25% #> beta[durnpso]                           0.04    0.00 0.06    -0.07     0.00 #> beta[prevsys]                          -0.13    0.00 0.16    -0.45    -0.24 #> beta[bsa]                              -0.07    0.01 0.44    -0.92    -0.36 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02 #> beta[psa]                              -0.08    0.00 0.17    -0.41    -0.19 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.15    -0.06 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.19    -0.20     0.06 #> beta[prevsys:.trtclassIL blocker]       0.06    0.00 0.18    -0.29    -0.06 #> beta[bsa:.trtclassTNFa blocker]         0.06    0.01 0.51    -0.94    -0.29 #> beta[bsa:.trtclassIL blocker]           0.29    0.01 0.48    -0.66    -0.06 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.19 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12 #> beta[psa:.trtclassTNFa blocker]        -0.06    0.00 0.21    -0.46    -0.19 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.18    -0.37    -0.11 #> d[ETN]                                  1.55    0.00 0.08     1.40     1.49 #> d[IXE_Q2W]                              2.95    0.00 0.08     2.79     2.89 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.38     2.49 #> d[SEC_150]                              2.14    0.00 0.11     1.92     2.07 #> d[SEC_300]                              2.45    0.00 0.12     2.22     2.37 #> lp__                                -1576.30    0.08 3.43 -1583.80 -1578.51 #>                                          50%      75%    97.5% n_eff Rhat #> beta[durnpso]                           0.04     0.08     0.16  5103    1 #> beta[prevsys]                          -0.13    -0.03     0.19  4888    1 #> beta[bsa]                              -0.06     0.23     0.78  5342    1 #> beta[weight]                            0.04     0.06     0.10  5359    1 #> beta[psa]                              -0.08     0.03     0.25  4877    1 #> beta[durnpso:.trtclassTNFa blocker]    -0.03     0.02     0.11  5209    1 #> beta[durnpso:.trtclassIL blocker]      -0.01     0.03     0.12  5937    1 #> beta[prevsys:.trtclassTNFa blocker]     0.19     0.32     0.56  5644    1 #> beta[prevsys:.trtclassIL blocker]       0.06     0.18     0.41  6059    1 #> beta[bsa:.trtclassTNFa blocker]         0.07     0.40     1.04  5041    1 #> beta[bsa:.trtclassIL blocker]           0.29     0.62     1.22  6734    1 #> beta[weight:.trtclassTNFa blocker]     -0.17    -0.14    -0.10  5868    1 #> beta[weight:.trtclassIL blocker]       -0.10    -0.08    -0.03  6486    1 #> beta[psa:.trtclassTNFa blocker]        -0.06     0.08     0.38  5288    1 #> beta[psa:.trtclassIL blocker]           0.00     0.13     0.37  6558    1 #> d[ETN]                                  1.55     1.61     1.70  3698    1 #> d[IXE_Q2W]                              2.95     3.01     3.12  4337    1 #> d[IXE_Q4W]                              2.54     2.60     2.70  4125    1 #> d[SEC_150]                              2.14     2.22     2.36  4399    1 #> d[SEC_300]                              2.45     2.53     2.68  4584    1 #> lp__                                -1575.97 -1573.79 -1570.54  1686    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Aug 30 14:35:10 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1).  # Plot numerical integration error plot_integration_error(pso_fit)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot prior vs posterior distribution — plot_prior_posterior","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"Produce plots comparing prior posterior distributions model parameters.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"","code":"plot_prior_posterior(   x,   ...,   prior = NULL,   post_args = list(),   prior_args = list(),   overlay = c(\"prior\", \"posterior\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"x stan_nma object ... Additional arguments passed methods prior Character vector selecting prior posterior distribution(s) plot. May include \"intercept\", \"trt\", \"het\", \"reg\", \"aux\", appropriate. post_args List arguments passed ggplot2::geom_histogram control plot output posterior distribution prior_args List arguments passed ggplot2::geom_path control plot output prior distribution. Additionally, n controls number points density curve evaluated (default 500), p_limits controls endpoints curve quantiles (default c(.001, .999)). overlay String, prior posterior shown top? Default \"prior\". ref_line Numeric vector positions reference lines, default reference lines drawn","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"Prior distributions displayed lines, posterior distributions displayed histograms.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"","code":"## Smoking cessation NMA # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Plot prior vs. posterior, by default all parameters are plotted plot_prior_posterior(smk_fit_RE)   # Plot prior vs. posterior for heterogeneity SD only plot_prior_posterior(smk_fit_RE, prior = \"het\")   # Customise plot plot_prior_posterior(smk_fit_RE, prior = \"het\",                      prior_args = list(colour = \"darkred\", size = 2),                      post_args = list(alpha = 0.6))  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":null,"dir":"Reference","previous_headings":"","what":"Treatment rankings and rank probabilities — posterior_ranks","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"Produce posterior treatment rankings rank probabilities fitted NMA model. meta-regression fitted effect modifier interactions treatment, differ study population.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"","code":"posterior_ranks(   x,   newdata = NULL,   study = NULL,   lower_better = TRUE,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   sucra = FALSE,   summary = TRUE )  posterior_rank_probs(   x,   newdata = NULL,   study = NULL,   lower_better = TRUE,   cumulative = FALSE,   sucra = FALSE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"x stan_nma object created nma() newdata used regression model fitted. data frame study details, one row per study, giving covariate values produce relative effects. Column names must match variables regression model. NULL, relative effects produced studies network. study Column newdata specifies study names, otherwise studies labelled row number. lower_better Logical, lower treatment effects better (TRUE; default) higher better (FALSE)? See details. probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) sucra Logical, calculate surface cumulative ranking curve (SUCRA) treatment? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE. cumulative Logical, return cumulative rank probabilities? Default FALSE, return posterior probabilities treatment given rank. TRUE, cumulative posterior rank probabilities returned treatment given rank better.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"function posterior_ranks() produces posterior rankings, distribution (e.g. mean/median rank 95% Credible Interval). function posterior_rank_probs() produces rank probabilities, give posterior probabilities ranked first, second, etc. treatments. argument lower_better specifies whether lower treatment effects higher treatment effects preferred. example, negative binary outcome lower (negative) log odds ratios preferred, lower_better = TRUE. Conversely, example, treatments aim increase rate positive outcome lower_better = FALSE.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce posterior ranks smk_rank_RE <- posterior_ranks(smk_fit_RE, lower_better = FALSE) smk_rank_RE #>                              mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[No intervention]        3.89 0.32    3   4   4   4     4     2360       NA #> rank[Group counselling]      1.37 0.62    1   1   1   2     3     2764     2594 #> rank[Individual counselling] 1.93 0.63    1   2   2   2     3     2453     2680 #> rank[Self-help]              2.81 0.70    1   3   3   3     4     2141       NA #>                              Rhat #> rank[No intervention]           1 #> rank[Group counselling]         1 #> rank[Individual counselling]    1 #> rank[Self-help]                 1 plot(smk_rank_RE)   # Produce rank probabilities smk_rankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE) smk_rankprob_RE #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.11      0.89 #> d[Group counselling]           0.70      0.24      0.06      0.00 #> d[Individual counselling]      0.24      0.60      0.16      0.00 #> d[Self-help]                   0.06      0.17      0.66      0.11 plot(smk_rankprob_RE)   # Produce cumulative rank probabilities smk_cumrankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE,                                            cumulative = TRUE) smk_cumrankprob_RE #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.11         1 #> d[Group counselling]           0.70      0.93      1.00         1 #> d[Individual counselling]      0.24      0.84      1.00         1 #> d[Self-help]                   0.06      0.23      0.89         1 plot(smk_cumrankprob_RE)   # Further customisation is possible with ggplot commands plot(smk_cumrankprob_RE) +   ggplot2::facet_null() +   ggplot2::aes(colour = Treatment)  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Produce population-adjusted rankings for all study populations in # the network  # Ranks pso_rank <- posterior_ranks(pso_fit) pso_rank #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[FIXTURE: PBO]     1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[FIXTURE: ETN]     2.00 0.00    2   2   2   2     2       NA       NA   NA #> rank[FIXTURE: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[FIXTURE: IXE_Q4W] 4.78 0.41    4   5   5   5     5     4445       NA    1 #> rank[FIXTURE: SEC_150] 3.00 0.07    3   3   3   3     3     2265     2315    1 #> rank[FIXTURE: SEC_300] 4.22 0.42    4   4   4   4     5     4538       NA    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-1: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-1: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-1: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA #> rank[UNCOVER-1: IXE_Q4W] 4.78 0.41    4   5   5   5     5     4445       NA #> rank[UNCOVER-1: SEC_150] 3.00 0.07    3   3   3   3     3     2265     2315 #> rank[UNCOVER-1: SEC_300] 4.22 0.42    4   4   4   4     5     4538       NA #>                          Rhat #> rank[UNCOVER-1: PBO]       NA #> rank[UNCOVER-1: ETN]       NA #> rank[UNCOVER-1: IXE_Q2W]   NA #> rank[UNCOVER-1: IXE_Q4W]    1 #> rank[UNCOVER-1: SEC_150]    1 #> rank[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-2: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-2: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-2: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA #> rank[UNCOVER-2: IXE_Q4W] 4.78 0.41    4   5   5   5     5     4445       NA #> rank[UNCOVER-2: SEC_150] 3.00 0.07    3   3   3   3     3     2265     2315 #> rank[UNCOVER-2: SEC_300] 4.22 0.42    4   4   4   4     5     4538       NA #>                          Rhat #> rank[UNCOVER-2: PBO]       NA #> rank[UNCOVER-2: ETN]       NA #> rank[UNCOVER-2: IXE_Q2W]   NA #> rank[UNCOVER-2: IXE_Q4W]    1 #> rank[UNCOVER-2: SEC_150]    1 #> rank[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-3: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-3: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-3: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA #> rank[UNCOVER-3: IXE_Q4W] 4.78 0.41    4   5   5   5     5     4445       NA #> rank[UNCOVER-3: SEC_150] 3.00 0.07    3   3   3   3     3     2265     2315 #> rank[UNCOVER-3: SEC_300] 4.22 0.42    4   4   4   4     5     4538       NA #>                          Rhat #> rank[UNCOVER-3: PBO]       NA #> rank[UNCOVER-3: ETN]       NA #> rank[UNCOVER-3: IXE_Q2W]   NA #> rank[UNCOVER-3: IXE_Q4W]    1 #> rank[UNCOVER-3: SEC_150]    1 #> rank[UNCOVER-3: SEC_300]    1 #>  plot(pso_rank)   # Rank probabilities pso_rankprobs <- posterior_rank_probs(pso_fit) pso_rankprobs #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             1         0         0      0.00      0.00         0 #> d[FIXTURE: ETN]             0         1         0      0.00      0.00         0 #> d[FIXTURE: IXE_Q2W]         0         0         0      0.00      0.00         1 #> d[FIXTURE: IXE_Q4W]         0         0         0      0.22      0.78         0 #> d[FIXTURE: SEC_150]         0         0         1      0.00      0.00         0 #> d[FIXTURE: SEC_300]         0         0         0      0.78      0.22         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-1: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-1: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-1: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-1: IXE_Q4W]         0         0         0      0.22      0.78 #> d[UNCOVER-1: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-1: SEC_300]         0         0         0      0.78      0.22 #>                       p_rank[6] #> d[UNCOVER-1: PBO]             0 #> d[UNCOVER-1: ETN]             0 #> d[UNCOVER-1: IXE_Q2W]         1 #> d[UNCOVER-1: IXE_Q4W]         0 #> d[UNCOVER-1: SEC_150]         0 #> d[UNCOVER-1: SEC_300]         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-2: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-2: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-2: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-2: IXE_Q4W]         0         0         0      0.22      0.78 #> d[UNCOVER-2: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-2: SEC_300]         0         0         0      0.78      0.22 #>                       p_rank[6] #> d[UNCOVER-2: PBO]             0 #> d[UNCOVER-2: ETN]             0 #> d[UNCOVER-2: IXE_Q2W]         1 #> d[UNCOVER-2: IXE_Q4W]         0 #> d[UNCOVER-2: SEC_150]         0 #> d[UNCOVER-2: SEC_300]         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-3: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-3: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-3: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-3: IXE_Q4W]         0         0         0      0.22      0.78 #> d[UNCOVER-3: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-3: SEC_300]         0         0         0      0.78      0.22 #>                       p_rank[6] #> d[UNCOVER-3: PBO]             0 #> d[UNCOVER-3: ETN]             0 #> d[UNCOVER-3: IXE_Q2W]         1 #> d[UNCOVER-3: IXE_Q4W]         0 #> d[UNCOVER-3: SEC_150]         0 #> d[UNCOVER-3: SEC_300]         0 #>  plot(pso_rankprobs)   # Cumulative rank probabilities pso_cumrankprobs <- posterior_rank_probs(pso_fit, cumulative = TRUE) pso_cumrankprobs #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             1         1         1      1.00         1         1 #> d[FIXTURE: ETN]             0         1         1      1.00         1         1 #> d[FIXTURE: IXE_Q2W]         0         0         0      0.00         0         1 #> d[FIXTURE: IXE_Q4W]         0         0         0      0.22         1         1 #> d[FIXTURE: SEC_150]         0         0         1      1.00         1         1 #> d[FIXTURE: SEC_300]         0         0         0      0.78         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-1: PBO]             1         1         1      1.00         1 #> d[UNCOVER-1: ETN]             0         1         1      1.00         1 #> d[UNCOVER-1: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-1: IXE_Q4W]         0         0         0      0.22         1 #> d[UNCOVER-1: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-1: SEC_300]         0         0         0      0.78         1 #>                       p_rank[6] #> d[UNCOVER-1: PBO]             1 #> d[UNCOVER-1: ETN]             1 #> d[UNCOVER-1: IXE_Q2W]         1 #> d[UNCOVER-1: IXE_Q4W]         1 #> d[UNCOVER-1: SEC_150]         1 #> d[UNCOVER-1: SEC_300]         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-2: PBO]             1         1         1      1.00         1 #> d[UNCOVER-2: ETN]             0         1         1      1.00         1 #> d[UNCOVER-2: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-2: IXE_Q4W]         0         0         0      0.22         1 #> d[UNCOVER-2: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-2: SEC_300]         0         0         0      0.78         1 #>                       p_rank[6] #> d[UNCOVER-2: PBO]             1 #> d[UNCOVER-2: ETN]             1 #> d[UNCOVER-2: IXE_Q2W]         1 #> d[UNCOVER-2: IXE_Q4W]         1 #> d[UNCOVER-2: SEC_150]         1 #> d[UNCOVER-2: SEC_300]         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-3: PBO]             1         1         1      1.00         1 #> d[UNCOVER-3: ETN]             0         1         1      1.00         1 #> d[UNCOVER-3: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-3: IXE_Q4W]         0         0         0      0.22         1 #> d[UNCOVER-3: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-3: SEC_300]         0         0         0      0.78         1 #>                       p_rank[6] #> d[UNCOVER-3: PBO]             1 #> d[UNCOVER-3: ETN]             1 #> d[UNCOVER-3: IXE_Q2W]         1 #> d[UNCOVER-3: IXE_Q4W]         1 #> d[UNCOVER-3: SEC_150]         1 #> d[UNCOVER-3: SEC_300]         1 #>  plot(pso_cumrankprobs)   # Produce population-adjusted rankings for a different target # population new_agd_means <- data.frame(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3)  # Ranks posterior_ranks(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                      mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[New 1: PBO]     1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[New 1: ETN]     2.00 0.00    2   2   2   2     2       NA       NA   NA #> rank[New 1: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[New 1: IXE_Q4W] 4.78 0.41    4   5   5   5     5     4445       NA    1 #> rank[New 1: SEC_150] 3.00 0.07    3   3   3   3     3     2265     2315    1 #> rank[New 1: SEC_300] 4.22 0.42    4   4   4   4     5     4538       NA    1 #>   # Rank probabilities posterior_rank_probs(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[New 1: PBO]             1         0         0      0.00      0.00         0 #> d[New 1: ETN]             0         1         0      0.00      0.00         0 #> d[New 1: IXE_Q2W]         0         0         0      0.00      0.00         1 #> d[New 1: IXE_Q4W]         0         0         0      0.22      0.78         0 #> d[New 1: SEC_150]         0         0         1      0.00      0.00         0 #> d[New 1: SEC_300]         0         0         0      0.78      0.22         0 #>   # Cumulative rank probabilities posterior_rank_probs(pso_fit, newdata = new_agd_means,                      cumulative = TRUE) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[New 1: PBO]             1         1         1      1.00         1         1 #> d[New 1: ETN]             0         1         1      1.00         1         1 #> d[New 1: IXE_Q2W]         0         0         0      0.00         0         1 #> d[New 1: IXE_Q4W]         0         0         0      0.22         1         1 #> d[New 1: SEC_150]         0         0         1      1.00         1         1 #> d[New 1: SEC_300]         0         0         0      0.78         1         1 #>  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions of absolute effects from NMA models — predict.stan_nma","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Obtain predictions absolute effects NMA models fitted nma(). example, model fitted binary data logit link, predicted outcome probabilities log odds can produced. survival models, predictions can made survival probabilities, (cumulative) hazards, (restricted) mean survival times, quantiles including median survival times. IPD NMA ML-NMR model fitted, predictions can produced either individual level aggregate level. Aggregate-level predictions population-average absolute effects; marginalised standardised population. example, average event probabilities logistic regression, marginal (standardised) survival probabilities survival model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"","code":"# S3 method for stan_nma predict(   object,   ...,   baseline = NULL,   newdata = NULL,   study = NULL,   trt_ref = NULL,   type = c(\"link\", \"response\"),   level = c(\"aggregate\", \"individual\"),   baseline_type = c(\"link\", \"response\"),   baseline_level = c(\"individual\", \"aggregate\"),   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE )  # S3 method for stan_nma_surv predict(   object,   times = NULL,   ...,   baseline = NULL,   aux = NULL,   newdata = NULL,   study = NULL,   trt_ref = NULL,   type = c(\"survival\", \"hazard\", \"cumhaz\", \"mean\", \"median\", \"quantile\", \"rmst\", \"link\"),   quantiles = c(0.25, 0.5, 0.75),   level = c(\"aggregate\", \"individual\"),   times_seq = NULL,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"object stan_nma object created nma(). ... Additional arguments, passed uniroot() regression models baseline_level = \"aggregate\". baseline optional distr() distribution baseline response (.e. intercept), produce absolute effects. Can also character string naming study network take estimated baseline response distribution . NULL, predictions produced using baseline response study network IPD arm-based AgD. regression models, may list distr() distributions (study names network use baseline distributions ) length number studies newdata, possibly named studies newdata otherwise order appearance newdata. Use baseline_type baseline_level arguments specify whether distribution response linear predictor scale, (ML-NMR models including IPD) whether applies individual reference level covariates entire newdata population, respectively. example, model logit link baseline_type = \"link\", distribution baseline log odds event. survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_type always \"link\", baseline_level \"individual\" IPD NMA ML-NMR, \"aggregate\" AgD NMA). Use trt_ref argument specify treatment distribution applies . newdata required regression model fitted baseline specified. data frame covariate details, produce predictions. Column names must match variables regression model. level = \"aggregate\" either data frame integration points produced add_integration() (one row per study), data frame individual covariate values (one row per individual) summarised . level = \"individual\" data frame individual covariate values, one row per individual. NULL, predictions produced studies IPD /arm-based AgD network, depending value level. study Column newdata specifies study names IDs. specified: newdata contains integration points produced add_integration(), studies labelled sequentially row; otherwise data assumed come single study. trt_ref Treatment baseline response distribution refers, baseline specified. default, baseline response distribution refer network reference treatment. Coerced character string. type Whether produce predictions \"link\" scale (default, e.g. log odds) \"response\" scale (e.g. probabilities). survival models, options \"survival\" survival probabilities (default), \"hazard\" hazards, \"cumhaz\" cumulative hazards, \"mean\" mean survival times, \"quantile\" quantiles survival time distribution, \"median\" median survival times (equivalent type = \"quantile\" quantiles = 0.5), \"rmst\" restricted mean survival times, \"link\" linear predictor. type = \"survival\", \"hazard\" \"cumhaz\", predictions given times specified times event/censoring times network times = NULL. type = \"rmst\", restricted time horizon specified times, times = NULL earliest last follow-time amongst studies network used. level = \"aggregate\", correspond standardised survival function (see details). level level predictions produced, either \"aggregate\" (default), \"individual\". baseline specified, predictions produced IPD studies network level \"individual\" \"aggregate\", arm-based AgD studies network level \"aggregate\". baseline_type baseline distribution given, specifies whether corresponds \"link\" scale (default, e.g. log odds) \"response\" scale (e.g. probabilities). survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_type always \"link\"). baseline_level baseline distribution given, specifies whether corresponds individual reference level covariates (\"individual\", default), (unadjusted) average outcome reference treatment newdata population (\"aggregate\"). Ignored AgD NMA, since option \"aggregate\" instance. survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_level \"individual\" IPD NMA ML-NMR, \"aggregate\" AgD NMA). probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) predictive_distribution Logical, random effects model fitted, predictive distribution absolute effects new study returned? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE. times numeric vector times evaluate predictions . Alternatively, newdata specified, times can name column newdata contains times. NULL (default) predictions made event/censoring times studies included network (according times_seq). used type \"survival\", \"hazard\", \"cumhaz\" \"rmst\". aux optional distr() distribution auxiliary parameter(s) baseline hazard (e.g. shapes). Can also character string naming study network take estimated auxiliary parameter distribution . NULL, predictions produced using parameter estimates study network IPD arm-based AgD. regression models, may list distr() distributions (study names network use auxiliary parameters ) length number studies newdata, possibly named study names otherwise order appearance newdata. quantiles numeric vector quantiles survival time distribution produce estimates type = \"quantile\". times_seq positive integer, specified evaluate predictions many evenly-spaced event times 0 latest follow-time study, instead every observed event/censoring time. used newdata = NULL type \"survival\", \"hazard\" \"cumhaz\". can useful plotting survival (cumulative) hazard curves, prediction every observed even/censoring time unnecessary can slow. call within plot() detected, e.g. like plot(predict(fit, type = \"survival\")), times_seq default 50.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"aggregate-level-predictions-from-ipd-nma-and-ml-nmr-models","dir":"Reference","previous_headings":"","what":"Aggregate-level predictions from IPD NMA and ML-NMR models","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Population-average absolute effects can produced IPD NMA ML-NMR models level = \"aggregate\". Predictions averaged target population (.e. standardised/marginalised), either (numerical) integration joint covariate distribution (AgD studies network ML-NMR, AgD newdata integration points created add_integration()), averaging predictions sample individuals (IPD studies network IPD NMA/ML-NMR, IPD newdata). example, binary outcome, population-average event probabilities treatment \\(k\\) study/population \\(j\\) $$\\bar{p}_{jk} = \\int_\\mathfrak{X} p_{jk}(\\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x}$$ joint covariate distribution \\(f_{jk}(\\mathbf{x})\\) support \\(\\mathfrak{X}\\) $$\\bar{p}_{jk} = \\sum_i p_{jk}(\\mathbf{x}_i)$$ sample individuals covariates \\(\\mathbf{x}_i\\). Population-average absolute predictions follow similarly types outcomes, however survival outcomes specific considerations.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"standardised-survival-predictions","dir":"Reference","previous_headings":"","what":"Standardised survival predictions","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Different types population-average survival predictions, often called standardised survival predictions, follow standardised survival function created integrating (equivalently averaging) individual-level survival functions time \\(t\\): $$\\bar{S}_{jk}(t) = \\int_\\mathfrak{X} S_{jk}(t | \\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x}$$ produced using type = \"survival\". standardised hazard function corresponding standardised survival function weighted average individual-level hazard functions $$\\bar{h}_{jk}(t) = \\frac{\\int_\\mathfrak{X} S_{jk}(t | \\mathbf{x}) h_{jk}(t | \\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x} }{\\bar{S}_{jk}(t)}$$ weighted probability surviving time \\(t\\). produced using type = \"hazard\". corresponding standardised cumulative hazard function $$\\bar{H}_{jk}(t) = -\\log(\\bar{S}_{jk}(t))$$ produced using type = \"cumhaz\". Quantiles medians standardised survival times found solving $$\\bar{S}_{jk}(t) = 1-\\alpha$$ \\(\\alpha\\%\\) quantile, using numerical root finding. produced using type = \"quantile\" \"median\". (Restricted) means standardised survival times found integrating $$\\mathrm{RMST}_{jk}(t^*) = \\int_0^{t^*} \\bar{S}_{jk}(t) dt$$ restricted time horizon \\(t^*\\), \\(t^*=\\infty\\) mean standardised survival time. produced using type = \"rmst\" \"mean\".","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Predicted log odds of success in each study in the network predict(smk_fit_RE) #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[1: No intervention]        -2.78 0.32 -3.43 -2.99 -2.77 -2.55 -2.17 #> pred[1: Group counselling]      -1.67 0.51 -2.65 -2.02 -1.69 -1.34 -0.66 #> pred[1: Individual counselling] -1.93 0.38 -2.68 -2.18 -1.93 -1.67 -1.18 #> pred[1: Self-help]              -2.28 0.51 -3.28 -2.61 -2.28 -1.96 -1.26 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[1: No intervention]            5429     2875    1 #> pred[1: Group counselling]          2871     3042    1 #> pred[1: Individual counselling]     2854     2901    1 #> pred[1: Self-help]                  2432     2755    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[2: No intervention]        -2.58 0.77 -4.18 -3.07 -2.56 -2.10 -1.09 #> pred[2: Group counselling]      -1.48 0.77 -3.06 -1.96 -1.48 -0.99  0.01 #> pred[2: Individual counselling] -1.74 0.76 -3.31 -2.21 -1.72 -1.25 -0.25 #> pred[2: Self-help]              -2.09 0.77 -3.70 -2.57 -2.08 -1.60 -0.54 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[2: No intervention]            2514     2441    1 #> pred[2: Group counselling]          2944     2436    1 #> pred[2: Individual counselling]     2837     2499    1 #> pred[2: Self-help]                  3014     2490    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[3: No intervention]        -2.14 0.12 -2.39 -2.22 -2.14 -2.06 -1.90 #> pred[3: Group counselling]      -1.04 0.44 -1.87 -1.34 -1.05 -0.75 -0.12 #> pred[3: Individual counselling] -1.30 0.26 -1.80 -1.47 -1.29 -1.12 -0.79 #> pred[3: Self-help]              -1.65 0.42 -2.45 -1.93 -1.64 -1.37 -0.79 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[3: No intervention]            8828     2595 1.00 #> pred[3: Group counselling]          2367     2854 1.00 #> pred[3: Individual counselling]     1469     2123 1.01 #> pred[3: Self-help]                  1779     2408 1.00 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[4: No intervention]        -4.06 0.57 -5.27 -4.42 -4.02 -3.65 -3.01 #> pred[4: Group counselling]      -2.95 0.68 -4.34 -3.40 -2.94 -2.49 -1.65 #> pred[4: Individual counselling] -3.21 0.58 -4.46 -3.58 -3.17 -2.82 -2.14 #> pred[4: Self-help]              -3.56 0.68 -4.97 -4.00 -3.55 -3.10 -2.26 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[4: No intervention]            4040     2969    1 #> pred[4: Group counselling]          3678     3003    1 #> pred[4: Individual counselling]     3506     2698    1 #> pred[4: Self-help]                  2855     2152    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[5: No intervention]        -2.15 0.14 -2.44 -2.25 -2.15 -2.06 -1.89 #> pred[5: Group counselling]      -1.05 0.45 -1.88 -1.35 -1.07 -0.75 -0.10 #> pred[5: Individual counselling] -1.31 0.27 -1.83 -1.49 -1.31 -1.13 -0.75 #> pred[5: Self-help]              -1.66 0.43 -2.46 -1.94 -1.67 -1.39 -0.79 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[5: No intervention]            7705     2528    1 #> pred[5: Group counselling]          2467     2669    1 #> pred[5: Individual counselling]     1495     2451    1 #> pred[5: Self-help]                  1797     2303    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[6: No intervention]        -3.42 0.75 -5.01 -3.88 -3.37 -2.89 -2.18 #> pred[6: Group counselling]      -2.32 0.83 -4.04 -2.85 -2.27 -1.75 -0.82 #> pred[6: Individual counselling] -2.58 0.73 -4.13 -3.02 -2.53 -2.07 -1.31 #> pred[6: Self-help]              -2.93 0.83 -4.71 -3.42 -2.88 -2.35 -1.47 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[6: No intervention]            3402     2533    1 #> pred[6: Group counselling]          3321     2826    1 #> pred[6: Individual counselling]     3477     2541    1 #> pred[6: Self-help]                  2875     2546    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[7: No intervention]        -3.04 0.44 -4.00 -3.31 -3.01 -2.73 -2.25 #> pred[7: Group counselling]      -1.93 0.58 -3.12 -2.31 -1.92 -1.53 -0.83 #> pred[7: Individual counselling] -2.19 0.46 -3.18 -2.49 -2.17 -1.87 -1.34 #> pred[7: Self-help]              -2.54 0.57 -3.76 -2.91 -2.53 -2.15 -1.45 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[7: No intervention]            3744     2881    1 #> pred[7: Group counselling]          3062     2703    1 #> pred[7: Individual counselling]     2979     2344    1 #> pred[7: Self-help]                  2581     2174    1 #>  #> ---------------------------------------------------------------------- Study: 8 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[8: No intervention]        -2.69 0.58 -3.96 -3.04 -2.66 -2.29 -1.66 #> pred[8: Group counselling]      -1.59 0.69 -3.02 -2.02 -1.57 -1.14 -0.27 #> pred[8: Individual counselling] -1.85 0.57 -3.07 -2.20 -1.82 -1.45 -0.78 #> pred[8: Self-help]              -2.20 0.69 -3.67 -2.62 -2.17 -1.73 -0.91 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[8: No intervention]            3731     2733    1 #> pred[8: Group counselling]          3474     2993    1 #> pred[8: Individual counselling]     3398     2894    1 #> pred[8: Self-help]                  2821     2599    1 #>  #> ---------------------------------------------------------------------- Study: 9 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[9: No intervention]        -1.84 0.42 -2.68 -2.11 -1.83 -1.55 -1.08 #> pred[9: Group counselling]      -0.74 0.59 -1.88 -1.12 -0.75 -0.35  0.40 #> pred[9: Individual counselling] -1.00 0.46 -1.91 -1.30 -0.99 -0.69 -0.11 #> pred[9: Self-help]              -1.35 0.57 -2.47 -1.71 -1.35 -0.97 -0.22 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[9: No intervention]            5062     3044    1 #> pred[9: Group counselling]          3116     3109    1 #> pred[9: Individual counselling]     3351     3271    1 #> pred[9: Self-help]                  2780     2545    1 #>  #> --------------------------------------------------------------------- Study: 10 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[10: No intervention]        -2.08 0.12 -2.32 -2.16 -2.08 -2.00 -1.84 #> pred[10: Group counselling]      -0.97 0.44 -1.79 -1.27 -0.99 -0.68 -0.03 #> pred[10: Individual counselling] -1.23 0.26 -1.74 -1.41 -1.24 -1.06 -0.71 #> pred[10: Self-help]              -1.58 0.42 -2.38 -1.87 -1.59 -1.32 -0.74 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[10: No intervention]            6860     2246    1 #> pred[10: Group counselling]          2333     2728    1 #> pred[10: Individual counselling]     1433     2355    1 #> pred[10: Self-help]                  1722     2057    1 #>  #> --------------------------------------------------------------------- Study: 11 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[11: No intervention]        -3.62 0.23 -4.10 -3.78 -3.62 -3.46 -3.20 #> pred[11: Group counselling]      -2.52 0.48 -3.42 -2.85 -2.53 -2.20 -1.54 #> pred[11: Individual counselling] -2.78 0.33 -3.43 -3.00 -2.78 -2.56 -2.13 #> pred[11: Self-help]              -3.13 0.44 -3.98 -3.42 -3.13 -2.86 -2.24 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[11: No intervention]            6150     3170    1 #> pred[11: Group counselling]          2575     2924    1 #> pred[11: Individual counselling]     2071     2786    1 #> pred[11: Self-help]                  1922     2285    1 #>  #> --------------------------------------------------------------------- Study: 12 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[12: No intervention]        -2.22 0.13 -2.47 -2.30 -2.22 -2.13 -1.97 #> pred[12: Group counselling]      -1.11 0.45 -1.94 -1.42 -1.13 -0.83 -0.20 #> pred[12: Individual counselling] -1.37 0.27 -1.87 -1.55 -1.38 -1.20 -0.84 #> pred[12: Self-help]              -1.72 0.43 -2.52 -2.01 -1.72 -1.45 -0.86 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[12: No intervention]            6495     2868    1 #> pred[12: Group counselling]          2345     2707    1 #> pred[12: Individual counselling]     1434     2346    1 #> pred[12: Self-help]                  1768     2280    1 #>  #> --------------------------------------------------------------------- Study: 13 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[13: No intervention]        -2.66 0.44 -3.57 -2.94 -2.65 -2.36 -1.83 #> pred[13: Group counselling]      -1.55 0.61 -2.70 -1.97 -1.54 -1.15 -0.34 #> pred[13: Individual counselling] -1.81 0.48 -2.79 -2.13 -1.80 -1.48 -0.89 #> pred[13: Self-help]              -2.16 0.59 -3.29 -2.56 -2.16 -1.77 -1.01 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[13: No intervention]            4846     3106    1 #> pred[13: Group counselling]          3372     2788    1 #> pred[13: Individual counselling]     3178     2883    1 #> pred[13: Self-help]                  2733     2518    1 #>  #> --------------------------------------------------------------------- Study: 14 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[14: No intervention]        -2.41 0.23 -2.88 -2.57 -2.41 -2.25 -1.98 #> pred[14: Group counselling]      -1.31 0.48 -2.23 -1.64 -1.32 -0.98 -0.34 #> pred[14: Individual counselling] -1.57 0.32 -2.19 -1.78 -1.57 -1.35 -0.94 #> pred[14: Self-help]              -1.92 0.47 -2.82 -2.24 -1.93 -1.61 -0.94 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[14: No intervention]            5034     3250    1 #> pred[14: Group counselling]          2517     2988    1 #> pred[14: Individual counselling]     1606     2766    1 #> pred[14: Self-help]                  1967     2404    1 #>  #> --------------------------------------------------------------------- Study: 15 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[15: No intervention]        -2.70 0.71 -4.21 -3.15 -2.65 -2.20 -1.47 #> pred[15: Group counselling]      -1.59 0.71 -3.08 -2.05 -1.56 -1.11 -0.32 #> pred[15: Individual counselling] -1.85 0.71 -3.35 -2.30 -1.80 -1.35 -0.63 #> pred[15: Self-help]              -2.20 0.78 -3.83 -2.70 -2.16 -1.67 -0.80 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[15: No intervention]            3474     2953    1 #> pred[15: Group counselling]          3991     3198    1 #> pred[15: Individual counselling]     3478     2861    1 #> pred[15: Self-help]                  3178     2596    1 #>  #> --------------------------------------------------------------------- Study: 16 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[16: No intervention]        -2.61 0.34 -3.32 -2.83 -2.60 -2.38 -2.00 #> pred[16: Group counselling]      -1.51 0.53 -2.55 -1.86 -1.51 -1.15 -0.47 #> pred[16: Individual counselling] -1.77 0.40 -2.57 -2.03 -1.76 -1.49 -0.99 #> pred[16: Self-help]              -2.12 0.49 -3.09 -2.43 -2.11 -1.80 -1.17 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[16: No intervention]            6061     2900    1 #> pred[16: Group counselling]          3084     2881    1 #> pred[16: Individual counselling]     2965     2839    1 #> pred[16: Self-help]                  2162     2599    1 #>  #> --------------------------------------------------------------------- Study: 17 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[17: No intervention]        -2.38 0.11 -2.59 -2.45 -2.37 -2.30 -2.17 #> pred[17: Group counselling]      -1.27 0.44 -2.09 -1.57 -1.29 -0.99 -0.39 #> pred[17: Individual counselling] -1.53 0.26 -2.03 -1.70 -1.54 -1.36 -1.02 #> pred[17: Self-help]              -1.88 0.42 -2.68 -2.16 -1.88 -1.62 -1.03 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[17: No intervention]            7663     3149    1 #> pred[17: Group counselling]          2333     2849    1 #> pred[17: Individual counselling]     1329     2101    1 #> pred[17: Self-help]                  1753     2179    1 #>  #> --------------------------------------------------------------------- Study: 18 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[18: No intervention]        -2.57 0.27 -3.12 -2.74 -2.56 -2.38 -2.07 #> pred[18: Group counselling]      -1.46 0.50 -2.41 -1.80 -1.48 -1.13 -0.43 #> pred[18: Individual counselling] -1.72 0.35 -2.39 -1.96 -1.73 -1.49 -1.03 #> pred[18: Self-help]              -2.07 0.49 -3.01 -2.39 -2.07 -1.76 -1.08 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[18: No intervention]            5943     2869    1 #> pred[18: Group counselling]          2820     2720    1 #> pred[18: Individual counselling]     1874     2411    1 #> pred[18: Self-help]                  1983     2438    1 #>  #> --------------------------------------------------------------------- Study: 19 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[19: No intervention]        -1.90 0.12 -2.14 -1.98 -1.90 -1.82 -1.66 #> pred[19: Group counselling]      -0.79 0.44 -1.61 -1.09 -0.81 -0.50  0.12 #> pred[19: Individual counselling] -1.05 0.26 -1.55 -1.23 -1.05 -0.88 -0.51 #> pred[19: Self-help]              -1.40 0.42 -2.19 -1.69 -1.41 -1.13 -0.54 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[19: No intervention]            7962     2958    1 #> pred[19: Group counselling]          2317     2722    1 #> pred[19: Individual counselling]     1395     2111    1 #> pred[19: Self-help]                  1744     2357    1 #>  #> --------------------------------------------------------------------- Study: 20 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[20: No intervention]        -2.80 0.12 -3.05 -2.88 -2.80 -2.72 -2.57 #> pred[20: Group counselling]      -1.69 0.45 -2.53 -1.99 -1.71 -1.40 -0.79 #> pred[20: Individual counselling] -1.95 0.26 -2.45 -2.14 -1.96 -1.78 -1.43 #> pred[20: Self-help]              -2.30 0.42 -3.12 -2.59 -2.31 -2.03 -1.44 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[20: No intervention]            6607     2567    1 #> pred[20: Group counselling]          2353     2660    1 #> pred[20: Individual counselling]     1413     2047    1 #> pred[20: Self-help]                  1751     2201    1 #>  #> --------------------------------------------------------------------- Study: 21 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[21: No intervention]        -1.11 0.81 -2.75 -1.63 -1.10 -0.59  0.51 #> pred[21: Group counselling]      -0.01 0.90 -1.72 -0.59 -0.01  0.57  1.76 #> pred[21: Individual counselling] -0.27 0.80 -1.84 -0.78 -0.28  0.24  1.34 #> pred[21: Self-help]              -0.62 0.81 -2.22 -1.14 -0.63 -0.10  0.99 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[21: No intervention]            2848     2584    1 #> pred[21: Group counselling]          2993     2838    1 #> pred[21: Individual counselling]     3101     2602    1 #> pred[21: Self-help]                  3327     2710    1 #>  #> --------------------------------------------------------------------- Study: 22 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[22: No intervention]        -2.44 0.84 -4.16 -2.99 -2.41 -1.89 -0.82 #> pred[22: Group counselling]      -1.33 0.81 -2.93 -1.89 -1.33 -0.80  0.27 #> pred[22: Individual counselling] -1.59 0.84 -3.28 -2.15 -1.58 -1.05  0.06 #> pred[22: Self-help]              -1.95 0.85 -3.62 -2.50 -1.93 -1.40 -0.29 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[22: No intervention]            2789     2449    1 #> pred[22: Group counselling]          3395     2843    1 #> pred[22: Individual counselling]     2972     2443    1 #> pred[22: Self-help]                  3300     3086    1 #>  #> --------------------------------------------------------------------- Study: 23 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[23: No intervention]        -2.32 0.80 -3.96 -2.84 -2.30 -1.79 -0.71 #> pred[23: Group counselling]      -1.21 0.78 -2.74 -1.72 -1.21 -0.70  0.35 #> pred[23: Individual counselling] -1.47 0.78 -3.02 -1.98 -1.47 -0.97  0.07 #> pred[23: Self-help]              -1.82 0.86 -3.48 -2.37 -1.84 -1.25 -0.12 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[23: No intervention]            2513     2419    1 #> pred[23: Group counselling]          2950     2836    1 #> pred[23: Individual counselling]     2862     2813    1 #> pred[23: Self-help]                  2637     2810    1 #>  #> --------------------------------------------------------------------- Study: 24 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[24: No intervention]        -2.80 0.86 -4.57 -3.36 -2.78 -2.23 -1.16 #> pred[24: Group counselling]      -1.69 0.85 -3.41 -2.23 -1.70 -1.14 -0.01 #> pred[24: Individual counselling] -1.95 0.83 -3.66 -2.49 -1.96 -1.40 -0.34 #> pred[24: Self-help]              -2.30 0.91 -4.13 -2.90 -2.27 -1.71 -0.53 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[24: No intervention]            2701     2464    1 #> pred[24: Group counselling]          3219     2614    1 #> pred[24: Individual counselling]     3274     2808    1 #> pred[24: Self-help]                  2908     2676    1 #>   # Predicted probabilities of success in each study in the network predict(smk_fit_RE, type = \"response\") #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[1: No intervention]        0.06 0.02 0.03 0.05 0.06 0.07  0.10     5429 #> pred[1: Group counselling]      0.17 0.07 0.07 0.12 0.16 0.21  0.34     2871 #> pred[1: Individual counselling] 0.13 0.04 0.06 0.10 0.13 0.16  0.23     2854 #> pred[1: Self-help]              0.10 0.05 0.04 0.07 0.09 0.12  0.22     2432 #>                                 Tail_ESS Rhat #> pred[1: No intervention]            2875    1 #> pred[1: Group counselling]          3042    1 #> pred[1: Individual counselling]     2901    1 #> pred[1: Self-help]                  2755    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[2: No intervention]        0.09 0.06 0.02 0.04 0.07 0.11  0.25     2514 #> pred[2: Group counselling]      0.21 0.12 0.04 0.12 0.19 0.27  0.50     2944 #> pred[2: Individual counselling] 0.17 0.10 0.04 0.10 0.15 0.22  0.44     2837 #> pred[2: Self-help]              0.13 0.09 0.02 0.07 0.11 0.17  0.37     3014 #>                                 Tail_ESS Rhat #> pred[2: No intervention]            2441    1 #> pred[2: Group counselling]          2436    1 #> pred[2: Individual counselling]     2499    1 #> pred[2: Self-help]                  2490    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[3: No intervention]        0.11 0.01 0.08 0.10 0.11 0.11  0.13     8828 #> pred[3: Group counselling]      0.27 0.09 0.13 0.21 0.26 0.32  0.47     2367 #> pred[3: Individual counselling] 0.22 0.04 0.14 0.19 0.22 0.25  0.31     1469 #> pred[3: Self-help]              0.17 0.06 0.08 0.13 0.16 0.20  0.31     1779 #>                                 Tail_ESS Rhat #> pred[3: No intervention]            2595 1.00 #> pred[3: Group counselling]          2854 1.00 #> pred[3: Individual counselling]     2123 1.01 #> pred[3: Self-help]                  2408 1.00 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[4: No intervention]        0.02 0.01 0.01 0.01 0.02 0.03  0.05     4040 #> pred[4: Group counselling]      0.06 0.04 0.01 0.03 0.05 0.08  0.16     3678 #> pred[4: Individual counselling] 0.04 0.02 0.01 0.03 0.04 0.06  0.11     3506 #> pred[4: Self-help]              0.03 0.02 0.01 0.02 0.03 0.04  0.09     2855 #>                                 Tail_ESS Rhat #> pred[4: No intervention]            2969    1 #> pred[4: Group counselling]          3003    1 #> pred[4: Individual counselling]     2698    1 #> pred[4: Self-help]                  2152    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[5: No intervention]        0.10 0.01 0.08 0.10 0.10 0.11  0.13     7705 #> pred[5: Group counselling]      0.27 0.09 0.13 0.21 0.26 0.32  0.47     2467 #> pred[5: Individual counselling] 0.22 0.05 0.14 0.18 0.21 0.24  0.32     1495 #> pred[5: Self-help]              0.17 0.06 0.08 0.13 0.16 0.20  0.31     1797 #>                                 Tail_ESS Rhat #> pred[5: No intervention]            2528    1 #> pred[5: Group counselling]          2669    1 #> pred[5: Individual counselling]     2451    1 #> pred[5: Self-help]                  2303    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[6: No intervention]        0.04 0.03 0.01 0.02 0.03 0.05  0.10     3402 #> pred[6: Group counselling]      0.11 0.08 0.02 0.05 0.09 0.15  0.30     3321 #> pred[6: Individual counselling] 0.08 0.05 0.02 0.05 0.07 0.11  0.21     3477 #> pred[6: Self-help]              0.07 0.05 0.01 0.03 0.05 0.09  0.19     2875 #>                                 Tail_ESS Rhat #> pred[6: No intervention]            2533    1 #> pred[6: Group counselling]          2826    1 #> pred[6: Individual counselling]     2541    1 #> pred[6: Self-help]                  2546    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[7: No intervention]        0.05 0.02 0.02 0.04 0.05 0.06  0.10     3744 #> pred[7: Group counselling]      0.14 0.07 0.04 0.09 0.13 0.18  0.30     3062 #> pred[7: Individual counselling] 0.11 0.04 0.04 0.08 0.10 0.13  0.21     2979 #> pred[7: Self-help]              0.08 0.04 0.02 0.05 0.07 0.10  0.19     2581 #>                                 Tail_ESS Rhat #> pred[7: No intervention]            2881    1 #> pred[7: Group counselling]          2703    1 #> pred[7: Individual counselling]     2344    1 #> pred[7: Self-help]                  2174    1 #>  #> ---------------------------------------------------------------------- Study: 8 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[8: No intervention]        0.07 0.04 0.02 0.05 0.07 0.09  0.16     3731 #> pred[8: Group counselling]      0.19 0.10 0.05 0.12 0.17 0.24  0.43     3474 #> pred[8: Individual counselling] 0.15 0.07 0.04 0.10 0.14 0.19  0.31     3398 #> pred[8: Self-help]              0.12 0.07 0.02 0.07 0.10 0.15  0.29     2821 #>                                 Tail_ESS Rhat #> pred[8: No intervention]            2733    1 #> pred[8: Group counselling]          2993    1 #> pred[8: Individual counselling]     2894    1 #> pred[8: Self-help]                  2599    1 #>  #> ---------------------------------------------------------------------- Study: 9 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[9: No intervention]        0.14 0.05 0.06 0.11 0.14 0.18  0.25     5062 #> pred[9: Group counselling]      0.34 0.12 0.13 0.25 0.32 0.41  0.60     3116 #> pred[9: Individual counselling] 0.28 0.09 0.13 0.21 0.27 0.33  0.47     3351 #> pred[9: Self-help]              0.22 0.10 0.08 0.15 0.21 0.28  0.45     2780 #>                                 Tail_ESS Rhat #> pred[9: No intervention]            3044    1 #> pred[9: Group counselling]          3109    1 #> pred[9: Individual counselling]     3271    1 #> pred[9: Self-help]                  2545    1 #>  #> --------------------------------------------------------------------- Study: 10 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[10: No intervention]        0.11 0.01 0.09 0.10 0.11 0.12  0.14     6860 #> pred[10: Group counselling]      0.28 0.09 0.14 0.22 0.27 0.34  0.49     2333 #> pred[10: Individual counselling] 0.23 0.05 0.15 0.20 0.22 0.26  0.33     1433 #> pred[10: Self-help]              0.18 0.06 0.09 0.13 0.17 0.21  0.32     1722 #>                                  Tail_ESS Rhat #> pred[10: No intervention]            2246    1 #> pred[10: Group counselling]          2728    1 #> pred[10: Individual counselling]     2355    1 #> pred[10: Self-help]                  2057    1 #>  #> --------------------------------------------------------------------- Study: 11 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[11: No intervention]        0.03 0.01 0.02 0.02 0.03 0.03  0.04     6150 #> pred[11: Group counselling]      0.08 0.04 0.03 0.05 0.07 0.10  0.18     2575 #> pred[11: Individual counselling] 0.06 0.02 0.03 0.05 0.06 0.07  0.11     2071 #> pred[11: Self-help]              0.05 0.02 0.02 0.03 0.04 0.05  0.10     1922 #>                                  Tail_ESS Rhat #> pred[11: No intervention]            3170    1 #> pred[11: Group counselling]          2924    1 #> pred[11: Individual counselling]     2786    1 #> pred[11: Self-help]                  2285    1 #>  #> --------------------------------------------------------------------- Study: 12 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[12: No intervention]        0.10 0.01 0.08 0.09 0.10 0.11  0.12     6495 #> pred[12: Group counselling]      0.26 0.09 0.13 0.19 0.24 0.30  0.45     2345 #> pred[12: Individual counselling] 0.21 0.04 0.13 0.17 0.20 0.23  0.30     1434 #> pred[12: Self-help]              0.16 0.06 0.07 0.12 0.15 0.19  0.30     1768 #>                                  Tail_ESS Rhat #> pred[12: No intervention]            2868    1 #> pred[12: Group counselling]          2707    1 #> pred[12: Individual counselling]     2346    1 #> pred[12: Self-help]                  2280    1 #>  #> --------------------------------------------------------------------- Study: 13 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[13: No intervention]        0.07 0.03 0.03 0.05 0.07 0.09  0.14     4846 #> pred[13: Group counselling]      0.19 0.09 0.06 0.12 0.18 0.24  0.42     3372 #> pred[13: Individual counselling] 0.15 0.06 0.06 0.11 0.14 0.18  0.29     3178 #> pred[13: Self-help]              0.12 0.06 0.04 0.07 0.10 0.15  0.27     2733 #>                                  Tail_ESS Rhat #> pred[13: No intervention]            3106    1 #> pred[13: Group counselling]          2788    1 #> pred[13: Individual counselling]     2883    1 #> pred[13: Self-help]                  2518    1 #>  #> --------------------------------------------------------------------- Study: 14 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[14: No intervention]        0.08 0.02 0.05 0.07 0.08 0.09  0.12     5034 #> pred[14: Group counselling]      0.22 0.08 0.10 0.16 0.21 0.27  0.42     2517 #> pred[14: Individual counselling] 0.18 0.05 0.10 0.14 0.17 0.21  0.28     1606 #> pred[14: Self-help]              0.14 0.06 0.06 0.10 0.13 0.17  0.28     1967 #>                                  Tail_ESS Rhat #> pred[14: No intervention]            3250    1 #> pred[14: Group counselling]          2988    1 #> pred[14: Individual counselling]     2766    1 #> pred[14: Self-help]                  2404    1 #>  #> --------------------------------------------------------------------- Study: 15 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[15: No intervention]        0.08 0.05 0.01 0.04 0.07 0.10  0.19     3474 #> pred[15: Group counselling]      0.19 0.10 0.04 0.11 0.17 0.25  0.42     3991 #> pred[15: Individual counselling] 0.16 0.08 0.03 0.09 0.14 0.21  0.35     3478 #> pred[15: Self-help]              0.12 0.08 0.02 0.06 0.10 0.16  0.31     3178 #>                                  Tail_ESS Rhat #> pred[15: No intervention]            2953    1 #> pred[15: Group counselling]          3198    1 #> pred[15: Individual counselling]     2861    1 #> pred[15: Self-help]                  2596    1 #>  #> --------------------------------------------------------------------- Study: 16 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[16: No intervention]        0.07 0.02 0.03 0.06 0.07 0.09  0.12     6061 #> pred[16: Group counselling]      0.19 0.08 0.07 0.14 0.18 0.24  0.38     3084 #> pred[16: Individual counselling] 0.15 0.05 0.07 0.12 0.15 0.18  0.27     2965 #> pred[16: Self-help]              0.12 0.05 0.04 0.08 0.11 0.14  0.24     2162 #>                                  Tail_ESS Rhat #> pred[16: No intervention]            2900    1 #> pred[16: Group counselling]          2881    1 #> pred[16: Individual counselling]     2839    1 #> pred[16: Self-help]                  2599    1 #>  #> --------------------------------------------------------------------- Study: 17 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[17: No intervention]        0.09 0.01 0.07 0.08 0.09 0.09  0.10     7663 #> pred[17: Group counselling]      0.23 0.08 0.11 0.17 0.22 0.27  0.40     2333 #> pred[17: Individual counselling] 0.18 0.04 0.12 0.15 0.18 0.20  0.27     1329 #> pred[17: Self-help]              0.14 0.05 0.06 0.10 0.13 0.17  0.26     1753 #>                                  Tail_ESS Rhat #> pred[17: No intervention]            3149    1 #> pred[17: Group counselling]          2849    1 #> pred[17: Individual counselling]     2101    1 #> pred[17: Self-help]                  2179    1 #>  #> --------------------------------------------------------------------- Study: 18 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[18: No intervention]        0.07 0.02 0.04 0.06 0.07 0.08  0.11     5943 #> pred[18: Group counselling]      0.20 0.08 0.08 0.14 0.19 0.24  0.39     2820 #> pred[18: Individual counselling] 0.16 0.05 0.08 0.12 0.15 0.18  0.26     1874 #> pred[18: Self-help]              0.12 0.05 0.05 0.08 0.11 0.15  0.25     1983 #>                                  Tail_ESS Rhat #> pred[18: No intervention]            2869    1 #> pred[18: Group counselling]          2720    1 #> pred[18: Individual counselling]     2411    1 #> pred[18: Self-help]                  2438    1 #>  #> --------------------------------------------------------------------- Study: 19 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[19: No intervention]        0.13 0.01 0.11 0.12 0.13 0.14  0.16     7962 #> pred[19: Group counselling]      0.32 0.09 0.17 0.25 0.31 0.38  0.53     2317 #> pred[19: Individual counselling] 0.26 0.05 0.17 0.23 0.26 0.29  0.38     1395 #> pred[19: Self-help]              0.21 0.07 0.10 0.16 0.20 0.24  0.37     1744 #>                                  Tail_ESS Rhat #> pred[19: No intervention]            2958    1 #> pred[19: Group counselling]          2722    1 #> pred[19: Individual counselling]     2111    1 #> pred[19: Self-help]                  2357    1 #>  #> --------------------------------------------------------------------- Study: 20 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[20: No intervention]        0.06 0.01 0.05 0.05 0.06 0.06  0.07     6607 #> pred[20: Group counselling]      0.16 0.06 0.07 0.12 0.15 0.20  0.31     2353 #> pred[20: Individual counselling] 0.13 0.03 0.08 0.11 0.12 0.14  0.19     1413 #> pred[20: Self-help]              0.10 0.04 0.04 0.07 0.09 0.12  0.19     1751 #>                                  Tail_ESS Rhat #> pred[20: No intervention]            2567    1 #> pred[20: Group counselling]          2660    1 #> pred[20: Individual counselling]     2047    1 #> pred[20: Self-help]                  2201    1 #>  #> --------------------------------------------------------------------- Study: 21 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[21: No intervention]        0.27 0.15 0.06 0.16 0.25 0.36  0.62     2848 #> pred[21: Group counselling]      0.50 0.19 0.15 0.36 0.50 0.64  0.85     2993 #> pred[21: Individual counselling] 0.44 0.17 0.14 0.31 0.43 0.56  0.79     3101 #> pred[21: Self-help]              0.37 0.17 0.10 0.24 0.35 0.48  0.73     3327 #>                                  Tail_ESS Rhat #> pred[21: No intervention]            2584    1 #> pred[21: Group counselling]          2838    1 #> pred[21: Individual counselling]     2602    1 #> pred[21: Self-help]                  2710    1 #>  #> --------------------------------------------------------------------- Study: 22 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[22: No intervention]        0.10 0.08 0.02 0.05 0.08 0.13  0.31     2789 #> pred[22: Group counselling]      0.24 0.14 0.05 0.13 0.21 0.31  0.57     3395 #> pred[22: Individual counselling] 0.20 0.12 0.04 0.10 0.17 0.26  0.52     2972 #> pred[22: Self-help]              0.15 0.10 0.03 0.08 0.13 0.20  0.43     3300 #>                                  Tail_ESS Rhat #> pred[22: No intervention]            2449    1 #> pred[22: Group counselling]          2843    1 #> pred[22: Individual counselling]     2443    1 #> pred[22: Self-help]                  3086    1 #>  #> --------------------------------------------------------------------- Study: 23 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[23: No intervention]        0.11 0.08 0.02 0.05 0.09 0.14  0.33     2513 #> pred[23: Group counselling]      0.25 0.14 0.06 0.15 0.23 0.33  0.59     2950 #> pred[23: Individual counselling] 0.21 0.12 0.05 0.12 0.19 0.28  0.52     2862 #> pred[23: Self-help]              0.17 0.12 0.03 0.09 0.14 0.22  0.47     2637 #>                                  Tail_ESS Rhat #> pred[23: No intervention]            2419    1 #> pred[23: Group counselling]          2836    1 #> pred[23: Individual counselling]     2813    1 #> pred[23: Self-help]                  2810    1 #>  #> --------------------------------------------------------------------- Study: 24 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[24: No intervention]        0.08 0.06 0.01 0.03 0.06 0.10  0.24     2701 #> pred[24: Group counselling]      0.18 0.12 0.03 0.10 0.15 0.24  0.50     3219 #> pred[24: Individual counselling] 0.15 0.10 0.03 0.08 0.12 0.20  0.42     3274 #> pred[24: Self-help]              0.12 0.09 0.02 0.05 0.09 0.15  0.37     2908 #>                                  Tail_ESS Rhat #> pred[24: No intervention]            2464    1 #> pred[24: Group counselling]          2614    1 #> pred[24: Individual counselling]     2808    1 #> pred[24: Self-help]                  2676    1 #>   # Predicted probabilities in a population with 67 observed events out of 566 # individuals on No Intervention, corresponding to a Beta(67, 566 - 67) # distribution on the baseline probability of response, using # `baseline_type = \"response\"` (smk_pred_RE <- predict(smk_fit_RE,                         baseline = distr(qbeta, 67, 566 - 67),                         baseline_type = \"response\",                         type = \"response\")) #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[No intervention]        0.12 0.01 0.09 0.11 0.12 0.13  0.15     4264 #> pred[Group counselling]      0.29 0.09 0.15 0.23 0.28 0.35  0.50     2346 #> pred[Individual counselling] 0.24 0.05 0.16 0.21 0.24 0.27  0.35     1416 #> pred[Self-help]              0.19 0.06 0.09 0.14 0.18 0.22  0.34     1746 #>                              Tail_ESS Rhat #> pred[No intervention]            4055 1.00 #> pred[Group counselling]          2856 1.00 #> pred[Individual counselling]     2261 1.01 #> pred[Self-help]                  2374 1.00 plot(smk_pred_RE, ref_line = c(0, 1))   # Predicted probabilities in a population with a baseline log odds of # response on No Intervention given a Normal distribution with mean -2 # and SD 0.13, using `baseline_type = \"link\"` (the default) # Note: this is approximately equivalent to the above Beta distribution on # the baseline probability (smk_pred_RE2 <- predict(smk_fit_RE,                          baseline = distr(qnorm, mean = -2, sd = 0.13),                          type = \"response\")) #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[No intervention]        0.12 0.01 0.09 0.11 0.12 0.13  0.15     4244 #> pred[Group counselling]      0.30 0.09 0.15 0.23 0.29 0.35  0.51     2369 #> pred[Individual counselling] 0.24 0.05 0.16 0.21 0.24 0.27  0.35     1504 #> pred[Self-help]              0.19 0.07 0.09 0.14 0.18 0.23  0.34     1760 #>                              Tail_ESS Rhat #> pred[No intervention]            4144    1 #> pred[Group counselling]          2746    1 #> pred[Individual counselling]     2553    1 #> pred[Self-help]                  2421    1 plot(smk_pred_RE2, ref_line = c(0, 1))  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Predicted probabilities of response in each study in the network (pso_pred <- predict(pso_fit, type = \"response\")) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[FIXTURE: PBO]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     4068     3436 #> pred[FIXTURE: ETN]     0.46 0.02 0.41 0.44 0.46 0.47  0.50     6613     3118 #> pred[FIXTURE: IXE_Q2W] 0.89 0.02 0.85 0.88 0.89 0.90  0.92     5541     3385 #> pred[FIXTURE: IXE_Q4W] 0.80 0.03 0.74 0.78 0.80 0.81  0.84     6418     3078 #> pred[FIXTURE: SEC_150] 0.67 0.03 0.62 0.65 0.67 0.69  0.72     9621     3083 #> pred[FIXTURE: SEC_300] 0.77 0.02 0.72 0.75 0.77 0.78  0.81     8254     3096 #>                        Rhat #> pred[FIXTURE: PBO]        1 #> pred[FIXTURE: ETN]        1 #> pred[FIXTURE: IXE_Q2W]    1 #> pred[FIXTURE: IXE_Q4W]    1 #> pred[FIXTURE: SEC_150]    1 #> pred[FIXTURE: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-1: PBO]     0.06 0.01 0.04 0.05 0.06 0.06  0.07     4740     3349 #> pred[UNCOVER-1: ETN]     0.46 0.03 0.40 0.44 0.46 0.48  0.52     6010     3259 #> pred[UNCOVER-1: IXE_Q2W] 0.90 0.01 0.88 0.89 0.90 0.91  0.92     7965     3115 #> pred[UNCOVER-1: IXE_Q4W] 0.81 0.02 0.78 0.80 0.81 0.82  0.84     8269     3355 #> pred[UNCOVER-1: SEC_150] 0.69 0.04 0.60 0.66 0.69 0.72  0.77     6303     2986 #> pred[UNCOVER-1: SEC_300] 0.78 0.04 0.71 0.76 0.78 0.81  0.85     6500     2782 #>                          Rhat #> pred[UNCOVER-1: PBO]        1 #> pred[UNCOVER-1: ETN]        1 #> pred[UNCOVER-1: IXE_Q2W]    1 #> pred[UNCOVER-1: IXE_Q4W]    1 #> pred[UNCOVER-1: SEC_150]    1 #> pred[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-2: PBO]     0.05 0.01 0.03 0.04 0.05 0.05  0.06     4525     3239 #> pred[UNCOVER-2: ETN]     0.42 0.02 0.38 0.41 0.42 0.43  0.46     6681     3031 #> pred[UNCOVER-2: IXE_Q2W] 0.88 0.01 0.85 0.87 0.88 0.89  0.91     6727     2708 #> pred[UNCOVER-2: IXE_Q4W] 0.78 0.02 0.75 0.77 0.78 0.79  0.81     7675     3068 #> pred[UNCOVER-2: SEC_150] 0.65 0.04 0.57 0.62 0.65 0.68  0.73     7059     3435 #> pred[UNCOVER-2: SEC_300] 0.75 0.04 0.68 0.73 0.75 0.78  0.82     8145     3524 #>                          Rhat #> pred[UNCOVER-2: PBO]        1 #> pred[UNCOVER-2: ETN]        1 #> pred[UNCOVER-2: IXE_Q2W]    1 #> pred[UNCOVER-2: IXE_Q4W]    1 #> pred[UNCOVER-2: SEC_150]    1 #> pred[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-3: PBO]     0.08 0.01 0.06 0.07 0.08 0.08  0.10     4957     3142 #> pred[UNCOVER-3: ETN]     0.53 0.02 0.49 0.52 0.53 0.54  0.57     8148     3145 #> pred[UNCOVER-3: IXE_Q2W] 0.93 0.01 0.91 0.92 0.93 0.93  0.94     6273     3098 #> pred[UNCOVER-3: IXE_Q4W] 0.85 0.01 0.83 0.85 0.85 0.86  0.88     8215     2881 #> pred[UNCOVER-3: SEC_150] 0.75 0.04 0.67 0.72 0.75 0.77  0.81     7785     3514 #> pred[UNCOVER-3: SEC_300] 0.83 0.03 0.77 0.81 0.83 0.85  0.88     8194     3366 #>                          Rhat #> pred[UNCOVER-3: PBO]        1 #> pred[UNCOVER-3: ETN]        1 #> pred[UNCOVER-3: IXE_Q2W]    1 #> pred[UNCOVER-3: IXE_Q4W]    1 #> pred[UNCOVER-3: SEC_150]    1 #> pred[UNCOVER-3: SEC_300]    1 #>  plot(pso_pred, ref_line = c(0, 1))   # Predicted probabilites of response in a new target population, with means # and SDs or proportions given by new_agd_int <- data.frame(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1 )  # We need to add integration points to this data frame of new data # We use the weighted mean correlation matrix computed from the IPD studies new_agd_int <- add_integration(new_agd_int,                                durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),                                prevsys = distr(qbern, prob = prevsys),                                bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),                                weight = distr(qgamma, mean = weight_mean, sd = weight_sd),                                psa = distr(qbern, prob = psa),                                cor = pso_net$int_cor,                                n_int = 64)  # Predicted probabilities of achieving PASI 75 in this target population, given # a Normal(-1.75, 0.08^2) distribution on the baseline probit-probability of # response on Placebo (at the reference levels of the covariates), are given by (pso_pred_new <- predict(pso_fit,                          type = \"response\",                          newdata = new_agd_int,                          baseline = distr(qnorm, -1.75, 0.08))) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: PBO]     0.06 0.03 0.03 0.04 0.06 0.08  0.12     5308     3187    1 #> pred[New 1: ETN]     0.37 0.06 0.26 0.33 0.37 0.41  0.49     4875     3700    1 #> pred[New 1: IXE_Q2W] 0.90 0.03 0.84 0.88 0.90 0.92  0.94     5341     3498    1 #> pred[New 1: IXE_Q4W] 0.81 0.04 0.72 0.78 0.81 0.83  0.87     5341     3698    1 #> pred[New 1: SEC_150] 0.68 0.06 0.56 0.64 0.68 0.72  0.79     4815     3614    1 #> pred[New 1: SEC_300] 0.78 0.05 0.68 0.75 0.78 0.81  0.86     5063     3826    1 #>  plot(pso_pred_new, ref_line = c(0, 1))  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Print nma_data objects — print.nma_data","title":"Print nma_data objects — print.nma_data","text":"Print details networks stored nma_data objects, created set_ipd(), set_agd_arm(), set_agd_contrast(), set_agd_surv(), combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print nma_data objects — print.nma_data","text":"","code":"# S3 method for nma_data print(x, ..., n = 10)  # S3 method for mlnmr_data print(x, ..., n = 10)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print nma_data objects — print.nma_data","text":"x nma_data object ... options (used) n number studies type print","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Print DIC details — print.nma_dic","title":"Print DIC details — print.nma_dic","text":"Print details DIC model fit statistics, computed dic() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print DIC details — print.nma_dic","text":"","code":"# S3 method for nma_dic print(x, digits = 1, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print DIC details — print.nma_dic","text":"x object class nma_dic digits integer passed round() ... Ignored","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print DIC details — print.nma_dic","text":"x returned invisibly.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"Print nma_nodesplit_df objects","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"","code":"# S3 method for nma_nodesplit_df print(x, ...)  # S3 method for nma_nodesplit print(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"x nma_nodesplit_df object ... arguments passed print.stanfit()","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Print stan_nma objects — print.stan_nma","title":"Print stan_nma objects — print.stan_nma","text":"Print stan_nma objects","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print stan_nma objects — print.stan_nma","text":"","code":"# S3 method for stan_nma print(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print stan_nma objects — print.stan_nma","text":"x stan_nma object ... arguments passed print.stanfit()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":null,"dir":"Reference","previous_headings":"","what":"Prior distributions — priors","title":"Prior distributions — priors","text":"functions used specify prior distributions model parameters.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prior distributions — priors","text":"","code":"normal(location = 0, scale)  half_normal(scale)  log_normal(location, scale)  cauchy(location = 0, scale)  half_cauchy(scale)  student_t(location = 0, scale, df)  half_student_t(scale, df)  log_student_t(location, scale, df)  exponential(scale = 1/rate, rate = 1/scale)  flat()  dirichlet(shape = 1)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prior distributions — priors","text":"location Prior location. Typically prior mean (see details). scale Prior scale. Typically prior standard deviation (see details). df Prior degrees freedom. rate Prior rate. shape Prior shape.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prior distributions — priors","text":"Object class nma_prior.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prior distributions — priors","text":"location scale parameters typically prior mean standard deviation, following exceptions: Cauchy distribution location prior median scale prior scale. log-Normal distribution, location scale prior mean standard deviation logarithm.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"compatibility-with-model-parameters","dir":"Reference","previous_headings":"","what":"Compatibility with model parameters","title":"Prior distributions — priors","text":"following table summarises prior distributions may used model parameters. Essentially, priors take non-negative values (e.g. half-Normal) may used non-negative parameters (heterogeneity SD/variance/precision, auxiliary parameter). real-valued prior distribution specified non-negative parameter, truncated 0 non-negative. flat() prior special case prior information added model, resulting implicit flat uniform prior distribution entire support parameter. improper prior parameter unbounded, generally advised. See Stan user's guide details. dirichlet() prior currently used prior distribution spline coefficients mspline pexp models, form \\(L\\)-dimensional unit simplex (.e. lie 0 1, sum 1). shape parameter controls concentration, shape=1 corresponding uniform prior simplexes. Values shape \\(<1\\) concentrate prior mass corners simplex, one dimension close 1 rest close zero; values shape \\(>1\\) increasingly concentrate dimensions towards prior mean \\(1/L\\).","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Random effects structure — RE_cor","title":"Random effects structure — RE_cor","text":"Use RE_cor generate random effects correlation matrix, assumption common heterogeneity variance (.e. within-study correlations 0.5). Use which_RE return vector IDs RE deltas (0 means RE delta arm).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random effects structure — RE_cor","text":"","code":"RE_cor(study, trt, contrast, type = c(\"reftrt\", \"blshift\"))  which_RE(study, trt, contrast, type = c(\"reftrt\", \"blshift\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random effects structure — RE_cor","text":"study vector study IDs (integer, character, factor) trt factor vector treatment codes (coercible ), first level indicating reference treatment contrast logical vector, length study trt, indicating whether corresponding data contrast rather arm format. type Character string, whether generate RE structure \"reference treatment\" parameterisation, \"baseline shift\" parameterisation.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random effects structure — RE_cor","text":"RE_cor(), correlation matrix dimension equal number random effects deltas (excluding set equal zero). which_RE(), integer vector IDs indexing rows columns correlation matrix returned RE_cor().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random effects structure — RE_cor","text":"","code":"RE_cor(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking))) #> Coerced `trt` to factor. #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #>  [1,]  1.0  0.5  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>  [2,]  0.5  1.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>  [3,]  0.0  0.0  1.0  0.5  0.5    0    0    0    0     0     0     0     0 #>  [4,]  0.0  0.0  0.5  1.0  0.5    0    0    0    0     0     0     0     0 #>  [5,]  0.0  0.0  0.5  0.5  1.0    0    0    0    0     0     0     0     0 #>  [6,]  0.0  0.0  0.0  0.0  0.0    1    0    0    0     0     0     0     0 #>  [7,]  0.0  0.0  0.0  0.0  0.0    0    1    0    0     0     0     0     0 #>  [8,]  0.0  0.0  0.0  0.0  0.0    0    0    1    0     0     0     0     0 #>  [9,]  0.0  0.0  0.0  0.0  0.0    0    0    0    1     0     0     0     0 #> [10,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     1     0     0     0 #> [11,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     1     0     0 #> [12,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     1     0 #> [13,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     1 #> [14,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [15,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [16,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [17,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [18,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [19,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [20,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [21,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [22,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [23,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [24,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [25,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [26,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [27,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [28,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [29,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [30,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [31,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] #>  [1,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [2,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [3,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [4,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [5,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [6,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [7,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [8,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [9,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [10,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [11,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [12,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [13,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [14,]     1     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [15,]     0     1     0     0     0     0     0     0     0     0   0.0   0.0 #> [16,]     0     0     1     0     0     0     0     0     0     0   0.0   0.0 #> [17,]     0     0     0     1     0     0     0     0     0     0   0.0   0.0 #> [18,]     0     0     0     0     1     0     0     0     0     0   0.0   0.0 #> [19,]     0     0     0     0     0     1     0     0     0     0   0.0   0.0 #> [20,]     0     0     0     0     0     0     1     0     0     0   0.0   0.0 #> [21,]     0     0     0     0     0     0     0     1     0     0   0.0   0.0 #> [22,]     0     0     0     0     0     0     0     0     1     0   0.0   0.0 #> [23,]     0     0     0     0     0     0     0     0     0     1   0.0   0.0 #> [24,]     0     0     0     0     0     0     0     0     0     0   1.0   0.5 #> [25,]     0     0     0     0     0     0     0     0     0     0   0.5   1.0 #> [26,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [27,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [28,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [29,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [30,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [31,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>       [,26] [,27] [,28] [,29] [,30] [,31] #>  [1,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [2,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [3,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [4,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [5,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [6,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [7,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [8,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [9,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [10,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [11,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [12,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [13,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [14,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [15,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [16,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [17,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [18,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [19,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [20,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [21,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [22,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [23,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [24,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [25,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [26,]   1.0   0.5   0.0   0.0   0.0   0.0 #> [27,]   0.5   1.0   0.0   0.0   0.0   0.0 #> [28,]   0.0   0.0   1.0   0.5   0.0   0.0 #> [29,]   0.0   0.0   0.5   1.0   0.0   0.0 #> [30,]   0.0   0.0   0.0   0.0   1.0   0.5 #> [31,]   0.0   0.0   0.0   0.0   0.5   1.0 RE_cor(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking)), type = \"blshift\") #> Coerced `trt` to factor. #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #>  [1,]  1.0  0.5  0.0  0.0    0    0    0    0    0     0     0     0     0 #>  [2,]  0.5  1.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #>  [3,]  0.0  0.0  1.0  0.5    0    0    0    0    0     0     0     0     0 #>  [4,]  0.0  0.0  0.5  1.0    0    0    0    0    0     0     0     0     0 #>  [5,]  0.0  0.0  0.0  0.0    1    0    0    0    0     0     0     0     0 #>  [6,]  0.0  0.0  0.0  0.0    0    1    0    0    0     0     0     0     0 #>  [7,]  0.0  0.0  0.0  0.0    0    0    1    0    0     0     0     0     0 #>  [8,]  0.0  0.0  0.0  0.0    0    0    0    1    0     0     0     0     0 #>  [9,]  0.0  0.0  0.0  0.0    0    0    0    0    1     0     0     0     0 #> [10,]  0.0  0.0  0.0  0.0    0    0    0    0    0     1     0     0     0 #> [11,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     1     0     0 #> [12,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     1     0 #> [13,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     1 #> [14,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [15,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [16,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [17,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [18,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [19,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [20,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [21,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [22,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [23,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [24,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [25,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [26,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #>       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] #>  [1,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [2,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [3,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [4,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [5,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [6,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [7,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [8,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [9,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [10,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [11,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [12,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [13,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [14,]     1     0     0     0     0     0     0     0     0     0     0     0 #> [15,]     0     1     0     0     0     0     0     0     0     0     0     0 #> [16,]     0     0     1     0     0     0     0     0     0     0     0     0 #> [17,]     0     0     0     1     0     0     0     0     0     0     0     0 #> [18,]     0     0     0     0     1     0     0     0     0     0     0     0 #> [19,]     0     0     0     0     0     1     0     0     0     0     0     0 #> [20,]     0     0     0     0     0     0     1     0     0     0     0     0 #> [21,]     0     0     0     0     0     0     0     1     0     0     0     0 #> [22,]     0     0     0     0     0     0     0     0     1     0     0     0 #> [23,]     0     0     0     0     0     0     0     0     0     1     0     0 #> [24,]     0     0     0     0     0     0     0     0     0     0     1     0 #> [25,]     0     0     0     0     0     0     0     0     0     0     0     1 #> [26,]     0     0     0     0     0     0     0     0     0     0     0     0 #>       [,26] #>  [1,]     0 #>  [2,]     0 #>  [3,]     0 #>  [4,]     0 #>  [5,]     0 #>  [6,]     0 #>  [7,]     0 #>  [8,]     0 #>  [9,]     0 #> [10,]     0 #> [11,]     0 #> [12,]     0 #> [13,]     0 #> [14,]     0 #> [15,]     0 #> [16,]     0 #> [17,]     0 #> [18,]     0 #> [19,]     0 #> [20,]     0 #> [21,]     0 #> [22,]     0 #> [23,]     0 #> [24,]     0 #> [25,]     0 #> [26,]     1 which_RE(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking))) #> Coerced `trt` to factor. #>  [1]  0  1  2  3  4  5  0  6  0  7  0  8  0  9  0 10  0 11  0 12  0 13  0 14  0 #> [26] 15  0 16  0 17  0 18  0 19  0 20  0 21  0 22  0 23 24 25 26 27 28 29 30 31 which_RE(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking)), type = \"blshift\") #> Coerced `trt` to factor. #>  [1]  0  1  2  0  3  4  0  5  0  6  0  7  0  8  0  9  0 10  0 11  0 12  0 13  0 #> [26] 14  0 15  0 16  0 17  0 18  0 19  0 20  0 21  0 22  0 23  0 24  0 25  0 26"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. survival Surv","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Relative treatment effects — relative_effects","title":"Relative treatment effects — relative_effects","text":"Generate (population-average) relative treatment effects. ML-NMR meta-regression model fitted, specific study population.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relative treatment effects — relative_effects","text":"","code":"relative_effects(   x,   newdata = NULL,   study = NULL,   all_contrasts = FALSE,   trt_ref = NULL,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relative treatment effects — relative_effects","text":"x stan_nma object created nma() newdata used regression model fitted. data frame study details, one row per study, giving covariate values produce relative effects. Column names must match variables regression model. NULL, relative effects produced studies network. study Column newdata specifies study names, otherwise studies labelled row number. all_contrasts Logical, generate estimates contrasts (TRUE), just \"basic\" contrasts network reference treatment (FALSE)? Default FALSE. trt_ref Reference treatment construct relative effects , all_contrasts = FALSE. default, relative effects network reference treatment. Coerced character string. probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) predictive_distribution Logical, random effects model fitted, predictive distribution relative effects new study returned? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relative treatment effects — relative_effects","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Relative treatment effects — relative_effects","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce relative effects smk_releff_RE <- relative_effects(smk_fit_RE) smk_releff_RE #>                           mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> d[Group counselling]      1.11 0.43  0.31 0.82 1.09 1.39  2.00     2253 #> d[Individual counselling] 0.85 0.24  0.40 0.68 0.84 1.00  1.32     1214 #> d[Self-help]              0.50 0.41 -0.28 0.22 0.49 0.76  1.33     1655 #>                           Tail_ESS Rhat #> d[Group counselling]          2603 1.00 #> d[Individual counselling]     1881 1.01 #> d[Self-help]                  2194 1.00 plot(smk_releff_RE, ref_line = 0)   # Relative effects for all pairwise comparisons relative_effects(smk_fit_RE, all_contrasts = TRUE) #>                                                  mean   sd  2.5%   25%   50% #> d[Group counselling vs. No intervention]         1.11 0.43  0.31  0.82  1.09 #> d[Individual counselling vs. No intervention]    0.85 0.24  0.40  0.68  0.84 #> d[Self-help vs. No intervention]                 0.50 0.41 -0.28  0.22  0.49 #> d[Individual counselling vs. Group counselling] -0.26 0.41 -1.09 -0.52 -0.25 #> d[Self-help vs. Group counselling]              -0.61 0.50 -1.60 -0.94 -0.59 #> d[Self-help vs. Individual counselling]         -0.35 0.42 -1.15 -0.63 -0.35 #>                                                   75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling vs. No intervention]         1.39  2.00     2253     2603 #> d[Individual counselling vs. No intervention]    1.00  1.32     1214     1881 #> d[Self-help vs. No intervention]                 0.76  1.33     1655     2194 #> d[Individual counselling vs. Group counselling]  0.02  0.53     2688     2920 #> d[Self-help vs. Group counselling]              -0.28  0.35     2366     2517 #> d[Self-help vs. Individual counselling]         -0.08  0.48     2022     1967 #>                                                 Rhat #> d[Group counselling vs. No intervention]        1.00 #> d[Individual counselling vs. No intervention]   1.01 #> d[Self-help vs. No intervention]                1.00 #> d[Individual counselling vs. Group counselling] 1.00 #> d[Self-help vs. Group counselling]              1.00 #> d[Self-help vs. Individual counselling]         1.00  # Relative effects against a different reference treatment relative_effects(smk_fit_RE, trt_ref = \"Self-help\") #>                            mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> d[No intervention]        -0.50 0.41 -1.33 -0.76 -0.49 -0.22  0.28     1655 #> d[Group counselling]       0.61 0.50 -0.35  0.28  0.59  0.94  1.60     2366 #> d[Individual counselling]  0.35 0.42 -0.48  0.08  0.35  0.63  1.15     2022 #>                           Tail_ESS Rhat #> d[No intervention]            2194    1 #> d[Group counselling]          2517    1 #> d[Individual counselling]     1967    1  # Transforming to odds ratios # We work with the array of relative effects samples LOR_array <- as.array(smk_releff_RE) OR_array <- exp(LOR_array)  # mcmc_array objects can be summarised to produce a nma_summary object smk_OR_RE <- summary(OR_array)  # This can then be printed or plotted smk_OR_RE #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling]      3.33 1.60 1.36 2.27 2.97 4.01  7.38     2253     2603 #> d[Individual counselling] 2.40 0.59 1.49 1.98 2.32 2.71  3.73     1214     1881 #> d[Self-help]              1.78 0.78 0.76 1.24 1.64 2.13  3.80     1655     2194 #>                           Rhat #> d[Group counselling]      1.00 #> d[Individual counselling] 1.01 #> d[Self-help]              1.00 plot(smk_OR_RE, ref_line = 1)  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Produce population-adjusted relative effects for all study populations in # the network pso_releff <- relative_effects(pso_fit) pso_releff #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[FIXTURE: ETN]     1.66 0.09 1.48 1.60 1.66 1.72  1.84     4577     3470    1 #> d[FIXTURE: IXE_Q2W] 3.03 0.10 2.84 2.96 3.02 3.09  3.22     5328     3193    1 #> d[FIXTURE: IXE_Q4W] 2.61 0.09 2.44 2.55 2.61 2.68  2.79     5246     3686    1 #> d[FIXTURE: SEC_150] 2.22 0.12 1.99 2.13 2.22 2.30  2.45     4708     3509    1 #> d[FIXTURE: SEC_300] 2.52 0.12 2.29 2.44 2.52 2.60  2.76     4965     3223    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-1: ETN]     1.51 0.08 1.35 1.45 1.51 1.56  1.67     4260     3334 #> d[UNCOVER-1: IXE_Q2W] 2.92 0.09 2.76 2.87 2.92 2.98  3.09     5335     3281 #> d[UNCOVER-1: IXE_Q4W] 2.51 0.08 2.36 2.46 2.51 2.56  2.66     4733     3249 #> d[UNCOVER-1: SEC_150] 2.11 0.12 1.88 2.03 2.11 2.19  2.34     4718     3614 #> d[UNCOVER-1: SEC_300] 2.42 0.12 2.18 2.33 2.41 2.50  2.67     5095     3286 #>                       Rhat #> d[UNCOVER-1: ETN]        1 #> d[UNCOVER-1: IXE_Q2W]    1 #> d[UNCOVER-1: IXE_Q4W]    1 #> d[UNCOVER-1: SEC_150]    1 #> d[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-2: ETN]     1.51 0.08 1.35 1.45 1.51 1.56  1.67     3963     3349 #> d[UNCOVER-2: IXE_Q2W] 2.92 0.08 2.76 2.87 2.92 2.98  3.09     5573     3418 #> d[UNCOVER-2: IXE_Q4W] 2.51 0.08 2.36 2.46 2.51 2.56  2.66     4800     3460 #> d[UNCOVER-2: SEC_150] 2.11 0.12 1.88 2.03 2.11 2.19  2.34     4774     3507 #> d[UNCOVER-2: SEC_300] 2.42 0.12 2.18 2.33 2.41 2.49  2.66     5089     3294 #>                       Rhat #> d[UNCOVER-2: ETN]        1 #> d[UNCOVER-2: IXE_Q2W]    1 #> d[UNCOVER-2: IXE_Q4W]    1 #> d[UNCOVER-2: SEC_150]    1 #> d[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-3: ETN]     1.53 0.08 1.38 1.48 1.53 1.58  1.68     3987     3088 #> d[UNCOVER-3: IXE_Q2W] 2.94 0.08 2.78 2.88 2.94 3.00  3.11     5507     3419 #> d[UNCOVER-3: IXE_Q4W] 2.53 0.08 2.37 2.47 2.53 2.58  2.67     5003     3429 #> d[UNCOVER-3: SEC_150] 2.13 0.12 1.90 2.05 2.13 2.21  2.35     4800     3514 #> d[UNCOVER-3: SEC_300] 2.43 0.12 2.20 2.35 2.43 2.51  2.67     5071     3312 #>                       Rhat #> d[UNCOVER-3: ETN]        1 #> d[UNCOVER-3: IXE_Q2W]    1 #> d[UNCOVER-3: IXE_Q4W]    1 #> d[UNCOVER-3: SEC_150]    1 #> d[UNCOVER-3: SEC_300]    1 #>  plot(pso_releff, ref_line = 0)   # Produce population-adjusted relative effects for a different target # population new_agd_means <- data.frame(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3)  relative_effects(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[New 1: ETN]     1.25 0.23 0.79 1.09 1.25 1.41  1.70     6403     3100    1 #> d[New 1: IXE_Q2W] 2.88 0.22 2.45 2.73 2.88 3.03  3.33     7400     3387    1 #> d[New 1: IXE_Q4W] 2.47 0.22 2.04 2.32 2.47 2.62  2.93     7661     3302    1 #> d[New 1: SEC_150] 2.07 0.23 1.64 1.92 2.07 2.22  2.53     6833     3327    1 #> d[New 1: SEC_300] 2.38 0.23 1.95 2.21 2.38 2.53  2.83     6474     3167    1 #>  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up arm-based aggregate data — set_agd_arm","title":"Set up arm-based aggregate data — set_agd_arm","text":"Set network containing arm-based aggregate data (AgD), event counts mean outcomes arm. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up arm-based aggregate data — set_agd_arm","text":"","code":"set_agd_arm(   data,   study,   trt,   y = NULL,   se = NULL,   r = NULL,   n = NULL,   E = NULL,   sample_size = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up arm-based aggregate data — set_agd_arm","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome se column data specifying standard error continuous outcome r column data specifying binary Binomial outcome count n column data specifying Binomial outcome numerator E column data specifying total time risk Poisson outcomes sample_size column data giving sample size arm. Optional, see details. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up arm-based aggregate data — set_agd_arm","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up arm-based aggregate data — set_agd_arm","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). sample_size argument optional, specified: Enables automatic centering predictors (center = TRUE) nma() regression model given network combining IPD AgD Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Nodes plot.nma_data() may weighted sample size Binomial outcome specified sample_size omitted, n used sample size default. Multinomial outcome specified sample_size omitted, sample size determined automatically supplied counts default. arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up arm-based aggregate data — set_agd_arm","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected   # Plot network plot(smk_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up contrast-based aggregate data — set_agd_contrast","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"Set network containing contrast-based aggregate data (AgD), .e. summaries relative effects treatments log Odds Ratios. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"","code":"set_agd_contrast(   data,   study,   trt,   y = NULL,   se = NULL,   sample_size = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome se column data specifying standard error continuous outcome sample_size column data giving sample size arm. Optional, see details. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"study single reference/baseline treatment, relative effects arm(s) given. reference arm, include data row continuous outcome y equal NA. study three arms (two relative effects), set standard error se reference arm data row equal standard error mean outcome reference arm (determines covariance relative effects, expressed differences mean outcomes arms). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year) default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). sample_size argument optional, specified: Enables automatic centering predictors (center = TRUE) nma() regression model given network combining IPD AgD Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Nodes plot.nma_data() may weighted sample size","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"","code":"# Set up network of Parkinson's contrast data head(parkinsons) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718  park_net <- set_agd_contrast(parkinsons,                              study = studyn,                              trt = trtn,                              y = diff,                              se = se_diff,                              sample_size = n)  # Print details park_net #> A network with 7 AgD studies (contrast-based). #>  #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected  # Plot network plot(park_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up aggregate survival data — set_agd_surv","title":"Set up aggregate survival data — set_agd_surv","text":"Set network containing aggregate survival data (AgD) form event/censoring times (e.g. reconstructed digitized Kaplan-Meier curves) covariate summary statistics study. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up aggregate survival data — set_agd_surv","text":"","code":"set_agd_surv(   data,   study,   trt,   Surv,   covariates = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up aggregate survival data — set_agd_surv","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors Surv column data specifying survival time--event outcome, using Surv() function. Right/left/interval censoring left truncation (delayed entry) supported. covariates data frame covariate summary statistics study study arm, corresponding study trt columns match data trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up aggregate survival data — set_agd_surv","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up aggregate survival data — set_agd_surv","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up aggregate survival data — set_agd_surv","text":"","code":"## Newly diagnosed multiple myeloma  head(ndmm_agd)  # Reconstructed Kaplan-Meier data #>        study     studyf trt trtf eventtime status #> 1 Morgan2012 Morgan2012 Pbo  Pbo  18.72575      1 #> 2 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 3 Morgan2012 Morgan2012 Pbo  Pbo  34.35726      1 #> 4 Morgan2012 Morgan2012 Pbo  Pbo  10.77826      1 #> 5 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 6 Morgan2012 Morgan2012 Pbo  Pbo  14.52966      1 ndmm_agd_covs   # Summary covariate information on each arm #>         study      studyf  trt trtf sample_size  age_min age_iqr_l age_median #> 1 Jackson2019 Jackson2019  Len  Len        1137 17.28246  59.13164   65.76766 #> 2 Jackson2019 Jackson2019  Pbo  Pbo         864 21.18572  58.30991   65.47402 #> 3  Morgan2012  Morgan2012  Pbo  Pbo         410 33.88979  58.05696   64.15999 #> 4  Morgan2012  Morgan2012 Thal Thal         408 38.45127  59.30022   65.48736 #>   age_iqr_h  age_max age_mean   age_sd iss_stage3 response_cr_vgpr      male #> 1  72.00756 85.76095 65.16867 8.936962  0.2480211        0.8258575 0.6165347 #> 2  71.80261 86.23080 64.62894 9.399272  0.1921296        0.8310185 0.6215278 #> 3  70.44791 84.79372 63.92360 9.006311  0.3634146        0.7170732 0.6195122 #> 4  71.73597 84.69365 65.59387 8.384686  0.3186275        0.7450980 0.6151961  set_agd_surv(ndmm_agd,              study = studyf,              trt = trtf,              Surv = Surv(eventtime, status),              covariates = ndmm_agd_covs) #> A network with 2 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study       Treatment arms #>  Jackson2019 2: Pbo | Len   #>  Morgan2012  2: Pbo | Thal  #>  #>  Outcome type: survival #> ------------------------------------------------------------------------------------ #> Total number of treatments: 3 #> Total number of studies: 2 #> Reference treatment is: Pbo #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up individual patient data — set_ipd","title":"Set up individual patient data — set_ipd","text":"Set network containing individual patient data (IPD). Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up individual patient data — set_ipd","text":"","code":"set_ipd(   data,   study,   trt,   y = NULL,   r = NULL,   E = NULL,   Surv = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up individual patient data — set_ipd","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome r column data specifying binary outcome Poisson outcome count E column data specifying total time risk Poisson outcomes Surv column data specifying survival time--event outcome, using Surv() function. Right/left/interval censoring left truncation (delayed entry) supported. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up individual patient data — set_ipd","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up individual patient data — set_ipd","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up individual patient data — set_ipd","text":"","code":"# Set up network of plaque psoriasis IPD head(plaque_psoriasis_ipd) #>    studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  62 38.6    15.8 #> 2 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  38 23.2    28.2 #> 3 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  54 27.5    13.2 #> 4 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  44 24.6    41.0 #> 5 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  44 28.3    15.2 #> 6 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 23.6    30.4 #>    male bsa weight durnpso prevsys   psa #> 1 FALSE  13  111.2       8    TRUE  TRUE #> 2 FALSE  37   62.0       1    TRUE FALSE #> 3  TRUE  13   83.5      38    TRUE FALSE #> 4 FALSE  67   66.0       1    TRUE FALSE #> 5 FALSE  10   92.7      23    TRUE FALSE #> 6 FALSE  75   73.5      21    TRUE FALSE  pso_net <- set_ipd(plaque_psoriasis_ipd,                    study = studyc,                    trt = trtc,                    r = pasi75)  # Print network details pso_net #> A network with 4 IPD studies. #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 4 #> Reference treatment is: IXE_Q2W #> Network is connected  # Plot network plot(pso_net)   # Setting a different reference treatment set_ipd(plaque_psoriasis_ipd,         study = studyc,         trt = trtc,         r = pasi75,         trt_ref = \"PBO\") #> A network with 4 IPD studies. #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":null,"dir":"Reference","previous_headings":"","what":"Smoking cessation data — smoking","title":"Smoking cessation data — smoking","text":"Data frame containing results 24 trials 4 smoking cessation treatments (Hasselblad 1998; Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smoking cessation data — smoking","text":"","code":"smoking"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Smoking cessation data — smoking","text":"data frame 50 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Smoking cessation data — smoking","text":"Dias S, Welton NJ, Sutton AJ, Caldwell DM, Lu G, Ades AE (2011). “NICE DSU Technical Support Document 4: Inconsistency networks evidence based randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Hasselblad V (1998). “Meta-analysis Multitreatment Studies.” Medical Decision Making, 18(1), 37--43. doi:10.1177/0272989x9801800110 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/stan_nma-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The stan_nma class — stan_nma-class","title":"The stan_nma class — stan_nma-class","text":"stan_nma stan_mlnmr classes contains results running model function nma().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/stan_nma-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The stan_nma class — stan_nma-class","text":"Objects class stan_nma stan_mlnmr following components: network network data model run (class nma_data stan_nma, class mlnmr_data stan_mlnmr) stanfit stanfit object returned calling sampling() model trt_effects Whether fixed random effects used (character string) consistency consistency/inconsistency model used (character string) regression regression model used (formula) class_interactions treatment classes regression model specified, model used interactions within class (common, exchangeable, independent) xbar named vector values used centering likelihood likelihood used (character string) link link function used (character string) priors list containing priors used (nma_prior objects) basis mspline pexp models, named list spline bases study stan_mlnmr sub-class inherits stan_nma, differs class network object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":null,"dir":"Reference","previous_headings":"","what":"Statins for cholesterol lowering — statins","title":"Statins for cholesterol lowering — statins","text":"Data frame containing results 19 trials comparing statins placebo usual care (Dias et al. 2011) . number deaths (-cause mortality) recorded. studies aim primary prevention (patients previous heart disease), others aim secondary prevention (patients previous heart disease).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statins for cholesterol lowering — statins","text":"","code":"statins"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Statins for cholesterol lowering — statins","text":"data frame 38 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name prevention primary secondary prevention study r number deaths n sample size","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Statins for cholesterol lowering — statins","text":"Dias S, Sutton AJ, Welton NJ, Ades AE (2011). “NICE DSU Technical Support Document 3: Heterogeneity: subgroups, meta-regression, bias bias-adjustment.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"Posterior summaries node-splitting models (nma_nodesplit nma_nodesplit_df objects) can produced using summary() method, plotted using plot() method.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"","code":"# S3 method for nma_nodesplit_df summary(   object,   consistency = NULL,   ...,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975) )  # S3 method for nma_nodesplit summary(   object,   consistency = NULL,   ...,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975) )  # S3 method for nma_nodesplit plot(x, consistency = NULL, ...)  # S3 method for nma_nodesplit_df plot(x, consistency = NULL, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"consistency Optional, stan_nma object corresponding fitted consistency model, display network estimates alongside direct indirect estimates. fitted consistency model present nma_nodesplit_df object used present (see get_nodesplits()). ... Additional arguments passed methods probs Numeric vector specifying quantiles interest, default c(0.025, 0.25, 0.5, 0.75, 0.975) x, object nma_nodesplit nma_nodesplit_df object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"nodesplit_summary object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"plot() method shortcut plot(summary(nma_nodesplit)). details plotting options, see plot.nodesplit_summary().","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"","code":"# \\donttest{ # Run smoking node-splitting example if not already available if (!exists(\"smk_fit_RE_nodesplit\")) example(\"example_smk_nodesplit\", run.donttest = TRUE) # } # \\donttest{ # Summarise the node-splitting results summary(smk_fit_RE_nodesplit) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.11 0.44  0.30  0.81  1.09 1.38  2.01     1550     2236 1.00 #> d_dir            1.04 0.75 -0.37  0.56  1.01 1.51  2.65     3290     2892 1.00 #> d_ind            1.13 0.54  0.10  0.77  1.11 1.48  2.19     2003     2397 1.00 #> omega           -0.08 0.89 -1.79 -0.67 -0.10 0.48  1.77     2575     2533 1.00 #> tau              0.86 0.20  0.55  0.72  0.84 0.98  1.33      911     1859 1.01 #> tau_consistency  0.84 0.19  0.54  0.70  0.81 0.94  1.28     1139     1813 1.00 #>  #> Residual deviance: 54.3 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.6 #>  #> Bayesian p-value: 0.91 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.85 0.25  0.38  0.69 0.84 1.00  1.36     1141     1891    1 #> d_dir           0.87 0.25  0.39  0.71 0.87 1.03  1.40     2059     2549    1 #> d_ind           0.57 0.66 -0.69  0.13 0.56 0.99  1.92     1789     1980    1 #> omega           0.31 0.68 -1.09 -0.13 0.30 0.75  1.63     1749     1998    1 #> tau             0.85 0.19  0.55  0.72 0.83 0.96  1.27     1251     1951    1 #> tau_consistency 0.84 0.19  0.54  0.70 0.81 0.94  1.28     1139     1813    1 #>  #> Residual deviance: 54.3 (on 50 data points) #>                pD: 44.1 #>               DIC: 98.3 #>  #> Bayesian p-value: 0.63 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.49 0.40 -0.26  0.22  0.47 0.76  1.30     2152     2404 1.00 #> d_dir            0.34 0.56 -0.73 -0.02  0.35 0.70  1.46     3022     2635 1.00 #> d_ind            0.70 0.62 -0.52  0.31  0.69 1.10  1.99     1817     2356 1.00 #> omega           -0.36 0.82 -2.03 -0.89 -0.36 0.16  1.25     1706     2114 1.00 #> tau              0.88 0.21  0.56  0.73  0.85 0.99  1.37      891     1904 1.01 #> tau_consistency  0.84 0.19  0.54  0.70  0.81 0.94  1.28     1139     1813 1.00 #>  #> Residual deviance: 53.5 (on 50 data points) #>                pD: 44 #>               DIC: 97.6 #>  #> Bayesian p-value: 0.65 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.25 0.41 -1.09 -0.51 -0.25  0.01  0.54     2461     2011    1 #> d_dir           -0.12 0.49 -1.06 -0.43 -0.11  0.20  0.83     3334     3008    1 #> d_ind           -0.55 0.62 -1.80 -0.95 -0.55 -0.13  0.62     1602     2006    1 #> omega            0.43 0.68 -0.91 -0.04  0.43  0.88  1.79     1475     1944    1 #> tau              0.87 0.20  0.55  0.73  0.84  0.98  1.34     1023     1759    1 #> tau_consistency  0.84 0.19  0.54  0.70  0.81  0.94  1.28     1139     1813    1 #>  #> Residual deviance: 53.7 (on 50 data points) #>                pD: 44 #>               DIC: 97.7 #>  #> Bayesian p-value: 0.53 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.62 0.49 -1.60 -0.93 -0.61 -0.30  0.33     2759     2629 1.00 #> d_dir           -0.64 0.66 -1.92 -1.09 -0.63 -0.20  0.65     3824     2942 1.00 #> d_ind           -0.62 0.66 -1.95 -1.05 -0.62 -0.18  0.63     1886     2020 1.00 #> omega           -0.02 0.87 -1.75 -0.60 -0.03  0.56  1.67     2343     2870 1.00 #> tau              0.87 0.20  0.56  0.73  0.85  0.98  1.36      939     1635 1.01 #> tau_consistency  0.84 0.19  0.54  0.70  0.81  0.94  1.28     1139     1813 1.00 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.5 #>               DIC: 98.6 #>  #> Bayesian p-value: 0.98 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.36 0.42 -1.18 -0.63 -0.37 -0.10  0.46     2448     2165    1 #> d_dir            0.08 0.65 -1.23 -0.33  0.09  0.50  1.36     3826     3039    1 #> d_ind           -0.61 0.52 -1.64 -0.94 -0.61 -0.28  0.39     1827     2096    1 #> omega            0.70 0.79 -0.85  0.16  0.70  1.21  2.27     2413     2497    1 #> tau              0.85 0.20  0.55  0.71  0.83  0.96  1.33     1156     1659    1 #> tau_consistency  0.84 0.19  0.54  0.70  0.81  0.94  1.28     1139     1813    1 #>  #> Residual deviance: 54.6 (on 50 data points) #>                pD: 44.8 #>               DIC: 99.3 #>  #> Bayesian p-value: 0.37  # Plot the node-splitting results plot(smk_fit_RE_nodesplit)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of prior distributions — summary.nma_prior","title":"Summary of prior distributions — summary.nma_prior","text":"Print summary prior distribution details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of prior distributions — summary.nma_prior","text":"","code":"# S3 method for nma_prior summary(object, ..., probs = c(0.5, 0.95), digits = 2, trunc = NULL)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of prior distributions — summary.nma_prior","text":"object Prior distribution nma_prior object ... Additional arguments, used probs Numeric vector probabilities calculate prior intervals digits Number digits display trunc Optional numeric vector length 2, giving truncation limits prior distribution. Useful real-valued prior assigned positive-valued parameter, trunc = c(0, Inf) give correct prior intervals. default, truncation used.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of prior distributions — summary.nma_prior","text":"data frame returned invisibly, giving prior intervals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of prior distributions — summary.nma_prior","text":"","code":"summary(normal(location = 0, scale = 1)) #> A Normal prior distribution: location = 0, scale = 1. #> 50% of the prior density lies between -0.67 and 0.67. #> 95% of the prior density lies between -1.96 and 1.96. summary(half_normal(scale = 1)) #> A half-Normal prior distribution: location = 0, scale = 1. #> 50% of the prior density lies between 0 and 0.67. #> 95% of the prior density lies between 0 and 1.96. summary(log_normal(location = -3.93, scale = 1.51)) #> A log-Normal prior distribution: location = -3.93, scale = 1.51. #> 50% of the prior density lies between 0.01 and 0.05. #> 95% of the prior density lies between 0 and 0.38.  # Truncation limits may be set, for example to restrict a prior to positive values summary(normal(location = 0.5, scale = 1), trunc = c(0, Inf)) #> A Normal prior distribution: location = 0.5, scale = 1. #> 50% of the prior density lies between 0.45 and 1.44. #> 95% of the prior density lies between 0.05 and 2.61."},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior summaries from stan_nma objects — summary.stan_nma","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"Posterior summaries model parameters stan_nma objects may produced using summary() method plotted plot() method. NOTE: produce relative effects, absolute predictions, posterior ranks, see relative_effects(), predict.stan_nma(), posterior_ranks(), posterior_rank_probs().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"","code":"# S3 method for stan_nma summary(object, ..., pars, include, probs = c(0.025, 0.25, 0.5, 0.75, 0.975))  # S3 method for stan_nma plot(   x,   ...,   pars,   include,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"... Additional arguments passed methods pars, include See rstan::extract() probs Numeric vector specifying quantiles interest, default c(0.025, 0.25, 0.5, 0.75, 0.975) x, object stan_nma object stat Character string specifying ggdist plot stat use, default \"pointinterval\" orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\" ref_line Numeric vector positions reference lines, default reference lines drawn summary Logical, calculate posterior summaries? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"nma_summary object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"plot() method shortcut plot(summary(stan_nma)). details plotting options, see plot.nma_summary().","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Summary and plot of all model parameters summary(smk_fit_RE) #>                                    mean   sd  2.5%   25%   50%   75% 97.5% #> mu[1]                             -2.78 0.32 -3.43 -2.99 -2.77 -2.55 -2.17 #> mu[2]                             -2.58 0.77 -4.18 -3.07 -2.56 -2.10 -1.09 #> mu[3]                             -2.14 0.12 -2.39 -2.22 -2.14 -2.06 -1.90 #> mu[4]                             -4.06 0.57 -5.27 -4.42 -4.02 -3.65 -3.01 #> mu[5]                             -2.15 0.14 -2.44 -2.25 -2.15 -2.06 -1.89 #> mu[6]                             -3.42 0.75 -5.01 -3.88 -3.37 -2.89 -2.18 #> mu[7]                             -3.04 0.44 -4.00 -3.31 -3.01 -2.73 -2.25 #> mu[8]                             -2.69 0.58 -3.96 -3.04 -2.66 -2.29 -1.66 #> mu[9]                             -1.84 0.42 -2.68 -2.11 -1.83 -1.55 -1.08 #> mu[10]                            -2.08 0.12 -2.32 -2.16 -2.08 -2.00 -1.84 #> mu[11]                            -3.62 0.23 -4.10 -3.78 -3.62 -3.46 -3.20 #> mu[12]                            -2.22 0.13 -2.47 -2.30 -2.22 -2.13 -1.97 #> mu[13]                            -2.66 0.44 -3.57 -2.94 -2.65 -2.36 -1.83 #> mu[14]                            -2.41 0.23 -2.88 -2.57 -2.41 -2.25 -1.98 #> mu[15]                            -2.70 0.71 -4.21 -3.15 -2.65 -2.20 -1.47 #> mu[16]                            -2.61 0.34 -3.32 -2.83 -2.60 -2.38 -2.00 #> mu[17]                            -2.38 0.11 -2.59 -2.45 -2.37 -2.30 -2.17 #> mu[18]                            -2.57 0.27 -3.12 -2.74 -2.56 -2.38 -2.07 #> mu[19]                            -1.90 0.12 -2.14 -1.98 -1.90 -1.82 -1.66 #> mu[20]                            -2.80 0.12 -3.05 -2.88 -2.80 -2.72 -2.57 #> mu[21]                            -1.11 0.81 -2.75 -1.63 -1.10 -0.59  0.51 #> mu[22]                            -2.44 0.84 -4.16 -2.99 -2.41 -1.89 -0.82 #> mu[23]                            -2.32 0.80 -3.96 -2.84 -2.30 -1.79 -0.71 #> mu[24]                            -2.80 0.86 -4.57 -3.36 -2.78 -2.23 -1.16 #> d[Group counselling]               1.11 0.43  0.31  0.82  1.09  1.39  2.00 #> d[Individual counselling]          0.85 0.24  0.40  0.68  0.84  1.00  1.32 #> d[Self-help]                       0.50 0.41 -0.28  0.22  0.49  0.76  1.33 #> tau                                0.84 0.18  0.55  0.71  0.82  0.94  1.27 #> delta[1: Individual counselling]   1.07 0.38  0.33  0.82  1.06  1.32  1.83 #> delta[1: Group counselling]        0.36 0.43 -0.47  0.08  0.37  0.65  1.17 #> delta[2: Self-help]                0.68 0.78 -0.82  0.16  0.65  1.17  2.30 #> delta[2: Individual counselling]   0.77 0.78 -0.73  0.26  0.76  1.26  2.36 #> delta[2: Group counselling]        1.00 0.78 -0.55  0.48  0.98  1.49  2.61 #> delta[3: Individual counselling]   2.16 0.14  1.89  2.07  2.16  2.26  2.45 #> delta[4: Individual counselling]   0.91 0.59 -0.22  0.51  0.90  1.29  2.08 #> delta[5: Individual counselling]   0.44 0.16  0.14  0.33  0.43  0.54  0.75 #> delta[6: Individual counselling]   1.72 0.74  0.45  1.21  1.67  2.18  3.30 #> delta[7: Individual counselling]   2.16 0.49  1.26  1.82  2.14  2.46  3.21 #> delta[8: Individual counselling]   1.64 0.59  0.58  1.23  1.60  2.01  2.93 #> delta[9: Individual counselling]   0.58 0.46 -0.30  0.26  0.57  0.88  1.52 #> delta[10: Self-help]               0.01 0.17 -0.33 -0.10  0.00  0.12  0.34 #> delta[11: Self-help]               0.41 0.30 -0.16  0.21  0.41  0.62  1.02 #> delta[12: Individual counselling]  0.41 0.16  0.09  0.30  0.41  0.52  0.72 #> delta[13: Individual counselling]  0.38 0.51 -0.60  0.03  0.37  0.72  1.37 #> delta[14: Individual counselling]  0.62 0.29  0.05  0.43  0.62  0.81  1.19 #> delta[15: Group counselling]       2.14 0.74  0.82  1.63  2.09  2.61  3.74 #> delta[16: Self-help]               0.65 0.40 -0.10  0.38  0.65  0.92  1.45 #> delta[17: Individual counselling]  0.55 0.13  0.29  0.46  0.55  0.64  0.81 #> delta[18: Individual counselling]  0.02 0.31 -0.57 -0.20  0.03  0.23  0.62 #> delta[19: Individual counselling] -0.20 0.17 -0.53 -0.31 -0.20 -0.08  0.14 #> delta[20: Individual counselling]  0.08 0.18 -0.28 -0.04  0.08  0.20  0.43 #> delta[21: Self-help]               0.68 0.81 -0.94  0.15  0.68  1.19  2.32 #> delta[21: Individual counselling]  0.63 0.80 -0.97  0.12  0.63  1.14  2.21 #> delta[22: Self-help]               0.34 0.83 -1.31 -0.20  0.35  0.87  2.04 #> delta[22: Group counselling]       1.31 0.85 -0.32  0.76  1.28  1.85  3.06 #> delta[23: Individual counselling]  0.67 0.79 -0.90  0.16  0.67  1.17  2.24 #> delta[23: Group counselling]       1.27 0.80 -0.30  0.75  1.25  1.79  2.91 #> delta[24: Individual counselling]  1.05 0.84 -0.59  0.50  1.02  1.57  2.78 #> delta[24: Group counselling]       0.89 0.85 -0.79  0.34  0.89  1.42  2.59 #>                                   Bulk_ESS Tail_ESS Rhat #> mu[1]                                 5429     2875 1.00 #> mu[2]                                 2514     2441 1.00 #> mu[3]                                 8828     2595 1.00 #> mu[4]                                 4040     2969 1.00 #> mu[5]                                 7705     2528 1.00 #> mu[6]                                 3402     2533 1.00 #> mu[7]                                 3744     2881 1.00 #> mu[8]                                 3731     2733 1.00 #> mu[9]                                 5062     3044 1.00 #> mu[10]                                6860     2246 1.00 #> mu[11]                                6150     3170 1.00 #> mu[12]                                6495     2868 1.00 #> mu[13]                                4846     3106 1.00 #> mu[14]                                5034     3250 1.00 #> mu[15]                                3474     2953 1.00 #> mu[16]                                6061     2900 1.00 #> mu[17]                                7663     3149 1.00 #> mu[18]                                5943     2869 1.00 #> mu[19]                                7962     2958 1.00 #> mu[20]                                6607     2567 1.00 #> mu[21]                                2848     2584 1.00 #> mu[22]                                2789     2449 1.00 #> mu[23]                                2513     2419 1.00 #> mu[24]                                2701     2464 1.00 #> d[Group counselling]                  2253     2603 1.00 #> d[Individual counselling]             1214     1881 1.01 #> d[Self-help]                          1655     2194 1.00 #> tau                                   1141     1905 1.00 #> delta[1: Individual counselling]      5190     3309 1.00 #> delta[1: Group counselling]           4849     3292 1.00 #> delta[2: Self-help]                   2622     2760 1.00 #> delta[2: Individual counselling]      2547     2885 1.00 #> delta[2: Group counselling]           2530     2616 1.00 #> delta[3: Individual counselling]      6918     3136 1.00 #> delta[4: Individual counselling]      4060     2962 1.00 #> delta[5: Individual counselling]      7313     2998 1.00 #> delta[6: Individual counselling]      3356     2703 1.00 #> delta[7: Individual counselling]      3722     3041 1.00 #> delta[8: Individual counselling]      3295     2727 1.00 #> delta[9: Individual counselling]      5254     3470 1.00 #> delta[10: Self-help]                  5913     3196 1.00 #> delta[11: Self-help]                  5624     3517 1.00 #> delta[12: Individual counselling]     5704     3658 1.00 #> delta[13: Individual counselling]     4151     3141 1.00 #> delta[14: Individual counselling]     4805     3117 1.00 #> delta[15: Group counselling]          3276     3000 1.00 #> delta[16: Self-help]                  5915     3157 1.00 #> delta[17: Individual counselling]     5719     3544 1.00 #> delta[18: Individual counselling]     5558     2634 1.00 #> delta[19: Individual counselling]     5954     3353 1.00 #> delta[20: Individual counselling]     5064     3416 1.00 #> delta[21: Self-help]                  2834     2636 1.00 #> delta[21: Individual counselling]     2872     2581 1.00 #> delta[22: Self-help]                  2800     2562 1.00 #> delta[22: Group counselling]          2753     2520 1.00 #> delta[23: Individual counselling]     2552     2948 1.00 #> delta[23: Group counselling]          2566     2911 1.00 #> delta[24: Individual counselling]     2737     2615 1.00 #> delta[24: Group counselling]          2862     2854 1.00 plot(smk_fit_RE)   # Summary and plot of heterogeneity tau only summary(smk_fit_RE, pars = \"tau\") #>     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau 0.84 0.18 0.55 0.71 0.82 0.94  1.27     1141     1905    1 plot(smk_fit_RE, pars = \"tau\")   # Customising plot output plot(smk_fit_RE,      pars = c(\"d\", \"tau\"),      stat = \"halfeye\",      ref_line = 0)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot theme for multinma plots — theme_multinma","title":"Plot theme for multinma plots — theme_multinma","text":"simple ggplot2 theme plots multinma package.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot theme for multinma plots — theme_multinma","text":"","code":"theme_multinma(...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot theme for multinma plots — theme_multinma","text":"... Arguments passed ggplot2::theme_light()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot theme for multinma plots — theme_multinma","text":"ggplot2 theme","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot theme for multinma plots — theme_multinma","text":"","code":"library(ggplot2) theme_set(theme_multinma())"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":null,"dir":"Reference","previous_headings":"","what":"Thrombolytic treatments data — thrombolytics","title":"Thrombolytic treatments data — thrombolytics","text":"Data frame containing results 50 trials 8 thrombolytic drugs (streptokinase, SK; alteplase, t-PA; accelerated alteplase, Acc t-PA; streptokinase plus alteplase, SK+tPA; reteplase, r-PA; tenocteplase, TNK; urokinase, UK; anistreptilase, ASPAC) plus per-cutaneous transluminal coronary angioplasty (PTCA) (Boland et al. 2003; Lu Ades 2006; Dias et al. 2011) . number deaths 30 35 days following acute myocardial infarction recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Thrombolytic treatments data — thrombolytics","text":"","code":"thrombolytics"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Thrombolytic treatments data — thrombolytics","text":"data frame 102 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Thrombolytic treatments data — thrombolytics","text":"Boland , Dundar Y, Bagust , Haycox , Hill R, Mota RM, Walley T, Dickson R (2003). “Early thrombolysis treatment acute myocardial infarction: systematic review economic evaluation.” Health Technology Assessment, 7(15). doi:10.3310/hta7150 . Dias S, Welton NJ, Sutton AJ, Caldwell DM, Lu G, Ades AE (2011). “NICE DSU Technical Support Document 4: Inconsistency networks evidence based randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Lu GB, Ades AE (2006). “Assessing evidence inconsistency mixed treatment comparisons.” Journal American Statistical Association, 101(474), 447--459. doi:10.1198/016214505000001302 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":null,"dir":"Reference","previous_headings":"","what":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"Data frame containing number deaths 6 trials comparing transfusion granulocytes (white blood cells) control (Stanworth et al. 2005) . Previously used demonstrate informative prior distributions heterogeneity variance Turner et al. (2012) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"","code":"transfusion"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"data frame 12 rows 4 variables: studyc study name trtc treatment name r total number deaths n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"Stanworth S, Massey E, Hyde C, Brunskill SJ, Navarette C, Lucas G, Marks D, Paulus U (2005). “Granulocyte transfusions treating infections patients neutropenia neutrophil dysfunction.” Cochrane Database Systematic Reviews. ISSN 1465-1858, doi:10.1002/14651858.CD005339 . Turner RM, Davey J, Clarke MJ, Thompson SG, Higgins JPT (2012). “Predicting extent heterogeneity meta-analysis, using empirical data Cochrane Database Systematic Reviews.” International Journal Epidemiology, 41(3), 818--827. doi:10.1093/ije/dys041 .","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"feature-survivaltime-to-event-models-are-now-supported-0-5-1-9000","dir":"Changelog","previous_headings":"","what":"Feature: Survival/time-to-event models are now supported","title":"multinma 0.5.1.9000","text":"set_ipd() now Surv argument specifying survival outcomes using survival::Surv(), new function set_agd_surv() sets aggregate data form event/censoring times (e.g. digitized Kaplan-Meier curves) overall covariate summaries. Left, right, interval censoring well left truncation (delayed entry) supported. available likelihoods Exponential (PH AFT forms), Weibull (PH AFT forms), Gompertz, log-Normal, log-Logistic, Gamma, Generalised Gamma, flexible M-splines baseline hazard, piecewise exponential hazards. Auxiliary parameters (e.g. shapes, spline coefficients) always stratified study respect randomisation, may stratified treatment (e.g. relax proportional hazards assumption) /additional factors using aux_by argument nma(). predict() method produces estimates survival probabilities, hazards, cumulative hazards, mean survival times, restricted mean survival times, quantiles survival time distribution, median survival times. predictions can plotted using plot() method. new vignette demonstrates ML-NMR survival analysis example progression-free survival autologous stem cell transplant newly diagnosed multiple myeloma, corresponding datasets ndmm_ipd, ndmm_agd, ndmm_agd_covs.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"feature-automatic-checking-of-numerical-integration-for-ml-nmr-models-0-5-1-9000","dir":"Changelog","previous_headings":"","what":"Feature: Automatic checking of numerical integration for ML-NMR models","title":"multinma 0.5.1.9000","text":"accuracy numerical integration ML-NMR models can now checked automatically, default. , half chains run n_int half n_int/2 integration points. Rhat effective sample size warnings can ascribed either: non-convergence MCMC chains, requiring increased number iterations iter nma(), ; insufficient accuracy numerical integration, requiring increased number integration points n_int add_integration(). Descriptive warning messages indicate case. feature controlled new int_check argument nma(), enabled (TRUE) default. Saving thinned cumulative integration points can now disabled int_thin = 0, now disabled default. previous default int_thin = max(n_int %/% 10, 1). can now check sufficient accuracy automatically, default number integration points n_int add_integration() lowered 64. still conservative choice, sufficient many cases; previous default 1000 excessive. result, ML-NMR models now much faster run default, due lower n_int disabling saving cumulative integration points.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"other-updates-0-5-1-9000","dir":"Changelog","previous_headings":"","what":"Other updates","title":"multinma 0.5.1.9000","text":"Feature: dic() now includes option use pV penalty instead pD. Feature: baseline aux arguments predict() can now specified name study network, use parameter estimates study prediction. Improvement: predict() now produce aggregate-level predictions sample individuals newdata ML-NMR models (previously newdata include integration points). Fix: plot.nma_data(), using custom layout string (e.g.  data frame layout coordinates) now works expected nudge > 0.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-051","dir":"Changelog","previous_headings":"","what":"multinma 0.5.1","title":"multinma 0.5.1","text":"CRAN release: 2023-05-24 Fix: Now compatible latest StanHeaders v2.26.25 (fixes #23) Fix: Dealt various tidyverse deprecations Fix: Updated TSD URLs (thanks @ndunnewind)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-050","dir":"Changelog","previous_headings":"","what":"multinma 0.5.0","title":"multinma 0.5.0","text":"CRAN release: 2022-08-29 Feature: Treatment labels network plots can now nudged away nodes weight_nodes = TRUE, using new nudge argument plot.nma_data() (#15). Feature: data frame returned calling as_tibble() .data.frame() nma_summary object (relative effects predictions) now includes columns corresponding treatment (.trt) contrast (.trta .trtb), .category column may included multinomial models. Previously details present part parameter column Feature: Added log t prior distribution log_student_t(), can used positive-valued parameters (e.g. heterogeneity variance). Improvement: set_agd_contrast() now produces informative error message covariance matrix implied se column positive definite. Previously checked Stan calling nma() function. Improvement: Updated plaque psoriasis ML-NMR vignette include new analyses, including assessing assumptions population adjustment synthesising multinomial outcomes. Improvement: Improved behaviour .trtclass special regression formulas, now main effects .trtclass always removed since collinear .trt. allows expansion interactions * work properly, e.g. ~variable*.trtclass, whereas previously resulted -parametrised model. Fix: CRAN check note manual HTML5 compatibility. Fix: Residual deviance log likelihood parameters now named correctly contrast-based aggregate data present (PR #19).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-042","dir":"Changelog","previous_headings":"","what":"multinma 0.4.2","title":"multinma 0.4.2","text":"CRAN release: 2022-03-02 Fix: Error get_nodesplits() studies multiple arms treatment. Fix: print.nma_data() now prints repeated arms studies multiple arms treatment. Fix: CRAN warning regarding invalid img tag height attribute documentation.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-041","dir":"Changelog","previous_headings":"","what":"multinma 0.4.1","title":"multinma 0.4.1","text":"CRAN release: 2022-02-04 Fix: tidyr v1.2.0 breaks ordered multinomial models studies report categories (.e. multinomial category outcomes NA multi()) (PR #11)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-040","dir":"Changelog","previous_headings":"","what":"multinma 0.4.0","title":"multinma 0.4.0","text":"CRAN release: 2022-01-18 Feature: Node-splitting models assessing inconsistency now available consistency = \"nodesplit\" nma(). Comparisons split can chosen using nodesplit argument, default possibly inconsistent comparisons chosen using get_nodesplits(). Node-splitting results can summarised summary.nma_nodesplit() plotted plot.nodesplit_summary(). Feature: correlation matrix generating integration points add_integration() ML-NMR models now adjusted underlying Gaussian copula, output correlations integration points better match requested input correlations. new argument cor_adjust controls behaviour, options \"spearman\", \"pearson\", \"none\". Although correlations typically little impact results, strict reproducibility old behaviour version 0.3.0 available cor_adjust = \"legacy\". Feature: random effects models, predictive distribution relative/absolute effects new study can now obtained relative_effects() predict.stan_nma() respectively, using new argument predictive_distribution = TRUE. Feature: Added option calculate SUCRA values summarising posterior treatment ranks posterior_ranks() posterior_rank_probs(), argument sucra = TRUE. Improvement: Factor order now respected trt, study, trt_class factors, previously order levels reset natural sort order. Improvement: Update package website Bootstrap 5 release pkgdown 2.0.0 Fix: Model fitting now robust non-default settings options(\"contrasts\"). Fix: plot.nma_data() longer gives ggplot deprecation warning (PR #6). Fix: Bug predict.stan_nma() single covariate newdata data.frame (PR #7). Fix: Attempting call predict.stan_nma() regression model contrast data newdata baseline specified now throws descriptive error message.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-030","dir":"Changelog","previous_headings":"","what":"multinma 0.3.0","title":"multinma 0.3.0","text":"CRAN release: 2021-03-18 Feature: Added baseline_type baseline_level arguments predict.stan_nma(), allow baseline distributions specified response linear predictor scale, individual aggregate level. Feature: baseline argument predict.stan_nma() can now accept (named) list baseline distributions newdata contains multiple studies. Improvement: Misspecified newdata arguments functions like relative_effects() predict.stan_nma() now give informative error messages. Fix: Constructing models contrast-based data previously gave errors scenarios (ML-NMR models, UME models, cases AgD meta-regression models). Fix: Ensure CRAN additional checks --run-donttest run correctly.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-021","dir":"Changelog","previous_headings":"","what":"multinma 0.2.1","title":"multinma 0.2.1","text":"CRAN release: 2021-01-09 Fix: Producing relative effect estimates contrasts using relative_effects() all_contrasts = TRUE longer gives error regression models. Fix: Specifying covariate correlation matrix cor add_integration() required one covariate present. Improvement: Added detailed documentation likelihoods link functions available data type (likelihood link arguments nma()).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-020","dir":"Changelog","previous_headings":"","what":"multinma 0.2.0","title":"multinma 0.2.0","text":"CRAN release: 2020-12-04 Feature: set_*() functions now accept dplyr::mutate() style semantics, allowing inline variable transformations. Feature: Added ordered multinomial models, helper function multi() specifying outcomes. Accompanied new data set hta_psoriasis vignette. Feature: Implicit flat priors can now specified, parameter, using flat(). Improvement: .array.stan_nma() now much efficient, meaning many post-estimation functions also now much efficient. Improvement: plot.nma_dic() now efficient, particularly large numbers data points. Improvement: layering points producing “dev-dev” plots using plot.nma_dic() multiple data types reversed improved clarity (now AgD top IPD). Improvement: Aggregate-level predictions predict() ML-NMR / IPD regression models now calculated much memory-efficient manner. Improvement: Added overview examples given vignettes. Improvement: Network plots weight_edges = TRUE longer produce legends non-integer values number studies. Fix: plot.nma_dic() longer gives error attempting specify .width argument producing “dev-dev” plots.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-013","dir":"Changelog","previous_headings":"","what":"multinma 0.1.3","title":"multinma 0.1.3","text":"CRAN release: 2020-06-30 Format DESCRIPTION CRAN requirements","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-012","dir":"Changelog","previous_headings":"","what":"multinma 0.1.2","title":"multinma 0.1.2","text":"Wrapped long-running examples \\donttest{} instead \\dontrun{}","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-011","dir":"Changelog","previous_headings":"","what":"multinma 0.1.1","title":"multinma 0.1.1","text":"Reduced size vignettes Added methods paper reference DESCRIPTION Added zenodo DOI","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-010","dir":"Changelog","previous_headings":"","what":"multinma 0.1.0","title":"multinma 0.1.0","text":"Feature: Network plots, using plot() method nma_data objects. Feature: .igraph(), as_tbl_graph() methods nma_data objects. Feature: Produce relative effect estimates relative_effects(), posterior ranks posterior_ranks(), posterior rank probabilities posterior_rank_probs(). study-specific regression model given. Feature: Produce predictions absolute effects predict() method stan_nma objects. Feature: Plots relative effects, ranks, predictions, parameter estimates via plot.nma_summary(). Enables centering predictors (center = TRUE) nma() regression model given, replacing agd_sample_size argument nma() Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Allows nodes network plots weighted sample size Feature: Plots residual deviance contributions model “dev-dev” plots comparing residual deviance contributions two models, using plot() method nma_dic objects produced dic(). Feature: Complementary log-log (cloglog) link function link = \"cloglog\" binomial likelihoods. Feature: Option specify priors heterogeneity standard deviation, variance, precision, argument prior_het_type. Feature: Added log-Normal prior distribution. Feature: Plots prior distributions vs. posterior distributions plot_prior_posterior(). Feature: Pairs plot method pairs(). Feature: Added vignettes example analyses NICE TSDs . Fix: Random effects models even moderate numbers studies slow. now run much quickly, using sparse representation RE correlation matrix automatically enabled sparsity 90% (roughly equivalent 10 studies).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-001","dir":"Changelog","previous_headings":"","what":"multinma 0.0.1","title":"multinma 0.0.1","text":"Initial release.","code":""}]
