[{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Atrial fibrillation","text":"Whilst data patient-years risk study (E), ignore follow analysis Cooper et al. (2009), instead analysing number patients stroke (r) total (n) arm. use function set_agd_arm() set network, making sure specify treatment classes trt_class. remove WASPO study network arms zero events, study therefore contributes information. (better analysis, accounting differences patient-years risk studies, can performed specifying rate outcome r E set_agd_arm() . following code remains identical.) Plot network plot() method:","code":"af_net <- set_agd_arm(atrial_fibrillation[atrial_fibrillation$studyc != \"WASPO\", ],                        study = studyc,                       trt = trtc,                       r = r,                        n = n,                       trt_class = trt_class) af_net #> A network with 25 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                                                  #>  ACTIVE-W      2: Standard adjusted dose anti-coagulant | Low dose aspirin + copidogrel        #>  AFASAK 1      3: Standard adjusted dose anti-coagulant | Low dose aspirin | Placebo/Standa... #>  AFASAK 2      4: Standard adjusted dose anti-coagulant | Fixed dose warfarin | Fixed dose ... #>  BAATAF        2: Low adjusted dose anti-coagulant | Placebo/Standard care                     #>  BAFTA         2: Standard adjusted dose anti-coagulant | Low dose aspirin                     #>  CAFA          2: Standard adjusted dose anti-coagulant | Placebo/Standard care                #>  Chinese ATAFS 2: Standard adjusted dose anti-coagulant | Low dose aspirin                     #>  EAFT          3: Standard adjusted dose anti-coagulant | Medium dose aspirin | Placebo/Sta... #>  ESPS 2        4: Dipyridamole | Low dose aspirin | Low dose aspirin + dipyridamole | Place... #>  JAST          2: Low dose aspirin | Placebo/Standard care                                     #>  ... plus 15 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 17, in 4 classes #> Total number of studies: 25 #> Reference treatment is: Standard adjusted dose anti-coagulant #> Network is connected plot(af_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE) +    ggplot2::theme(legend.position = \"bottom\", legend.box = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Atrial fibrillation","text":"fit two (random effects) models: standard NMA model without covariates (model 1 Cooper et al. (2009)); meta-regression model adjusting proportion individuals study prior stroke, shared interaction coefficients treatment class (model 4b Cooper et al. (2009)).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"nma-with-no-covariates","dir":"Articles","previous_headings":"Meta-analysis models","what":"NMA with no covariates","title":"Example: Atrial fibrillation","text":"fit random effects model using nma() function trt_effects = \"random\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting model nma() function. increase target acceptance rate adapt_delta = 0.99 minimise divergent transition warnings. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  can compute relative effects placebo/standard care relative_effects() function trt_ref argument: estimates can easily plotted plot() method:  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. af_fit_1 <- nma(af_net,                  trt_effects = \"random\",                 prior_intercept = normal(scale = 100),                 prior_trt = normal(scale = 100),                 prior_het = half_normal(scale = 5),                 adapt_delta = 0.99) #> Note: Setting \"Standard adjusted dose anti-coagulant\" as the network reference treatment. af_fit_1 #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                  mean se_mean   sd     2.5%      25%      50% #> d[Acenocoumarol]                                -0.78    0.01 0.83    -2.48    -1.31    -0.75 #> d[Alternate day aspirin]                        -0.98    0.02 1.35    -4.12    -1.70    -0.82 #> d[Dipyridamole]                                  0.60    0.01 0.44    -0.30     0.32     0.60 #> d[Fixed dose warfarin]                           0.93    0.01 0.40     0.12     0.67     0.94 #> d[Fixed dose warfarin + low dose aspirin]        0.49    0.01 0.44    -0.42     0.22     0.49 #> d[Fixed dose warfarin + medium dose aspirin]     0.89    0.01 0.32     0.23     0.69     0.90 #> d[High dose aspirin]                             0.53    0.01 0.77    -1.04     0.03     0.54 #> d[Indobufen]                                     0.24    0.01 0.44    -0.62    -0.03     0.24 #> d[Low adjusted dose anti-coagulant]             -0.29    0.01 0.38    -1.02    -0.55    -0.30 #> d[Low dose aspirin]                              0.62    0.01 0.22     0.18     0.48     0.63 #> d[Low dose aspirin + copidogrel]                 0.51    0.01 0.34    -0.20     0.31     0.52 #> d[Low dose aspirin + dipyridamole]               0.27    0.01 0.46    -0.63    -0.02     0.27 #> d[Medium dose aspirin]                           0.39    0.00 0.20    -0.01     0.26     0.40 #> d[Placebo/Standard care]                         0.76    0.00 0.20     0.38     0.64     0.76 #> d[Triflusal]                                     0.64    0.01 0.63    -0.54     0.22     0.63 #> d[Ximelagatran]                                 -0.09    0.00 0.26    -0.61    -0.25    -0.08 #> lp__                                         -5000.74    0.23 7.21 -5015.58 -5005.34 -5000.40 #> tau                                              0.28    0.01 0.14     0.03     0.18     0.27 #>                                                   75%    97.5% n_eff Rhat #> d[Acenocoumarol]                                -0.22     0.81  3946 1.00 #> d[Alternate day aspirin]                        -0.03     1.20  3968 1.00 #> d[Dipyridamole]                                  0.89     1.51  3105 1.00 #> d[Fixed dose warfarin]                           1.20     1.72  3221 1.00 #> d[Fixed dose warfarin + low dose aspirin]        0.79     1.34  2643 1.00 #> d[Fixed dose warfarin + medium dose aspirin]     1.09     1.50  2492 1.00 #> d[High dose aspirin]                             1.05     2.04  4819 1.00 #> d[Indobufen]                                     0.52     1.15  4004 1.00 #> d[Low adjusted dose anti-coagulant]             -0.04     0.44  2853 1.00 #> d[Low dose aspirin]                              0.77     1.07  1903 1.00 #> d[Low dose aspirin + copidogrel]                 0.71     1.22  3089 1.00 #> d[Low dose aspirin + dipyridamole]               0.58     1.17  3034 1.00 #> d[Medium dose aspirin]                           0.52     0.76  2479 1.00 #> d[Placebo/Standard care]                         0.89     1.14  1601 1.00 #> d[Triflusal]                                     1.03     1.95  3413 1.00 #> d[Ximelagatran]                                  0.07     0.45  3680 1.00 #> lp__                                         -4995.68 -4987.55   962 1.00 #> tau                                              0.36     0.56   705 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:28:00 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(af_fit_1, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(af_fit_1, prior = c(\"trt\", \"het\")) (af_1_releff <- relative_effects(af_fit_1, trt_ref = \"Placebo/Standard care\")) #>                                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> d[Standard adjusted dose anti-coagulant]     -0.76 0.20 -1.14 -0.89 -0.76 -0.64 -0.38     1635 #> d[Acenocoumarol]                             -1.54 0.85 -3.29 -2.10 -1.52 -0.96  0.06     3642 #> d[Alternate day aspirin]                     -1.74 1.34 -4.94 -2.44 -1.57 -0.81  0.42     4991 #> d[Dipyridamole]                              -0.16 0.42 -0.98 -0.43 -0.17  0.11  0.65     5029 #> d[Fixed dose warfarin]                        0.17 0.43 -0.71 -0.11  0.17  0.46  1.02     3048 #> d[Fixed dose warfarin + low dose aspirin]    -0.27 0.40 -1.08 -0.51 -0.27 -0.02  0.51     4301 #> d[Fixed dose warfarin + medium dose aspirin]  0.13 0.36 -0.64 -0.10  0.14  0.37  0.82     2655 #> d[High dose aspirin]                         -0.23 0.76 -1.77 -0.73 -0.21  0.27  1.25     5735 #> d[Indobufen]                                 -0.52 0.49 -1.49 -0.83 -0.52 -0.21  0.46     3173 #> d[Low adjusted dose anti-coagulant]          -1.06 0.35 -1.73 -1.29 -1.06 -0.83 -0.39     5144 #> d[Low dose aspirin]                          -0.14 0.21 -0.56 -0.27 -0.14  0.00  0.27     4961 #> d[Low dose aspirin + copidogrel]             -0.25 0.40 -1.06 -0.49 -0.25  0.00  0.54     2532 #> d[Low dose aspirin + dipyridamole]           -0.49 0.44 -1.35 -0.77 -0.49 -0.21  0.37     4736 #> d[Medium dose aspirin]                       -0.37 0.22 -0.82 -0.51 -0.37 -0.23  0.05     2720 #> d[Triflusal]                                 -0.12 0.66 -1.40 -0.56 -0.13  0.30  1.21     3080 #> d[Ximelagatran]                              -0.85 0.33 -1.50 -1.06 -0.85 -0.64 -0.19     2862 #>                                              Tail_ESS Rhat #> d[Standard adjusted dose anti-coagulant]         2170    1 #> d[Acenocoumarol]                                 3217    1 #> d[Alternate day aspirin]                         2495    1 #> d[Dipyridamole]                                  2896    1 #> d[Fixed dose warfarin]                           2779    1 #> d[Fixed dose warfarin + low dose aspirin]        2738    1 #> d[Fixed dose warfarin + medium dose aspirin]     2306    1 #> d[High dose aspirin]                             3074    1 #> d[Indobufen]                                     2454    1 #> d[Low adjusted dose anti-coagulant]              3161    1 #> d[Low dose aspirin]                              2702    1 #> d[Low dose aspirin + copidogrel]                 2383    1 #> d[Low dose aspirin + dipyridamole]               3067    1 #> d[Medium dose aspirin]                           2704    1 #> d[Triflusal]                                     2869    1 #> d[Ximelagatran]                                  2279    1 plot(af_1_releff, ref_line = 0) (af_1_ranks <- posterior_ranks(af_fit_1)) #>                                                  mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS #> rank[Standard adjusted dose anti-coagulant]      5.27 1.45    3   4   5   6     8     2533 #> rank[Acenocoumarol]                              3.05 3.13    1   1   2   3    13     3646 #> rank[Alternate day aspirin]                      3.75 4.24    1   1   2   5    16     5001 #> rank[Dipyridamole]                              11.30 3.77    4   9  11  15    17     4497 #> rank[Fixed dose warfarin]                       14.13 3.04    6  12  15  16    17     3439 #> rank[Fixed dose warfarin + low dose aspirin]    10.25 3.80    3   8  10  13    17     3824 #> rank[Fixed dose warfarin + medium dose aspirin] 14.10 2.66    8  13  15  16    17     2354 #> rank[High dose aspirin]                         10.37 5.28    1   6  11  16    17     5236 #> rank[Indobufen]                                  7.98 3.92    2   5   8  10    16     3993 #> rank[Low adjusted dose anti-coagulant]           3.71 2.13    1   2   3   5     9     3643 #> rank[Low dose aspirin]                          11.76 2.25    7  10  12  13    16     3975 #> rank[Low dose aspirin + copidogrel]             10.50 3.41    4   8  10  13    17     3110 #> rank[Low dose aspirin + dipyridamole]            8.17 3.84    2   5   8  11    16     4103 #> rank[Medium dose aspirin]                        9.16 2.10    5   8   9  11    13     3717 #> rank[Placebo/Standard care]                     13.42 1.78   10  12  14  15    16     3565 #> rank[Triflusal]                                 11.28 4.65    3   7  12  16    17     3367 #> rank[Ximelagatran]                               4.82 2.25    2   3   4   6    10     2913 #>                                                 Tail_ESS Rhat #> rank[Standard adjusted dose anti-coagulant]         2697    1 #> rank[Acenocoumarol]                                 3409    1 #> rank[Alternate day aspirin]                         4048    1 #> rank[Dipyridamole]                                    NA    1 #> rank[Fixed dose warfarin]                             NA    1 #> rank[Fixed dose warfarin + low dose aspirin]        2831    1 #> rank[Fixed dose warfarin + medium dose aspirin]       NA    1 #> rank[High dose aspirin]                               NA    1 #> rank[Indobufen]                                     3258    1 #> rank[Low adjusted dose anti-coagulant]              2778    1 #> rank[Low dose aspirin]                              3209    1 #> rank[Low dose aspirin + copidogrel]                 2867    1 #> rank[Low dose aspirin + dipyridamole]               3349    1 #> rank[Medium dose aspirin]                           3154    1 #> rank[Placebo/Standard care]                         3380    1 #> rank[Triflusal]                                       NA    1 #> rank[Ximelagatran]                                  2821    1 plot(af_1_ranks) (af_1_rankprobs <- posterior_rank_probs(af_fit_1)) #>                                              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[Standard adjusted dose anti-coagulant]          0.00      0.02      0.08      0.20      0.29 #> d[Acenocoumarol]                                  0.38      0.29      0.10      0.05      0.04 #> d[Alternate day aspirin]                          0.46      0.18      0.07      0.04      0.04 #> d[Dipyridamole]                                   0.00      0.01      0.02      0.02      0.03 #> d[Fixed dose warfarin]                            0.00      0.00      0.00      0.01      0.01 #> d[Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.02      0.04      0.04 #> d[Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00      0.00      0.00 #> d[High dose aspirin]                              0.03      0.06      0.05      0.06      0.04 #> d[Indobufen]                                      0.01      0.04      0.07      0.08      0.09 #> d[Low adjusted dose anti-coagulant]               0.08      0.23      0.27      0.15      0.09 #> d[Low dose aspirin]                               0.00      0.00      0.00      0.00      0.00 #> d[Low dose aspirin + copidogrel]                  0.00      0.01      0.01      0.02      0.03 #> d[Low dose aspirin + dipyridamole]                0.01      0.04      0.07      0.08      0.08 #> d[Medium dose aspirin]                            0.00      0.00      0.00      0.01      0.02 #> d[Placebo/Standard care]                          0.00      0.00      0.00      0.00      0.00 #> d[Triflusal]                                      0.00      0.02      0.05      0.04      0.04 #> d[Ximelagatran]                                   0.02      0.10      0.18      0.21      0.17 #>                                              p_rank[6] p_rank[7] p_rank[8] p_rank[9] #> d[Standard adjusted dose anti-coagulant]          0.23      0.12      0.05      0.01 #> d[Acenocoumarol]                                  0.03      0.02      0.02      0.01 #> d[Alternate day aspirin]                          0.03      0.03      0.03      0.02 #> d[Dipyridamole]                                   0.04      0.06      0.07      0.08 #> d[Fixed dose warfarin]                            0.01      0.02      0.02      0.03 #> d[Fixed dose warfarin + low dose aspirin]         0.06      0.07      0.09      0.10 #> d[Fixed dose warfarin + medium dose aspirin]      0.01      0.01      0.02      0.03 #> d[High dose aspirin]                              0.05      0.06      0.05      0.05 #> d[Indobufen]                                      0.09      0.10      0.10      0.09 #> d[Low adjusted dose anti-coagulant]               0.07      0.05      0.02      0.01 #> d[Low dose aspirin]                               0.01      0.02      0.05      0.08 #> d[Low dose aspirin + copidogrel]                  0.05      0.09      0.09      0.11 #> d[Low dose aspirin + dipyridamole]                0.10      0.10      0.10      0.08 #> d[Medium dose aspirin]                            0.06      0.12      0.17      0.20 #> d[Placebo/Standard care]                          0.00      0.00      0.01      0.01 #> d[Triflusal]                                      0.05      0.06      0.06      0.06 #> d[Ximelagatran]                                   0.12      0.08      0.05      0.02 #>                                              p_rank[10] p_rank[11] p_rank[12] p_rank[13] #> d[Standard adjusted dose anti-coagulant]           0.00       0.00       0.00       0.00 #> d[Acenocoumarol]                                   0.01       0.01       0.01       0.01 #> d[Alternate day aspirin]                           0.02       0.02       0.01       0.01 #> d[Dipyridamole]                                    0.08       0.09       0.08       0.08 #> d[Fixed dose warfarin]                             0.04       0.05       0.06       0.07 #> d[Fixed dose warfarin + low dose aspirin]          0.09       0.09       0.07       0.08 #> d[Fixed dose warfarin + medium dose aspirin]       0.04       0.06       0.07       0.09 #> d[High dose aspirin]                               0.05       0.05       0.04       0.04 #> d[Indobufen]                                       0.07       0.05       0.04       0.04 #> d[Low adjusted dose anti-coagulant]                0.01       0.00       0.00       0.00 #> d[Low dose aspirin]                                0.13       0.16       0.18       0.14 #> d[Low dose aspirin + copidogrel]                   0.11       0.10       0.10       0.08 #> d[Low dose aspirin + dipyridamole]                 0.08       0.06       0.06       0.04 #> d[Medium dose aspirin]                             0.16       0.13       0.06       0.04 #> d[Placebo/Standard care]                           0.04       0.08       0.14       0.21 #> d[Triflusal]                                       0.06       0.05       0.06       0.05 #> d[Ximelagatran]                                    0.02       0.01       0.01       0.00 #>                                              p_rank[14] p_rank[15] p_rank[16] p_rank[17] #> d[Standard adjusted dose anti-coagulant]           0.00       0.00       0.00       0.00 #> d[Acenocoumarol]                                   0.01       0.01       0.00       0.00 #> d[Alternate day aspirin]                           0.01       0.01       0.02       0.02 #> d[Dipyridamole]                                    0.08       0.09       0.08       0.08 #> d[Fixed dose warfarin]                             0.09       0.13       0.21       0.25 #> d[Fixed dose warfarin + low dose aspirin]          0.08       0.06       0.06       0.04 #> d[Fixed dose warfarin + medium dose aspirin]       0.11       0.17       0.22       0.16 #> d[High dose aspirin]                               0.05       0.06       0.08       0.18 #> d[Indobufen]                                       0.03       0.03       0.03       0.02 #> d[Low adjusted dose anti-coagulant]                0.00       0.00       0.00       0.00 #> d[Low dose aspirin]                                0.12       0.07       0.03       0.01 #> d[Low dose aspirin + copidogrel]                   0.07       0.06       0.05       0.03 #> d[Low dose aspirin + dipyridamole]                 0.04       0.03       0.02       0.02 #> d[Medium dose aspirin]                             0.02       0.01       0.00       0.00 #> d[Placebo/Standard care]                           0.23       0.17       0.09       0.02 #> d[Triflusal]                                       0.06       0.08       0.10       0.17 #> d[Ximelagatran]                                    0.00       0.00       0.00       0.00 plot(af_1_rankprobs) (af_1_cumrankprobs <- posterior_rank_probs(af_fit_1, cumulative = TRUE)) #>                                              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[Standard adjusted dose anti-coagulant]          0.00      0.02      0.10      0.30      0.59 #> d[Acenocoumarol]                                  0.38      0.67      0.77      0.81      0.85 #> d[Alternate day aspirin]                          0.46      0.63      0.70      0.74      0.77 #> d[Dipyridamole]                                   0.00      0.01      0.02      0.05      0.08 #> d[Fixed dose warfarin]                            0.00      0.00      0.00      0.01      0.02 #> d[Fixed dose warfarin + low dose aspirin]         0.00      0.02      0.04      0.08      0.12 #> d[Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00      0.00      0.01 #> d[High dose aspirin]                              0.03      0.09      0.14      0.20      0.24 #> d[Indobufen]                                      0.01      0.06      0.13      0.21      0.30 #> d[Low adjusted dose anti-coagulant]               0.08      0.31      0.59      0.74      0.82 #> d[Low dose aspirin]                               0.00      0.00      0.00      0.00      0.00 #> d[Low dose aspirin + copidogrel]                  0.00      0.01      0.02      0.04      0.07 #> d[Low dose aspirin + dipyridamole]                0.01      0.05      0.12      0.19      0.27 #> d[Medium dose aspirin]                            0.00      0.00      0.00      0.01      0.03 #> d[Placebo/Standard care]                          0.00      0.00      0.00      0.00      0.00 #> d[Triflusal]                                      0.00      0.02      0.07      0.11      0.15 #> d[Ximelagatran]                                   0.02      0.12      0.30      0.52      0.68 #>                                              p_rank[6] p_rank[7] p_rank[8] p_rank[9] #> d[Standard adjusted dose anti-coagulant]          0.82      0.93      0.98      1.00 #> d[Acenocoumarol]                                  0.88      0.90      0.93      0.94 #> d[Alternate day aspirin]                          0.80      0.83      0.86      0.88 #> d[Dipyridamole]                                   0.12      0.17      0.25      0.33 #> d[Fixed dose warfarin]                            0.03      0.04      0.07      0.10 #> d[Fixed dose warfarin + low dose aspirin]         0.18      0.25      0.34      0.44 #> d[Fixed dose warfarin + medium dose aspirin]      0.01      0.02      0.05      0.07 #> d[High dose aspirin]                              0.29      0.34      0.39      0.44 #> d[Indobufen]                                      0.39      0.49      0.60      0.69 #> d[Low adjusted dose anti-coagulant]               0.89      0.94      0.96      0.98 #> d[Low dose aspirin]                               0.01      0.03      0.08      0.16 #> d[Low dose aspirin + copidogrel]                  0.12      0.20      0.30      0.40 #> d[Low dose aspirin + dipyridamole]                0.37      0.47      0.57      0.65 #> d[Medium dose aspirin]                            0.10      0.22      0.38      0.58 #> d[Placebo/Standard care]                          0.00      0.00      0.01      0.02 #> d[Triflusal]                                      0.20      0.26      0.31      0.37 #> d[Ximelagatran]                                   0.81      0.88      0.94      0.96 #>                                              p_rank[10] p_rank[11] p_rank[12] p_rank[13] #> d[Standard adjusted dose anti-coagulant]           1.00       1.00       1.00       1.00 #> d[Acenocoumarol]                                   0.95       0.96       0.97       0.98 #> d[Alternate day aspirin]                           0.90       0.91       0.92       0.94 #> d[Dipyridamole]                                    0.41       0.50       0.58       0.67 #> d[Fixed dose warfarin]                             0.14       0.19       0.25       0.32 #> d[Fixed dose warfarin + low dose aspirin]          0.53       0.61       0.69       0.76 #> d[Fixed dose warfarin + medium dose aspirin]       0.11       0.17       0.24       0.33 #> d[High dose aspirin]                               0.49       0.54       0.58       0.63 #> d[Indobufen]                                       0.75       0.80       0.85       0.89 #> d[Low adjusted dose anti-coagulant]                0.99       0.99       1.00       1.00 #> d[Low dose aspirin]                                0.29       0.45       0.62       0.77 #> d[Low dose aspirin + copidogrel]                   0.51       0.61       0.70       0.78 #> d[Low dose aspirin + dipyridamole]                 0.73       0.79       0.85       0.89 #> d[Medium dose aspirin]                             0.75       0.87       0.94       0.98 #> d[Placebo/Standard care]                           0.06       0.14       0.28       0.49 #> d[Triflusal]                                       0.42       0.48       0.54       0.59 #> d[Ximelagatran]                                    0.98       0.99       0.99       0.99 #>                                              p_rank[14] p_rank[15] p_rank[16] p_rank[17] #> d[Standard adjusted dose anti-coagulant]           1.00       1.00       1.00          1 #> d[Acenocoumarol]                                   0.98       0.99       1.00          1 #> d[Alternate day aspirin]                           0.95       0.96       0.98          1 #> d[Dipyridamole]                                    0.75       0.84       0.92          1 #> d[Fixed dose warfarin]                             0.41       0.55       0.75          1 #> d[Fixed dose warfarin + low dose aspirin]          0.84       0.90       0.96          1 #> d[Fixed dose warfarin + medium dose aspirin]       0.44       0.61       0.84          1 #> d[High dose aspirin]                               0.68       0.74       0.82          1 #> d[Indobufen]                                       0.92       0.95       0.98          1 #> d[Low adjusted dose anti-coagulant]                1.00       1.00       1.00          1 #> d[Low dose aspirin]                                0.89       0.96       0.99          1 #> d[Low dose aspirin + copidogrel]                   0.85       0.92       0.97          1 #> d[Low dose aspirin + dipyridamole]                 0.93       0.96       0.98          1 #> d[Medium dose aspirin]                             0.99       1.00       1.00          1 #> d[Placebo/Standard care]                           0.72       0.88       0.98          1 #> d[Triflusal]                                       0.65       0.73       0.83          1 #> d[Ximelagatran]                                    1.00       1.00       1.00          1 plot(af_1_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"network-meta-regression-adjusting-for-proportion-of-prior-stroke","dir":"Articles","previous_headings":"Meta-analysis models","what":"Network meta-regression adjusting for proportion of prior stroke","title":"Example: Atrial fibrillation","text":"now consider meta-regression model adjusting proportion individuals study prior stroke, shared interaction coefficients treatment class. regression model specified nma() function using formula regression argument. formula ~ .trt:stroke means interactions prior stroke treatment included; .trt special variable indicates treatment, stroke original data set. specify class_interactions = \"common\" denote interaction parameters common (.e. shared) treatments within class. (Setting class_interactions = \"independent\" fit model 2 Cooper et al. (2009) separate interactions treatment, data permitting.) use prior distributions , additionally require prior distribution regression coefficients prior_reg; use \\(\\mathrm{N}(0, 100^2)\\) prior distribution. QR decomposition can greatly improve efficiency sampling regression models decorrelating sampling space; specify used QR = TRUE, increase target acceptance rate adapt_delta = 0.99 minimise divergent transition warnings. Basic parameter summaries given print() method: estimated treatment effects d[] shown correspond relative effects reference level covariate, proportion prior stroke centered network mean value 0.296. default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  can compute relative effects placebo/standard care relative_effects() function trt_ref argument, default produces relative effects observed proportions prior stroke study: can produce estimated treatment effects particular covariate values using newdata argument. example, treatment effects individuals individuals prior stroke produced  estimated class interactions (reference “Mixed” class) uncertain.  interactions straightforward interpret transform interaction coefficients (using consistency equations) control class:  evidence effect anti-coagulants increases (compared control) prior stroke. little evidence effect anti-platelets reduces prior stroke, although point estimate represents substantial reduction effectiveness, 95% Credible Interval includes values correspond substantial increases treatment effect. interaction effect stroke mixed treatments uncertain, potentially indicates substantial reduction treatment effects prior stroke. can also produce treatment rankings, rank probabilities, cumulative rank probabilities. default (without newdata argument specified), produced value stroke study network turn. instead produce rankings individuals individuals prior stroke, specify newdata argument.","code":"af_fit_4b <- nma(af_net,                   trt_effects = \"random\",                  regression = ~ .trt:stroke,                  class_interactions = \"common\",                  QR = TRUE,                  prior_intercept = normal(scale = 100),                  prior_trt = normal(scale = 100),                  prior_reg = normal(scale = 100),                  prior_het = half_normal(scale = 5),                  adapt_delta = 0.99) #> Note: Setting \"Standard adjusted dose anti-coagulant\" as the network reference treatment. #> Warning: There were 4 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess af_fit_4b #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:stroke. #> Centred covariates at the following overall mean values: #>    stroke  #> 0.2957377  #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                  mean se_mean   sd     2.5%      25%      50% #> beta[.trtclassControl:stroke]                    0.71    0.01 0.45    -0.13     0.41     0.70 #> beta[.trtclassAnti-platelet:stroke]              0.94    0.01 0.43     0.12     0.67     0.94 #> beta[.trtclassMixed:stroke]                      3.93    0.03 2.07    -0.08     2.61     3.91 #> d[Acenocoumarol]                                 0.37    0.02 0.99    -1.63    -0.27     0.39 #> d[Alternate day aspirin]                        -0.93    0.03 1.41    -4.31    -1.66    -0.72 #> d[Dipyridamole]                                  0.57    0.01 0.41    -0.24     0.31     0.57 #> d[Fixed dose warfarin]                           0.65    0.01 0.38    -0.09     0.40     0.65 #> d[Fixed dose warfarin + low dose aspirin]        1.46    0.01 0.74    -0.01     0.99     1.46 #> d[Fixed dose warfarin + medium dose aspirin]     1.01    0.00 0.31     0.44     0.81     1.00 #> d[High dose aspirin]                             0.43    0.01 0.74    -1.03    -0.08     0.44 #> d[Indobufen]                                    -0.42    0.01 0.49    -1.39    -0.75    -0.42 #> d[Low adjusted dose anti-coagulant]             -0.43    0.01 0.38    -1.20    -0.67    -0.42 #> d[Low dose aspirin]                              0.72    0.00 0.20     0.30     0.59     0.72 #> d[Low dose aspirin + copidogrel]                 0.65    0.01 0.29     0.06     0.49     0.65 #> d[Low dose aspirin + dipyridamole]               0.25    0.01 0.43    -0.61    -0.02     0.26 #> d[Medium dose aspirin]                           0.35    0.00 0.17     0.00     0.24     0.35 #> d[Placebo/Standard care]                         0.79    0.00 0.19     0.41     0.67     0.79 #> d[Triflusal]                                     0.92    0.01 0.60    -0.24     0.51     0.92 #> d[Ximelagatran]                                 -0.09    0.00 0.22    -0.51    -0.22    -0.09 #> lp__                                         -5016.95    0.20 7.21 -5032.26 -5021.61 -5016.62 #> tau                                              0.18    0.01 0.13     0.01     0.08     0.16 #>                                                   75%    97.5% n_eff Rhat #> beta[.trtclassControl:stroke]                    1.00     1.63  3248 1.00 #> beta[.trtclassAnti-platelet:stroke]              1.20     1.81  3002 1.00 #> beta[.trtclassMixed:stroke]                      5.22     8.14  3768 1.00 #> d[Acenocoumarol]                                 1.03     2.31  4216 1.00 #> d[Alternate day aspirin]                         0.03     1.27  1709 1.00 #> d[Dipyridamole]                                  0.84     1.35  4724 1.00 #> d[Fixed dose warfarin]                           0.90     1.37  3881 1.00 #> d[Fixed dose warfarin + low dose aspirin]        1.94     2.92  3875 1.00 #> d[Fixed dose warfarin + medium dose aspirin]     1.20     1.63  4144 1.00 #> d[High dose aspirin]                             0.93     1.86  4371 1.00 #> d[Indobufen]                                    -0.09     0.56  4046 1.00 #> d[Low adjusted dose anti-coagulant]             -0.18     0.30  4103 1.00 #> d[Low dose aspirin]                              0.85     1.11  3504 1.00 #> d[Low dose aspirin + copidogrel]                 0.82     1.22  2053 1.00 #> d[Low dose aspirin + dipyridamole]               0.53     1.09  5423 1.00 #> d[Medium dose aspirin]                           0.45     0.70  3570 1.00 #> d[Placebo/Standard care]                         0.91     1.16  3425 1.00 #> d[Triflusal]                                     1.30     2.11  4532 1.00 #> d[Ximelagatran]                                  0.04     0.35  2281 1.00 #> lp__                                         -5011.84 -5003.95  1314 1.00 #> tau                                              0.26     0.50   304 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:28:29 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(af_fit_4b, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(af_fit_4b, prior = c(\"reg\", \"het\")) # Not run (af_4b_releff <- relative_effects(af_fit_4b, trt_ref = \"Placebo/Standard care\")) plot(af_4b_releff, ref_line = 0) (af_4b_releff_01 <- relative_effects(af_fit_4b,                                       trt_ref = \"Placebo/Standard care\",                                      newdata = data.frame(stroke = c(0, 1),                                                            label = c(\"stroke = 0\", \"stroke = 1\")),                                      study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                           mean   sd  2.5%   25%   50%   75% #> d[stroke = 0: Standard adjusted dose anti-coagulant]     -0.58 0.25 -1.05 -0.74 -0.59 -0.42 #> d[stroke = 0: Acenocoumarol]                             -1.37 0.83 -3.09 -1.90 -1.35 -0.80 #> d[stroke = 0: Alternate day aspirin]                     -1.79 1.41 -5.12 -2.50 -1.58 -0.82 #> d[stroke = 0: Dipyridamole]                              -0.28 0.44 -1.17 -0.58 -0.29 -0.01 #> d[stroke = 0: Fixed dose warfarin]                        0.07 0.44 -0.79 -0.21  0.07  0.35 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]    -0.29 0.33 -0.95 -0.49 -0.29 -0.08 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin] -0.73 0.66 -2.07 -1.17 -0.71 -0.30 #> d[stroke = 0: High dose aspirin]                         -0.43 0.78 -1.95 -0.96 -0.42  0.08 #> d[stroke = 0: Indobufen]                                 -1.28 0.58 -2.40 -1.65 -1.27 -0.91 #> d[stroke = 0: Low adjusted dose anti-coagulant]          -1.01 0.34 -1.68 -1.22 -1.00 -0.78 #> d[stroke = 0: Low dose aspirin]                          -0.14 0.22 -0.58 -0.29 -0.15  0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]             -0.21 0.36 -0.92 -0.43 -0.21  0.01 #> d[stroke = 0: Low dose aspirin + dipyridamole]           -0.60 0.46 -1.55 -0.90 -0.60 -0.30 #> d[stroke = 0: Medium dose aspirin]                       -0.51 0.27 -1.03 -0.69 -0.52 -0.34 #> d[stroke = 0: Triflusal]                                  0.06 0.63 -1.14 -0.37  0.05  0.48 #> d[stroke = 0: Ximelagatran]                              -0.66 0.33 -1.29 -0.87 -0.67 -0.47 #>                                                          97.5% Bulk_ESS Tail_ESS Rhat #> d[stroke = 0: Standard adjusted dose anti-coagulant]     -0.08     3806     2442    1 #> d[stroke = 0: Acenocoumarol]                              0.20     3710     2739    1 #> d[stroke = 0: Alternate day aspirin]                      0.40     2585     1386    1 #> d[stroke = 0: Dipyridamole]                               0.60     5094     2676    1 #> d[stroke = 0: Fixed dose warfarin]                        0.92     3948     2838    1 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]     0.37     3832     1728    1 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]  0.56     4084     2528    1 #> d[stroke = 0: High dose aspirin]                          1.15     4508     3017    1 #> d[stroke = 0: Indobufen]                                 -0.17     3818     2621    1 #> d[stroke = 0: Low adjusted dose anti-coagulant]          -0.35     5432     3171    1 #> d[stroke = 0: Low dose aspirin]                           0.31     3699     2192    1 #> d[stroke = 0: Low dose aspirin + copidogrel]              0.53     2764     1731    1 #> d[stroke = 0: Low dose aspirin + dipyridamole]            0.30     5043     2763    1 #> d[stroke = 0: Medium dose aspirin]                        0.03     3967     2454    1 #> d[stroke = 0: Triflusal]                                  1.35     4693     3101    1 #> d[stroke = 0: Ximelagatran]                               0.00     3525     2025    1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                           mean   sd  2.5%   25%   50%   75% #> d[stroke = 1: Standard adjusted dose anti-coagulant]     -1.29 0.35 -2.00 -1.51 -1.28 -1.06 #> d[stroke = 1: Acenocoumarol]                              1.85 2.22 -2.58  0.40  1.85  3.27 #> d[stroke = 1: Alternate day aspirin]                     -1.56 1.43 -4.98 -2.33 -1.34 -0.60 #> d[stroke = 1: Dipyridamole]                              -0.05 0.39 -0.87 -0.30 -0.05  0.20 #> d[stroke = 1: Fixed dose warfarin]                       -0.64 0.53 -1.69 -0.98 -0.63 -0.29 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]     2.94 2.14 -1.25  1.54  2.94  4.29 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]  2.49 1.58 -0.57  1.45  2.46  3.51 #> d[stroke = 1: High dose aspirin]                         -0.20 0.74 -1.65 -0.69 -0.19  0.29 #> d[stroke = 1: Indobufen]                                 -1.05 0.52 -2.07 -1.38 -1.05 -0.70 #> d[stroke = 1: Low adjusted dose anti-coagulant]          -1.72 0.52 -2.76 -2.05 -1.72 -1.37 #> d[stroke = 1: Low dose aspirin]                           0.09 0.29 -0.50 -0.10  0.10  0.28 #> d[stroke = 1: Low dose aspirin + copidogrel]              0.02 0.39 -0.77 -0.21  0.03  0.26 #> d[stroke = 1: Low dose aspirin + dipyridamole]           -0.37 0.43 -1.24 -0.64 -0.36 -0.10 #> d[stroke = 1: Medium dose aspirin]                       -0.28 0.24 -0.78 -0.43 -0.27 -0.12 #> d[stroke = 1: Triflusal]                                  0.29 0.65 -0.97 -0.14  0.30  0.71 #> d[stroke = 1: Ximelagatran]                              -1.37 0.41 -2.19 -1.63 -1.37 -1.12 #>                                                          97.5% Bulk_ESS Tail_ESS Rhat #> d[stroke = 1: Standard adjusted dose anti-coagulant]     -0.61     3439     1396    1 #> d[stroke = 1: Acenocoumarol]                              6.40     4058     2594    1 #> d[stroke = 1: Alternate day aspirin]                      0.71     2606     1396    1 #> d[stroke = 1: Dipyridamole]                               0.71     4355     2635    1 #> d[stroke = 1: Fixed dose warfarin]                        0.37     3789     2331    1 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]     7.20     3971     2586    1 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]  5.67     4097     2477    1 #> d[stroke = 1: High dose aspirin]                          1.24     4434     2747    1 #> d[stroke = 1: Indobufen]                                 -0.05     4212     2396    1 #> d[stroke = 1: Low adjusted dose anti-coagulant]          -0.73     3399     2607    1 #> d[stroke = 1: Low dose aspirin]                           0.66     3351     2391    1 #> d[stroke = 1: Low dose aspirin + copidogrel]              0.77     3389     2302    1 #> d[stroke = 1: Low dose aspirin + dipyridamole]            0.45     4673     2357    1 #> d[stroke = 1: Medium dose aspirin]                        0.18     4402     2529    1 #> d[stroke = 1: Triflusal]                                  1.54     4715     2889    1 #> d[stroke = 1: Ximelagatran]                              -0.59     3139     1879    1 plot(af_4b_releff_01, ref_line = 0) plot(af_fit_4b, pars = \"beta\", stat = \"halfeye\", ref_line = 0) af_4b_beta <- as.array(af_fit_4b, pars = \"beta\")  # Subtract beta[Control:stroke] from the other class interactions af_4b_beta[ , , 2:3] <- sweep(af_4b_beta[ , , 2:3], 1:2,                                af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"], FUN = \"-\")  # Set beta[Anti-coagulant:stroke] = -beta[Control:stroke] af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"] <- -af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"] names(af_4b_beta)[1] <- \"beta[.trtclassAnti-coagulant:stroke]\"  # Summarise summary(af_4b_beta) #>                                       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> beta[.trtclassAnti-coagulant:stroke] -0.71 0.45 -1.63 -1.00 -0.70 -0.41  0.13     3598 #> beta[.trtclassAnti-platelet:stroke]   0.23 0.34 -0.45  0.01  0.24  0.45  0.89     4291 #> beta[.trtclassMixed:stroke]           3.22 2.10 -0.86  1.85  3.21  4.58  7.36     3968 #>                                      Tail_ESS Rhat #> beta[.trtclassAnti-coagulant:stroke]     1866    1 #> beta[.trtclassAnti-platelet:stroke]      2370    1 #> beta[.trtclassMixed:stroke]              2960    1 plot(summary(af_4b_beta), stat = \"halfeye\", ref_line = 0) (af_4b_ranks <- posterior_ranks(af_fit_4b,                                 newdata = data.frame(stroke = c(0, 1),                                                       label = c(\"stroke = 0\", \"stroke = 1\")),                                  study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                              mean   sd 2.5% 25% 50% 75% 97.5% #> rank[stroke = 0: Standard adjusted dose anti-coagulant]      7.74 1.87    4   6   8   9    11 #> rank[stroke = 0: Acenocoumarol]                              4.01 3.71    1   1   3   5    15 #> rank[stroke = 0: Alternate day aspirin]                      3.96 4.41    1   1   2   5    16 #> rank[stroke = 0: Dipyridamole]                              11.08 3.68    4   9  11  14    17 #> rank[stroke = 0: Fixed dose warfarin]                       14.23 2.82    7  13  15  16    17 #> rank[stroke = 0: Fixed dose warfarin + low dose aspirin]    11.04 3.65    4   8  11  14    17 #> rank[stroke = 0: Fixed dose warfarin + medium dose aspirin]  7.23 4.52    1   3   6  11    16 #> rank[stroke = 0: High dose aspirin]                          9.66 5.32    1   5  10  15    17 #> rank[stroke = 0: Indobufen]                                  3.59 2.71    1   2   3   4    12 #> rank[stroke = 0: Low adjusted dose anti-coagulant]           4.53 2.43    1   3   4   6    11 #> rank[stroke = 0: Low dose aspirin]                          12.86 1.94    9  12  13  14    16 #> rank[stroke = 0: Low dose aspirin + copidogrel]             12.03 2.88    6  10  12  14    17 #> rank[stroke = 0: Low dose aspirin + dipyridamole]            7.90 3.70    2   5   7  11    16 #> rank[stroke = 0: Medium dose aspirin]                        8.61 2.18    4   7   9  10    13 #> rank[stroke = 0: Placebo/Standard care]                     14.26 1.93   10  13  15  16    17 #> rank[stroke = 0: Triflusal]                                 13.37 4.05    4  11  15  17    17 #> rank[stroke = 0: Ximelagatran]                               6.91 2.63    3   5   7   8    13 #>                                                             Bulk_ESS Tail_ESS Rhat #> rank[stroke = 0: Standard adjusted dose anti-coagulant]         3233     2928    1 #> rank[stroke = 0: Acenocoumarol]                                 3970     3031    1 #> rank[stroke = 0: Alternate day aspirin]                         4399     3039    1 #> rank[stroke = 0: Dipyridamole]                                  4657       NA    1 #> rank[stroke = 0: Fixed dose warfarin]                           3890       NA    1 #> rank[stroke = 0: Fixed dose warfarin + low dose aspirin]        3818     2629    1 #> rank[stroke = 0: Fixed dose warfarin + medium dose aspirin]     3878     3407    1 #> rank[stroke = 0: High dose aspirin]                             4590       NA    1 #> rank[stroke = 0: Indobufen]                                     3570     2166    1 #> rank[stroke = 0: Low adjusted dose anti-coagulant]              4137     3164    1 #> rank[stroke = 0: Low dose aspirin]                              2844     2771    1 #> rank[stroke = 0: Low dose aspirin + copidogrel]                 2698     2055    1 #> rank[stroke = 0: Low dose aspirin + dipyridamole]               5335     3527    1 #> rank[stroke = 0: Medium dose aspirin]                           3553     2910    1 #> rank[stroke = 0: Placebo/Standard care]                         2688       NA    1 #> rank[stroke = 0: Triflusal]                                     4347       NA    1 #> rank[stroke = 0: Ximelagatran]                                  3092     1980    1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                              mean   sd 2.5% 25% 50% 75% 97.5% #> rank[stroke = 1: Standard adjusted dose anti-coagulant]      3.64 1.12 2.00   3   4   4     6 #> rank[stroke = 1: Acenocoumarol]                             13.35 4.26 1.00  14  15  16    17 #> rank[stroke = 1: Alternate day aspirin]                      4.46 3.96 1.00   1   3   6    14 #> rank[stroke = 1: Dipyridamole]                              10.55 2.69 5.00   9  11  13    15 #> rank[stroke = 1: Fixed dose warfarin]                        7.15 2.71 3.00   5   6   8    14 #> rank[stroke = 1: Fixed dose warfarin + low dose aspirin]    15.76 2.97 5.98  16  17  17    17 #> rank[stroke = 1: Fixed dose warfarin + medium dose aspirin] 15.44 1.88 9.00  15  16  16    17 #> rank[stroke = 1: High dose aspirin]                          9.48 3.96 2.00   6   9  13    16 #> rank[stroke = 1: Indobufen]                                  4.89 2.15 1.00   4   5   6    10 #> rank[stroke = 1: Low adjusted dose anti-coagulant]           2.01 1.29 1.00   1   2   2     5 #> rank[stroke = 1: Low dose aspirin]                          11.87 1.84 8.00  11  12  13    15 #> rank[stroke = 1: Low dose aspirin + copidogrel]             11.17 2.41 6.00  10  11  13    15 #> rank[stroke = 1: Low dose aspirin + dipyridamole]            8.24 2.65 3.00   6   8  10    14 #> rank[stroke = 1: Medium dose aspirin]                        8.61 1.69 6.00   7   8  10    12 #> rank[stroke = 1: Placebo/Standard care]                     11.14 1.92 8.00  10  11  12    15 #> rank[stroke = 1: Triflusal]                                 12.11 3.14 5.00  10  13  14    17 #> rank[stroke = 1: Ximelagatran]                               3.14 1.40 1.00   2   3   4     6 #>                                                             Bulk_ESS Tail_ESS Rhat #> rank[stroke = 1: Standard adjusted dose anti-coagulant]         3205     2642    1 #> rank[stroke = 1: Acenocoumarol]                                 3958       NA    1 #> rank[stroke = 1: Alternate day aspirin]                         4128     2691    1 #> rank[stroke = 1: Dipyridamole]                                  4084     3335    1 #> rank[stroke = 1: Fixed dose warfarin]                           3576     2717    1 #> rank[stroke = 1: Fixed dose warfarin + low dose aspirin]        3072       NA    1 #> rank[stroke = 1: Fixed dose warfarin + medium dose aspirin]     3611       NA    1 #> rank[stroke = 1: High dose aspirin]                             4444     3221    1 #> rank[stroke = 1: Indobufen]                                     4075     1794    1 #> rank[stroke = 1: Low adjusted dose anti-coagulant]              3233     3096    1 #> rank[stroke = 1: Low dose aspirin]                              3557     2724    1 #> rank[stroke = 1: Low dose aspirin + copidogrel]                 3458     2470    1 #> rank[stroke = 1: Low dose aspirin + dipyridamole]               4561     2944    1 #> rank[stroke = 1: Medium dose aspirin]                           3459     3275    1 #> rank[stroke = 1: Placebo/Standard care]                         4317     3348    1 #> rank[stroke = 1: Triflusal]                                     4182       NA    1 #> rank[stroke = 1: Ximelagatran]                                  2708     1973    1 plot(af_4b_ranks) (af_4b_rankprobs <- posterior_rank_probs(af_fit_4b,                                          newdata = data.frame(stroke = c(0, 1),                                                                label = c(\"stroke = 0\", \"stroke = 1\")),                                           study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.00      0.00      0.01 #> d[stroke = 0: Acenocoumarol]                                  0.26      0.23      0.13 #> d[stroke = 0: Alternate day aspirin]                          0.44      0.15      0.09 #> d[stroke = 0: Dipyridamole]                                   0.00      0.01      0.01 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.00      0.00 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.05      0.09      0.11 #> d[stroke = 0: High dose aspirin]                              0.03      0.06      0.08 #> d[stroke = 0: Indobufen]                                      0.17      0.26      0.20 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.04      0.15      0.21 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.01      0.03      0.07 #> d[stroke = 0: Medium dose aspirin]                            0.00      0.00      0.00 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.00      0.01      0.01 #> d[stroke = 0: Ximelagatran]                                   0.00      0.02      0.05 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.03      0.08      0.15 #> d[stroke = 0: Acenocoumarol]                                  0.09      0.06      0.04 #> d[stroke = 0: Alternate day aspirin]                          0.06      0.05      0.03 #> d[stroke = 0: Dipyridamole]                                   0.02      0.04      0.05 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.00      0.01 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.03      0.04      0.05 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.11      0.10      0.07 #> d[stroke = 0: High dose aspirin]                              0.07      0.07      0.05 #> d[stroke = 0: Indobufen]                                      0.14      0.07      0.04 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.21      0.14      0.08 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.01      0.01      0.02 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.10      0.10      0.10 #> d[stroke = 0: Medium dose aspirin]                            0.02      0.05      0.10 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.02      0.02      0.03 #> d[stroke = 0: Ximelagatran]                                   0.10      0.16      0.17 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.20      0.20      0.17 #> d[stroke = 0: Acenocoumarol]                                  0.03      0.02      0.02 #> d[stroke = 0: Alternate day aspirin]                          0.02      0.02      0.02 #> d[stroke = 0: Dipyridamole]                                   0.05      0.06      0.08 #> d[stroke = 0: Fixed dose warfarin]                            0.01      0.02      0.03 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.05      0.06      0.07 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.06      0.05      0.05 #> d[stroke = 0: High dose aspirin]                              0.05      0.03      0.04 #> d[stroke = 0: Indobufen]                                      0.03      0.02      0.02 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.05      0.04      0.03 #> d[stroke = 0: Low dose aspirin]                               0.00      0.01      0.03 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.03      0.05      0.06 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.10      0.08      0.08 #> d[stroke = 0: Medium dose aspirin]                            0.13      0.17      0.18 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.01 #> d[stroke = 0: Triflusal]                                      0.03      0.03      0.04 #> d[stroke = 0: Ximelagatran]                                   0.14      0.11      0.09 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.10       0.05       0.01 #> d[stroke = 0: Acenocoumarol]                                   0.02       0.02       0.01 #> d[stroke = 0: Alternate day aspirin]                           0.02       0.02       0.01 #> d[stroke = 0: Dipyridamole]                                    0.09       0.09       0.11 #> d[stroke = 0: Fixed dose warfarin]                             0.04       0.05       0.07 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.09       0.10       0.10 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.05       0.04       0.04 #> d[stroke = 0: High dose aspirin]                               0.05       0.05       0.04 #> d[stroke = 0: Indobufen]                                       0.01       0.01       0.01 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.02       0.01       0.01 #> d[stroke = 0: Low dose aspirin]                                0.06       0.11       0.17 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.09       0.12       0.14 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.07       0.07       0.05 #> d[stroke = 0: Medium dose aspirin]                             0.14       0.11       0.06 #> d[stroke = 0: Placebo/Standard care]                           0.02       0.04       0.08 #> d[stroke = 0: Triflusal]                                       0.04       0.06       0.05 #> d[stroke = 0: Ximelagatran]                                    0.06       0.04       0.02 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.01       0.00       0.00 #> d[stroke = 0: Acenocoumarol]                                   0.01       0.01       0.02 #> d[stroke = 0: Alternate day aspirin]                           0.01       0.02       0.02 #> d[stroke = 0: Dipyridamole]                                    0.09       0.08       0.08 #> d[stroke = 0: Fixed dose warfarin]                             0.08       0.10       0.13 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.10       0.09       0.08 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.04       0.04       0.03 #> d[stroke = 0: High dose aspirin]                               0.05       0.05       0.06 #> d[stroke = 0: Indobufen]                                       0.00       0.01       0.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.00       0.00       0.00 #> d[stroke = 0: Low dose aspirin]                                0.22       0.18       0.13 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.13       0.12       0.11 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.04       0.03       0.03 #> d[stroke = 0: Medium dose aspirin]                             0.02       0.01       0.00 #> d[stroke = 0: Placebo/Standard care]                           0.12       0.19       0.23 #> d[stroke = 0: Triflusal]                                       0.05       0.06       0.09 #> d[stroke = 0: Ximelagatran]                                    0.01       0.01       0.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.00       0.00 #> d[stroke = 0: Acenocoumarol]                                   0.01       0.00 #> d[stroke = 0: Alternate day aspirin]                           0.02       0.02 #> d[stroke = 0: Dipyridamole]                                    0.08       0.05 #> d[stroke = 0: Fixed dose warfarin]                             0.20       0.24 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.07       0.04 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.04       0.02 #> d[stroke = 0: High dose aspirin]                               0.08       0.14 #> d[stroke = 0: Indobufen]                                       0.00       0.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.00       0.00 #> d[stroke = 0: Low dose aspirin]                                0.06       0.01 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.07       0.04 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.02       0.01 #> d[stroke = 0: Medium dose aspirin]                             0.00       0.00 #> d[stroke = 0: Placebo/Standard care]                           0.20       0.09 #> d[stroke = 0: Triflusal]                                       0.14       0.32 #> d[stroke = 0: Ximelagatran]                                    0.00       0.00 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.12      0.34 #> d[stroke = 1: Acenocoumarol]                                  0.04      0.02      0.01 #> d[stroke = 1: Alternate day aspirin]                          0.36      0.10      0.05 #> d[stroke = 1: Dipyridamole]                                   0.00      0.00      0.00 #> d[stroke = 1: Fixed dose warfarin]                            0.00      0.01      0.02 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.02      0.03      0.03 #> d[stroke = 1: Indobufen]                                      0.04      0.09      0.11 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.44      0.34      0.11 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.00      0.01      0.01 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.00      0.00 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 1: Triflusal]                                      0.00      0.00      0.01 #> d[stroke = 1: Ximelagatran]                                   0.09      0.26      0.31 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.34      0.14      0.03 #> d[stroke = 1: Acenocoumarol]                                  0.01      0.02      0.02 #> d[stroke = 1: Alternate day aspirin]                          0.06      0.10      0.09 #> d[stroke = 1: Dipyridamole]                                   0.00      0.02      0.04 #> d[stroke = 1: Fixed dose warfarin]                            0.07      0.17      0.24 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.00      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.03      0.06      0.10 #> d[stroke = 1: Indobufen]                                      0.18      0.27      0.15 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.06      0.04      0.01 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.01      0.02 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.03      0.06      0.15 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.01      0.06 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.01 #> d[stroke = 1: Triflusal]                                      0.01      0.01      0.03 #> d[stroke = 1: Ximelagatran]                                   0.20      0.09      0.04 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.00      0.00 #> d[stroke = 1: Acenocoumarol]                                  0.02      0.02      0.01 #> d[stroke = 1: Alternate day aspirin]                          0.06      0.03      0.03 #> d[stroke = 1: Dipyridamole]                                   0.08      0.10      0.11 #> d[stroke = 1: Fixed dose warfarin]                            0.15      0.09      0.07 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.01      0.01      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.01      0.01      0.01 #> d[stroke = 1: High dose aspirin]                              0.10      0.07      0.07 #> d[stroke = 1: Indobufen]                                      0.07      0.04      0.02 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin]                               0.01      0.03      0.06 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.04      0.07      0.09 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.18      0.16      0.11 #> d[stroke = 1: Medium dose aspirin]                            0.18      0.25      0.23 #> d[stroke = 1: Placebo/Standard care]                          0.02      0.06      0.12 #> d[stroke = 1: Triflusal]                                      0.05      0.05      0.06 #> d[stroke = 1: Ximelagatran]                                   0.01      0.00      0.00 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.01       0.01       0.01 #> d[stroke = 1: Alternate day aspirin]                           0.02       0.02       0.02 #> d[stroke = 1: Dipyridamole]                                    0.13       0.12       0.12 #> d[stroke = 1: Fixed dose warfarin]                             0.04       0.04       0.03 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.01       0.01       0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.01       0.01       0.01 #> d[stroke = 1: High dose aspirin]                               0.06       0.06       0.07 #> d[stroke = 1: Indobufen]                                       0.01       0.01       0.01 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.10       0.18       0.24 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.12       0.15       0.16 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.09       0.07       0.05 #> d[stroke = 1: Medium dose aspirin]                             0.14       0.07       0.03 #> d[stroke = 1: Placebo/Standard care]                           0.19       0.19       0.18 #> d[stroke = 1: Triflusal]                                       0.05       0.06       0.08 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00       0.00 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.02       0.04       0.46 #> d[stroke = 1: Alternate day aspirin]                           0.03       0.03       0.01 #> d[stroke = 1: Dipyridamole]                                    0.12       0.09       0.03 #> d[stroke = 1: Fixed dose warfarin]                             0.03       0.02       0.01 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.01       0.02       0.04 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.01       0.02       0.25 #> d[stroke = 1: High dose aspirin]                               0.09       0.14       0.04 #> d[stroke = 1: Indobufen]                                       0.00       0.00       0.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.21       0.11       0.03 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.16       0.11       0.03 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.04       0.02       0.01 #> d[stroke = 1: Medium dose aspirin]                             0.01       0.01       0.00 #> d[stroke = 1: Placebo/Standard care]                           0.14       0.07       0.02 #> d[stroke = 1: Triflusal]                                       0.12       0.32       0.06 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00       0.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.19       0.08 #> d[stroke = 1: Alternate day aspirin]                           0.00       0.00 #> d[stroke = 1: Dipyridamole]                                    0.01       0.01 #> d[stroke = 1: Fixed dose warfarin]                             0.00       0.00 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.18       0.66 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.51       0.16 #> d[stroke = 1: High dose aspirin]                               0.02       0.02 #> d[stroke = 1: Indobufen]                                       0.00       0.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.02       0.01 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.02       0.01 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.00       0.00 #> d[stroke = 1: Medium dose aspirin]                             0.00       0.00 #> d[stroke = 1: Placebo/Standard care]                           0.01       0.00 #> d[stroke = 1: Triflusal]                                       0.03       0.05 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00  # Modify the default output with ggplot2 functionality library(ggplot2) plot(af_4b_rankprobs) +    facet_grid(Treatment~Study, labeller = label_wrap_gen(20)) +    theme(strip.text.y = element_text(angle = 0)) (af_4b_cumrankprobs <- posterior_rank_probs(af_fit_4b, cumulative = TRUE,                                             newdata = data.frame(stroke = c(0, 1),                                                                   label = c(\"stroke = 0\", \"stroke = 1\")),                                              study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.00      0.00      0.01 #> d[stroke = 0: Acenocoumarol]                                  0.26      0.49      0.62 #> d[stroke = 0: Alternate day aspirin]                          0.44      0.59      0.67 #> d[stroke = 0: Dipyridamole]                                   0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.00      0.00 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.05      0.14      0.25 #> d[stroke = 0: High dose aspirin]                              0.03      0.09      0.17 #> d[stroke = 0: Indobufen]                                      0.17      0.43      0.63 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.04      0.18      0.39 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.01      0.04      0.11 #> d[stroke = 0: Medium dose aspirin]                            0.00      0.00      0.01 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.00      0.01      0.02 #> d[stroke = 0: Ximelagatran]                                   0.00      0.02      0.07 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.03      0.11      0.26 #> d[stroke = 0: Acenocoumarol]                                  0.72      0.78      0.82 #> d[stroke = 0: Alternate day aspirin]                          0.73      0.78      0.81 #> d[stroke = 0: Dipyridamole]                                   0.04      0.09      0.14 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.05      0.09      0.14 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.36      0.46      0.53 #> d[stroke = 0: High dose aspirin]                              0.24      0.31      0.36 #> d[stroke = 0: Indobufen]                                      0.77      0.84      0.88 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.60      0.74      0.83 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.01      0.02      0.04 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.21      0.31      0.41 #> d[stroke = 0: Medium dose aspirin]                            0.03      0.08      0.17 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.04      0.07      0.09 #> d[stroke = 0: Ximelagatran]                                   0.17      0.33      0.49 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.46      0.66      0.83 #> d[stroke = 0: Acenocoumarol]                                  0.84      0.87      0.89 #> d[stroke = 0: Alternate day aspirin]                          0.83      0.85      0.86 #> d[stroke = 0: Dipyridamole]                                   0.19      0.25      0.33 #> d[stroke = 0: Fixed dose warfarin]                            0.03      0.05      0.08 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.19      0.25      0.32 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.59      0.64      0.69 #> d[stroke = 0: High dose aspirin]                              0.41      0.44      0.48 #> d[stroke = 0: Indobufen]                                      0.91      0.94      0.95 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.88      0.92      0.95 #> d[stroke = 0: Low dose aspirin]                               0.01      0.02      0.05 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.07      0.12      0.18 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.51      0.59      0.67 #> d[stroke = 0: Medium dose aspirin]                            0.31      0.48      0.66 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.01      0.02 #> d[stroke = 0: Triflusal]                                      0.12      0.15      0.19 #> d[stroke = 0: Ximelagatran]                                   0.64      0.75      0.84 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.93       0.98       0.99 #> d[stroke = 0: Acenocoumarol]                                   0.91       0.93       0.94 #> d[stroke = 0: Alternate day aspirin]                           0.88       0.90       0.91 #> d[stroke = 0: Dipyridamole]                                    0.42       0.51       0.62 #> d[stroke = 0: Fixed dose warfarin]                             0.12       0.17       0.24 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.41       0.51       0.61 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.74       0.79       0.83 #> d[stroke = 0: High dose aspirin]                               0.54       0.59       0.63 #> d[stroke = 0: Indobufen]                                       0.97       0.97       0.98 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.97       0.98       0.99 #> d[stroke = 0: Low dose aspirin]                                0.11       0.22       0.39 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.27       0.39       0.54 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.75       0.82       0.87 #> d[stroke = 0: Medium dose aspirin]                             0.80       0.91       0.97 #> d[stroke = 0: Placebo/Standard care]                           0.05       0.09       0.17 #> d[stroke = 0: Triflusal]                                       0.23       0.29       0.34 #> d[stroke = 0: Ximelagatran]                                    0.90       0.94       0.97 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 0: Acenocoumarol]                                   0.96       0.97       0.99 #> d[stroke = 0: Alternate day aspirin]                           0.92       0.94       0.96 #> d[stroke = 0: Dipyridamole]                                    0.71       0.79       0.87 #> d[stroke = 0: Fixed dose warfarin]                             0.32       0.42       0.55 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.71       0.80       0.88 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.87       0.91       0.94 #> d[stroke = 0: High dose aspirin]                               0.68       0.73       0.78 #> d[stroke = 0: Indobufen]                                       0.99       0.99       1.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 0: Low dose aspirin]                                0.62       0.80       0.92 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.67       0.79       0.89 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.91       0.94       0.97 #> d[stroke = 0: Medium dose aspirin]                             0.99       1.00       1.00 #> d[stroke = 0: Placebo/Standard care]                           0.29       0.48       0.71 #> d[stroke = 0: Triflusal]                                       0.39       0.46       0.55 #> d[stroke = 0: Ximelagatran]                                    0.98       0.99       1.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           1.00          1 #> d[stroke = 0: Acenocoumarol]                                   1.00          1 #> d[stroke = 0: Alternate day aspirin]                           0.98          1 #> d[stroke = 0: Dipyridamole]                                    0.95          1 #> d[stroke = 0: Fixed dose warfarin]                             0.76          1 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.96          1 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.98          1 #> d[stroke = 0: High dose aspirin]                               0.86          1 #> d[stroke = 0: Indobufen]                                       1.00          1 #> d[stroke = 0: Low adjusted dose anti-coagulant]                1.00          1 #> d[stroke = 0: Low dose aspirin]                                0.99          1 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.96          1 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.99          1 #> d[stroke = 0: Medium dose aspirin]                             1.00          1 #> d[stroke = 0: Placebo/Standard care]                           0.91          1 #> d[stroke = 0: Triflusal]                                       0.68          1 #> d[stroke = 0: Ximelagatran]                                    1.00          1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.13      0.47 #> d[stroke = 1: Acenocoumarol]                                  0.04      0.06      0.07 #> d[stroke = 1: Alternate day aspirin]                          0.36      0.46      0.51 #> d[stroke = 1: Dipyridamole]                                   0.00      0.00      0.00 #> d[stroke = 1: Fixed dose warfarin]                            0.00      0.01      0.03 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.02 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.02      0.04      0.07 #> d[stroke = 1: Indobufen]                                      0.04      0.13      0.24 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.44      0.77      0.88 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.00      0.01      0.03 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.00      0.00 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 1: Triflusal]                                      0.00      0.01      0.01 #> d[stroke = 1: Ximelagatran]                                   0.09      0.35      0.66 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.81      0.95      0.98 #> d[stroke = 1: Acenocoumarol]                                  0.08      0.10      0.12 #> d[stroke = 1: Alternate day aspirin]                          0.58      0.67      0.76 #> d[stroke = 1: Dipyridamole]                                   0.01      0.03      0.06 #> d[stroke = 1: Fixed dose warfarin]                            0.10      0.27      0.52 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.02      0.03      0.03 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.01      0.01 #> d[stroke = 1: High dose aspirin]                              0.10      0.16      0.27 #> d[stroke = 1: Indobufen]                                      0.41      0.68      0.83 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.94      0.98      0.99 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.01 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.01      0.04 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.05      0.11      0.26 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.02      0.08 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.01 #> d[stroke = 1: Triflusal]                                      0.02      0.03      0.06 #> d[stroke = 1: Ximelagatran]                                   0.86      0.94      0.98 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          1.00      1.00      1.00 #> d[stroke = 1: Acenocoumarol]                                  0.14      0.15      0.17 #> d[stroke = 1: Alternate day aspirin]                          0.81      0.85      0.87 #> d[stroke = 1: Dipyridamole]                                   0.14      0.24      0.35 #> d[stroke = 1: Fixed dose warfarin]                            0.67      0.76      0.83 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.05      0.06      0.07 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.02      0.02      0.03 #> d[stroke = 1: High dose aspirin]                              0.37      0.44      0.51 #> d[stroke = 1: Indobufen]                                      0.91      0.95      0.96 #> d[stroke = 1: Low adjusted dose anti-coagulant]               1.00      1.00      1.00 #> d[stroke = 1: Low dose aspirin]                               0.01      0.04      0.10 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.08      0.15      0.24 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.44      0.60      0.71 #> d[stroke = 1: Medium dose aspirin]                            0.26      0.51      0.74 #> d[stroke = 1: Placebo/Standard care]                          0.02      0.08      0.20 #> d[stroke = 1: Triflusal]                                      0.11      0.16      0.22 #> d[stroke = 1: Ximelagatran]                                   0.99      1.00      1.00 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 1: Acenocoumarol]                                   0.18       0.20       0.21 #> d[stroke = 1: Alternate day aspirin]                           0.89       0.91       0.93 #> d[stroke = 1: Dipyridamole]                                    0.49       0.61       0.73 #> d[stroke = 1: Fixed dose warfarin]                             0.87       0.91       0.94 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.08       0.08       0.09 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.04       0.05       0.06 #> d[stroke = 1: High dose aspirin]                               0.57       0.63       0.69 #> d[stroke = 1: Indobufen]                                       0.98       0.99       0.99 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 1: Low dose aspirin]                                0.20       0.39       0.62 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.36       0.51       0.68 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.81       0.87       0.92 #> d[stroke = 1: Medium dose aspirin]                             0.88       0.95       0.98 #> d[stroke = 1: Placebo/Standard care]                           0.39       0.58       0.75 #> d[stroke = 1: Triflusal]                                       0.27       0.33       0.41 #> d[stroke = 1: Ximelagatran]                                    1.00       1.00       1.00 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 1: Acenocoumarol]                                   0.23       0.27       0.73 #> d[stroke = 1: Alternate day aspirin]                           0.95       0.98       0.99 #> d[stroke = 1: Dipyridamole]                                    0.86       0.95       0.98 #> d[stroke = 1: Fixed dose warfarin]                             0.97       0.98       0.99 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.10       0.12       0.16 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.06       0.08       0.33 #> d[stroke = 1: High dose aspirin]                               0.79       0.92       0.96 #> d[stroke = 1: Indobufen]                                       1.00       1.00       1.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 1: Low dose aspirin]                                0.84       0.94       0.98 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.84       0.95       0.98 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.96       0.98       0.99 #> d[stroke = 1: Medium dose aspirin]                             0.99       1.00       1.00 #> d[stroke = 1: Placebo/Standard care]                           0.89       0.97       0.99 #> d[stroke = 1: Triflusal]                                       0.53       0.86       0.92 #> d[stroke = 1: Ximelagatran]                                    1.00       1.00       1.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00          1 #> d[stroke = 1: Acenocoumarol]                                   0.92          1 #> d[stroke = 1: Alternate day aspirin]                           1.00          1 #> d[stroke = 1: Dipyridamole]                                    0.99          1 #> d[stroke = 1: Fixed dose warfarin]                             1.00          1 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.34          1 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.84          1 #> d[stroke = 1: High dose aspirin]                               0.98          1 #> d[stroke = 1: Indobufen]                                       1.00          1 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00          1 #> d[stroke = 1: Low dose aspirin]                                0.99          1 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.99          1 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 1.00          1 #> d[stroke = 1: Medium dose aspirin]                             1.00          1 #> d[stroke = 1: Placebo/Standard care]                           1.00          1 #> d[stroke = 1: Triflusal]                                       0.95          1 #> d[stroke = 1: Ximelagatran]                                    1.00          1  plot(af_4b_cumrankprobs) +    facet_grid(Treatment~Study, labeller = label_wrap_gen(20)) +    theme(strip.text.y = element_text(angle = 0))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: Atrial fibrillation","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC slightly lower meta-regression model, although couple points (substantial differences usually considered 3-5 points). estimated heterogeneity standard deviation much lower meta-regression model, suggesting adjusting proportion patients prior stroke explaining heterogeneity data. can also examine residual deviance contributions corresponding plot() method.","code":"(af_dic_1 <- dic(af_fit_1)) #> Residual deviance: 60.4 (on 61 data points) #>                pD: 48.4 #>               DIC: 108.8 (af_dic_4b <- dic(af_fit_4b)) #> Residual deviance: 58.1 (on 61 data points) #>                pD: 47.9 #>               DIC: 106.1 plot(af_dic_1) plot(af_dic_4b)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: BCG vaccine for tuberculosis","text":"data giving number diagnosed TB trial follow-(r) total (n) arm, use function set_agd_arm() set network. set “unvaccinated” network reference treatment. latitude variable bcg_vaccine data frame automatically available use meta-regression model.","code":"bcg_net <- set_agd_arm(bcg_vaccine,                         study = studyn,                        trt = trtc,                        r = r,                         n = n,                        trt_ref = \"Unvaccinated\") bcg_net #> A network with 13 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms               #>  1     2: Unvaccinated | Vaccinated #>  2     2: Unvaccinated | Vaccinated #>  3     2: Unvaccinated | Vaccinated #>  4     2: Unvaccinated | Vaccinated #>  5     2: Unvaccinated | Vaccinated #>  6     2: Unvaccinated | Vaccinated #>  7     2: Unvaccinated | Vaccinated #>  8     2: Unvaccinated | Vaccinated #>  9     2: Unvaccinated | Vaccinated #>  10    2: Unvaccinated | Vaccinated #>  ... plus 3 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 13 #> Reference treatment is: Unvaccinated #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: BCG vaccine for tuberculosis","text":"fit random effects (RE) models, firstly without covariates, meta-regression continuous covariate latitude.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"re-meta-analysis-no-covariate","dir":"Articles","previous_headings":"Meta-analysis models","what":"RE meta-analysis (no covariate)","title":"Example: BCG vaccine for tuberculosis","text":"start fitting standard RE model without covariates. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Vaccine}\\) study-specific intercepts \\(\\mu_j\\), \\(\\textrm{half-N}(0, 5^2)\\) prior distribution heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: model fitted nma() function, random effects model specified trt_effects = \"random\". Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) random effects \\(\\delta_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. bcg_fit_unadj <- nma(bcg_net,                       trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = half_normal(scale = 5)) bcg_fit_unadj #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                    mean se_mean   sd      2.5%       25%       50%       75%     97.5% n_eff #> d[Vaccinated]     -0.77    0.01 0.22     -1.23     -0.90     -0.77     -0.63     -0.36   984 #> lp__          -13533.58    0.15 4.47 -13542.90 -13536.48 -13533.39 -13530.40 -13525.66   931 #> tau                0.69    0.01 0.21      0.39      0.54      0.65      0.79      1.17  1106 #>               Rhat #> d[Vaccinated] 1.00 #> lp__          1.01 #> tau           1.00 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:29:10 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(bcg_fit_unadj, pars = c(\"d\", \"mu\", \"delta\", \"tau\")) plot_prior_posterior(bcg_fit_unadj, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"re-meta-regression-with-covariate-latitude","dir":"Articles","previous_headings":"Meta-analysis models","what":"RE meta-regression with covariate latitude","title":"Example: BCG vaccine for tuberculosis","text":"now fit RE meta-regression model, adjusting latitude. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Vaccine}\\), study-specific intercepts \\(\\mu_j\\), regression coefficient \\(\\beta\\). use \\(\\text{half-N}(0, 5^2)\\) prior distribution heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: , model fitted nma() function. regression formula ~ .trt:latitude means interaction latitude treatment included; .trt special variable indicates treatment, latitude original data set. increase adapt_delta 0.99 remove small number divergent transition errors (default RE models set 0.95). Basic parameter summaries given print() method: Note latitude automatically centered 33.46, mean value studies network. default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. bcg_fit_lat <- nma(bcg_net,                     trt_effects = \"random\",                    regression = ~.trt:latitude,                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_reg = normal(scale = 100),                    prior_het = half_normal(scale = 5),                    adapt_delta = 0.99) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. bcg_fit_lat #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:latitude. #> Centred covariates at the following overall mean values: #> latitude  #> 33.46154  #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                    mean se_mean   sd      2.5%       25%       50%       75% #> beta[.trtVaccinated:latitude]     -0.03    0.00 0.01     -0.05     -0.04     -0.03     -0.03 #> d[Vaccinated]                     -0.76    0.00 0.12     -1.01     -0.82     -0.75     -0.69 #> lp__                          -13542.71    0.18 4.98 -13552.83 -13546.04 -13542.52 -13539.19 #> tau                                0.29    0.01 0.18      0.03      0.16      0.26      0.39 #>                                   97.5% n_eff Rhat #> beta[.trtVaccinated:latitude]     -0.01  1950    1 #> d[Vaccinated]                     -0.53  1974    1 #> lp__                          -13533.59   771    1 #> tau                                0.70   876    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:29:24 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(bcg_fit_lat, pars = c(\"d\", \"beta\", \"mu\", \"delta\", \"tau\")) plot_prior_posterior(bcg_fit_lat, prior = c(\"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: BCG vaccine for tuberculosis","text":"Model fit can checked using dic() function: DIC similar two models, might first choose unadjusted model. posterior mean residual deviance larger model covariate, model also lower effective number parameters \\(p_D\\) allowing shrinkage random treatment effects. Moreover, model covariate much lower estimated heterogeneity standard deviation: Adjusting latitude explaining substantial amount heterogeneity data. 95% Credible Interval regression coefficient also excludes zero:  Altogether, might prefer model adjustment latitude. considering covariates random effects models important just look DIC (Dias et al. 2011). also consider reductions heterogeneity, estimated regression coefficients standard error. DIC sensitive changes heterogeneity, RE models flexible can fit data well whatever level heterogeneity.","code":"(bcg_dic_unadj <- dic(bcg_fit_unadj)) #> Residual deviance: 25.8 (on 26 data points) #>                pD: 23.3 #>               DIC: 49.1 (bcg_dic_lat <- dic(bcg_fit_lat)) #> Residual deviance: 30.7 (on 26 data points) #>                pD: 21.3 #>               DIC: 52.1 summary(bcg_fit_unadj, pars = \"tau\") #>     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau 0.69 0.21 0.39 0.54 0.65 0.79  1.17     1110     1720    1 summary(bcg_fit_lat, pars = \"tau\") #>     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau 0.29 0.18 0.03 0.16 0.26 0.39   0.7      785     1201    1 summary(bcg_fit_lat, pars = \"beta\") #>                                mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> beta[.trtVaccinated:latitude] -0.03 0.01 -0.05 -0.04 -0.03 -0.03 -0.01     2007     2047    1  plot(bcg_fit_lat,       pars = \"beta\",       ref_line = 0,      stat = \"halfeye\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: BCG vaccine for tuberculosis","text":"can produce estimates relative effect vaccination latitude using relative_effects() function. newdata argument specifies data frame containing values covariate latitude interested , study argument used specify column newdata informative label. plot() method may used visually compare estimates:  sophisticated plot shows regression line confidence band effect latitude, overlaid observed log odds ratios study:  presence heterogeneity, argued decision makers consider predictive distribution relative effects new study, instead posterior distribution mean treatment effects, reflects uncertainty due heterogeneity may better represent uncertainty future roll-treatment (see Dias et al. 2011). can produce predictive distributions using predictive_distribution = TRUE argument relative_effects(). Dias et al. (2018, sec. 8.3.2) consider predictive distributions BCG vaccine analysis. unadjusted analysis, whilst substantial evidence vaccination effective average essentially zero probability harm based mean effect, predictive distribution effectiveness new study wide covers range harmful effects: predictive probability new trial showing harmful effect : analysis adjusting latitude, predictive distribution relative effects now depends latitude; calculate increments 10 degrees equator: predictive probabilities new trial carried given latitude showing harmful effect can calculated : predictive probability new trial carried equator shows harmful effect around 80%, whereas 50 degrees latitude predictive probability 0.7%.","code":"bcg_releff_lat <- relative_effects(bcg_fit_lat,                                    newdata = tibble::tibble(latitude = seq(10, 50, by = 10),                                                             label = paste0(latitude, \"\\u00B0 latitude\")),                                    study = label)  bcg_releff_lat #> ----------------------------------------------------------- Study: 10° latitude ----  #>  #> Covariate values: #>  latitude #>        10 #>  #>                              mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[10° latitude: Vaccinated] -0.01 0.21 -0.46 -0.12 0.01 0.11  0.38     1925     1977    1 #>  #> ----------------------------------------------------------- Study: 20° latitude ----  #>  #> Covariate values: #>  latitude #>        20 #>  #>                              mean   sd  2.5%  25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[20° latitude: Vaccinated] -0.33 0.15 -0.65 -0.4 -0.32 -0.24 -0.06     1927     2103    1 #>  #> ----------------------------------------------------------- Study: 30° latitude ----  #>  #> Covariate values: #>  latitude #>        30 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[30° latitude: Vaccinated] -0.65 0.12 -0.91 -0.71 -0.64 -0.58 -0.43     2002     2155    1 #>  #> ----------------------------------------------------------- Study: 40° latitude ----  #>  #> Covariate values: #>  latitude #>        40 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[40° latitude: Vaccinated] -0.97 0.13 -1.25 -1.04 -0.96 -0.89  -0.7     2122     2097    1 #>  #> ----------------------------------------------------------- Study: 50° latitude ----  #>  #> Covariate values: #>  latitude #>        50 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[50° latitude: Vaccinated] -1.28 0.19 -1.66 -1.39 -1.28 -1.18 -0.91     2128     2153    1 plot(bcg_releff_lat,       ref_line = 0) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2)  # Get data for regression line lat_range <- range(bcg_vaccine$latitude) lat_dat <- tibble(latitude = seq(lat_range[1], lat_range[2], by = 1))  bcg_lat_reg <- relative_effects(bcg_fit_lat,                                  newdata = lat_dat) %>%    as_tibble() %>%    bind_cols(lat_dat)  # Get study log odds ratios bcg_lor <- bcg_vaccine %>%    group_by(studyn) %>%    mutate(lor = log(r / (n - r)) - log(first(r) / (first(n) - first(r))),          sample_size = sum(n)) %>%    slice(-1)  # Plot ggplot(aes(x = latitude), data = bcg_lor) +   geom_hline(yintercept = 0, colour = \"grey60\") +   geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), data = bcg_lat_reg,               fill = \"darkred\", alpha = 0.3) +   geom_line(aes(y = mean), data = bcg_lat_reg,             colour = \"darkred\") +   geom_point(aes(y = lor, size = sample_size), alpha = 0.6) +   coord_cartesian(xlim = c(0, 60)) +   xlab(\"Degrees Latitude\") + ylab(\"log Odds Ratio\") +   scale_size(\"Sample Size\") +   theme_multinma() (bcg_predeff_unadj <- relative_effects(bcg_fit_unadj, predictive_distribution = TRUE)) #>                        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> delta_new[Vaccinated] -0.78 0.75 -2.32 -1.22 -0.78 -0.31  0.72     3378     3143    1 mean(as.matrix(bcg_predeff_unadj) > 0) #> [1] 0.128 bcg_predeff_lat <- relative_effects(bcg_fit_lat,                                    newdata = tibble::tibble(latitude = seq(0, 50, by = 10),                                                             label = paste0(latitude, \"\\u00B0 latitude\")),                                    study = label,                                    predictive_distribution = TRUE)  bcg_predeff_lat #> ------------------------------------------------------------ Study: 0° latitude ----  #>  #> Covariate values: #>  latitude #>         0 #>  #>                                    mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> delta_new[0° latitude: Vaccinated]  0.3 0.44 -0.68 0.09 0.33 0.53  1.19     2971     2904    1 #>  #> ----------------------------------------------------------- Study: 10° latitude ----  #>  #> Covariate values: #>  latitude #>        10 #>  #>                                      mean  sd  2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> delta_new[10° latitude: Vaccinated] -0.01 0.4 -0.89 -0.2 0.01 0.19  0.78     3260     3093 #>                                     Rhat #> delta_new[10° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 20° latitude ----  #>  #> Covariate values: #>  latitude #>        20 #>  #>                                      mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[20° latitude: Vaccinated] -0.33 0.37 -1.16 -0.51 -0.31 -0.15   0.4     3556     3350 #>                                     Rhat #> delta_new[20° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 30° latitude ----  #>  #> Covariate values: #>  latitude #>        30 #>  #>                                      mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[30° latitude: Vaccinated] -0.65 0.35 -1.43 -0.82 -0.63 -0.48  0.07     3727     3353 #>                                     Rhat #> delta_new[30° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 40° latitude ----  #>  #> Covariate values: #>  latitude #>        40 #>  #>                                      mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[40° latitude: Vaccinated] -0.97 0.35 -1.73 -1.14 -0.95 -0.79 -0.23     3638     3533 #>                                     Rhat #> delta_new[40° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 50° latitude ----  #>  #> Covariate values: #>  latitude #>        50 #>  #>                                      mean   sd 2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS #> delta_new[50° latitude: Vaccinated] -1.29 0.38 -2.1 -1.47 -1.28 -1.1 -0.52     3313     3132 #>                                     Rhat #> delta_new[50° latitude: Vaccinated]    1 colMeans(as.matrix(bcg_predeff_lat) > 0) #>  delta_new[0° latitude: Vaccinated] delta_new[10° latitude: Vaccinated]  #>                             0.81200                             0.51925  #> delta_new[20° latitude: Vaccinated] delta_new[30° latitude: Vaccinated]  #>                             0.12950                             0.03075  #> delta_new[40° latitude: Vaccinated] delta_new[50° latitude: Vaccinated]  #>                             0.01075                             0.00500"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Beta blockers","text":"begin setting network - just pairwise meta-analysis. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). set “Control” reference treatment.","code":"blocker_net <- set_agd_arm(blocker,                             study = studyn,                            trt = trtc,                            r = r,                             n = n,                            trt_ref = \"Control\") blocker_net #> A network with 22 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms            #>  1     2: Control | Beta Blocker #>  2     2: Control | Beta Blocker #>  3     2: Control | Beta Blocker #>  4     2: Control | Beta Blocker #>  5     2: Control | Beta Blocker #>  6     2: Control | Beta Blocker #>  7     2: Control | Beta Blocker #>  8     2: Control | Beta Blocker #>  9     2: Control | Beta Blocker #>  10    2: Control | Beta Blocker #>  ... plus 12 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 22 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Beta blockers","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Beta blockers","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. blocker_fit_FE <- nma(blocker_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) blocker_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                     mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff Rhat #> d[Beta Blocker]    -0.26    0.00 0.05    -0.36    -0.30    -0.26    -0.23    -0.16  3136    1 #> lp__            -6087.49    0.09 3.42 -6095.16 -6089.59 -6087.10 -6084.98 -6081.87  1564    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:29:46 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(blocker_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(blocker_fit_FE, prior = \"trt\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Beta blockers","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. blocker_fit_RE <- nma(blocker_net,                     trt_effects = \"random\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_het = half_normal(scale = 5)) blocker_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                     mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff Rhat #> d[Beta Blocker]    -0.25    0.00 0.07    -0.37    -0.29    -0.25    -0.21    -0.11  2235    1 #> lp__            -6100.32    0.17 5.68 -6112.33 -6103.91 -6099.95 -6096.32 -6090.04  1107    1 #> tau                 0.14    0.00 0.08     0.01     0.07     0.13     0.19     0.32   910    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:29:55 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(blocker_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(blocker_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Beta blockers","text":"Model fit can checked using dic() function: residual deviance lower RE model, expected model flexible. However, comes increased effective number parameters (note increase \\(p_D\\)). result, DIC models similar FE model may preferred parsimony. can also examine residual deviance contributions corresponding plot() method.   number points well fit FE model, posterior mean residual deviance contributions greater 1. Study 14 particularly poor fit FE model, residual deviance reduced (although still high) RE model. evidence given careful examination, consideration given issues potential effect-modifying covariates (Dias et al. 2011).","code":"(dic_FE <- dic(blocker_fit_FE)) #> Residual deviance: 46.9 (on 44 data points) #>                pD: 23.2 #>               DIC: 70.1 (dic_RE <- dic(blocker_fit_RE)) #> Residual deviance: 41.8 (on 44 data points) #>                pD: 28.4 #>               DIC: 70.2 plot(dic_FE) plot(dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Beta blockers","text":"Dias et al. (2011) produce absolute predictions probability mortality beta blockers control, assuming Normal distribution baseline logit-probability mortality mean \\(-2.2\\) precision \\(3.3\\). can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted probabilities (type = \"link\" produce predicted log odds).   instead information baseline logit-probability mortality event counts, can use construct Beta distribution baseline probability mortality. example, 4 36 individuals died control treatment target population interest, appropriate Beta distribution probability \\(\\textrm{Beta}(4, 36-4)\\). can specify Beta distribution baseline response using baseline_type = \"reponse\" argument (default \"link\", used baseline logit-probability).   Notice results nearly equivalent calculated using Normal distribution baseline logit-probability, since event counts correspond approximately distribution logit-probability.","code":"pred_FE <- predict(blocker_fit_FE,                     baseline = distr(qnorm, mean = -2.2, sd = 3.3^-0.5),                     type = \"response\") pred_FE #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.06 0.03 0.07 0.10 0.14  0.25     3938     3967    1 #> pred[Beta Blocker] 0.09 0.05 0.03 0.06 0.08 0.11  0.21     3945     3847    1 plot(pred_FE) pred_RE <- predict(blocker_fit_RE,                     baseline = distr(qnorm, mean = -2.2, sd = 3.3^-0.5),                     type = \"response\") pred_RE #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.06 0.04 0.07 0.10 0.14  0.25     4315     4084    1 #> pred[Beta Blocker] 0.09 0.05 0.03 0.06 0.08 0.11  0.21     4361     4099    1 plot(pred_RE) pred_FE_beta <- predict(blocker_fit_FE,                          baseline = distr(qbeta, 4, 36-4),                         baseline_type = \"response\",                         type = \"response\") pred_FE_beta #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.03 0.07 0.10 0.14  0.23     3919     4016    1 #> pred[Beta Blocker] 0.09 0.04 0.03 0.06 0.08 0.11  0.19     3935     3972    1 plot(pred_FE_beta) pred_RE_beta <- predict(blocker_fit_RE,                          baseline = distr(qbeta, 4, 36-4),                         baseline_type = \"response\",                         type = \"response\") pred_RE_beta #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.03 0.07 0.10 0.14  0.23     3773     3829    1 #> pred[Beta Blocker] 0.09 0.04 0.03 0.06 0.08 0.11  0.19     3720     3655    1 plot(pred_RE_beta)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Diabetes","text":"begin setting network. arm-level count data giving number new cases diabetes (r) total (n) arm, use function set_agd_arm(). computational efficiency, let “Beta Blocker” set network reference treatment default. Elliott Meyer (2007) Dias et al. (2011) use “Diuretic” reference, simple matter transform results fitting NMA model.1 also details length follow-years trial (time), use offset cloglog link function model data rates. specify function set_agd_arm(): additional columns data (e.g. offsets covariates, column time) automatically made available network. Plot network structure.","code":"db_net <- set_agd_arm(diabetes,                        study = studyc,                       trt = trtc,                       r = r,                        n = n) db_net #> A network with 22 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study  Treatment arms                        #>  AASK   3: Beta Blocker | ACE Inhibitor | CCB #>  ALLHAT 3: ACE Inhibitor | CCB | Diuretic     #>  ALPINE 2: ARB | Diuretic                     #>  ANBP-2 2: ACE Inhibitor | Diuretic           #>  ASCOT  2: Beta Blocker | CCB                 #>  CAPPP  2: Beta Blocker | ACE Inhibitor       #>  CHARM  2: ARB | Placebo                      #>  DREAM  2: ACE Inhibitor | Placebo            #>  EWPH   2: Diuretic | Placebo                 #>  FEVER  2: CCB | Placebo                      #>  ... plus 12 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6 #> Total number of studies: 22 #> Reference treatment is: Beta Blocker #> Network is connected plot(db_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Diabetes","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Diabetes","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. specify cloglog link used link = \"cloglog\" (Binomial likelihood default data), specify log follow-time offset using regression formula regression = ~offset(log(time)). Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. db_fit_FE <- nma(db_net,                   trt_effects = \"fixed\",                  link = \"cloglog\",                  regression = ~offset(log(time)),                  prior_intercept = normal(scale = 100),                  prior_trt = normal(scale = 100)) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. #> Note: Setting \"Beta Blocker\" as the network reference treatment. db_fit_FE #> A fixed effects NMA with a binomial likelihood (cloglog link). #> Regression model: ~offset(log(time)). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                       mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[ACE Inhibitor]     -0.30     0.0 0.05     -0.39     -0.33     -0.30     -0.27     -0.22 #> d[ARB]               -0.40     0.0 0.05     -0.48     -0.43     -0.40     -0.37     -0.31 #> d[CCB]               -0.20     0.0 0.03     -0.26     -0.22     -0.20     -0.18     -0.14 #> d[Diuretic]           0.06     0.0 0.06     -0.05      0.02      0.06      0.09      0.16 #> d[Placebo]           -0.19     0.0 0.05     -0.29     -0.22     -0.19     -0.16     -0.10 #> lp__             -38119.54     0.1 3.70 -38127.71 -38121.82 -38119.19 -38116.90 -38113.27 #>                  n_eff Rhat #> d[ACE Inhibitor]  1448    1 #> d[ARB]            2096    1 #> d[CCB]            1989    1 #> d[Diuretic]       1858    1 #> d[Placebo]        1340    1 #> lp__              1405    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:30:19 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(db_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(db_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Diabetes","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. db_fit_RE <- nma(db_net,                   trt_effects = \"random\",                  link = \"cloglog\",                  regression = ~offset(log(time)),                  prior_intercept = normal(scale = 10),                  prior_trt = normal(scale = 10),                  prior_het = half_normal(scale = 5),                  init_r = 0.5) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. #> Note: Setting \"Beta Blocker\" as the network reference treatment. db_fit_RE #> A random effects NMA with a binomial likelihood (cloglog link). #> Regression model: ~offset(log(time)). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                       mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[ACE Inhibitor]     -0.33    0.00 0.08     -0.49     -0.38     -0.33     -0.28     -0.17 #> d[ARB]               -0.40    0.00 0.10     -0.60     -0.46     -0.40     -0.34     -0.22 #> d[CCB]               -0.17    0.00 0.07     -0.30     -0.21     -0.17     -0.13     -0.03 #> d[Diuretic]           0.07    0.00 0.09     -0.10      0.02      0.07      0.13      0.25 #> d[Placebo]           -0.21    0.00 0.09     -0.40     -0.27     -0.21     -0.15     -0.05 #> lp__             -38070.23    0.21 6.80 -38084.64 -38074.53 -38069.90 -38065.52 -38057.91 #> tau                   0.13    0.00 0.05      0.06      0.10      0.13      0.16      0.23 #>                  n_eff Rhat #> d[ACE Inhibitor]  1707 1.01 #> d[ARB]            1876 1.00 #> d[CCB]            2033 1.00 #> d[Diuretic]       2101 1.00 #> d[Placebo]        1270 1.01 #> lp__              1017 1.00 #> tau                839 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:30:45 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(db_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(db_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Diabetes","text":"Model fit can checked using dic() function: FE model poor fit data, residual deviance much higher number data points. RE model fits data better, much lower DIC; prefer RE model. can also examine residual deviance contributions corresponding plot() method.","code":"(dic_FE <- dic(db_fit_FE)) #> Residual deviance: 78.4 (on 48 data points) #>                pD: 27.2 #>               DIC: 105.5 (dic_RE <- dic(db_fit_RE)) #> Residual deviance: 53.3 (on 48 data points) #>                pD: 38 #>               DIC: 91.3 plot(dic_FE) plot(dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Diabetes","text":"comparison Elliott Meyer (2007) Dias et al. (2011), can produce relative effects “Diuretic” using relative_effects() function trt_ref = \"Diuretic\":   Dias et al. (2011) produce absolute predictions probability developing diabetes three years, assuming Normal distribution baseline cloglog probability developing diabetes diuretic treatment mean \\(-4.2\\) precision \\(1.11\\). can replicate results using predict() method. specify data frame newdata, containing time offset(s) produce predictions (3 years). baseline argument takes distr() distribution object specify corresponding Normal distribution baseline cloglog probability, set trt_ref = \"Diuretic\" indicate baseline distribution corresponds “Diuretic” rather network reference “Beta Blocker”. set type = \"response\" produce predicted event probabilities (type = \"link\" produce predicted cloglog probabilities).   baseline newdata arguments omitted, predicted probabilities produced every study network based follow-times estimated baseline cloglog probabilities \\(\\mu_j\\):  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(db_releff_FE <- relative_effects(db_fit_FE, trt_ref = \"Diuretic\")) #>                   mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Beta Blocker]  -0.06 0.06 -0.16 -0.09 -0.06 -0.02  0.05     1880     2634    1 #> d[ACE Inhibitor] -0.36 0.05 -0.46 -0.39 -0.36 -0.32 -0.26     4305     3183    1 #> d[ARB]           -0.45 0.06 -0.57 -0.49 -0.45 -0.41 -0.33     3544     2749    1 #> d[CCB]           -0.25 0.05 -0.35 -0.29 -0.25 -0.22 -0.14     2985     2949    1 #> d[Placebo]       -0.25 0.06 -0.35 -0.29 -0.25 -0.21 -0.14     3899     3123    1 plot(db_releff_FE, ref_line = 0) (db_releff_RE <- relative_effects(db_fit_RE, trt_ref = \"Diuretic\")) #>                   mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Beta Blocker]  -0.07 0.09 -0.25 -0.13 -0.07 -0.02  0.10     2118     2106    1 #> d[ACE Inhibitor] -0.40 0.09 -0.58 -0.45 -0.40 -0.35 -0.24     4548     3026    1 #> d[ARB]           -0.48 0.11 -0.70 -0.54 -0.47 -0.40 -0.27     3522     3170    1 #> d[CCB]           -0.24 0.08 -0.41 -0.29 -0.24 -0.19 -0.08     4396     3072    1 #> d[Placebo]       -0.29 0.09 -0.48 -0.34 -0.28 -0.23 -0.12     3421     2675    1 plot(db_releff_RE, ref_line = 0) db_pred_FE <- predict(db_fit_FE,                        newdata = data.frame(time = 3),                       baseline = distr(qnorm, mean = -4.2, sd = 1.11^-0.5),                        trt_ref = \"Diuretic\",                       type = \"response\") db_pred_FE #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: Beta Blocker]  0.06 0.06 0.01 0.02 0.04 0.08  0.24     3632     3686    1 #> pred[New 1: ACE Inhibitor] 0.05 0.05 0.00 0.02 0.03 0.06  0.19     3634     3553    1 #> pred[New 1: ARB]           0.04 0.05 0.00 0.02 0.03 0.05  0.17     3652     3607    1 #> pred[New 1: CCB]           0.05 0.05 0.01 0.02 0.04 0.06  0.21     3642     3640    1 #> pred[New 1: Diuretic]      0.07 0.07 0.01 0.02 0.04 0.08  0.26     3624     3684    1 #> pred[New 1: Placebo]       0.05 0.05 0.01 0.02 0.04 0.06  0.21     3639     3643    1 plot(db_pred_FE) db_pred_RE <- predict(db_fit_RE,                        newdata = data.frame(time = 3),                       baseline = distr(qnorm, mean = -4.2, sd = 1.11^-0.5),                        trt_ref = \"Diuretic\",                       type = \"response\") db_pred_RE #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: Beta Blocker]  0.06 0.06 0.01 0.02 0.04 0.08  0.24     3891     3800    1 #> pred[New 1: ACE Inhibitor] 0.04 0.05 0.00 0.02 0.03 0.06  0.18     3921     3735    1 #> pred[New 1: ARB]           0.04 0.04 0.00 0.01 0.03 0.05  0.17     3909     3690    1 #> pred[New 1: CCB]           0.05 0.05 0.01 0.02 0.03 0.07  0.21     3918     3888    1 #> pred[New 1: Diuretic]      0.07 0.07 0.01 0.02 0.04 0.08  0.25     3938     3809    1 #> pred[New 1: Placebo]       0.05 0.05 0.00 0.02 0.03 0.06  0.20     3921     3689    1 plot(db_pred_RE) db_pred_RE_studies <- predict(db_fit_RE, type = \"response\") db_pred_RE_studies #> ------------------------------------------------------------------- Study: AASK ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[AASK: Beta Blocker]  0.17 0.02 0.14 0.16 0.17 0.18  0.20     5150     3173    1 #> pred[AASK: ACE Inhibitor] 0.13 0.01 0.10 0.12 0.12 0.13  0.15     4624     3505    1 #> pred[AASK: ARB]           0.12 0.01 0.09 0.11 0.12 0.13  0.15     4058     3115    1 #> pred[AASK: CCB]           0.15 0.01 0.12 0.13 0.14 0.15  0.18     5402     3452    1 #> pred[AASK: Diuretic]      0.18 0.02 0.15 0.17 0.18 0.19  0.22     4517     3039    1 #> pred[AASK: Placebo]       0.14 0.02 0.11 0.13 0.14 0.15  0.17     3592     3398    1 #>  #> ----------------------------------------------------------------- Study: ALLHAT ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ALLHAT: Beta Blocker]  0.04 0.01 0.03 0.04 0.04 0.05  0.06     2802     2665    1 #> pred[ALLHAT: ACE Inhibitor] 0.03 0.00 0.02 0.03 0.03 0.03  0.04     4223     2998    1 #> pred[ALLHAT: ARB]           0.03 0.00 0.02 0.03 0.03 0.03  0.04     4178     3000    1 #> pred[ALLHAT: CCB]           0.04 0.00 0.03 0.03 0.04 0.04  0.05     4310     2823    1 #> pred[ALLHAT: Diuretic]      0.05 0.01 0.04 0.04 0.05 0.05  0.06     4425     2803    1 #> pred[ALLHAT: Placebo]       0.03 0.00 0.03 0.03 0.03 0.04  0.04     4111     2841    1 #>  #> ----------------------------------------------------------------- Study: ALPINE ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ALPINE: Beta Blocker]  0.03 0.01 0.01 0.02 0.03 0.03  0.05     6375     3293    1 #> pred[ALPINE: ACE Inhibitor] 0.02 0.01 0.01 0.01 0.02 0.02  0.03     6972     3063    1 #> pred[ALPINE: ARB]           0.02 0.01 0.01 0.01 0.02 0.02  0.03     6594     3013    1 #> pred[ALPINE: CCB]           0.02 0.01 0.01 0.02 0.02 0.03  0.04     6877     3102    1 #> pred[ALPINE: Diuretic]      0.03 0.01 0.01 0.02 0.03 0.03  0.05     6941     3116    1 #> pred[ALPINE: Placebo]       0.02 0.01 0.01 0.02 0.02 0.03  0.04     7022     3234    1 #>  #> ----------------------------------------------------------------- Study: ANBP-2 ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ANBP-2: Beta Blocker]  0.07 0.01 0.05 0.06 0.07 0.07  0.09     2864     2484    1 #> pred[ANBP-2: ACE Inhibitor] 0.05 0.01 0.04 0.04 0.05 0.05  0.06     4571     2550    1 #> pred[ANBP-2: ARB]           0.05 0.01 0.03 0.04 0.05 0.05  0.06     4166     2929    1 #> pred[ANBP-2: CCB]           0.06 0.01 0.04 0.05 0.06 0.06  0.07     4459     2947    1 #> pred[ANBP-2: Diuretic]      0.07 0.01 0.05 0.07 0.07 0.08  0.09     4549     2754    1 #> pred[ANBP-2: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     4527     2934    1 #>  #> ------------------------------------------------------------------ Study: ASCOT ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ASCOT: Beta Blocker]  0.11 0.00 0.10 0.11 0.11 0.11  0.12     5347     2975    1 #> pred[ASCOT: ACE Inhibitor] 0.08 0.01 0.07 0.08 0.08 0.09  0.10     2121     2453    1 #> pred[ASCOT: ARB]           0.08 0.01 0.06 0.07 0.08 0.08  0.09     2145     2546    1 #> pred[ASCOT: CCB]           0.10 0.01 0.08 0.09 0.10 0.10  0.11     2380     2462    1 #> pred[ASCOT: Diuretic]      0.12 0.01 0.10 0.11 0.12 0.13  0.14     2295     2485    1 #> pred[ASCOT: Placebo]       0.09 0.01 0.08 0.09 0.09 0.10  0.11     1654     2071    1 #>  #> ------------------------------------------------------------------ Study: CAPPP ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[CAPPP: Beta Blocker]  0.07 0.00 0.07 0.07 0.07 0.08  0.08     5653     3120    1 #> pred[CAPPP: ACE Inhibitor] 0.05 0.00 0.05 0.05 0.05 0.06  0.06     2221     2345    1 #> pred[CAPPP: ARB]           0.05 0.01 0.04 0.05 0.05 0.05  0.06     2315     2736    1 #> pred[CAPPP: CCB]           0.06 0.00 0.05 0.06 0.06 0.07  0.07     3018     2774    1 #> pred[CAPPP: Diuretic]      0.08 0.01 0.07 0.08 0.08 0.08  0.10     2761     3057    1 #> pred[CAPPP: Placebo]       0.06 0.01 0.05 0.06 0.06 0.06  0.07     1775     2459    1 #>  #> ------------------------------------------------------------------ Study: CHARM ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[CHARM: Beta Blocker]  0.09 0.01 0.07 0.08 0.09 0.10  0.12     2455     2403    1 #> pred[CHARM: ACE Inhibitor] 0.07 0.01 0.05 0.06 0.07 0.07  0.09     4091     2812    1 #> pred[CHARM: ARB]           0.06 0.01 0.05 0.06 0.06 0.07  0.08     4220     2535    1 #> pred[CHARM: CCB]           0.08 0.01 0.06 0.07 0.08 0.08  0.10     3798     2337    1 #> pred[CHARM: Diuretic]      0.10 0.02 0.07 0.09 0.10 0.11  0.13     4060     2314    1 #> pred[CHARM: Placebo]       0.07 0.01 0.06 0.07 0.07 0.08  0.10     4305     2536    1 #>  #> ------------------------------------------------------------------ Study: DREAM ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[DREAM: Beta Blocker]  0.23 0.03 0.18 0.21 0.23 0.24  0.29     2738     2210    1 #> pred[DREAM: ACE Inhibitor] 0.17 0.02 0.13 0.16 0.17 0.18  0.22     4364     2731    1 #> pred[DREAM: ARB]           0.16 0.02 0.12 0.14 0.16 0.17  0.21     4239     2770    1 #> pred[DREAM: CCB]           0.20 0.03 0.15 0.18 0.19 0.21  0.25     3846     2737    1 #> pred[DREAM: Diuretic]      0.24 0.03 0.19 0.22 0.24 0.26  0.31     3909     2461    1 #> pred[DREAM: Placebo]       0.19 0.02 0.15 0.17 0.19 0.20  0.24     4470     2638    1 #>  #> ------------------------------------------------------------------- Study: EWPH ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[EWPH: Beta Blocker]  0.06 0.01 0.04 0.05 0.06 0.07  0.09     3544     2667    1 #> pred[EWPH: ACE Inhibitor] 0.05 0.01 0.03 0.04 0.04 0.05  0.07     5465     2628    1 #> pred[EWPH: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     5079     3230    1 #> pred[EWPH: CCB]           0.05 0.01 0.04 0.05 0.05 0.06  0.08     4864     2842    1 #> pred[EWPH: Diuretic]      0.07 0.01 0.05 0.06 0.07 0.07  0.09     5650     2706    1 #> pred[EWPH: Placebo]       0.05 0.01 0.03 0.04 0.05 0.06  0.07     5598     2945    1 #>  #> ------------------------------------------------------------------ Study: FEVER ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[FEVER: Beta Blocker]  0.04 0.01 0.03 0.04 0.04 0.04  0.06     2998     2538    1 #> pred[FEVER: ACE Inhibitor] 0.03 0.00 0.02 0.03 0.03 0.03  0.04     4609     3203    1 #> pred[FEVER: ARB]           0.03 0.00 0.02 0.02 0.03 0.03  0.04     4346     2692    1 #> pred[FEVER: CCB]           0.04 0.00 0.03 0.03 0.03 0.04  0.05     4060     2726    1 #> pred[FEVER: Diuretic]      0.04 0.01 0.03 0.04 0.04 0.05  0.06     4813     3036    1 #> pred[FEVER: Placebo]       0.03 0.00 0.02 0.03 0.03 0.04  0.04     4835     2658    1 #>  #> ----------------------------------------------------------------- Study: HAPPHY ----  #>  #>                             mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[HAPPHY: Beta Blocker]  0.02  0 0.02 0.02 0.02 0.03  0.03     5209     3443    1 #> pred[HAPPHY: ACE Inhibitor] 0.02  0 0.01 0.02 0.02 0.02  0.02     4049     3042    1 #> pred[HAPPHY: ARB]           0.02  0 0.01 0.02 0.02 0.02  0.02     4192     2892    1 #> pred[HAPPHY: CCB]           0.02  0 0.02 0.02 0.02 0.02  0.03     4740     3114    1 #> pred[HAPPHY: Diuretic]      0.03  0 0.02 0.02 0.03 0.03  0.03     3897     3010    1 #> pred[HAPPHY: Placebo]       0.02  0 0.02 0.02 0.02 0.02  0.02     3340     2952    1 #>  #> ------------------------------------------------------------------- Study: HOPE ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[HOPE: Beta Blocker]  0.06 0.01 0.04 0.05 0.06 0.06  0.08     2944     2747    1 #> pred[HOPE: ACE Inhibitor] 0.04 0.01 0.03 0.04 0.04 0.05  0.06     4889     3151    1 #> pred[HOPE: ARB]           0.04 0.01 0.03 0.04 0.04 0.04  0.05     4497     3049    1 #> pred[HOPE: CCB]           0.05 0.01 0.04 0.04 0.05 0.05  0.07     4130     2573    1 #> pred[HOPE: Diuretic]      0.06 0.01 0.05 0.06 0.06 0.07  0.08     4316     2896    1 #> pred[HOPE: Placebo]       0.05 0.01 0.04 0.04 0.05 0.05  0.06     5337     2810    1 #>  #> ---------------------------------------------------------------- Study: INSIGHT ----  #>  #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[INSIGHT: Beta Blocker]  0.06 0.01 0.05 0.06 0.06 0.07  0.09     3155     2612    1 #> pred[INSIGHT: ACE Inhibitor] 0.05 0.01 0.03 0.04 0.05 0.05  0.06     4046     2968    1 #> pred[INSIGHT: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     3945     3110    1 #> pred[INSIGHT: CCB]           0.06 0.01 0.04 0.05 0.05 0.06  0.07     4172     2451    1 #> pred[INSIGHT: Diuretic]      0.07 0.01 0.05 0.06 0.07 0.07  0.09     4375     2726    1 #> pred[INSIGHT: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     3649     2683    1 #>  #> ----------------------------------------------------------------- Study: INVEST ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[INVEST: Beta Blocker]  0.08 0.00 0.08 0.08 0.08 0.08  0.09     7996     2898 1.00 #> pred[INVEST: ACE Inhibitor] 0.06 0.00 0.05 0.06 0.06 0.06  0.07     2098     2547 1.01 #> pred[INVEST: ARB]           0.06 0.01 0.05 0.05 0.06 0.06  0.07     2170     2368 1.00 #> pred[INVEST: CCB]           0.07 0.00 0.06 0.07 0.07 0.07  0.08     2407     2697 1.00 #> pred[INVEST: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.09  0.11     2382     2420 1.00 #> pred[INVEST: Placebo]       0.07 0.01 0.06 0.06 0.07 0.07  0.08     1518     2144 1.00 #>  #> ------------------------------------------------------------------- Study: LIFE ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[LIFE: Beta Blocker]  0.08 0.00 0.07 0.08 0.08 0.08  0.09     7053     2974    1 #> pred[LIFE: ACE Inhibitor] 0.06 0.01 0.05 0.06 0.06 0.06  0.07     2383     2482    1 #> pred[LIFE: ARB]           0.06 0.01 0.05 0.05 0.06 0.06  0.07     2220     2436    1 #> pred[LIFE: CCB]           0.07 0.01 0.06 0.07 0.07 0.07  0.08     3138     2826    1 #> pred[LIFE: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.09  0.11     2890     2801    1 #> pred[LIFE: Placebo]       0.07 0.01 0.05 0.06 0.07 0.07  0.08     1819     2138    1 #>  #> ------------------------------------------------------------------ Study: MRC-E ----  #>  #>                            mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[MRC-E: Beta Blocker]  0.03  0 0.02 0.03 0.03 0.03  0.04     3544     2689    1 #> pred[MRC-E: ACE Inhibitor] 0.02  0 0.02 0.02 0.02 0.02  0.03     4459     3404    1 #> pred[MRC-E: ARB]           0.02  0 0.01 0.02 0.02 0.02  0.03     4450     2855    1 #> pred[MRC-E: CCB]           0.03  0 0.02 0.02 0.02 0.03  0.03     4358     3181    1 #> pred[MRC-E: Diuretic]      0.03  0 0.02 0.03 0.03 0.03  0.04     3858     2892    1 #> pred[MRC-E: Placebo]       0.02  0 0.02 0.02 0.02 0.03  0.03     4321     3208    1 #>  #> ----------------------------------------------------------------- Study: NORDIL ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[NORDIL: Beta Blocker]  0.05 0.00 0.04 0.05 0.05 0.05  0.06     7033     3487    1 #> pred[NORDIL: ACE Inhibitor] 0.04 0.00 0.03 0.03 0.04 0.04  0.04     2824     2298    1 #> pred[NORDIL: ARB]           0.03 0.00 0.03 0.03 0.03 0.04  0.04     2629     2933    1 #> pred[NORDIL: CCB]           0.04 0.00 0.04 0.04 0.04 0.04  0.05     3232     2662    1 #> pred[NORDIL: Diuretic]      0.05 0.01 0.04 0.05 0.05 0.06  0.06     3065     2636    1 #> pred[NORDIL: Placebo]       0.04 0.00 0.03 0.04 0.04 0.04  0.05     2250     2298    1 #>  #> ------------------------------------------------------------------ Study: PEACE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[PEACE: Beta Blocker]  0.14 0.02 0.10 0.13 0.14 0.15  0.18     2360     1958    1 #> pred[PEACE: ACE Inhibitor] 0.10 0.01 0.08 0.09 0.10 0.11  0.13     4112     2327    1 #> pred[PEACE: ARB]           0.09 0.01 0.07 0.09 0.09 0.10  0.12     3826     2758    1 #> pred[PEACE: CCB]           0.12 0.02 0.09 0.11 0.12 0.13  0.15     3490     2551    1 #> pred[PEACE: Diuretic]      0.15 0.02 0.11 0.13 0.15 0.16  0.19     4156     2562    1 #> pred[PEACE: Placebo]       0.11 0.01 0.09 0.10 0.11 0.12  0.14     4576     2816    1 #>  #> ------------------------------------------------------------------ Study: SCOPE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[SCOPE: Beta Blocker]  0.06 0.01 0.05 0.06 0.06 0.07  0.09     2368     2363    1 #> pred[SCOPE: ACE Inhibitor] 0.05 0.01 0.03 0.04 0.05 0.05  0.06     3972     2860    1 #> pred[SCOPE: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     4162     2822    1 #> pred[SCOPE: CCB]           0.06 0.01 0.04 0.05 0.05 0.06  0.07     3501     2896    1 #> pred[SCOPE: Diuretic]      0.07 0.01 0.05 0.06 0.07 0.08  0.09     3487     2901    1 #> pred[SCOPE: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     4053     2957    1 #>  #> ------------------------------------------------------------------- Study: SHEP ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[SHEP: Beta Blocker]  0.09 0.01 0.06 0.08 0.09 0.09  0.12     2844     2522    1 #> pred[SHEP: ACE Inhibitor] 0.06 0.01 0.05 0.06 0.06 0.07  0.08     4578     2891    1 #> pred[SHEP: ARB]           0.06 0.01 0.04 0.05 0.06 0.06  0.08     4432     2666    1 #> pred[SHEP: CCB]           0.07 0.01 0.05 0.07 0.07 0.08  0.10     3917     2798    1 #> pred[SHEP: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.10  0.12     4366     2825    1 #> pred[SHEP: Placebo]       0.07 0.01 0.05 0.06 0.07 0.08  0.09     4908     3126    1 #>  #> ----------------------------------------------------------------- Study: STOP-2 ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[STOP-2: Beta Blocker]  0.05 0.00 0.04 0.05 0.05 0.06  0.06     4242     2833    1 #> pred[STOP-2: ACE Inhibitor] 0.04 0.00 0.03 0.04 0.04 0.04  0.05     2692     1665    1 #> pred[STOP-2: ARB]           0.04 0.00 0.03 0.03 0.04 0.04  0.05     2791     2312    1 #> pred[STOP-2: CCB]           0.05 0.00 0.04 0.04 0.05 0.05  0.05     3752     2744    1 #> pred[STOP-2: Diuretic]      0.06 0.01 0.05 0.05 0.06 0.06  0.07     3543     3008    1 #> pred[STOP-2: Placebo]       0.04 0.00 0.03 0.04 0.04 0.05  0.05     2322     1907    1 #>  #> ------------------------------------------------------------------ Study: VALUE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[VALUE: Beta Blocker]  0.20 0.03 0.15 0.18 0.19 0.21  0.25     2806     2448    1 #> pred[VALUE: ACE Inhibitor] 0.15 0.02 0.11 0.13 0.14 0.16  0.19     4296     2917    1 #> pred[VALUE: ARB]           0.14 0.02 0.10 0.13 0.14 0.15  0.17     4774     2725    1 #> pred[VALUE: CCB]           0.17 0.02 0.13 0.16 0.17 0.18  0.21     4324     2387    1 #> pred[VALUE: Diuretic]      0.21 0.03 0.16 0.19 0.21 0.23  0.28     4201     2789    1 #> pred[VALUE: Placebo]       0.16 0.02 0.12 0.15 0.16 0.17  0.21     4209     2822    1 plot(db_pred_RE_studies) (db_ranks <- posterior_ranks(db_fit_RE)) #>                     mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[Beta Blocker]  5.18 0.42    5   5   5   5     6     2521       NA    1 #> rank[ACE Inhibitor] 1.86 0.54    1   2   2   2     3     3818     3330    1 #> rank[ARB]           1.26 0.50    1   1   1   1     2     3319     2893    1 #> rank[CCB]           3.68 0.54    3   3   4   4     4     4029     3260    1 #> rank[Diuretic]      5.81 0.40    5   6   6   6     6     2756       NA    1 #> rank[Placebo]       3.22 0.60    2   3   3   4     4     3002     2245    1 plot(db_ranks) (db_rankprobs <- posterior_rank_probs(db_fit_RE)) #>                  p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[Beta Blocker]       0.00      0.00      0.00      0.01      0.80      0.19 #> d[ACE Inhibitor]      0.22      0.70      0.07      0.01      0.00      0.00 #> d[ARB]                0.77      0.21      0.02      0.00      0.00      0.00 #> d[CCB]                0.00      0.02      0.28      0.68      0.01      0.00 #> d[Diuretic]           0.00      0.00      0.00      0.00      0.19      0.81 #> d[Placebo]            0.01      0.07      0.62      0.30      0.00      0.00 plot(db_rankprobs) (db_cumrankprobs <- posterior_rank_probs(db_fit_RE, cumulative = TRUE)) #>                  p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[Beta Blocker]       0.00      0.00      0.00      0.01      0.81         1 #> d[ACE Inhibitor]      0.22      0.92      0.99      1.00      1.00         1 #> d[ARB]                0.77      0.98      1.00      1.00      1.00         1 #> d[CCB]                0.00      0.02      0.31      0.99      1.00         1 #> d[Diuretic]           0.00      0.00      0.00      0.00      0.19         1 #> d[Placebo]            0.01      0.08      0.70      1.00      1.00         1 plot(db_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Dietary fat","text":"begin setting network - just pairwise meta-analysis. arm-level rate data giving number deaths (r) person-years risk (E) arm, use function set_agd_arm(). set “Control” reference treatment. also specify optional sample_size argument, although strictly necessary . case sample_size required produce network plot nodes weighted sample size, network plot particularly informative meta-analysis two treatments. (sample_size argument important regression model specified, since also enables automatic centering predictors production predictions studies network, see ?set_agd_arm.)","code":"diet_net <- set_agd_arm(dietary_fat,                          study = studyc,                         trt = trtc,                         r = r,                          E = E,                         trt_ref = \"Control\",                         sample_size = n) diet_net #> A network with 10 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study                   Treatment arms                         #>  DART                    2: Control | Reduced Fat               #>  London Corn/Olive       3: Control | Reduced Fat | Reduced Fat #>  London Low Fat          2: Control | Reduced Fat               #>  Minnesota Coronary      2: Control | Reduced Fat               #>  MRC Soya                2: Control | Reduced Fat               #>  Oslo Diet-Heart         2: Control | Reduced Fat               #>  STARS                   2: Control | Reduced Fat               #>  Sydney Diet-Heart       2: Control | Reduced Fat               #>  Veterans Administration 2: Control | Reduced Fat               #>  Veterans Diet & Skin CA 2: Control | Reduced Fat               #>  #>  Outcome type: rate #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 10 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Dietary fat","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Dietary fat","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Poisson likelihood log link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. diet_fit_FE <- nma(diet_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) diet_fit_FE #> A fixed effects NMA with a poisson likelihood (log link). #> Inference for Stan model: poisson. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Reduced Fat]   -0.01    0.00 0.05   -0.11   -0.04   -0.01    0.03    0.10  2840    1 #> lp__           5325.59    0.05 2.26 5320.27 5324.30 5325.92 5327.24 5328.98  1880    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:31:21 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(diet_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(diet_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Dietary fat","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. diet_fit_RE <- nma(diet_net,                     trt_effects = \"random\",                    prior_intercept = normal(scale = 10),                    prior_trt = normal(scale = 10),                    prior_het = half_normal(scale = 5)) diet_fit_RE #> A random effects NMA with a poisson likelihood (log link). #> Inference for Stan model: poisson. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Reduced Fat]   -0.01    0.00 0.09   -0.18   -0.07   -0.01    0.04    0.17  1674    1 #> lp__           5340.94    0.12 3.86 5332.76 5338.52 5341.24 5343.62 5347.69  1033    1 #> tau               0.14    0.00 0.11    0.01    0.05    0.11    0.19    0.43  1029    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:31:31 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(diet_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(diet_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Dietary fat","text":"Model fit can checked using dic() function: models appear fit data well, residual deviance close number data points. DIC similar models, FE model may preferred parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(dic_FE <- dic(diet_fit_FE)) #> Residual deviance: 22.1 (on 21 data points) #>                pD: 10.9 #>               DIC: 33 (dic_RE <- dic(diet_fit_RE)) #> Residual deviance: 21.2 (on 21 data points) #>                pD: 13.5 #>               DIC: 34.6 plot(dic_FE) plot(dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Dietary fat","text":"Dias et al. (2011) produce absolute predictions mortality rates reduced fat control diets, assuming Normal distribution baseline log rate mortality mean \\(-3\\) precision \\(1.77\\). can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted rates (type = \"link\" produce predicted log rates).   baseline argument omitted, predicted rates produced every study network based estimated baseline log rate \\(\\mu_j\\):","code":"pred_FE <- predict(diet_fit_FE,                     baseline = distr(qnorm, mean = -3, sd = 1.77^-0.5),                     type = \"response\") pred_FE #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]     0.07 0.06 0.01 0.03 0.05 0.08  0.21     3927     3968    1 #> pred[Reduced Fat] 0.07 0.06 0.01 0.03 0.05 0.08  0.21     3930     3926    1 plot(pred_FE) pred_RE <- predict(diet_fit_RE,                     baseline = distr(qnorm, mean = -3, sd = 1.77^-0.5),                     type = \"response\") pred_RE #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]     0.07 0.06 0.01 0.03 0.05 0.08  0.21     3943     3757    1 #> pred[Reduced Fat] 0.07 0.06 0.01 0.03 0.05 0.08  0.21     3900     3773    1 plot(pred_RE) pred_FE_studies <- predict(diet_fit_FE, type = \"response\") pred_FE_studies #> ------------------------------------------------------------------- Study: DART ----  #>  #>                         mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[DART: Control]     0.06  0 0.05 0.06 0.06 0.06  0.07     4537     3237    1 #> pred[DART: Reduced Fat] 0.06  0 0.05 0.06 0.06 0.06  0.07     6633     3527    1 #>  #> ------------------------------------------------------ Study: London Corn/Olive ----  #>  #>                                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[London Corn/Olive: Control]     0.07 0.02 0.03 0.06 0.07 0.09  0.13     5775     2915 #> pred[London Corn/Olive: Reduced Fat] 0.07 0.02 0.03 0.06 0.07 0.09  0.13     6012     2959 #>                                      Rhat #> pred[London Corn/Olive: Control]        1 #> pred[London Corn/Olive: Reduced Fat]    1 #>  #> --------------------------------------------------------- Study: London Low Fat ----  #>  #>                                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[London Low Fat: Control]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     5486     3045    1 #> pred[London Low Fat: Reduced Fat] 0.06 0.01 0.04 0.05 0.06 0.06  0.08     6534     2917    1 #>  #> ----------------------------------------------------- Study: Minnesota Coronary ----  #>  #>                                       mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Minnesota Coronary: Control]     0.05  0 0.05 0.05 0.05 0.06  0.06     4209     3494    1 #> pred[Minnesota Coronary: Reduced Fat] 0.05  0 0.05 0.05 0.05 0.06  0.06     7676     3964    1 #>  #> --------------------------------------------------------------- Study: MRC Soya ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[MRC Soya: Control]     0.04 0.01 0.03 0.04 0.04 0.04  0.05     5758     3106    1 #> pred[MRC Soya: Reduced Fat] 0.04 0.01 0.03 0.04 0.04 0.04  0.05     7170     3360    1 #>  #> -------------------------------------------------------- Study: Oslo Diet-Heart ----  #>  #>                                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Oslo Diet-Heart: Control]     0.06 0.01 0.05 0.06 0.06 0.07  0.08     6144     3229    1 #> pred[Oslo Diet-Heart: Reduced Fat] 0.06 0.01 0.05 0.06 0.06 0.07  0.08     8196     3426    1 #>  #> ------------------------------------------------------------------ Study: STARS ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[STARS: Control]     0.02 0.01 0.01 0.01 0.02 0.03  0.05     5733     2635    1 #> pred[STARS: Reduced Fat] 0.02 0.01 0.01 0.01 0.02 0.03  0.05     5703     2532    1 #>  #> ------------------------------------------------------ Study: Sydney Diet-Heart ----  #>  #>                                      mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Sydney Diet-Heart: Control]     0.03  0 0.03 0.03 0.03 0.04  0.04     6568     3312    1 #> pred[Sydney Diet-Heart: Reduced Fat] 0.03  0 0.03 0.03 0.03 0.04  0.04     7507     3148    1 #>  #> ------------------------------------------------ Study: Veterans Administration ----  #>  #>                                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Veterans Administration: Control]     0.11 0.01  0.1 0.11 0.11 0.12  0.13     4779 #> pred[Veterans Administration: Reduced Fat] 0.11 0.01  0.1 0.11 0.11 0.12  0.13     7560 #>                                            Tail_ESS Rhat #> pred[Veterans Administration: Control]         3217    1 #> pred[Veterans Administration: Reduced Fat]     3268    1 #>  #> ------------------------------------------------ Study: Veterans Diet & Skin CA ----  #>  #>                                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Veterans Diet & Skin CA: Control]     0.01 0.01    0 0.01 0.01 0.02  0.03     6127 #> pred[Veterans Diet & Skin CA: Reduced Fat] 0.01 0.01    0 0.01 0.01 0.02  0.03     6184 #>                                            Tail_ESS Rhat #> pred[Veterans Diet & Skin CA: Control]         3115    1 #> pred[Veterans Diet & Skin CA: Reduced Fat]     3039    1 plot(pred_FE_studies) + ggplot2::facet_grid(Study~., labeller = ggplot2::label_wrap_gen(width = 10))"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Plaque psoriasis HTA report","text":"begin setting network. arm-level ordered multinomial count data, use function set_agd_arm(). function multi() helps us specify ordered outcomes correctly. Plot network structure.","code":"pso_net <- set_agd_arm(hta_psoriasis,                         study = paste(studyc, year),                         trt = trtc,                         r = multi(r0 = sample_size - rowSums(cbind(PASI50, PASI75, PASI90), na.rm = TRUE),                                   PASI50, PASI75, PASI90,                                  inclusive = FALSE,                                   type = \"ordered\")) pso_net #> A network with 16 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                           #>  ACD2058g 2004 2: Supportive care | Efalizumab                          #>  ACD2600g 2004 2: Supportive care | Efalizumab                          #>  Altmeyer 1994 2: Supportive care | Fumaderm                            #>  Chaudari 2001 2: Supportive care | Infliximab                          #>  Elewski 2004  3: Supportive care | Etanercept 25 mg | Etanercept 50 mg #>  Ellis 1991    3: Supportive care | Ciclosporin | Ciclosporin           #>  Gordon 2003   2: Supportive care | Efalizumab                          #>  Gottlieb 2003 2: Supportive care | Etanercept 25 mg                    #>  Gottlieb 2004 3: Supportive care | Infliximab | Infliximab             #>  Guenther 1991 2: Supportive care | Ciclosporin                         #>  ... plus 6 more studies #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 8 #> Total number of studies: 16 #> Reference treatment is: Supportive care #> Network is connected plot(pso_net, weight_edges = TRUE, weight_nodes = TRUE) +    # Nudge the legend over   ggplot2::theme(legend.box.spacing = ggplot2::unit(0.75, \"in\"),                  plot.margin = ggplot2::margin(0.1, 0, 0.1, 0.75, \"in\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Plaque psoriasis HTA report","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Plaque psoriasis HTA report","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\", using probit link function link = \"probit\". use \\(\\mathrm{N}(0, 10^2)\\) prior distributions treatment effects \\(d_k\\), \\(\\mathrm{N}(0, 100^2)\\) prior distributions study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: also need specify prior distributions latent cutpoints \\(c_\\textrm{PASI75}\\) \\(c_\\textrm{PASI90}\\) underlying scale - PASI standardised mean difference due probit link (cutpoint \\(c_\\textrm{PASI50}=0\\)). make easier reason , actually specify priors differences adjacent cutpoints, e.g. \\(c_\\textrm{PASI90} - c_\\textrm{PASI75}\\) \\(c_\\textrm{PASI75} - c_\\textrm{PASI50}\\). can given positive-valued prior distribution, Stan automatically impose necessary ordering constraints behind scenes. choose give implicit flat priors flat(). model fitted using nma() function. Basic parameter summaries given print() method: Note: treatment effects opposite sign TSD 2 (Dias et al. 2011). parameterise linear predictor \\(\\mu_j + d_k + c_m\\), rather \\(\\mu_j + d_k - c_m\\). interpretation thus follows standard binomial probit (logit) regression; SMDs (log ORs) greater zero mean treatment increases probability event compared comparator (less zero mean reduction probability). higher outcomes positive, active treatments estimated increase response (.e. greater reduction) PASI scale compared network reference (supportive care). default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Focusing specifically cutpoints see highly identified data, implicit flat priors work parameters.","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10),                   prior_aux = flat()) #> Note: Setting \"Supportive care\" as the network reference treatment. pso_fit_FE #> A fixed effects NMA with a ordered likelihood (probit link). #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff #> d[Ciclosporin]          1.92    0.01 0.33     1.32     1.70     1.91     2.13     2.63  1416 #> d[Efalizumab]           1.19    0.00 0.06     1.08     1.15     1.19     1.23     1.30  2233 #> d[Etanercept 25 mg]     1.51    0.00 0.10     1.32     1.45     1.51     1.58     1.70  2308 #> d[Etanercept 50 mg]     1.92    0.00 0.10     1.73     1.85     1.92     1.99     2.12  2481 #> d[Fumaderm]             1.47    0.01 0.48     0.63     1.14     1.44     1.76     2.50  2853 #> d[Infliximab]           2.34    0.00 0.27     1.83     2.15     2.33     2.52     2.87  3055 #> d[Methotrexate]         1.62    0.01 0.42     0.80     1.33     1.61     1.90     2.46  1735 #> lp__                -3516.08    0.09 3.55 -3524.10 -3518.24 -3515.74 -3513.59 -3510.19  1661 #> cc[PASI50]              0.00     NaN 0.00     0.00     0.00     0.00     0.00     0.00   NaN #> cc[PASI75]              0.76    0.00 0.03     0.70     0.73     0.76     0.78     0.82  5144 #> cc[PASI90]              1.57    0.00 0.05     1.46     1.53     1.57     1.60     1.66  6330 #>                     Rhat #> d[Ciclosporin]         1 #> d[Efalizumab]          1 #> d[Etanercept 25 mg]    1 #> d[Etanercept 50 mg]    1 #> d[Fumaderm]            1 #> d[Infliximab]          1 #> d[Methotrexate]        1 #> lp__                   1 #> cc[PASI50]           NaN #> cc[PASI75]             1 #> cc[PASI90]             1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:31:59 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_FE, pars = c(\"d\", \"mu\", \"cc\")) plot_prior_posterior(pso_fit_FE) plot_prior_posterior(pso_fit_FE, prior = \"aux\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Plaque psoriasis HTA report","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 10^2)\\) prior distributions treatment effects \\(d_k\\), \\(\\mathrm{N}(0, 100^2)\\) prior distributions study-specific intercepts \\(\\mu_j\\), implicit flat prior distributions latent cutpoints, additionally use \\(\\textrm{half-N}(2.5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 2.5)) #> A half-Normal prior distribution: location = 0, scale = 2.5. #> 50% of the prior density lies between 0 and 1.69. #> 95% of the prior density lies between 0 and 4.9. pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10),                   prior_aux = flat(),                   prior_het = half_normal(scale = 2.5),                   adapt_delta = 0.99) #> Note: Setting \"Supportive care\" as the network reference treatment. pso_fit_RE #> A random effects NMA with a ordered likelihood (probit link). #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=5000; warmup=2500; thin=1;  #> post-warmup draws per chain=2500, total post-warmup draws=10000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff #> d[Ciclosporin]          2.02    0.01 0.42     1.28     1.73     1.99     2.26     2.97  3349 #> d[Efalizumab]           1.19    0.00 0.18     0.81     1.10     1.19     1.27     1.56  4030 #> d[Etanercept 25 mg]     1.52    0.00 0.23     1.03     1.40     1.52     1.64     1.99  4678 #> d[Etanercept 50 mg]     1.92    0.00 0.27     1.34     1.79     1.92     2.05     2.46  4600 #> d[Fumaderm]             1.48    0.01 0.60     0.37     1.08     1.46     1.85     2.74  6822 #> d[Infliximab]           2.31    0.00 0.37     1.57     2.08     2.31     2.54     3.05  6872 #> d[Methotrexate]         1.70    0.01 0.61     0.57     1.30     1.68     2.06     2.97  4556 #> lp__                -3523.54    0.18 6.69 -3537.25 -3527.98 -3523.42 -3518.84 -3511.17  1324 #> tau                     0.30    0.01 0.21     0.02     0.14     0.26     0.42     0.82  1000 #> cc[PASI50]              0.00     NaN 0.00     0.00     0.00     0.00     0.00     0.00   NaN #> cc[PASI75]              0.76    0.00 0.03     0.70     0.74     0.76     0.78     0.82 15453 #> cc[PASI90]              1.56    0.00 0.05     1.46     1.53     1.56     1.60     1.67 18856 #>                     Rhat #> d[Ciclosporin]         1 #> d[Efalizumab]          1 #> d[Etanercept 25 mg]    1 #> d[Etanercept 50 mg]    1 #> d[Fumaderm]            1 #> d[Infliximab]          1 #> d[Methotrexate]        1 #> lp__                   1 #> tau                    1 #> cc[PASI50]           NaN #> cc[PASI75]             1 #> cc[PASI90]             1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:33:49 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_RE, pars = c(\"d\", \"cc\", \"mu\", \"delta\")) plot_prior_posterior(pso_fit_RE, prior = c(\"trt\", \"aux\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Plaque psoriasis HTA report","text":"Model fit can checked using dic() function: random effects model lower DIC residual deviance closer number data points, preferred case. can also examine residual deviance contributions corresponding plot() method.   data points fit well, posterior mean residual deviances close degrees freedom. Meffert 1997 study substantially higher residual deviance contribution, investigated see study appears outlier.","code":"(dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 74.9 (on 58 data points) #>                pD: 25.4 #>               DIC: 100.3 (dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 63.2 (on 58 data points) #>                pD: 33.3 #>               DIC: 96.4 plot(dic_FE) plot(dic_RE)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"predicted-probabilities-of-response","dir":"Articles","previous_headings":"Further results","what":"Predicted probabilities of response","title":"Example: Plaque psoriasis HTA report","text":"Dias et al. (2011) produce absolute predictions probability achieving responses PASI cutoff, assuming Normal distribution baseline probit probability PASI50 response supportive care mean \\(-1.097\\) precision \\(123\\). can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted probabilities (type = \"link\" produce predicted probit probabilities).   instead information baseline PASI 50 response probit probability PASI 50 event counts, can use construct Beta distribution baseline probability PASI 50 response. example, 56 408 individuals achieved PASI 50 response supportive care target population interest, appropriate Beta distribution response probability \\(\\textrm{Beta}(56, 408-56)\\). can specify Beta distribution baseline response using baseline_type = \"reponse\" argument (default \"link\", used baseline probit probability).  (Notice results equivalent calculated using Normal distribution baseline probit probability, since event counts correspond probit probability.) can modify plots using standard ggplot2 functions. example, plot cutpoints together colour coding (instead split facets):  baseline argument omitted, predicted probabilities produced every study network based estimated baseline probit probability \\(\\mu_j\\).","code":"pred_FE <- predict(pso_fit_FE,                     baseline = distr(qnorm, mean = -1.097, sd = 123^-0.5),                     type = \"response\") pred_FE #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.18     3631     3432    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05     3616     3597    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01     3973     3581    1 #> pred[Ciclosporin, PASI50]      0.78 0.09 0.57 0.72 0.79 0.85  0.94     1486     1791    1 #> pred[Ciclosporin, PASI75]      0.53 0.13 0.28 0.44 0.52 0.61  0.79     1529     1844    1 #> pred[Ciclosporin, PASI90]      0.24 0.10 0.08 0.17 0.23 0.30  0.49     1564     1852    1 #> pred[Efalizumab, PASI50]       0.54 0.04 0.45 0.51 0.54 0.57  0.62     3073     3408    1 #> pred[Efalizumab, PASI75]       0.25 0.04 0.19 0.23 0.25 0.28  0.33     3069     3472    1 #> pred[Efalizumab, PASI90]       0.07 0.02 0.04 0.06 0.07 0.08  0.11     3300     3573    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.05 0.56 0.63 0.66 0.69  0.75     2802     3330    1 #> pred[Etanercept 25 mg, PASI75] 0.37 0.05 0.28 0.33 0.37 0.40  0.47     2803     3274    1 #> pred[Etanercept 25 mg, PASI90] 0.13 0.03 0.08 0.11 0.13 0.15  0.19     3018     3307    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.04 0.71 0.77 0.80 0.82  0.86     2996     3419    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.05 0.42 0.49 0.53 0.56  0.63     3013     3513    1 #> pred[Etanercept 50 mg, PASI90] 0.23 0.04 0.16 0.20 0.23 0.26  0.32     3217     3271    1 #> pred[Fumaderm, PASI50]         0.63 0.16 0.31 0.51 0.64 0.75  0.92     3004     2600    1 #> pred[Fumaderm, PASI75]         0.36 0.17 0.11 0.23 0.34 0.46  0.74     3001     2550    1 #> pred[Fumaderm, PASI90]         0.14 0.11 0.02 0.06 0.11 0.19  0.44     3030     2449    1 #> pred[Infliximab, PASI50]       0.88 0.05 0.76 0.85 0.89 0.92  0.97     3175     2659    1 #> pred[Infliximab, PASI75]       0.68 0.10 0.48 0.61 0.68 0.75  0.86     3119     2647    1 #> pred[Infliximab, PASI90]       0.38 0.11 0.19 0.30 0.37 0.44  0.60     3175     2620    1 #> pred[Methotrexate, PASI50]     0.68 0.14 0.37 0.59 0.70 0.79  0.92     1777     2461    1 #> pred[Methotrexate, PASI75]     0.41 0.16 0.14 0.30 0.40 0.52  0.74     1804     2566    1 #> pred[Methotrexate, PASI90]     0.17 0.11 0.03 0.09 0.15 0.23  0.43     1825     2501    1 plot(pred_FE) pred_RE <- predict(pso_fit_RE,                     baseline = distr(qnorm, mean = -1.097, sd = 123^-0.5),                     type = \"response\") pred_RE #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.18     9886     9993    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05    10232     9932    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01    11095     9598    1 #> pred[Ciclosporin, PASI50]      0.80 0.11 0.56 0.73 0.82 0.88  0.97     3733     3514    1 #> pred[Ciclosporin, PASI75]      0.56 0.15 0.27 0.45 0.56 0.66  0.87     3753     3468    1 #> pred[Ciclosporin, PASI90]      0.28 0.14 0.08 0.17 0.25 0.35  0.63     3771     3547    1 #> pred[Efalizumab, PASI50]       0.53 0.08 0.38 0.49 0.54 0.58  0.69     4883     3996    1 #> pred[Efalizumab, PASI75]       0.26 0.06 0.14 0.22 0.25 0.29  0.40     4976     4262    1 #> pred[Efalizumab, PASI90]       0.07 0.03 0.03 0.06 0.07 0.09  0.15     5154     3936    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.09 0.46 0.61 0.66 0.71  0.82     5618     4862    1 #> pred[Etanercept 25 mg, PASI75] 0.37 0.09 0.20 0.32 0.37 0.42  0.56     5673     4992    1 #> pred[Etanercept 25 mg, PASI90] 0.13 0.05 0.05 0.10 0.13 0.16  0.26     5711     4954    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.08 0.59 0.75 0.80 0.84  0.92     5555     3622    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.10 0.30 0.47 0.53 0.59  0.73     5564     3595    1 #> pred[Etanercept 50 mg, PASI90] 0.24 0.08 0.09 0.19 0.23 0.28  0.43     5569     3680    1 #> pred[Fumaderm, PASI50]         0.63 0.19 0.23 0.49 0.64 0.78  0.95     7165     5227    1 #> pred[Fumaderm, PASI75]         0.37 0.20 0.07 0.22 0.34 0.50  0.81     7168     5158    1 #> pred[Fumaderm, PASI90]         0.16 0.14 0.01 0.06 0.11 0.21  0.54     7214     5214    1 #> pred[Infliximab, PASI50]       0.87 0.08 0.67 0.84 0.89 0.93  0.98     7159     5981    1 #> pred[Infliximab, PASI75]       0.67 0.13 0.38 0.59 0.68 0.76  0.89     7177     6101    1 #> pred[Infliximab, PASI90]       0.37 0.13 0.13 0.28 0.36 0.46  0.66     7214     5765    1 #> pred[Methotrexate, PASI50]     0.70 0.18 0.29 0.58 0.72 0.84  0.97     4718     4538    1 #> pred[Methotrexate, PASI75]     0.45 0.21 0.09 0.29 0.43 0.59  0.87     4726     4664    1 #> pred[Methotrexate, PASI90]     0.21 0.16 0.02 0.09 0.16 0.28  0.63     4722     4449    1 plot(pred_RE) pred_FE_beta <- predict(pso_fit_FE,                          baseline = distr(qbeta, 56, 408-56),                         baseline_type = \"response\",                         type = \"response\") pred_FE_beta #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.17     3940     4002    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05     4084     3877    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01     4634     3607    1 #> pred[Ciclosporin, PASI50]      0.78 0.09 0.58 0.72 0.79 0.85  0.94     1485     1664    1 #> pred[Ciclosporin, PASI75]      0.53 0.13 0.29 0.43 0.52 0.61  0.79     1521     1811    1 #> pred[Ciclosporin, PASI90]      0.24 0.10 0.09 0.16 0.22 0.30  0.49     1564     1699    1 #> pred[Efalizumab, PASI50]       0.54 0.04 0.46 0.51 0.54 0.56  0.61     3314     3885    1 #> pred[Efalizumab, PASI75]       0.25 0.03 0.19 0.23 0.25 0.28  0.32     3361     3897    1 #> pred[Efalizumab, PASI90]       0.07 0.02 0.05 0.06 0.07 0.08  0.10     3556     3809    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.04 0.57 0.63 0.66 0.69  0.75     3029     3466    1 #> pred[Etanercept 25 mg, PASI75] 0.37 0.05 0.28 0.34 0.37 0.40  0.46     3107     3621    1 #> pred[Etanercept 25 mg, PASI90] 0.13 0.03 0.08 0.11 0.13 0.14  0.18     3360     3550    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.04 0.72 0.77 0.80 0.82  0.86     3164     3649    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.05 0.43 0.49 0.53 0.56  0.62     3268     3617    1 #> pred[Etanercept 50 mg, PASI90] 0.23 0.04 0.16 0.20 0.23 0.26  0.31     3486     3785    1 #> pred[Fumaderm, PASI50]         0.63 0.16 0.32 0.51 0.64 0.75  0.92     3125     2462    1 #> pred[Fumaderm, PASI75]         0.36 0.17 0.11 0.23 0.34 0.47  0.74     3133     2400    1 #> pred[Fumaderm, PASI90]         0.14 0.11 0.02 0.06 0.11 0.19  0.43     3146     2371    1 #> pred[Infliximab, PASI50]       0.88 0.05 0.76 0.85 0.89 0.92  0.96     3270     2747    1 #> pred[Infliximab, PASI75]       0.68 0.10 0.48 0.61 0.68 0.75  0.85     3225     2690    1 #> pred[Infliximab, PASI90]       0.38 0.11 0.19 0.30 0.37 0.45  0.60     3265     2690    1 #> pred[Methotrexate, PASI50]     0.68 0.14 0.38 0.59 0.70 0.79  0.92     1734     2278    1 #> pred[Methotrexate, PASI75]     0.41 0.16 0.14 0.30 0.40 0.52  0.73     1766     2224    1 #> pred[Methotrexate, PASI90]     0.17 0.11 0.03 0.09 0.15 0.22  0.43     1779     2406    1 plot(pred_FE_beta) pred_RE_beta <- predict(pso_fit_RE,                          baseline = distr(qbeta, 56, 408-56),                         baseline_type = \"response\",                         type = \"response\") pred_RE_beta #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.11 0.13 0.14 0.15  0.17     9843     9606    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05    10409     9721    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01    11568     9176    1 #> pred[Ciclosporin, PASI50]      0.80 0.11 0.57 0.73 0.81 0.88  0.97     3885     3312    1 #> pred[Ciclosporin, PASI75]      0.56 0.15 0.28 0.45 0.55 0.66  0.87     3911     3327    1 #> pred[Ciclosporin, PASI90]      0.28 0.14 0.08 0.17 0.25 0.35  0.63     3930     3380    1 #> pred[Efalizumab, PASI50]       0.53 0.07 0.38 0.49 0.54 0.58  0.69     4725     3842    1 #> pred[Efalizumab, PASI75]       0.26 0.06 0.14 0.22 0.25 0.29  0.40     4853     3687    1 #> pred[Efalizumab, PASI90]       0.07 0.03 0.03 0.06 0.07 0.09  0.14     5086     3711    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.09 0.46 0.61 0.66 0.71  0.82     5176     4267    1 #> pred[Etanercept 25 mg, PASI75] 0.37 0.09 0.20 0.32 0.37 0.42  0.57     5178     4294    1 #> pred[Etanercept 25 mg, PASI90] 0.13 0.05 0.05 0.10 0.13 0.16  0.26     5364     4316    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.08 0.59 0.75 0.80 0.83  0.92     5228     3482    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.10 0.30 0.47 0.53 0.59  0.73     5238     3522    1 #> pred[Etanercept 50 mg, PASI90] 0.24 0.08 0.09 0.19 0.23 0.28  0.43     5242     3596    1 #> pred[Fumaderm, PASI50]         0.63 0.19 0.23 0.49 0.64 0.78  0.95     7183     5265    1 #> pred[Fumaderm, PASI75]         0.37 0.20 0.07 0.22 0.35 0.50  0.82     7183     5084    1 #> pred[Fumaderm, PASI90]         0.16 0.14 0.01 0.06 0.11 0.21  0.54     7238     5207    1 #> pred[Infliximab, PASI50]       0.87 0.08 0.67 0.84 0.89 0.93  0.98     7036     5485    1 #> pred[Infliximab, PASI75]       0.67 0.13 0.37 0.59 0.68 0.75  0.89     7063     5412    1 #> pred[Infliximab, PASI90]       0.37 0.13 0.13 0.28 0.37 0.45  0.66     6942     5407    1 #> pred[Methotrexate, PASI50]     0.70 0.18 0.30 0.58 0.72 0.83  0.97     4826     4663    1 #> pred[Methotrexate, PASI75]     0.45 0.21 0.10 0.29 0.43 0.59  0.87     4834     4774    1 #> pred[Methotrexate, PASI90]     0.20 0.16 0.02 0.09 0.16 0.28  0.63     4828     4635    1 plot(pred_RE_beta) library(ggplot2) plot(pred_RE, position = position_dodge(width = 0.75)) +   facet_null() +   aes(colour = Category) +   scale_colour_brewer(palette = \"Blues\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"ranks-and-rank-probabilities","dir":"Articles","previous_headings":"Further results","what":"Ranks and rank probabilities","title":"Example: Plaque psoriasis HTA report","text":"Treatment rankings, rank probabilities, cumulative rank probabilities can also produced. set lower_better = FALSE since higher outcome categories better (outcomes positive).","code":"(pso_ranks <- posterior_ranks(pso_fit_RE, lower_better = FALSE)) #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[Supportive care]  7.99 0.11    8   8   8   8     8     7122       NA    1 #> rank[Ciclosporin]      2.78 1.27    1   2   3   4     5     6116     6400    1 #> rank[Efalizumab]       6.33 0.82    4   6   7   7     7     5093       NA    1 #> rank[Etanercept 25 mg] 4.95 1.07    3   4   5   6     7     6384       NA    1 #> rank[Etanercept 50 mg] 3.04 1.19    1   2   3   4     5     4949     4192    1 #> rank[Fumaderm]         4.90 1.94    1   3   5   7     7     7331     5583    1 #> rank[Infliximab]       1.77 1.16    1   1   1   2     5     4128     4973    1 #> rank[Methotrexate]     4.25 1.88    1   3   4   6     7     5660     6544    1 plot(pso_ranks) (pso_rankprobs <- posterior_rank_probs(pso_fit_RE, lower_better = FALSE)) #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] #> d[Supportive care]       0.00      0.00      0.00      0.00      0.00      0.00      0.01 #> d[Ciclosporin]           0.16      0.29      0.28      0.17      0.08      0.02      0.00 #> d[Efalizumab]            0.00      0.00      0.01      0.02      0.10      0.36      0.51 #> d[Etanercept 25 mg]      0.00      0.01      0.08      0.20      0.39      0.26      0.05 #> d[Etanercept 50 mg]      0.07      0.31      0.27      0.24      0.08      0.02      0.01 #> d[Fumaderm]              0.07      0.09      0.10      0.12      0.16      0.19      0.27 #> d[Infliximab]            0.60      0.19      0.12      0.06      0.02      0.01      0.00 #> d[Methotrexate]          0.10      0.11      0.15      0.18      0.17      0.14      0.15 #>                     p_rank[8] #> d[Supportive care]       0.99 #> d[Ciclosporin]           0.00 #> d[Efalizumab]            0.00 #> d[Etanercept 25 mg]      0.00 #> d[Etanercept 50 mg]      0.00 #> d[Fumaderm]              0.01 #> d[Infliximab]            0.00 #> d[Methotrexate]          0.00 plot(pso_rankprobs) (pso_cumrankprobs <- posterior_rank_probs(pso_fit_RE, lower_better = FALSE, cumulative = TRUE)) #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] #> d[Supportive care]       0.00      0.00      0.00      0.00      0.00      0.00      0.01 #> d[Ciclosporin]           0.16      0.45      0.73      0.90      0.98      1.00      1.00 #> d[Efalizumab]            0.00      0.00      0.01      0.03      0.13      0.49      1.00 #> d[Etanercept 25 mg]      0.00      0.02      0.09      0.30      0.69      0.95      1.00 #> d[Etanercept 50 mg]      0.07      0.38      0.65      0.89      0.98      0.99      1.00 #> d[Fumaderm]              0.07      0.16      0.26      0.37      0.53      0.72      0.99 #> d[Infliximab]            0.60      0.79      0.90      0.96      0.99      1.00      1.00 #> d[Methotrexate]          0.10      0.21      0.36      0.54      0.71      0.85      1.00 #>                     p_rank[8] #> d[Supportive care]          1 #> d[Ciclosporin]              1 #> d[Efalizumab]               1 #> d[Etanercept 25 mg]         1 #> d[Etanercept 50 mg]         1 #> d[Fumaderm]                 1 #> d[Infliximab]               1 #> d[Methotrexate]             1 plot(pso_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"study-data","dir":"Articles","previous_headings":"","what":"Study data","title":"Example: Newly diagnosed multiple myeloma","text":"First, let us look Kaplan-Meier plots data study:  consider adjustment following covariates: Age Sex ISS stage, -II vs. III Response post-ASCT, complete good partial response vs. lesser response summary distributions characteristics study follows:","code":"kmdat <- bind_rows(ndmm_ipd, ndmm_agd) %>%   group_by(studyf, trtf) %>%   # KM estimate within each study   group_modify(~with(survfit(Surv(eventtime, event = status) ~ 1, data = .),                      tibble(time, n.censor, estimate = surv, std.err, upper, lower))) %>%   # Add S(0) = 1   group_modify(~add_row(., time = 0, n.censor = 0, estimate = 1, std.err = 0, upper = 1, lower = 1, .before = 0)) %>%   arrange(studyf, trtf, time)  ggplot(kmdat, aes(x = time, y = estimate, colour = trtf)) +   geom_step() +   geom_point(shape = 3, data = function(x) filter(x, n.censor >= 1)) +   facet_wrap(~studyf) +   labs(y = \"Survival probability\", x = \"Time\") +   coord_cartesian(ylim = c(0, 1)) +   theme_multinma() +   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\")) bind_rows(   summarise(ndmm_ipd,             N = n(),             age_mean = mean(age), age_sd = sd(age),             iss_stage3 = mean(iss_stage3),             response_cr_vgpr = mean(response_cr_vgpr),             male = mean(male),             .by = c(studyf, trtf)),   transmute(ndmm_agd_covs,             studyf, trtf,             N = sample_size,             age_mean, age_sd, iss_stage3, response_cr_vgpr, male) ) %>%   mutate(across(where(is.double), ~round(., digits = 2))) #>          studyf trtf    N age_mean age_sd iss_stage3 response_cr_vgpr male #> 1  McCarthy2012  Pbo  229    57.39   5.56       0.18             0.71 0.55 #> 2  McCarthy2012  Len  231    57.93   6.33       0.27             0.62 0.52 #> 3     Attal2012  Pbo  307    54.22   5.24       0.16             0.54 0.58 #> 4     Attal2012  Len  307    54.35   6.06       0.24             0.55 0.55 #> 5   Palumbo2014  Pbo  125    54.44   8.98       0.12             0.38 0.63 #> 6   Palumbo2014  Len  126    53.90   9.69       0.10             0.42 0.46 #> 7   Jackson2019  Len 1137    65.17   8.94       0.25             0.83 0.62 #> 8   Jackson2019  Pbo  864    64.63   9.40       0.19             0.83 0.62 #> 9    Morgan2012  Pbo  410    63.92   9.01       0.36             0.72 0.62 #> 10   Morgan2012 Thal  408    65.59   8.38       0.32             0.75 0.62"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"preparing-treatment-classes","dir":"Articles","previous_headings":"Setup","what":"Preparing treatment classes","title":"Example: Newly diagnosed multiple myeloma","text":"start setting network analysis. Since IPD placebo vs. lenalidomide comparison, one AgD study placebo vs. thalidomide comparison, make shared effect modifier assumption two active treatments order estimate effect modifying treatment-covariate interactions thalidomide Phillippo et al. (2020). Since lenalidomide thalidomide class treatments, assumption may reasonable. impose assumption, create treatment class variable active treatments vs. placebo.","code":"ndmm_ipd$trtclass <- case_match(ndmm_ipd$trtf,                                 \"Pbo\" ~ \"Placebo\",                                 c(\"Len\", \"Thal\") ~ \"Active\")  ndmm_agd$trtclass <- case_match(ndmm_agd$trtf,                                 \"Pbo\" ~ \"Placebo\",                                 c(\"Len\", \"Thal\") ~ \"Active\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"Setup","what":"Setting up the network","title":"Example: Newly diagnosed multiple myeloma","text":"set network using set_ipd(), set_agd_surv(), combine_network() functions. Since survival data form event/censoring times censoring indicators, use Surv argument set_*() functions set outcome data using usual survival::Surv() function. AgD set similar fashion IPD, except summary covariate information (data frame ndmm_agd_covs) included using covariates argument. data frame passed covariates must matching study treatment columns outcome data set (ndmm_agd), case studyf trtf respectively, one row per arm, covariate information can matched corresponding arms outcome data. IPD AgD combined single network using combine_network().","code":"ndmm_net <- combine_network(   set_ipd(ndmm_ipd,           study = studyf,           trt = trtf,           trt_class = trtclass,           Surv = Surv(eventtime, status)),   set_agd_surv(ndmm_agd,                study = studyf,                trt = trtf,                trt_class = trtclass,                Surv = Surv(eventtime, status),                covariates = ndmm_agd_covs) )"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"adding-numerical-integration-for-ml-nmr","dir":"Articles","previous_headings":"Setup","what":"Adding numerical integration for ML-NMR","title":"Example: Newly diagnosed multiple myeloma","text":"perform ML-NMR, need create numerical integration points joint covariate distributions AgD study. used integrate (.e. average) individual-level model joint covariate distribution form aggregate-level model. done using add_integration() function, covariate specify marginal distribution using distr() function. Since age skewed, use gamma distribution covariate; remaining covariates binary given Bernoulli distributions. procedure also requires information correlations covariates. known, can specified using cor argument. However, default weighted average correlations IPD studies used.","code":"ndmm_net <- add_integration(ndmm_net,                             age = distr(qgamma, mean = age_mean, sd = age_sd),                             iss_stage3 = distr(qbern, iss_stage3),                             response_cr_vgpr = distr(qbern, response_cr_vgpr),                             male = distr(qbern, male)) #> Using weighted average correlation matrix computed from IPD studies.  ndmm_net #> A network with 3 IPD studies, and 2 AgD studies (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study        Treatment arms #>  Attal2012    2: Pbo | Len   #>  McCarthy2012 2: Pbo | Len   #>  Palumbo2014  2: Pbo | Len   #>  #>  Outcome type: survival #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study       Treatment arms #>  Jackson2019 2: Pbo | Len   #>  Morgan2012  2: Pbo | Thal  #>  #>  Outcome type: survival #> ------------------------------------------------------------------------------------ #> Total number of treatments: 3, in 2 classes #> Total number of studies: 5 #> Reference treatment is: Pbo #> Network is connected #>  #> --------------------------------------------------------- Numerical integration ----  #> Numerical integration points available for 4 covariates:  #>   age iss_stage3 response_cr_vgpr male #> Number of numerical integration points: 64"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"network-plot","dir":"Articles","previous_headings":"Setup","what":"Network plot","title":"Example: Newly diagnosed multiple myeloma","text":"can plot network diagram using plot() method.","code":"plot(ndmm_net,     weight_nodes = TRUE,     weight_edges = TRUE,     # Nudge treatment labels away from nodes     nudge = 0.1,     # Manual layout     layout = data.frame(x = c(0, -1, 1),                         y = c(-0.5, 0, 0))) +   guides(edge_colour = guide_legend(override.aes = list(edge_width = 2))) +   theme(legend.position = \"bottom\", legend.direction = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"ml-nmr-models-with-m-spline-baseline-hazards","dir":"Articles","previous_headings":"","what":"ML-NMR models with M-spline baseline hazards","title":"Example: Newly diagnosed multiple myeloma","text":"fit proportional hazards survival model cubic M-splines baseline hazard Phillippo et al. (n.d.). allows baseline hazard flexibly follow shape baseline hazard may take.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"choosing-the-number-of-knots","dir":"Articles","previous_headings":"ML-NMR models with M-spline baseline hazards","what":"Choosing the number of knots","title":"Example: Newly diagnosed multiple myeloma","text":"ML-NMR models fit using nma() function, specify M-spline baseline hazard used likelihood = \"mspline\". Fitting spline models requires user specify number location knots. default, three internal knots used (n_knots = 3) placed evenly spaced quantiles observed event times within study (.e. 25%, 50%, 75% quantiles 3 internal knots). number knots can changed using n_knots argument, custom knot locations can specified using knots argument. nma() function always place boundary knots earliest entry time study (0 delayed entry) maximum event/censoring time. default, nma() function fit cubic M-spline (mspline_degree = 3). Piecewise-constant hazards (.e. piecewise exponential hazards) special case degree 0 splines, specified using likelihood = \"pexp\" (equivalent mspline_degree = 0). specify regression model using regression argument includes main effects covariates (prognostic effects) treatment-covariate interactions (effect modifier interactions) covariate. place vague \\(\\operatorname{N}(0, 100^2)\\) priors parameters linear predictor, \\(\\operatorname{Dirichlet}(1)\\) prior distribution spline coefficients uniform unit simplex. Using QR decomposition (QR = TRUE) can greatly increase sampling efficiency regression models, also reduce max_treedepth Stan sampler speed warm-time. fit models 1, 2, 3 internal knots, choose number knots using leave-one-information criterion (LOOIC). compare LOOIC, using loo package. model single internal knot median uncensored survival time lowest LOOIC (highest ELPD). Increasing number knots improve overall model fit case. also important check model fit within study, check single study better fit larger number knots washed increased model complexity studies. conclude 1 knot sufficient studies.","code":"ndmm_fit_1kt <- nma(ndmm_net,                     regression = ~(age + iss_stage3 + response_cr_vgpr + male)*.trt,                     likelihood = \"mspline\",                     n_knots = 1,                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_reg = normal(0, 100),                     prior_aux = dirichlet(1),                     QR = TRUE,                     # Reducing max_treedepth can speed up warm-up, but                     # increase if max_treedepth errors occur                     control = list(max_treedepth = 6)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_1kt #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Regression model: ~(age + iss_stage3 + response_cr_vgpr + male) * .trt. #> Centred covariates at the following overall mean values: #>              age       iss_stage3 response_cr_vgpr             male  #>       61.6558571        0.2297184        0.7314265        0.6020451  #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd      2.5%       25%       50% #> beta[age]                                   0.08    0.00 0.01      0.06      0.07      0.08 #> beta[iss_stage3]                            0.36    0.00 0.13      0.09      0.27      0.36 #> beta[response_cr_vgpr]                     -0.14    0.00 0.10     -0.33     -0.20     -0.14 #> beta[male]                                  0.01    0.00 0.10     -0.19     -0.06      0.01 #> beta[age:.trtclassActive]                  -0.02    0.00 0.01     -0.03     -0.02     -0.02 #> beta[iss_stage3:.trtclassActive]            0.20    0.00 0.17     -0.14      0.08      0.20 #> beta[response_cr_vgpr:.trtclassActive]      0.20    0.00 0.14     -0.07      0.10      0.20 #> beta[male:.trtclassActive]                  0.13    0.00 0.15     -0.17      0.03      0.13 #> d[Len]                                     -0.67    0.00 0.05     -0.77     -0.71     -0.67 #> d[Thal]                                    -0.20    0.00 0.11     -0.42     -0.27     -0.20 #> lp__                                   -12422.83    0.12 4.54 -12432.71 -12425.68 -12422.41 #> scoef[Attal2012, 1]                         0.03    0.00 0.01      0.01      0.02      0.03 #> scoef[Attal2012, 2]                         0.18    0.00 0.05      0.07      0.14      0.17 #> scoef[Attal2012, 3]                         0.38    0.00 0.10      0.19      0.32      0.38 #> scoef[Attal2012, 4]                         0.20    0.00 0.09      0.03      0.13      0.19 #> scoef[Attal2012, 5]                         0.22    0.00 0.05      0.13      0.19      0.22 #> scoef[McCarthy2012, 1]                      0.01    0.00 0.01      0.00      0.00      0.00 #> scoef[McCarthy2012, 2]                      0.28    0.00 0.04      0.20      0.25      0.28 #> scoef[McCarthy2012, 3]                      0.17    0.00 0.09      0.02      0.10      0.16 #> scoef[McCarthy2012, 4]                      0.31    0.00 0.11      0.08      0.23      0.31 #> scoef[McCarthy2012, 5]                      0.23    0.00 0.07      0.09      0.18      0.23 #> scoef[Palumbo2014, 1]                       0.01    0.00 0.01      0.00      0.00      0.01 #> scoef[Palumbo2014, 2]                       0.39    0.00 0.07      0.26      0.34      0.39 #> scoef[Palumbo2014, 3]                       0.20    0.00 0.11      0.02      0.12      0.20 #> scoef[Palumbo2014, 4]                       0.18    0.00 0.11      0.01      0.09      0.17 #> scoef[Palumbo2014, 5]                       0.21    0.00 0.08      0.06      0.15      0.21 #> scoef[Jackson2019, 1]                       0.04    0.00 0.01      0.03      0.03      0.04 #> scoef[Jackson2019, 2]                       0.32    0.00 0.03      0.25      0.29      0.32 #> scoef[Jackson2019, 3]                       0.23    0.00 0.06      0.11      0.18      0.23 #> scoef[Jackson2019, 4]                       0.22    0.00 0.07      0.09      0.18      0.22 #> scoef[Jackson2019, 5]                       0.20    0.00 0.04      0.12      0.17      0.20 #> scoef[Morgan2012, 1]                        0.02    0.00 0.01      0.01      0.02      0.02 #> scoef[Morgan2012, 2]                        0.45    0.00 0.04      0.37      0.43      0.45 #> scoef[Morgan2012, 3]                        0.10    0.00 0.07      0.00      0.05      0.09 #> scoef[Morgan2012, 4]                        0.34    0.00 0.08      0.16      0.29      0.35 #> scoef[Morgan2012, 5]                        0.08    0.00 0.05      0.01      0.04      0.08 #>                                              75%     97.5% n_eff Rhat #> beta[age]                                   0.08      0.09  4125 1.00 #> beta[iss_stage3]                            0.45      0.60  8460 1.00 #> beta[response_cr_vgpr]                     -0.07      0.06  7319 1.00 #> beta[male]                                  0.07      0.21  9061 1.00 #> beta[age:.trtclassActive]                  -0.01      0.00  4984 1.00 #> beta[iss_stage3:.trtclassActive]            0.32      0.54 10231 1.00 #> beta[response_cr_vgpr:.trtclassActive]      0.30      0.48  6680 1.00 #> beta[male:.trtclassActive]                  0.23      0.43  6211 1.00 #> d[Len]                                     -0.63     -0.56  4645 1.00 #> d[Thal]                                    -0.13      0.01  4208 1.01 #> lp__                                   -12419.56 -12415.14  1403 1.00 #> scoef[Attal2012, 1]                         0.04      0.06  3835 1.00 #> scoef[Attal2012, 2]                         0.21      0.28  3107 1.00 #> scoef[Attal2012, 3]                         0.45      0.57  2743 1.00 #> scoef[Attal2012, 4]                         0.26      0.39  2986 1.00 #> scoef[Attal2012, 5]                         0.25      0.31  3693 1.00 #> scoef[McCarthy2012, 1]                      0.01      0.02  6817 1.00 #> scoef[McCarthy2012, 2]                      0.31      0.37  3650 1.00 #> scoef[McCarthy2012, 3]                      0.24      0.36  2881 1.00 #> scoef[McCarthy2012, 4]                      0.39      0.52  2946 1.00 #> scoef[McCarthy2012, 5]                      0.28      0.38  3514 1.00 #> scoef[Palumbo2014, 1]                       0.02      0.04  5219 1.00 #> scoef[Palumbo2014, 2]                       0.44      0.53  4516 1.00 #> scoef[Palumbo2014, 3]                       0.27      0.41  3449 1.00 #> scoef[Palumbo2014, 4]                       0.27      0.42  3763 1.00 #> scoef[Palumbo2014, 5]                       0.27      0.38  4682 1.00 #> scoef[Jackson2019, 1]                       0.04      0.05  1789 1.01 #> scoef[Jackson2019, 2]                       0.34      0.38  3085 1.00 #> scoef[Jackson2019, 3]                       0.27      0.35  2521 1.00 #> scoef[Jackson2019, 4]                       0.27      0.35  2601 1.00 #> scoef[Jackson2019, 5]                       0.22      0.27  3485 1.00 #> scoef[Morgan2012, 1]                        0.03      0.04  6058 1.00 #> scoef[Morgan2012, 2]                        0.49      0.54  3772 1.00 #> scoef[Morgan2012, 3]                        0.14      0.26  3793 1.00 #> scoef[Morgan2012, 4]                        0.40      0.48  4936 1.00 #> scoef[Morgan2012, 5]                        0.11      0.18  5093 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Fri Aug 25 18:49:17 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1).  ndmm_fit_2kt <- nma(ndmm_net,                     regression = ~(age + iss_stage3 + response_cr_vgpr + male)*.trt,                     likelihood = \"mspline\",                     n_knots = 2,                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_reg = normal(0, 100),                     prior_aux = dirichlet(1),                     QR = TRUE,                     # Reducing max_treedepth can speed up warm-up, but                     # increase if max_treedepth errors occur                     control = list(max_treedepth = 6)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_2kt #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Regression model: ~(age + iss_stage3 + response_cr_vgpr + male) * .trt. #> Centred covariates at the following overall mean values: #>              age       iss_stage3 response_cr_vgpr             male  #>       61.6558571        0.2297184        0.7314265        0.6020451  #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd      2.5%       25%       50% #> beta[age]                                   0.08    0.00 0.01      0.06      0.07      0.08 #> beta[iss_stage3]                            0.35    0.00 0.13      0.08      0.26      0.35 #> beta[response_cr_vgpr]                     -0.13    0.00 0.10     -0.33     -0.20     -0.13 #> beta[male]                                  0.01    0.00 0.10     -0.20     -0.07      0.01 #> beta[age:.trtclassActive]                  -0.02    0.00 0.01     -0.03     -0.02     -0.02 #> beta[iss_stage3:.trtclassActive]            0.20    0.00 0.18     -0.15      0.07      0.20 #> beta[response_cr_vgpr:.trtclassActive]      0.20    0.00 0.14     -0.07      0.11      0.20 #> beta[male:.trtclassActive]                  0.13    0.00 0.15     -0.16      0.03      0.13 #> d[Len]                                     -0.67    0.00 0.05     -0.77     -0.70     -0.67 #> d[Thal]                                    -0.20    0.00 0.11     -0.40     -0.27     -0.20 #> lp__                                   -12438.01    0.14 4.81 -12448.46 -12441.00 -12437.62 #> scoef[Attal2012, 1]                         0.02    0.00 0.01      0.00      0.01      0.01 #> scoef[Attal2012, 2]                         0.11    0.00 0.03      0.05      0.08      0.11 #> scoef[Attal2012, 3]                         0.21    0.00 0.07      0.08      0.16      0.21 #> scoef[Attal2012, 4]                         0.39    0.00 0.08      0.22      0.34      0.39 #> scoef[Attal2012, 5]                         0.10    0.00 0.06      0.00      0.05      0.09 #> scoef[Attal2012, 6]                         0.19    0.00 0.04      0.11      0.16      0.19 #> scoef[McCarthy2012, 1]                      0.00    0.00 0.00      0.00      0.00      0.00 #> scoef[McCarthy2012, 2]                      0.12    0.00 0.03      0.07      0.10      0.12 #> scoef[McCarthy2012, 3]                      0.20    0.00 0.07      0.07      0.15      0.19 #> scoef[McCarthy2012, 4]                      0.30    0.00 0.09      0.11      0.24      0.30 #> scoef[McCarthy2012, 5]                      0.17    0.00 0.10      0.02      0.09      0.16 #> scoef[McCarthy2012, 6]                      0.21    0.00 0.07      0.07      0.16      0.21 #> scoef[Palumbo2014, 1]                       0.01    0.00 0.01      0.00      0.00      0.00 #> scoef[Palumbo2014, 2]                       0.15    0.00 0.04      0.09      0.12      0.15 #> scoef[Palumbo2014, 3]                       0.27    0.00 0.09      0.10      0.20      0.26 #> scoef[Palumbo2014, 4]                       0.27    0.00 0.11      0.04      0.19      0.27 #> scoef[Palumbo2014, 5]                       0.12    0.00 0.09      0.00      0.05      0.10 #> scoef[Palumbo2014, 6]                       0.19    0.00 0.08      0.05      0.14      0.19 #> scoef[Jackson2019, 1]                       0.02    0.00 0.00      0.01      0.02      0.02 #> scoef[Jackson2019, 2]                       0.11    0.00 0.01      0.08      0.10      0.11 #> scoef[Jackson2019, 3]                       0.29    0.00 0.04      0.21      0.26      0.28 #> scoef[Jackson2019, 4]                       0.23    0.00 0.06      0.12      0.20      0.24 #> scoef[Jackson2019, 5]                       0.18    0.00 0.06      0.07      0.14      0.18 #> scoef[Jackson2019, 6]                       0.16    0.00 0.03      0.10      0.14      0.16 #> scoef[Morgan2012, 1]                        0.01    0.00 0.01      0.00      0.01      0.01 #> scoef[Morgan2012, 2]                        0.13    0.00 0.02      0.09      0.12      0.13 #> scoef[Morgan2012, 3]                        0.37    0.00 0.05      0.26      0.33      0.37 #> scoef[Morgan2012, 4]                        0.15    0.00 0.08      0.01      0.09      0.14 #> scoef[Morgan2012, 5]                        0.28    0.00 0.08      0.12      0.23      0.29 #> scoef[Morgan2012, 6]                        0.06    0.00 0.04      0.00      0.03      0.06 #>                                              75%     97.5% n_eff Rhat #> beta[age]                                   0.08      0.09  4785    1 #> beta[iss_stage3]                            0.44      0.61  9636    1 #> beta[response_cr_vgpr]                     -0.07      0.06  7143    1 #> beta[male]                                  0.08      0.21 11638    1 #> beta[age:.trtclassActive]                  -0.01      0.00  5969    1 #> beta[iss_stage3:.trtclassActive]            0.33      0.55  9439    1 #> beta[response_cr_vgpr:.trtclassActive]      0.29      0.48  6518    1 #> beta[male:.trtclassActive]                  0.23      0.42  9271    1 #> d[Len]                                     -0.63     -0.56  6105    1 #> d[Thal]                                    -0.13      0.01  6436    1 #> lp__                                   -12434.68 -12429.63  1236    1 #> scoef[Attal2012, 1]                         0.02      0.04  3682    1 #> scoef[Attal2012, 2]                         0.13      0.17  2921    1 #> scoef[Attal2012, 3]                         0.25      0.34  2594    1 #> scoef[Attal2012, 4]                         0.44      0.53  2511    1 #> scoef[Attal2012, 5]                         0.14      0.24  3383    1 #> scoef[Attal2012, 6]                         0.21      0.27  4507    1 #> scoef[McCarthy2012, 1]                      0.00      0.01  6677    1 #> scoef[McCarthy2012, 2]                      0.14      0.18  3644    1 #> scoef[McCarthy2012, 3]                      0.24      0.33  2551    1 #> scoef[McCarthy2012, 4]                      0.36      0.47  2414    1 #> scoef[McCarthy2012, 5]                      0.23      0.39  3211    1 #> scoef[McCarthy2012, 6]                      0.26      0.35  4569    1 #> scoef[Palumbo2014, 1]                       0.01      0.02  6325    1 #> scoef[Palumbo2014, 2]                       0.17      0.22  5110    1 #> scoef[Palumbo2014, 3]                       0.33      0.44  3219    1 #> scoef[Palumbo2014, 4]                       0.34      0.48  2887    1 #> scoef[Palumbo2014, 5]                       0.17      0.32  4497    1 #> scoef[Palumbo2014, 6]                       0.25      0.35  5667    1 #> scoef[Jackson2019, 1]                       0.02      0.03  6003    1 #> scoef[Jackson2019, 2]                       0.12      0.14  3181    1 #> scoef[Jackson2019, 3]                       0.31      0.36  3327    1 #> scoef[Jackson2019, 4]                       0.27      0.35  2815    1 #> scoef[Jackson2019, 5]                       0.22      0.30  3409    1 #> scoef[Jackson2019, 6]                       0.19      0.23  4284    1 #> scoef[Morgan2012, 1]                        0.01      0.02  4714    1 #> scoef[Morgan2012, 2]                        0.14      0.17  4716    1 #> scoef[Morgan2012, 3]                        0.40      0.46  3378    1 #> scoef[Morgan2012, 4]                        0.20      0.32  3326    1 #> scoef[Morgan2012, 5]                        0.34      0.42  3824    1 #> scoef[Morgan2012, 6]                        0.09      0.16  4608    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Aug 25 19:38:00 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1).  ndmm_fit_3kt <- nma(ndmm_net,                     regression = ~(age + iss_stage3 + response_cr_vgpr + male)*.trt,                     likelihood = \"mspline\",                     n_knots = 3,                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_reg = normal(0, 100),                     prior_aux = dirichlet(1),                     QR = TRUE,                     # Reducing max_treedepth can speed up warm-up, but                     # increase if max_treedepth errors occur                     control = list(max_treedepth = 6)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_3kt #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Regression model: ~(age + iss_stage3 + response_cr_vgpr + male) * .trt. #> Centred covariates at the following overall mean values: #>              age       iss_stage3 response_cr_vgpr             male  #>       61.6558571        0.2297184        0.7314265        0.6020451  #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd      2.5%       25%       50% #> beta[age]                                   0.08    0.00 0.01      0.06      0.07      0.08 #> beta[iss_stage3]                            0.35    0.00 0.13      0.08      0.26      0.35 #> beta[response_cr_vgpr]                     -0.14    0.00 0.10     -0.33     -0.20     -0.14 #> beta[male]                                  0.01    0.00 0.10     -0.19     -0.06      0.01 #> beta[age:.trtclassActive]                  -0.02    0.00 0.01     -0.03     -0.02     -0.02 #> beta[iss_stage3:.trtclassActive]            0.20    0.00 0.17     -0.13      0.08      0.20 #> beta[response_cr_vgpr:.trtclassActive]      0.20    0.00 0.14     -0.07      0.11      0.20 #> beta[male:.trtclassActive]                  0.13    0.00 0.15     -0.16      0.02      0.13 #> d[Len]                                     -0.67    0.00 0.05     -0.77     -0.70     -0.67 #> d[Thal]                                    -0.19    0.00 0.11     -0.40     -0.27     -0.19 #> lp__                                   -12455.31    0.14 5.25 -12466.37 -12458.71 -12454.92 #> scoef[Attal2012, 1]                         0.01    0.00 0.01      0.00      0.01      0.01 #> scoef[Attal2012, 2]                         0.07    0.00 0.03      0.02      0.05      0.07 #> scoef[Attal2012, 3]                         0.13    0.00 0.04      0.04      0.10      0.13 #> scoef[Attal2012, 4]                         0.29    0.00 0.06      0.17      0.25      0.29 #> scoef[Attal2012, 5]                         0.25    0.00 0.07      0.11      0.20      0.25 #> scoef[Attal2012, 6]                         0.09    0.00 0.06      0.01      0.04      0.08 #> scoef[Attal2012, 7]                         0.16    0.00 0.04      0.09      0.13      0.16 #> scoef[McCarthy2012, 1]                      0.00    0.00 0.00      0.00      0.00      0.00 #> scoef[McCarthy2012, 2]                      0.05    0.00 0.02      0.01      0.04      0.05 #> scoef[McCarthy2012, 3]                      0.18    0.00 0.04      0.10      0.15      0.18 #> scoef[McCarthy2012, 4]                      0.15    0.00 0.06      0.03      0.10      0.15 #> scoef[McCarthy2012, 5]                      0.32    0.00 0.08      0.16      0.26      0.32 #> scoef[McCarthy2012, 6]                      0.10    0.00 0.07      0.00      0.04      0.08 #> scoef[McCarthy2012, 7]                      0.21    0.00 0.07      0.08      0.16      0.21 #> scoef[Palumbo2014, 1]                       0.00    0.00 0.00      0.00      0.00      0.00 #> scoef[Palumbo2014, 2]                       0.08    0.00 0.03      0.03      0.07      0.08 #> scoef[Palumbo2014, 3]                       0.13    0.00 0.05      0.03      0.09      0.13 #> scoef[Palumbo2014, 4]                       0.29    0.00 0.09      0.10      0.23      0.29 #> scoef[Palumbo2014, 5]                       0.19    0.00 0.10      0.02      0.12      0.19 #> scoef[Palumbo2014, 6]                       0.11    0.00 0.08      0.00      0.05      0.10 #> scoef[Palumbo2014, 7]                       0.18    0.00 0.08      0.04      0.12      0.18 #> scoef[Jackson2019, 1]                       0.01    0.00 0.00      0.01      0.01      0.01 #> scoef[Jackson2019, 2]                       0.07    0.00 0.01      0.05      0.06      0.07 #> scoef[Jackson2019, 3]                       0.13    0.00 0.02      0.09      0.11      0.13 #> scoef[Jackson2019, 4]                       0.29    0.00 0.04      0.22      0.26      0.29 #> scoef[Jackson2019, 5]                       0.18    0.00 0.05      0.07      0.14      0.18 #> scoef[Jackson2019, 6]                       0.18    0.00 0.05      0.08      0.15      0.18 #> scoef[Jackson2019, 7]                       0.13    0.00 0.03      0.08      0.11      0.13 #> scoef[Morgan2012, 1]                        0.01    0.00 0.00      0.00      0.00      0.01 #> scoef[Morgan2012, 2]                        0.07    0.00 0.01      0.04      0.06      0.07 #> scoef[Morgan2012, 3]                        0.16    0.00 0.03      0.11      0.14      0.16 #> scoef[Morgan2012, 4]                        0.32    0.00 0.05      0.21      0.28      0.32 #> scoef[Morgan2012, 5]                        0.15    0.00 0.08      0.02      0.10      0.15 #> scoef[Morgan2012, 6]                        0.24    0.00 0.07      0.10      0.20      0.25 #> scoef[Morgan2012, 7]                        0.05    0.00 0.04      0.00      0.02      0.05 #>                                              75%     97.5% n_eff Rhat #> beta[age]                                   0.08      0.09  4506    1 #> beta[iss_stage3]                            0.44      0.61  6426    1 #> beta[response_cr_vgpr]                     -0.07      0.07  7209    1 #> beta[male]                                  0.07      0.21  8857    1 #> beta[age:.trtclassActive]                  -0.01      0.00  5260    1 #> beta[iss_stage3:.trtclassActive]            0.32      0.55  6366    1 #> beta[response_cr_vgpr:.trtclassActive]      0.30      0.48  6422    1 #> beta[male:.trtclassActive]                  0.23      0.42  8144    1 #> d[Len]                                     -0.63     -0.56  5030    1 #> d[Thal]                                    -0.12      0.02  5503    1 #> lp__                                   -12451.50 -12446.12  1382    1 #> scoef[Attal2012, 1]                         0.02      0.03  3352    1 #> scoef[Attal2012, 2]                         0.09      0.12  2388    1 #> scoef[Attal2012, 3]                         0.15      0.21  2194    1 #> scoef[Attal2012, 4]                         0.34      0.42  2340    1 #> scoef[Attal2012, 5]                         0.30      0.37  2473    1 #> scoef[Attal2012, 6]                         0.13      0.22  3104    1 #> scoef[Attal2012, 7]                         0.19      0.24  4230    1 #> scoef[McCarthy2012, 1]                      0.00      0.01  6289    1 #> scoef[McCarthy2012, 2]                      0.06      0.09  2993    1 #> scoef[McCarthy2012, 3]                      0.21      0.26  2593    1 #> scoef[McCarthy2012, 4]                      0.19      0.28  2638    1 #> scoef[McCarthy2012, 5]                      0.37      0.46  2649    1 #> scoef[McCarthy2012, 6]                      0.14      0.27  3040    1 #> scoef[McCarthy2012, 7]                      0.25      0.33  5255    1 #> scoef[Palumbo2014, 1]                       0.01      0.02  6677    1 #> scoef[Palumbo2014, 2]                       0.10      0.14  4492    1 #> scoef[Palumbo2014, 3]                       0.17      0.25  3415    1 #> scoef[Palumbo2014, 4]                       0.36      0.47  2937    1 #> scoef[Palumbo2014, 5]                       0.26      0.40  2979    1 #> scoef[Palumbo2014, 6]                       0.17      0.30  4765    1 #> scoef[Palumbo2014, 7]                       0.23      0.34  5738    1 #> scoef[Jackson2019, 1]                       0.02      0.02  4062    1 #> scoef[Jackson2019, 2]                       0.08      0.09  3391    1 #> scoef[Jackson2019, 3]                       0.14      0.17  2978    1 #> scoef[Jackson2019, 4]                       0.31      0.36  3043    1 #> scoef[Jackson2019, 5]                       0.22      0.28  2885    1 #> scoef[Jackson2019, 6]                       0.22      0.29  3491    1 #> scoef[Jackson2019, 7]                       0.15      0.20  4055    1 #> scoef[Morgan2012, 1]                        0.01      0.02  4940    1 #> scoef[Morgan2012, 2]                        0.08      0.10  3823    1 #> scoef[Morgan2012, 3]                        0.18      0.22  3920    1 #> scoef[Morgan2012, 4]                        0.35      0.42  3178    1 #> scoef[Morgan2012, 5]                        0.20      0.31  2888    1 #> scoef[Morgan2012, 6]                        0.29      0.37  3457    1 #> scoef[Morgan2012, 7]                        0.07      0.13  5032    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Aug 25 20:28:03 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). (ndmm_fit_1kt_loo <- loo(ndmm_fit_1kt)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12385.5 116.2 #> p_loo        31.8   0.8 #> looic     24770.9 232.5 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  (ndmm_fit_2kt_loo <- loo(ndmm_fit_2kt)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12386.1 116.2 #> p_loo        35.9   0.9 #> looic     24772.2 232.4 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  (ndmm_fit_3kt_loo <- loo(ndmm_fit_3kt)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12388.2 116.2 #> p_loo        40.1   0.9 #> looic     24776.3 232.5 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  loo_compare(list(\"1 knot\" = ndmm_fit_1kt_loo,                  \"2 knots\" = ndmm_fit_2kt_loo,                  \"3 knots\" = ndmm_fit_3kt_loo)) #>         elpd_diff se_diff #> 1 knot   0.0       0.0    #> 2 knots -0.7       2.1    #> 3 knots -2.7       2.7 studies_all <- c(ndmm_ipd$study, ndmm_agd$study) cbind(   `1 knot` = by(ndmm_fit_1kt_loo$pointwise[, \"looic\"], studies_all, sum),   `2 knots` = by(ndmm_fit_2kt_loo$pointwise[, \"looic\"], studies_all, sum),   `3 knots` = by(ndmm_fit_3kt_loo$pointwise[, \"looic\"], studies_all, sum) ) #>                 1 knot   2 knots   3 knots #> Attal2012     3342.043  3341.188  3342.966 #> Jackson2019  12394.107 12395.073 12396.222 #> McCarthy2012  2723.239  2724.039  2723.232 #> Morgan2012    4981.445  4981.976  4983.157 #> Palumbo2014   1330.072  1329.954  1330.747"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"ploting-hazards","dir":"Articles","previous_headings":"ML-NMR models with M-spline baseline hazards","what":"Ploting hazards","title":"Example: Newly diagnosed multiple myeloma","text":"Let us look estimated hazard functions model increasing numbers knots. default, predict() function type = \"hazard\" produce plots population-average marginal hazards (level = \"aggregate\", default). can plotted using plot() function. combine plots one grid using patchwork package.  see increasing numbers knots marginal hazards become increasingly “wiggly”, case overfitting. can also look individual-level baseline hazards. possible using predict() function, time level = \"individual\". Since want show baseline hazard reference level covariates, ’ll create data frame pass predict() newdata. Since providing new data frame prediction, also need provide times predict distributions baseline (intercept) auxiliary (spline coefficient) parameters. predict evenly spaced times time 0 last event/censoring time study. specify named list study names baseline aux, use posterior distributions study parameters. produce predictions, plot combine using patchwork.  , see number knots increases baseline hazards get “wiggly”. noted , based LOOIC model 1 internal knot sufficient .","code":"mhp1 <- plot(predict(ndmm_fit_1kt, type = \"hazard\", level = \"aggregate\"))  mhp2 <- plot(predict(ndmm_fit_2kt, type = \"hazard\", level = \"aggregate\"))  mhp3 <- plot(predict(ndmm_fit_3kt, type = \"hazard\", level = \"aggregate\"))  # Combining these into a single plot using patchwork mhp1 + facet_grid(rows = vars(\"1 knot\"), cols = vars(Study)) +   mhp2 + facet_grid(rows = vars(\"2 knots\"), cols = vars(Study)) +   mhp3 + facet_grid(rows = vars(\"3 knots\"), cols = vars(Study)) +   plot_layout(ncol = 1, guides = \"collect\") &   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\")) refdat <- tibble(study = ndmm_net$studies,                  age = ndmm_fit_1kt$xbar[\"age\"],                  iss_stage3 = 0,                  response_cr_vgpr = 0,                  male = 0) # At evenly spaced times between the boundary knots tdat <- purrr::imap_dfr(ndmm_fit_1kt$basis,                         ~tibble(study = factor(.y, levels = ndmm_net$studies),                                 lower = attr(.x, \"Boundary.knots\")[1],                                 upper = attr(.x, \"Boundary.knots\")[2],                                 times = seq(lower, upper, length = 50)))  refdat <- left_join(refdat, tdat, by = \"study\")  studies <- as.list(setNames(nm = levels(ndmm_net$studies))) bhp1 <- plot(predict(ndmm_fit_1kt, type = \"hazard\", level = \"individual\",                     newdata = refdat, study = study, times = times,                     baseline = studies, aux = studies))  bhp2 <- plot(predict(ndmm_fit_2kt, type = \"hazard\", level = \"individual\",                     newdata = refdat, study = study, times = times,                     baseline = studies, aux = studies))  bhp3 <- plot(predict(ndmm_fit_3kt, type = \"hazard\", level = \"individual\",                     newdata = refdat, study = study, times = times,                     baseline = studies, aux = studies))  # Combining these into a single plot using patchwork bhp1 + facet_grid(rows = vars(\"1 knot\"), cols = vars(Study)) +   bhp2 + facet_grid(rows = vars(\"2 knots\"), cols = vars(Study)) +   bhp3 + facet_grid(rows = vars(\"3 knots\"), cols = vars(Study)) +   plot_layout(ncol = 1, guides = \"collect\") &   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"assessing-the-proportional-hazards-assumption","dir":"Articles","previous_headings":"","what":"Assessing the proportional hazards assumption","title":"Example: Newly diagnosed multiple myeloma","text":"can relax assess proportional hazards (PH) assumption allowing spline coefficients vary treatment arms within study. achieved using aux_by argument, aux_by = c(.study, .trt). Technically, aux_by = .study always assumed order respect randomisation (analogous stratifying intercept terms NMA study), simply write aux_by = .trt; choose make stratification study explicit instance. compare model fit models without PH using LOOIC. overall fit proportional hazards model better (substantially). , check single study better fit non-PH model. LOOIC slightly lower non-PH model Jackson2019 Palumbo2014 studies, substantially . studies LOOIC lower PH model. Overall, little evidence suggest proportional hazards assumption invalid .","code":"ndmm_fit_nph <- nma(ndmm_net,                     regression = ~(age + iss_stage3 + response_cr_vgpr + male)*.trt,                     likelihood = \"mspline\",                     n_knots = 1,                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_reg = normal(0, 100),                     prior_aux = dirichlet(1),                     aux_by = c(.study, .trt),                     QR = TRUE,                     # Reducing max_treedepth can speed up warm-up, but                     # increase if max_treedepth errors occur                     control = list(max_treedepth = 6)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nph #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Regression model: ~(age + iss_stage3 + response_cr_vgpr + male) * .trt. #> Centred covariates at the following overall mean values: #>              age       iss_stage3 response_cr_vgpr             male  #>       61.6558571        0.2297184        0.7314265        0.6020451  #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd      2.5%       25%       50% #> beta[age]                                   0.07    0.00 0.01      0.06      0.07      0.07 #> beta[iss_stage3]                            0.33    0.00 0.13      0.07      0.24      0.34 #> beta[response_cr_vgpr]                     -0.11    0.00 0.10     -0.29     -0.17     -0.11 #> beta[male]                                  0.00    0.00 0.10     -0.21     -0.07      0.00 #> beta[age:.trtclassActive]                  -0.01    0.00 0.01     -0.03     -0.02     -0.01 #> beta[iss_stage3:.trtclassActive]            0.24    0.00 0.18     -0.11      0.11      0.24 #> beta[response_cr_vgpr:.trtclassActive]      0.15    0.00 0.14     -0.12      0.06      0.15 #> beta[male:.trtclassActive]                  0.15    0.00 0.15     -0.14      0.05      0.15 #> d[Len]                                     -0.61    0.00 0.07     -0.75     -0.66     -0.61 #> d[Thal]                                    -0.27    0.00 0.13     -0.53     -0.35     -0.27 #> lp__                                   -12473.08    0.16 5.68 -12485.07 -12476.69 -12472.77 #> scoef[Attal2012: Pbo, 1]                    0.03    0.00 0.02      0.01      0.02      0.03 #> scoef[Attal2012: Pbo, 2]                    0.17    0.00 0.07      0.05      0.13      0.17 #> scoef[Attal2012: Pbo, 3]                    0.46    0.00 0.11      0.21      0.39      0.47 #> scoef[Attal2012: Pbo, 4]                    0.15    0.00 0.10      0.01      0.06      0.13 #> scoef[Attal2012: Pbo, 5]                    0.19    0.00 0.06      0.08      0.15      0.19 #> scoef[Attal2012: Len, 1]                    0.03    0.00 0.02      0.00      0.01      0.03 #> scoef[Attal2012: Len, 2]                    0.18    0.00 0.07      0.04      0.13      0.18 #> scoef[Attal2012: Len, 3]                    0.26    0.00 0.13      0.03      0.16      0.25 #> scoef[Attal2012: Len, 4]                    0.31    0.00 0.12      0.07      0.22      0.31 #> scoef[Attal2012: Len, 5]                    0.23    0.00 0.06      0.11      0.18      0.22 #> scoef[McCarthy2012: Pbo, 1]                 0.01    0.00 0.01      0.00      0.00      0.01 #> scoef[McCarthy2012: Pbo, 2]                 0.30    0.00 0.06      0.18      0.26      0.30 #> scoef[McCarthy2012: Pbo, 3]                 0.20    0.00 0.12      0.02      0.11      0.19 #> scoef[McCarthy2012: Pbo, 4]                 0.30    0.00 0.14      0.04      0.20      0.31 #> scoef[McCarthy2012: Pbo, 5]                 0.19    0.00 0.11      0.01      0.10      0.18 #> scoef[McCarthy2012: Len, 1]                 0.01    0.00 0.01      0.00      0.00      0.01 #> scoef[McCarthy2012: Len, 2]                 0.26    0.00 0.06      0.13      0.22      0.26 #> scoef[McCarthy2012: Len, 3]                 0.20    0.00 0.12      0.01      0.11      0.19 #> scoef[McCarthy2012: Len, 4]                 0.30    0.00 0.13      0.04      0.20      0.30 #> scoef[McCarthy2012: Len, 5]                 0.23    0.00 0.08      0.08      0.18      0.23 #> scoef[Palumbo2014: Pbo, 1]                  0.02    0.00 0.02      0.00      0.01      0.02 #> scoef[Palumbo2014: Pbo, 2]                  0.47    0.00 0.09      0.29      0.41      0.47 #> scoef[Palumbo2014: Pbo, 3]                  0.13    0.00 0.09      0.01      0.05      0.11 #> scoef[Palumbo2014: Pbo, 4]                  0.15    0.00 0.10      0.01      0.07      0.13 #> scoef[Palumbo2014: Pbo, 5]                  0.23    0.00 0.10      0.06      0.17      0.23 #> scoef[Palumbo2014: Len, 1]                  0.02    0.00 0.01      0.00      0.00      0.01 #> scoef[Palumbo2014: Len, 2]                  0.23    0.00 0.09      0.07      0.16      0.22 #> scoef[Palumbo2014: Len, 3]                  0.38    0.00 0.16      0.07      0.27      0.38 #> scoef[Palumbo2014: Len, 4]                  0.20    0.00 0.14      0.01      0.08      0.17 #> scoef[Palumbo2014: Len, 5]                  0.18    0.00 0.10      0.02      0.11      0.18 #> scoef[Jackson2019: Pbo, 1]                  0.06    0.00 0.01      0.04      0.05      0.06 #> scoef[Jackson2019: Pbo, 2]                  0.30    0.00 0.05      0.21      0.27      0.30 #> scoef[Jackson2019: Pbo, 3]                  0.26    0.00 0.08      0.10      0.21      0.27 #> scoef[Jackson2019: Pbo, 4]                  0.13    0.00 0.09      0.01      0.06      0.12 #> scoef[Jackson2019: Pbo, 5]                  0.25    0.00 0.06      0.13      0.22      0.26 #> scoef[Jackson2019: Len, 1]                  0.02    0.00 0.01      0.01      0.02      0.02 #> scoef[Jackson2019: Len, 2]                  0.36    0.00 0.04      0.27      0.33      0.36 #> scoef[Jackson2019: Len, 3]                  0.17    0.00 0.08      0.03      0.12      0.17 #> scoef[Jackson2019: Len, 4]                  0.28    0.00 0.08      0.13      0.23      0.28 #> scoef[Jackson2019: Len, 5]                  0.16    0.00 0.04      0.09      0.14      0.16 #> scoef[Morgan2012: Pbo, 1]                   0.03    0.00 0.01      0.01      0.02      0.03 #> scoef[Morgan2012: Pbo, 2]                   0.40    0.00 0.06      0.29      0.36      0.40 #> scoef[Morgan2012: Pbo, 3]                   0.12    0.00 0.08      0.01      0.05      0.10 #> scoef[Morgan2012: Pbo, 4]                   0.30    0.00 0.11      0.08      0.23      0.31 #> scoef[Morgan2012: Pbo, 5]                   0.15    0.00 0.08      0.02      0.09      0.14 #> scoef[Morgan2012: Thal, 1]                  0.02    0.00 0.01      0.00      0.01      0.02 #> scoef[Morgan2012: Thal, 2]                  0.48    0.00 0.06      0.36      0.44      0.48 #> scoef[Morgan2012: Thal, 3]                  0.15    0.00 0.10      0.01      0.08      0.14 #> scoef[Morgan2012: Thal, 4]                  0.28    0.00 0.10      0.06      0.22      0.29 #> scoef[Morgan2012: Thal, 5]                  0.07    0.00 0.05      0.00      0.03      0.06 #>                                              75%     97.5% n_eff Rhat #> beta[age]                                   0.08      0.09  2216 1.00 #> beta[iss_stage3]                            0.42      0.58  6138 1.00 #> beta[response_cr_vgpr]                     -0.04      0.08  5661 1.00 #> beta[male]                                  0.06      0.19  6871 1.00 #> beta[age:.trtclassActive]                  -0.01      0.01  2534 1.00 #> beta[iss_stage3:.trtclassActive]            0.36      0.59  5870 1.00 #> beta[response_cr_vgpr:.trtclassActive]      0.25      0.43  5511 1.00 #> beta[male:.trtclassActive]                  0.25      0.45  5021 1.00 #> d[Len]                                     -0.57     -0.48  3125 1.00 #> d[Thal]                                    -0.18     -0.02  3754 1.00 #> lp__                                   -12469.06 -12462.95  1240 1.00 #> scoef[Attal2012: Pbo, 1]                    0.04      0.07  3057 1.00 #> scoef[Attal2012: Pbo, 2]                    0.22      0.31  2162 1.00 #> scoef[Attal2012: Pbo, 3]                    0.54      0.65  2063 1.00 #> scoef[Attal2012: Pbo, 4]                    0.21      0.37  2671 1.00 #> scoef[Attal2012: Pbo, 5]                    0.23      0.31  4213 1.00 #> scoef[Attal2012: Len, 1]                    0.04      0.08  3132 1.00 #> scoef[Attal2012: Len, 2]                    0.23      0.32  2367 1.00 #> scoef[Attal2012: Len, 3]                    0.35      0.52  2260 1.00 #> scoef[Attal2012: Len, 4]                    0.40      0.54  2831 1.00 #> scoef[Attal2012: Len, 5]                    0.27      0.36  3702 1.00 #> scoef[McCarthy2012: Pbo, 1]                 0.01      0.03  5235 1.00 #> scoef[McCarthy2012: Pbo, 2]                 0.34      0.42  3670 1.00 #> scoef[McCarthy2012: Pbo, 3]                 0.28      0.45  3512 1.00 #> scoef[McCarthy2012: Pbo, 4]                 0.41      0.56  3277 1.00 #> scoef[McCarthy2012: Pbo, 5]                 0.27      0.41  3494 1.00 #> scoef[McCarthy2012: Len, 1]                 0.02      0.04  4684 1.00 #> scoef[McCarthy2012: Len, 2]                 0.30      0.38  3049 1.00 #> scoef[McCarthy2012: Len, 3]                 0.28      0.45  2374 1.00 #> scoef[McCarthy2012: Len, 4]                 0.40      0.55  3123 1.00 #> scoef[McCarthy2012: Len, 5]                 0.29      0.39  4068 1.00 #> scoef[Palumbo2014: Pbo, 1]                  0.03      0.07  4681 1.00 #> scoef[Palumbo2014: Pbo, 2]                  0.53      0.64  3988 1.00 #> scoef[Palumbo2014: Pbo, 3]                  0.18      0.34  4258 1.00 #> scoef[Palumbo2014: Pbo, 4]                  0.21      0.38  5324 1.00 #> scoef[Palumbo2014: Pbo, 5]                  0.30      0.42  5781 1.00 #> scoef[Palumbo2014: Len, 1]                  0.02      0.05  5708 1.00 #> scoef[Palumbo2014: Len, 2]                  0.29      0.41  3657 1.00 #> scoef[Palumbo2014: Len, 3]                  0.49      0.67  3305 1.00 #> scoef[Palumbo2014: Len, 4]                  0.29      0.52  3535 1.00 #> scoef[Palumbo2014: Len, 5]                  0.25      0.39  5333 1.00 #> scoef[Jackson2019: Pbo, 1]                  0.06      0.08  2324 1.01 #> scoef[Jackson2019: Pbo, 2]                  0.33      0.40  2500 1.00 #> scoef[Jackson2019: Pbo, 3]                  0.32      0.41  2483 1.00 #> scoef[Jackson2019: Pbo, 4]                  0.18      0.33  2635 1.00 #> scoef[Jackson2019: Pbo, 5]                  0.29      0.37  3039 1.00 #> scoef[Jackson2019: Len, 1]                  0.03      0.04  3353 1.00 #> scoef[Jackson2019: Len, 2]                  0.39      0.44  1886 1.00 #> scoef[Jackson2019: Len, 3]                  0.23      0.33  1757 1.00 #> scoef[Jackson2019: Len, 4]                  0.34      0.43  2340 1.00 #> scoef[Jackson2019: Len, 5]                  0.19      0.24  3382 1.00 #> scoef[Morgan2012: Pbo, 1]                   0.04      0.06  3363 1.00 #> scoef[Morgan2012: Pbo, 2]                   0.44      0.52  2588 1.00 #> scoef[Morgan2012: Pbo, 3]                   0.17      0.31  2850 1.00 #> scoef[Morgan2012: Pbo, 4]                   0.37      0.49  3817 1.00 #> scoef[Morgan2012: Pbo, 5]                   0.20      0.31  3731 1.00 #> scoef[Morgan2012: Thal, 1]                  0.02      0.04  4551 1.00 #> scoef[Morgan2012: Thal, 2]                  0.52      0.60  3293 1.00 #> scoef[Morgan2012: Thal, 3]                  0.22      0.36  2756 1.00 #> scoef[Morgan2012: Thal, 4]                  0.35      0.45  3444 1.00 #> scoef[Morgan2012: Thal, 5]                  0.10      0.19  3985 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Fri Aug 25 21:49:33 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). (ndmm_fit_nph_loo <- loo(ndmm_fit_nph)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12389.4 116.2 #> p_loo        44.5   1.1 #> looic     24778.8 232.5 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  # Compare to PH model loo_compare(ndmm_fit_1kt_loo, ndmm_fit_nph_loo) #>        elpd_diff se_diff #> model1  0.0       0.0    #> model2 -3.9       4.4 cbind(   PH = by(ndmm_fit_1kt_loo$pointwise[, \"looic\"], studies_all, sum),   `non-PH` = by(ndmm_fit_nph_loo$pointwise[, \"looic\"], studies_all, sum) ) #>                     PH    non-PH #> Attal2012     3342.043  3344.800 #> Jackson2019  12394.107 12391.884 #> McCarthy2012  2723.239  2728.845 #> Morgan2012    4981.445  4984.381 #> Palumbo2014   1330.072  1328.877"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"comparison-to-unadjusted-nma","dir":"Articles","previous_headings":"Assessing the proportional hazards assumption","what":"Comparison to unadjusted NMA","title":"Example: Newly diagnosed multiple myeloma","text":"comparison, also fit NMA models without covariate adjustment, without proportional hazards assumption. , compare model fit using LOOIC, overall within study. Whilst little difference overall model fit, non-PH model preferred Jackson2019 study substantially lower LOOIC. Including covariates ML-NMR model sufficient remove PH violation, even though covariates fixed time-varying, ML-NMR model much better fit overall.","code":"ndmm_fit_nma <- nma(ndmm_net,                     likelihood = \"mspline\",                     n_knots = 1,                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_aux = dirichlet(1)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nma #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                             mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[Len]                     -0.52    0.00 0.04     -0.61     -0.55     -0.52     -0.49     -0.43 #> d[Thal]                    -0.10    0.00 0.09     -0.27     -0.16     -0.10     -0.04      0.06 #> lp__                   -12503.23    0.11 4.05 -12511.77 -12505.82 -12502.95 -12500.28 -12496.36 #> scoef[Attal2012, 1]         0.03    0.00 0.01      0.01      0.02      0.03      0.04      0.06 #> scoef[Attal2012, 2]         0.20    0.00 0.06      0.09      0.16      0.20      0.24      0.32 #> scoef[Attal2012, 3]         0.39    0.00 0.10      0.19      0.33      0.40      0.46      0.58 #> scoef[Attal2012, 4]         0.18    0.00 0.09      0.03      0.11      0.17      0.23      0.36 #> scoef[Attal2012, 5]         0.20    0.00 0.04      0.12      0.17      0.20      0.23      0.28 #> scoef[McCarthy2012, 1]      0.01    0.00 0.01      0.00      0.00      0.00      0.01      0.02 #> scoef[McCarthy2012, 2]      0.32    0.00 0.05      0.23      0.29      0.32      0.35      0.41 #> scoef[McCarthy2012, 3]      0.16    0.00 0.09      0.02      0.09      0.16      0.23      0.35 #> scoef[McCarthy2012, 4]      0.30    0.00 0.11      0.09      0.22      0.30      0.37      0.50 #> scoef[McCarthy2012, 5]      0.21    0.00 0.07      0.08      0.16      0.21      0.26      0.35 #> scoef[Palumbo2014, 1]       0.02    0.00 0.02      0.00      0.01      0.01      0.03      0.06 #> scoef[Palumbo2014, 2]       0.46    0.00 0.07      0.31      0.41      0.46      0.51      0.60 #> scoef[Palumbo2014, 3]       0.18    0.00 0.10      0.01      0.10      0.17      0.25      0.39 #> scoef[Palumbo2014, 4]       0.17    0.00 0.10      0.01      0.08      0.16      0.24      0.39 #> scoef[Palumbo2014, 5]       0.18    0.00 0.07      0.04      0.13      0.18      0.23      0.33 #> scoef[Jackson2019, 1]       0.06    0.00 0.01      0.04      0.05      0.06      0.06      0.07 #> scoef[Jackson2019, 2]       0.39    0.00 0.03      0.33      0.37      0.39      0.42      0.46 #> scoef[Jackson2019, 3]       0.19    0.00 0.06      0.06      0.15      0.19      0.23      0.31 #> scoef[Jackson2019, 4]       0.20    0.00 0.06      0.08      0.16      0.20      0.24      0.32 #> scoef[Jackson2019, 5]       0.16    0.00 0.03      0.10      0.14      0.16      0.18      0.22 #> scoef[Morgan2012, 1]        0.03    0.00 0.01      0.01      0.03      0.03      0.04      0.06 #> scoef[Morgan2012, 2]        0.54    0.00 0.04      0.46      0.51      0.54      0.57      0.62 #> scoef[Morgan2012, 3]        0.07    0.00 0.06      0.00      0.03      0.06      0.11      0.21 #> scoef[Morgan2012, 4]        0.29    0.00 0.06      0.15      0.25      0.29      0.33      0.40 #> scoef[Morgan2012, 5]        0.06    0.00 0.04      0.01      0.03      0.06      0.09      0.15 #>                        n_eff Rhat #> d[Len]                  2978    1 #> d[Thal]                 4013    1 #> lp__                    1395    1 #> scoef[Attal2012, 1]     3007    1 #> scoef[Attal2012, 2]     2364    1 #> scoef[Attal2012, 3]     2346    1 #> scoef[Attal2012, 4]     2882    1 #> scoef[Attal2012, 5]     3828    1 #> scoef[McCarthy2012, 1]  6595    1 #> scoef[McCarthy2012, 2]  3449    1 #> scoef[McCarthy2012, 3]  3024    1 #> scoef[McCarthy2012, 4]  3374    1 #> scoef[McCarthy2012, 5]  3625    1 #> scoef[Palumbo2014, 1]   5315    1 #> scoef[Palumbo2014, 2]   4138    1 #> scoef[Palumbo2014, 3]   3389    1 #> scoef[Palumbo2014, 4]   4881    1 #> scoef[Palumbo2014, 5]   5368    1 #> scoef[Jackson2019, 1]   4388    1 #> scoef[Jackson2019, 2]   2848    1 #> scoef[Jackson2019, 3]   2470    1 #> scoef[Jackson2019, 4]   2915    1 #> scoef[Jackson2019, 5]   3695    1 #> scoef[Morgan2012, 1]    5208    1 #> scoef[Morgan2012, 2]    3911    1 #> scoef[Morgan2012, 3]    3425    1 #> scoef[Morgan2012, 4]    4896    1 #> scoef[Morgan2012, 5]    5102    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Aug 25 21:55:07 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1).  ndmm_fit_nma_nph <- nma(ndmm_net,                         likelihood = \"mspline\",                         n_knots = 1,                         prior_intercept = normal(0, 100),                         prior_trt = normal(0, 100),                         prior_aux = dirichlet(1),                         aux_by = c(.study, .trt)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nma_nph #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                  mean se_mean   sd      2.5%       25%       50%       75% #> d[Len]                          -0.46    0.00 0.05     -0.56     -0.50     -0.46     -0.43 #> d[Thal]                         -0.13    0.00 0.10     -0.33     -0.20     -0.13     -0.06 #> lp__                        -12548.70    0.15 5.42 -12560.09 -12552.11 -12548.29 -12544.91 #> scoef[Attal2012: Pbo, 1]         0.04    0.00 0.02      0.01      0.02      0.03      0.05 #> scoef[Attal2012: Pbo, 2]         0.21    0.00 0.07      0.07      0.16      0.21      0.26 #> scoef[Attal2012: Pbo, 3]         0.45    0.00 0.11      0.21      0.38      0.46      0.53 #> scoef[Attal2012: Pbo, 4]         0.13    0.00 0.09      0.01      0.06      0.11      0.18 #> scoef[Attal2012: Pbo, 5]         0.17    0.00 0.05      0.07      0.13      0.17      0.21 #> scoef[Attal2012: Len, 1]         0.03    0.00 0.02      0.00      0.02      0.03      0.05 #> scoef[Attal2012: Len, 2]         0.19    0.00 0.07      0.04      0.14      0.19      0.24 #> scoef[Attal2012: Len, 3]         0.28    0.00 0.13      0.05      0.19      0.28      0.37 #> scoef[Attal2012: Len, 4]         0.28    0.00 0.12      0.05      0.20      0.28      0.37 #> scoef[Attal2012: Len, 5]         0.21    0.00 0.06      0.10      0.17      0.21      0.25 #> scoef[McCarthy2012: Pbo, 1]      0.01    0.00 0.01      0.00      0.00      0.01      0.02 #> scoef[McCarthy2012: Pbo, 2]      0.33    0.00 0.07      0.20      0.29      0.33      0.38 #> scoef[McCarthy2012: Pbo, 3]      0.20    0.00 0.12      0.02      0.11      0.19      0.28 #> scoef[McCarthy2012: Pbo, 4]      0.28    0.00 0.14      0.03      0.18      0.28      0.38 #> scoef[McCarthy2012: Pbo, 5]      0.17    0.00 0.11      0.01      0.09      0.16      0.25 #> scoef[McCarthy2012: Len, 1]      0.01    0.00 0.01      0.00      0.00      0.01      0.02 #> scoef[McCarthy2012: Len, 2]      0.29    0.00 0.07      0.16      0.24      0.29      0.34 #> scoef[McCarthy2012: Len, 3]      0.19    0.00 0.12      0.01      0.10      0.18      0.28 #> scoef[McCarthy2012: Len, 4]      0.28    0.00 0.13      0.04      0.19      0.28      0.38 #> scoef[McCarthy2012: Len, 5]      0.22    0.00 0.08      0.08      0.17      0.22      0.27 #> scoef[Palumbo2014: Pbo, 1]       0.04    0.00 0.03      0.00      0.02      0.03      0.06 #> scoef[Palumbo2014: Pbo, 2]       0.54    0.00 0.09      0.34      0.48      0.54      0.60 #> scoef[Palumbo2014: Pbo, 3]       0.11    0.00 0.09      0.00      0.04      0.09      0.16 #> scoef[Palumbo2014: Pbo, 4]       0.13    0.00 0.09      0.01      0.06      0.12      0.19 #> scoef[Palumbo2014: Pbo, 5]       0.18    0.00 0.08      0.04      0.12      0.18      0.24 #> scoef[Palumbo2014: Len, 1]       0.02    0.00 0.02      0.00      0.01      0.01      0.03 #> scoef[Palumbo2014: Len, 2]       0.25    0.00 0.10      0.07      0.18      0.25      0.32 #> scoef[Palumbo2014: Len, 3]       0.37    0.00 0.16      0.06      0.26      0.37      0.48 #> scoef[Palumbo2014: Len, 4]       0.18    0.00 0.13      0.01      0.07      0.15      0.27 #> scoef[Palumbo2014: Len, 5]       0.18    0.00 0.10      0.02      0.11      0.18      0.25 #> scoef[Jackson2019: Pbo, 1]       0.08    0.00 0.01      0.06      0.07      0.08      0.09 #> scoef[Jackson2019: Pbo, 2]       0.38    0.00 0.05      0.29      0.35      0.38      0.42 #> scoef[Jackson2019: Pbo, 3]       0.22    0.00 0.07      0.07      0.17      0.22      0.27 #> scoef[Jackson2019: Pbo, 4]       0.11    0.00 0.07      0.01      0.05      0.10      0.16 #> scoef[Jackson2019: Pbo, 5]       0.20    0.00 0.05      0.11      0.17      0.20      0.24 #> scoef[Jackson2019: Len, 1]       0.03    0.00 0.01      0.01      0.02      0.03      0.03 #> scoef[Jackson2019: Len, 2]       0.42    0.00 0.04      0.33      0.39      0.42      0.45 #> scoef[Jackson2019: Len, 3]       0.16    0.00 0.08      0.02      0.10      0.15      0.21 #> scoef[Jackson2019: Len, 4]       0.26    0.00 0.07      0.11      0.22      0.27      0.32 #> scoef[Jackson2019: Len, 5]       0.14    0.00 0.03      0.07      0.11      0.13      0.16 #> scoef[Morgan2012: Pbo, 1]        0.05    0.00 0.02      0.02      0.04      0.05      0.06 #> scoef[Morgan2012: Pbo, 2]        0.48    0.00 0.06      0.36      0.44      0.48      0.52 #> scoef[Morgan2012: Pbo, 3]        0.10    0.00 0.08      0.00      0.04      0.09      0.15 #> scoef[Morgan2012: Pbo, 4]        0.25    0.00 0.09      0.05      0.19      0.25      0.31 #> scoef[Morgan2012: Pbo, 5]        0.12    0.00 0.06      0.02      0.07      0.11      0.16 #> scoef[Morgan2012: Thal, 1]       0.02    0.00 0.01      0.00      0.01      0.02      0.03 #> scoef[Morgan2012: Thal, 2]       0.56    0.00 0.06      0.44      0.52      0.56      0.60 #> scoef[Morgan2012: Thal, 3]       0.12    0.00 0.08      0.01      0.06      0.11      0.17 #> scoef[Morgan2012: Thal, 4]       0.24    0.00 0.08      0.06      0.19      0.25      0.30 #> scoef[Morgan2012: Thal, 5]       0.06    0.00 0.04      0.00      0.03      0.05      0.09 #>                                 97.5% n_eff Rhat #> d[Len]                          -0.36  3061    1 #> d[Thal]                          0.07  3427    1 #> lp__                        -12539.10  1292    1 #> scoef[Attal2012: Pbo, 1]         0.08  3716    1 #> scoef[Attal2012: Pbo, 2]         0.36  2527    1 #> scoef[Attal2012: Pbo, 3]         0.65  2431    1 #> scoef[Attal2012: Pbo, 4]         0.34  2795    1 #> scoef[Attal2012: Pbo, 5]         0.28  3952    1 #> scoef[Attal2012: Len, 1]         0.09  3219    1 #> scoef[Attal2012: Len, 2]         0.33  2734    1 #> scoef[Attal2012: Len, 3]         0.54  2558    1 #> scoef[Attal2012: Len, 4]         0.51  2982    1 #> scoef[Attal2012: Len, 5]         0.33  4146    1 #> scoef[McCarthy2012: Pbo, 1]      0.04  5654    1 #> scoef[McCarthy2012: Pbo, 2]      0.47  3260    1 #> scoef[McCarthy2012: Pbo, 3]      0.45  3526    1 #> scoef[McCarthy2012: Pbo, 4]      0.53  3302    1 #> scoef[McCarthy2012: Pbo, 5]      0.40  3313    1 #> scoef[McCarthy2012: Len, 1]      0.05  5359    1 #> scoef[McCarthy2012: Len, 2]      0.42  3494    1 #> scoef[McCarthy2012: Len, 3]      0.44  2615    1 #> scoef[McCarthy2012: Len, 4]      0.52  3389    1 #> scoef[McCarthy2012: Len, 5]      0.37  4228    1 #> scoef[Palumbo2014: Pbo, 1]       0.11  4909    1 #> scoef[Palumbo2014: Pbo, 2]       0.70  4223    1 #> scoef[Palumbo2014: Pbo, 3]       0.31  3717    1 #> scoef[Palumbo2014: Pbo, 4]       0.34  4973    1 #> scoef[Palumbo2014: Pbo, 5]       0.34  6107    1 #> scoef[Palumbo2014: Len, 1]       0.06  5491    1 #> scoef[Palumbo2014: Len, 2]       0.45  4035    1 #> scoef[Palumbo2014: Len, 3]       0.66  3294    1 #> scoef[Palumbo2014: Len, 4]       0.48  3538    1 #> scoef[Palumbo2014: Len, 5]       0.38  5038    1 #> scoef[Jackson2019: Pbo, 1]       0.11  4284    1 #> scoef[Jackson2019: Pbo, 2]       0.48  2761    1 #> scoef[Jackson2019: Pbo, 3]       0.36  2322    1 #> scoef[Jackson2019: Pbo, 4]       0.27  2512    1 #> scoef[Jackson2019: Pbo, 5]       0.30  3455    1 #> scoef[Jackson2019: Len, 1]       0.05  4152    1 #> scoef[Jackson2019: Len, 2]       0.50  3220    1 #> scoef[Jackson2019: Len, 3]       0.32  2662    1 #> scoef[Jackson2019: Len, 4]       0.39  2987    1 #> scoef[Jackson2019: Len, 5]       0.21  4141    1 #> scoef[Morgan2012: Pbo, 1]        0.09  4143    1 #> scoef[Morgan2012: Pbo, 2]        0.59  3575    1 #> scoef[Morgan2012: Pbo, 3]        0.28  3103    1 #> scoef[Morgan2012: Pbo, 4]        0.41  4253    1 #> scoef[Morgan2012: Pbo, 5]        0.25  4940    1 #> scoef[Morgan2012: Thal, 1]       0.05  5500    1 #> scoef[Morgan2012: Thal, 2]       0.67  4790    1 #> scoef[Morgan2012: Thal, 3]       0.30  3678    1 #> scoef[Morgan2012: Thal, 4]       0.39  4719    1 #> scoef[Morgan2012: Thal, 5]       0.16  4992    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Aug 25 22:00:38 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Compare overall model fit (ndmm_fit_nma_loo <- loo(ndmm_fit_nma)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12461.3 115.4 #> p_loo        22.6   0.6 #> looic     24922.7 230.8 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  (ndmm_fit_nma_nph_loo <- loo(ndmm_fit_nma_nph)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12460.3 115.4 #> p_loo        35.1   1.0 #> looic     24920.5 230.9 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  loo_compare(ndmm_fit_nma_loo, ndmm_fit_nma_nph_loo) #>        elpd_diff se_diff #> model2  0.0       0.0    #> model1 -1.1       5.3     # Compare model fit by study cbind(   PH = by(ndmm_fit_nma_loo$pointwise[, \"looic\"], studies_all, sum),   `non-PH` = by(ndmm_fit_nma_nph_loo$pointwise[, \"looic\"], studies_all, sum) ) #>                     PH    non-PH #> Attal2012     3406.395  3408.744 #> Jackson2019  12401.491 12391.276 #> McCarthy2012  2766.946  2771.886 #> Morgan2012    4981.328  4984.390 #> Palumbo2014   1366.513  1364.247"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"producing-population-average-estimates","dir":"Articles","previous_headings":"","what":"Producing population-average estimates","title":"Example: Newly diagnosed multiple myeloma","text":"now produce population-average estimates several different quantities interest. usual array posterior summary functions available, including relative_effects(), predict(), posterior_ranks() posterior_rank_probs(). predict() function particular numerous options working survival models, selected using type argument: \"survival\" survival probabilities \"hazard\" hazards \"cumhaz\" cumulative hazards \"rmst\" restricted mean survival times \"mean\" mean survival times (equivalent type = \"rmst\" time = Inf) \"quantile\" quantiles survival time distribution \"median\" median survival times (equivalent type = \"quantile\" quantiles = 0.5) \"link\" linear predictor producing population-average predictions (default level = \"aggregate\"), quantities corresponds population-average marginal survival function; see ?predict.stan_nma details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-survival-probabilities","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average survival probabilities","title":"Example: Newly diagnosed multiple myeloma","text":"produce population-average survival curves use predict() function type = \"survival\". marginal standardised survival curves.","code":"sp <- plot(predict(ndmm_fit_1kt, type = \"survival\"))  # Overlay the KM data kmdat <- bind_rows(ndmm_ipd, ndmm_agd) %>%   group_by(studyf, trtf) %>%   group_modify(~with(survfit(Surv(eventtime, event = status) ~ 1, data = .),                      tibble(time, n.censor, estimate = surv, std.err, upper, lower))) %>%   # Add S(0) = 1   group_modify(~add_row(., time = 0, n.censor = 0, estimate = 1, std.err = 0, upper = 1, lower = 1, .before = 0)) %>%   mutate(Treatment = trtf, Study = studyf)  sp +   geom_step(aes(x = time, y = estimate, colour = Treatment), linewidth = 0.15, data = kmdat) +   geom_point(aes(x = time, y = estimate, colour = Treatment), stroke = 0.15, shape = 3,              data = filter(kmdat, n.censor >= 1)) +   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-median-survival-times","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average median survival times","title":"Example: Newly diagnosed multiple myeloma","text":"predict() function can produce range absolute effect summaries, example population-average median survival times:","code":"(medsurv <- predict(ndmm_fit_1kt, type = \"median\")) #> Warning: Evaluating M-spline at times beyond the boundary knots. #> Evaluating M-spline at times beyond the boundary knots. #> Evaluating M-spline at times beyond the boundary knots. #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Attal2012: Pbo]  28.70 1.58 25.71 27.61 28.66 29.78 31.89     4745     3841 1.00 #> pred[Attal2012: Len]  46.73 2.44 42.11 45.04 46.67 48.22 51.76     9315     3365 1.00 #> pred[Attal2012: Thal] 32.09 3.64 25.61 29.58 31.82 34.32 40.13     3745     3106 1.01 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                           mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[McCarthy2012: Pbo]  33.38 2.24 29.20 31.82 33.31 34.82 37.97     3962     3084 1.00 #> pred[McCarthy2012: Len]  56.00 3.14 50.08 53.83 55.87 58.05 62.39     5489     3362 1.00 #> pred[McCarthy2012: Thal] 38.53 4.49 30.22 35.47 38.41 41.43 47.67     3274     3168 1.01 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Palumbo2014: Pbo]  21.13 2.30 17.08 19.48 21.01 22.62 26.03     5413     3337    1 #> pred[Palumbo2014: Len]  45.00 5.10 35.93 41.48 44.80 48.07 54.91     6004     3412    1 #> pred[Palumbo2014: Thal] 26.60 4.76 18.58 23.22 26.15 29.44 37.10     4761     3278    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Jackson2019: Pbo]  24.15 1.33 21.67 23.23 24.11 25.04 26.87     2566     3327 1.01 #> pred[Jackson2019: Len]  50.99 2.52 46.06 49.28 50.96 52.67 55.99       88     3022 1.03 #> pred[Jackson2019: Thal] 31.10 3.87 24.30 28.36 30.82 33.41 39.59     6238     3128 1.00 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                         mean    sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Morgan2012: Pbo]  20.73  1.91 17.26 19.39 20.62 21.96 24.76     2535     3344 1.01 #> pred[Morgan2012: Len]  49.95 70.67 37.84 44.01 47.84 52.12 64.21      770     3185 1.01 #> pred[Morgan2012: Thal] 27.34  2.43 22.93 25.65 27.22 28.89 32.42     5881     3470 1.00  plot(medsurv)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-conditional-log-hazard-ratios","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average conditional log hazard ratios","title":"Example: Newly diagnosed multiple myeloma","text":"Relative effects produced using relative_effects() function. ML-NMR model (IPD meta-regression), population-average conditional log hazard ratios (log survival time ratios AFT models).","code":"(loghr <- relative_effects(ndmm_fit_1kt, all_contrasts = TRUE)) #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  54.29        0.2             0.54 0.57 #>  #>                             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Attal2012: Len vs. Pbo]  -0.59 0.07 -0.74 -0.64 -0.59 -0.54 -0.45     6206     3113 1.00 #> d[Attal2012: Thal vs. Pbo] -0.12 0.13 -0.39 -0.21 -0.12 -0.03  0.14     4379     3188 1.01 #> d[Attal2012: Thal vs. Len]  0.47 0.12  0.23  0.39  0.47  0.55  0.70     1026     3072 1.01 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  57.66       0.23             0.67 0.54 #>  #>                                mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[McCarthy2012: Len vs. Pbo]  -0.62 0.06 -0.74 -0.66 -0.62 -0.58 -0.51     5733     3240 1.00 #> d[McCarthy2012: Thal vs. Pbo] -0.15 0.12 -0.39 -0.23 -0.15 -0.07  0.08     4199     2973 1.01 #> d[McCarthy2012: Thal vs. Len]  0.47 0.12  0.23  0.39  0.47  0.55  0.70     1026     3072 1.01 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  54.17       0.11              0.4 0.55 #>  #>                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Palumbo2014: Len vs. Pbo]  -0.64 0.08 -0.80 -0.69 -0.64 -0.58 -0.48     6475     3111 1.00 #> d[Palumbo2014: Thal vs. Pbo] -0.17 0.14 -0.45 -0.26 -0.17 -0.08  0.11     4947     3204 1.01 #> d[Palumbo2014: Thal vs. Len]  0.47 0.12  0.23  0.39  0.47  0.55  0.70     1026     3072 1.01 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  64.63       0.21             0.84 0.62 #>  #>                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Jackson2019: Len vs. Pbo]  -0.70 0.06 -0.82 -0.74 -0.70 -0.65 -0.57     4415     3352 1.01 #> d[Jackson2019: Thal vs. Pbo] -0.23 0.11 -0.45 -0.30 -0.23 -0.15 -0.02     5473     2863 1.00 #> d[Jackson2019: Thal vs. Len]  0.47 0.12  0.23  0.39  0.47  0.55  0.70     1026     3072 1.01 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  64.46       0.33             0.73 0.62 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Morgan2012: Len vs. Pbo]  -0.69 0.06 -0.82 -0.74 -0.70 -0.65 -0.57     4724     3265 1.01 #> d[Morgan2012: Thal vs. Pbo] -0.22 0.10 -0.44 -0.29 -0.22 -0.15 -0.02     5072     2969 1.00 #> d[Morgan2012: Thal vs. Len]  0.47 0.12  0.23  0.39  0.47  0.55  0.70     1026     3072 1.01  plot(loghr)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-arm-based-data","dir":"Articles","previous_headings":"","what":"Analysis of arm-based data","title":"Example: Parkinson's disease","text":"begin analysis arm-based data - means standard errors.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"arm-level continuous data giving mean -time reduction (y) standard error (se) arm. use function set_agd_arm() set network. let treatment 4 set default network reference treatment, since results considerably improved sampling efficiency choosing treatment 1 network reference. sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"arm_net <- set_agd_arm(parkinsons,                        study = studyn,                       trt = trtn,                       y = y,                        se = se,                       sample_size = n) arm_net #> A network with 7 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(arm_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. arm_fit_FE <- nma(arm_net,                    trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10)) #> Note: Setting \"4\" as the network reference treatment. arm_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> d[1]   0.52    0.01 0.48  -0.42   0.20   0.52   0.84   1.48  1494    1 #> d[2]  -1.28    0.01 0.53  -2.33  -1.64  -1.29  -0.92  -0.27  1583    1 #> d[3]   0.04    0.01 0.33  -0.60  -0.18   0.04   0.26   0.68  2236    1 #> d[5]  -0.30    0.00 0.21  -0.71  -0.44  -0.31  -0.17   0.11  2949    1 #> lp__ -58.24    0.06 2.38 -63.79 -59.63 -57.90 -56.50 -54.63  1664    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:34:43 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(arm_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(arm_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. arm_fit_RE <- nma(arm_net,                    seed = 379394727,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = half_normal(scale = 5),                   adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. #> Warning: There were 2 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems pairs(arm_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\")) arm_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> d[1]   0.52    0.01 0.62  -0.67   0.15   0.52   0.91   1.72  1710 1.00 #> d[2]  -1.31    0.02 0.73  -2.69  -1.76  -1.31  -0.85   0.04  1711 1.00 #> d[3]   0.03    0.01 0.48  -0.92  -0.24   0.03   0.31   1.00  1856 1.00 #> d[5]  -0.29    0.01 0.41  -1.10  -0.51  -0.30  -0.08   0.63  1637 1.00 #> lp__ -76.16    0.10 3.51 -83.71 -78.35 -75.84 -73.72 -70.07  1146 1.00 #> tau    0.39    0.02 0.39   0.01   0.13   0.28   0.52   1.43   650 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:34:54 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(arm_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(arm_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(arm_dic_FE <- dic(arm_fit_FE)) #> Residual deviance: 13.3 (on 15 data points) #>                pD: 11 #>               DIC: 24.4 (arm_dic_RE <- dic(arm_fit_RE)) #> Residual deviance: 13.7 (on 15 data points) #>                pD: 12.5 #>               DIC: 26.3 plot(arm_dic_FE) plot(arm_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean \\(-0.73\\) precision \\(21\\). use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify trt_ref = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted, predictions mean -time reduction produced every study network based estimated baseline response \\(\\mu_j\\):  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(arm_releff_FE <- relative_effects(arm_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.52 0.48 -1.48 -0.84 -0.52 -0.20  0.42     1529     1987    1 #> d[2] -1.80 0.33 -2.47 -2.02 -1.81 -1.58 -1.17     5397     3202    1 #> d[3] -0.48 0.49 -1.45 -0.81 -0.48 -0.15  0.47     2182     2848    1 #> d[5] -0.83 0.52 -1.85 -1.18 -0.83 -0.49  0.21     1621     2358    1 plot(arm_releff_FE, ref_line = 0) (arm_releff_RE <- relative_effects(arm_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.52 0.62 -1.72 -0.91 -0.52 -0.15  0.67     1774     2046    1 #> d[2] -1.83 0.50 -2.83 -2.12 -1.82 -1.53 -0.88     3630     2352    1 #> d[3] -0.49 0.66 -1.76 -0.90 -0.49 -0.10  0.74     2630     1949    1 #> d[5] -0.81 0.76 -2.30 -1.26 -0.82 -0.38  0.71     1730     2076    1 plot(arm_releff_RE, ref_line = 0) arm_pred_FE <- predict(arm_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) arm_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.25 0.53 -2.27 -1.61 -1.26 -0.90 -0.20     1699     2397    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.58 -0.29     3910     3936    1 #> pred[2] -2.53 0.40 -3.31 -2.80 -2.55 -2.27 -1.74     4990     3869    1 #> pred[3] -1.21 0.54 -2.26 -1.57 -1.22 -0.84 -0.16     2408     2891    1 #> pred[5] -1.56 0.56 -2.65 -1.93 -1.55 -1.18 -0.46     1757     2382    1 plot(arm_pred_FE) arm_pred_RE <- predict(arm_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) arm_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.25 0.66 -2.57 -1.66 -1.26 -0.84  0.08     1941     2195    1 #> pred[1] -0.73 0.22 -1.16 -0.87 -0.73 -0.58 -0.30     3976     3867    1 #> pred[2] -2.55 0.56 -3.64 -2.89 -2.55 -2.21 -1.49     3511     2486    1 #> pred[3] -1.22 0.69 -2.58 -1.65 -1.22 -0.79  0.13     2647     2099    1 #> pred[5] -1.54 0.80 -3.16 -2.01 -1.55 -1.06  0.10     1911     2256    1 plot(arm_pred_RE) arm_pred_FE_studies <- predict(arm_fit_FE, type = \"response\") arm_pred_FE_studies #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[1: 4] -1.64 0.46 -2.57 -1.93 -1.64 -1.34 -0.71     2013     2736    1 #> pred[1: 1] -1.12 0.43 -1.97 -1.41 -1.13 -0.83 -0.27     3601     3334    1 #> pred[1: 2] -2.92 0.51 -3.93 -3.26 -2.92 -2.58 -1.95     3308     3245    1 #> pred[1: 3] -1.60 0.39 -2.40 -1.87 -1.59 -1.32 -0.83     3638     3119    1 #> pred[1: 5] -1.94 0.51 -2.97 -2.26 -1.94 -1.61 -0.96     2119     2751    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[2: 4] -1.17 0.52 -2.21 -1.52 -1.17 -0.81 -0.15     1559     2300    1 #> pred[2: 1] -0.65 0.26 -1.15 -0.82 -0.64 -0.47 -0.14     4763     3614    1 #> pred[2: 2] -2.45 0.24 -2.92 -2.61 -2.45 -2.29 -1.97     4993     3321    1 #> pred[2: 3] -1.13 0.54 -2.20 -1.49 -1.12 -0.77 -0.08     2155     2924    1 #> pred[2: 5] -1.47 0.56 -2.57 -1.84 -1.48 -1.09 -0.35     1646     2139    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[3: 4] -1.11 0.43 -1.95 -1.40 -1.11 -0.83 -0.25     1886     2390    1 #> pred[3: 1] -0.59 0.37 -1.31 -0.83 -0.59 -0.34  0.13     4325     3226    1 #> pred[3: 2] -2.39 0.39 -3.15 -2.65 -2.39 -2.13 -1.63     3704     3294    1 #> pred[3: 3] -1.07 0.48 -2.03 -1.39 -1.06 -0.75 -0.14     2763     3013    1 #> pred[3: 5] -1.41 0.47 -2.33 -1.72 -1.42 -1.11 -0.48     1952     2775    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4: 4] -0.39 0.30 -0.99 -0.59 -0.39 -0.19  0.19     2574     2835    1 #> pred[4: 1]  0.13 0.51 -0.87 -0.21  0.14  0.48  1.13     2020     2700    1 #> pred[4: 2] -1.67 0.56 -2.76 -2.04 -1.68 -1.29 -0.57     2066     2695    1 #> pred[4: 3] -0.35 0.24 -0.81 -0.51 -0.35 -0.19  0.14     5117     3445    1 #> pred[4: 5] -0.69 0.36 -1.39 -0.94 -0.69 -0.44 -0.01     2748     3217    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[5: 4] -0.55 0.34 -1.20 -0.79 -0.55 -0.33  0.13     2864     2908    1 #> pred[5: 1] -0.03 0.54 -1.09 -0.39 -0.02  0.33  1.03     2092     2697    1 #> pred[5: 2] -1.84 0.58 -2.98 -2.22 -1.84 -1.45 -0.69     2101     2601    1 #> pred[5: 3] -0.51 0.29 -1.07 -0.70 -0.51 -0.32  0.06     5638     3643    1 #> pred[5: 5] -0.86 0.40 -1.65 -1.13 -0.86 -0.59 -0.07     2993     3061    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[6: 4] -2.19 0.17 -2.53 -2.31 -2.20 -2.08 -1.85     3024     2980    1 #> pred[6: 1] -1.67 0.51 -2.71 -2.01 -1.67 -1.33 -0.66     1542     2189    1 #> pred[6: 2] -3.48 0.55 -4.57 -3.85 -3.48 -3.10 -2.39     1654     2402    1 #> pred[6: 3] -2.15 0.37 -2.88 -2.40 -2.16 -1.91 -1.43     2409     2796    1 #> pred[6: 5] -2.50 0.17 -2.83 -2.61 -2.50 -2.38 -2.17     5627     2766    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[7: 4] -1.79 0.18 -2.14 -1.91 -1.79 -1.67 -1.45     3542     2517    1 #> pred[7: 1] -1.27 0.52 -2.29 -1.62 -1.27 -0.92 -0.25     1673     2239    1 #> pred[7: 2] -3.08 0.56 -4.17 -3.46 -3.08 -2.68 -1.99     1717     2492    1 #> pred[7: 3] -1.75 0.37 -2.49 -2.00 -1.75 -1.51 -1.04     2466     2832    1 #> pred[7: 5] -2.10 0.20 -2.50 -2.23 -2.10 -1.96 -1.69     4762     3244    1 plot(arm_pred_FE_studies) (arm_ranks <- posterior_ranks(arm_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.51 0.70    2   3   3   4     5     2272       NA    1 #> rank[1] 4.63 0.78    2   5   5   5     5     2078       NA    1 #> rank[2] 1.06 0.29    1   1   1   1     2     2582     2644    1 #> rank[3] 3.53 0.92    2   3   4   4     5     3076       NA    1 #> rank[5] 2.27 0.67    1   2   2   2     4     2492     2805    1 plot(arm_ranks) (arm_rankprobs <- posterior_rank_probs(arm_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.48      0.40      0.08 #> d[1]      0.00      0.04      0.06      0.12      0.78 #> d[2]      0.96      0.03      0.01      0.00      0.00 #> d[3]      0.00      0.16      0.27      0.43      0.13 #> d[5]      0.04      0.72      0.17      0.05      0.01 plot(arm_rankprobs) (arm_cumrankprobs <- posterior_rank_probs(arm_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.53      0.92         1 #> d[1]      0.00      0.04      0.11      0.22         1 #> d[2]      0.96      0.99      1.00      1.00         1 #> d[3]      0.00      0.16      0.43      0.87         1 #> d[5]      0.04      0.76      0.94      0.99         1 plot(arm_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-contrast-based-data","dir":"Articles","previous_headings":"","what":"Analysis of contrast-based data","title":"Example: Parkinson's disease","text":"now perform analysis using contrast-based data (mean differences standard errors).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"contrast-level data giving mean difference -time reduction (diff) standard error (se_diff), use function set_agd_contrast() set network. sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"contr_net <- set_agd_contrast(parkinsons,                                study = studyn,                               trt = trtn,                               y = diff,                                se = se_diff,                               sample_size = n) contr_net #> A network with 7 AgD studies (contrast-based). #>  #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(contr_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. contr_fit_FE <- nma(contr_net,                      trt_effects = \"fixed\",                     prior_trt = normal(scale = 100)) #> Note: Setting \"4\" as the network reference treatment. contr_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> d[1]   0.51    0.01 0.48  -0.45   0.19   0.51   0.83   1.45  1960    1 #> d[2]  -1.30    0.01 0.52  -2.32  -1.65  -1.29  -0.94  -0.31  1929    1 #> d[3]   0.04    0.01 0.33  -0.59  -0.18   0.04   0.27   0.67  2585    1 #> d[5]  -0.30    0.00 0.21  -0.72  -0.45  -0.30  -0.16   0.10  3750    1 #> lp__ -25.25    0.03 1.40 -28.84 -25.94 -24.93 -24.22 -23.49  1923    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:35:16 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). plot_prior_posterior(contr_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. contr_fit_RE <- nma(contr_net,                      seed = 1150676438,                     trt_effects = \"random\",                     prior_trt = normal(scale = 100),                     prior_het = half_normal(scale = 5),                     adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. pairs(contr_fit_RE, pars = c(\"d[3]\", \"delta[4: 4 vs. 3]\", \"tau\")) contr_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> d[1]   0.53    0.02 0.63  -0.63   0.14   0.53   0.91   1.80  1729 1.00 #> d[2]  -1.30    0.02 0.68  -2.64  -1.72  -1.31  -0.89   0.07  1778 1.00 #> d[3]   0.04    0.01 0.46  -0.89  -0.23   0.04   0.30   1.00  1998 1.00 #> d[5]  -0.30    0.01 0.45  -1.12  -0.50  -0.29  -0.09   0.55  1245 1.00 #> lp__ -32.79    0.08 2.73 -38.78 -34.51 -32.54 -30.84 -28.11  1144 1.01 #> tau    0.39    0.02 0.40   0.01   0.12   0.28   0.51   1.50   628 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:35:24 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(contr_fit_RE, pars = c(\"d\", \"delta\")) plot_prior_posterior(contr_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(contr_dic_FE <- dic(contr_fit_FE)) #> Residual deviance: 6.3 (on 8 data points) #>                pD: 4 #>               DIC: 10.3 (contr_dic_RE <- dic(contr_fit_RE)) #> Residual deviance: 6.5 (on 8 data points) #>                pD: 5.3 #>               DIC: 11.9 plot(contr_dic_FE) plot(contr_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean \\(-0.73\\) precision \\(21\\). use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify trt_ref = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted error raised, study baselines estimated network. can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(contr_releff_FE <- relative_effects(contr_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.51 0.48 -1.45 -0.83 -0.51 -0.19  0.45     1992     2501    1 #> d[2] -1.81 0.33 -2.46 -2.02 -1.80 -1.59 -1.17     4600     3370    1 #> d[3] -0.46 0.48 -1.39 -0.79 -0.46 -0.13  0.50     2910     3175    1 #> d[5] -0.81 0.52 -1.82 -1.17 -0.82 -0.46  0.23     2306     2696    1 plot(contr_releff_FE, ref_line = 0) (contr_releff_RE <- relative_effects(contr_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.53 0.63 -1.80 -0.91 -0.53 -0.14  0.63     2077     1539    1 #> d[2] -1.84 0.50 -2.84 -2.11 -1.83 -1.55 -0.89     3782     2513    1 #> d[3] -0.50 0.65 -1.75 -0.89 -0.49 -0.12  0.75     3121     1834    1 #> d[5] -0.83 0.79 -2.32 -1.24 -0.82 -0.39  0.61     1834     1147    1 plot(contr_releff_RE, ref_line = 0) contr_pred_FE <- predict(contr_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) contr_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.24 0.52 -2.28 -1.59 -1.23 -0.90 -0.22     2141     2747    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.58 -0.30     3988     3629    1 #> pred[2] -2.53 0.39 -3.31 -2.80 -2.54 -2.26 -1.76     4307     3185    1 #> pred[3] -1.19 0.52 -2.21 -1.54 -1.20 -0.84 -0.14     3030     3120    1 #> pred[5] -1.54 0.56 -2.64 -1.93 -1.54 -1.17 -0.40     2437     2998    1 plot(contr_pred_FE) contr_pred_RE <- predict(contr_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) contr_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.27 0.67 -2.57 -1.67 -1.26 -0.85  0.00     2172     1664    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.59 -0.31     3715     3592    1 #> pred[2] -2.57 0.54 -3.68 -2.89 -2.57 -2.23 -1.53     3756     2658    1 #> pred[3] -1.23 0.68 -2.52 -1.65 -1.22 -0.81  0.09     3176     2175    1 #> pred[5] -1.56 0.82 -3.17 -2.00 -1.55 -1.10 -0.06     1977     1247    1 plot(contr_pred_RE) # Not run predict(contr_fit_FE, type = \"response\") (contr_ranks <- posterior_ranks(contr_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.52 0.72    2   3   3   4     5     2539       NA    1 #> rank[1] 4.62 0.80    2   5   5   5     5     2579       NA    1 #> rank[2] 1.04 0.23    1   1   1   1     2     2925     2905    1 #> rank[3] 3.52 0.92    2   3   4   4     5     3559       NA    1 #> rank[5] 2.29 0.67    1   2   2   3     4     2569     2771    1 plot(contr_ranks) (contr_rankprobs <- posterior_rank_probs(contr_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.49      0.38      0.09 #> d[1]      0.00      0.05      0.06      0.12      0.77 #> d[2]      0.96      0.03      0.00      0.00      0.00 #> d[3]      0.00      0.16      0.26      0.45      0.12 #> d[5]      0.03      0.72      0.19      0.05      0.01 plot(contr_rankprobs) (contr_cumrankprobs <- posterior_rank_probs(contr_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.53      0.91         1 #> d[1]      0.00      0.05      0.11      0.23         1 #> d[2]      0.96      1.00      1.00      1.00         1 #> d[3]      0.00      0.17      0.43      0.88         1 #> d[5]      0.03      0.75      0.94      0.99         1 plot(contr_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-mixed-arm-based-and-contrast-based-data","dir":"Articles","previous_headings":"","what":"Analysis of mixed arm-based and contrast-based data","title":"Example: Parkinson's disease","text":"now perform analysis studies contribute arm-based data, contribute contrast-based data. Replicating Dias et al. (2011), consider arm-based data studies 1-3, contrast-based data studies 4-7.","code":"studies <- parkinsons$studyn (parkinsons_arm <- parkinsons[studies %in% 1:3, ]) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718 #> 7      3    4 -1.20 0.478  81 -0.90   0.695 (parkinsons_contr <- parkinsons[studies %in% 4:7, ]) #>    studyn trtn     y    se   n  diff se_diff #> 8       4    3 -0.24 0.265 128    NA   0.265 #> 9       4    4 -0.59 0.354  72 -0.35   0.442 #> 10      5    3 -0.73 0.335  80    NA   0.335 #> 11      5    4 -0.18 0.442  46  0.55   0.555 #> 12      6    4 -2.20 0.197 137    NA   0.197 #> 13      6    5 -2.50 0.190 131 -0.30   0.274 #> 14      7    4 -1.80 0.200 154    NA   0.200 #> 15      7    5 -2.10 0.250 143 -0.30   0.320"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"use functions set_agd_arm() set_agd_contrast() set respective data sources within network, combine together combine_network(). sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"mix_arm_net <- set_agd_arm(parkinsons_arm,                             study = studyn,                            trt = trtn,                            y = y,                             se = se,                            sample_size = n)  mix_contr_net <- set_agd_contrast(parkinsons_contr,                                    study = studyn,                                   trt = trtn,                                   y = diff,                                    se = se_diff,                                   sample_size = n)  mix_net <- combine_network(mix_arm_net, mix_contr_net) mix_net #> A network with 3 AgD studies (arm-based), and 4 AgD studies (contrast-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  #>  Outcome type: continuous #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(mix_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. mix_fit_FE <- nma(mix_net,                    trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100)) #> Note: Setting \"4\" as the network reference treatment. mix_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> d[1]   0.53    0.01 0.48  -0.43   0.21   0.53   0.85   1.44  1314    1 #> d[2]  -1.29    0.01 0.52  -2.34  -1.64  -1.29  -0.93  -0.30  1432    1 #> d[3]   0.05    0.01 0.32  -0.58  -0.17   0.04   0.27   0.68  2217    1 #> d[5]  -0.30    0.00 0.21  -0.71  -0.44  -0.30  -0.17   0.11  2816    1 #> lp__ -43.30    0.04 1.88 -47.72 -44.33 -42.97 -41.90 -40.60  1859    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:35:37 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(mix_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(mix_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. mix_fit_RE <- nma(mix_net,                    seed = 437219664,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = half_normal(scale = 5),                   adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. #> Warning: There were 18 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess pairs(mix_fit_RE, pars = c(\"d[3]\", \"delta[4: 4 vs. 3]\", \"tau\")) mix_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> d[1]   0.56    0.02 0.67  -0.72   0.15   0.56   0.93   1.94   837 1.01 #> d[2]  -1.27    0.04 0.80  -2.74  -1.71  -1.29  -0.85   0.19   432 1.01 #> d[3]   0.04    0.02 0.52  -1.02  -0.24   0.05   0.30   1.00   715 1.00 #> d[5]  -0.33    0.02 0.50  -1.50  -0.53  -0.32  -0.10   0.60   742 1.01 #> lp__ -51.90    0.10 3.22 -59.12 -53.79 -51.62 -49.66 -46.36  1119 1.00 #> tau    0.43    0.04 0.55   0.01   0.13   0.29   0.53   1.69   234 1.04 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:35:48 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(mix_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(mix_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(mix_dic_FE <- dic(mix_fit_FE)) #> Residual deviance: 9.3 (on 11 data points) #>                pD: 7 #>               DIC: 16.2 (mix_dic_RE <- dic(mix_fit_RE)) #> Residual deviance: 9.7 (on 11 data points) #>                pD: 8.5 #>               DIC: 18.2 plot(mix_dic_FE) plot(mix_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean \\(-0.73\\) precision \\(21\\). use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify trt_ref = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted, predictions mean -time reduction produced every arm-based study network based estimated baseline response \\(\\mu_j\\):  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(mix_releff_FE <- relative_effects(mix_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.53 0.48 -1.44 -0.85 -0.53 -0.21  0.43     1324     1823    1 #> d[2] -1.82 0.33 -2.48 -2.04 -1.81 -1.59 -1.15     5822     3307    1 #> d[3] -0.48 0.49 -1.45 -0.80 -0.48 -0.16  0.46     2162     2697    1 #> d[5] -0.83 0.52 -1.85 -1.18 -0.84 -0.48  0.19     1410     1885    1 plot(mix_releff_FE, ref_line = 0) (mix_releff_RE <- relative_effects(mix_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.56 0.67 -1.94 -0.93 -0.56 -0.15  0.72     1260      678 1.00 #> d[2] -1.83 0.58 -2.88 -2.12 -1.85 -1.54 -0.71     1894      685 1.01 #> d[3] -0.53 0.74 -1.91 -0.91 -0.50 -0.11  0.80     1445      652 1.00 #> d[5] -0.89 0.89 -2.62 -1.32 -0.87 -0.40  0.70     1186      515 1.00 plot(mix_releff_RE, ref_line = 0) mix_pred_FE <- predict(mix_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) mix_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.25 0.53 -2.28 -1.61 -1.26 -0.90 -0.21     1445     2165    1 #> pred[1] -0.72 0.22 -1.14 -0.87 -0.72 -0.58 -0.29     3556     3638    1 #> pred[2] -2.54 0.40 -3.32 -2.81 -2.54 -2.26 -1.77     4860     3651    1 #> pred[3] -1.20 0.54 -2.26 -1.55 -1.21 -0.85 -0.13     2253     2980    1 #> pred[5] -1.55 0.57 -2.68 -1.92 -1.56 -1.16 -0.45     1523     2083    1 plot(mix_pred_FE) mix_pred_RE <- predict(mix_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) mix_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.29 0.71 -2.76 -1.69 -1.29 -0.87  0.04     1318      664    1 #> pred[1] -0.73 0.22 -1.17 -0.88 -0.73 -0.58 -0.31     4051     3817    1 #> pred[2] -2.56 0.62 -3.73 -2.90 -2.56 -2.24 -1.40     1832      874    1 #> pred[3] -1.26 0.77 -2.74 -1.65 -1.23 -0.81  0.15     1402      660    1 #> pred[5] -1.62 0.92 -3.50 -2.08 -1.60 -1.10  0.02     1201      532    1 plot(mix_pred_RE) mix_pred_FE_studies <- predict(mix_fit_FE, type = \"response\") mix_pred_FE_studies #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[1: 4] -1.65 0.45 -2.51 -1.94 -1.64 -1.34 -0.76     1839     2305    1 #> pred[1: 1] -1.12 0.43 -1.97 -1.41 -1.12 -0.83 -0.29     3298     2870    1 #> pred[1: 2] -2.94 0.52 -3.94 -3.28 -2.94 -2.59 -1.92     3294     2922    1 #> pred[1: 3] -1.60 0.38 -2.34 -1.86 -1.61 -1.34 -0.86     3407     2836    1 #> pred[1: 5] -1.95 0.49 -2.91 -2.27 -1.95 -1.62 -0.97     1881     2480    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[2: 4] -1.17 0.51 -2.14 -1.52 -1.16 -0.82 -0.18     1363     2079    1 #> pred[2: 1] -0.64 0.26 -1.15 -0.81 -0.64 -0.47 -0.12     4954     3729    1 #> pred[2: 2] -2.45 0.24 -2.93 -2.62 -2.45 -2.29 -1.98     4943     3529    1 #> pred[2: 3] -1.12 0.53 -2.15 -1.46 -1.12 -0.77 -0.10     2095     2633    1 #> pred[2: 5] -1.47 0.55 -2.55 -1.84 -1.47 -1.09 -0.41     1409     1834    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[3: 4] -1.11 0.42 -1.92 -1.40 -1.12 -0.84 -0.28     1579     2614    1 #> pred[3: 1] -0.59 0.36 -1.30 -0.83 -0.59 -0.34  0.13     4003     3062    1 #> pred[3: 2] -2.40 0.39 -3.16 -2.66 -2.40 -2.14 -1.61     4060     3202    1 #> pred[3: 3] -1.07 0.47 -1.98 -1.40 -1.07 -0.75 -0.14     2799     2406    1 #> pred[3: 5] -1.42 0.47 -2.35 -1.73 -1.42 -1.10 -0.51     1642     2070    1 plot(mix_pred_FE_studies) (mix_ranks <- posterior_ranks(mix_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.50 0.71    2   3   3   4     5     1961       NA    1 #> rank[1] 4.66 0.75    2   5   5   5     5     2078       NA    1 #> rank[2] 1.05 0.26    1   1   1   1     2     1812     1600    1 #> rank[3] 3.52 0.92    2   3   4   4     5     3057       NA    1 #> rank[5] 2.27 0.65    1   2   2   2     4     2220     2540    1 plot(mix_ranks) (mix_rankprobs <- posterior_rank_probs(mix_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.49      0.39      0.08 #> d[1]      0.00      0.04      0.06      0.12      0.79 #> d[2]      0.96      0.03      0.01      0.00      0.00 #> d[3]      0.00      0.16      0.27      0.45      0.12 #> d[5]      0.04      0.72      0.18      0.05      0.01 plot(mix_rankprobs) (mix_cumrankprobs <- posterior_rank_probs(mix_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.53      0.92         1 #> d[1]      0.00      0.04      0.10      0.21         1 #> d[2]      0.96      0.99      1.00      1.00         1 #> d[3]      0.00      0.16      0.43      0.88         1 #> d[5]      0.04      0.76      0.94      0.99         1 plot(mix_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"initial_analysis","dir":"Articles","previous_headings":"","what":"Initial analysis","title":"Example: Plaque psoriasis ML-NMR","text":"start recreating analysis presented Phillippo et al. (2020). analyse IPD three studies, UNCOVER-1, UNCOVER-2, UNCOVER-3 (Griffiths et al. 2015; Gordon et al. 2016), AgD one study, FIXTURE (Langley et al. 2014). consider running ML-NMR adjusting five potential effect-modifying covariates: duration psoriasis durnpso, weight weight, previous systemic treatment prevsys, body surface area bsa, psoriatic arthritis psa.","code":"pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0  male bsa #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2  TRUE  18 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4  TRUE  33 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8  TRUE  33 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 FALSE  50 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 FALSE  35 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2  TRUE  29 #>   weight durnpso prevsys   psa #> 1   98.1     6.7    TRUE  TRUE #> 2  129.6    14.5   FALSE  TRUE #> 3   78.0    26.5    TRUE FALSE #> 4  139.9    25.0    TRUE  TRUE #> 5   54.2    11.9    TRUE FALSE #> 6   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n pasi100_r #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323        14 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324         0 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327        47 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323        78 #>   pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd pasi_w0_mean pasi_w0_sd male #> 1       323            326     43.8   13.0     28.7    5.9         23.2        9.8 71.2 #> 2       324            326     44.1   12.6     27.9    6.1         24.1       10.5 72.7 #> 3       327            327     45.4   12.9     28.4    5.9         23.7       10.5 72.2 #> 4       323            327     44.5   13.2     28.4    6.4         23.9        9.9 68.5 #>   bsa_mean bsa_sd weight_mean weight_sd durnpso_mean durnpso_sd prevsys  psa #> 1     33.6   18.0        84.6      20.5         16.4       12.0    65.6 13.5 #> 2     35.2   19.1        82.0      20.4         16.6       11.6    62.6 15.0 #> 3     34.5   19.4        83.6      20.8         17.3       12.2    64.8 15.0 #> 4     34.3   19.2        83.0      21.6         15.8       12.3    63.0 15.3"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"preparing-the-data","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Preparing the data","title":"Example: Plaque psoriasis ML-NMR","text":"need prepare data acceptable format run ML-NMR model. Firstly, need handle binary covariates prevsys psa. IPD, coded TRUE FALSE, AgD coded percentages (100). need transform sets variables numeric lie interval \\([0,1]\\), variables compatible across data sources. Whilst , also transform body surface area bsa (percentage) lie \\([0,1]\\), since make specifying appropriate marginal distribution easier later, rescale weight duration aid interpretation regression coefficients (terms 10 kilos 10 years respectively). also add trtclass variable, indicating treatments belong classes. Finally, check missing values IPD. small number individuals missing covariates: Since proportion missing data small, simply exclude individuals analysis.","code":"pso_ipd <- pso_ipd %>%    mutate(# Variable transformations          bsa = bsa / 100,          prevsys = as.numeric(prevsys),          psa = as.numeric(psa),          weight = weight / 10,          durnpso = durnpso / 10,          # Treatment classes          trtclass = case_when(trtn == 1 ~ \"Placebo\",                               trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                               trtn == 4 ~ \"TNFa blocker\"),          # Check complete cases for covariates of interest          complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%    mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                               trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                               trtn == 4 ~ \"TNFa blocker\")   ) sum(!pso_ipd$complete) #> [1] 4 mean(!pso_ipd$complete) #> [1] 0.001036807 pso_ipd <- filter(pso_ipd, complete)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"creating-the-network","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Creating the network","title":"Example: Plaque psoriasis ML-NMR","text":"Set network, setting IPD set_ipd(), AgD (arm-based) set_agd_arm(), combining together using combine_network(). specify binary pasi75 outcome r IPD, count outcome pasi75_r denominator pasi75_n r n AgD. specify treatment classes trt_class = trtclass. can produce network plot plot() method:","code":"pso_net <- combine_network(   set_ipd(pso_ipd,            study = studyc,            trt = trtc,            r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,                study = studyc,                trt = trtc,                r = pasi75_r,                n = pasi75_n,               trt_class = trtclass) )  pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE) +    ggplot2::theme(legend.position = \"bottom\", legend.box = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"numerical-integration-for-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Numerical integration for ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"ML-NMR models define meta-regression model individual level, exactly manner full-IPD meta-regression. ML-NMR incorporates AgD model integrating individual-level model covariate distribution AgD study (Phillippo et al. 2020; Phillippo 2019). Using integration, instead simply “plugging-” mean covariate values AgD studies, avoids aggregation bias link function identity function. package utilises numerical integration incorporate aggregate data - specifically, quasi-Monte Carlo (QMC) integration Gaussian copula (Phillippo et al. 2020; Phillippo 2019). QMC integration general flexible integration approach, typically requires far fewer integration points standard (pseudo-random) Monte-Carlo integration achieve numerical accuracy.1 Gaussian copula allows us account correlations covariates, may specified marginal distributions. now set numerical integration network. five covariates consider adjusting body surface area bsa, duration psoriasis durnpso, previous systemic treatment prevsys, psoriatic arthritis psa, weight weight. need choose suitable marginal distributions covariates draw integration points . prevsys psa binary covariates, given Bernoulli distribution. bsa percentage, choose logit-Normal distribution (note, requires logitnorm package installed). choose Gamma distributions durnpso weight account skewness. choices seem match well marginal distributions observed IPD:  add integration points AgD studies network using add_integration() function. Marginal distributions covariate specified using distr() function, takes cumulative distribution function corresponding chosen marginal distribution, arguments distribution column names aggregate data. Since know correlations covariates AgD studies, impute weighted mean correlations IPD studies (default option). Note: package provides several convenience functions specifying distributions, including qgamma() allows parameterisation Gamma distribution terms mean standard deviation, qbern() provides Bernoulli distribution, qlogitnorm() provides logit-Normal distribution allowing parameterisation terms mean standard deviation (requires logitnorm package installed).","code":"# Get mean and sd of covariates in each study ipd_summary <- pso_ipd %>%    group_by(studyc) %>%    summarise_at(vars(weight, durnpso, bsa), list(mean = mean, sd = sd, min = min, max = max)) %>%    pivot_longer(weight_mean:bsa_max, names_sep = \"_\", names_to = c(\"covariate\", \".value\")) %>%    # Assign distributions   mutate(dist = recode(covariate,                        bsa = \"dlogitnorm\",                        durnpso = \"dgamma\",                        weight = \"dgamma\")) %>%    # Compute density curves   group_by(studyc, covariate) %>%    mutate(value = if_else(dist == \"dlogitnorm\",                          list(seq(0, 1, length.out = 101)),                          list(seq(min*0.8, max*1.2, length.out = 101)))) %>%    unnest(cols = value) %>%    mutate(dens = eval(call(first(dist), x = value, mean = first(mean), sd = first(sd))))  # Plot histograms and assumed densities pso_ipd %>%    pivot_longer(c(weight, durnpso, bsa), names_to = \"covariate\", values_to = \"value\") %>%  ggplot(aes(x = value)) +   geom_histogram(aes(y = after_stat(density)),                   binwidth = function(x) diff(range(x)) / nclass.Sturges(x),                  boundary = 0,                  fill = \"grey50\") +   geom_line(aes(y = dens), data = ipd_summary,             colour = \"darkred\", linewidth = 0.5) +   facet_wrap(~studyc + covariate, scales = \"free\", ncol = 3) +   theme_multinma() pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64 ) #> Using weighted average correlation matrix computed from IPD studies."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"ml-nmr-models","dir":"Articles","previous_headings":"Initial analysis","what":"ML-NMR models","title":"Example: Plaque psoriasis ML-NMR","text":"fit fixed effect (FE) random effects (RE) ML-NMR models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"fixed-effect-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > ML-NMR models","what":"Fixed effect ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"First, fit FE ML-NMR model using function nma(). Following (Phillippo et al. 2020) specify weakly-informative \\(N(0, 10^2)\\) priors parameter. range parameter values implied prior distributions can checked using summary() method: regression model specified regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt, include main (prognostic) effects covariate well interactions treatment. use probit link function (link = \"probit\"), specify two-parameter Binomial approximation aggregate-level likelihood used (likelihood = \"bernoulli2\", “bernoulli” refers individual-level likelihood, “2” denotes two-parameter adjustment aggregate-level likelihood) (Phillippo et al. 2020). utilise shared effect modifier assumption help identify model, setting treatment-covariate interactions equal within class (class_interactions = \"common\"). narrow possible range random initial values init_r = 0.1 (default init_r = 2), since probit models particular often hard initialise. Using QR decomposition (QR = TRUE) greatly improves sampling efficiency , often case regression models. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  now recommend assessing sufficient accuracy numerical integration running half chains n_int / 2 integration points half full n_int. Rhat n_eff diagnostic warnings can either attributed insufficient MCMC iterations (argument iter nma()) insufficient integration points (n_int add_integration()), depending whether occur within two groups chains chains combined. feature enabled default (int_check = TRUE). case, warnings content number iterations number integration points. (Phillippo et al. (2020) used alternative approach based saving cumulative integration points plotting empirical integration error, can achieved setting int_thin nma() using plot_integration_error() function.)","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                    likelihood = \"bernoulli2\",                   regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   init_r = 0.1,                   QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. print(pso_fit_FE) #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                           0.04    0.00 0.06    -0.08     0.00     0.04     0.09 #> beta[prevsys]                          -0.14    0.00 0.16    -0.45    -0.25    -0.14    -0.03 #> beta[bsa]                              -0.06    0.01 0.46    -0.99    -0.37    -0.04     0.26 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02     0.04     0.06 #> beta[psa]                              -0.08    0.00 0.17    -0.42    -0.19    -0.07     0.04 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08    -0.03     0.02 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.14    -0.06    -0.01     0.03 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.19    -0.17     0.06     0.19     0.32 #> beta[prevsys:.trtclassIL blocker]       0.07    0.00 0.18    -0.29    -0.06     0.07     0.19 #> beta[bsa:.trtclassTNFa blocker]         0.06    0.01 0.52    -0.97    -0.31     0.05     0.41 #> beta[bsa:.trtclassIL blocker]           0.29    0.01 0.50    -0.65    -0.06     0.28     0.63 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.19    -0.17    -0.14 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12    -0.10    -0.08 #> beta[psa:.trtclassTNFa blocker]        -0.06    0.00 0.21    -0.47    -0.20    -0.06     0.09 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.18    -0.35    -0.12     0.01     0.13 #> d[ETN]                                  1.55    0.00 0.08     1.39     1.50     1.55     1.61 #> d[IXE_Q2W]                              2.95    0.00 0.08     2.79     2.90     2.95     3.01 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.39     2.49     2.54     2.60 #> d[SEC_150]                              2.15    0.00 0.11     1.93     2.07     2.15     2.22 #> d[SEC_300]                              2.45    0.00 0.12     2.21     2.37     2.45     2.53 #> lp__                                -1653.65    0.08 3.43 -1661.19 -1655.75 -1653.37 -1651.25 #>                                        97.5% n_eff Rhat #> beta[durnpso]                           0.16  5704    1 #> beta[prevsys]                           0.18  5445    1 #> beta[bsa]                               0.77  6157    1 #> beta[weight]                            0.10  6791    1 #> beta[psa]                               0.26  6202    1 #> beta[durnpso:.trtclassTNFa blocker]     0.12  6110    1 #> beta[durnpso:.trtclassIL blocker]       0.12  6962    1 #> beta[prevsys:.trtclassTNFa blocker]     0.56  5951    1 #> beta[prevsys:.trtclassIL blocker]       0.41  6602    1 #> beta[bsa:.trtclassTNFa blocker]         1.09  6269    1 #> beta[bsa:.trtclassIL blocker]           1.29  7803    1 #> beta[weight:.trtclassTNFa blocker]     -0.10  7101    1 #> beta[weight:.trtclassIL blocker]       -0.04  7760    1 #> beta[psa:.trtclassTNFa blocker]         0.35  6680    1 #> beta[psa:.trtclassIL blocker]           0.37  6904    1 #> d[ETN]                                  1.70  4735    1 #> d[IXE_Q2W]                              3.12  5688    1 #> d[IXE_Q4W]                              2.69  5228    1 #> d[SEC_150]                              2.37  5631    1 #> d[SEC_300]                              2.68  5019    1 #> lp__                                -1647.77  1660    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:36:50 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_FE, pars = c(\"d\", \"beta\", \"mu\")) plot_prior_posterior(pso_fit_FE, prior = c(\"intercept\", \"trt\", \"reg\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"random-effects-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > ML-NMR models","what":"Random effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"now fit RE model. , specify weakly-informative \\(N(0, 10^2)\\) priors parameter, now specify \\(\\textrm{half-N}(0, 2.5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). range parameter values implied prior distributions can checked using summary() method: Fitting model uses call nma() , except now trt_effects = \"random\". Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: number divergent transitions, can investigate using pairs() method:  divergent transition errors (red crosses) seem concentrated upper tail heterogeneity standard deviation parameter. suggests information identify heterogeneity parameter weak - four studies network - informative prior distribution might aid estimation. prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(half_normal(scale = 2.5)) #> A half-Normal prior distribution: location = 0, scale = 2.5. #> 50% of the prior density lies between 0 and 1.69. #> 95% of the prior density lies between 0 and 4.9. pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                    likelihood = \"bernoulli2\",                   regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_het = half_normal(scale = 2.5),                   init_r = 0.1,                   QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. #> Warning: There were 15 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems print(pso_fit_RE) #> A random effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                           0.05    0.00 0.06    -0.08     0.01     0.05     0.09 #> beta[prevsys]                          -0.12    0.00 0.16    -0.43    -0.24    -0.13    -0.02 #> beta[bsa]                              -0.11    0.01 0.45    -1.00    -0.41    -0.11     0.20 #> beta[weight]                            0.04    0.00 0.03    -0.01     0.02     0.04     0.06 #> beta[psa]                              -0.06    0.00 0.17    -0.39    -0.17    -0.06     0.05 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.08    -0.18    -0.08    -0.03     0.02 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.15    -0.06    -0.01     0.03 #> beta[prevsys:.trtclassTNFa blocker]     0.18    0.00 0.19    -0.19     0.05     0.18     0.31 #> beta[prevsys:.trtclassIL blocker]       0.05    0.00 0.18    -0.30    -0.07     0.05     0.17 #> beta[bsa:.trtclassTNFa blocker]         0.09    0.01 0.52    -0.90    -0.27     0.08     0.45 #> beta[bsa:.trtclassIL blocker]           0.34    0.01 0.49    -0.58     0.00     0.34     0.66 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.20    -0.17    -0.15 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.13    -0.10    -0.08 #> beta[psa:.trtclassTNFa blocker]        -0.07    0.00 0.21    -0.47    -0.21    -0.07     0.07 #> beta[psa:.trtclassIL blocker]          -0.01    0.00 0.18    -0.37    -0.14    -0.02     0.11 #> d[ETN]                                  1.56    0.00 0.14     1.27     1.47     1.55     1.64 #> d[IXE_Q2W]                              2.98    0.00 0.16     2.69     2.89     2.97     3.07 #> d[IXE_Q4W]                              2.56    0.00 0.15     2.26     2.47     2.56     2.65 #> d[SEC_150]                              2.12    0.01 0.24     1.63     1.99     2.12     2.26 #> d[SEC_300]                              2.42    0.01 0.23     1.94     2.29     2.43     2.56 #> lp__                                -1659.48    0.15 4.74 -1669.44 -1662.49 -1659.29 -1656.19 #> tau                                     0.19    0.00 0.12     0.02     0.11     0.17     0.25 #>                                        97.5% n_eff Rhat #> beta[durnpso]                           0.17  5108    1 #> beta[prevsys]                           0.18  5446    1 #> beta[bsa]                               0.74  4432    1 #> beta[weight]                            0.10  4829    1 #> beta[psa]                               0.27  5093    1 #> beta[durnpso:.trtclassTNFa blocker]     0.12  5430    1 #> beta[durnpso:.trtclassIL blocker]       0.12  6233    1 #> beta[prevsys:.trtclassTNFa blocker]     0.54  5304    1 #> beta[prevsys:.trtclassIL blocker]       0.39  5934    1 #> beta[bsa:.trtclassTNFa blocker]         1.13  4636    1 #> beta[bsa:.trtclassIL blocker]           1.33  5485    1 #> beta[weight:.trtclassTNFa blocker]     -0.10  4805    1 #> beta[weight:.trtclassIL blocker]       -0.04  6214    1 #> beta[psa:.trtclassTNFa blocker]         0.33  5313    1 #> beta[psa:.trtclassIL blocker]           0.36  5160    1 #> d[ETN]                                  1.86  1477    1 #> d[IXE_Q2W]                              3.34  1128    1 #> d[IXE_Q4W]                              2.89  1530    1 #> d[SEC_150]                              2.59  1311    1 #> d[SEC_300]                              2.84  1833    1 #> lp__                                -1651.10  1045    1 #> tau                                     0.48   609    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:41:25 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_RE, pars = c(\"d\", \"beta\", \"tau\", \"mu\", \"delta\")) pairs(pso_fit_RE, pars = c(\"delta[UNCOVER-2: ETN]\", \"d[ETN]\", \"tau\", \"lp__\")) plot_prior_posterior(pso_fit_RE, prior = c(\"intercept\", \"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"model-comparison","dir":"Articles","previous_headings":"Initial analysis","what":"Model comparison","title":"Example: Plaque psoriasis ML-NMR","text":"model fit FE RE models can checked using dic() function. DIC similar FE RE models, suggesting little evidence residual heterogeneity.","code":"(pso_dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 3129.5 (on 3858 data points) #>                pD: 24.2 #>               DIC: 3153.7 (pso_dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 3123.5 (on 3858 data points) #>                pD: 28.3 #>               DIC: 3151.8"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"producing-relative-effects-and-event-probabilities","dir":"Articles","previous_headings":"Initial analysis","what":"Producing relative effects and event probabilities","title":"Example: Plaque psoriasis ML-NMR","text":"Parameter estimates can plotted using plot() method, example examine estimated regression coefficients:  Plots posterior summaries based ggdist package, allows great degree flexibility, can customised using ggplot2 commands. command specify \"halfeye\" plot, shows posterior density along posterior medians (points) 95% Credible Intervals (thin line) 66% inner bands (thicker line) default. details plotting options see ?plot.nma_summary. can produce population-adjusted relative effects study population network using relative_effects() function.  Predicted probabilities achieving PASI 75 study population treatment produced using predict() method. argument type = \"reponse\" specifies want predicted probabilities, rather probit probabilities.  can produce population-adjusted ranks, rank probabilities, cumulative rank probabilities study population using posterior_ranks() posterior_rank_probs() functions (although ranks unchanged populations, distributions effect modifiers similar). specify lower_better = FALSE, since higher outcome better (higher chance achieving PASI 75).    estimates (relative effects, predictions, rankings) can also produced specific target population populations providing suitable newdata argument function (baseline distribution predict()). produce population-adjusted relative effects (corresponding rankings) chosen target population, require mean covariate values population. example, newdata provide following mean covariate values: Population-adjusted relative effects target population calculated using relative_effects() function, can plotted corresponding plot() method:  absolute predictions, require information full covariate distribution target population, just mean values. IPD available target population, newdata simply data frame IPD. AgD available target population, newdata must data frame added integration points created using add_integration() function. example, suppose aggregate target population introduced following covariate means standard deviations (continuous covariates) proportions (discrete covariates): add integration points data frame similar manner . , need supply correlation matrix joint covariate distribution; use weighted mean correlation matrix computed earlier IPD network, stored network object int_cor. Predicted probabilities achieving PASI 75 target population, given \\(N(-1.75, 0.08^2)\\) distribution baseline probit-probability response Placebo (reference levels covariates), produced using predict() method:","code":"plot(pso_fit_FE,      pars = \"beta\",      stat = \"halfeye\",      ref_line = 0) (pso_releff_FE <- relative_effects(pso_fit_FE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[FIXTURE: ETN]     1.66 0.09 1.49 1.60 1.66 1.72  1.84     4543     3289    1 #> d[FIXTURE: IXE_Q2W] 3.03 0.10 2.84 2.96 3.03 3.09  3.22     5637     3013    1 #> d[FIXTURE: IXE_Q4W] 2.62 0.09 2.43 2.55 2.61 2.68  2.80     5232     3561    1 #> d[FIXTURE: SEC_150] 2.22 0.12 2.00 2.14 2.22 2.30  2.45     5374     3357    1 #> d[FIXTURE: SEC_300] 2.52 0.12 2.28 2.44 2.52 2.60  2.76     4930     3114    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-1: ETN]     1.51 0.09 1.34 1.45 1.51 1.56  1.67     5064     3489    1 #> d[UNCOVER-1: IXE_Q2W] 2.92 0.09 2.76 2.86 2.92 2.98  3.09     5868     2864    1 #> d[UNCOVER-1: IXE_Q4W] 2.51 0.08 2.35 2.46 2.51 2.57  2.67     5419     3233    1 #> d[UNCOVER-1: SEC_150] 2.12 0.12 1.88 2.03 2.11 2.20  2.35     5796     3307    1 #> d[UNCOVER-1: SEC_300] 2.42 0.12 2.17 2.34 2.42 2.50  2.66     5110     3199    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-2: ETN]     1.51 0.08 1.35 1.45 1.51 1.56  1.66     5052     3558    1 #> d[UNCOVER-2: IXE_Q2W] 2.92 0.08 2.76 2.87 2.92 2.98  3.09     5997     3188    1 #> d[UNCOVER-2: IXE_Q4W] 2.51 0.08 2.36 2.46 2.51 2.56  2.66     5530     3476    1 #> d[UNCOVER-2: SEC_150] 2.11 0.12 1.89 2.03 2.11 2.20  2.34     6016     3742    1 #> d[UNCOVER-2: SEC_300] 2.42 0.12 2.18 2.34 2.42 2.50  2.65     5256     3042    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-3: ETN]     1.53 0.08 1.37 1.48 1.53 1.58  1.68     4903     3396    1 #> d[UNCOVER-3: IXE_Q2W] 2.94 0.08 2.78 2.88 2.94 3.00  3.11     5970     3193    1 #> d[UNCOVER-3: IXE_Q4W] 2.53 0.08 2.37 2.47 2.53 2.58  2.68     5496     3473    1 #> d[UNCOVER-3: SEC_150] 2.13 0.11 1.91 2.05 2.13 2.21  2.35     5953     3585    1 #> d[UNCOVER-3: SEC_300] 2.43 0.12 2.20 2.36 2.44 2.51  2.67     5248     3062    1 plot(pso_releff_FE, ref_line = 0) (pso_pred_FE <- predict(pso_fit_FE, type = \"response\")) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[FIXTURE: PBO]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     4718     3063    1 #> pred[FIXTURE: ETN]     0.46 0.02 0.41 0.44 0.46 0.47  0.50     7978     2953    1 #> pred[FIXTURE: IXE_Q2W] 0.89 0.02 0.85 0.88 0.89 0.90  0.92     7144     3334    1 #> pred[FIXTURE: IXE_Q4W] 0.80 0.03 0.74 0.78 0.80 0.81  0.84     7720     3409    1 #> pred[FIXTURE: SEC_150] 0.67 0.03 0.62 0.65 0.67 0.69  0.72    10936     2962    1 #> pred[FIXTURE: SEC_300] 0.77 0.02 0.72 0.75 0.77 0.79  0.81     8187     3246    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-1: PBO]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     5942     3276    1 #> pred[UNCOVER-1: ETN]     0.46 0.03 0.40 0.44 0.46 0.48  0.52     6153     3301    1 #> pred[UNCOVER-1: IXE_Q2W] 0.90 0.01 0.88 0.89 0.90 0.91  0.92     8804     2940    1 #> pred[UNCOVER-1: IXE_Q4W] 0.81 0.02 0.78 0.80 0.81 0.82  0.84     9424     3480    1 #> pred[UNCOVER-1: SEC_150] 0.69 0.04 0.60 0.66 0.69 0.72  0.76     7673     3381    1 #> pred[UNCOVER-1: SEC_300] 0.78 0.04 0.71 0.76 0.79 0.81  0.85     6496     3506    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-2: PBO]     0.05 0.01 0.03 0.04 0.05 0.05  0.06     6020     3153    1 #> pred[UNCOVER-2: ETN]     0.42 0.02 0.38 0.41 0.42 0.43  0.46     8032     3162    1 #> pred[UNCOVER-2: IXE_Q2W] 0.88 0.01 0.86 0.87 0.88 0.89  0.90     7628     3223    1 #> pred[UNCOVER-2: IXE_Q4W] 0.78 0.02 0.75 0.77 0.78 0.79  0.81     8345     3199    1 #> pred[UNCOVER-2: SEC_150] 0.65 0.04 0.57 0.62 0.65 0.68  0.73     8986     3470    1 #> pred[UNCOVER-2: SEC_300] 0.75 0.04 0.68 0.73 0.75 0.78  0.82     7090     3391    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-3: PBO]     0.08 0.01 0.06 0.07 0.08 0.08  0.10     5959     3278    1 #> pred[UNCOVER-3: ETN]     0.53 0.02 0.49 0.52 0.53 0.54  0.57     9789     3050    1 #> pred[UNCOVER-3: IXE_Q2W] 0.93 0.01 0.91 0.92 0.93 0.93  0.94     7060     3305    1 #> pred[UNCOVER-3: IXE_Q4W] 0.85 0.01 0.83 0.85 0.85 0.86  0.88     9515     3188    1 #> pred[UNCOVER-3: SEC_150] 0.75 0.03 0.68 0.72 0.75 0.77  0.81    10127     3055    1 #> pred[UNCOVER-3: SEC_300] 0.83 0.03 0.77 0.81 0.83 0.85  0.88     7898     3218    1 plot(pso_pred_FE, ref_line = c(0, 1)) (pso_ranks_FE <- posterior_ranks(pso_fit_FE, lower_better = FALSE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[FIXTURE: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[FIXTURE: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[FIXTURE: IXE_Q2W] 1.00 0.02    1   1   1   1     1     4016     4016    1 #> rank[FIXTURE: IXE_Q4W] 2.22 0.42    2   2   2   2     3     4384       NA    1 #> rank[FIXTURE: SEC_150] 4.00 0.03    4   4   4   4     4     4021       NA    1 #> rank[FIXTURE: SEC_300] 2.78 0.42    2   3   3   3     3     4335     4021    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-1: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-1: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-1: IXE_Q2W] 1.00 0.02    1   1   1   1     1     4016     4016    1 #> rank[UNCOVER-1: IXE_Q4W] 2.22 0.42    2   2   2   2     3     4384       NA    1 #> rank[UNCOVER-1: SEC_150] 4.00 0.03    4   4   4   4     4     4021       NA    1 #> rank[UNCOVER-1: SEC_300] 2.78 0.42    2   3   3   3     3     4335     4021    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-2: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-2: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-2: IXE_Q2W] 1.00 0.02    1   1   1   1     1     4016     4016    1 #> rank[UNCOVER-2: IXE_Q4W] 2.22 0.42    2   2   2   2     3     4384       NA    1 #> rank[UNCOVER-2: SEC_150] 4.00 0.03    4   4   4   4     4     4021       NA    1 #> rank[UNCOVER-2: SEC_300] 2.78 0.42    2   3   3   3     3     4335     4021    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-3: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-3: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-3: IXE_Q2W] 1.00 0.02    1   1   1   1     1     4016     4016    1 #> rank[UNCOVER-3: IXE_Q4W] 2.22 0.42    2   2   2   2     3     4384       NA    1 #> rank[UNCOVER-3: SEC_150] 4.00 0.03    4   4   4   4     4     4021       NA    1 #> rank[UNCOVER-3: SEC_300] 2.78 0.42    2   3   3   3     3     4335     4021    1 plot(pso_ranks_FE) (pso_rankprobs_FE <- posterior_rank_probs(pso_fit_FE, lower_better = FALSE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             0      0.00      0.00         0         0         1 #> d[FIXTURE: ETN]             0      0.00      0.00         0         1         0 #> d[FIXTURE: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[FIXTURE: IXE_Q4W]         0      0.78      0.22         0         0         0 #> d[FIXTURE: SEC_150]         0      0.00      0.00         1         0         0 #> d[FIXTURE: SEC_300]         0      0.22      0.77         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-1: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-1: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-1: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-1: IXE_Q4W]         0      0.78      0.22         0         0         0 #> d[UNCOVER-1: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-1: SEC_300]         0      0.22      0.77         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-2: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-2: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-2: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-2: IXE_Q4W]         0      0.78      0.22         0         0         0 #> d[UNCOVER-2: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-2: SEC_300]         0      0.22      0.77         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-3: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-3: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-3: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-3: IXE_Q4W]         0      0.78      0.22         0         0         0 #> d[UNCOVER-3: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-3: SEC_300]         0      0.22      0.77         0         0         0 plot(pso_rankprobs_FE) (pso_cumrankprobs_FE <- posterior_rank_probs(pso_fit_FE, lower_better = FALSE, cumulative = TRUE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             0      0.00         0         0         0         1 #> d[FIXTURE: ETN]             0      0.00         0         0         1         1 #> d[FIXTURE: IXE_Q2W]         1      1.00         1         1         1         1 #> d[FIXTURE: IXE_Q4W]         0      0.78         1         1         1         1 #> d[FIXTURE: SEC_150]         0      0.00         0         1         1         1 #> d[FIXTURE: SEC_300]         0      0.22         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-1: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-1: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-1: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-1: IXE_Q4W]         0      0.78         1         1         1         1 #> d[UNCOVER-1: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-1: SEC_300]         0      0.22         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-2: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-2: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-2: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-2: IXE_Q4W]         0      0.78         1         1         1         1 #> d[UNCOVER-2: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-2: SEC_300]         0      0.22         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-3: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-3: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-3: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-3: IXE_Q4W]         0      0.78         1         1         1         1 #> d[UNCOVER-3: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-3: SEC_300]         0      0.22         1         1         1         1 plot(pso_cumrankprobs_FE) new_agd_means <- tibble(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3) (pso_releff_FE_new <- relative_effects(pso_fit_FE, newdata = new_agd_means)) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[New 1: ETN]     1.25 0.23 0.81 1.09 1.26 1.41  1.71     6261     2896    1 #> d[New 1: IXE_Q2W] 2.89 0.23 2.45 2.73 2.89 3.04  3.35     7599     3152    1 #> d[New 1: IXE_Q4W] 2.48 0.23 2.05 2.32 2.48 2.63  2.93     7380     3239    1 #> d[New 1: SEC_150] 2.08 0.23 1.65 1.93 2.08 2.24  2.54     7068     3223    1 #> d[New 1: SEC_300] 2.39 0.23 1.94 2.22 2.38 2.54  2.87     6977     3028    1 plot(pso_releff_FE_new, ref_line = 0) new_agd_int <- tibble(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1 ) new_agd_int <- add_integration(new_agd_int,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   cor = pso_net$int_cor,   n_int = 64) (pso_pred_FE_new <- predict(pso_fit_FE,                              type = \"response\",                             newdata = new_agd_int,                             baseline = distr(qnorm, -1.75, 0.08))) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: PBO]     0.06 0.03 0.03 0.04 0.06 0.08  0.12     5297     3042    1 #> pred[New 1: ETN]     0.37 0.06 0.26 0.33 0.37 0.41  0.49     6775     3741    1 #> pred[New 1: IXE_Q2W] 0.90 0.03 0.84 0.88 0.90 0.92  0.94     6010     3687    1 #> pred[New 1: IXE_Q4W] 0.81 0.04 0.72 0.78 0.81 0.83  0.87     5833     3638    1 #> pred[New 1: SEC_150] 0.68 0.06 0.57 0.64 0.68 0.72  0.79     5490     3853    1 #> pred[New 1: SEC_300] 0.78 0.05 0.68 0.75 0.78 0.81  0.86     5377     3620    1 plot(pso_pred_FE_new, ref_line = c(0, 1))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"extended_analysis","dir":"Articles","previous_headings":"","what":"Extended analysis","title":"Example: Plaque psoriasis ML-NMR","text":"now extend network include five studies (four AgD one IPD), recreating analysis Phillippo et al. (2022). larger network allows us assess key assumptions underlying population adjustment.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"preparing-the-data-1","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Preparing the data","title":"Example: Plaque psoriasis ML-NMR","text":"begin, , data transformations covariates set treatment class variable trtclass. small number individuals missing values IPD, simply exclude analysis.","code":"# IPD studies pso_ipd <- plaque_psoriasis_ipd %>%    mutate(     # Variable transformations     bsa = bsa / 100,     weight = weight / 10,     durnpso = durnpso / 10,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL-17 blocker\",                          trtn == 4 ~ \"TNFa blocker\",                          trtn == 7 ~ \"IL-12/23 blocker\"),     # Check complete cases for covariates of interest     is_complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   ) %>%    arrange(studyc, trtn)  # AgD studies pso_agd <- plaque_psoriasis_agd %>%    mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,      bsa_sd = bsa_sd / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     prevsys = prevsys / 100,     psa = psa / 100,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL-17 blocker\",                          trtn == 4 ~ \"TNFa blocker\",                          trtn == 7 ~ \"IL-12/23 blocker\")     ) %>%    arrange(studyc, trtn) pso_ipd %>%    group_by(studyc) %>%    summarise(n_total = n(),             n_missing = sum(!is_complete),              pct_missing = mean(!is_complete) * 100) #> # A tibble: 4 × 4 #>   studyc    n_total n_missing pct_missing #>   <chr>       <int>     <int>       <dbl> #> 1 IXORA-S       260         0       0     #> 2 UNCOVER-1    1296         0       0     #> 3 UNCOVER-2    1221         2       0.164 #> 4 UNCOVER-3    1341         2       0.149  pso_ipd <- filter(pso_ipd, is_complete)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"creating-the-network-1","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Creating the network","title":"Example: Plaque psoriasis ML-NMR","text":"Next set network. set IPD set_ipd() AgD (arm-based) set_agd_arm(), combine together using combine_network(). specify ordered categorical (multinomial) outcome using multi() helper function. outcome data “inclusive” format, .e. lowest category sample size (1 IPD), second category counts achieving PASI 75 greater (\\(\\ge 75\\%\\) reduction symptoms), third counts achieving PASI 90 greater (\\(\\ge 90\\%\\) reduction), final category counts achieving PASI 100 (\\(100\\%\\) reduction).2 specify treatment classes trt_class = trtclass. create network plot using plot() function applied pso_net network object, choosing scale edges nodes number studies/sample size (weight_edges weight_nodes = TRUE), colour treatment nodes class (show_trt_class = TRUE), nudge treatment names away nodes (nudge = 0.1). customise plot using ggplot syntax alter colour scheme.","code":"pso_net <- combine_network(   set_ipd(pso_ipd,     study = studyc,     trt = trtc,     r = multi(r0 = 1,                PASI75 = pasi75,               PASI90 = pasi90,               PASI100 = pasi100,               type = \"ordered\", inclusive = TRUE),     trt_class = trtclass),   set_agd_arm(pso_agd,     study = studyc,     trt = trtc,     r = multi(r0 = pasi75_n,                PASI75 = pasi75_r,               PASI90 = pasi90_r,               PASI100 = pasi100_r,               type = \"ordered\", inclusive = TRUE),     trt_class = trtclass) )  pso_net #> A network with 4 IPD studies, and 5 AgD studies (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: PBO | IXE_Q2W | IXE_Q4W       #>  UNCOVER-2 4: PBO | IXE_Q2W | IXE_Q4W | ETN #>  UNCOVER-3 4: PBO | IXE_Q2W | IXE_Q4W | ETN #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study    Treatment arms                   #>  CLEAR    2: SEC_300 | UST                 #>  ERASURE  3: PBO | SEC_150 | SEC_300       #>  FEATURE  3: PBO | SEC_150 | SEC_300       #>  FIXTURE  4: PBO | ETN | SEC_150 | SEC_300 #>  JUNCTURE 3: PBO | SEC_150 | SEC_300       #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 7, in 4 classes #> Total number of studies: 9 #> Reference treatment is: PBO #> Network is connected class_pal <- c(\"#D95F02\", \"#7570B3\", \"#E7298A\", \"#E6AB02\")  plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE, nudge = 0.1) +   ggraph::scale_edge_colour_manual(\"Data\",                                     values = c(AgD = \"#113259\", IPD = \"#55A480\"),                                    guide = guide_legend(override.aes = list(edge_width = 2))) +   scale_fill_manual(\"Treatment class\",                      values = class_pal,                     aesthetics = c(\"fill\", \"colour\"),                     guide = guide_legend(override.aes = list(size = 2))) #> Scale for edge_colour is already present. #> Adding another scale for edge_colour, which will replace the existing scale. #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale. #> Warning: Duplicated `override.aes` is ignored."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"numerical-integration-for-ml-nmr-models","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Numerical integration for ML-NMR models","title":"Example: Plaque psoriasis ML-NMR","text":"add integration points AgD studies network using add_integration() function, specifying chosen marginal distribution covariate using distr() function. , specify Gamma distributions weight duration psoriasis, logit-Normal distribution body surface area, Bernoulli distributions previous systemic treatment psoriatic arthritis binary covariates. Since know correlations covariates AgD studies, impute weighted mean correlations IPD studies (default option).","code":"pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"ml-nmr-model","dir":"Articles","previous_headings":"Extended analysis","what":"ML-NMR model","title":"Example: Plaque psoriasis ML-NMR","text":"Using nma() function, fit (fixed effect) ML-NMR model includes main effects (prognostic terms) covariate-treatment interactions (effect-modifying terms) five covariates. Ideally, fit independent interaction terms treatment; however, requires either IPD several AgD studies range covariate values treatment. data insufficient fit independent interaction terms treatment, make shared effect modifier assumption within class treatments (Phillippo et al. 2016) specify common interaction terms within treatment class (class_interactions = \"common\"). , specify \\(\\mathrm{N}(0, 10^2)\\) prior distributions study-specific intercepts, treatment effects, regression parameters. However, since now ordered multinomial likelihood also need specify priors differences latent cutoffs outcome category; choose improper flat prior \\(\\mathrm{U}(-\\infty,\\infty)\\) automatically truncated meet ordering constraints (prior_aux = flat()).","code":"pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                    regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_aux = flat(),                   QR = TRUE,                   init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit_FE #> A fixed effects ML-NMR with a ordered likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8159830 0.6576489 0.2987820 8.9097263 0.2104826  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.03    0.00 0.06    -0.08    -0.01     0.03     0.08 #> beta[prevsys]                              -0.17    0.00 0.16    -0.49    -0.28    -0.17    -0.06 #> beta[bsa]                                  -0.10    0.01 0.45    -1.01    -0.40    -0.08     0.21 #> beta[weight]                                0.04    0.00 0.03    -0.01     0.02     0.04     0.06 #> beta[psa]                                  -0.08    0.00 0.17    -0.42    -0.20    -0.08     0.03 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.16    -0.07    -0.02     0.03 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.06    0.00 0.10    -0.26    -0.13    -0.07     0.00 #> beta[durnpso:.trtclassIL-17 blocker]       -0.02    0.00 0.06    -0.14    -0.07    -0.02     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.19    0.00 0.19    -0.18     0.07     0.19     0.32 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.45    0.01 0.34    -0.24     0.24     0.47     0.68 #> beta[prevsys:.trtclassIL-17 blocker]        0.16    0.00 0.17    -0.17     0.05     0.16     0.28 #> beta[bsa:.trtclassTNFa blocker]             0.24    0.01 0.51    -0.73    -0.11     0.22     0.57 #> beta[bsa:.trtclassIL-12/23 blocker]         0.61    0.01 0.68    -0.71     0.14     0.61     1.07 #> beta[bsa:.trtclassIL-17 blocker]            0.27    0.01 0.47    -0.63    -0.06     0.26     0.58 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.18    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.18    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.05    0.00 0.20    -0.43    -0.18    -0.04     0.08 #> beta[psa:.trtclassIL-12/23 blocker]         0.12    0.01 0.33    -0.51    -0.11     0.12     0.36 #> beta[psa:.trtclassIL-17 blocker]            0.10    0.00 0.18    -0.24    -0.02     0.10     0.21 #> d[ETN]                                      1.58    0.00 0.07     1.44     1.53     1.58     1.63 #> d[IXE_Q2W]                                  2.91    0.00 0.07     2.76     2.86     2.91     2.96 #> d[IXE_Q4W]                                  2.69    0.00 0.08     2.54     2.64     2.69     2.74 #> d[SEC_150]                                  2.19    0.00 0.08     2.03     2.13     2.19     2.24 #> d[SEC_300]                                  2.60    0.00 0.08     2.45     2.54     2.60     2.65 #> d[UST]                                      2.13    0.00 0.11     1.91     2.06     2.13     2.20 #> lp__                                    -7640.27    0.11 4.31 -7649.63 -7642.96 -7639.97 -7637.16 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.65     0.68     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.49     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.15  2512    1 #> beta[prevsys]                               0.14  2701    1 #> beta[bsa]                                   0.77  2254    1 #> beta[weight]                                0.10  2331    1 #> beta[psa]                                   0.24  3019    1 #> beta[durnpso:.trtclassTNFa blocker]         0.12  2678    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.14  3490    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.10  2899    1 #> beta[prevsys:.trtclassTNFa blocker]         0.55  2824    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.11  4293    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.48  3128    1 #> beta[bsa:.trtclassTNFa blocker]             1.27  2433    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.93  2921    1 #> beta[bsa:.trtclassIL-17 blocker]            1.25  2728    1 #> beta[weight:.trtclassTNFa blocker]         -0.10  2590    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.01  3473    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  2731    1 #> beta[psa:.trtclassTNFa blocker]             0.33  2990    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.77  3967    1 #> beta[psa:.trtclassIL-17 blocker]            0.46  3516    1 #> d[ETN]                                      1.72  1969    1 #> d[IXE_Q2W]                                  3.06  2104    1 #> d[IXE_Q4W]                                  2.84  2327    1 #> d[SEC_150]                                  2.36  2267    1 #> d[SEC_300]                                  2.76  2396    1 #> d[UST]                                      2.34  3215    1 #> lp__                                    -7632.94  1664    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  3323    1 #> cc[PASI100]                                 1.58  2862    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Aug 28 12:56:36 2022. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1)."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-assumptions","dir":"Articles","previous_headings":"Extended analysis","what":"Assessing assumptions","title":"Example: Plaque psoriasis ML-NMR","text":"first analysis, small network made assessing assumptions difficult. larger network (although still nine studies) greater opportunity assess key assumptions. key assumption made ML-NMR (indeed population adjustment methods connected networks) conditional constancy relative effects assumption (Phillippo et al. 2016). means unobserved effect modifiers, relative effects constant given included effect-modifying covariates. assumption implies residual heterogeneity inconsistency, can assessed using standard network meta-analysis techniques. assess residual heterogeneity using random effects model, residual inconsistency using unrelated mean effects (UME) model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-residual-heterogeneity-with-a-random-effects-ml-nmr","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Assessing residual heterogeneity with a random effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"First, fit random effects model assess residual heterogeneity. call nma() function identical fixed effect model , except now specify trt_effects = \"random\" need provide prior -study heterogeneity (choose \\(\\textrm{half-N}(0, 2.5^2)\\) prior prior_het = half_normal(scale = 2.5). estimated -study heterogeneity standard deviation tau small compared relative treatment effects. compare model fit using DIC: DIC lower RE model, indicating may residual heterogeneity network conditional constancy relative effects assumption may invalid—may additional effect modifiers accounted . result different actual analysis reported Phillippo et al. (2022), since using synthetic IPD simulated closely resemble original IPD. actual analysis DIC similar FE RE models, might choose parsimonious FE model based DIC alone, evidence residual heterogeneity network.","code":"pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                    regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_aux = flat(),                   prior_het = half_normal(scale = 2.5),                   QR = TRUE,                   init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. #> Warning: There were 1 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems pso_fit_RE #> A random effects ML-NMR with a ordered likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8159830 0.6576489 0.2987820 8.9097263 0.2104826  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.04    0.00 0.06    -0.08    -0.01     0.04     0.08 #> beta[prevsys]                              -0.16    0.00 0.16    -0.46    -0.26    -0.15    -0.06 #> beta[bsa]                                  -0.14    0.01 0.46    -1.09    -0.45    -0.13     0.17 #> beta[weight]                                0.05    0.00 0.03    -0.01     0.03     0.05     0.07 #> beta[psa]                                  -0.07    0.00 0.17    -0.40    -0.18    -0.06     0.04 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.17    -0.07    -0.02     0.03 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.07    0.00 0.10    -0.27    -0.14    -0.07     0.01 #> beta[durnpso:.trtclassIL-17 blocker]       -0.03    0.00 0.06    -0.15    -0.07    -0.02     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.19    0.00 0.18    -0.17     0.07     0.19     0.31 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.43    0.00 0.35    -0.27     0.20     0.44     0.67 #> beta[prevsys:.trtclassIL-17 blocker]        0.15    0.00 0.16    -0.18     0.04     0.15     0.26 #> beta[bsa:.trtclassTNFa blocker]             0.27    0.01 0.53    -0.73    -0.08     0.25     0.61 #> beta[bsa:.trtclassIL-12/23 blocker]         0.66    0.01 0.66    -0.65     0.21     0.67     1.09 #> beta[bsa:.trtclassIL-17 blocker]            0.32    0.01 0.48    -0.58    -0.01     0.31     0.63 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.19    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.18    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.06    0.00 0.20    -0.46    -0.20    -0.06     0.07 #> beta[psa:.trtclassIL-12/23 blocker]         0.11    0.00 0.33    -0.53    -0.10     0.11     0.34 #> beta[psa:.trtclassIL-17 blocker]            0.08    0.00 0.18    -0.27    -0.04     0.08     0.20 #> d[ETN]                                      1.59    0.00 0.11     1.38     1.52     1.59     1.66 #> d[IXE_Q2W]                                  2.93    0.00 0.11     2.73     2.86     2.93     3.00 #> d[IXE_Q4W]                                  2.71    0.00 0.12     2.49     2.64     2.71     2.78 #> d[SEC_150]                                  2.21    0.00 0.12     1.99     2.13     2.21     2.28 #> d[SEC_300]                                  2.64    0.00 0.12     2.42     2.56     2.63     2.71 #> d[UST]                                      2.17    0.00 0.17     1.85     2.06     2.16     2.27 #> lp__                                    -7646.77    0.21 6.32 -7660.09 -7650.88 -7646.44 -7642.40 #> tau                                         0.13    0.00 0.07     0.02     0.09     0.13     0.17 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.66     0.68     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.49     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.16  3817    1 #> beta[prevsys]                               0.16  4212    1 #> beta[bsa]                                   0.73  3325    1 #> beta[weight]                                0.10  3585    1 #> beta[psa]                                   0.27  4167    1 #> beta[durnpso:.trtclassTNFa blocker]         0.12  3797    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.13  5280    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.10  4181    1 #> beta[prevsys:.trtclassTNFa blocker]         0.54  4064    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.06  5604    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.46  4509    1 #> beta[bsa:.trtclassTNFa blocker]             1.31  3573    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.98  4347    1 #> beta[bsa:.trtclassIL-17 blocker]            1.29  3634    1 #> beta[weight:.trtclassTNFa blocker]         -0.10  3833    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.00  5021    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  4493    1 #> beta[psa:.trtclassTNFa blocker]             0.35  4225    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.75  6190    1 #> beta[psa:.trtclassIL-17 blocker]            0.43  4403    1 #> d[ETN]                                      1.81  2805    1 #> d[IXE_Q2W]                                  3.15  3031    1 #> d[IXE_Q4W]                                  2.95  2966    1 #> d[SEC_150]                                  2.47  2726    1 #> d[SEC_300]                                  2.88  2575    1 #> d[UST]                                      2.52  2667    1 #> lp__                                    -7635.39   899    1 #> tau                                         0.29   620    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  5665    1 #> cc[PASI100]                                 1.58  6212    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Aug 28 14:09:25 2022. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). (pso_dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 8811.4 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.4 (pso_dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 8800.1 (on 12387 data points) #>                pD: 42.3 #>               DIC: 8842.4"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-residual-inconsistency-with-an-unrelated-mean-effects-ml-nmr","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Assessing residual inconsistency with an unrelated mean effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"assess residual inconsistency using unrelated mean effects model (Dias et al. 2011). , call nma() function identical, except time specify consistency = \"ume\". Node-splitting also possibility (consistency = \"nodesplit\"), takes substantially longer since model re-run node-split comparison. proceed analysis Phillippo et al. (2022) fit fixed effect UME model (since evidence heterogeneity actual analysis); however, recreated analysis using synthetic IPD evidence heterogeneity really fit random effects UME model instead. compare model fit FE ML-NMR model using DIC. DIC values similar FE model (assuming consistency) UME (inconsistency) model, suggests evidence inconsistency overall. also important compare residual deviance contributions model see whether points fit better UME model, can also indicate inconsistency. Using plot() function produces “dev-dev” plot residual deviance contributions either model.  points lie line equality, evidence inconsistency. random effects models fitted heterogeneity estimates also compared drop tau UME model can also indicate inconsistency.","code":"pso_fit_UME <- nma(pso_net,                     trt_effects = \"fixed\",                    consistency = \"ume\",                    link = \"probit\",                     regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                    class_interactions = \"common\",                    prior_intercept = normal(scale = 10),                    prior_trt = normal(scale = 10),                    prior_reg = normal(scale = 10),                    prior_aux = flat(),                    QR = TRUE,                    init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit_UME #> A fixed effects ML-NMR with a ordered likelihood (probit link). #> An inconsistency model ('ume') was fitted. #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8159830 0.6576489 0.2987820 8.9097263 0.2104826  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.03    0.00 0.06    -0.09    -0.01     0.03     0.07 #> beta[prevsys]                              -0.17    0.00 0.16    -0.47    -0.27    -0.17    -0.06 #> beta[bsa]                                  -0.09    0.01 0.44    -0.98    -0.38    -0.08     0.21 #> beta[weight]                                0.04    0.00 0.03    -0.01     0.02     0.04     0.06 #> beta[psa]                                  -0.08    0.00 0.17    -0.42    -0.20    -0.08     0.03 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.16    -0.07    -0.02     0.03 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.06    0.00 0.10    -0.26    -0.13    -0.06     0.01 #> beta[durnpso:.trtclassIL-17 blocker]       -0.02    0.00 0.06    -0.14    -0.06    -0.02     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.19    0.00 0.18    -0.16     0.07     0.19     0.31 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.45    0.01 0.35    -0.24     0.21     0.46     0.70 #> beta[prevsys:.trtclassIL-17 blocker]        0.16    0.00 0.16    -0.16     0.05     0.16     0.27 #> beta[bsa:.trtclassTNFa blocker]             0.22    0.01 0.50    -0.76    -0.12     0.20     0.56 #> beta[bsa:.trtclassIL-12/23 blocker]         0.59    0.01 0.67    -0.72     0.13     0.60     1.05 #> beta[bsa:.trtclassIL-17 blocker]            0.26    0.01 0.46    -0.64    -0.05     0.25     0.56 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.18    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.18    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.05    0.00 0.20    -0.44    -0.18    -0.05     0.09 #> beta[psa:.trtclassIL-12/23 blocker]         0.12    0.01 0.35    -0.54    -0.12     0.12     0.36 #> beta[psa:.trtclassIL-17 blocker]            0.10    0.00 0.18    -0.26    -0.03     0.09     0.22 #> d[ETN vs. PBO]                              1.58    0.00 0.07     1.44     1.53     1.58     1.63 #> d[IXE_Q2W vs. PBO]                          2.91    0.00 0.07     2.77     2.86     2.91     2.96 #> d[IXE_Q4W vs. PBO]                          2.69    0.00 0.07     2.54     2.64     2.69     2.74 #> d[SEC_150 vs. PBO]                          2.19    0.00 0.08     2.02     2.13     2.19     2.25 #> d[SEC_300 vs. PBO]                          2.60    0.00 0.08     2.44     2.54     2.60     2.65 #> d[UST vs. IXE_Q2W]                         -0.78    0.00 0.16    -1.09    -0.89    -0.78    -0.68 #> d[UST vs. SEC_300]                         -0.47    0.00 0.09    -0.65    -0.53    -0.47    -0.41 #> lp__                                    -7640.40    0.10 4.39 -7650.22 -7643.16 -7639.97 -7637.34 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.65     0.68     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.49     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.15  2591    1 #> beta[prevsys]                               0.14  2698    1 #> beta[bsa]                                   0.74  2778    1 #> beta[weight]                                0.10  2854    1 #> beta[psa]                                   0.25  2997    1 #> beta[durnpso:.trtclassTNFa blocker]         0.12  2850    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.13  3732    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.11  3146    1 #> beta[prevsys:.trtclassTNFa blocker]         0.54  2803    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.09  4034    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.48  3191    1 #> beta[bsa:.trtclassTNFa blocker]             1.20  2846    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.91  3889    1 #> beta[bsa:.trtclassIL-17 blocker]            1.19  3282    1 #> beta[weight:.trtclassTNFa blocker]         -0.09  3169    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.00  4218    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  3421    1 #> beta[psa:.trtclassTNFa blocker]             0.35  3036    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.81  4680    1 #> beta[psa:.trtclassIL-17 blocker]            0.45  3454    1 #> d[ETN vs. PBO]                              1.73  2815    1 #> d[IXE_Q2W vs. PBO]                          3.05  2892    1 #> d[IXE_Q4W vs. PBO]                          2.84  3286    1 #> d[SEC_150 vs. PBO]                          2.36  2992    1 #> d[SEC_300 vs. PBO]                          2.76  3203    1 #> d[UST vs. IXE_Q2W]                         -0.47  4990    1 #> d[UST vs. SEC_300]                         -0.29  6387    1 #> lp__                                    -7633.00  1771    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  3712    1 #> cc[PASI100]                                 1.58  3257    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Aug 28 14:26:48 2022. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). pso_dic_FE #> Residual deviance: 8811.4 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.4 (pso_dic_UME <- dic(pso_fit_UME)) #> Residual deviance: 8811.7 (on 12387 data points) #>                pD: 36.3 #>               DIC: 8848 plot(pso_dic_FE, pso_dic_UME, show_uncertainty = FALSE) +   xlab(\"Residual deviance - consistency model\") +   ylab(\"Residual deviance - inconsistency (UME) model\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"relaxing-the-shared-effect-modifier-assumption","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Relaxing the shared effect modifier assumption","title":"Example: Plaque psoriasis ML-NMR","text":"treatment classes network follows: fitted common interaction terms within treatment class, shared effect modifier assumption, order make model estimable available data. Note interleukin-17 blocker class one treatment; etanercept ustekinumab classes unaffected specifying class_interactions = \"common\". assess assumption simply fit independent interaction terms treatments effect modifiers sufficient data. Instead, relax assumption one covariate time, estimating independent interactions one covariate whilst keeping shared effect modifier assumption (common interactions within treatment class) covariates. specify relaxed models, need somehow mix class_interactions = \"common\" class_interactions = \"independent\" different covariates. way .trt .trtclass specials specifying regression model. see works, first note model making shared effect modifiers assumption can written equivalently using .trtclass special .trtclass special essentially factor variable containing treatment classes, available time treatment classes specified network; regression formula therefore single interaction term covariate within treatment class (result specifying class_interactions = \"common\" ). Finally, fit independent interactions single covariate, say durnpso, split using .trt special class_interactions = \"independent\" (.e. telling model combine interactions .trt within classes): Since fitting several models, let us set list model specifications iterate . Comparing model fit using DIC models similar higher DIC original model making shared effect modifier assumption covariates, exception model independent interactions weight slightly lower DIC. also visually examine differences estimated interaction terms original model (shared effect modifier assumption covariates) relaxed models (independent interactions, one covariate time).  independent interaction estimates similar common interaction estimates, much uncertainty—particularly secukinumab regimens estimated aggregate data. exception weight, suggestion covariate may interact differently secukinumab treatment regimens ixekizumab regimens. However, credible intervals secukinumab interactions wide overlap ixekizumab regimens common interaction. Overall, weak evidence shared effect modifier assumption (class interleukin-17 blockers) may invalid weight. Since fitting multiple models mindful multiple testing possibility differences occurred chance. hand, approach likely low power detect violations shared effect modifier assumption, particularly data lacking. case, results model relaxing shared effect modifier assumption weight similar original model (see Phillippo et al. 2022).","code":"data.frame(classes = pso_net$classes, treatments = pso_net$treatments) #>            classes treatments #> 1          Placebo        PBO #> 2     TNFa blocker        ETN #> 3    IL-17 blocker    IXE_Q2W #> 4    IL-17 blocker    IXE_Q4W #> 5    IL-17 blocker    SEC_150 #> 6    IL-17 blocker    SEC_300 #> 7 IL-12/23 blocker        UST regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt, class_interactions = \"common\" regression = ~(durnpso + prevsys + bsa + weight + psa)*.trtclass regression = ~(prevsys + bsa + weight + psa)*.trtclass + durnpso*.trt, class_interactions = \"independent\" noSEM_mods <- list(   durnpso = ~(prevsys + bsa + weight + psa)*.trtclass + durnpso*.trt,   prevsys = ~(durnpso + bsa + weight + psa)*.trtclass + prevsys*.trt,   bsa = ~(durnpso + prevsys + weight + psa)*.trtclass + bsa*.trt,   weight = ~(durnpso + prevsys + bsa + psa)*.trtclass + weight*.trt,   psa = ~(durnpso + prevsys + bsa + weight)*.trtclass + psa*.trt   )  noSEM_fits <- noSEM_mods  for (m in 1:length(noSEM_mods)) {   cat(\"Fitting model with independent interactions for\", names(noSEM_mods)[m], \"\\n\")      noSEM_fits[[m]] <-      nma(pso_net,          trt_effects = \"fixed\",         link = \"probit\",          regression = noSEM_mods[[m]],         class_interactions = \"independent\",         prior_intercept = normal(scale = 10),         prior_trt = normal(scale = 10),         prior_reg = normal(scale = 10),         prior_aux = flat(),         QR = TRUE,         init_r = 0.5,         # Using save_warmup = FALSE reduces memory footprint when          # fitting many models in one session         save_warmup = FALSE) } #> Fitting model with independent interactions for durnpso #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for prevsys #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for bsa #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for weight #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for psa #> Note: Setting \"PBO\" as the network reference treatment. pso_dic_FE #> Residual deviance: 8811.4 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.4 lapply(noSEM_fits, dic) #> $durnpso #> Residual deviance: 8812.5 (on 12387 data points) #>                pD: 37.7 #>               DIC: 8850.3 #>  #> $prevsys #> Residual deviance: 8813.4 (on 12387 data points) #>                pD: 37.8 #>               DIC: 8851.2 #>  #> $bsa #> Residual deviance: 8813 (on 12387 data points) #>                pD: 37.8 #>               DIC: 8850.8 #>  #> $weight #> Residual deviance: 8807.5 (on 12387 data points) #>                pD: 37.9 #>               DIC: 8845.4 #>  #> $psa #> Residual deviance: 8812.2 (on 12387 data points) #>                pD: 37.8 #>               DIC: 8850 library(purrr) library(stringr) library(forcats)  # Extract draws from relaxed models imap_dfr(noSEM_fits,         ~as_tibble(as.matrix(.x, pars = \"beta\")) %>%             pivot_longer(cols = everything(), names_to = \"parameter\", values_to = \"value\") %>%             filter(str_detect(parameter, paste0(\"(IXE|SEC).+:\", .y))) %>%             mutate(model = .y)) %>%       # Add in draws from the original model   bind_rows(     as_tibble(as.matrix(pso_fit_FE, pars = \"beta\")) %>%      pivot_longer(cols = everything(), names_to = \"parameter\", values_to = \"value\") %>%      filter(str_detect(parameter, \":.+IL\\\\-17 blocker\")) %>%      mutate(model = \"all\")   ) %>%       mutate(     # Rescale BSA to per 10%      value = if_else(str_detect(parameter, \"bsa\"), value / 10, value),     # Create labels     covariate = str_extract(parameter, \"durnpso|prevsys|bsa|weight|psa\"),     covariatef = recode_factor(covariate,                                durnpso = \"Duration of psoriasis, per 10 years\",                                prevsys = \"Previous systemic use\",                                bsa = \"Body surface area, per 10%\",                                weight = \"Weight, per 10 kg\",                                psa = \"Psoriatic arthritis\"),     treatment = str_remove(str_extract(parameter, \"\\\\.trt(class)?.+?(?=[\\\\]:])\"),                            \"\\\\.trt(class)?\"),     Interactions = fct_collapse(factor(model),                                  Common = \"all\",                                  other_level = \"Independent\")) %>%     # Plot ggplot(aes(x = value, y = fct_rev(treatment), colour = Interactions, fill = Interactions)) +   geom_vline(xintercept = 0, colour = \"grey70\") +   ggdist::stat_halfeye(normalize = \"panels\", slab_alpha = 0.3, .width = c(0, 0.95)) +   facet_wrap(\"covariatef\", scales = \"free\") +   xlab(\"Interaction effect (SMD)\") +    ylab(\"Treatment / Class\") +   scale_colour_manual(values = c(Common = \"#7B3294\", Independent = \"#91D388\"),                       aesthetics = c(\"colour\", \"fill\")) +   theme_multinma() +   theme(legend.position = c(0.85, 0.2))"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"study-populations-included-in-the-network","dir":"Articles","previous_headings":"Extended analysis > Producing relative effects and event probabilities","what":"Study populations included in the network","title":"Example: Plaque psoriasis ML-NMR","text":"Population-average treatment effects can produced study populations represented network using relative_effects() function. relative effects can plotted using plot() function.  Similarly, average response probabilities treatment, study population, PASI cutoff can produced using predict() function. specify type = \"response\" produce predicted probabilities (rather probit-probabilities). , can plotted using plot() function.","code":"(pso_releff_FE <- relative_effects(pso_fit_FE)) plot(pso_releff_FE, ref_line = 0) (pso_pred_FE <- predict(pso_fit_FE, type = \"response\")) plot(pso_pred_FE, ref_line = c(0, 1))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"external-target-populations","dir":"Articles","previous_headings":"Extended analysis > Producing relative effects and event probabilities","what":"External target populations","title":"Example: Plaque psoriasis ML-NMR","text":"purposes decision-making crucial population-average estimates produced decision target population interest. decision target population may represented study populations network, indeed likely best represented external registry cohort study, perhaps expert knowledge (Phillippo et al. 2016). example, Phillippo et al. (2022) produce estimates three external target populations represented PsoBest registry (Reich et al. 2015; Augustin et al. 2014), PROSPECT (Thaçi et al. 2019) Chiricozzi 2019 (Chiricozzi et al. 2019) cohort studies. First , need covariate means standard deviations populations: produce estimates population-average treatment effects, use relative_effects() function data frame covariate means target populations newdata argument. need covariate means, variable names matching regression. estimates plotted using plot() function.  Estimates average event probabilities produced integrating predictions joint covariate distribution population. Since marginal summary statistics available, rather full IPD, create integration points using add_integration() function specifying forms marginal distributions correlation matrix. choose use forms marginal distributions used specifying integration points AgD studies network, weighted correlation matrix IPD studies. use predict() function produce average event probabilities (type = \"response\", level = \"aggregate\" default) target populations. , also need specify distribution baseline event probabilities (.e. probability achieving PASI 75 response) target populations. PASI 75 event counts individuals receiving secukinumab 300 mg treatment available PROSPECT (1156 achieved PASI 75 1509) Chiricozzi 2019 (243 330), use construct beta distributions baseline average response probabilities (specify baseline_level = \"aggregate\" population averages, rather specific reference individual, baseline_type = \"response\" probabilities rather transformed probit probabilities). information baseline response available PsoBest, predictions absolute response rates made. , plot estimates using plot() function, customisation using ggplot syntax.","code":"new_agd_means <- tibble::tribble(              ~study, ~covariate,  ~mean,   ~sd,           \"PsoBest\",      \"bsa\",     24,  20.5,           \"PsoBest\",  \"durnpso\",   18.2,  14.1,           \"PsoBest\",  \"prevsys\",   0.54,    NA,           \"PsoBest\",      \"psa\",  0.207,    NA,           \"PsoBest\",   \"weight\",     85,  19.1,          \"PROSPECT\",      \"bsa\",   18.7,  18.4,          \"PROSPECT\",  \"durnpso\",   19.6,  13.5,          \"PROSPECT\",  \"prevsys\", 0.9095,    NA,          \"PROSPECT\",      \"psa\",  0.202,    NA,          \"PROSPECT\",   \"weight\",   87.5,  20.3,   \"Chiricozzi 2019\",      \"bsa\",     23, 16.79,   \"Chiricozzi 2019\",  \"durnpso\",  16.93, 10.82,   \"Chiricozzi 2019\",  \"prevsys\", 0.9061,    NA,   \"Chiricozzi 2019\",      \"psa\", 0.2152,    NA,   \"Chiricozzi 2019\",   \"weight\",   78.3, 15.87   ) %>%   # Tidy up   pivot_wider(id_cols = study,                names_from = covariate,                values_from = c(mean, sd),               names_glue = \"{covariate}_{.value}\") %>%    # Rescale as per analysis   transmute(study,             bsa_mean = bsa_mean / 100,              bsa_sd = bsa_sd / 100,             weight_mean = weight_mean / 10,             weight_sd = weight_sd / 10,             durnpso_mean = durnpso_mean / 10,             durnpso_sd = durnpso_sd / 10,             prevsys = prevsys_mean,             psa = psa_mean) (pso_releff_FE_new <- relative_effects(pso_fit_FE,                                         newdata = transmute(new_agd_means,                                                            study,                                                            bsa = bsa_mean,                                                            weight = weight_mean,                                                            durnpso = durnpso_mean,                                                            prevsys,                                                            psa),                                        study = study)) #> -------------------------------------------------------- Study: Chiricozzi 2019 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.69    0.91 0.23   7.83 0.22 #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Chiricozzi 2019: ETN]     1.79 0.11 1.58 1.71 1.79 1.86  2.01     1618     2360    1 #> d[Chiricozzi 2019: IXE_Q2W] 3.07 0.10 2.87 3.00 3.07 3.14  3.28     1623     2630    1 #> d[Chiricozzi 2019: IXE_Q4W] 2.85 0.10 2.65 2.78 2.85 2.92  3.06     1782     2447    1 #> d[Chiricozzi 2019: SEC_150] 2.35 0.11 2.13 2.28 2.35 2.43  2.58     2248     2749    1 #> d[Chiricozzi 2019: SEC_300] 2.76 0.11 2.55 2.69 2.76 2.84  2.98     1883     2739    1 #> d[Chiricozzi 2019: UST]     2.30 0.15 2.02 2.20 2.30 2.40  2.58     2569     2878    1 #>  #> --------------------------------------------------------------- Study: PROSPECT ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.96    0.91 0.19   8.75 0.2 #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[PROSPECT: ETN]     1.62 0.11 1.42 1.55 1.62 1.70  1.84     2215     2573    1 #> d[PROSPECT: IXE_Q2W] 2.94 0.10 2.74 2.87 2.93 3.00  3.13     2128     2844    1 #> d[PROSPECT: IXE_Q4W] 2.72 0.10 2.52 2.65 2.72 2.78  2.92     2329     2929    1 #> d[PROSPECT: SEC_150] 2.22 0.11 2.00 2.14 2.22 2.29  2.44     2719     3321    1 #> d[PROSPECT: SEC_300] 2.63 0.11 2.41 2.55 2.63 2.70  2.85     2295     3224    1 #> d[PROSPECT: UST]     2.18 0.15 1.89 2.08 2.18 2.28  2.47     3205     3089    1 #>  #> ---------------------------------------------------------------- Study: PsoBest ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.82    0.54 0.24    8.5 0.21 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[PsoBest: ETN]     1.61 0.08 1.46 1.56 1.61 1.66  1.77     2021     2876    1 #> d[PsoBest: IXE_Q2W] 2.93 0.08 2.78 2.87 2.93 2.98  3.08     1857     2249    1 #> d[PsoBest: IXE_Q4W] 2.71 0.08 2.56 2.66 2.71 2.76  2.86     2164     2259    1 #> d[PsoBest: SEC_150] 2.21 0.09 2.04 2.15 2.21 2.27  2.39     2451     2706    1 #> d[PsoBest: SEC_300] 2.62 0.09 2.45 2.56 2.62 2.67  2.79     2016     2919    1 #> d[PsoBest: UST]     2.08 0.13 1.82 1.99 2.08 2.17  2.34     2852     3123    1 #> plot(pso_releff_FE_new, ref_line = 0) + facet_wrap(\"Study\") new_agd_int <- add_integration(filter(new_agd_means, study != \"PsoBest\"),                                durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),                                prevsys = distr(qbern, prob = prevsys),                                bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),                                weight = distr(qgamma, mean = weight_mean, sd = weight_sd),                                psa = distr(qbern, prob = psa),                                n_int = 64,                                cor = pso_net$int_cor) (pso_pred_FE_new <- predict(pso_fit_FE,          type = \"response\",          newdata = new_agd_int,         study = study,         baseline = list(PROSPECT = distr(qbeta, 1156, 1509-1156),                         \"Chiricozzi 2019\" = distr(qbeta, 243, 330-243)),         baseline_type = \"response\",         baseline_level = \"aggregate\",         trt_ref = \"SEC_300\")) #> -------------------------------------------------------- Study: Chiricozzi 2019 ----  #>  #>                                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Chiricozzi 2019: PBO, PASI75]      0.02 0.01 0.01 0.01 0.02 0.02  0.03     2564     3595    1 #> pred[Chiricozzi 2019: PBO, PASI90]      0.00 0.00 0.00 0.00 0.00 0.00  0.01     2643     3414    1 #> pred[Chiricozzi 2019: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     2763     3690    1 #> pred[Chiricozzi 2019: ETN, PASI75]      0.37 0.04 0.30 0.34 0.37 0.40  0.46     4758     3892    1 #> pred[Chiricozzi 2019: ETN, PASI90]      0.16 0.03 0.11 0.14 0.16 0.18  0.22     4762     3997    1 #> pred[Chiricozzi 2019: ETN, PASI100]     0.03 0.01 0.02 0.03 0.03 0.04  0.05     4701     3931    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI75]  0.83 0.03 0.77 0.81 0.83 0.84  0.88     4481     3929    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI90]  0.60 0.04 0.52 0.57 0.60 0.63  0.68     4458     4057    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI100] 0.28 0.04 0.21 0.26 0.28 0.31  0.36     4418     4016    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI75]  0.76 0.03 0.70 0.74 0.77 0.79  0.83     4476     3773    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI90]  0.52 0.04 0.43 0.49 0.52 0.55  0.60     4444     3737    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI100] 0.22 0.03 0.16 0.19 0.21 0.24  0.28     4393     3701    1 #> pred[Chiricozzi 2019: SEC_150, PASI75]  0.59 0.04 0.52 0.57 0.59 0.62  0.66     4949     3965    1 #> pred[Chiricozzi 2019: SEC_150, PASI90]  0.33 0.03 0.26 0.30 0.33 0.35  0.40     4810     3887    1 #> pred[Chiricozzi 2019: SEC_150, PASI100] 0.10 0.02 0.07 0.09 0.10 0.11  0.14     4741     3846    1 #> pred[Chiricozzi 2019: SEC_300, PASI75]  0.74 0.02 0.69 0.72 0.74 0.75  0.78     3923     3931    1 #> pred[Chiricozzi 2019: SEC_300, PASI90]  0.48 0.03 0.42 0.46 0.48 0.50  0.54     3912     3974    1 #> pred[Chiricozzi 2019: SEC_300, PASI100] 0.19 0.02 0.15 0.17 0.19 0.20  0.23     3885     3933    1 #> pred[Chiricozzi 2019: UST, PASI75]      0.57 0.05 0.47 0.53 0.57 0.60  0.67     5538     3835    1 #> pred[Chiricozzi 2019: UST, PASI90]      0.31 0.05 0.22 0.28 0.31 0.34  0.41     5591     3798    1 #> pred[Chiricozzi 2019: UST, PASI100]     0.10 0.02 0.06 0.08 0.09 0.11  0.15     5462     3920    1 #>  #> --------------------------------------------------------------- Study: PROSPECT ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[PROSPECT: PBO, PASI75]      0.03 0.01 0.02 0.03 0.03 0.04  0.05     2902     3561    1 #> pred[PROSPECT: PBO, PASI90]      0.01 0.00 0.00 0.00 0.01 0.01  0.01     3098     3528    1 #> pred[PROSPECT: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3269     3415    1 #> pred[PROSPECT: ETN, PASI75]      0.40 0.03 0.33 0.38 0.40 0.42  0.47     5199     3240    1 #> pred[PROSPECT: ETN, PASI90]      0.18 0.02 0.14 0.16 0.18 0.20  0.23     5147     3365    1 #> pred[PROSPECT: ETN, PASI100]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     4967     3490    1 #> pred[PROSPECT: IXE_Q2W, PASI75]  0.85 0.02 0.81 0.84 0.85 0.86  0.88     5001     3224    1 #> pred[PROSPECT: IXE_Q2W, PASI90]  0.64 0.03 0.57 0.62 0.64 0.66  0.70     4949     3615    1 #> pred[PROSPECT: IXE_Q2W, PASI100] 0.32 0.03 0.26 0.30 0.32 0.34  0.38     4883     3727    1 #> pred[PROSPECT: IXE_Q4W, PASI75]  0.79 0.02 0.74 0.78 0.79 0.81  0.84     5310     3627    1 #> pred[PROSPECT: IXE_Q4W, PASI90]  0.56 0.03 0.49 0.53 0.56 0.58  0.62     5152     3587    1 #> pred[PROSPECT: IXE_Q4W, PASI100] 0.25 0.03 0.19 0.23 0.24 0.26  0.30     4930     3584    1 #> pred[PROSPECT: SEC_150, PASI75]  0.63 0.03 0.58 0.61 0.63 0.65  0.68     5720     3577    1 #> pred[PROSPECT: SEC_150, PASI90]  0.36 0.03 0.31 0.35 0.36 0.38  0.42     5332     3598    1 #> pred[PROSPECT: SEC_150, PASI100] 0.12 0.01 0.09 0.11 0.12 0.13  0.15     5036     3554    1 #> pred[PROSPECT: SEC_300, PASI75]  0.77 0.01 0.74 0.76 0.77 0.77  0.79     3785     4056    1 #> pred[PROSPECT: SEC_300, PASI90]  0.52 0.02 0.49 0.51 0.52 0.53  0.55     3560     3888    1 #> pred[PROSPECT: SEC_300, PASI100] 0.22 0.01 0.19 0.21 0.22 0.23  0.24     3510     3811    1 #> pred[PROSPECT: UST, PASI75]      0.61 0.05 0.52 0.58 0.61 0.64  0.70     5992     3337    1 #> pred[PROSPECT: UST, PASI90]      0.35 0.04 0.27 0.32 0.35 0.38  0.44     6096     3471    1 #> pred[PROSPECT: UST, PASI100]     0.12 0.02 0.08 0.10 0.11 0.13  0.17     5841     3581    1 plot(pso_pred_FE_new, ref_line = c(0, 1)) +    facet_grid(rows = \"Study\") +    aes(colour = Category) +   scale_colour_brewer(palette = \"Blues\")"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Smoking cessation","text":"begin setting network. arm-level count data giving number quitting smoking (r) total (n) arm, use function set_agd_arm(). Treatment “intervention” set network reference treatment. Plot network structure.","code":"smknet <- set_agd_arm(smoking,                        study = studyn,                       trt = trtc,                       r = r,                        n = n,                       trt_ref = \"No intervention\") smknet #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected plot(smknet, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"random-effects-nma","dir":"Articles","previous_headings":"","what":"Random effects NMA","title":"Example: Smoking cessation","text":"Following TSD 4, fit random effects NMA model, using nma() function trt_effects = \"random\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), \\(\\textrm{half-N}(5^2)\\) prior distribution -study heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  default, displays model parameters given prior distributions (case \\(d_k\\), \\(\\mu_j\\), \\(\\tau\\)), may changed using prior argument:  Model fit can checked using dic() function residual deviance contributions examined corresponding plot() method  Overall model fit seems adequate, almost points showing good fit (mean residual deviance contribution 1). two points higher residual deviance (.e. worse fit) correspond two zero counts data:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. smkfit <- nma(smknet,                trt_effects = \"random\",               prior_intercept = normal(scale = 100),               prior_trt = normal(scale = 100),               prior_het = normal(scale = 5)) smkfit #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50%      75%    97.5% #> d[Group counselling]          1.09    0.01 0.44     0.22     0.80     1.07     1.36     2.01 #> d[Individual counselling]     0.84    0.01 0.24     0.40     0.68     0.84     1.00     1.34 #> d[Self-help]                  0.48    0.01 0.39    -0.28     0.23     0.48     0.73     1.27 #> lp__                      -5920.13    0.19 6.54 -5933.65 -5924.32 -5919.82 -5915.56 -5908.36 #> tau                           0.83    0.01 0.19     0.54     0.70     0.81     0.93     1.27 #>                           n_eff Rhat #> d[Group counselling]       1683    1 #> d[Individual counselling]  1023    1 #> d[Self-help]               1208    1 #> lp__                       1144    1 #> tau                        1036    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:44:05 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(smkfit, pars = c(\"d\", \"tau\", \"mu\", \"delta\")) plot_prior_posterior(smkfit) plot_prior_posterior(smkfit, prior = \"het\") (dic_consistency <- dic(smkfit)) #> Residual deviance: 54.6 (on 50 data points) #>                pD: 44.1 #>               DIC: 98.7 plot(dic_consistency) smoking[smoking$r == 0, ] #>    studyn trtn            trtc r  n #> 13      6    1 No intervention 0 33 #> 31     15    1 No intervention 0 20"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"checking-for-inconsistency","dir":"Articles","previous_headings":"","what":"Checking for inconsistency","title":"Example: Smoking cessation","text":"Note: results inconsistency models slightly different Dias et al. (2010, 2011), although overall conclusions . due presence multi-arm trials different ordering treatments, meaning inconsistency parameterised differently within multi-arm trials. results Dias et al. obtained network instead set trtn treatment variable.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"unrelated-mean-effects","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Unrelated mean effects","title":"Example: Smoking cessation","text":"first fit unrelated mean effects (UME) model (Dias et al. 2011) assess consistency assumption. , use function nma(), now argument consistency = \"ume\". Comparing model fit statistics see little choose two models. However, also important examine individual contributions model fit data point two models (-called “dev-dev” plot). Passing two nma_dic objects produced dic() function plot() method produces dev-dev plot:  points lie roughly line equality, evidence inconsistency .","code":"smkfit_ume <- nma(smknet,                    consistency = \"ume\",                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = normal(scale = 5)) smkfit_ume #> A random effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                     mean se_mean   sd     2.5%      25% #> d[Group counselling vs. No intervention]            1.15    0.02 0.82    -0.39     0.61 #> d[Individual counselling vs. No intervention]       0.90    0.01 0.28     0.38     0.72 #> d[Self-help vs. No intervention]                    0.34    0.01 0.58    -0.81    -0.03 #> d[Individual counselling vs. Group counselling]    -0.30    0.01 0.61    -1.53    -0.69 #> d[Self-help vs. Group counselling]                 -0.62    0.01 0.73    -2.05    -1.09 #> d[Self-help vs. Individual counselling]             0.15    0.02 1.07    -1.92    -0.55 #> lp__                                            -5933.53    0.18 6.14 -5946.05 -5937.54 #> tau                                                 0.94    0.01 0.22     0.59     0.78 #>                                                      50%      75%    97.5% n_eff Rhat #> d[Group counselling vs. No intervention]            1.11     1.65     2.87  2468    1 #> d[Individual counselling vs. No intervention]       0.90     1.08     1.47   913    1 #> d[Self-help vs. No intervention]                    0.35     0.71     1.52  2052    1 #> d[Individual counselling vs. Group counselling]    -0.31     0.11     0.92  2366    1 #> d[Self-help vs. Group counselling]                 -0.62    -0.14     0.80  2422    1 #> d[Self-help vs. Individual counselling]             0.15     0.86     2.31  3309    1 #> lp__                                            -5933.22 -5929.18 -5922.46  1213    1 #> tau                                                 0.91     1.06     1.48  1213    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:44:25 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). dic_consistency #> Residual deviance: 54.6 (on 50 data points) #>                pD: 44.1 #>               DIC: 98.7 (dic_ume <- dic(smkfit_ume)) #> Residual deviance: 53.8 (on 50 data points) #>                pD: 45.2 #>               DIC: 99 plot(dic_consistency, dic_ume, point_alpha = 0.5, interval_alpha = 0.2)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"node-splitting","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Node-splitting","title":"Example: Smoking cessation","text":"Another method assessing inconsistency node-splitting (Dias et al. 2011, 2010). Whereas UME model assesses inconsistency globally, node-splitting assesses inconsistency locally potentially inconsistent comparison (direct indirect evidence) turn. Node-splitting can performed using nma() function argument consistency = \"nodesplit\". default, possible comparisons split (determined get_nodesplits() function). Alternatively, specific comparison comparisons split can provided nodesplit argument. summary() method summarises node-splitting results, displaying direct indirect estimates \\(d_\\mathrm{dir}\\) \\(d_\\mathrm{ind}\\) node-split model, network estimate \\(d_\\mathrm{net}\\) consistency model, inconsistency factor \\(\\omega = d_\\mathrm{dir} - d_\\mathrm{ind}\\), Bayesian \\(p\\)-value inconsistency comparison. Since random effects models fitted, heterogeneity standard deviation \\(\\tau\\) node-split model consistency model also displayed. DIC model fit statistics also provided. DIC inconsistency model unchanged consistency model, node-splits result reduced heterogeneity standard deviation \\(\\tau\\) compared consistency model, Bayesian \\(p\\)-values large. evidence inconsistency. can visually compare posterior distributions direct, indirect, network estimates using plot() method. agreement; posterior densities direct indirect estimates overlap. Notice much indirect information Individual counselling vs. intervention comparison, network (consistency) estimate similar direct estimate comparison.","code":"smk_nodesplit <- nma(smknet,                       consistency = \"nodesplit\",                      trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = normal(scale = 5)) #> Fitting model 1 of 7, node-split: Group counselling vs. No intervention #> Fitting model 2 of 7, node-split: Individual counselling vs. No intervention #> Fitting model 3 of 7, node-split: Self-help vs. No intervention #> Fitting model 4 of 7, node-split: Individual counselling vs. Group counselling #> Fitting model 5 of 7, node-split: Self-help vs. Group counselling #> Fitting model 6 of 7, node-split: Self-help vs. Individual counselling #> Fitting model 7 of 7, consistency model summary(smk_nodesplit) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.08 0.43  0.26  0.80  1.08 1.36  1.93     1787     2529    1 #> d_dir            1.08 0.77 -0.37  0.57  1.05 1.58  2.70     3141     2796    1 #> d_ind            1.15 0.54  0.08  0.80  1.14 1.50  2.25     2000     2413    1 #> omega           -0.07 0.92 -1.80 -0.69 -0.07 0.51  1.80     2699     2399    1 #> tau              0.88 0.20  0.55  0.74  0.86 1.00  1.33     1077     2145    1 #> tau_consistency  0.84 0.19  0.55  0.71  0.82 0.94  1.26     1366     1779    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 43.9 #>               DIC: 97.5 #>  #> Bayesian p-value: 0.93 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.84 0.24  0.38  0.68 0.83 0.99  1.34     1159     1803    1 #> d_dir           0.89 0.25  0.41  0.72 0.88 1.05  1.41     1746     2508    1 #> d_ind           0.59 0.67 -0.72  0.15 0.57 1.03  1.93     1186     1550    1 #> omega           0.30 0.69 -1.08 -0.16 0.29 0.75  1.67     1316     1590    1 #> tau             0.86 0.20  0.55  0.72 0.84 0.98  1.32      983     1739    1 #> tau_consistency 0.84 0.19  0.55  0.71 0.82 0.94  1.26     1366     1779    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.2 #>               DIC: 98.3 #>  #> Bayesian p-value: 0.64 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.48 0.40 -0.33  0.22  0.48 0.74  1.26     1830     2289    1 #> d_dir            0.35 0.56 -0.75 -0.02  0.36 0.72  1.46     2754     2785    1 #> d_ind            0.71 0.62 -0.51  0.29  0.71 1.12  1.90     1629     2157    1 #> omega           -0.35 0.83 -1.99 -0.90 -0.36 0.17  1.35     1690     2048    1 #> tau              0.87 0.20  0.56  0.73  0.84 0.98  1.31     1216     1759    1 #> tau_consistency  0.84 0.19  0.55  0.71  0.82 0.94  1.26     1366     1779    1 #>  #> Residual deviance: 53.8 (on 50 data points) #>                pD: 44.2 #>               DIC: 98 #>  #> Bayesian p-value: 0.66 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.25 0.41 -1.07 -0.51 -0.25  0.02  0.55     2589     2848    1 #> d_dir           -0.12 0.49 -1.13 -0.42 -0.11  0.18  0.82     3421     2869    1 #> d_ind           -0.55 0.62 -1.84 -0.95 -0.54 -0.13  0.66     1464     1694    1 #> omega            0.42 0.68 -0.92 -0.04  0.41  0.88  1.77     1690     2214    1 #> tau              0.87 0.20  0.56  0.73  0.84  0.98  1.36     1314     1627    1 #> tau_consistency  0.84 0.19  0.55  0.71  0.82  0.94  1.26     1366     1779    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44 #>               DIC: 97.7 #>  #> Bayesian p-value: 0.53 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.61 0.48 -1.57 -0.91 -0.61 -0.29  0.33     2923     2801    1 #> d_dir           -0.60 0.66 -1.91 -1.02 -0.60 -0.19  0.70     3820     3081    1 #> d_ind           -0.65 0.67 -2.01 -1.10 -0.64 -0.18  0.64     1975     2177    1 #> omega            0.04 0.87 -1.68 -0.52  0.03  0.60  1.79     2303     2587    1 #> tau              0.87 0.19  0.57  0.74  0.84  0.98  1.32     1129     1916    1 #> tau_consistency  0.84 0.19  0.55  0.71  0.82  0.94  1.26     1366     1779    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.4 #>               DIC: 98.4 #>  #> Bayesian p-value: 0.97 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.36 0.41 -1.16 -0.62 -0.36 -0.09  0.46     2181     2531    1 #> d_dir            0.08 0.65 -1.19 -0.34  0.08  0.50  1.37     3408     2988    1 #> d_ind           -0.63 0.53 -1.67 -0.98 -0.63 -0.29  0.42     1768     2365    1 #> omega            0.72 0.82 -0.89  0.15  0.72  1.26  2.31     2062     2568    1 #> tau              0.84 0.19  0.55  0.70  0.82  0.95  1.27     1132     2221    1 #> tau_consistency  0.84 0.19  0.55  0.71  0.82  0.94  1.26     1366     1779    1 #>  #> Residual deviance: 54 (on 50 data points) #>                pD: 44.2 #>               DIC: 98.2 #>  #> Bayesian p-value: 0.37 plot(smk_nodesplit) +   ggplot2::theme(legend.position = \"bottom\", legend.direct = \"horizontal\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Smoking cessation","text":"Pairwise relative effects, pairwise contrasts all_contrasts = TRUE.  Treatment rankings, rank probabilities, cumulative rank probabilities. set lower_better = FALSE since higher log odds cessation better (outcome positive).","code":"(smk_releff <- relative_effects(smkfit, all_contrasts = TRUE)) #>                                                  mean   sd  2.5%   25%   50%   75% 97.5% #> d[Group counselling vs. No intervention]         1.09 0.44  0.22  0.80  1.07  1.36  2.01 #> d[Individual counselling vs. No intervention]    0.84 0.24  0.40  0.68  0.84  1.00  1.34 #> d[Self-help vs. No intervention]                 0.48 0.39 -0.28  0.23  0.48  0.73  1.27 #> d[Individual counselling vs. Group counselling] -0.24 0.41 -1.07 -0.51 -0.24  0.03  0.56 #> d[Self-help vs. Group counselling]              -0.61 0.48 -1.58 -0.92 -0.60 -0.28  0.31 #> d[Self-help vs. Individual counselling]         -0.36 0.40 -1.16 -0.62 -0.36 -0.10  0.45 #>                                                 Bulk_ESS Tail_ESS Rhat #> d[Group counselling vs. No intervention]            1742     2094    1 #> d[Individual counselling vs. No intervention]       1058     1707    1 #> d[Self-help vs. No intervention]                    1248     1769    1 #> d[Individual counselling vs. Group counselling]     2546     2878    1 #> d[Self-help vs. Group counselling]                  2892     2851    1 #> d[Self-help vs. Individual counselling]             2103     2678    1 plot(smk_releff, ref_line = 0) (smk_ranks <- posterior_ranks(smkfit, lower_better = FALSE)) #>                              mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[No intervention]        3.89 0.32    3   4   4   4     4     2078       NA    1 #> rank[Group counselling]      1.38 0.62    1   1   1   2     3     3124     3136    1 #> rank[Individual counselling] 1.90 0.63    1   1   2   2     3     2359     2407    1 #> rank[Self-help]              2.83 0.67    1   3   3   3     4     2261       NA    1 plot(smk_ranks) (smk_rankprobs <- posterior_rank_probs(smkfit, lower_better = FALSE)) #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.10      0.89 #> d[Group counselling]           0.69      0.24      0.06      0.00 #> d[Individual counselling]      0.25      0.60      0.15      0.00 #> d[Self-help]                   0.05      0.16      0.68      0.10 plot(smk_rankprobs) (smk_cumrankprobs <- posterior_rank_probs(smkfit, lower_better = FALSE, cumulative = TRUE)) #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.11         1 #> d[Group counselling]           0.69      0.93      1.00         1 #> d[Individual counselling]      0.25      0.85      1.00         1 #> d[Self-help]                   0.05      0.22      0.90         1 plot(smk_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Statins for cholesterol lowering","text":"data giving number deaths (r) total (n) arm, use function set_agd_arm() set network. set placebo network reference treatment. prevention variable statins data frame automatically available use meta-regression model.","code":"statin_net <- set_agd_arm(statins,                            study = studyc,                           trt = trtc,                           r = r,                            n = n,                           trt_ref = \"Placebo\") statin_net #> A network with 19 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study     Treatment arms      #>  4S        2: Placebo | Statin #>  Bestehorn 2: Placebo | Statin #>  Brown     2: Placebo | Statin #>  CCAIT     2: Placebo | Statin #>  Downs     2: Placebo | Statin #>  EXCEL     2: Placebo | Statin #>  Furberg   2: Placebo | Statin #>  Haskell   2: Placebo | Statin #>  Jones     2: Placebo | Statin #>  KAPS      2: Placebo | Statin #>  ... plus 9 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 19 #> Reference treatment is: Placebo #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Statins for cholesterol lowering","text":"fit fixed effect (FE) random effects (RE) models, meta-regression binary covariate prevention.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"fixed-effect-meta-regression","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-regression","title":"Example: Statins for cholesterol lowering","text":"start fitting FE model. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Statin}\\), study-specific intercepts \\(\\mu_j\\), regression coefficient \\(\\beta\\). can examine range parameter values implied prior distributions summary() method: model fitted nma() function, fixed effect model specified trt_effects = \"fixed\". regression formula ~ .trt:prevention means interaction primary/secondary prevention treatment included; .trt special variable indicates treatment, prevention original data set. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. statin_fit_FE <- nma(statin_net,                       trt_effects = \"fixed\",                      regression = ~.trt:prevention,                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_reg = normal(scale = 100)) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. statin_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:prevention. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                          mean se_mean   sd     2.5%      25%      50%      75% #> beta[.trtStatin:preventionSecondary]    -0.20    0.00 0.11    -0.43    -0.28    -0.20    -0.13 #> d[Statin]                               -0.11    0.00 0.10    -0.30    -0.17    -0.11    -0.04 #> lp__                                 -7362.86    0.09 3.49 -7370.50 -7365.02 -7362.53 -7360.36 #>                                         97.5% n_eff Rhat #> beta[.trtStatin:preventionSecondary]     0.01  2135    1 #> d[Statin]                                0.09  2082    1 #> lp__                                 -7357.05  1430    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:46:37 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(statin_fit_FE, pars = c(\"d\", \"beta\", \"mu\")) plot_prior_posterior(statin_fit_FE, prior = c(\"trt\", \"reg\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"random-effects-meta-regression","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-regression","title":"Example: Statins for cholesterol lowering","text":"now fit RE model. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Statin}\\), study-specific intercepts \\(\\mu_j\\), regression coefficient \\(\\beta\\). use \\(\\textrm{half-N}(0, 5^2)\\) prior distribution heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: , model fitted nma() function, now trt_effects = \"random\". increase adapt_delta 0.99 remove small number divergent transition errors (default RE models set 0.95). Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. statin_fit_RE <- nma(statin_net,                       trt_effects = \"random\",                      regression = ~.trt:prevention,                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_reg = normal(scale = 100),                      prior_het = half_normal(scale = 5),                      adapt_delta = 0.99) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. statin_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:prevention. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                          mean se_mean   sd     2.5%      25%      50%      75% #> beta[.trtStatin:preventionSecondary]    -0.29    0.01 0.24    -0.84    -0.42    -0.27    -0.15 #> d[Statin]                               -0.07    0.00 0.19    -0.46    -0.18    -0.07     0.03 #> lp__                                 -7374.82    0.20 5.36 -7386.07 -7378.24 -7374.45 -7371.04 #> tau                                      0.23    0.01 0.19     0.01     0.09     0.18     0.32 #>                                         97.5% n_eff Rhat #> beta[.trtStatin:preventionSecondary]     0.15  1509    1 #> d[Statin]                                0.35  1489    1 #> lp__                                 -7365.35   744    1 #> tau                                      0.72   810    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:46:53 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(statin_fit_RE, pars = c(\"d\", \"beta\", \"mu\", \"delta\")) plot_prior_posterior(statin_fit_RE, prior = c(\"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: Statins for cholesterol lowering","text":"Model fit can checked using dic() function: DIC similar FE RE models, might choose FE model based parsimony. residual deviance statistics larger number data points, suggesting data points fit well. can also examine residual deviance contributions corresponding plot() method.   number studies fit well either model, posterior mean residual deviance contributions greater 1, investigated see substantive differences studies.","code":"(statin_dic_FE <- dic(statin_fit_FE)) #> Residual deviance: 46.3 (on 38 data points) #>                pD: 22 #>               DIC: 68.4 (statin_dic_RE <- dic(statin_fit_RE)) #> Residual deviance: 43 (on 38 data points) #>                pD: 25.2 #>               DIC: 68.2 plot(statin_dic_FE) plot(statin_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Statins for cholesterol lowering","text":"can produce estimates relative effect statins vs. placebo either primary secondary prevention, using relative_effects() function. newdata argument specifies data frame containing levels covariate prevention interested , study argument used specify column newdata informative label. plot() method may used visually compare estimates:  Model parameters may plotted corresponding plot() method:  Whilst 95% Credible Interval includes zero, suggestion statins effective secondary prevention.","code":"statin_releff_FE <- relative_effects(statin_fit_FE,                                      newdata = data.frame(prevention = c(\"Primary\", \"Secondary\")),                                      study = prevention)  statin_releff_FE #> ---------------------------------------------------------------- Study: Primary ----  #>  #> Covariate values: #>  prevention #>     Primary #>  #>                     mean  sd 2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Primary: Statin] -0.11 0.1 -0.3 -0.17 -0.11 -0.04  0.09     2148     2538    1 #>  #> -------------------------------------------------------------- Study: Secondary ----  #>  #> Covariate values: #>  prevention #>   Secondary #>  #>                       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Secondary: Statin] -0.31 0.05 -0.42 -0.35 -0.31 -0.28 -0.21     4697     3169    1 plot(statin_releff_FE,       ref_line = 0) plot(statin_fit_FE,       pars = \"beta\",       ref_line = 0,      stat = \"halfeye\")"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Thrombolytic treatments","text":"begin setting network. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). default, SK set network reference treatment. Plot network structure.","code":"thrombo_net <- set_agd_arm(thrombolytics,                             study = studyn,                            trt = trtc,                            r = r,                             n = n) thrombo_net #> A network with 50 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms               #>  1     3: SK | Acc t-PA | SK + t-PA #>  2     2: SK | t-PA                 #>  3     2: SK | t-PA                 #>  4     2: SK | t-PA                 #>  5     2: SK | t-PA                 #>  6     3: SK | ASPAC | t-PA         #>  7     2: SK | t-PA                 #>  8     2: SK | t-PA                 #>  9     2: SK | t-PA                 #>  10    2: SK | SK + t-PA            #>  ... plus 40 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 9 #> Total number of studies: 50 #> Reference treatment is: SK #> Network is connected plot(thrombo_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"fixed-effects-nma","dir":"Articles","previous_headings":"","what":"Fixed effects NMA","title":"Example: Thrombolytic treatments","text":"Following TSD 4 (Dias et al. 2011), fit fixed effects NMA model, using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Model fit can checked using dic() function residual deviance contributions examined corresponding plot() method.  number points well fit model, posterior mean residual deviance contributions greater 1.","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. thrombo_fit <- nma(thrombo_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) #> Note: Setting \"SK\" as the network reference treatment. thrombo_fit #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd      2.5%       25%       50%       75%     97.5% n_eff #> d[Acc t-PA]      -0.18    0.00 0.04     -0.26     -0.21     -0.18     -0.15     -0.09  2712 #> d[ASPAC]          0.02    0.00 0.04     -0.06     -0.01      0.02      0.04      0.09  6169 #> d[PTCA]          -0.48    0.00 0.10     -0.67     -0.54     -0.47     -0.41     -0.29  3940 #> d[r-PA]          -0.12    0.00 0.06     -0.25     -0.17     -0.12     -0.08     -0.01  3450 #> d[SK + t-PA]     -0.05    0.00 0.05     -0.14     -0.08     -0.05     -0.02      0.04  5420 #> d[t-PA]           0.00    0.00 0.03     -0.06     -0.02      0.00      0.02      0.06  5146 #> d[TNK]           -0.17    0.00 0.08     -0.32     -0.22     -0.17     -0.12     -0.02  3823 #> d[UK]            -0.21    0.00 0.22     -0.64     -0.36     -0.21     -0.06      0.22  4498 #> lp__         -43363.03    0.14 5.43 -43374.60 -43366.45 -43362.77 -43359.26 -43353.42  1490 #>              Rhat #> d[Acc t-PA]     1 #> d[ASPAC]        1 #> d[PTCA]         1 #> d[r-PA]         1 #> d[SK + t-PA]    1 #> d[t-PA]         1 #> d[TNK]          1 #> d[UK]           1 #> lp__            1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:47:18 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(thrombo_fit, pars = c(\"d\", \"mu\")) plot_prior_posterior(thrombo_fit, prior = \"trt\") (dic_consistency <- dic(thrombo_fit)) #> Residual deviance: 105.4 (on 102 data points) #>                pD: 58.2 #>               DIC: 163.7 plot(dic_consistency)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"checking-for-inconsistency","dir":"Articles","previous_headings":"","what":"Checking for inconsistency","title":"Example: Thrombolytic treatments","text":"Note: results inconsistency models slightly different Dias et al. (2010, 2011), although overall conclusions . due presence multi-arm trials different ordering treatments, meaning inconsistency parameterised differently within multi-arm trials. results Dias et al. obtained network instead set trtn treatment variable.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"unrelated-mean-effects-model","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Unrelated mean effects model","title":"Example: Thrombolytic treatments","text":"first fit unrelated mean effects (UME) model (Dias et al. 2011) assess consistency assumption. , use function nma(), now argument consistency = \"ume\". Comparing model fit statistics Whilst UME model fits data better, lower residual deviance, additional parameters UME model mean DIC similar models. However, also important examine individual contributions model fit data point two models (-called “dev-dev” plot). Passing two nma_dic objects produced dic() function plot() method produces dev-dev plot:  four points lying lower right corner plot much lower posterior mean residual deviance UME model, indicating data potentially inconsistent. points correspond trials 44 45, two trials comparing Acc t-PA ASPAC. ASPAC vs. Acc t-PA estimates different consistency model inconsistency (UME) model, suggesting two trials may systematically different others network.","code":"thrombo_fit_ume <- nma(thrombo_net,                         consistency = \"ume\",                        trt_effects = \"fixed\",                        prior_intercept = normal(scale = 100),                        prior_trt = normal(scale = 100)) #> Note: Setting \"SK\" as the network reference treatment. thrombo_fit_ume #> A fixed effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                            mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[Acc t-PA vs. SK]        -0.16    0.00 0.05     -0.26     -0.19     -0.16     -0.12     -0.06 #> d[ASPAC vs. SK]            0.01    0.00 0.04     -0.07     -0.02      0.01      0.03      0.08 #> d[PTCA vs. SK]            -0.67    0.00 0.19     -1.04     -0.79     -0.67     -0.54     -0.30 #> d[r-PA vs. SK]            -0.06    0.00 0.09     -0.23     -0.12     -0.06      0.00      0.12 #> d[SK + t-PA vs. SK]       -0.04    0.00 0.05     -0.14     -0.07     -0.04     -0.01      0.05 #> d[t-PA vs. SK]             0.00    0.00 0.03     -0.06     -0.02      0.00      0.02      0.06 #> d[UK vs. SK]              -0.37    0.01 0.52     -1.42     -0.71     -0.36     -0.02      0.61 #> d[ASPAC vs. Acc t-PA]      1.41    0.01 0.41      0.64      1.11      1.39      1.68      2.27 #> d[PTCA vs. Acc t-PA]      -0.22    0.00 0.12     -0.45     -0.30     -0.22     -0.14      0.01 #> d[r-PA vs. Acc t-PA]       0.02    0.00 0.07     -0.11     -0.03      0.02      0.07      0.15 #> d[TNK vs. Acc t-PA]        0.01    0.00 0.07     -0.12     -0.04      0.01      0.05      0.13 #> d[UK vs. Acc t-PA]         0.14    0.01 0.37     -0.56     -0.10      0.14      0.38      0.88 #> d[t-PA vs. ASPAC]          0.30    0.01 0.36     -0.38      0.05      0.29      0.54      1.01 #> d[t-PA vs. PTCA]           0.54    0.01 0.42     -0.28      0.27      0.52      0.81      1.37 #> d[UK vs. t-PA]            -0.30    0.00 0.34     -0.97     -0.54     -0.30     -0.06      0.39 #> lp__                  -43398.84    0.15 5.85 -43411.29 -43402.63 -43398.43 -43394.79 -43388.48 #>                       n_eff Rhat #> d[Acc t-PA vs. SK]     6614    1 #> d[ASPAC vs. SK]        5184    1 #> d[PTCA vs. SK]         5645    1 #> d[r-PA vs. SK]         4960    1 #> d[SK + t-PA vs. SK]    5570    1 #> d[t-PA vs. SK]         4626    1 #> d[UK vs. SK]           5560    1 #> d[ASPAC vs. Acc t-PA]  3505    1 #> d[PTCA vs. Acc t-PA]   4969    1 #> d[r-PA vs. Acc t-PA]   5466    1 #> d[TNK vs. Acc t-PA]    5555    1 #> d[UK vs. Acc t-PA]     4803    1 #> d[t-PA vs. ASPAC]      4912    1 #> d[t-PA vs. PTCA]       4012    1 #> d[UK vs. t-PA]         5508    1 #> lp__                   1485    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:47:33 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). dic_consistency #> Residual deviance: 105.4 (on 102 data points) #>                pD: 58.2 #>               DIC: 163.7 (dic_ume <- dic(thrombo_fit_ume)) #> Residual deviance: 99.7 (on 102 data points) #>                pD: 66 #>               DIC: 165.7 plot(dic_consistency, dic_ume, show_uncertainty = FALSE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"node-splitting","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Node-splitting","title":"Example: Thrombolytic treatments","text":"Another method assessing inconsistency node-splitting (Dias et al. 2011, 2010). Whereas UME model assesses inconsistency globally, node-splitting assesses inconsistency locally potentially inconsistent comparison (direct indirect evidence) turn. Node-splitting can performed using nma() function argument consistency = \"nodesplit\". default, possible comparisons split (determined get_nodesplits() function). Alternatively, specific comparison comparisons split can provided nodesplit argument. summary() method summarises node-splitting results, displaying direct indirect estimates \\(d_\\mathrm{dir}\\) \\(d_\\mathrm{ind}\\) node-split model, network estimate \\(d_\\mathrm{net}\\) consistency model, inconsistency factor \\(\\omega = d_\\mathrm{dir} - d_\\mathrm{ind}\\), Bayesian \\(p\\)-value inconsistency comparison. DIC model fit statistics also provided. (random effects model fitted, heterogeneity standard deviation \\(\\tau\\) node-split model consistency model also displayed.) Node-splitting ASPAC vs. Acc t-PA comparison results lowest DIC, lower consistency model. posterior distribution inconsistency factor \\(\\omega\\) comparison lies far 0 Bayesian \\(p\\)-value inconsistency small (< 0.01), meaning substantial disagreement direct indirect evidence comparison. can visually compare direct, indirect, network estimates using plot() method.  can also plot posterior distributions inconsistency factors \\(\\omega\\), using plot() method. , specify “halfeye” plot posterior density median credible intervals, customise plot layout standard ggplot2 functions.  Notice posterior distribution inconsistency factor ASPAC vs. Acc t-PA comparison lies far 0, indicating substantial inconsistency direct indirect evidence comparison.","code":"thrombo_nodesplit <- nma(thrombo_net,                           consistency = \"nodesplit\",                          trt_effects = \"fixed\",                          prior_intercept = normal(scale = 100),                          prior_trt = normal(scale = 100)) #> Fitting model 1 of 15, node-split: Acc t-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 2 of 15, node-split: ASPAC vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 3 of 15, node-split: PTCA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 4 of 15, node-split: r-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 5 of 15, node-split: t-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 6 of 15, node-split: UK vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 7 of 15, node-split: ASPAC vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 8 of 15, node-split: PTCA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 9 of 15, node-split: r-PA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 10 of 15, node-split: SK + t-PA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 11 of 15, node-split: UK vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 12 of 15, node-split: t-PA vs. ASPAC #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 13 of 15, node-split: t-PA vs. PTCA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 14 of 15, node-split: UK vs. t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 15 of 15, consistency model #> Note: Setting \"SK\" as the network reference treatment. summary(thrombo_nodesplit) #> Node-splitting models fitted for 14 comparisons. #>  #> ---------------------------------------------------- Node-split Acc t-PA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.18 0.04 -0.26 -0.21 -0.18 -0.15 -0.09     2715     3159 1.00 #> d_dir -0.16 0.05 -0.25 -0.19 -0.16 -0.12 -0.06     4453     3933 1.00 #> d_ind -0.24 0.09 -0.43 -0.30 -0.24 -0.18 -0.07      673     1566 1.01 #> omega  0.09 0.10 -0.11  0.02  0.09  0.15  0.29      810     1723 1.01 #>  #> Residual deviance: 106.1 (on 102 data points) #>                pD: 59.6 #>               DIC: 165.7 #>  #> Bayesian p-value: 0.39 #>  #> ------------------------------------------------------- Node-split ASPAC vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.02 0.04 -0.06 -0.01  0.02  0.04  0.08     5237     3262    1 #> d_dir  0.01 0.04 -0.07 -0.02  0.01  0.03  0.08     4682     3661    1 #> d_ind  0.42 0.25 -0.05  0.26  0.42  0.59  0.92     2417     2866    1 #> omega -0.42 0.25 -0.91 -0.58 -0.41 -0.25  0.06     2503     2931    1 #>  #> Residual deviance: 104.4 (on 102 data points) #>                pD: 59.9 #>               DIC: 164.3 #>  #> Bayesian p-value: 0.09 #>  #> -------------------------------------------------------- Node-split PTCA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.48 0.10 -0.68 -0.54 -0.48 -0.41 -0.27     4003     3448    1 #> d_dir -0.67 0.19 -1.05 -0.79 -0.66 -0.54 -0.31     5750     3970    1 #> d_ind -0.40 0.12 -0.64 -0.48 -0.39 -0.31 -0.16     3552     3114    1 #> omega -0.27 0.23 -0.74 -0.42 -0.27 -0.12  0.15     4589     3187    1 #>  #> Residual deviance: 105.6 (on 102 data points) #>                pD: 59.9 #>               DIC: 165.6 #>  #> Bayesian p-value: 0.23 #>  #> -------------------------------------------------------- Node-split r-PA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.12 0.06 -0.24 -0.17 -0.12 -0.08 -0.01     3923     3204    1 #> d_dir -0.06 0.09 -0.24 -0.12 -0.06  0.00  0.11     6231     3130    1 #> d_ind -0.17 0.08 -0.34 -0.23 -0.17 -0.12 -0.01     2267     3011    1 #> omega  0.11 0.12 -0.12  0.03  0.12  0.20  0.35     2886     2699    1 #>  #> Residual deviance: 105.4 (on 102 data points) #>                pD: 59.1 #>               DIC: 164.5 #>  #> Bayesian p-value: 0.37 #>  #> -------------------------------------------------------- Node-split t-PA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.00 0.03 -0.06 -0.02  0.00  0.02  0.06     4375     3589    1 #> d_dir  0.00 0.03 -0.06 -0.02  0.00  0.02  0.06     4285     3682    1 #> d_ind  0.19 0.24 -0.27  0.02  0.19  0.35  0.65     1432     2281    1 #> omega -0.19 0.24 -0.65 -0.35 -0.19 -0.03  0.27     1456     2357    1 #>  #> Residual deviance: 106.9 (on 102 data points) #>                pD: 60.4 #>               DIC: 167.3 #>  #> Bayesian p-value: 0.43 #>  #> ---------------------------------------------------------- Node-split UK vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.20 0.23 -0.66 -0.35 -0.20 -0.04  0.23     4630     3400    1 #> d_dir -0.37 0.51 -1.39 -0.71 -0.36 -0.01  0.62     5898     3303    1 #> d_ind -0.17 0.24 -0.63 -0.33 -0.17  0.00  0.30     4360     3603    1 #> omega -0.20 0.57 -1.35 -0.58 -0.20  0.18  0.88     5339     3344    1 #>  #> Residual deviance: 107.2 (on 102 data points) #>                pD: 60.1 #>               DIC: 167.3 #>  #> Bayesian p-value: 0.73 #>  #> ------------------------------------------------- Node-split ASPAC vs. Acc t-PA ----  #>  #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net 0.19 0.05 0.09 0.16 0.19 0.23  0.30     3717     3186    1 #> d_dir 1.40 0.42 0.64 1.11 1.38 1.66  2.26     3890     2702    1 #> d_ind 0.16 0.06 0.05 0.13 0.16 0.20  0.27     3131     3111    1 #> omega 1.24 0.42 0.47 0.94 1.22 1.50  2.10     3788     2743    1 #>  #> Residual deviance: 97 (on 102 data points) #>                pD: 59.9 #>               DIC: 156.9 #>  #> Bayesian p-value: <0.01 #>  #> -------------------------------------------------- Node-split PTCA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.30 0.10 -0.49 -0.37 -0.30 -0.24 -0.11     4997     3368    1 #> d_dir -0.21 0.12 -0.44 -0.29 -0.21 -0.14  0.02     4466     3518    1 #> d_ind -0.47 0.17 -0.81 -0.59 -0.47 -0.36 -0.15     3286     2913    1 #> omega  0.26 0.20 -0.14  0.12  0.26  0.40  0.66     3036     3123    1 #>  #> Residual deviance: 105.3 (on 102 data points) #>                pD: 59.7 #>               DIC: 165 #>  #> Bayesian p-value: 0.2 #>  #> -------------------------------------------------- Node-split r-PA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.05 0.06 -0.05  0.02  0.05  0.09  0.16     5971     3496    1 #> d_dir  0.02 0.07 -0.11 -0.02  0.02  0.06  0.15     4731     3390    1 #> d_ind  0.14 0.10 -0.06  0.07  0.14  0.20  0.34     2065     2630    1 #> omega -0.12 0.12 -0.36 -0.20 -0.12 -0.04  0.11     2012     2485    1 #>  #> Residual deviance: 105.6 (on 102 data points) #>                pD: 59.4 #>               DIC: 165 #>  #> Bayesian p-value: 0.32 #>  #> --------------------------------------------- Node-split SK + t-PA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.13 0.05  0.02  0.09  0.13  0.17  0.23     5116     3503    1 #> d_dir  0.13 0.05  0.02  0.09  0.13  0.16  0.23     3640     3225    1 #> d_ind  0.61 0.69 -0.73  0.14  0.61  1.06  2.03     2675     2502    1 #> omega -0.49 0.69 -1.91 -0.93 -0.48 -0.02  0.86     2689     2544    1 #>  #> Residual deviance: 106.7 (on 102 data points) #>                pD: 60 #>               DIC: 166.7 #>  #> Bayesian p-value: 0.49 #>  #> ---------------------------------------------------- Node-split UK vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.03 0.23 -0.48 -0.17 -0.02 0.13  0.42     4689     3552    1 #> d_dir  0.15 0.35 -0.53 -0.09  0.14 0.38  0.83     4554     3486    1 #> d_ind -0.14 0.29 -0.72 -0.33 -0.14 0.05  0.41     4390     3242    1 #> omega  0.29 0.45 -0.59 -0.01  0.28 0.60  1.17     3633     3245    1 #>  #> Residual deviance: 106.5 (on 102 data points) #>                pD: 59.7 #>               DIC: 166.2 #>  #> Bayesian p-value: 0.52 #>  #> ----------------------------------------------------- Node-split t-PA vs. ASPAC ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.01 0.04 -0.08 -0.04 -0.01  0.01  0.06     6864     2889    1 #> d_dir -0.02 0.04 -0.10 -0.05 -0.02  0.00  0.05     4864     3539    1 #> d_ind  0.03 0.06 -0.09 -0.01  0.03  0.07  0.15     3079     3095    1 #> omega -0.05 0.06 -0.17 -0.09 -0.05 -0.01  0.07     3296     3289    1 #>  #> Residual deviance: 106.3 (on 102 data points) #>                pD: 59.8 #>               DIC: 166.1 #>  #> Bayesian p-value: 0.41 #>  #> ------------------------------------------------------ Node-split t-PA vs. PTCA ----  #>  #>       mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net 0.48 0.10  0.27  0.41 0.48 0.55  0.68     4310     3243    1 #> d_dir 0.53 0.41 -0.27  0.26 0.53 0.79  1.35     5283     2964    1 #> d_ind 0.47 0.11  0.27  0.40 0.47 0.55  0.68     3838     3503    1 #> omega 0.06 0.42 -0.78 -0.22 0.05 0.33  0.91     4500     3057    1 #>  #> Residual deviance: 106.8 (on 102 data points) #>                pD: 59.6 #>               DIC: 166.4 #>  #> Bayesian p-value: 0.89 #>  #> -------------------------------------------------------- Node-split UK vs. t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.21 0.23 -0.66 -0.36 -0.20 -0.05  0.23     4771     3307    1 #> d_dir -0.29 0.34 -0.98 -0.53 -0.28 -0.05  0.36     5290     3505    1 #> d_ind -0.14 0.29 -0.71 -0.34 -0.14  0.06  0.44     3856     3153    1 #> omega -0.15 0.45 -1.05 -0.44 -0.13  0.15  0.69     4583     3758    1 #>  #> Residual deviance: 106.8 (on 102 data points) #>                pD: 59.7 #>               DIC: 166.4 #>  #> Bayesian p-value: 0.75 plot(thrombo_nodesplit) plot(thrombo_nodesplit, pars = \"omega\", stat = \"halfeye\", ref_line = 0) +   ggplot2::aes(y = comparison) +   ggplot2::facet_null()"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Thrombolytic treatments","text":"Relative effects pairwise contrasts treatments can produced using relative_effects() function, all_contrasts = TRUE.  Treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(thrombo_releff <- relative_effects(thrombo_fit, all_contrasts = TRUE)) #>                            mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Acc t-PA vs. SK]        -0.18 0.04 -0.26 -0.21 -0.18 -0.15 -0.09     2721     3163    1 #> d[ASPAC vs. SK]            0.02 0.04 -0.06 -0.01  0.02  0.04  0.09     5951     3612    1 #> d[PTCA vs. SK]            -0.48 0.10 -0.67 -0.54 -0.47 -0.41 -0.29     3996     3162    1 #> d[r-PA vs. SK]            -0.12 0.06 -0.25 -0.17 -0.12 -0.08 -0.01     3464     2934    1 #> d[SK + t-PA vs. SK]       -0.05 0.05 -0.14 -0.08 -0.05 -0.02  0.04     5372     3064    1 #> d[t-PA vs. SK]             0.00 0.03 -0.06 -0.02  0.00  0.02  0.06     5121     3540    1 #> d[TNK vs. SK]             -0.17 0.08 -0.32 -0.22 -0.17 -0.12 -0.02     3843     3294    1 #> d[UK vs. SK]              -0.21 0.22 -0.64 -0.36 -0.21 -0.06  0.22     4538     3455    1 #> d[ASPAC vs. Acc t-PA]      0.19 0.06  0.08  0.16  0.19  0.23  0.30     3555     3352    1 #> d[PTCA vs. Acc t-PA]      -0.30 0.10 -0.49 -0.36 -0.30 -0.23 -0.12     5309     3539    1 #> d[r-PA vs. Acc t-PA]       0.05 0.06 -0.06  0.02  0.05  0.09  0.16     5866     3580    1 #> d[SK + t-PA vs. Acc t-PA]  0.13 0.05  0.03  0.09  0.13  0.16  0.23     5916     3367    1 #> d[t-PA vs. Acc t-PA]       0.18 0.05  0.08  0.14  0.18  0.21  0.28     3431     3408    1 #> d[TNK vs. Acc t-PA]        0.01 0.06 -0.12 -0.04  0.01  0.05  0.13     5778     3484    1 #> d[UK vs. Acc t-PA]        -0.03 0.22 -0.46 -0.18 -0.03  0.12  0.40     4763     3197    1 #> d[PTCA vs. ASPAC]         -0.49 0.10 -0.70 -0.56 -0.49 -0.42 -0.29     4229     2976    1 #> d[r-PA vs. ASPAC]         -0.14 0.07 -0.28 -0.19 -0.14 -0.09  0.00     3914     3270    1 #> d[SK + t-PA vs. ASPAC]    -0.06 0.06 -0.18 -0.10 -0.06 -0.03  0.05     5780     3288    1 #> d[t-PA vs. ASPAC]         -0.01 0.04 -0.09 -0.04 -0.01  0.01  0.06     6233     3111    1 #> d[TNK vs. ASPAC]          -0.19 0.08 -0.35 -0.24 -0.19 -0.13 -0.02     4207     3392    1 #> d[UK vs. ASPAC]           -0.22 0.22 -0.65 -0.37 -0.22 -0.07  0.21     4510     3046    1 #> d[r-PA vs. PTCA]           0.35 0.11  0.14  0.28  0.35  0.42  0.56     5360     3680    1 #> d[SK + t-PA vs. PTCA]      0.43 0.11  0.22  0.36  0.43  0.50  0.63     5058     3102    1 #> d[t-PA vs. PTCA]           0.48 0.10  0.28  0.41  0.48  0.55  0.68     4246     3155    1 #> d[TNK vs. PTCA]            0.31 0.11  0.08  0.23  0.30  0.38  0.54     6279     3358    1 #> d[UK vs. PTCA]             0.27 0.24 -0.19  0.10  0.27  0.43  0.73     4640     3383    1 #> d[SK + t-PA vs. r-PA]      0.08 0.07 -0.06  0.03  0.08  0.12  0.22     6371     2993    1 #> d[t-PA vs. r-PA]           0.13 0.07 -0.01  0.08  0.13  0.17  0.26     3825     2590    1 #> d[TNK vs. r-PA]           -0.05 0.08 -0.21 -0.10 -0.05  0.01  0.12     7454     3326    1 #> d[UK vs. r-PA]            -0.08 0.23 -0.52 -0.24 -0.08  0.07  0.36     4838     3289    1 #> d[t-PA vs. SK + t-PA]      0.05 0.05 -0.05  0.02  0.05  0.09  0.15     5500     3147    1 #> d[TNK vs. SK + t-PA]      -0.12 0.08 -0.29 -0.18 -0.12 -0.07  0.04     6085     2909    1 #> d[UK vs. SK + t-PA]       -0.16 0.22 -0.60 -0.31 -0.16 -0.01  0.27     4820     3336    1 #> d[TNK vs. t-PA]           -0.17 0.08 -0.33 -0.23 -0.17 -0.12 -0.01     4256     3318    1 #> d[UK vs. t-PA]            -0.21 0.22 -0.64 -0.36 -0.21 -0.06  0.22     4605     3309    1 #> d[UK vs. TNK]             -0.04 0.23 -0.49 -0.19 -0.04  0.12  0.42     4905     3436    1 plot(thrombo_releff, ref_line = 0) (thrombo_ranks <- posterior_ranks(thrombo_fit)) #>                 mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[SK]        7.45 0.97    6   7   7   8     9     3746       NA    1 #> rank[Acc t-PA]  3.20 0.81    2   3   3   4     5     4145     3188    1 #> rank[ASPAC]     8.00 1.11    5   7   8   9     9     4952       NA    1 #> rank[PTCA]      1.14 0.36    1   1   1   1     2     3644     3626    1 #> rank[r-PA]      4.40 1.19    2   4   4   5     7     4688     3226    1 #> rank[SK + t-PA] 5.97 1.20    4   5   6   6     9     5371       NA    1 #> rank[t-PA]      7.50 1.10    5   7   8   8     9     4625       NA    1 #> rank[TNK]       3.50 1.26    2   3   3   4     6     5027     3561    1 #> rank[UK]        3.84 2.66    1   2   2   5     9     4934       NA    1 plot(thrombo_ranks) (thrombo_rankprobs <- posterior_rank_probs(thrombo_fit)) #>              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] p_rank[8] #> d[SK]             0.00      0.00      0.00      0.00      0.02      0.13      0.39      0.31 #> d[Acc t-PA]       0.00      0.20      0.45      0.30      0.05      0.00      0.00      0.00 #> d[ASPAC]          0.00      0.00      0.00      0.00      0.02      0.09      0.19      0.26 #> d[PTCA]           0.86      0.14      0.00      0.00      0.00      0.00      0.00      0.00 #> d[r-PA]           0.00      0.06      0.14      0.30      0.38      0.08      0.02      0.01 #> d[SK + t-PA]      0.00      0.00      0.01      0.06      0.25      0.47      0.09      0.07 #> d[t-PA]           0.00      0.00      0.00      0.00      0.03      0.14      0.30      0.32 #> d[TNK]            0.00      0.23      0.32      0.25      0.15      0.03      0.01      0.01 #> d[UK]             0.14      0.37      0.06      0.09      0.10      0.06      0.02      0.02 #>              p_rank[9] #> d[SK]             0.16 #> d[Acc t-PA]       0.00 #> d[ASPAC]          0.44 #> d[PTCA]           0.00 #> d[r-PA]           0.01 #> d[SK + t-PA]      0.05 #> d[t-PA]           0.20 #> d[TNK]            0.01 #> d[UK]             0.14 plot(thrombo_rankprobs) (thrombo_cumrankprobs <- posterior_rank_probs(thrombo_fit, cumulative = TRUE)) #>              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] p_rank[8] #> d[SK]             0.00      0.00      0.00      0.00      0.02      0.15      0.54      0.84 #> d[Acc t-PA]       0.00      0.20      0.65      0.95      1.00      1.00      1.00      1.00 #> d[ASPAC]          0.00      0.00      0.00      0.00      0.03      0.11      0.30      0.56 #> d[PTCA]           0.86      1.00      1.00      1.00      1.00      1.00      1.00      1.00 #> d[r-PA]           0.00      0.06      0.20      0.51      0.88      0.97      0.98      0.99 #> d[SK + t-PA]      0.00      0.00      0.01      0.07      0.32      0.79      0.88      0.95 #> d[t-PA]           0.00      0.00      0.00      0.01      0.04      0.18      0.48      0.80 #> d[TNK]            0.00      0.23      0.55      0.80      0.95      0.98      0.99      0.99 #> d[UK]             0.14      0.51      0.57      0.66      0.76      0.82      0.84      0.86 #>              p_rank[9] #> d[SK]                1 #> d[Acc t-PA]          1 #> d[ASPAC]             1 #> d[PTCA]              1 #> d[r-PA]              1 #> d[SK + t-PA]         1 #> d[t-PA]              1 #> d[TNK]               1 #> d[UK]                1 plot(thrombo_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: White blood cell transfusion","text":"begin setting network - just pairwise meta-analysis. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). set “Control” reference treatment.","code":"tr_net <- set_agd_arm(transfusion,                             study = studyc,                            trt = trtc,                            r = r,                             n = n,                            trt_ref = \"Control\") tr_net #> A network with 6 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms           #>  Bow 1984      2: Control | Transfusion #>  Herzig 1977   2: Control | Transfusion #>  Higby 1975    2: Control | Transfusion #>  Scali 1978    2: Control | Transfusion #>  Vogler 1977   2: Control | Transfusion #>  Winston 1982a 2: Control | Transfusion #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 6 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: White blood cell transfusion","text":"fit two random effects models, first non-informative prior heterogeneity, using informative prior described Turner et al. (2012).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"random-effects-meta-analysis-with-non-informative-heterogeneity-prior","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis with non-informative heterogeneity prior","title":"Example: White blood cell transfusion","text":"fit random effects model using nma() function trt_effects = \"random\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), non-informative \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  posterior distribution heterogeneity variance \\(\\tau^2\\) summarised ","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. tr_fit_RE_noninf <- nma(tr_net,                          trt_effects = \"random\",                         prior_intercept = normal(scale = 100),                         prior_trt = normal(scale = 100),                         prior_het = half_normal(scale = 5)) tr_fit_RE_noninf #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Transfusion]   -1.17    0.03 0.99   -3.55   -1.67   -1.07   -0.57    0.61  1236    1 #> lp__           -175.56    0.10 3.16 -182.58 -177.37 -175.20 -173.28 -170.42  1048    1 #> tau               1.87    0.03 1.04    0.56    1.16    1.62    2.30    4.53  1251    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:50:27 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(tr_fit_RE_noninf, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(tr_fit_RE_noninf, prior = \"het\") noninf_tau <- as.array(tr_fit_RE_noninf, pars = \"tau\") noninf_tausq <- noninf_tau^2 names(noninf_tausq) <- \"tausq\" summary(noninf_tausq) #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq 4.57 5.97 0.32 1.35 2.64 5.29 20.52     1169     1910    1"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"random-effects-meta-analysis-with-informative-heterogeneity-prior","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis with informative heterogeneity prior","title":"Example: White blood cell transfusion","text":"Keeping rest model setup , now use informative \\(\\textrm{log-N}(-3.93, 1.51^2)\\) prior heterogeneity variance \\(\\tau^2\\). can examine range parameter values implied prior distribution summary() method: Fitting RE model, specify log_normal prior distribution prior_het argument, set prior_het_type = \"var\" indicate prior distribution variance scale (instead standard deviation, default). Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Note: heterogeneity variance \\(\\tau^2\\) plotted since prior specified \\(\\tau^2\\). posterior distribution heterogeneity variance \\(\\tau^2\\) summarised ","code":"summary(log_normal(-3.93, 1.51)) #> A log-Normal prior distribution: location = -3.93, scale = 1.51. #> 50% of the prior density lies between 0.01 and 0.05. #> 95% of the prior density lies between 0 and 0.38. tr_fit_RE_inf <- nma(tr_net,                       trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = log_normal(-3.93, 1.51),                      prior_het_type = \"var\") tr_fit_RE_inf #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%    75%   97.5% n_eff Rhat #> d[Transfusion]   -0.78    0.01 0.43   -1.72   -1.03   -0.76   -0.5    0.00  2075    1 #> lp__           -180.19    0.07 2.77 -186.32 -181.82 -179.88 -178.2 -175.67  1544    1 #> tau               0.50    0.01 0.35    0.05    0.23    0.45    0.7    1.36  1683    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:50:33 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(tr_fit_RE_inf, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(tr_fit_RE_inf, prior = \"het\") inf_tau <- as.array(tr_fit_RE_inf, pars = \"tau\") inf_tausq <- inf_tau^2 names(inf_tausq) <- \"tausq\" summary(inf_tausq) #>       mean   sd 2.5%  25% 50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq 0.37 0.52    0 0.05 0.2 0.49  1.84     1463     2457    1"},{"path":[]},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David M. Phillippo. Author, maintainer.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Phillippo DM (2023). multinma: Bayesian Network Meta-Analysis Individual Aggregate Data. doi:10.5281/zenodo.3904454, R package version 0.5.1.9001, https://dmphillippo.github.io/multinma/. Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189-1210. doi:10.1111/rssa.12579.","code":"@Manual{,   title = {multinma: Bayesian Network Meta-Analysis of Individual and Aggregate Data},   author = {David M. Phillippo},   year = {2023},   note = {R package version 0.5.1.9001},   url = {https://dmphillippo.github.io/multinma/},   doi = {10.5281/zenodo.3904454}, } @Article{,   title = {Multilevel Network Meta-Regression for population-adjusted treatment comparisons},   author = {David M. Phillippo and Sofia Dias and A. E. Ades and Mark Belger and Alan Brnabic and Alexander Schacht and Daniel Saure and Zbigniew Kadziola and Nicky J. Welton},   year = {2020},   doi = {10.1111/rssa.12579},   journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},   volume = {183},   number = {3},   pages = {1189-1210}, }"},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"multinma-network-meta-analysis-of-individual-and-aggregate-data-in-stan-","dir":"","previous_headings":"","what":"Bayesian network meta-analysis of individual and aggregate data","title":"Bayesian network meta-analysis of individual and aggregate data","text":"multinma package implements network meta-analysis, network meta-regression, multilevel network meta-regression models combine evidence network studies treatments using either aggregate data individual patient data study (Phillippo et al. 2020; Phillippo 2019). Models estimated Bayesian framework using Stan (Carpenter et al. 2017).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian network meta-analysis of individual and aggregate data","text":"can install released version multinma CRAN : development version can installed R-universe : source GitHub : Installing source requires rstan package installed configured. See installation guide .","code":"install.packages(\"multinma\") install.packages(\"multinma\", repos = c(\"https://dmphillippo.r-universe.dev\", getOption(\"repos\"))) # install.packages(\"devtools\") devtools::install_github(\"dmphillippo/multinma\")"},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting started","title":"Bayesian network meta-analysis of individual and aggregate data","text":"good place start package vignettes walk example analyses, see vignette(\"vignette_overview\") overview. series NICE Technical Support Documents evidence synthesis gives detailed introduction network meta-analysis: Dias, S. et al. (2011). “NICE DSU Technical Support Documents 1-7: Evidence Synthesis Decision Making.” National Institute Health Care Excellence. Available https://www.sheffield.ac.uk/nice-dsu/tsds. Multilevel network meta-regression set following methods paper: Phillippo, D. M. et al. (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3):1189-1210. doi: 10.1111/rssa.12579.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"citing-multinma","dir":"","previous_headings":"","what":"Citing multinma","title":"Bayesian network meta-analysis of individual and aggregate data","text":"multinma package can cited follows: Phillippo, D. M. (2023). multinma: Bayesian Network Meta-Analysis Individual Aggregate Data. R package version 0.5.1.9000, doi: 10.5281/zenodo.3904454. fitting ML-NMR models, please cite methods paper: Phillippo, D. M. et al. (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3):1189-1210. doi: 10.1111/rssa.12579.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":null,"dir":"Reference","previous_headings":"","what":"The Bernoulli Distribution — qbern","title":"The Bernoulli Distribution — qbern","text":"quantile function qbern Bernoulli distribution, success probability prob. equivalent qbinom(p, 1, prob).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Bernoulli Distribution — qbern","text":"","code":"qbern(p, prob, lower.tail = TRUE, log.p = FALSE)  pbern(q, prob, lower.tail = TRUE, log.p = FALSE)  dbern(x, prob, log = FALSE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Bernoulli Distribution — qbern","text":"p vector probabilities prob probability success lower.tail, log.p, log see stats::Binomial x, q vector quantiles","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":null,"dir":"Reference","previous_headings":"","what":"The Gamma distribution — qgamma","title":"The Gamma distribution — qgamma","text":"provide convenient extensions [dpq]gamma functions, allow distribution specified terms mean standard deviation, instead shape rate/scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Gamma distribution — qgamma","text":"","code":"qgamma(   p,   shape,   rate = 1,   scale = 1/rate,   lower.tail = TRUE,   log.p = FALSE,   mean,   sd )  dgamma(x, shape, rate = 1, scale = 1/rate, log = FALSE, mean, sd)  pgamma(   q,   shape,   rate = 1,   scale = 1/rate,   lower.tail = TRUE,   log.p = FALSE,   mean,   sd )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Gamma distribution — qgamma","text":"p vector probabilities shape, rate, scale, log, lower.tail, log.p see stats::GammaDist mean, sd mean standard deviation, overriding shape rate scale specified x, q vector quantiles","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_pso_mlnmr.html","id":null,"dir":"Reference","previous_headings":"","what":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","title":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","text":"Calling example(\"example_pso_mlnmr\") run ML-NMR model plaque psoriasis IPD AgD, using code Examples section . resulting stan_nma object pso_fit available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_pso_mlnmr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","text":"Plaque psoriasis ML-NMR use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_pso_mlnmr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","text":"","code":"# Set up plaque psoriasis network combining IPD and AgD library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.  # \\donttest{ # Fitting a ML-NMR model. # Specify a regression model to include effect modifier interactions for five # covariates, along with main (prognostic) effects. We use a probit link and # specify that the two-parameter Binomial approximation for the aggregate-level # likelihood should be used. We set treatment-covariate interactions to be equal # within each class. We narrow the possible range for random initial values with # init_r = 0.1, since probit models in particular are often hard to initialise. # Using the QR decomposition greatly improves sampling efficiency here, as is # often the case for regression models. pso_fit <- nma(pso_net, refresh = if (interactive()) 200 else 0,                trt_effects = \"fixed\",                link = \"probit\",                likelihood = \"bernoulli2\",                regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                class_interactions = \"common\",                prior_intercept = normal(scale = 10),                prior_trt = normal(scale = 10),                prior_reg = normal(scale = 10),                init_r = 0.1,                QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25% #> beta[durnpso]                           0.04    0.00 0.06    -0.08     0.00 #> beta[prevsys]                          -0.14    0.00 0.16    -0.45    -0.25 #> beta[bsa]                              -0.08    0.01 0.44    -0.97    -0.37 #> beta[weight]                            0.04    0.00 0.03    -0.01     0.02 #> beta[psa]                              -0.08    0.00 0.17    -0.42    -0.20 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.15    -0.06 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.19    -0.17     0.07 #> beta[prevsys:.trtclassIL blocker]       0.07    0.00 0.17    -0.27    -0.05 #> beta[bsa:.trtclassTNFa blocker]         0.06    0.01 0.51    -0.94    -0.29 #> beta[bsa:.trtclassIL blocker]           0.30    0.01 0.48    -0.62    -0.03 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.19 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12 #> beta[psa:.trtclassTNFa blocker]        -0.05    0.00 0.21    -0.47    -0.19 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.19    -0.35    -0.11 #> d[ETN]                                  1.55    0.00 0.08     1.39     1.50 #> d[IXE_Q2W]                              2.95    0.00 0.09     2.78     2.89 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.38     2.48 #> d[SEC_150]                              2.15    0.00 0.11     1.93     2.07 #> d[SEC_300]                              2.45    0.00 0.12     2.22     2.37 #> lp__                                -1653.65    0.08 3.48 -1661.28 -1655.83 #>                                          50%      75%    97.5% n_eff Rhat #> beta[durnpso]                           0.04     0.08     0.17  5928    1 #> beta[prevsys]                          -0.14    -0.03     0.17  5050    1 #> beta[bsa]                              -0.06     0.23     0.76  4369    1 #> beta[weight]                            0.04     0.06     0.10  4836    1 #> beta[psa]                              -0.08     0.03     0.26  5292    1 #> beta[durnpso:.trtclassTNFa blocker]    -0.03     0.02     0.12  5858    1 #> beta[durnpso:.trtclassIL blocker]      -0.01     0.04     0.12  7352    1 #> beta[prevsys:.trtclassTNFa blocker]     0.19     0.32     0.55  5671    1 #> beta[prevsys:.trtclassIL blocker]       0.07     0.18     0.41  6129    1 #> beta[bsa:.trtclassTNFa blocker]         0.05     0.40     1.09  4832    1 #> beta[bsa:.trtclassIL blocker]           0.28     0.62     1.27  5055    1 #> beta[weight:.trtclassTNFa blocker]     -0.17    -0.14    -0.10  5022    1 #> beta[weight:.trtclassIL blocker]       -0.10    -0.08    -0.04  5454    1 #> beta[psa:.trtclassTNFa blocker]        -0.05     0.09     0.35  5749    1 #> beta[psa:.trtclassIL blocker]           0.02     0.14     0.39  6356    1 #> d[ETN]                                  1.55     1.61     1.71  4007    1 #> d[IXE_Q2W]                              2.95     3.01     3.13  4944    1 #> d[IXE_Q4W]                              2.54     2.60     2.71  4957    1 #> d[SEC_150]                              2.14     2.22     2.37  4038    1 #> d[SEC_300]                              2.45     2.53     2.69  4847    1 #> lp__                                -1653.36 -1651.13 -1647.68  1711    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:15:17 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"pso_net\", pso_net, .GlobalEnv)   assign(\"pso_fit\", pso_fit, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_fe.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking FE NMA — example_smk_fe","title":"Example smoking FE NMA — example_smk_fe","text":"Calling example(\"example_smk_fe\") run fixed effects NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_FE available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_fe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking FE NMA — example_smk_fe","text":"Smoking FE NMA use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_fe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking FE NMA — example_smk_fe","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting a fixed effect model smk_fit_FE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100))  smk_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          0.84    0.00 0.18     0.50     0.72     0.84 #> d[Individual counselling]     0.77    0.00 0.06     0.65     0.73     0.77 #> d[Self-help]                  0.22    0.00 0.13    -0.03     0.14     0.22 #> lp__                      -6008.57    0.09 3.66 -6016.66 -6010.78 -6008.17 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          0.96     1.18  2578    1 #> d[Individual counselling]     0.81     0.88  1990    1 #> d[Self-help]                  0.31     0.47  3127    1 #> lp__                      -6005.97 -6002.46  1800    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:16:46 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_FE\", smk_fit_FE, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_nodesplit.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking node-splitting — example_smk_nodesplit","title":"Example smoking node-splitting — example_smk_nodesplit","text":"Calling example(\"example_smk_nodesplit\") run node-splitting models smoking cessation data, using code Examples section . resulting nma_nodesplit_df object smk_fit_RE_nodesplit available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_nodesplit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking node-splitting — example_smk_nodesplit","text":"Smoking node-splitting use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_nodesplit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking node-splitting — example_smk_nodesplit","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting all possible node-splitting models smk_fit_RE_nodesplit <- nma(smk_net, refresh = if (interactive()) 200 else 0,                             consistency = \"nodesplit\",                             trt_effects = \"random\",                             prior_intercept = normal(scale = 100),                             prior_trt = normal(scale = 100),                             prior_het = normal(scale = 5)) #> Fitting model 1 of 7, node-split: Group counselling vs. No intervention #> Fitting model 2 of 7, node-split: Individual counselling vs. No intervention #> Fitting model 3 of 7, node-split: Self-help vs. No intervention #> Fitting model 4 of 7, node-split: Individual counselling vs. Group counselling #> Fitting model 5 of 7, node-split: Self-help vs. Group counselling #> Fitting model 6 of 7, node-split: Self-help vs. Individual counselling #> Fitting model 7 of 7, consistency model # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_RE_nodesplit\", smk_fit_RE_nodesplit, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_re.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking RE NMA — example_smk_re","title":"Example smoking RE NMA — example_smk_re","text":"Calling example(\"example_smk_re\") run random effects NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_RE available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_re.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking RE NMA — example_smk_re","text":"Smoking RE NMA use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_re.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking RE NMA — example_smk_re","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting a random effects model smk_fit_RE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = normal(scale = 5))  smk_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          1.10    0.01 0.44     0.26     0.81     1.09 #> d[Individual counselling]     0.85    0.01 0.24     0.40     0.68     0.85 #> d[Self-help]                  0.50    0.01 0.41    -0.30     0.23     0.48 #> lp__                      -5919.86    0.20 6.46 -5932.86 -5924.25 -5919.55 #> tau                           0.85    0.01 0.19     0.54     0.71     0.82 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          1.37     1.97  1839    1 #> d[Individual counselling]     1.01     1.34  1030    1 #> d[Self-help]                  0.76     1.34  1437    1 #> lp__                      -5915.22 -5908.32  1000    1 #> tau                           0.95     1.29  1065    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:18:57 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_RE\", smk_fit_RE, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_ume.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking UME NMA — example_smk_ume","title":"Example smoking UME NMA — example_smk_ume","text":"Calling example(\"example_smk_ume\") run unrelated mean effects (inconsistency) NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_RE_UME available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_ume.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking UME NMA — example_smk_ume","text":"Smoking UME NMA use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_ume.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking UME NMA — example_smk_ume","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting an unrelated mean effects (inconsistency) model smk_fit_RE_UME <- nma(smk_net, refresh = if (interactive()) 200 else 0,                       consistency = \"ume\",                       trt_effects = \"random\",                       prior_intercept = normal(scale = 100),                       prior_trt = normal(scale = 100),                       prior_het = normal(scale = 5))  smk_fit_RE_UME #> A random effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                     mean se_mean   sd     2.5% #> d[Group counselling vs. No intervention]            1.17    0.02 0.81    -0.32 #> d[Individual counselling vs. No intervention]       0.92    0.01 0.27     0.42 #> d[Self-help vs. No intervention]                    0.34    0.01 0.60    -0.82 #> d[Individual counselling vs. Group counselling]    -0.29    0.01 0.62    -1.54 #> d[Self-help vs. Group counselling]                 -0.61    0.02 0.72    -2.06 #> d[Self-help vs. Individual counselling]             0.18    0.02 1.05    -1.90 #> lp__                                            -5933.54    0.21 6.26 -5946.66 #> tau                                                 0.94    0.01 0.23     0.60 #>                                                      25%      50%      75% #> d[Group counselling vs. No intervention]            0.63     1.12     1.66 #> d[Individual counselling vs. No intervention]       0.74     0.91     1.09 #> d[Self-help vs. No intervention]                   -0.06     0.34     0.72 #> d[Individual counselling vs. Group counselling]    -0.69    -0.29     0.11 #> d[Self-help vs. Group counselling]                 -1.05    -0.61    -0.16 #> d[Self-help vs. Individual counselling]            -0.49     0.18     0.85 #> lp__                                            -5937.49 -5933.15 -5929.10 #> tau                                                 0.78     0.91     1.06 #>                                                    97.5% n_eff Rhat #> d[Group counselling vs. No intervention]            2.92  2384 1.00 #> d[Individual counselling vs. No intervention]       1.50  1196 1.00 #> d[Self-help vs. No intervention]                    1.54  1901 1.00 #> d[Individual counselling vs. Group counselling]     0.93  2120 1.00 #> d[Self-help vs. Group counselling]                  0.83  2069 1.00 #> d[Self-help vs. Individual counselling]             2.31  3036 1.00 #> lp__                                            -5922.37   918 1.01 #> tau                                                 1.49  1203 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:19:10 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_RE_UME\", smk_fit_RE_UME, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/adapt_delta.html","id":null,"dir":"Reference","previous_headings":"","what":"Target average acceptance probability — adapt_delta","title":"Target average acceptance probability — adapt_delta","text":"Stan control argument adapt_delta sets target average acceptance probability -U-Turn Sampler (NUTS) used Stan.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/adapt_delta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Target average acceptance probability — adapt_delta","text":"default value adapt_delta used nma() 0.8 fixed effect models, 0.95 random effects models. need change adapt_delta unless see warning message divergent transitions. Increasing adapt_delta default value closer 1 means Stan use smaller step size, making sampling slower robust, resulting fewer divergent transitions. details see Stan documentation available https://mc-stan.org/users/documentation/.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":null,"dir":"Reference","previous_headings":"","what":"Add numerical integration points to aggregate data — add_integration","title":"Add numerical integration points to aggregate data — add_integration","text":"add_integration() generic creates Quasi-Monte Carlo numerical integration points using Gaussian copula Sobol' sequences, described Phillippo et al. (2020) . Methods available networks stored nma_data objects, data frames. function unnest_integration() unnests integration points stored data frame, aid plotting exploration.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add numerical integration points to aggregate data — add_integration","text":"","code":"add_integration(x, ...)  # S3 method for default add_integration(x, ...)  # S3 method for data.frame add_integration(   x,   ...,   cor = NULL,   cor_adjust = NULL,   n_int = 64L,   int_args = list() )  # S3 method for nma_data add_integration(   x,   ...,   cor = NULL,   cor_adjust = NULL,   n_int = 64L,   int_args = list() )  unnest_integration(data)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add numerical integration points to aggregate data — add_integration","text":"x nma_data object, created set_*() functions combine_network(), data frame ... Distributions covariates, see \"Details\" cor Correlation matrix use generating integration points. default, takes weighted correlation matrix IPD studies. Rows columns match order covariates specified .... cor_adjust Adjustment apply correlation matrix given cor (computed IPD cor = NULL) obtain Gaussian copula correlations, either \"spearman\", \"pearson\", \"none\", see \"Details\". default cor = NULL \"spearman\", otherwise default \"pearson\". n_int Number integration points generate, default 64. Powers 2 recommended, expected particularly efficient QMC integration. int_args named list arguments pass sobol() data Data frame nested integration points, stored list columns .int_<variable name>","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add numerical integration points to aggregate data — add_integration","text":"nma_data method, object class nma_data. data.frame method, input data frame returned (tibble) added column covariate (prefixed \".int_\"), containing numerical integration points nested length-n_int vectors within row. unnest_integration(), data frame integration points unnested.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add numerical integration points to aggregate data — add_integration","text":"arguments passed ... specify distributions covariates. Argument names specify name covariate, match covariate name IPD (IPD present). required marginal distribution specified using function distr(). argument cor_adjust specifies correlation matrix given cor (computed IPD cor = NULL) adjusted obtain correlation matrix Gaussian copula, using formulae Xiao Zhou (2018) . cor_adjust = \"spearman\" used correlations cor computed using Spearman's rank correlation. Correlations continuous covariates reproduced exactly integration points. Correlations discrete covariates reproduced approximately. default cor = NULL correlations calculated IPD studies. cor_adjust = \"pearson\" used correlations cor computed using Pearson's product-moment correlation. Correlations Normal covariates reproduced exactly integration points, others reproduced approximately. Correlations discrete covariates reproduced approximately (identically cor_adjust   = \"spearman\"). default cor provided user, since cor() defaults method = \"pearson\" Pearson correlations likely reported published data. However, recommend providing Spearman correlations (e.g. cor(., method = \"spearman\")) using cor_adjust = \"spearman\" possible. cor_adjust = \"none\" allows user specify correlation matrix Gaussian copula directly; adjustment applied. cor_adjust = \"legacy\" also available, reproduces exactly behaviour version 0.3.0 earlier. similar cor_adjust =   \"none\", unadjusted Spearman correlations used cor = NULL. adding integration points network object correlation matrix used stored $int_cor, copula correlation matrix adjustment used stored attributes $int_cor. correlation matrix passed add_integration() (e.g. reuse correlations external target population) detected, correct setting cor_adjust automatically applied.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Add numerical integration points to aggregate data — add_integration","text":"Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 . Xiao Q, Zhou S (2018). “Matching correlation coefficient Gaussian copula.” Communications Statistics - Theory Methods, 48(7), 1728--1747. doi:10.1080/03610926.2018.1439962 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add numerical integration points to aggregate data — add_integration","text":"","code":"## Plaque psoriasis ML-NMR - network setup and adding integration points # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.   ## Adding integration points to a data frame, e.g. for prediction # Define a data frame of covariate summaries new_agd_int <- data.frame(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1)  # Adding integration points, using the weighted average correlation matrix # computed for the plaque psoriasis network new_agd_int <- add_integration(new_agd_int,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   cor = pso_net$int_cor,   n_int = 64)  # Here, since we reused the correlation matrix pso_net$int_cor from the # network, the correct setting of cor_adjust = \"spearman\" is automatically # applied  new_agd_int #> # A tibble: 1 × 13 #>   bsa_mean bsa_sd prevsys   psa weight_mean weight_sd durnpso_mean durnpso_sd #>      <dbl>  <dbl>   <dbl> <dbl>       <dbl>     <dbl>        <dbl>      <dbl> #> 1      0.6    0.3     0.1   0.2          10         1            3          1 #> # ℹ 5 more variables: .int_durnpso <list>, .int_prevsys <list>, #> #   .int_bsa <list>, .int_weight <list>, .int_psa <list>"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"Samples (post warm-) stan_nma model object can coerced array, matrix, data frame.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"","code":"# S3 method for stan_nma as.array(x, ..., pars, include = TRUE)  # S3 method for stan_nma as.data.frame(x, ..., pars, include = TRUE)  # S3 method for stan_nma as.matrix(x, ..., pars, include = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"x stan_nma object ... Additional arguments passed .array.stanfit() pars Optional character vector parameter names include output. specified, parameters used. include Logical, parameters pars included (TRUE, default) excluded (FALSE)?","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":".array() method produces 3D array [Iteration, Chain, Parameter] containing posterior samples parameter (class mcmc_array). side effect enabling bayesplot functions seamlessly work stan_nma objects. .data.frame() method produces data frame containing posterior samples parameter, combined chains. .matrix() method produces matrix containing posterior samples parameter, combined chains.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":null,"dir":"Reference","previous_headings":"","what":"as.stanfit — as.stanfit","title":"as.stanfit — as.stanfit","text":"Attempt turn object stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"as.stanfit — as.stanfit","text":"","code":"as.stanfit(x, ...)  # S3 method for stan_nma as.stanfit(x, ...)  # S3 method for default as.stanfit(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"as.stanfit — as.stanfit","text":"x object ... additional arguments","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"as.stanfit — as.stanfit","text":"stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":null,"dir":"Reference","previous_headings":"","what":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"Data frame containing results 26 trials comparing 17 treatments 4 classes prevention stroke patients atrial fibrillation (Cooper et al. 2009) . data corrected versions given van Valkenhoef Kuiper (2016) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"","code":"atrial_fibrillation"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"data frame 63 rows 11 variables: studyc study name studyn numeric study ID trtc treatment name trtn numeric treatment code trt_class treatment class r number events n sample size E person-years risk stroke proportion individuals prior stroke year year study publication followup mean length follow-(years)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"Cooper NJ, Sutton AJ, Morris D, Ades AE, Welton NJ (2009). “Addressing -study heterogeneity inconsistency mixed treatment comparisons: Application stroke prevention treatments individuals non-rheumatic atrial fibrillation.” Statistics Medicine, 28(14), 1861--1881. doi:10.1002/sim.3594 . van Valkenhoef G, Kuiper J (2016). gemtc: Network Meta-Analysis Using Bayesian Methods. R package version 0.8-2, https://CRAN.R-project.org/package=gemtc.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":null,"dir":"Reference","previous_headings":"","what":"BCG vaccination — bcg_vaccine","title":"BCG vaccination — bcg_vaccine","text":"Data frame containing results 13 trials comparing BCG vaccination vaccination preventing tuberculosis (TB) (Dias et al. 2011; Berkey et al. 1995) . numbers individuals diagnosed TB arm study follow-period recorded. absolute degrees latitude study conducted also recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BCG vaccination — bcg_vaccine","text":"","code":"bcg_vaccine"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"BCG vaccination — bcg_vaccine","text":"data frame 26 rows 6 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name latitude absolute degrees latitude r number diagnosed TB n sample size","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"BCG vaccination — bcg_vaccine","text":"Berkey CS, Hoaglin DC, Mosteller F, Colditz GA (1995). “random-effects regression model meta-analysis.” Statistics Medicine, 14(4), 395--411. doi:10.1002/sim.4780140406 . Dias S, Sutton AJ, Welton NJ, Ades AE (2011). “NICE DSU Technical Support Document 3: Heterogeneity: subgroups, meta-regression, bias bias-adjustment.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":null,"dir":"Reference","previous_headings":"","what":"Beta blockers to prevent mortality after MI — blocker","title":"Beta blockers to prevent mortality after MI — blocker","text":"Data frame containing number deaths 22 trials comparing beta blockers vs. control preventing mortality myocardial infarction (Carlin 1992; Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Beta blockers to prevent mortality after MI — blocker","text":"","code":"blocker"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Beta blockers to prevent mortality after MI — blocker","text":"data frame 44 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Beta blockers to prevent mortality after MI — blocker","text":"Carlin JB (1992). “Meta-analysis 2 x 2 tables: bayesian approach.” Statistics Medicine, 11(2), 141--158. doi:10.1002/sim.4780110202 . Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine multiple data sources into one network — combine_network","title":"Combine multiple data sources into one network — combine_network","text":"Multiple data sources created using set_ipd(), set_agd_arm(), set_agd_contrast() can combined single network analysis.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine multiple data sources into one network — combine_network","text":"","code":"combine_network(..., trt_ref)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine multiple data sources into one network — combine_network","text":"... multiple data sources, defined using set_* functions trt_ref reference treatment entire network, string (coerced ) referring levels treatment factor variable","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine multiple data sources into one network — combine_network","text":"object class nma_data","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine multiple data sources into one network — combine_network","text":"","code":"## Parkinson's - combining contrast- and arm-based data studies <- parkinsons$studyn (parkinsons_arm <- parkinsons[studies %in% 1:3, ]) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718 #> 7      3    4 -1.20 0.478  81 -0.90   0.695 (parkinsons_contr <- parkinsons[studies %in% 4:7, ]) #>    studyn trtn     y    se   n  diff se_diff #> 8       4    3 -0.24 0.265 128    NA   0.265 #> 9       4    4 -0.59 0.354  72 -0.35   0.442 #> 10      5    3 -0.73 0.335  80    NA   0.335 #> 11      5    4 -0.18 0.442  46  0.55   0.555 #> 12      6    4 -2.20 0.197 137    NA   0.197 #> 13      6    5 -2.50 0.190 131 -0.30   0.274 #> 14      7    4 -1.80 0.200 154    NA   0.200 #> 15      7    5 -2.10 0.250 143 -0.30   0.320  park_arm_net <- set_agd_arm(parkinsons_arm,                             study = studyn,                             trt = trtn,                             y = y,                             se = se,                             sample_size = n)  park_contr_net <- set_agd_contrast(parkinsons_contr,                                    study = studyn,                                    trt = trtn,                                    y = diff,                                    se = se_diff,                                    sample_size = n)  park_net <- combine_network(park_arm_net, park_contr_net)  # Print network details park_net #> A network with 3 AgD studies (arm-based), and 4 AgD studies (contrast-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  #>  Outcome type: continuous #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected  # Plot network plot(park_net, weight_edges = TRUE, weight_nodes = TRUE)   ## Plaque Psoriasis - combining IPD and AgD in a network # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected   # Plot network plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Set default values — .default","title":"Set default values — .default","text":".default() function used internally mark certain values default, user may notified default values used. example, choosing default reference treatment network, using default prior distributions. function .is_default() checks whether argument/object set default value. Neither functions intended called user.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set default values — .default","text":"","code":".default(x = list())  .is_default(x)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set default values — .default","text":"x object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set default values — .default","text":".default(), identical object additional attribute .default. .is_default(), logical value (TRUE FALSE).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":null,"dir":"Reference","previous_headings":"","what":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"Data frame containing number new cases diabetes 22 trials 6 antihypertensive drugs (Elliott Meyer 2007; Dias et al. 2011) . trial duration (years) also recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"","code":"diabetes"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"data frame 48 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name r total number events n total number individuals time trial follow-(years)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Elliott WJ, Meyer PM (2007). “Incident diabetes clinical trials antihypertensive drugs: network meta-analysis.” Lancet, 369(9557), 201--207. doi:10.1016/s0140-6736(07)60108-1 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Deviance Information Criterion (DIC) — dic","title":"Deviance Information Criterion (DIC) — dic","text":"Calculate DIC model fitted using nma() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deviance Information Criterion (DIC) — dic","text":"","code":"dic(x, penalty = c(\"pD\", \"pV\"), ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deviance Information Criterion (DIC) — dic","text":"x fitted model object, inheriting class stan_nma penalty method estimating effective number parameters, used penalise model fit DIC. Either \"pD\" (default), \"pV\". survival likelihoods \"pV\" currently available. ... arguments (used)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deviance Information Criterion (DIC) — dic","text":"nma_dic object.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deviance Information Criterion (DIC) — dic","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking FE NMA example if not already available if (!exists(\"smk_fit_FE\")) example(\"example_smk_fe\", run.donttest = TRUE) # } # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC of FE and RE models (smk_dic_FE <- dic(smk_fit_FE)) #> Residual deviance: 267.3 (on 50 data points) #>                pD: 27.2 #>               DIC: 294.5 (smk_dic_RE <- dic(smk_fit_RE))   # substantially better fit #> Residual deviance: 54.4 (on 50 data points) #>                pD: 44.1 #>               DIC: 98.5  # Plot residual deviance contributions under RE model plot(smk_dic_RE)   # Check for inconsistency using UME model # } # \\donttest{ # Run smoking UME NMA example if not already available if (!exists(\"smk_fit_RE_UME\")) example(\"example_smk_ume\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC smk_dic_RE #> Residual deviance: 54.4 (on 50 data points) #>                pD: 44.1 #>               DIC: 98.5 (smk_dic_RE_UME <- dic(smk_fit_RE_UME))  # no difference in fit #> Residual deviance: 53.8 (on 50 data points) #>                pD: 45.2 #>               DIC: 99.1  # Compare residual deviance contributions plot(smk_dic_RE, smk_dic_RE_UME, show_uncertainty = FALSE)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduced dietary fat to prevent mortality — dietary_fat","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"Data frame containing number deaths person-years risk 10 trials comparing reduced fat diets vs. control (non-reduced fat diet) preventing mortality (Hooper et al. 2000; Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"","code":"dietary_fat"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"data frame 21 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name r number events n number randomised E person-years risk","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Hooper L, Summerbell CD, Higgins JPT, Thompson RL, Clements G, Capps N, Davey Smith G, Riemersma R, Ebrahim S (2000). “Reduced modified dietary fat preventing cardiovascular disease.” Cochrane Database Systematic Reviews. ISSN 1465-1858, doi:10.1002/14651858.CD002137 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":null,"dir":"Reference","previous_headings":"","what":"Specify a general marginal distribution — distr","title":"Specify a general marginal distribution — distr","text":"distr() used within function add_integration() specify marginal distributions covariates, via corresponding inverse CDF. also used predict.stan_nma() specify distribution baseline response (intercept) predicting absolute outcomes.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specify a general marginal distribution — distr","text":"","code":"distr(qfun, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specify a general marginal distribution — distr","text":"qfun inverse CDF, either function name string ... parameters distribution arguments qfun, quoted evaluated later context aggregate data sources","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specify a general marginal distribution — distr","text":"object class distr.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Specify a general marginal distribution — distr","text":"function qfun formal argument called p. restriction serves crude check inverse CDFs (e.g. error given dnorm used instead qnorm). user-written CDF supplied, must argument p takes vector probabilities.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Specify a general marginal distribution — distr","text":"","code":"## Specifying marginal distributions for integration  df <- data.frame(x1_mean = 2, x1_sd = 0.5, x2 = 0.8)  # Distribution parameters are evaluated in the context of the data frame add_integration(df,                 x1 = distr(qnorm, mean = x1_mean, sd = x1_sd),                 x2 = distr(qbern, prob = x2),                 cor = diag(2)) #> # A tibble: 1 × 5 #>   x1_mean x1_sd    x2 .int_x1    .int_x2    #>     <dbl> <dbl> <dbl> <list>     <list>     #> 1       2   0.5   0.8 <dbl [64]> <dbl [64]>"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalised Student's t distribution (with location and scale) — dgent","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"Density, distribution, quantile function generalised t distribution degrees freedom df, shifted location scaled scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"","code":"dgent(x, df, location = 0, scale = 1)  pgent(q, df, location = 0, scale = 1)  qgent(p, df, location = 0, scale = 1)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"x, q Vector quantiles df Degrees freedom, greater zero location Location parameter scale Scale parameter, greater zero p Vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"dgent() gives density, pgent() gives distribution function, qgent() gives quantile function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":null,"dir":"Reference","previous_headings":"","what":"Direct and indirect evidence — get_nodesplits","title":"Direct and indirect evidence — get_nodesplits","text":"Determine whether two treatments network connected direct /indirect evidence, generate list comparisons direct indirect evidence (.e. potential inconsistency) node-splitting.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Direct and indirect evidence — get_nodesplits","text":"","code":"get_nodesplits(network, include_consistency = FALSE)  has_direct(network, trt1, trt2)  has_indirect(network, trt1, trt2)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Direct and indirect evidence — get_nodesplits","text":"network nma_data object, created functions set_*() combine_network(). include_consistency Logical, whether include row NAs indicate consistency model (.e. model node-splitting) also fitted nma() function. Default FALSE calling get_nodesplits() hand, nma() sets TRUE default. trt1, trt2 Treatments, single integer, string, factor","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Direct and indirect evidence — get_nodesplits","text":"has_direct() has_indirect(), single logical value. get_nodesplits(), data frame two columns giving comparisons node-splitting.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Direct and indirect evidence — get_nodesplits","text":"list comparisons node-splitting generated following algorithm van Valkenhoef et al. (2016) . comparison two treatments potential inconsistency, thus considered node-splitting, comparison direct evidence independent indirect evidence. notion independent indirect evidence necessary multi-arm trials present, since design trials internally consistent. comparison two treatments independent indirect evidence , removing studies comparing two treatments network, two treatments still connected path evidence. criterion considered has_indirect() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Direct and indirect evidence — get_nodesplits","text":"van Valkenhoef G, Dias S, Ades AE, Welton NJ (2016). “Automated generation node-splitting models assessment inconsistency network meta-analysis.” Research Synthesis Methods, 7(1), 80--93. doi:10.1002/jrsm.1167 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Direct and indirect evidence — get_nodesplits","text":"","code":"# Parkinsons example park_net <- set_agd_arm(parkinsons,                         study = studyn,                         trt = trtn,                         y = y,                         se = se,                         trt_ref = 1) #> Note: Optional argument `sample_size` not provided, some features may not be available (see ?set_agd_arm).  # View the network plot plot(park_net)   # The 4 vs. 5 comparison is a spur on the network has_direct(park_net, 4, 5) #> [1] TRUE has_indirect(park_net, 4, 5) #> [1] FALSE  # 1 and 5 are not directly connected has_direct(park_net, 1, 5) #> [1] FALSE has_indirect(park_net, 1, 5) #> [1] TRUE  # The 1 vs. 2 comparison does not have independent indirect evidence, since # the 1-2-4 loop is a multi-arm study has_indirect(park_net, 1, 2) #> [1] FALSE  # Get a list of comparisons with potential inconsistency for node-splitting get_nodesplits(park_net) #> # A tibble: 4 × 2 #>   trt1  trt2  #>   <fct> <fct> #> 1 1     3     #> 2 1     4     #> 3 2     4     #> 4 3     4      # See van Valkenhoef (2016) for a discussion of this example"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert networks to graph objects — as.igraph.nma_data","title":"Convert networks to graph objects — as.igraph.nma_data","text":"method .igraph() converts nma_data objects form used igraph package. method as_tbl_graph() converts nma_data objects form used ggraph tidygraph packages.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert networks to graph objects — as.igraph.nma_data","text":"","code":"# S3 method for nma_data as.igraph(x, ..., collapse = TRUE)  # S3 method for nma_data as_tbl_graph(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert networks to graph objects — as.igraph.nma_data","text":"x nma_data object convert ... Additional arguments collapse Logical, collapse edges studies? Default TRUE, one edge produced comparison (IPD AgD study type) .nstudy attribute giving number studies making comparison. FALSE, repeated edges added study making comparison.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert networks to graph objects — as.igraph.nma_data","text":"igraph object .igraph(), tbl_graph object as_tbl_graph().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert networks to graph objects — as.igraph.nma_data","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # Convert to igraph object igraph::as.igraph(smk_net)  # Edges combined by default #> IGRAPH 1cf35e8 UN-- 4 6 --  #> + attr: name (v/c), .sample_size (v/n), .nstudy (e/n), .type (e/c) #> + edges from 1cf35e8 (vertex names): #> [1] No intervention       --Group counselling      #> [2] No intervention       --Individual counselling #> [3] Group counselling     --Individual counselling #> [4] No intervention       --Self-help              #> [5] Group counselling     --Self-help              #> [6] Individual counselling--Self-help              igraph::as.igraph(smk_net, collapse = FALSE)  # Without combining edges #> IGRAPH 644a0cb UN-- 4 28 --  #> + attr: name (v/c), .sample_size (v/n), .study (e/c), .type (e/c) #> + edges from 644a0cb (vertex names): #>  [1] No intervention       --Group counselling      #>  [2] No intervention       --Individual counselling #>  [3] Group counselling     --Individual counselling #>  [4] Group counselling     --Individual counselling #>  [5] Group counselling     --Self-help              #>  [6] Individual counselling--Self-help              #>  [7] No intervention       --Individual counselling #>  [8] No intervention       --Individual counselling #> + ... omitted several edges  # Convert to tbl_graph object tidygraph::as_tbl_graph(smk_net)  # Edges combined by default #> # A tbl_graph: 4 nodes and 6 edges #> # #> # An undirected simple graph with 1 component #> # #> # A tibble: 4 × 2 #>   name                   .sample_size #>   <chr>                         <dbl> #> 1 No intervention                7231 #> 2 Group counselling               555 #> 3 Individual counselling         7383 #> 4 Self-help                      1571 #> # #> # A tibble: 6 × 4 #>    from    to .nstudy .type #>   <int> <int>   <int> <chr> #> 1     1     2       2 AgD   #> 2     1     3      15 AgD   #> 3     2     3       4 AgD   #> # ℹ 3 more rows tidygraph::as_tbl_graph(smk_net, collapse = FALSE)  # Without combining edges #> # A tbl_graph: 4 nodes and 28 edges #> # #> # An undirected multigraph with 1 component #> # #> # A tibble: 4 × 2 #>   name                   .sample_size #>   <chr>                         <dbl> #> 1 No intervention                7231 #> 2 Group counselling               555 #> 3 Individual counselling         7383 #> 4 Self-help                      1571 #> # #> # A tibble: 28 × 4 #>    from    to .study .type #>   <int> <int> <chr>  <chr> #> 1     1     2 1      AgD   #> 2     1     3 1      AgD   #> 3     2     3 1      AgD   #> # ℹ 25 more rows"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":null,"dir":"Reference","previous_headings":"","what":"HTA Plaque Psoriasis — hta_psoriasis","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"Data frame containing results 16 trials comparing 8 treatments moderate--severe plaque psoriasis HTA report (Woolacott et al. 2006) , analysed TSD2 (Dias et al. 2011) . Outcomes success/failure achieve 50%, 75%, 90% reduction symptoms Psoriasis Area Severity Index (PASI) scale. studies report three ordered outcomes, others one two. latter coded missing values (see details).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"","code":"hta_psoriasis"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"data frame 36 rows 9 variables: studyn numeric study ID studyc study name year year publication trtn numeric treatment code trtc treatment name sample_size sample size arm PASI50, PASI75, PASI90 ordered multinomial outcome counts (exclusive, see details)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"Outcome counts \"exclusive\"; , study reporting outcomes, counts represent categories 50 < PASI < 75, 75 < PASI < 90, 90 < PASI < 100, named lower end interval. (opposed \"inclusive\" counts, represent overlapping categories PASI > 50, PASI > 70, PASI > 90.) count fourth category (lowest), 0 < PASI < 50, equal sample_size - PASI50 - PASI75 - PASI90. Missing values used studies report subset outcomes. study reporting two outcomes, say 50 75, counts represent 50 < PASI < 75 75 < PASI < 100. study reporting one outcome, say PASI 75, count represents 75 < PASI < 100.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Woolacott N, Hawkins N, Mason , Kainth , Khadjesari Z, Bravo Vergel Y, Misso K, Light K, Chalmers R, Sculpher M, Riemsma R (2006). “Etanercept efalizumab treatment psoriasis: systematic review.” Health Technology Assessment, 10(46). doi:10.3310/hta10460 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":null,"dir":"Reference","previous_headings":"","what":"Check network connectedness — is_network_connected","title":"Check network connectedness — is_network_connected","text":"Check whether network connected - whether path study evidence linking every pair treatments network.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check network connectedness — is_network_connected","text":"","code":"is_network_connected(network)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check network connectedness — is_network_connected","text":"network nma_data object, created functions set_*() combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check network connectedness — is_network_connected","text":"Logical TRUE FALSE","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check network connectedness — is_network_connected","text":"Models still run disconnected networks. However, estimated relative effects treatments across disconnected parts network entirely based prior distribution (typically uncertain), information update prior distribution. Relative effects within connected sub-network estimated sub-network analysed separately.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check network connectedness — is_network_connected","text":"","code":"## Smoking cessation # Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  is_network_connected(smk_net)  # TRUE, network is connected #> [1] TRUE ## A disconnected network disc_net <- set_agd_arm(smoking[smoking$studyn %in% c(15, 21), ],                         study = studyn,                         trt = trtc,                         r = r,                         n = n) is_network_connected(disc_net)  # FALSE, network is disconnected #> [1] FALSE disc_net #> A network with 2 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                         #>  15    2: Group counselling | No intervention #>  21    2: Individual counselling | Self-help  #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 2 #> Reference treatment is: Group counselling #> Network is disconnected plot(disc_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Student's t distribution — dlogt","title":"Log Student's t distribution — dlogt","text":"Density, distribution, quantile function log t distribution, whose logarithm degrees freedom df, mean location, standard deviation scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Student's t distribution — dlogt","text":"","code":"dlogt(x, df, location = 0, scale = 1)  plogt(q, df, location = 0, scale = 1)  qlogt(p, df, location = 0, scale = 1)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Student's t distribution — dlogt","text":"x, q Vector quantiles df Degrees freedom, greater zero location Location parameter scale Scale parameter, greater zero p Vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Student's t distribution — dlogt","text":"dlogt() gives density, plogt() gives distribution function, qlogt() gives quantile function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log Student's t distribution — dlogt","text":"\\(\\log(Y) \\sim t_\\nu(\\mu, \\sigma^2)\\), \\(Y\\) log t distribution location \\(\\mu\\), scale \\(\\sigma\\), df \\(\\nu\\). mean higher moments log t distribution undefined infinite. df = 1 distribution log Cauchy distribution. df tends infinity, approaches log Normal distribution.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":null,"dir":"Reference","previous_headings":"","what":"The logit Normal distribution — qlogitnorm","title":"The logit Normal distribution — qlogitnorm","text":"provide convenient extensions [dpq]logitnorm functions package logitnorm, allow distribution specified terms mean standard deviation, instead logit-mean logit-sd.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The logit Normal distribution — qlogitnorm","text":"","code":"qlogitnorm(p, mu = 0, sigma = 1, ..., mean, sd)  dlogitnorm(x, mu = 0, sigma = 1, ..., mean, sd)  plogitnorm(q, mu = 0, sigma = 1, ..., mean, sd)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The logit Normal distribution — qlogitnorm","text":"p, x vector quantiles mu, sigma, ... see logitnorm mean, sd mean standard deviation, overriding mu sigma specified q vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":null,"dir":"Reference","previous_headings":"","what":"Model comparison using the loo package — loo.stan_nma","title":"Model comparison using the loo package — loo.stan_nma","text":"loo() waic() functions loo package may called directly stan_nma stan_mlnmr objects.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model comparison using the loo package — loo.stan_nma","text":"","code":"# S3 method for stan_nma loo(x, ...)  # S3 method for stan_nma waic(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model comparison using the loo package — loo.stan_nma","text":"x object class stan_nma stan_mlnmr ... arguments loo() waic()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Working with 3D MCMC arrays — mcmc_array-class","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"3D MCMC arrays (Iterations, Chains, Parameters) produced .array() methods applied stan_nma nma_summary objects.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"","code":"# S3 method for mcmc_array summary(object, ..., probs = c(0.025, 0.25, 0.5, 0.75, 0.975))  # S3 method for mcmc_array print(x, ...)  # S3 method for mcmc_array names(x)  # S3 method for mcmc_array names(x) <- value"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"... arguments passed methods probs Numeric vector quantiles interest x, object 3D MCMC array class mcmc_array value Character vector replacement parameter names","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"summary() method returns nma_summary object, print() method returns x invisibly. names() method returns character vector parameter names, names()<- returns object updated parameter names.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Working with arrays of posterior draws (as mcmc_array objects) is # convenient when transforming parameters  # Transforming log odds ratios to odds ratios LOR_array <- as.array(relative_effects(smk_fit_RE)) OR_array <- exp(LOR_array)  # mcmc_array objects can be summarised to produce a nma_summary object smk_OR_RE <- summary(OR_array)  # This can then be printed or plotted smk_OR_RE #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling]      3.33 1.74 1.30 2.25 2.99 3.94  7.18     1889     2027 #> d[Individual counselling] 2.41 0.61 1.49 1.98 2.33 2.74  3.84     1052     1684 #> d[Self-help]              1.79 0.80 0.74 1.26 1.62 2.13  3.84     1466     1962 #>                           Rhat #> d[Group counselling]         1 #> d[Individual counselling]    1 #> d[Self-help]                 1 plot(smk_OR_RE, ref_line = 1)   # Transforming heterogeneity SD to variance tau_array <- as.array(smk_fit_RE, pars = \"tau\") tausq_array <- tau_array^2  # Correct parameter names names(tausq_array) <- \"tausq\"  # Summarise summary(tausq_array) #>       mean   sd 2.5% 25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq 0.75 0.36  0.3 0.5 0.67 0.91  1.66     1153     1486    1 # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":null,"dir":"Reference","previous_headings":"","what":"Distribution functions for M-spline baseline hazards — dmspline","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"Density, distribution, quantile, hazard, cumulative hazard, restricted mean survival time functions M-spline baseline hazards model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"","code":"dmspline(x, basis, scoef, rate, log = FALSE)  pmspline(q, basis, scoef, rate, lower.tail = TRUE, log.p = FALSE)  qmspline(p, basis, scoef, rate, lower.tail = TRUE, log.p = FALSE)  hmspline(x, basis, scoef, rate, log = FALSE)  Hmspline(x, basis, scoef, rate, log = FALSE)  rmst_mspline(t, basis, scoef, rate, start = 0)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"x, q Vector quantiles basis M-spline basis produced splines2::mSpline() scoef Vector (matrix) spline coefficients length (number columns) equal dimension basis rate Vector rate parameters log, log.p Logical; TRUE, probabilities p given \\(\\log(p)\\) lower.tail Logical; TRUE (default), probabilities \\(P(X \\le x)\\), otherwise \\(P(X > x)\\) p Vector probabilities t Vector times restricted mean survival time calculated start Optional left-truncation time times. returned restricted mean survival conditioned survival time","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"dmspline() gives density, pmspline() gives distribution function (CDF), qmspline() gives quantile function (inverse-CDF), hmspline() gives hazard function, Hmspline() gives cumulative hazard function, rmst_mspline() gives restricted mean survival times.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"Survival models flexible M-spline baseline hazard described Brilleman et al. (2020) . Piecewise-exponential baseline hazards special case degree M-spline polynomial 0. d/p/h/H functions calculated definitions. qmspline() uses numerical inversion via flexsurv::qgeneric(). rmst_mspline()uses numerical integration via flexsurv::rmst_generic(), except special case piecewise-exponential hazard (.e. degree 0 M-splines) uses explicit formula Royston Parmar (2013) . Beyond boundary knots, hazard assumed constant. (differs approach splines2::mSpline() extrapolates polynomial basis functions, numerically unstable highly dependent data just boundary knots.) extrapolation, care taken evaluating splines times beyond boundary knots (either directly d/p/h/H/rmst functions, indirectly requesting quantiles qmspline() correspond times beyond boundary knots). reason evaluating (unrestricted) mean survival time generally recommended requires integrating infinite time horizon (.e. rmst_mspline() t = Inf).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"Brilleman SL, Elci EM, Novik JB, Wolfe R (2020). “Bayesian Survival Analysis Using rstanarm R Package.” arXiv. doi:10.48550/arXiv.2002.09633 , 2002.09633. Royston P, Parmar MKB (2013). “Restricted mean survival time: alternative hazard ratio design analysis randomized trials time--event outcome.” BMC Medical Research Methodology, 13(1). doi:10.1186/1471-2288-13-152 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial outcome data — multi","title":"Multinomial outcome data — multi","text":"function aids specification multinomial outcome data setting network set_agd_arm() set_ipd(). takes set columns (, generally, numeric vectors length) outcome counts category, binds together produce matrix.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multinomial outcome data — multi","text":"","code":"multi(..., inclusive = FALSE, type = c(\"ordered\", \"competing\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multinomial outcome data — multi","text":"... Two numeric columns (vectors) category counts. Argument names (optional) used label categories. inclusive Logical, ordered category counts inclusive (TRUE) exclusive (FALSE)? Default FALSE. used ordered = TRUE. See details. type String, indicating whether categories \"ordered\" \"competing\". Currently ordered categorical outcomes supported modelling functions package.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multinomial outcome data — multi","text":"matrix (exclusive) category counts","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multinomial outcome data — multi","text":"specifying ordered categorical counts, can either given exclusive counts (inclusive = FALSE, default) individuals counted highest category achieve, inclusive counts (inclusive = TRUE) individuals counted every category including highest category achieved. (Competing outcomes, nature, always specified exclusive counts.) NA values can used indicate categories/cutpoints measured.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multinomial outcome data — multi","text":"","code":"# These two data sets specify the same ordered categorical data for outcomes # r0 < r1 < r2, but the first uses the \"inclusive\" format and the second the # \"exclusive\" format. df_inclusive <- tibble::tribble(~r0, ~r1, ~r2,                                 1, 1, 1,                                 5, 4, 1,                                 5, 2, 2,                                 10, 5, 0,                                 5, 5, 0,                                 7, NA, 6,   # Achieved r2 or not (no r1)                                 10, 4, NA)  # Achieved r1 or not (no r2)  df_exclusive <- tibble::tribble(~r0, ~r1, ~r2,                                 0, 0, 1,                                 1, 3, 1,                                 3, 0, 2,                                 5, 5, 0,                                 0, 5, 0,                                 1, NA, 6,   # Achieved r2 or not (no r1)                                 6, 4, NA)   # Achieved r1 or not (no r2)  (r_inclusive <- with(df_inclusive, multi(r0, r1, r2, inclusive = TRUE))) #>      r0 r1 r2 #> [1,]  0  0  1 #> [2,]  1  3  1 #> [3,]  3  0  2 #> [4,]  5  5  0 #> [5,]  0  5  0 #> [6,]  1 NA  6 #> [7,]  6  4 NA #> attr(,\"class\") #> [1] \"multi_ordered\" \"matrix\"        \"array\"         (r_exclusive <- with(df_exclusive, multi(r0, r1, r2, inclusive = FALSE))) #>      r0 r1 r2 #> [1,]  0  0  1 #> [2,]  1  3  1 #> [3,]  3  0  2 #> [4,]  5  5  0 #> [5,]  0  5  0 #> [6,]  1 NA  6 #> [7,]  6  4 NA #> attr(,\"class\") #> [1] \"multi_ordered\" \"matrix\"        \"array\"          # Counts are always stored in exclusive format stopifnot(isTRUE(all.equal(r_inclusive, r_exclusive)))   ## HTA Plaque Psoriasis library(dplyr)  # Ordered outcomes here are given as \"exclusive\" counts head(hta_psoriasis) #>   studyn   studyc year trtn             trtc sample_size PASI50 PASI75 PASI90 #> 1      1  Elewski 2004    1  Supportive care         193     12      5      1 #> 2      1  Elewski 2004    2 Etanercept 25 mg         196     59     46     21 #> 3      1  Elewski 2004    3 Etanercept 50 mg         194     54     56     40 #> 4      2 Gottlieb 2003    1  Supportive care          55      5      1      0 #> 5      2 Gottlieb 2003    2 Etanercept 25 mg          57     23     11      6 #> 6      3  Lebwohl 2003    1  Supportive care         122     13      5      1  # Calculate lowest category count (failure to achieve PASI 50) pso_dat <- hta_psoriasis %>%   mutate(`PASI<50` = sample_size - rowSums(cbind(PASI50, PASI75, PASI90), na.rm = TRUE))  # Set up network pso_net <- set_agd_arm(pso_dat,                        study = paste(studyc, year),                        trt = trtc,                        r = multi(`PASI<50`, PASI50, PASI75, PASI90,                                  inclusive = FALSE,                                  type = \"ordered\"))  pso_net #> A network with 16 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                           #>  ACD2058g 2004 2: Supportive care | Efalizumab                          #>  ACD2600g 2004 2: Supportive care | Efalizumab                          #>  Altmeyer 1994 2: Supportive care | Fumaderm                            #>  Chaudari 2001 2: Supportive care | Infliximab                          #>  Elewski 2004  3: Supportive care | Etanercept 25 mg | Etanercept 50 mg #>  Ellis 1991    3: Supportive care | Ciclosporin | Ciclosporin           #>  Gordon 2003   2: Supportive care | Efalizumab                          #>  Gottlieb 2003 2: Supportive care | Etanercept 25 mg                    #>  Gottlieb 2004 3: Supportive care | Infliximab | Infliximab             #>  Guenther 1991 2: Supportive care | Ciclosporin                         #>  ... plus 6 more studies #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 8 #> Total number of studies: 16 #> Reference treatment is: Supportive care #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":null,"dir":"Reference","previous_headings":"","what":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"R package performing network meta-analysis network meta-regression aggregate data, individual patient data, mixtures .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"Network meta-analysis (NMA) combines (aggregate) data multiple studies multiple treatments order produce consistent estimates relative treatment effects pair treatments network (Dias et al. 2011) . Network meta-regression (NMR) extends NMA include covariates, allowing adjustment differences effect-modifying variables studies (Dias et al. 2011) . NMR typically performed using aggregate data (AgD), lacks power prone ecological bias. NMR individual patient data (IPD) gold standard, data available. Multilevel network meta-regression (ML-NMR) allows IPD AgD incorporated together network meta-regression (Phillippo et al. 2020; Phillippo 2019) . IPD NMR, individual-level regression model defined. AgD studies fitted integrating individual-level model respective covariate distributions. correctly links two levels model (instead \"plugging \" mean covariate values), avoiding aggregation bias. Population-adjusted treatment effects (Phillippo et al. 2016)  can produced study population network, external target population. Models estimated Bayesian framework using Stan (Carpenter et al. 2017) . Quasi-Monte Carlo numerical integration based Sobol' sequences used integration ML-NMR models, Gaussian copula account correlations covariates (Phillippo et al. 2020; Phillippo 2019) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"getting-started","dir":"Reference","previous_headings":"","what":"Getting Started","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"good place start package vignettes walk example analyses, see vignette(\"vignette_overview\") overview. series NICE Technical Support Documents evidence synthesis gives detailed introduction network meta-analysis: Dias S, Welton NJ, Sutton AJ, Caldwell DM, Lu G, Reken S, Ades AE (2011). “NICE DSU Technical Support Documents 1-7: Evidence Synthesis Decision Making.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Multilevel network meta-regression set following methods paper: Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"Carpenter B, Gelman , Hoffman MD, Lee D, Goodrich B, Betancourt M, Brubaker M, Guo J, Li P, Riddell (2017). “Stan: Probabilistic Programming Language.” Journal Statistical Software, 76(1). doi:10.18637/jss.v076.i01 . Dias S, Sutton AJ, Welton NJ, Ades AE (2011). “NICE DSU Technical Support Document 3: Heterogeneity: subgroups, meta-regression, bias bias-adjustment.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Phillippo DM (2019). Calibration Treatment Effects Network Meta-Analysis using Individual Patient Data. Ph.D. thesis, University Bristol. Available https://research-information.bris.ac.uk/. Phillippo DM, Ades AE, Dias S, Palmer S, Abrams KR, Welton NJ (2016). “NICE DSU Technical Support Document 18: Methods population-adjusted indirect comparisons submission NICE.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Newly diagnosed multiple myeloma — ndmm_ipd","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"Three data frames, ndmm_ipd, ndmm_agd, ndmm_agd_covs containing (simulated) individual patient data (IPD) three studies aggregate data (AgD) two studies newly diagnosed multiple myeloma. outcome interest progression-free survival autologous stem cell transplant. IPD studies ndmm_ipd provide event/censoring times covariate values individual. AgD studies provide reconstructed event/censoring times digitized Kaplan-Meier curves ndmm_agd covariate summaries ndmm_agd_covs, obtained published trial reports. data constructed resemble used Leahy Walsh (2019) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"","code":"ndmm_ipd  ndmm_agd  ndmm_agd_covs"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"individual patient data contained data frame ndmm_ipd 1325 rows, one per individual, 10 variables: study, studyf study name trt, trtf treatment name eventtime event/censoring time status censoring indicator (0 = censored, 1 = event) age age (years) iss_stage3 ISS stage 3 (0 = , 1 = yes) response_cr_vgpr complete good partial response (0 = , 1 = yes) male male sex (0 = , 1 = yes) reconstructed Kaplan-Meier data aggregate studies contained data frame ndmm_agd 2819 rows 6 variables: study, studyf study name trt, trtf treatment name eventtime event/censoring time status censoring indicator (0 = censored, 1 = event) covariate summaries extracted published reportes aggregate studies contained data frame ndmm_agd_covs 4 rows, one per study arm, 15 columns: study, studyf study name trt, trtf treatment name sample_size sample size arm age_min, age_iqr_l, age_median, age_iqr_h, age_max, age_mean, age_sd summary statistics age (years) iss_stage3 proportion participants ISS stage 3 response_cr_vgpr proportion participants complete good partial response male proportion male participants","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"Leahy J, Walsh C (2019). “Assessing impact matching-adjusted indirect comparison Bayesian network meta-analysis.” Research Synthesis Methods, 10(4), 546--568. doi:10.1002/jrsm.1372 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Network meta-analysis models — nma","title":"Network meta-analysis models — nma","text":"nma function fits network meta-analysis (multilevel) network meta-regression models Stan.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Network meta-analysis models — nma","text":"","code":"nma(   network,   consistency = c(\"consistency\", \"ume\", \"nodesplit\"),   trt_effects = c(\"fixed\", \"random\"),   regression = NULL,   class_interactions = c(\"common\", \"exchangeable\", \"independent\"),   likelihood = NULL,   link = NULL,   ...,   nodesplit = get_nodesplits(network, include_consistency = TRUE),   prior_intercept = .default(normal(scale = 100)),   prior_trt = .default(normal(scale = 10)),   prior_het = .default(half_normal(scale = 5)),   prior_het_type = c(\"sd\", \"var\", \"prec\"),   prior_reg = .default(normal(scale = 10)),   prior_aux = .default(),   aux_by = NULL,   QR = FALSE,   center = TRUE,   adapt_delta = NULL,   int_thin = 0,   int_check = TRUE,   mspline_degree = 3,   n_knots = 3,   knots = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Network meta-analysis models — nma","text":"network nma_data object, created functions set_*(), combine_network(), add_integration() consistency Character string specifying type ()consistency model fit, either \"consistency\", \"ume\", \"nodesplit\" trt_effects Character string specifying either \"fixed\" \"random\" effects regression one-sided model formula, specifying prognostic effect-modifying terms regression model. references treatment use .trt special variable, example specifying effect modifier interactions variable:.trt (see details). class_interactions Character string specifying whether effect modifier interactions specified \"common\", \"exchangeable\", \"independent\". likelihood Character string specifying likelihood, unspecified inferred data (see details) link Character string specifying link function, unspecified default canonical link (see details) ... arguments passed sampling(), iter, chains, cores, etc. nodesplit consistency = \"nodesplit\", comparison(s) split node-splitting model(s). Either length 2 vector giving treatments single comparison, 2 column data frame listing multiple treatment comparisons split turn. default, possible comparisons chosen (see get_nodesplits()). prior_intercept Specification prior distribution intercept prior_trt Specification prior distribution treatment effects prior_het Specification prior distribution heterogeneity (trt_effects = \"random\") prior_het_type Character string specifying whether prior distribution prior_het placed heterogeneity standard deviation \\(\\tau\\) (\"sd\", default), variance \\(\\tau^2\\) (\"var\"), precision \\(1/\\tau^2\\) (\"prec\"). prior_reg Specification prior distribution regression coefficients (regression formula specified) prior_aux Specification prior distribution auxiliary parameter, applicable (see details). likelihood = \"gengamma\" list prior distributions elements sigma k. aux_by Vector variable names listing variables stratify auxiliary parameters . Currently used survival models, see details. QR Logical scalar (default FALSE), whether apply QR decomposition model design matrix center Logical scalar (default TRUE), whether center (numeric) regression terms overall means adapt_delta See adapt_delta details int_thin single integer value, thinning factor returning cumulative estimates integration error. Saving cumulative estimates disabled int_thin = 0, default. int_check Logical, check sufficient accuracy numerical integration fitting half chains n_int/2? TRUE, Rhat n_eff diagnostic warnings given numerical integration sufficiently converged (suggesting increasing n_int add_integration()). Default TRUE, disabled (FALSE) int_thin > 0. mspline_degree Non-negative integer giving degree M-spline polynomial likelihood = \"mspline\". Piecewise exponential hazards (likelihood = \"pexp\") special case mspline_degree = 0. n_knots mspline pexp likelihoods, non-negative integer giving number internal knots partitioning baseline hazard intervals. knot locations within study determined corresponding quantiles observed event times, plus boundary knots earliest entry time (0 delayed entry) maximum event/censoring time. example, default n_knots = 3, internal knot locations 25%, 50%, 75% quantiles observed event times. Ignored knots specified. knots mspline pexp likelihoods, named list numeric vectors internal knot locations studies network. Currently, vector must length (.e. study must use number knots). unspecified (default), knots chosen based n_knots described .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Network meta-analysis models — nma","text":"nma() returns stan_nma object, except consistency = \"nodesplit\" nma_nodesplit nma_nodesplit_df object returned. nma.fit() returns stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Network meta-analysis models — nma","text":"specifying model formula regression argument, usual formula syntax available (interpreted model.matrix()). additional requirement special variable .trt used refer treatment. example, effect modifier interactions specified variable:.trt. Prognostic (main) effects interactions can included together compactly variable*.trt, expands variable + variable:.trt (plus .trt, already NMA model). advanced user, additional specials .study .trtclass also available, refer studies (specified) treatment classes respectively. node-splitting models fitted (consistency = \"nodesplit\") special .omega available, indicating arms node-splitting inconsistency factor added. See ?priors details prior specification. Default prior distributions available, may appropriate particular setting raise warning used. attempt made tailor defaults data provided. Please consider appropriate prior distributions particular setting, accounting scales outcomes covariates, etc. function plot_prior_posterior() may useful examining influence chosen prior distributions posterior distributions, summary() method nma_prior objects prints prior intervals.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"likelihoods-and-link-functions","dir":"Reference","previous_headings":"","what":"Likelihoods and link functions","title":"Network meta-analysis models — nma","text":"Currently, following likelihoods link functions supported data type: bernoulli2 binomial2 likelihoods correspond two-parameter Binomial likelihood arm-based AgD, closely matches underlying Poisson Binomial distribution summarised aggregate outcomes ML-NMR model typical (one parameter) Binomial distribution (see Phillippo et al. 2020) . cloglog link used, including offset log follow-time (.e. regression = ~offset(log(time))) results model log hazard (see Dias et al. 2011) . survival data, accelerated failure time models (exponential-aft, weibull-aft, lognormal, loglogistic, gamma, gengamma) parameterised treatment effects regression parameters log Survival Time Ratios (.e. coefficient \\(\\log(2)\\) means treatment covariate associated doubling expected survival time). can converted log Acceleration Factors using relation \\(\\log(\\mathrm{AF}) = -\\log(\\mathrm{STR})\\) (equivalently \\(\\mathrm{AF} = 1/\\mathrm{STR}\\)). details likelihood link function given Dias et al. (2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"auxiliary-parameters","dir":"Reference","previous_headings":"","what":"Auxiliary parameters","title":"Network meta-analysis models — nma","text":"Auxiliary parameters present following models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"normal-likelihood-with-ipd","dir":"Reference","previous_headings":"","what":"Normal likelihood with IPD","title":"Network meta-analysis models — nma","text":"Normal likelihood fitted IPD, auxiliary parameters arm-level standard deviations \\(\\sigma_{jk}\\) treatment \\(k\\) study \\(j\\).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"ordered-multinomial-likelihood","dir":"Reference","previous_headings":"","what":"Ordered multinomial likelihood","title":"Network meta-analysis models — nma","text":"fitting model \\(M\\) ordered outcomes, auxiliary parameters latent cutoffs category, \\(c_0 < c_1 < \\dots <   c_M\\). \\(c_2\\) \\(c_{M-1}\\) estimated; fix \\(c_0 =   -\\infty\\), \\(c_1 = 0\\), \\(c_M = \\infty\\). specifying priors latent cutoffs, choose specify priors differences \\(c_{m+1} - c_m\\). Stan automatically truncates priors ordering constraints satisfied.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"survival-time-to-event-likelihoods","dir":"Reference","previous_headings":"","what":"Survival (time-to-event) likelihoods","title":"Network meta-analysis models — nma","text":"survival likelihoods except exponential exponential-aft likelihoods auxiliary parameters. typically study-specific shape parameters \\(\\gamma_j>0\\), except lognormal likelihood auxiliary parameters study-specific standard deviations log scale \\(\\sigma_j>0\\). gengamma likelihood two sets auxiliary parameters, study-specific scale parameters \\(\\sigma_j>0\\) shape parameters \\(k_j\\), following parameterisation Lawless (1980) , permits range behaviours baseline hazard including increasing, decreasing, bathtub arc-shaped hazards. parameterisation related discussed Cox et al. (2007)  implemented flexsurv package \\(Q = k^{-0.5}\\). parameterisation used effectively bounds shape parameter \\(k\\) away numerical instabilities \\(k \\rightarrow \\infty\\) (.e. away \\(Q   \\rightarrow 0\\), log-Normal distribution) via prior distribution. Implicitly, parameterisation restricted \\(Q > 0\\) certain survival distributions like inverse-Gamma inverse-Weibull part parameter space; however, \\(Q > 0\\) still encompasses survival distributions implemented package. mspline pexp likelihoods, auxiliary parameters spline coefficients study. form unit simplex (.e. lie 0 1, sum 1), given dirichlet() prior distribution. auxiliary parameters can stratified additional factors aux_by argument. example, allow shape baseline hazard vary treatment arms well studies, use aux_by = c(\".study\", \".trt\"). (Technically, .study always included stratification even omitted aux_by, choose make stratification explicit.) common way relaxing proportional hazards assumption. default equivalent aux_by = \".study\" stratifies auxiliary parameters study, described .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Network meta-analysis models — nma","text":"Cox C, Chu H, Schneider MF, Mu~noz (2007). “Parametric survival analysis taxonomy hazard functions generalized gamma distribution.” Statistics Medicine, 26(23), 4352--4374. doi:10.1002/sim.2836 . Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Lawless JF (1980). “Inference Generalized Gamma Log Gamma Distributions.” Technometrics, 22(3), 409--419. doi:10.1080/00401706.1980.10486173 . Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Network meta-analysis models — nma","text":"","code":"## Smoking cessation NMA # Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting a fixed effect model smk_fit_FE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100))  smk_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          0.84    0.00 0.18     0.49     0.72     0.84 #> d[Individual counselling]     0.77    0.00 0.06     0.65     0.73     0.77 #> d[Self-help]                  0.22    0.00 0.12    -0.02     0.14     0.22 #> lp__                      -6008.40    0.09 3.71 -6016.74 -6010.61 -6008.06 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          0.96     1.18  2054    1 #> d[Individual counselling]     0.81     0.88  1543    1 #> d[Self-help]                  0.31     0.47  2228    1 #> lp__                      -6005.79 -6002.28  1750    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:19:42 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\donttest{ # Fitting a random effects model smk_fit_RE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = normal(scale = 5))  smk_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          1.11    0.01 0.43     0.28     0.81     1.10 #> d[Individual counselling]     0.85    0.01 0.25     0.37     0.69     0.84 #> d[Self-help]                  0.49    0.01 0.39    -0.26     0.22     0.49 #> lp__                      -5919.96    0.20 6.51 -5933.65 -5924.12 -5919.69 #> tau                           0.84    0.01 0.19     0.55     0.70     0.81 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          1.39     1.99  1645    1 #> d[Individual counselling]     1.01     1.35   992    1 #> d[Self-help]                  0.76     1.29  1788    1 #> lp__                      -5915.40 -5908.25  1041    1 #> tau                           0.95     1.30  1019    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:19:56 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\donttest{ # Fitting an unrelated mean effects (inconsistency) model smk_fit_RE_UME <- nma(smk_net, refresh = if (interactive()) 200 else 0,                       consistency = \"ume\",                       trt_effects = \"random\",                       prior_intercept = normal(scale = 100),                       prior_trt = normal(scale = 100),                       prior_het = normal(scale = 5))  smk_fit_RE_UME #> A random effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                     mean se_mean   sd     2.5% #> d[Group counselling vs. No intervention]            1.14    0.02 0.81    -0.38 #> d[Individual counselling vs. No intervention]       0.91    0.01 0.28     0.40 #> d[Self-help vs. No intervention]                    0.33    0.01 0.58    -0.78 #> d[Individual counselling vs. Group counselling]    -0.29    0.01 0.60    -1.47 #> d[Self-help vs. Group counselling]                 -0.62    0.02 0.72    -2.07 #> d[Self-help vs. Individual counselling]             0.16    0.02 1.08    -2.04 #> lp__                                            -5933.22    0.19 6.30 -5946.38 #> tau                                                 0.94    0.01 0.23     0.59 #>                                                      25%      50%      75% #> d[Group counselling vs. No intervention]            0.60     1.12     1.63 #> d[Individual counselling vs. No intervention]       0.72     0.90     1.08 #> d[Self-help vs. No intervention]                   -0.05     0.32     0.70 #> d[Individual counselling vs. Group counselling]    -0.69    -0.30     0.10 #> d[Self-help vs. Group counselling]                 -1.09    -0.62    -0.16 #> d[Self-help vs. Individual counselling]            -0.52     0.21     0.87 #> lp__                                            -5937.27 -5932.90 -5928.80 #> tau                                                 0.78     0.91     1.06 #>                                                    97.5% n_eff Rhat #> d[Group counselling vs. No intervention]            2.83  2459 1.00 #> d[Individual counselling vs. No intervention]       1.52  1029 1.01 #> d[Self-help vs. No intervention]                    1.51  1819 1.00 #> d[Individual counselling vs. Group counselling]     0.91  2275 1.00 #> d[Self-help vs. Group counselling]                  0.80  2203 1.00 #> d[Self-help vs. Individual counselling]             2.17  2856 1.00 #> lp__                                            -5921.75  1144 1.00 #> tau                                                 1.49  1122 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:20:09 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\donttest{ # Fitting all possible node-splitting models smk_fit_RE_nodesplit <- nma(smk_net, refresh = if (interactive()) 200 else 0,                             consistency = \"nodesplit\",                             trt_effects = \"random\",                             prior_intercept = normal(scale = 100),                             prior_trt = normal(scale = 100),                             prior_het = normal(scale = 5)) #> Fitting model 1 of 7, node-split: Group counselling vs. No intervention #> Fitting model 2 of 7, node-split: Individual counselling vs. No intervention #> Fitting model 3 of 7, node-split: Self-help vs. No intervention #> Fitting model 4 of 7, node-split: Individual counselling vs. Group counselling #> Fitting model 5 of 7, node-split: Self-help vs. Group counselling #> Fitting model 6 of 7, node-split: Self-help vs. Individual counselling #> Fitting model 7 of 7, consistency model # }  # \\donttest{ # Summarise the node-splitting results summary(smk_fit_RE_nodesplit) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.11 0.44  0.26  0.82  1.10 1.40  2.00     1647     2254    1 #> d_dir            1.08 0.76 -0.32  0.57  1.05 1.55  2.66     3214     2670    1 #> d_ind            1.11 0.56  0.02  0.76  1.12 1.47  2.23     1788     2024    1 #> omega           -0.03 0.92 -1.75 -0.63 -0.06 0.53  1.87     2353     2493    1 #> tau              0.88 0.21  0.55  0.74  0.85 1.00  1.35     1112     1696    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82 0.95  1.26     1250     1938    1 #>  #> Residual deviance: 54 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.3 #>  #> Bayesian p-value: 0.94 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.84 0.25  0.37  0.68 0.83 0.99  1.35     1081     1753    1 #> d_dir           0.88 0.26  0.38  0.71 0.88 1.05  1.42     1504     2201    1 #> d_ind           0.53 0.67 -0.74  0.08 0.52 0.96  1.88     1121     1653    1 #> omega           0.35 0.70 -1.02 -0.10 0.34 0.83  1.68     1130     1734    1 #> tau             0.86 0.20  0.55  0.73 0.83 0.98  1.31     1050     1730    1 #> tau_consistency 0.84 0.19  0.54  0.71 0.82 0.95  1.26     1250     1938    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44 #>               DIC: 98.1 #>  #> Bayesian p-value: 0.6 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.48 0.40 -0.28  0.21  0.48 0.74  1.31     1654     2374    1 #> d_dir            0.33 0.54 -0.75 -0.02  0.33 0.68  1.42     3604     2773    1 #> d_ind            0.72 0.64 -0.49  0.30  0.71 1.12  2.03     2422     2265    1 #> omega           -0.39 0.82 -2.02 -0.92 -0.38 0.14  1.20     2314     2202    1 #> tau              0.87 0.20  0.56  0.73  0.85 0.97  1.32     1205     1815    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82 0.95  1.26     1250     1938    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44 #>               DIC: 97.6 #>  #> Bayesian p-value: 0.62 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.27 0.41 -1.08 -0.54 -0.27  0.00  0.51     2291     2676    1 #> d_dir           -0.11 0.47 -1.03 -0.42 -0.10  0.20  0.79     3895     3550    1 #> d_ind           -0.52 0.61 -1.69 -0.92 -0.53 -0.14  0.70     1571     2148    1 #> omega            0.41 0.67 -0.94  0.01  0.41  0.85  1.70     1549     1934    1 #> tau              0.87 0.19  0.56  0.73  0.84  0.98  1.31     1113     1471    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82  0.95  1.26     1250     1938    1 #>  #> Residual deviance: 53.7 (on 50 data points) #>                pD: 44.2 #>               DIC: 97.9 #>  #> Bayesian p-value: 0.49 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.63 0.48 -1.57 -0.94 -0.63 -0.31  0.32     2524     2698    1 #> d_dir           -0.61 0.67 -1.98 -1.05 -0.60 -0.18  0.73     3656     2598    1 #> d_ind           -0.61 0.66 -1.98 -1.05 -0.60 -0.17  0.68     2016     2267    1 #> omega            0.00 0.90 -1.72 -0.60 -0.03  0.59  1.83     2168     2193    1 #> tau              0.87 0.20  0.56  0.73  0.85  0.99  1.34     1115     1875    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82  0.95  1.26     1250     1938    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.4 #>  #> Bayesian p-value: 0.97 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.36 0.41 -1.15 -0.62 -0.35 -0.09  0.44     2066     2310    1 #> d_dir            0.06 0.66 -1.24 -0.38  0.07  0.48  1.38     3390     2659    1 #> d_ind           -0.62 0.53 -1.65 -0.96 -0.62 -0.27  0.44     1561     2258    1 #> omega            0.67 0.83 -0.93  0.12  0.67  1.22  2.33     2040     2609    1 #> tau              0.85 0.20  0.55  0.71  0.83  0.96  1.33     1286     1976    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82  0.95  1.26     1250     1938    1 #>  #> Residual deviance: 54.2 (on 50 data points) #>                pD: 44.4 #>               DIC: 98.5 #>  #> Bayesian p-value: 0.41 # }  ## Plaque psoriasis ML-NMR # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.  # \\donttest{ # Fitting a ML-NMR model. # Specify a regression model to include effect modifier interactions for five # covariates, along with main (prognostic) effects. We use a probit link and # specify that the two-parameter Binomial approximation for the aggregate-level # likelihood should be used. We set treatment-covariate interactions to be equal # within each class. We narrow the possible range for random initial values with # init_r = 0.1, since probit models in particular are often hard to initialise. # Using the QR decomposition greatly improves sampling efficiency here, as is # often the case for regression models. pso_fit <- nma(pso_net, refresh = if (interactive()) 200 else 0,                trt_effects = \"fixed\",                link = \"probit\",                likelihood = \"bernoulli2\",                regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                class_interactions = \"common\",                prior_intercept = normal(scale = 10),                prior_trt = normal(scale = 10),                prior_reg = normal(scale = 10),                init_r = 0.1,                QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25% #> beta[durnpso]                           0.04    0.00 0.06    -0.07     0.00 #> beta[prevsys]                          -0.14    0.00 0.16    -0.44    -0.25 #> beta[bsa]                              -0.06    0.01 0.43    -0.92    -0.35 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02 #> beta[psa]                              -0.08    0.00 0.17    -0.42    -0.19 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.18    -0.08 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.15    -0.06 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.18    -0.17     0.07 #> beta[prevsys:.trtclassIL blocker]       0.07    0.00 0.17    -0.27    -0.05 #> beta[bsa:.trtclassTNFa blocker]         0.05    0.01 0.51    -0.94    -0.30 #> beta[bsa:.trtclassIL blocker]           0.29    0.01 0.47    -0.61    -0.04 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.19 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12 #> beta[psa:.trtclassTNFa blocker]        -0.05    0.00 0.20    -0.46    -0.19 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.19    -0.35    -0.11 #> d[ETN]                                  1.55    0.00 0.08     1.40     1.50 #> d[IXE_Q2W]                              2.96    0.00 0.08     2.80     2.90 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.38     2.49 #> d[SEC_150]                              2.14    0.00 0.11     1.92     2.07 #> d[SEC_300]                              2.45    0.00 0.12     2.22     2.37 #> lp__                                -1653.59    0.08 3.38 -1661.08 -1655.64 #>                                          50%      75%    97.5% n_eff Rhat #> beta[durnpso]                           0.05     0.09     0.16  5650    1 #> beta[prevsys]                          -0.14    -0.04     0.16  5361    1 #> beta[bsa]                              -0.06     0.24     0.77  4928    1 #> beta[weight]                            0.04     0.06     0.09  4906    1 #> beta[psa]                              -0.08     0.03     0.25  5165    1 #> beta[durnpso:.trtclassTNFa blocker]    -0.03     0.02     0.12  5701    1 #> beta[durnpso:.trtclassIL blocker]      -0.01     0.03     0.11  6711    1 #> beta[prevsys:.trtclassTNFa blocker]     0.20     0.32     0.54  5330    1 #> beta[prevsys:.trtclassIL blocker]       0.07     0.19     0.41  7144    1 #> beta[bsa:.trtclassTNFa blocker]         0.04     0.39     1.05  5510    1 #> beta[bsa:.trtclassIL blocker]           0.28     0.60     1.23  5765    1 #> beta[weight:.trtclassTNFa blocker]     -0.17    -0.14    -0.10  5847    1 #> beta[weight:.trtclassIL blocker]       -0.10    -0.08    -0.04  6286    1 #> beta[psa:.trtclassTNFa blocker]        -0.05     0.08     0.35  5416    1 #> beta[psa:.trtclassIL blocker]           0.01     0.13     0.38  6049    1 #> d[ETN]                                  1.55     1.60     1.71  3718    1 #> d[IXE_Q2W]                              2.95     3.01     3.12  5218    1 #> d[IXE_Q4W]                              2.54     2.60     2.71  5203    1 #> d[SEC_150]                              2.14     2.22     2.37  4002    1 #> d[SEC_300]                              2.45     2.53     2.67  4805    1 #> lp__                                -1653.23 -1651.16 -1647.89  1618    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:22:37 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_data-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_data class — nma_data-class","title":"The nma_data class — nma_data-class","text":"nma_data class contains data NMA standard format, created using functions set_ipd(), set_agd_arm(), set_agd_contrast(), set_agd_surv(), combine_network(). sub-class mlnmr_data created function add_integration(), contains numerical integration points aggregate data.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_data-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_data class — nma_data-class","text":"Objects class nma_data following components: agd_arm data studies aggregate data (arm format) agd_contrast data studies aggregate data (contrast format) ipd data studies individual patient data treatments treatment coding factor entire network classes treatment class coding factor (length treatments entire network) studies study coding factor entire network outcome outcome type data source, named list agd_arm, agd_contrast, ipd components tibbles following columns: .study study (factor) .trt treatment (factor) .trtclass treatment class (factor), specified .y continuous outcome .se standard error (continuous) .r event count (discrete) .n event count denominator (discrete, agd_arm ) .E time risk (discrete) .Surv survival outcome type Surv (time--event), nested study arm .sample_size sample size (agd_* ) ... columns (typically covariates) original data frame Objects class mlnmr_data additionally components: n_int number numerical integration points int_names names covariates numerical integration points int_cor correlation matrix covariates used generate numerical integration points agd_arm agd_contrast tibbles additional list columns prefix .int_, one covariate, contain numerical integration points nested length-n_int vectors within row.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_dic-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_dic class — nma_dic-class","title":"The nma_dic class — nma_dic-class","text":"nma_dic class contains details Deviance Information Criterion (DIC), produced using dic() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_dic-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_dic class — nma_dic-class","text":"Objects class nma_dic following components: dic DIC value pd, pv effective number parameters resdev total residual deviance pointwise list data frames containing pointwise contributions IPD AgD. resdev_array 3D MCMC array [Iterations, Chains, Parameters] posterior residual deviance samples.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_nodesplit-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_nodesplit class — nma_nodesplit-class","title":"The nma_nodesplit class — nma_nodesplit-class","text":"nma_nodesplit nma_nodesplit_df classes contains results running node-splitting model function nma().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_nodesplit-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_nodesplit class — nma_nodesplit-class","text":"Objects class nma_nodesplit inherit stan_nma class, contain results fitting single node-split model. one additional component, nodesplit, gives comparison node-split length 2 vector. Objects class nma_nodesplit_df tibble data frames one row node-split comparison columns: trt1, trt2 Treatments forming comparison model list column containing results model nma_nodesplit object Optionally, additional row consistency model fitted (e.g. get_nodesplits(., include_consistency = TRUE)) trt1 trt2 NA.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_prior-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_prior class — nma_prior-class","title":"The nma_prior class — nma_prior-class","text":"nma_prior class used specify prior distributions.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_prior-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_prior class — nma_prior-class","text":"Objects class nma_prior following components: dist Distribution name fun Name constructor function, string (e.g. \"normal\") ... Parameters distribution distribution parameters, specified named components ..., match constructor functions (see priors).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_summary class — nma_summary-class","title":"The nma_summary class — nma_summary-class","text":"nma_summary class contains posterior summary statistics model parameters quantities interest, draws used obtain statistics.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_summary class — nma_summary-class","text":"Objects class nma_summary following components: summary data frame containing computed summary statistics. Column .trt indicates corresponding treatment, columns .trta .trtb indicate corresponding contrast (.trtb vs. .trta). regression model fitted effect modifier interactions treatment, summaries study-specific. case, corresponding study population indicated .study column. multinomial model fitted, .category column indicates corresponding category. sims 3D array [Iteration, Chain, Parameter] MCMC simulations studies (Optional) data frame containing study information, printed along corresponding summary statistics summary contains .study column. matching .study column. following attributes may also set: xlab Label x axis plots, usually either \"Treatment\" \"Contrast\". ylab Label y axis plots, usually used scale e.g. \"log Odds Ratio\". subclass nma_rank_probs used function posterior_rank_probs(), contains posterior rank probabilities. subclass sims component, rank probabilities posterior summaries ranks (.e. posterior distribution). posterior ranks rank probabilities calculated may obtained posterior_ranks().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for nma_summary objects — print.nma_summary","title":"Methods for nma_summary objects — print.nma_summary","text":".data.frame(), as_tibble(), .tibble() methods return posterior summary statistics data frame tibble. .matrix() method returns matrix posterior draws. .array() method returns 3D array [Iteration, Chain, Parameter] posterior draws (class mcmc_array).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for nma_summary objects — print.nma_summary","text":"","code":"# S3 method for nma_summary print(x, ..., digits = 2, pars, include = TRUE)  # S3 method for nma_summary as.data.frame(x, ...)  # S3 method for nma_summary as.tibble(x, ...)  # S3 method for nma_summary as_tibble(x, ...)  # S3 method for nma_summary as.array(x, ...)  # S3 method for nma_summary as.matrix(x, ...)  # S3 method for nma_rank_probs as.array(x, ...)  # S3 method for nma_rank_probs as.matrix(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for nma_summary objects — print.nma_summary","text":"x nma_summary object ... Additional arguments passed methods digits Integer number digits display pars Character vector parameters display printed summary include Logical, parameters named pars included (TRUE) excluded (FALSE)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for nma_summary objects — print.nma_summary","text":"data.frame .data.frame(), tbl_df .tibble() as_tibble(), matrix .matrix(), mcmc_array .array(). print() method returns x invisibly.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nodesplit_summary class — nodesplit_summary-class","title":"The nodesplit_summary class — nodesplit_summary-class","text":"nodesplit_summary class contains posterior summary statistics node-splitting models, result calling summary() nma_nodesplit nma_nodesplit_df object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nodesplit_summary class — nodesplit_summary-class","text":"Objects class nodesplit_summary tibble data frames, one row node-split comparison columns: trt1, trt2 Treatments forming comparison summary list column containing nma_summary objects posterior summaries draws node-splitting parameters p_value Bayesian p-value inconsistency dic list column containing nma_dic objects, giving model fit statistics parameters included summary : d_net Network estimate corresponding consistency model, available d_dir Direct estimate node-splitting model d_ind Indirect estimate node-splitting model omega Inconsistency factor \\(\\omega = d_\\mathrm{dir} -   d_\\mathrm{ind}\\) tau Heterogeneity standard deviation node-splitting model, random effects model fitted tau_consistency Heterogeneity standard deviation corresponding consistency model, available random effects model fitted","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for nodesplit_summary objects — print.nodesplit_summary","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":".data.frame(), as_tibble(), .tibble() methods return node-splitting summaries data frame tibble.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"","code":"# S3 method for nodesplit_summary print(x, ..., digits = 2)  # S3 method for nodesplit_summary as_tibble(x, ..., nest = FALSE)  as.tibble.nodesplit_summary(x, ..., nest = FALSE)  # S3 method for nodesplit_summary as.data.frame(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"x nodesplit_summary object ... Additional arguments passed methods digits Integer number digits display nest Whether return nested tibble, full nma_summary nma_dic objects, unnest summaries, default FALSE","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"data.frame .data.frame(), tbl_df .tibble() as_tibble(). print() method returns x invisibly.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix of plots for a stan_nma object — pairs.stan_nma","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"pairs() method stan_nma objects, calls bayesplot::mcmc_pairs() underlying stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"","code":"# S3 method for stan_nma pairs(x, ..., pars, include = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"x object class stan_nma ... arguments passed bayesplot::mcmc_pairs() pars Optional character vector parameter names include output. specified, parameters used. include Logical, parameters pars included (TRUE, default) excluded (FALSE)?","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"grid ggplot objects produced bayesplot::mcmc_pairs().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"","code":"if (FALSE) { ## Parkinson's mean off time reduction park_net <- set_agd_arm(parkinsons,                         study = studyn,                         trt = trtn,                         y = y,                         se = se,                         sample_size = n)  # Fitting a RE model park_fit_RE <- nma(park_net,                    trt_effects = \"random\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_het = half_normal(scale = 5))  # We see a small number of divergent transition errors # These do not go away entirely when adapt_delta is increased  # Try to diagnose with a pairs plot pairs(park_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\"))  # Transforming tau onto log scale pairs(park_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\"),       transformations = list(tau = \"log\"))  # The divergent transitions occur in the upper tail of the heterogeneity # standard deviation. In this case, with only a small number of studies, there # is not very much information to estimate the heterogeneity standard deviation # and the prior distribution may be too heavy-tailed. We could consider a more # informative prior distribution for the heterogeneity variance to aid # estimation. }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean off-time reduction in Parkison's disease — parkinsons","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"Data frame containing mean -time reduction patients given dopamine agonists adjunct therapy Parkinson's disease, 7 trials comparing four active drugs placebo (Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"","code":"parkinsons"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"data frame 15 rows 7 variables: studyn numeric study ID trtn numeric treatment code (placebo = 1) y mean -time reduction se standard error n sample size diff mean difference vs. treatment reference arm se_diff standard error mean difference, see details","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"dataset may analysed using either arm-based likelihood using y se, contrast-based likelihood using diff se_diff (combination two across different studies). contrast-based data formatted described set_agd_contrast(). , chosen reference arm study, mean difference diff set NA, se_diff set standard error se outcome reference arm.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":null,"dir":"Reference","previous_headings":"","what":"Plaque psoriasis data — plaque_psoriasis_ipd","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"Two data frames, plaque_psoriasis_ipd plaque_psoriasis_agd, containing (simulated) individual patient data four studies aggregate data five studies (Phillippo 2019) . Outcomes binary success/failure achieve 75%, 90%, 100% reduction symptoms Psoriasis Area Severity Index (PASI) scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"","code":"plaque_psoriasis_ipd  plaque_psoriasis_agd"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"individual patient data contained data frame plaque_psoriasis_ipd 4118 rows, one per individual, 16 variables: studyc study name trtc_long treatment name (long format) trtc treatment name trtn numeric treatment code pasi75 binary PASI 75 outcome pasi90 binary PASI 90 outcome pasi100 binary PASI 100 outcome age age (years) bmi body mass index (BMI) pasi_w0 PASI score week 0 male male sex (TRUE FALSE) bsa body surface area (percent) weight weight (kilograms) durnpso duration psoriasis (years) prevsys previous systemic treatment (TRUE FALSE) psa psoriatic arthritis (TRUE FALSE) aggregate data contained data frame plaque_psoriasis_agd 15 rows, one per study arm, 26 variables: studyc study name trtc_long treatment name (long format) trtc treatment name trtn numeric treatment code pasi75_r, pasi75_n PASI 75 outcome count denominator pasi90_r, pasi90_n PASI 75 outcome count denominator pasi100_r, pasi100_n PASI 75 outcome count denominator sample_size_w0 sample size week zero age_mean, age_sd mean standard deviation age (years) bmi_mean, bmi_sd mean standard deviation BMI pasi_w0_mean, pasi_w0_sd mean standard deviation PASI score week 0 male percentage males bsa_mean, bsa_sd mean standard deviation body surface area (percent) weight_mean, weight_sd mean standard deviation weight (kilograms) durnpso_mean, durnpso_sd mean standard deviation duration psoriasis (years) prevsys percentage individuals previous systemic treatment psa percentage individuals psoriatic arthritis object class data.frame 15 rows 26 columns.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"Phillippo DM (2019). Calibration Treatment Effects Network Meta-Analysis using Individual Patient Data. Ph.D. thesis, University Bristol. Available https://research-information.bris.ac.uk/.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Network plots — plot.nma_data","title":"Network plots — plot.nma_data","text":"Create network plot nma_data network object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Network plots — plot.nma_data","text":"","code":"# S3 method for nma_data plot(   x,   ...,   layout,   circular,   weight_edges = TRUE,   weight_nodes = FALSE,   show_trt_class = FALSE,   nudge = 0 )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Network plots — plot.nma_data","text":"x nma_data object plot ... Additional arguments passed ggraph() layout function layout type layout create. layout accepted ggraph() may used, including layout functions provided igraph. circular Whether use circular representation. See ggraph(). weight_edges Weight edges number studies? Default TRUE. weight_nodes Weight nodes total sample size? Default FALSE. show_trt_class Colour treatment nodes class, trt_class set? Default FALSE. nudge Numeric value nudge treatment labels away nodes weight_nodes = TRUE. Default 0 (adjustment label position). small value like 0.1 usually sufficient.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Network plots — plot.nma_data","text":"ggplot object, produced ggraph().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Network plots — plot.nma_data","text":"default equivalent layout = \"linear\" circular = TRUE, places treatment nodes circle order defined treatment factor variable. alternative layout may give good results simple networks \"sugiyama\", attempts minimise number edge crossings. weight_nodes = TRUE requires sample sizes specified aggregate data network, using sample_size option set_agd_*().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Network plots — plot.nma_data","text":"","code":"## Stroke prevention in atrial fibrillation # Setting up the network af_net <- set_agd_arm(atrial_fibrillation,                       study = studyc,                       trt = abbreviate(trtc, minlength = 3),                       r = r,                       n = n,                       trt_class = trt_class) af_net #> A network with 26 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                #>  ACTIVE-W      2: Sada | Lda+c               #>  AFASAK 1      3: Sada | Lda | P/c           #>  AFASAK 2      4: Sada | Fdw | Fdw+mda | Mda #>  BAATAF        2: Lada | P/c                 #>  BAFTA         2: Sada | Lda                 #>  CAFA          2: Sada | P/c                 #>  Chinese ATAFS 2: Sada | Lda                 #>  EAFT          3: Sada | Mda | P/c           #>  ESPS 2        4: Dpy | Lda | Lda+d | P/c    #>  JAST          2: Lda | P/c                  #>  ... plus 16 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 17, in 4 classes #> Total number of studies: 26 #> Reference treatment is: Sada #> Network is connected  # Basic plot plot(af_net)   # Turn off weighting edges by number of studies plot(af_net, weight_edges = FALSE)   # Turn on weighting nodes by sample size plot(af_net, weight_nodes = TRUE)   # Colour treatment nodes by class plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE)   # Nudge the treatment labels away from the nodes plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE, nudge = 0.1)   # Output may be customised using standard ggplot commands # For example, to display the legends below the plot: plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE) +   ggplot2::theme(legend.position = \"bottom\",                  legend.box = \"vertical\",                  legend.margin = ggplot2::margin(0, 0, 0, 0),                  legend.spacing = ggplot2::unit(0.5, \"lines\"))   # Choosing a different ggraph layout, hiding some legends plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE,      layout = \"star\") +   ggplot2::guides(edge_width = \"none\", size = \"none\")"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of model fit diagnostics — plot.nma_dic","title":"Plots of model fit diagnostics — plot.nma_dic","text":"plot() method nma_dic objects produced dic() produces several useful diagnostic plots checking model fit model comparison. detail plots interpretation given Dias et al. (2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of model fit diagnostics — plot.nma_dic","text":"","code":"# S3 method for nma_dic plot(   x,   y,   ...,   show_uncertainty = TRUE,   stat = \"pointinterval\",   orientation = c(\"vertical\", \"horizontal\", \"x\", \"y\") )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of model fit diagnostics — plot.nma_dic","text":"x nma_dic object y (Optional) second nma_dic object, produce \"dev-dev\" plots model comparison. ... Additional arguments passed methods show_uncertainty Logical, show uncertainty ggdist plot stat? Default TRUE. stat Character string specifying ggdist plot stat use show_uncertainty = TRUE, default \"pointinterval\". y provided, currently \"pointinterval\" supported. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"). used residual deviance plots, default \"vertical\".","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of model fit diagnostics — plot.nma_dic","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of model fit diagnostics — plot.nma_dic","text":"single nma_dic object given, plot residual deviance contribution data point produced. good fitting model, data point expected residual deviance 1; larger values indicate data points fit poorly model. two nma_dic objects given, \"dev-dev\" plot comparing residual deviance contributions model produced. Data points residual deviance contributions lying line equality fit equally well either model. Data points lying line equality indicate better fit second model (y); conversely, data points lying line equality indicate better fit first model (x). common use case compare standard consistency model (fitted using nma() consistency = \"consistency\") unrelated mean effects (UME) inconsistency model (fitted using nma() consistency = \"ume\"), check potential inconsistency. See Dias et al. (2011)  details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plots of model fit diagnostics — plot.nma_dic","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of model fit diagnostics — plot.nma_dic","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking FE NMA example if not already available if (!exists(\"smk_fit_FE\")) example(\"example_smk_fe\", run.donttest = TRUE) # } # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC of FE and RE models (smk_dic_FE <- dic(smk_fit_FE)) #> Residual deviance: 267.3 (on 50 data points) #>                pD: 27.2 #>               DIC: 294.5 (smk_dic_RE <- dic(smk_fit_RE))   # substantially better fit #> Residual deviance: 54.4 (on 50 data points) #>                pD: 44.1 #>               DIC: 98.5  # Plot residual deviance contributions under RE model plot(smk_dic_RE)   # Further customisation is possible using ggplot commands # For example, highlighting data points with residual deviance above a certain threshold plot(smk_dic_RE) +   ggplot2::aes(colour = ggplot2::after_stat(ifelse(y > 1.5, \"darkorange\", \"black\"))) +   ggplot2::scale_colour_identity()   # Or by posterior probability, for example here a central probability of 0.6 # corresponds to a lower tail probability of (1 - 0.6)/2 = 0.2 plot(smk_dic_RE, .width = c(0.6, 0.95)) +   ggplot2::aes(colour = ggplot2::after_stat(ifelse(ymin > 1, \"darkorange\", \"black\"))) +   ggplot2::scale_colour_identity()   # Check for inconsistency using UME model # } # \\donttest{ # Run smoking UME NMA example if not already available if (!exists(\"smk_fit_RE_UME\")) example(\"example_smk_ume\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC smk_dic_RE #> Residual deviance: 54.4 (on 50 data points) #>                pD: 44.1 #>               DIC: 98.5 (smk_dic_RE_UME <- dic(smk_fit_RE_UME))  # no difference in fit #> Residual deviance: 53.8 (on 50 data points) #>                pD: 45.2 #>               DIC: 99.1  # Compare residual deviance contributions with a \"dev-dev\" plot plot(smk_dic_RE, smk_dic_RE_UME)   # By default the dev-dev plot can be a little cluttered # Hiding the credible intervals plot(smk_dic_RE, smk_dic_RE_UME, show_uncertainty = FALSE)   # Changing transparency plot(smk_dic_RE, smk_dic_RE_UME, point_alpha = 0.5, interval_alpha = 0.1)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of summary results — plot.nma_summary","title":"Plots of summary results — plot.nma_summary","text":"plot method nma_summary objects used produce plots parameter estimates (called stan_nma object summary), relative effects (called output relative_effects()), absolute predictions (called output predict.stan_nma()), posterior ranks rank probabilities (called output posterior_ranks() posterior_rank_probs()).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of summary results — plot.nma_summary","text":"","code":"# S3 method for nma_summary plot(   x,   ...,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )  # S3 method for nma_parameter_summary plot(   x,   ...,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )  # S3 method for nma_rank_probs plot(x, ...)  # S3 method for surv_nma_summary plot(x, ..., stat = \"lineribbon\")"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of summary results — plot.nma_summary","text":"x nma_summary object ... Additional arguments passed underlying ggdist plot stat, see Details stat Character string specifying ggdist plot stat use, default \"pointinterval\", except plotting estimated survival/hazard/cumulative hazard curves survival models default \"lineribbon\" orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\" ref_line Numeric vector positions reference lines, default reference lines drawn","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of summary results — plot.nma_summary","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of summary results — plot.nma_summary","text":"Plotting handled ggplot2 stats geoms provided ggdist package. result, output flexible. plotting stats provided ggdist may used, via argument stat. default uses ggdist::stat_pointinterval(), produce medians 95% Credible Intervals 66% inner bands. Additional arguments ... passed ggdist stat, customise output. example, produce means Credible Intervals, specify point_interval = \"mean_qi\". produce 80% Credible Interval inner band, specify .width = c(0, 0.8). Alternative stats can specified produce different summaries. example, specify stat = \"[half]eye\" produce (half) eye plots, stat = \"histinterval\" produce histograms intervals. full list options examples found ggdist vignette vignette(\"slabinterval\", package = \"ggdist\"). survival/hazard/cumulative hazard curves estimated survival models, default uses ggdist::stat_lineribbon() produces curves posterior medians 50%, 80%, 95% Credible Interval bands. , additional arguments ... passed ggdist stat. example, produce posterior means 95% Credible bands, specify point_interval = \"mean_qi\" .width = 0.95. ggplot object returned can modified usual ggplot2 functions add aesthetics, geoms, themes, etc.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of summary results — plot.nma_summary","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce relative effects smk_releff_RE <- relative_effects(smk_fit_RE) plot(smk_releff_RE, ref_line = 0)   # Customise plot options plot(smk_releff_RE, ref_line = 0, stat = \"halfeye\")   # Further customisation is possible with ggplot commands plot(smk_releff_RE, ref_line = 0, stat = \"halfeye\", slab_alpha = 0.6) +   ggplot2::aes(slab_fill = ggplot2::after_stat(ifelse(x < 0, \"darkred\", \"grey60\")))   # Produce posterior ranks smk_rank_RE <- posterior_ranks(smk_fit_RE, lower_better = FALSE) plot(smk_rank_RE)   # Produce rank probabilities smk_rankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE) plot(smk_rankprob_RE)   # Produce cumulative rank probabilities smk_cumrankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE,                                            cumulative = TRUE) plot(smk_cumrankprob_RE)   # Further customisation is possible with ggplot commands plot(smk_cumrankprob_RE) +   ggplot2::facet_null() +   ggplot2::aes(colour = Treatment)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of node-splitting models — plot.nodesplit_summary","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"Produce summary plots node-splitting models","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"","code":"# S3 method for nodesplit_summary plot(   x,   ...,   pars = \"d\",   stat = \"dens_overlay\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"x nodesplit_summary object. ... Additional arguments passed underlying ggdist plot stat, see Details. pars Character vector specifying parameters include plot, choices include \"d\" direct, indirect, network estimates relative effects, \"omega\" inconsistency factor, \"tau\" heterogeneity standard deviation random effects models. Default \"d\". stat Character string specifying ggdist plot stat use. default \"dens_overlay\" special case, producing overlaid density plot. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\". ref_line Numeric vector positions reference lines, default reference lines drawn.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"Plotting handled ggplot2 stats geoms provided ggdist package. result, output flexible. plotting stats provided ggdist may used, via argument stat. default \"dens_overlay\" special exception, uses ggplot2::geom_density(), plot overlaid densities. Additional arguments ... passed ggdist stat, customise output. Alternative stats can specified produce different summaries. example, specify stat = \"[half]eye\" produce (half) eye plots, stat = \"pointinterval\" produce point estimates credible intervals. full list options examples found ggdist vignette vignette(\"slabinterval\", package = \"ggdist\"). ggplot object returned can modified usual ggplot2 functions add aesthetics, geoms, themes, etc.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"","code":"# \\donttest{ # Run smoking node-splitting example if not already available if (!exists(\"smk_fit_RE_nodesplit\")) example(\"example_smk_nodesplit\", run.donttest = TRUE) # } # \\donttest{ # Summarise the node-splitting results (smk_nodesplit_summary <- summary(smk_fit_RE_nodesplit)) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.10 0.43  0.26  0.81  1.09 1.38  1.96     2148     2137    1 #> d_dir            1.04 0.75 -0.37  0.54  1.01 1.51  2.59     2543     1931    1 #> d_ind            1.18 0.55  0.12  0.82  1.16 1.53  2.29     1749     2385    1 #> omega           -0.14 0.89 -1.85 -0.73 -0.16 0.43  1.68     2134     2282    1 #> tau              0.87 0.20  0.55  0.73  0.84 0.99  1.35     1152     1760    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82 0.95  1.29     1135     1734    1 #>  #> Residual deviance: 53.9 (on 50 data points) #>                pD: 44 #>               DIC: 97.9 #>  #> Bayesian p-value: 0.86 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.83 0.24  0.38  0.68 0.83 0.98  1.33     1318     1877 1.00 #> d_dir           0.89 0.26  0.41  0.72 0.88 1.05  1.43     1470     2358 1.00 #> d_ind           0.58 0.69 -0.77  0.14 0.57 1.01  1.98     1311     1709 1.00 #> omega           0.31 0.72 -1.15 -0.14 0.32 0.77  1.75     1396     1840 1.00 #> tau             0.85 0.19  0.55  0.71 0.82 0.96  1.29      934     1909 1.01 #> tau_consistency 0.84 0.19  0.54  0.71 0.82 0.95  1.29     1135     1734 1.00 #>  #> Residual deviance: 54.5 (on 50 data points) #>                pD: 44.4 #>               DIC: 98.9 #>  #> Bayesian p-value: 0.63 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.49 0.40 -0.27  0.23  0.48 0.75  1.30     1961     2380    1 #> d_dir            0.35 0.54 -0.70  0.00  0.35 0.69  1.49     3146     1798    1 #> d_ind            0.70 0.63 -0.54  0.29  0.69 1.10  2.00     2377     2626    1 #> omega           -0.35 0.83 -2.04 -0.86 -0.34 0.19  1.19     2302     2600    1 #> tau              0.87 0.19  0.57  0.73  0.85 0.97  1.32     1251     1812    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82 0.95  1.29     1135     1734    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44 #>               DIC: 97.6 #>  #> Bayesian p-value: 0.67 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.27 0.41 -1.10 -0.52 -0.26  0.00  0.53     2693     2005    1 #> d_dir           -0.11 0.48 -1.07 -0.41 -0.11  0.20  0.82     3490     3136    1 #> d_ind           -0.56 0.62 -1.79 -0.95 -0.56 -0.15  0.66     1642     1983    1 #> omega            0.44 0.68 -0.89  0.00  0.43  0.89  1.79     1656     2018    1 #> tau              0.86 0.19  0.56  0.72  0.84  0.96  1.32     1229     1755    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82  0.95  1.29     1135     1734    1 #>  #> Residual deviance: 54.3 (on 50 data points) #>                pD: 44.6 #>               DIC: 98.8 #>  #> Bayesian p-value: 0.5 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.60 0.47 -1.57 -0.91 -0.59 -0.30  0.30     3295     2567    1 #> d_dir           -0.59 0.66 -1.90 -1.02 -0.59 -0.17  0.73     3914     3278    1 #> d_ind           -0.64 0.68 -2.02 -1.07 -0.65 -0.20  0.66     1938     2087    1 #> omega            0.05 0.89 -1.65 -0.54  0.03  0.62  1.88     2089     1983    1 #> tau              0.87 0.20  0.56  0.73  0.84  0.99  1.36     1221     1940    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82  0.95  1.29     1135     1734    1 #>  #> Residual deviance: 53.7 (on 50 data points) #>                pD: 44.1 #>               DIC: 97.8 #>  #> Bayesian p-value: 0.97 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.34 0.41 -1.17 -0.60 -0.34 -0.08  0.46     2214     2651    1 #> d_dir            0.07 0.65 -1.22 -0.36  0.07  0.49  1.36     3658     2981    1 #> d_ind           -0.63 0.53 -1.71 -0.97 -0.62 -0.28  0.39     2161     2530    1 #> omega            0.70 0.81 -0.83  0.17  0.69  1.24  2.33     2519     2547    1 #> tau              0.85 0.19  0.54  0.71  0.82  0.95  1.29     1250     2163    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82  0.95  1.29     1135     1734    1 #>  #> Residual deviance: 53.8 (on 50 data points) #>                pD: 44 #>               DIC: 97.8 #>  #> Bayesian p-value: 0.38  # Plot the node-splitting results plot(smk_nodesplit_summary)   # Plot the inconsistency factors instead, change the plot stat to half-eye, # and add a reference line at 0 plot(smk_nodesplit_summary, pars = \"omega\", stat = \"halfeye\", ref_line = 0)   # Plot a comparison of the heterogeneity under the node-split models vs. # the consistency model plot(smk_nodesplit_summary, pars = \"tau\")  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot numerical integration error — plot_integration_error","title":"Plot numerical integration error — plot_integration_error","text":"ML-NMR models, plot estimated numerical integration error entire posterior distribution, number integration points increases. See (Phillippo et al. 2020; Phillippo 2019)  details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot numerical integration error — plot_integration_error","text":"","code":"plot_integration_error(   x,   ...,   stat = \"violin\",   orientation = c(\"vertical\", \"horizontal\", \"x\", \"y\"),   show_expected_rate = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot numerical integration error — plot_integration_error","text":"x object type stan_mlnmr ... Additional arguments passed ggdist plot stat. stat Character string specifying ggdist plot stat used summarise integration error posterior. Default \"violin\", equivalent \"eye\" cosmetic tweaks. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"vertical\" show_expected_rate Logical, show typical convergence rate \\(1/N\\)? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot numerical integration error — plot_integration_error","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot numerical integration error — plot_integration_error","text":"total number integration points set n_int argument add_integration(), intervals integration error estimated set int_thin argument nma(). typical convergence rate Quasi-Monte Carlo integration (used ) \\(1/N\\), default displayed plot output. integration error thinning interval \\(N_\\mathrm{thin}\\) estimated point posterior distribution subtracting final estimate (using n_int points) estimate using first \\(N_\\mathrm{thin}\\) points.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"note-for-survival-models","dir":"Reference","previous_headings":"","what":"Note for survival models","title":"Plot numerical integration error — plot_integration_error","text":"function supported survival/time--event models. save cumulative integration points efficiency reasons (time memory).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot numerical integration error — plot_integration_error","text":"","code":"## Plaque psoriasis ML-NMR # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.  # \\donttest{ # Fit the ML-NMR model pso_fit <- nma(pso_net, refresh = if (interactive()) 200 else 0,                trt_effects = \"fixed\",                link = \"probit\",                likelihood = \"bernoulli2\",                regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                class_interactions = \"common\",                prior_intercept = normal(scale = 10),                prior_trt = normal(scale = 10),                prior_reg = normal(scale = 10),                init_r = 0.1,                QR = TRUE,                # Set the thinning factor for saving the cumulative results                # (This also sets int_check = FALSE)                int_thin = 8) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25% #> beta[durnpso]                           0.04    0.00 0.06    -0.08     0.00 #> beta[prevsys]                          -0.14    0.00 0.16    -0.45    -0.25 #> beta[bsa]                              -0.07    0.01 0.44    -0.95    -0.35 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02 #> beta[psa]                              -0.08    0.00 0.17    -0.41    -0.19 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.14    -0.06 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.19    -0.18     0.07 #> beta[prevsys:.trtclassIL blocker]       0.07    0.00 0.18    -0.29    -0.05 #> beta[bsa:.trtclassTNFa blocker]         0.05    0.01 0.52    -0.98    -0.30 #> beta[bsa:.trtclassIL blocker]           0.28    0.01 0.48    -0.67    -0.04 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.19 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12 #> beta[psa:.trtclassTNFa blocker]        -0.05    0.00 0.21    -0.46    -0.19 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.19    -0.35    -0.12 #> d[ETN]                                  1.55    0.00 0.08     1.39     1.49 #> d[IXE_Q2W]                              2.95    0.00 0.09     2.78     2.89 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.38     2.48 #> d[SEC_150]                              2.14    0.00 0.12     1.91     2.06 #> d[SEC_300]                              2.45    0.00 0.12     2.21     2.36 #> lp__                                -1653.68    0.09 3.51 -1661.32 -1655.81 #>                                          50%      75%    97.5% n_eff Rhat #> beta[durnpso]                           0.04     0.08     0.16  7303    1 #> beta[prevsys]                          -0.14    -0.03     0.18  5290    1 #> beta[bsa]                              -0.06     0.24     0.80  6181    1 #> beta[weight]                            0.04     0.06     0.10  6626    1 #> beta[psa]                              -0.08     0.04     0.25  6281    1 #> beta[durnpso:.trtclassTNFa blocker]    -0.03     0.02     0.12  7989    1 #> beta[durnpso:.trtclassIL blocker]      -0.01     0.03     0.12  9375    1 #> beta[prevsys:.trtclassTNFa blocker]     0.19     0.32     0.55  5556    1 #> beta[prevsys:.trtclassIL blocker]       0.07     0.19     0.41  6407    1 #> beta[bsa:.trtclassTNFa blocker]         0.04     0.39     1.09  6746    1 #> beta[bsa:.trtclassIL blocker]           0.27     0.61     1.26  7150    1 #> beta[weight:.trtclassTNFa blocker]     -0.17    -0.14    -0.10  7157    1 #> beta[weight:.trtclassIL blocker]       -0.10    -0.08    -0.04  7554    1 #> beta[psa:.trtclassTNFa blocker]        -0.05     0.09     0.35  6621    1 #> beta[psa:.trtclassIL blocker]           0.01     0.13     0.38  7966    1 #> d[ETN]                                  1.55     1.60     1.71  4321    1 #> d[IXE_Q2W]                              2.95     3.01     3.12  5270    1 #> d[IXE_Q4W]                              2.54     2.59     2.70  5237    1 #> d[SEC_150]                              2.14     2.22     2.37  5485    1 #> d[SEC_300]                              2.45     2.53     2.69  5306    1 #> lp__                                -1653.28 -1651.21 -1647.87  1481    1 #>  #> Samples were drawn using NUTS(diag_e) at Mon Sep 11 11:25:02 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1).  # Plot numerical integration error plot_integration_error(pso_fit)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot prior vs posterior distribution — plot_prior_posterior","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"Produce plots comparing prior posterior distributions model parameters.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"","code":"plot_prior_posterior(   x,   ...,   prior = NULL,   post_args = list(),   prior_args = list(),   overlay = c(\"prior\", \"posterior\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"x stan_nma object ... Additional arguments passed methods prior Character vector selecting prior posterior distribution(s) plot. May include \"intercept\", \"trt\", \"het\", \"reg\", \"aux\", appropriate. post_args List arguments passed ggplot2::geom_histogram control plot output posterior distribution prior_args List arguments passed ggplot2::geom_path control plot output prior distribution. Additionally, n controls number points density curve evaluated (default 500), p_limits controls endpoints curve quantiles (default c(.001, .999)). overlay String, prior posterior shown top? Default \"prior\". ref_line Numeric vector positions reference lines, default reference lines drawn","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"Prior distributions displayed lines, posterior distributions displayed histograms.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"","code":"## Smoking cessation NMA # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Plot prior vs. posterior, by default all parameters are plotted plot_prior_posterior(smk_fit_RE)   # Plot prior vs. posterior for heterogeneity SD only plot_prior_posterior(smk_fit_RE, prior = \"het\")   # Customise plot plot_prior_posterior(smk_fit_RE, prior = \"het\",                      prior_args = list(colour = \"darkred\", size = 2),                      post_args = list(alpha = 0.6))  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":null,"dir":"Reference","previous_headings":"","what":"Treatment rankings and rank probabilities — posterior_ranks","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"Produce posterior treatment rankings rank probabilities fitted NMA model. meta-regression fitted effect modifier interactions treatment, differ study population.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"","code":"posterior_ranks(   x,   newdata = NULL,   study = NULL,   lower_better = TRUE,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   sucra = FALSE,   summary = TRUE )  posterior_rank_probs(   x,   newdata = NULL,   study = NULL,   lower_better = TRUE,   cumulative = FALSE,   sucra = FALSE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"x stan_nma object created nma() newdata used regression model fitted. data frame study details, one row per study, giving covariate values produce relative effects. Column names must match variables regression model. NULL, relative effects produced studies network. study Column newdata specifies study names, otherwise studies labelled row number. lower_better Logical, lower treatment effects better (TRUE; default) higher better (FALSE)? See details. probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) sucra Logical, calculate surface cumulative ranking curve (SUCRA) treatment? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE. cumulative Logical, return cumulative rank probabilities? Default FALSE, return posterior probabilities treatment given rank. TRUE, cumulative posterior rank probabilities returned treatment given rank better.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"function posterior_ranks() produces posterior rankings, distribution (e.g. mean/median rank 95% Credible Interval). function posterior_rank_probs() produces rank probabilities, give posterior probabilities ranked first, second, etc. treatments. argument lower_better specifies whether lower treatment effects higher treatment effects preferred. example, negative binary outcome lower (negative) log odds ratios preferred, lower_better = TRUE. Conversely, example, treatments aim increase rate positive outcome lower_better = FALSE.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce posterior ranks smk_rank_RE <- posterior_ranks(smk_fit_RE, lower_better = FALSE) smk_rank_RE #>                              mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[No intervention]        3.89 0.32    3   4   4   4     4     2145       NA #> rank[Group counselling]      1.37 0.63    1   1   1   2     3     2668     2724 #> rank[Individual counselling] 1.94 0.64    1   2   2   2     3     2233       NA #> rank[Self-help]              2.80 0.69    1   3   3   3     4     2283       NA #>                              Rhat #> rank[No intervention]           1 #> rank[Group counselling]         1 #> rank[Individual counselling]    1 #> rank[Self-help]                 1 plot(smk_rank_RE)   # Produce rank probabilities smk_rankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE) smk_rankprob_RE #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.11      0.89 #> d[Group counselling]           0.70      0.23      0.06      0.01 #> d[Individual counselling]      0.24      0.59      0.17      0.00 #> d[Self-help]                   0.06      0.18      0.66      0.10 plot(smk_rankprob_RE)   # Produce cumulative rank probabilities smk_cumrankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE,                                            cumulative = TRUE) smk_cumrankprob_RE #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.11         1 #> d[Group counselling]           0.70      0.93      0.99         1 #> d[Individual counselling]      0.24      0.83      1.00         1 #> d[Self-help]                   0.06      0.24      0.90         1 plot(smk_cumrankprob_RE)   # Further customisation is possible with ggplot commands plot(smk_cumrankprob_RE) +   ggplot2::facet_null() +   ggplot2::aes(colour = Treatment)  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Produce population-adjusted rankings for all study populations in # the network  # Ranks pso_rank <- posterior_ranks(pso_fit) pso_rank #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[FIXTURE: PBO]     1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[FIXTURE: ETN]     2.00 0.00    2   2   2   2     2       NA       NA   NA #> rank[FIXTURE: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[FIXTURE: IXE_Q4W] 4.76 0.43    4   5   5   5     5     4433       NA    1 #> rank[FIXTURE: SEC_150] 3.00 0.05    3   3   3   3     3     3062     3062    1 #> rank[FIXTURE: SEC_300] 4.23 0.43    4   4   4   4     5     4356       NA    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-1: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-1: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-1: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA #> rank[UNCOVER-1: IXE_Q4W] 4.76 0.43    4   5   5   5     5     4433       NA #> rank[UNCOVER-1: SEC_150] 3.00 0.05    3   3   3   3     3     3062     3062 #> rank[UNCOVER-1: SEC_300] 4.23 0.43    4   4   4   4     5     4356       NA #>                          Rhat #> rank[UNCOVER-1: PBO]       NA #> rank[UNCOVER-1: ETN]       NA #> rank[UNCOVER-1: IXE_Q2W]   NA #> rank[UNCOVER-1: IXE_Q4W]    1 #> rank[UNCOVER-1: SEC_150]    1 #> rank[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-2: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-2: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-2: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA #> rank[UNCOVER-2: IXE_Q4W] 4.76 0.43    4   5   5   5     5     4433       NA #> rank[UNCOVER-2: SEC_150] 3.00 0.05    3   3   3   3     3     3062     3062 #> rank[UNCOVER-2: SEC_300] 4.23 0.43    4   4   4   4     5     4356       NA #>                          Rhat #> rank[UNCOVER-2: PBO]       NA #> rank[UNCOVER-2: ETN]       NA #> rank[UNCOVER-2: IXE_Q2W]   NA #> rank[UNCOVER-2: IXE_Q4W]    1 #> rank[UNCOVER-2: SEC_150]    1 #> rank[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-3: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-3: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-3: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA #> rank[UNCOVER-3: IXE_Q4W] 4.76 0.43    4   5   5   5     5     4433       NA #> rank[UNCOVER-3: SEC_150] 3.00 0.05    3   3   3   3     3     3062     3062 #> rank[UNCOVER-3: SEC_300] 4.23 0.43    4   4   4   4     5     4356       NA #>                          Rhat #> rank[UNCOVER-3: PBO]       NA #> rank[UNCOVER-3: ETN]       NA #> rank[UNCOVER-3: IXE_Q2W]   NA #> rank[UNCOVER-3: IXE_Q4W]    1 #> rank[UNCOVER-3: SEC_150]    1 #> rank[UNCOVER-3: SEC_300]    1 #>  plot(pso_rank)   # Rank probabilities pso_rankprobs <- posterior_rank_probs(pso_fit) pso_rankprobs #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             1         0         0      0.00      0.00         0 #> d[FIXTURE: ETN]             0         1         0      0.00      0.00         0 #> d[FIXTURE: IXE_Q2W]         0         0         0      0.00      0.00         1 #> d[FIXTURE: IXE_Q4W]         0         0         0      0.24      0.76         0 #> d[FIXTURE: SEC_150]         0         0         1      0.00      0.00         0 #> d[FIXTURE: SEC_300]         0         0         0      0.76      0.24         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-1: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-1: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-1: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-1: IXE_Q4W]         0         0         0      0.24      0.76 #> d[UNCOVER-1: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-1: SEC_300]         0         0         0      0.76      0.24 #>                       p_rank[6] #> d[UNCOVER-1: PBO]             0 #> d[UNCOVER-1: ETN]             0 #> d[UNCOVER-1: IXE_Q2W]         1 #> d[UNCOVER-1: IXE_Q4W]         0 #> d[UNCOVER-1: SEC_150]         0 #> d[UNCOVER-1: SEC_300]         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-2: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-2: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-2: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-2: IXE_Q4W]         0         0         0      0.24      0.76 #> d[UNCOVER-2: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-2: SEC_300]         0         0         0      0.76      0.24 #>                       p_rank[6] #> d[UNCOVER-2: PBO]             0 #> d[UNCOVER-2: ETN]             0 #> d[UNCOVER-2: IXE_Q2W]         1 #> d[UNCOVER-2: IXE_Q4W]         0 #> d[UNCOVER-2: SEC_150]         0 #> d[UNCOVER-2: SEC_300]         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-3: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-3: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-3: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-3: IXE_Q4W]         0         0         0      0.24      0.76 #> d[UNCOVER-3: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-3: SEC_300]         0         0         0      0.76      0.24 #>                       p_rank[6] #> d[UNCOVER-3: PBO]             0 #> d[UNCOVER-3: ETN]             0 #> d[UNCOVER-3: IXE_Q2W]         1 #> d[UNCOVER-3: IXE_Q4W]         0 #> d[UNCOVER-3: SEC_150]         0 #> d[UNCOVER-3: SEC_300]         0 #>  plot(pso_rankprobs)   # Cumulative rank probabilities pso_cumrankprobs <- posterior_rank_probs(pso_fit, cumulative = TRUE) pso_cumrankprobs #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             1         1         1      1.00         1         1 #> d[FIXTURE: ETN]             0         1         1      1.00         1         1 #> d[FIXTURE: IXE_Q2W]         0         0         0      0.00         0         1 #> d[FIXTURE: IXE_Q4W]         0         0         0      0.24         1         1 #> d[FIXTURE: SEC_150]         0         0         1      1.00         1         1 #> d[FIXTURE: SEC_300]         0         0         0      0.76         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-1: PBO]             1         1         1      1.00         1 #> d[UNCOVER-1: ETN]             0         1         1      1.00         1 #> d[UNCOVER-1: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-1: IXE_Q4W]         0         0         0      0.24         1 #> d[UNCOVER-1: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-1: SEC_300]         0         0         0      0.76         1 #>                       p_rank[6] #> d[UNCOVER-1: PBO]             1 #> d[UNCOVER-1: ETN]             1 #> d[UNCOVER-1: IXE_Q2W]         1 #> d[UNCOVER-1: IXE_Q4W]         1 #> d[UNCOVER-1: SEC_150]         1 #> d[UNCOVER-1: SEC_300]         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-2: PBO]             1         1         1      1.00         1 #> d[UNCOVER-2: ETN]             0         1         1      1.00         1 #> d[UNCOVER-2: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-2: IXE_Q4W]         0         0         0      0.24         1 #> d[UNCOVER-2: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-2: SEC_300]         0         0         0      0.76         1 #>                       p_rank[6] #> d[UNCOVER-2: PBO]             1 #> d[UNCOVER-2: ETN]             1 #> d[UNCOVER-2: IXE_Q2W]         1 #> d[UNCOVER-2: IXE_Q4W]         1 #> d[UNCOVER-2: SEC_150]         1 #> d[UNCOVER-2: SEC_300]         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-3: PBO]             1         1         1      1.00         1 #> d[UNCOVER-3: ETN]             0         1         1      1.00         1 #> d[UNCOVER-3: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-3: IXE_Q4W]         0         0         0      0.24         1 #> d[UNCOVER-3: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-3: SEC_300]         0         0         0      0.76         1 #>                       p_rank[6] #> d[UNCOVER-3: PBO]             1 #> d[UNCOVER-3: ETN]             1 #> d[UNCOVER-3: IXE_Q2W]         1 #> d[UNCOVER-3: IXE_Q4W]         1 #> d[UNCOVER-3: SEC_150]         1 #> d[UNCOVER-3: SEC_300]         1 #>  plot(pso_cumrankprobs)   # Produce population-adjusted rankings for a different target # population new_agd_means <- data.frame(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3)  # Ranks posterior_ranks(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                      mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[New 1: PBO]     1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[New 1: ETN]     2.00 0.00    2   2   2   2     2       NA       NA   NA #> rank[New 1: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[New 1: IXE_Q4W] 4.76 0.43    4   5   5   5     5     4433       NA    1 #> rank[New 1: SEC_150] 3.00 0.05    3   3   3   3     3     3062     3062    1 #> rank[New 1: SEC_300] 4.23 0.43    4   4   4   4     5     4356       NA    1 #>   # Rank probabilities posterior_rank_probs(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[New 1: PBO]             1         0         0      0.00      0.00         0 #> d[New 1: ETN]             0         1         0      0.00      0.00         0 #> d[New 1: IXE_Q2W]         0         0         0      0.00      0.00         1 #> d[New 1: IXE_Q4W]         0         0         0      0.24      0.76         0 #> d[New 1: SEC_150]         0         0         1      0.00      0.00         0 #> d[New 1: SEC_300]         0         0         0      0.76      0.24         0 #>   # Cumulative rank probabilities posterior_rank_probs(pso_fit, newdata = new_agd_means,                      cumulative = TRUE) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[New 1: PBO]             1         1         1      1.00         1         1 #> d[New 1: ETN]             0         1         1      1.00         1         1 #> d[New 1: IXE_Q2W]         0         0         0      0.00         0         1 #> d[New 1: IXE_Q4W]         0         0         0      0.24         1         1 #> d[New 1: SEC_150]         0         0         1      1.00         1         1 #> d[New 1: SEC_300]         0         0         0      0.76         1         1 #>  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions of absolute effects from NMA models — predict.stan_nma","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Obtain predictions absolute effects NMA models fitted nma(). example, model fitted binary data logit link, predicted outcome probabilities log odds can produced. survival models, predictions can made survival probabilities, (cumulative) hazards, (restricted) mean survival times, quantiles including median survival times. IPD NMA ML-NMR model fitted, predictions can produced either individual level aggregate level. Aggregate-level predictions population-average absolute effects; marginalised standardised population. example, average event probabilities logistic regression, marginal (standardised) survival probabilities survival model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"","code":"# S3 method for stan_nma predict(   object,   ...,   baseline = NULL,   newdata = NULL,   study = NULL,   trt_ref = NULL,   type = c(\"link\", \"response\"),   level = c(\"aggregate\", \"individual\"),   baseline_type = c(\"link\", \"response\"),   baseline_level = c(\"individual\", \"aggregate\"),   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE )  # S3 method for stan_nma_surv predict(   object,   times = NULL,   ...,   baseline = NULL,   aux = NULL,   newdata = NULL,   study = NULL,   trt_ref = NULL,   type = c(\"survival\", \"hazard\", \"cumhaz\", \"mean\", \"median\", \"quantile\", \"rmst\", \"link\"),   quantiles = c(0.25, 0.5, 0.75),   level = c(\"aggregate\", \"individual\"),   times_seq = NULL,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"object stan_nma object created nma(). ... Additional arguments, passed uniroot() regression models baseline_level = \"aggregate\". baseline optional distr() distribution baseline response (.e. intercept), produce absolute effects. Can also character string naming study network take estimated baseline response distribution . NULL, predictions produced using baseline response study network IPD arm-based AgD. regression models, may list distr() distributions (study names network use baseline distributions ) length number studies newdata, possibly named studies newdata otherwise order appearance newdata. Use baseline_type baseline_level arguments specify whether distribution response linear predictor scale, (ML-NMR models including IPD) whether applies individual reference level covariates entire newdata population, respectively. example, model logit link baseline_type = \"link\", distribution baseline log odds event. survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_type always \"link\", baseline_level \"individual\" IPD NMA ML-NMR, \"aggregate\" AgD NMA). Use trt_ref argument specify treatment distribution applies . newdata required regression model fitted baseline specified. data frame covariate details, produce predictions. Column names must match variables regression model. level = \"aggregate\" either data frame integration points produced add_integration() (one row per study), data frame individual covariate values (one row per individual) summarised . level = \"individual\" data frame individual covariate values, one row per individual. NULL, predictions produced studies IPD /arm-based AgD network, depending value level. study Column newdata specifies study names IDs. specified: newdata contains integration points produced add_integration(), studies labelled sequentially row; otherwise data assumed come single study. trt_ref Treatment baseline response distribution refers, baseline specified. default, baseline response distribution refer network reference treatment. Coerced character string. type Whether produce predictions \"link\" scale (default, e.g. log odds) \"response\" scale (e.g. probabilities). survival models, options \"survival\" survival probabilities (default), \"hazard\" hazards, \"cumhaz\" cumulative hazards, \"mean\" mean survival times, \"quantile\" quantiles survival time distribution, \"median\" median survival times (equivalent type = \"quantile\" quantiles = 0.5), \"rmst\" restricted mean survival times, \"link\" linear predictor. type = \"survival\", \"hazard\" \"cumhaz\", predictions given times specified times event/censoring times network times = NULL. type = \"rmst\", restricted time horizon specified times, times = NULL earliest last follow-time amongst studies network used. level = \"aggregate\", correspond standardised survival function (see details). level level predictions produced, either \"aggregate\" (default), \"individual\". baseline specified, predictions produced IPD studies network level \"individual\" \"aggregate\", arm-based AgD studies network level \"aggregate\". baseline_type baseline distribution given, specifies whether corresponds \"link\" scale (default, e.g. log odds) \"response\" scale (e.g. probabilities). survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_type always \"link\"). baseline_level baseline distribution given, specifies whether corresponds individual reference level covariates (\"individual\", default), (unadjusted) average outcome reference treatment newdata population (\"aggregate\"). Ignored AgD NMA, since option \"aggregate\" instance. survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_level \"individual\" IPD NMA ML-NMR, \"aggregate\" AgD NMA). probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) predictive_distribution Logical, random effects model fitted, predictive distribution absolute effects new study returned? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE. times numeric vector times evaluate predictions . Alternatively, newdata specified, times can name column newdata contains times. NULL (default) predictions made event/censoring times studies included network (according times_seq). used type \"survival\", \"hazard\", \"cumhaz\" \"rmst\". aux optional distr() distribution auxiliary parameter(s) baseline hazard (e.g. shapes). Can also character string naming study network take estimated auxiliary parameter distribution . NULL, predictions produced using parameter estimates study network IPD arm-based AgD. regression models, may list distr() distributions (study names network use auxiliary parameters ) length number studies newdata, possibly named study names otherwise order appearance newdata. quantiles numeric vector quantiles survival time distribution produce estimates type = \"quantile\". times_seq positive integer, specified evaluate predictions many evenly-spaced event times 0 latest follow-time study, instead every observed event/censoring time. used newdata = NULL type \"survival\", \"hazard\" \"cumhaz\". can useful plotting survival (cumulative) hazard curves, prediction every observed even/censoring time unnecessary can slow. call within plot() detected, e.g. like plot(predict(fit, type = \"survival\")), times_seq default 50.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"aggregate-level-predictions-from-ipd-nma-and-ml-nmr-models","dir":"Reference","previous_headings":"","what":"Aggregate-level predictions from IPD NMA and ML-NMR models","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Population-average absolute effects can produced IPD NMA ML-NMR models level = \"aggregate\". Predictions averaged target population (.e. standardised/marginalised), either (numerical) integration joint covariate distribution (AgD studies network ML-NMR, AgD newdata integration points created add_integration()), averaging predictions sample individuals (IPD studies network IPD NMA/ML-NMR, IPD newdata). example, binary outcome, population-average event probabilities treatment \\(k\\) study/population \\(j\\) $$\\bar{p}_{jk} = \\int_\\mathfrak{X} p_{jk}(\\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x}$$ joint covariate distribution \\(f_{jk}(\\mathbf{x})\\) support \\(\\mathfrak{X}\\) $$\\bar{p}_{jk} = \\sum_i p_{jk}(\\mathbf{x}_i)$$ sample individuals covariates \\(\\mathbf{x}_i\\). Population-average absolute predictions follow similarly types outcomes, however survival outcomes specific considerations.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"standardised-survival-predictions","dir":"Reference","previous_headings":"","what":"Standardised survival predictions","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Different types population-average survival predictions, often called standardised survival predictions, follow standardised survival function created integrating (equivalently averaging) individual-level survival functions time \\(t\\): $$\\bar{S}_{jk}(t) = \\int_\\mathfrak{X} S_{jk}(t | \\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x}$$ produced using type = \"survival\". standardised hazard function corresponding standardised survival function weighted average individual-level hazard functions $$\\bar{h}_{jk}(t) = \\frac{\\int_\\mathfrak{X} S_{jk}(t | \\mathbf{x}) h_{jk}(t | \\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x} }{\\bar{S}_{jk}(t)}$$ weighted probability surviving time \\(t\\). produced using type = \"hazard\". corresponding standardised cumulative hazard function $$\\bar{H}_{jk}(t) = -\\log(\\bar{S}_{jk}(t))$$ produced using type = \"cumhaz\". Quantiles medians standardised survival times found solving $$\\bar{S}_{jk}(t) = 1-\\alpha$$ \\(\\alpha\\%\\) quantile, using numerical root finding. produced using type = \"quantile\" \"median\". (Restricted) means standardised survival times found integrating $$\\mathrm{RMST}_{jk}(t^*) = \\int_0^{t^*} \\bar{S}_{jk}(t) dt$$ restricted time horizon \\(t^*\\), \\(t^*=\\infty\\) mean standardised survival time. produced using type = \"rmst\" \"mean\".","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Predicted log odds of success in each study in the network predict(smk_fit_RE) #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[1: No intervention]        -2.79 0.32 -3.47 -2.99 -2.77 -2.57 -2.17 #> pred[1: Group counselling]      -1.69 0.51 -2.70 -2.02 -1.70 -1.35 -0.66 #> pred[1: Individual counselling] -1.94 0.39 -2.73 -2.19 -1.93 -1.68 -1.16 #> pred[1: Self-help]              -2.29 0.51 -3.31 -2.63 -2.29 -1.96 -1.27 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[1: No intervention]            5068     3240    1 #> pred[1: Group counselling]          2418     2512    1 #> pred[1: Individual counselling]     2404     2552    1 #> pred[1: Self-help]                  2122     2626    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[2: No intervention]        -2.56 0.78 -4.18 -3.05 -2.54 -2.07 -1.03 #> pred[2: Group counselling]      -1.46 0.79 -3.04 -1.95 -1.47 -0.98  0.14 #> pred[2: Individual counselling] -1.71 0.77 -3.26 -2.20 -1.70 -1.23 -0.16 #> pred[2: Self-help]              -2.07 0.79 -3.64 -2.55 -2.06 -1.58 -0.44 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[2: No intervention]            2353     2353    1 #> pred[2: Group counselling]          3028     2281    1 #> pred[2: Individual counselling]     2687     2326    1 #> pred[2: Self-help]                  3045     2223    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[3: No intervention]        -2.14 0.12 -2.38 -2.22 -2.14 -2.06 -1.92 #> pred[3: Group counselling]      -1.04 0.46 -1.92 -1.34 -1.05 -0.75 -0.13 #> pred[3: Individual counselling] -1.29 0.27 -1.80 -1.47 -1.30 -1.12 -0.78 #> pred[3: Self-help]              -1.64 0.42 -2.46 -1.92 -1.65 -1.37 -0.79 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[3: No intervention]            8329     2837    1 #> pred[3: Group counselling]          2004     2417    1 #> pred[3: Individual counselling]     1224     2094    1 #> pred[3: Self-help]                  1571     2222    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[4: No intervention]        -4.06 0.58 -5.32 -4.43 -4.03 -3.66 -3.03 #> pred[4: Group counselling]      -2.96 0.70 -4.39 -3.43 -2.94 -2.49 -1.66 #> pred[4: Individual counselling] -3.21 0.59 -4.48 -3.59 -3.18 -2.80 -2.12 #> pred[4: Self-help]              -3.56 0.70 -5.03 -4.02 -3.54 -3.07 -2.25 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[4: No intervention]            4743     2492    1 #> pred[4: Group counselling]          3416     2807    1 #> pred[4: Individual counselling]     4058     2538    1 #> pred[4: Self-help]                  3262     2739    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[5: No intervention]        -2.15 0.14 -2.43 -2.24 -2.15 -2.06 -1.89 #> pred[5: Group counselling]      -1.06 0.46 -1.93 -1.36 -1.06 -0.76 -0.15 #> pred[5: Individual counselling] -1.30 0.28 -1.83 -1.49 -1.31 -1.12 -0.74 #> pred[5: Self-help]              -1.66 0.43 -2.49 -1.93 -1.67 -1.39 -0.75 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[5: No intervention]            8314     2957    1 #> pred[5: Group counselling]          1937     2313    1 #> pred[5: Individual counselling]     1245     2369    1 #> pred[5: Self-help]                  1583     2008    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[6: No intervention]        -3.41 0.73 -5.00 -3.84 -3.37 -2.91 -2.11 #> pred[6: Group counselling]      -2.31 0.83 -4.06 -2.84 -2.28 -1.73 -0.76 #> pred[6: Individual counselling] -2.56 0.72 -4.15 -3.01 -2.52 -2.07 -1.26 #> pred[6: Self-help]              -2.91 0.82 -4.64 -3.41 -2.88 -2.34 -1.43 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[6: No intervention]            3435     2611    1 #> pred[6: Group counselling]          3392     3043    1 #> pred[6: Individual counselling]     3346     2611    1 #> pred[6: Self-help]                  3023     2693    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[7: No intervention]        -3.02 0.45 -4.00 -3.30 -3.00 -2.70 -2.25 #> pred[7: Group counselling]      -1.92 0.61 -3.24 -2.31 -1.90 -1.52 -0.75 #> pred[7: Individual counselling] -2.17 0.48 -3.18 -2.47 -2.15 -1.85 -1.29 #> pred[7: Self-help]              -2.53 0.59 -3.75 -2.89 -2.49 -2.13 -1.43 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[7: No intervention]            4212     2555    1 #> pred[7: Group counselling]          3260     2250    1 #> pred[7: Individual counselling]     3459     2751    1 #> pred[7: Self-help]                  2842     2502    1 #>  #> ---------------------------------------------------------------------- Study: 8 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[8: No intervention]        -2.73 0.60 -4.00 -3.11 -2.68 -2.32 -1.68 #> pred[8: Group counselling]      -1.63 0.71 -3.18 -2.09 -1.61 -1.15 -0.29 #> pred[8: Individual counselling] -1.88 0.60 -3.18 -2.26 -1.84 -1.47 -0.81 #> pred[8: Self-help]              -2.23 0.70 -3.71 -2.68 -2.21 -1.75 -0.95 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[8: No intervention]            2768     1636    1 #> pred[8: Group counselling]          2783     1739    1 #> pred[8: Individual counselling]     2898     2107    1 #> pred[8: Self-help]                  2658     2419    1 #>  #> ---------------------------------------------------------------------- Study: 9 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[9: No intervention]        -1.84 0.42 -2.73 -2.11 -1.83 -1.56 -1.07 #> pred[9: Group counselling]      -0.75 0.60 -1.92 -1.15 -0.75 -0.35  0.45 #> pred[9: Individual counselling] -0.99 0.46 -1.91 -1.30 -0.98 -0.69 -0.07 #> pred[9: Self-help]              -1.35 0.57 -2.49 -1.73 -1.35 -0.97 -0.24 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[9: No intervention]            4942     2609    1 #> pred[9: Group counselling]          2598     2300    1 #> pred[9: Individual counselling]     3100     2892    1 #> pred[9: Self-help]                  2158     2346    1 #>  #> --------------------------------------------------------------------- Study: 10 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[10: No intervention]        -2.08 0.12 -2.32 -2.16 -2.08 -2.00 -1.86 #> pred[10: Group counselling]      -0.99 0.46 -1.84 -1.29 -0.99 -0.70 -0.08 #> pred[10: Individual counselling] -1.23 0.27 -1.75 -1.42 -1.24 -1.05 -0.68 #> pred[10: Self-help]              -1.59 0.42 -2.38 -1.86 -1.60 -1.32 -0.74 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[10: No intervention]            8019     2541    1 #> pred[10: Group counselling]          2018     2080    1 #> pred[10: Individual counselling]     1264     1996    1 #> pred[10: Self-help]                  1518     1991    1 #>  #> --------------------------------------------------------------------- Study: 11 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[11: No intervention]        -3.62 0.24 -4.13 -3.78 -3.62 -3.46 -3.16 #> pred[11: Group counselling]      -2.53 0.50 -3.51 -2.87 -2.53 -2.20 -1.52 #> pred[11: Individual counselling] -2.77 0.34 -3.46 -3.00 -2.78 -2.55 -2.10 #> pred[11: Self-help]              -3.13 0.45 -4.01 -3.42 -3.13 -2.84 -2.19 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[11: No intervention]            7614     2918    1 #> pred[11: Group counselling]          2344     2853    1 #> pred[11: Individual counselling]     1859     2719    1 #> pred[11: Self-help]                  1796     2281    1 #>  #> --------------------------------------------------------------------- Study: 12 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[12: No intervention]        -2.22 0.13 -2.48 -2.30 -2.22 -2.13 -1.97 #> pred[12: Group counselling]      -1.12 0.46 -1.98 -1.42 -1.13 -0.83 -0.21 #> pred[12: Individual counselling] -1.37 0.27 -1.88 -1.55 -1.38 -1.19 -0.84 #> pred[12: Self-help]              -1.72 0.43 -2.55 -2.00 -1.73 -1.46 -0.86 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[12: No intervention]            7791     2892    1 #> pred[12: Group counselling]          1947     2185    1 #> pred[12: Individual counselling]     1257     2163    1 #> pred[12: Self-help]                  1528     2049    1 #>  #> --------------------------------------------------------------------- Study: 13 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[13: No intervention]        -2.67 0.44 -3.58 -2.96 -2.66 -2.35 -1.86 #> pred[13: Group counselling]      -1.57 0.63 -2.79 -1.99 -1.57 -1.16 -0.32 #> pred[13: Individual counselling] -1.82 0.48 -2.79 -2.14 -1.81 -1.48 -0.90 #> pred[13: Self-help]              -2.17 0.61 -3.37 -2.58 -2.17 -1.76 -0.97 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[13: No intervention]            5359     2840    1 #> pred[13: Group counselling]          3018     2668    1 #> pred[13: Individual counselling]     3098     2796    1 #> pred[13: Self-help]                  2461     2983    1 #>  #> --------------------------------------------------------------------- Study: 14 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[14: No intervention]        -2.41 0.23 -2.87 -2.56 -2.40 -2.25 -1.98 #> pred[14: Group counselling]      -1.31 0.50 -2.27 -1.64 -1.31 -0.99 -0.28 #> pred[14: Individual counselling] -1.56 0.33 -2.18 -1.78 -1.56 -1.35 -0.91 #> pred[14: Self-help]              -1.91 0.47 -2.85 -2.22 -1.93 -1.61 -0.96 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[14: No intervention]            6296     2917    1 #> pred[14: Group counselling]          2356     2378    1 #> pred[14: Individual counselling]     1736     2005    1 #> pred[14: Self-help]                  1934     2045    1 #>  #> --------------------------------------------------------------------- Study: 15 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[15: No intervention]        -2.69 0.77 -4.33 -3.16 -2.63 -2.15 -1.39 #> pred[15: Group counselling]      -1.60 0.74 -3.14 -2.06 -1.56 -1.09 -0.26 #> pred[15: Individual counselling] -1.84 0.76 -3.46 -2.32 -1.79 -1.31 -0.51 #> pred[15: Self-help]              -2.20 0.82 -3.94 -2.70 -2.12 -1.64 -0.77 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[15: No intervention]            2911     2364    1 #> pred[15: Group counselling]          3332     2829    1 #> pred[15: Individual counselling]     3259     2633    1 #> pred[15: Self-help]                  2905     2190    1 #>  #> --------------------------------------------------------------------- Study: 16 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[16: No intervention]        -2.62 0.35 -3.34 -2.84 -2.60 -2.37 -1.98 #> pred[16: Group counselling]      -1.52 0.55 -2.60 -1.87 -1.52 -1.16 -0.42 #> pred[16: Individual counselling] -1.77 0.42 -2.62 -2.04 -1.76 -1.47 -0.97 #> pred[16: Self-help]              -2.12 0.49 -3.07 -2.45 -2.13 -1.80 -1.15 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[16: No intervention]            5582     2651    1 #> pred[16: Group counselling]          2871     2839    1 #> pred[16: Individual counselling]     2535     2467    1 #> pred[16: Self-help]                  2229     2713    1 #>  #> --------------------------------------------------------------------- Study: 17 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[17: No intervention]        -2.38 0.10 -2.58 -2.45 -2.37 -2.30 -2.17 #> pred[17: Group counselling]      -1.28 0.45 -2.14 -1.57 -1.29 -0.99 -0.36 #> pred[17: Individual counselling] -1.52 0.26 -2.03 -1.71 -1.53 -1.35 -1.00 #> pred[17: Self-help]              -1.88 0.42 -2.69 -2.15 -1.89 -1.61 -1.01 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[17: No intervention]            7568     2843    1 #> pred[17: Group counselling]          1926     2016    1 #> pred[17: Individual counselling]     1174     1680    1 #> pred[17: Self-help]                  1590     2219    1 #>  #> --------------------------------------------------------------------- Study: 18 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[18: No intervention]        -2.57 0.27 -3.12 -2.74 -2.56 -2.38 -2.07 #> pred[18: Group counselling]      -1.47 0.52 -2.47 -1.81 -1.47 -1.12 -0.44 #> pred[18: Individual counselling] -1.72 0.35 -2.42 -1.95 -1.72 -1.47 -1.03 #> pred[18: Self-help]              -2.07 0.49 -3.04 -2.40 -2.08 -1.75 -1.07 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[18: No intervention]            6718     3039    1 #> pred[18: Group counselling]          2444     2711    1 #> pred[18: Individual counselling]     1861     2587    1 #> pred[18: Self-help]                  1868     2320    1 #>  #> --------------------------------------------------------------------- Study: 19 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[19: No intervention]        -1.90 0.12 -2.13 -1.98 -1.90 -1.82 -1.67 #> pred[19: Group counselling]      -0.80 0.46 -1.67 -1.11 -0.81 -0.51  0.10 #> pred[19: Individual counselling] -1.05 0.27 -1.55 -1.23 -1.06 -0.88 -0.49 #> pred[19: Self-help]              -1.40 0.43 -2.23 -1.68 -1.42 -1.13 -0.49 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[19: No intervention]            8220     2919    1 #> pred[19: Group counselling]          1998     2262    1 #> pred[19: Individual counselling]     1211     2138    1 #> pred[19: Self-help]                  1607     1935    1 #>  #> --------------------------------------------------------------------- Study: 20 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[20: No intervention]        -2.80 0.13 -3.05 -2.89 -2.80 -2.72 -2.55 #> pred[20: Group counselling]      -1.70 0.46 -2.59 -2.01 -1.71 -1.40 -0.77 #> pred[20: Individual counselling] -1.95 0.27 -2.47 -2.14 -1.96 -1.77 -1.40 #> pred[20: Self-help]              -2.30 0.43 -3.13 -2.59 -2.32 -2.03 -1.42 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[20: No intervention]            8570     2682    1 #> pred[20: Group counselling]          2001     2480    1 #> pred[20: Individual counselling]     1255     2070    1 #> pred[20: Self-help]                  1603     2206    1 #>  #> --------------------------------------------------------------------- Study: 21 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[21: No intervention]        -1.13 0.81 -2.73 -1.67 -1.13 -0.62  0.47 #> pred[21: Group counselling]      -0.03 0.87 -1.68 -0.62 -0.05  0.51  1.66 #> pred[21: Individual counselling] -0.28 0.80 -1.80 -0.80 -0.29  0.23  1.32 #> pred[21: Self-help]              -0.64 0.80 -2.20 -1.16 -0.64 -0.11  0.98 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[21: No intervention]            2568     2522    1 #> pred[21: Group counselling]          3185     2443    1 #> pred[21: Individual counselling]     2884     2655    1 #> pred[21: Self-help]                  3395     2806    1 #>  #> --------------------------------------------------------------------- Study: 22 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[22: No intervention]        -2.40 0.86 -4.16 -2.95 -2.38 -1.84 -0.72 #> pred[22: Group counselling]      -1.30 0.82 -2.89 -1.82 -1.29 -0.76  0.34 #> pred[22: Individual counselling] -1.55 0.86 -3.31 -2.10 -1.53 -0.98  0.18 #> pred[22: Self-help]              -1.90 0.83 -3.52 -2.44 -1.90 -1.37 -0.23 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[22: No intervention]            2319     2269    1 #> pred[22: Group counselling]          2883     2556    1 #> pred[22: Individual counselling]     2370     2574    1 #> pred[22: Self-help]                  3234     2581    1 #>  #> --------------------------------------------------------------------- Study: 23 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[23: No intervention]        -2.33 0.85 -4.03 -2.89 -2.32 -1.77 -0.68 #> pred[23: Group counselling]      -1.23 0.82 -2.80 -1.77 -1.24 -0.71  0.50 #> pred[23: Individual counselling] -1.48 0.82 -3.09 -2.01 -1.48 -0.96  0.19 #> pred[23: Self-help]              -1.83 0.89 -3.61 -2.42 -1.82 -1.26 -0.03 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[23: No intervention]            2274     2337    1 #> pred[23: Group counselling]          3082     2533    1 #> pred[23: Individual counselling]     2990     2534    1 #> pred[23: Self-help]                  2851     2489    1 #>  #> --------------------------------------------------------------------- Study: 24 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[24: No intervention]        -2.83 0.89 -4.61 -3.42 -2.82 -2.25 -1.07 #> pred[24: Group counselling]      -1.73 0.87 -3.42 -2.31 -1.73 -1.16  0.02 #> pred[24: Individual counselling] -1.98 0.87 -3.68 -2.55 -1.98 -1.41 -0.27 #> pred[24: Self-help]              -2.33 0.94 -4.19 -2.94 -2.33 -1.72 -0.49 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[24: No intervention]            2803     2553    1 #> pred[24: Group counselling]          3216     2765    1 #> pred[24: Individual counselling]     3511     2903    1 #> pred[24: Self-help]                  2993     2664    1 #>   # Predicted probabilities of success in each study in the network predict(smk_fit_RE, type = \"response\") #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[1: No intervention]        0.06 0.02 0.03 0.05 0.06 0.07  0.10     5068 #> pred[1: Group counselling]      0.17 0.07 0.06 0.12 0.15 0.21  0.34     2418 #> pred[1: Individual counselling] 0.13 0.05 0.06 0.10 0.13 0.16  0.24     2404 #> pred[1: Self-help]              0.10 0.05 0.04 0.07 0.09 0.12  0.22     2122 #>                                 Tail_ESS Rhat #> pred[1: No intervention]            3240    1 #> pred[1: Group counselling]          2512    1 #> pred[1: Individual counselling]     2552    1 #> pred[1: Self-help]                  2626    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[2: No intervention]        0.09 0.07 0.02 0.05 0.07 0.11  0.26     2353 #> pred[2: Group counselling]      0.21 0.13 0.05 0.12 0.19 0.27  0.53     3028 #> pred[2: Individual counselling] 0.18 0.11 0.04 0.10 0.15 0.23  0.46     2687 #> pred[2: Self-help]              0.13 0.09 0.03 0.07 0.11 0.17  0.39     3045 #>                                 Tail_ESS Rhat #> pred[2: No intervention]            2353    1 #> pred[2: Group counselling]          2281    1 #> pred[2: Individual counselling]     2326    1 #> pred[2: Self-help]                  2223    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[3: No intervention]        0.11 0.01 0.08 0.10 0.11 0.11  0.13     8329 #> pred[3: Group counselling]      0.27 0.09 0.13 0.21 0.26 0.32  0.47     2004 #> pred[3: Individual counselling] 0.22 0.05 0.14 0.19 0.21 0.25  0.32     1224 #> pred[3: Self-help]              0.17 0.06 0.08 0.13 0.16 0.20  0.31     1571 #>                                 Tail_ESS Rhat #> pred[3: No intervention]            2837    1 #> pred[3: Group counselling]          2417    1 #> pred[3: Individual counselling]     2094    1 #> pred[3: Self-help]                  2222    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[4: No intervention]        0.02 0.01 0.00 0.01 0.02 0.03  0.05     4743 #> pred[4: Group counselling]      0.06 0.04 0.01 0.03 0.05 0.08  0.16     3416 #> pred[4: Individual counselling] 0.04 0.03 0.01 0.03 0.04 0.06  0.11     4058 #> pred[4: Self-help]              0.03 0.02 0.01 0.02 0.03 0.04  0.09     3262 #>                                 Tail_ESS Rhat #> pred[4: No intervention]            2492    1 #> pred[4: Group counselling]          2807    1 #> pred[4: Individual counselling]     2538    1 #> pred[4: Self-help]                  2739    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[5: No intervention]        0.10 0.01 0.08 0.10 0.10 0.11  0.13     8314 #> pred[5: Group counselling]      0.27 0.09 0.13 0.20 0.26 0.32  0.46     1937 #> pred[5: Individual counselling] 0.22 0.05 0.14 0.18 0.21 0.25  0.32     1245 #> pred[5: Self-help]              0.17 0.06 0.08 0.13 0.16 0.20  0.32     1583 #>                                 Tail_ESS Rhat #> pred[5: No intervention]            2957    1 #> pred[5: Group counselling]          2313    1 #> pred[5: Individual counselling]     2369    1 #> pred[5: Self-help]                  2008    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[6: No intervention]        0.04 0.03 0.01 0.02 0.03 0.05  0.11     3435 #> pred[6: Group counselling]      0.11 0.08 0.02 0.06 0.09 0.15  0.32     3392 #> pred[6: Individual counselling] 0.09 0.05 0.02 0.05 0.07 0.11  0.22     3346 #> pred[6: Self-help]              0.07 0.05 0.01 0.03 0.05 0.09  0.19     3023 #>                                 Tail_ESS Rhat #> pred[6: No intervention]            2611    1 #> pred[6: Group counselling]          3043    1 #> pred[6: Individual counselling]     2611    1 #> pred[6: Self-help]                  2693    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[7: No intervention]        0.05 0.02 0.02 0.04 0.05 0.06  0.10     4212 #> pred[7: Group counselling]      0.14 0.07 0.04 0.09 0.13 0.18  0.32     3260 #> pred[7: Individual counselling] 0.11 0.05 0.04 0.08 0.10 0.14  0.22     3459 #> pred[7: Self-help]              0.08 0.04 0.02 0.05 0.08 0.11  0.19     2842 #>                                 Tail_ESS Rhat #> pred[7: No intervention]            2555    1 #> pred[7: Group counselling]          2250    1 #> pred[7: Individual counselling]     2751    1 #> pred[7: Self-help]                  2502    1 #>  #> ---------------------------------------------------------------------- Study: 8 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[8: No intervention]        0.07 0.04 0.02 0.04 0.06 0.09  0.16     2768 #> pred[8: Group counselling]      0.18 0.10 0.04 0.11 0.17 0.24  0.43     2783 #> pred[8: Individual counselling] 0.15 0.07 0.04 0.09 0.14 0.19  0.31     2898 #> pred[8: Self-help]              0.11 0.07 0.02 0.06 0.10 0.15  0.28     2658 #>                                 Tail_ESS Rhat #> pred[8: No intervention]            1636    1 #> pred[8: Group counselling]          1739    1 #> pred[8: Individual counselling]     2107    1 #> pred[8: Self-help]                  2419    1 #>  #> ---------------------------------------------------------------------- Study: 9 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[9: No intervention]        0.14 0.05 0.06 0.11 0.14 0.17  0.26     4942 #> pred[9: Group counselling]      0.33 0.12 0.13 0.24 0.32 0.41  0.61     2598 #> pred[9: Individual counselling] 0.28 0.09 0.13 0.21 0.27 0.33  0.48     3100 #> pred[9: Self-help]              0.22 0.10 0.08 0.15 0.21 0.28  0.44     2158 #>                                 Tail_ESS Rhat #> pred[9: No intervention]            2609    1 #> pred[9: Group counselling]          2300    1 #> pred[9: Individual counselling]     2892    1 #> pred[9: Self-help]                  2346    1 #>  #> --------------------------------------------------------------------- Study: 10 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[10: No intervention]        0.11 0.01 0.09 0.10 0.11 0.12  0.13     8019 #> pred[10: Group counselling]      0.28 0.09 0.14 0.22 0.27 0.33  0.48     2018 #> pred[10: Individual counselling] 0.23 0.05 0.15 0.19 0.22 0.26  0.34     1264 #> pred[10: Self-help]              0.18 0.06 0.09 0.13 0.17 0.21  0.32     1518 #>                                  Tail_ESS Rhat #> pred[10: No intervention]            2541 1.01 #> pred[10: Group counselling]          2080 1.00 #> pred[10: Individual counselling]     1996 1.00 #> pred[10: Self-help]                  1991 1.00 #>  #> --------------------------------------------------------------------- Study: 11 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[11: No intervention]        0.03 0.01 0.02 0.02 0.03 0.03  0.04     7614 #> pred[11: Group counselling]      0.08 0.04 0.03 0.05 0.07 0.10  0.18     2344 #> pred[11: Individual counselling] 0.06 0.02 0.03 0.05 0.06 0.07  0.11     1859 #> pred[11: Self-help]              0.05 0.02 0.02 0.03 0.04 0.06  0.10     1796 #>                                  Tail_ESS Rhat #> pred[11: No intervention]            2918    1 #> pred[11: Group counselling]          2853    1 #> pred[11: Individual counselling]     2719    1 #> pred[11: Self-help]                  2281    1 #>  #> --------------------------------------------------------------------- Study: 12 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[12: No intervention]        0.10 0.01 0.08 0.09 0.10 0.11  0.12     7791 #> pred[12: Group counselling]      0.25 0.09 0.12 0.19 0.24 0.30  0.45     1947 #> pred[12: Individual counselling] 0.21 0.04 0.13 0.17 0.20 0.23  0.30     1257 #> pred[12: Self-help]              0.16 0.06 0.07 0.12 0.15 0.19  0.30     1528 #>                                  Tail_ESS Rhat #> pred[12: No intervention]            2892    1 #> pred[12: Group counselling]          2185    1 #> pred[12: Individual counselling]     2163    1 #> pred[12: Self-help]                  2049    1 #>  #> --------------------------------------------------------------------- Study: 13 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[13: No intervention]        0.07 0.03 0.03 0.05 0.07 0.09  0.14     5359 #> pred[13: Group counselling]      0.19 0.09 0.06 0.12 0.17 0.24  0.42     3018 #> pred[13: Individual counselling] 0.15 0.06 0.06 0.11 0.14 0.19  0.29     3098 #> pred[13: Self-help]              0.12 0.06 0.03 0.07 0.10 0.15  0.27     2461 #>                                  Tail_ESS Rhat #> pred[13: No intervention]            2840    1 #> pred[13: Group counselling]          2668    1 #> pred[13: Individual counselling]     2796    1 #> pred[13: Self-help]                  2983    1 #>  #> --------------------------------------------------------------------- Study: 14 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[14: No intervention]        0.08 0.02 0.05 0.07 0.08 0.10  0.12     6296 #> pred[14: Group counselling]      0.22 0.09 0.09 0.16 0.21 0.27  0.43     2356 #> pred[14: Individual counselling] 0.18 0.05 0.10 0.14 0.17 0.21  0.29     1736 #> pred[14: Self-help]              0.14 0.06 0.05 0.10 0.13 0.17  0.28     1934 #>                                  Tail_ESS Rhat #> pred[14: No intervention]            2917    1 #> pred[14: Group counselling]          2378    1 #> pred[14: Individual counselling]     2005    1 #> pred[14: Self-help]                  2045    1 #>  #> --------------------------------------------------------------------- Study: 15 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[15: No intervention]        0.08 0.05 0.01 0.04 0.07 0.10  0.20     2911 #> pred[15: Group counselling]      0.19 0.10 0.04 0.11 0.17 0.25  0.44     3332 #> pred[15: Individual counselling] 0.16 0.09 0.03 0.09 0.14 0.21  0.38     3259 #> pred[15: Self-help]              0.12 0.08 0.02 0.06 0.11 0.16  0.32     2905 #>                                  Tail_ESS Rhat #> pred[15: No intervention]            2364    1 #> pred[15: Group counselling]          2829    1 #> pred[15: Individual counselling]     2633    1 #> pred[15: Self-help]                  2190    1 #>  #> --------------------------------------------------------------------- Study: 16 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[16: No intervention]        0.07 0.02 0.03 0.06 0.07 0.09  0.12     5582 #> pred[16: Group counselling]      0.19 0.08 0.07 0.13 0.18 0.24  0.40     2871 #> pred[16: Individual counselling] 0.15 0.05 0.07 0.11 0.15 0.19  0.27     2535 #> pred[16: Self-help]              0.12 0.05 0.04 0.08 0.11 0.14  0.24     2229 #>                                  Tail_ESS Rhat #> pred[16: No intervention]            2651    1 #> pred[16: Group counselling]          2839    1 #> pred[16: Individual counselling]     2467    1 #> pred[16: Self-help]                  2713    1 #>  #> --------------------------------------------------------------------- Study: 17 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[17: No intervention]        0.09 0.01 0.07 0.08 0.09 0.09  0.10     7568 #> pred[17: Group counselling]      0.23 0.08 0.11 0.17 0.22 0.27  0.41     1926 #> pred[17: Individual counselling] 0.18 0.04 0.12 0.15 0.18 0.21  0.27     1174 #> pred[17: Self-help]              0.14 0.05 0.06 0.10 0.13 0.17  0.27     1590 #>                                  Tail_ESS Rhat #> pred[17: No intervention]            2843    1 #> pred[17: Group counselling]          2016    1 #> pred[17: Individual counselling]     1680    1 #> pred[17: Self-help]                  2219    1 #>  #> --------------------------------------------------------------------- Study: 18 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[18: No intervention]        0.07 0.02 0.04 0.06 0.07 0.08  0.11     6718 #> pred[18: Group counselling]      0.20 0.08 0.08 0.14 0.19 0.25  0.39     2444 #> pred[18: Individual counselling] 0.16 0.05 0.08 0.12 0.15 0.19  0.26     1861 #> pred[18: Self-help]              0.12 0.05 0.05 0.08 0.11 0.15  0.26     1868 #>                                  Tail_ESS Rhat #> pred[18: No intervention]            3039    1 #> pred[18: Group counselling]          2711    1 #> pred[18: Individual counselling]     2587    1 #> pred[18: Self-help]                  2320    1 #>  #> --------------------------------------------------------------------- Study: 19 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[19: No intervention]        0.13 0.01 0.11 0.12 0.13 0.14  0.16     8220 #> pred[19: Group counselling]      0.32 0.10 0.16 0.25 0.31 0.37  0.53     1998 #> pred[19: Individual counselling] 0.26 0.05 0.18 0.23 0.26 0.29  0.38     1211 #> pred[19: Self-help]              0.21 0.07 0.10 0.16 0.20 0.24  0.38     1607 #>                                  Tail_ESS Rhat #> pred[19: No intervention]            2919    1 #> pred[19: Group counselling]          2262    1 #> pred[19: Individual counselling]     2138    1 #> pred[19: Self-help]                  1935    1 #>  #> --------------------------------------------------------------------- Study: 20 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[20: No intervention]        0.06 0.01 0.05 0.05 0.06 0.06  0.07     8570 #> pred[20: Group counselling]      0.16 0.06 0.07 0.12 0.15 0.20  0.32     2001 #> pred[20: Individual counselling] 0.13 0.03 0.08 0.10 0.12 0.15  0.20     1255 #> pred[20: Self-help]              0.10 0.04 0.04 0.07 0.09 0.12  0.19     1603 #>                                  Tail_ESS Rhat #> pred[20: No intervention]            2682    1 #> pred[20: Group counselling]          2480    1 #> pred[20: Individual counselling]     2070    1 #> pred[20: Self-help]                  2206    1 #>  #> --------------------------------------------------------------------- Study: 21 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[21: No intervention]        0.27 0.15 0.06 0.16 0.24 0.35  0.62     2568 #> pred[21: Group counselling]      0.49 0.18 0.16 0.35 0.49 0.62  0.84     3185 #> pred[21: Individual counselling] 0.44 0.17 0.14 0.31 0.43 0.56  0.79     2884 #> pred[21: Self-help]              0.36 0.16 0.10 0.24 0.34 0.47  0.73     3395 #>                                  Tail_ESS Rhat #> pred[21: No intervention]            2522    1 #> pred[21: Group counselling]          2443    1 #> pred[21: Individual counselling]     2655    1 #> pred[21: Self-help]                  2806    1 #>  #> --------------------------------------------------------------------- Study: 22 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[22: No intervention]        0.11 0.08 0.02 0.05 0.08 0.14  0.33     2319 #> pred[22: Group counselling]      0.24 0.14 0.05 0.14 0.22 0.32  0.58     2883 #> pred[22: Individual counselling] 0.20 0.13 0.04 0.11 0.18 0.27  0.55     2370 #> pred[22: Self-help]              0.16 0.11 0.03 0.08 0.13 0.20  0.44     3234 #>                                  Tail_ESS Rhat #> pred[22: No intervention]            2269    1 #> pred[22: Group counselling]          2556    1 #> pred[22: Individual counselling]     2574    1 #> pred[22: Self-help]                  2581    1 #>  #> --------------------------------------------------------------------- Study: 23 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[23: No intervention]        0.11 0.08 0.02 0.05 0.09 0.15  0.34     2274 #> pred[23: Group counselling]      0.25 0.14 0.06 0.15 0.23 0.33  0.62     3082 #> pred[23: Individual counselling] 0.21 0.13 0.04 0.12 0.19 0.28  0.55     2990 #> pred[23: Self-help]              0.17 0.12 0.03 0.08 0.14 0.22  0.49     2851 #>                                  Tail_ESS Rhat #> pred[23: No intervention]            2337    1 #> pred[23: Group counselling]          2533    1 #> pred[23: Individual counselling]     2534    1 #> pred[23: Self-help]                  2489    1 #>  #> --------------------------------------------------------------------- Study: 24 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[24: No intervention]        0.08 0.07 0.01 0.03 0.06 0.10  0.25     2803 #> pred[24: Group counselling]      0.18 0.12 0.03 0.09 0.15 0.24  0.51     3216 #> pred[24: Individual counselling] 0.15 0.11 0.02 0.07 0.12 0.20  0.43     3511 #> pred[24: Self-help]              0.12 0.10 0.01 0.05 0.09 0.15  0.38     2993 #>                                  Tail_ESS Rhat #> pred[24: No intervention]            2553    1 #> pred[24: Group counselling]          2765    1 #> pred[24: Individual counselling]     2903    1 #> pred[24: Self-help]                  2664    1 #>   # Predicted probabilities in a population with 67 observed events out of 566 # individuals on No Intervention, corresponding to a Beta(67, 566 - 67) # distribution on the baseline probability of response, using # `baseline_type = \"response\"` (smk_pred_RE <- predict(smk_fit_RE,                         baseline = distr(qbeta, 67, 566 - 67),                         baseline_type = \"response\",                         type = \"response\")) #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[No intervention]        0.12 0.01 0.09 0.11 0.12 0.13  0.15     3697 #> pred[Group counselling]      0.29 0.09 0.14 0.23 0.28 0.35  0.50     1985 #> pred[Individual counselling] 0.24 0.05 0.16 0.21 0.24 0.27  0.36     1272 #> pred[Self-help]              0.19 0.07 0.09 0.14 0.18 0.22  0.35     1572 #>                              Tail_ESS Rhat #> pred[No intervention]            3933    1 #> pred[Group counselling]          2467    1 #> pred[Individual counselling]     2027    1 #> pred[Self-help]                  1724    1 plot(smk_pred_RE, ref_line = c(0, 1))   # Predicted probabilities in a population with a baseline log odds of # response on No Intervention given a Normal distribution with mean -2 # and SD 0.13, using `baseline_type = \"link\"` (the default) # Note: this is approximately equivalent to the above Beta distribution on # the baseline probability (smk_pred_RE2 <- predict(smk_fit_RE,                          baseline = distr(qnorm, mean = -2, sd = 0.13),                          type = \"response\")) #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[No intervention]        0.12 0.01 0.10 0.11 0.12 0.13  0.15     3856 #> pred[Group counselling]      0.30 0.09 0.14 0.23 0.29 0.35  0.51     1891 #> pred[Individual counselling] 0.24 0.05 0.16 0.21 0.24 0.28  0.36     1221 #> pred[Self-help]              0.19 0.07 0.09 0.14 0.18 0.23  0.35     1525 #>                              Tail_ESS Rhat #> pred[No intervention]            3813    1 #> pred[Group counselling]          2204    1 #> pred[Individual counselling]     1982    1 #> pred[Self-help]                  2002    1 plot(smk_pred_RE2, ref_line = c(0, 1))  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Predicted probabilities of response in each study in the network (pso_pred <- predict(pso_fit, type = \"response\")) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[FIXTURE: PBO]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     3799     2827 #> pred[FIXTURE: ETN]     0.46 0.03 0.41 0.44 0.46 0.47  0.51     8263     3116 #> pred[FIXTURE: IXE_Q2W] 0.89 0.02 0.85 0.88 0.89 0.90  0.92     6355     3005 #> pred[FIXTURE: IXE_Q4W] 0.80 0.03 0.74 0.78 0.80 0.81  0.84     7261     3206 #> pred[FIXTURE: SEC_150] 0.67 0.03 0.62 0.65 0.67 0.69  0.72     8354     2843 #> pred[FIXTURE: SEC_300] 0.77 0.02 0.72 0.75 0.77 0.79  0.81     8469     2807 #>                        Rhat #> pred[FIXTURE: PBO]        1 #> pred[FIXTURE: ETN]        1 #> pred[FIXTURE: IXE_Q2W]    1 #> pred[FIXTURE: IXE_Q4W]    1 #> pred[FIXTURE: SEC_150]    1 #> pred[FIXTURE: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-1: PBO]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     5203     3214 #> pred[UNCOVER-1: ETN]     0.46 0.03 0.41 0.44 0.46 0.48  0.52     5935     3067 #> pred[UNCOVER-1: IXE_Q2W] 0.90 0.01 0.88 0.89 0.90 0.91  0.92     7353     2704 #> pred[UNCOVER-1: IXE_Q4W] 0.81 0.01 0.78 0.80 0.81 0.82  0.84     8352     2848 #> pred[UNCOVER-1: SEC_150] 0.69 0.04 0.60 0.66 0.69 0.72  0.76     6491     3237 #> pred[UNCOVER-1: SEC_300] 0.78 0.04 0.71 0.76 0.79 0.81  0.85     7001     3016 #>                          Rhat #> pred[UNCOVER-1: PBO]        1 #> pred[UNCOVER-1: ETN]        1 #> pred[UNCOVER-1: IXE_Q2W]    1 #> pred[UNCOVER-1: IXE_Q4W]    1 #> pred[UNCOVER-1: SEC_150]    1 #> pred[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-2: PBO]     0.05 0.01 0.03 0.04 0.05 0.05  0.06     5030     2975 #> pred[UNCOVER-2: ETN]     0.42 0.02 0.38 0.41 0.42 0.43  0.46     8584     3005 #> pred[UNCOVER-2: IXE_Q2W] 0.88 0.01 0.86 0.87 0.88 0.89  0.90     6612     3249 #> pred[UNCOVER-2: IXE_Q4W] 0.78 0.02 0.75 0.77 0.78 0.79  0.81     8710     3101 #> pred[UNCOVER-2: SEC_150] 0.65 0.04 0.57 0.62 0.65 0.68  0.73     6843     2926 #> pred[UNCOVER-2: SEC_300] 0.75 0.04 0.68 0.73 0.75 0.78  0.82     7552     2896 #>                          Rhat #> pred[UNCOVER-2: PBO]        1 #> pred[UNCOVER-2: ETN]        1 #> pred[UNCOVER-2: IXE_Q2W]    1 #> pred[UNCOVER-2: IXE_Q4W]    1 #> pred[UNCOVER-2: SEC_150]    1 #> pred[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-3: PBO]     0.08 0.01 0.06 0.07 0.08 0.08  0.10     5087     3270 #> pred[UNCOVER-3: ETN]     0.53 0.02 0.49 0.52 0.53 0.54  0.57     9351     3172 #> pred[UNCOVER-3: IXE_Q2W] 0.93 0.01 0.91 0.92 0.93 0.93  0.94     6234     3189 #> pred[UNCOVER-3: IXE_Q4W] 0.85 0.01 0.83 0.85 0.85 0.86  0.88     8074     3188 #> pred[UNCOVER-3: SEC_150] 0.75 0.03 0.68 0.72 0.75 0.77  0.81     7695     3213 #> pred[UNCOVER-3: SEC_300] 0.83 0.03 0.77 0.81 0.83 0.85  0.89     7771     3164 #>                          Rhat #> pred[UNCOVER-3: PBO]        1 #> pred[UNCOVER-3: ETN]        1 #> pred[UNCOVER-3: IXE_Q2W]    1 #> pred[UNCOVER-3: IXE_Q4W]    1 #> pred[UNCOVER-3: SEC_150]    1 #> pred[UNCOVER-3: SEC_300]    1 #>  plot(pso_pred, ref_line = c(0, 1))   # Predicted probabilites of response in a new target population, with means # and SDs or proportions given by new_agd_int <- data.frame(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1 )  # We need to add integration points to this data frame of new data # We use the weighted mean correlation matrix computed from the IPD studies new_agd_int <- add_integration(new_agd_int,                                durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),                                prevsys = distr(qbern, prob = prevsys),                                bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),                                weight = distr(qgamma, mean = weight_mean, sd = weight_sd),                                psa = distr(qbern, prob = psa),                                cor = pso_net$int_cor,                                n_int = 64)  # Predicted probabilities of achieving PASI 75 in this target population, given # a Normal(-1.75, 0.08^2) distribution on the baseline probit-probability of # response on Placebo (at the reference levels of the covariates), are given by (pso_pred_new <- predict(pso_fit,                          type = \"response\",                          newdata = new_agd_int,                          baseline = distr(qnorm, -1.75, 0.08))) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: PBO]     0.06 0.02 0.02 0.04 0.06 0.07  0.12     4601     3191    1 #> pred[New 1: ETN]     0.37 0.06 0.26 0.33 0.37 0.41  0.49     5989     3447    1 #> pred[New 1: IXE_Q2W] 0.90 0.03 0.84 0.88 0.90 0.92  0.94     5299     3352    1 #> pred[New 1: IXE_Q4W] 0.81 0.04 0.73 0.78 0.81 0.83  0.87     5523     3551    1 #> pred[New 1: SEC_150] 0.68 0.06 0.57 0.64 0.68 0.72  0.78     4702     3508    1 #> pred[New 1: SEC_300] 0.78 0.05 0.68 0.75 0.78 0.81  0.86     5279     3155    1 #>  plot(pso_pred_new, ref_line = c(0, 1))  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Print nma_data objects — print.nma_data","title":"Print nma_data objects — print.nma_data","text":"Print details networks stored nma_data objects, created set_ipd(), set_agd_arm(), set_agd_contrast(), set_agd_surv(), combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print nma_data objects — print.nma_data","text":"","code":"# S3 method for nma_data print(x, ..., n = 10)  # S3 method for mlnmr_data print(x, ..., n = 10)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print nma_data objects — print.nma_data","text":"x nma_data object ... options (used) n number studies type print","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Print DIC details — print.nma_dic","title":"Print DIC details — print.nma_dic","text":"Print details DIC model fit statistics, computed dic() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print DIC details — print.nma_dic","text":"","code":"# S3 method for nma_dic print(x, digits = 1, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print DIC details — print.nma_dic","text":"x object class nma_dic digits integer passed round() ... Ignored","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print DIC details — print.nma_dic","text":"x returned invisibly.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"Print nma_nodesplit_df objects","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"","code":"# S3 method for nma_nodesplit_df print(x, ...)  # S3 method for nma_nodesplit print(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"x nma_nodesplit_df object ... arguments passed print.stanfit()","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Print stan_nma objects — print.stan_nma","title":"Print stan_nma objects — print.stan_nma","text":"Print stan_nma objects","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print stan_nma objects — print.stan_nma","text":"","code":"# S3 method for stan_nma print(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print stan_nma objects — print.stan_nma","text":"x stan_nma object ... arguments passed print.stanfit()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":null,"dir":"Reference","previous_headings":"","what":"Prior distributions — priors","title":"Prior distributions — priors","text":"functions used specify prior distributions model parameters.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prior distributions — priors","text":"","code":"normal(location = 0, scale)  half_normal(scale)  log_normal(location, scale)  cauchy(location = 0, scale)  half_cauchy(scale)  student_t(location = 0, scale, df)  half_student_t(scale, df)  log_student_t(location, scale, df)  exponential(scale = 1/rate, rate = 1/scale)  flat()  dirichlet(shape = 1)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prior distributions — priors","text":"location Prior location. Typically prior mean (see details). scale Prior scale. Typically prior standard deviation (see details). df Prior degrees freedom. rate Prior rate. shape Prior shape.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prior distributions — priors","text":"Object class nma_prior.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prior distributions — priors","text":"location scale parameters typically prior mean standard deviation, following exceptions: Cauchy distribution location prior median scale prior scale. log-Normal distribution, location scale prior mean standard deviation logarithm.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"compatibility-with-model-parameters","dir":"Reference","previous_headings":"","what":"Compatibility with model parameters","title":"Prior distributions — priors","text":"following table summarises prior distributions may used model parameters. Essentially, priors take non-negative values (e.g. half-Normal) may used non-negative parameters (heterogeneity SD/variance/precision, auxiliary parameter). real-valued prior distribution specified non-negative parameter, truncated 0 non-negative. flat() prior special case prior information added model, resulting implicit flat uniform prior distribution entire support parameter. improper prior parameter unbounded, generally advised. See Stan user's guide details. dirichlet() prior currently used prior distribution spline coefficients mspline pexp models, form \\(L\\)-dimensional unit simplex (.e. lie 0 1, sum 1). shape parameter controls concentration, shape=1 corresponding uniform prior simplexes. Values shape \\(<1\\) concentrate prior mass corners simplex, one dimension close 1 rest close zero; values shape \\(>1\\) increasingly concentrate dimensions towards prior mean \\(1/L\\).","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Random effects structure — RE_cor","title":"Random effects structure — RE_cor","text":"Use RE_cor generate random effects correlation matrix, assumption common heterogeneity variance (.e. within-study correlations 0.5). Use which_RE return vector IDs RE deltas (0 means RE delta arm).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random effects structure — RE_cor","text":"","code":"RE_cor(study, trt, contrast, type = c(\"reftrt\", \"blshift\"))  which_RE(study, trt, contrast, type = c(\"reftrt\", \"blshift\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random effects structure — RE_cor","text":"study vector study IDs (integer, character, factor) trt factor vector treatment codes (coercible ), first level indicating reference treatment contrast logical vector, length study trt, indicating whether corresponding data contrast rather arm format. type Character string, whether generate RE structure \"reference treatment\" parameterisation, \"baseline shift\" parameterisation.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random effects structure — RE_cor","text":"RE_cor(), correlation matrix dimension equal number random effects deltas (excluding set equal zero). which_RE(), integer vector IDs indexing rows columns correlation matrix returned RE_cor().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random effects structure — RE_cor","text":"","code":"RE_cor(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking))) #> Coerced `trt` to factor. #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #>  [1,]  1.0  0.5  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>  [2,]  0.5  1.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>  [3,]  0.0  0.0  1.0  0.5  0.5    0    0    0    0     0     0     0     0 #>  [4,]  0.0  0.0  0.5  1.0  0.5    0    0    0    0     0     0     0     0 #>  [5,]  0.0  0.0  0.5  0.5  1.0    0    0    0    0     0     0     0     0 #>  [6,]  0.0  0.0  0.0  0.0  0.0    1    0    0    0     0     0     0     0 #>  [7,]  0.0  0.0  0.0  0.0  0.0    0    1    0    0     0     0     0     0 #>  [8,]  0.0  0.0  0.0  0.0  0.0    0    0    1    0     0     0     0     0 #>  [9,]  0.0  0.0  0.0  0.0  0.0    0    0    0    1     0     0     0     0 #> [10,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     1     0     0     0 #> [11,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     1     0     0 #> [12,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     1     0 #> [13,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     1 #> [14,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [15,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [16,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [17,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [18,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [19,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [20,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [21,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [22,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [23,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [24,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [25,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [26,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [27,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [28,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [29,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [30,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [31,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] #>  [1,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [2,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [3,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [4,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [5,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [6,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [7,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [8,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [9,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [10,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [11,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [12,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [13,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [14,]     1     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [15,]     0     1     0     0     0     0     0     0     0     0   0.0   0.0 #> [16,]     0     0     1     0     0     0     0     0     0     0   0.0   0.0 #> [17,]     0     0     0     1     0     0     0     0     0     0   0.0   0.0 #> [18,]     0     0     0     0     1     0     0     0     0     0   0.0   0.0 #> [19,]     0     0     0     0     0     1     0     0     0     0   0.0   0.0 #> [20,]     0     0     0     0     0     0     1     0     0     0   0.0   0.0 #> [21,]     0     0     0     0     0     0     0     1     0     0   0.0   0.0 #> [22,]     0     0     0     0     0     0     0     0     1     0   0.0   0.0 #> [23,]     0     0     0     0     0     0     0     0     0     1   0.0   0.0 #> [24,]     0     0     0     0     0     0     0     0     0     0   1.0   0.5 #> [25,]     0     0     0     0     0     0     0     0     0     0   0.5   1.0 #> [26,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [27,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [28,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [29,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [30,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [31,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>       [,26] [,27] [,28] [,29] [,30] [,31] #>  [1,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [2,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [3,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [4,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [5,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [6,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [7,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [8,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [9,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [10,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [11,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [12,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [13,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [14,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [15,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [16,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [17,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [18,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [19,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [20,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [21,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [22,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [23,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [24,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [25,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [26,]   1.0   0.5   0.0   0.0   0.0   0.0 #> [27,]   0.5   1.0   0.0   0.0   0.0   0.0 #> [28,]   0.0   0.0   1.0   0.5   0.0   0.0 #> [29,]   0.0   0.0   0.5   1.0   0.0   0.0 #> [30,]   0.0   0.0   0.0   0.0   1.0   0.5 #> [31,]   0.0   0.0   0.0   0.0   0.5   1.0 RE_cor(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking)), type = \"blshift\") #> Coerced `trt` to factor. #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #>  [1,]  1.0  0.5  0.0  0.0    0    0    0    0    0     0     0     0     0 #>  [2,]  0.5  1.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #>  [3,]  0.0  0.0  1.0  0.5    0    0    0    0    0     0     0     0     0 #>  [4,]  0.0  0.0  0.5  1.0    0    0    0    0    0     0     0     0     0 #>  [5,]  0.0  0.0  0.0  0.0    1    0    0    0    0     0     0     0     0 #>  [6,]  0.0  0.0  0.0  0.0    0    1    0    0    0     0     0     0     0 #>  [7,]  0.0  0.0  0.0  0.0    0    0    1    0    0     0     0     0     0 #>  [8,]  0.0  0.0  0.0  0.0    0    0    0    1    0     0     0     0     0 #>  [9,]  0.0  0.0  0.0  0.0    0    0    0    0    1     0     0     0     0 #> [10,]  0.0  0.0  0.0  0.0    0    0    0    0    0     1     0     0     0 #> [11,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     1     0     0 #> [12,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     1     0 #> [13,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     1 #> [14,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [15,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [16,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [17,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [18,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [19,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [20,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [21,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [22,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [23,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [24,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [25,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [26,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #>       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] #>  [1,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [2,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [3,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [4,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [5,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [6,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [7,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [8,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [9,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [10,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [11,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [12,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [13,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [14,]     1     0     0     0     0     0     0     0     0     0     0     0 #> [15,]     0     1     0     0     0     0     0     0     0     0     0     0 #> [16,]     0     0     1     0     0     0     0     0     0     0     0     0 #> [17,]     0     0     0     1     0     0     0     0     0     0     0     0 #> [18,]     0     0     0     0     1     0     0     0     0     0     0     0 #> [19,]     0     0     0     0     0     1     0     0     0     0     0     0 #> [20,]     0     0     0     0     0     0     1     0     0     0     0     0 #> [21,]     0     0     0     0     0     0     0     1     0     0     0     0 #> [22,]     0     0     0     0     0     0     0     0     1     0     0     0 #> [23,]     0     0     0     0     0     0     0     0     0     1     0     0 #> [24,]     0     0     0     0     0     0     0     0     0     0     1     0 #> [25,]     0     0     0     0     0     0     0     0     0     0     0     1 #> [26,]     0     0     0     0     0     0     0     0     0     0     0     0 #>       [,26] #>  [1,]     0 #>  [2,]     0 #>  [3,]     0 #>  [4,]     0 #>  [5,]     0 #>  [6,]     0 #>  [7,]     0 #>  [8,]     0 #>  [9,]     0 #> [10,]     0 #> [11,]     0 #> [12,]     0 #> [13,]     0 #> [14,]     0 #> [15,]     0 #> [16,]     0 #> [17,]     0 #> [18,]     0 #> [19,]     0 #> [20,]     0 #> [21,]     0 #> [22,]     0 #> [23,]     0 #> [24,]     0 #> [25,]     0 #> [26,]     1 which_RE(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking))) #> Coerced `trt` to factor. #>  [1]  0  1  2  3  4  5  0  6  0  7  0  8  0  9  0 10  0 11  0 12  0 13  0 14  0 #> [26] 15  0 16  0 17  0 18  0 19  0 20  0 21  0 22  0 23 24 25 26 27 28 29 30 31 which_RE(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking)), type = \"blshift\") #> Coerced `trt` to factor. #>  [1]  0  1  2  0  3  4  0  5  0  6  0  7  0  8  0  9  0 10  0 11  0 12  0 13  0 #> [26] 14  0 15  0 16  0 17  0 18  0 19  0 20  0 21  0 22  0 23  0 24  0 25  0 26"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. survival Surv","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Relative treatment effects — relative_effects","title":"Relative treatment effects — relative_effects","text":"Generate (population-average) relative treatment effects. ML-NMR meta-regression model fitted, specific study population.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relative treatment effects — relative_effects","text":"","code":"relative_effects(   x,   newdata = NULL,   study = NULL,   all_contrasts = FALSE,   trt_ref = NULL,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relative treatment effects — relative_effects","text":"x stan_nma object created nma() newdata used regression model fitted. data frame study details, one row per study, giving covariate values produce relative effects. Column names must match variables regression model. NULL, relative effects produced studies network. study Column newdata specifies study names, otherwise studies labelled row number. all_contrasts Logical, generate estimates contrasts (TRUE), just \"basic\" contrasts network reference treatment (FALSE)? Default FALSE. trt_ref Reference treatment construct relative effects , all_contrasts = FALSE. default, relative effects network reference treatment. Coerced character string. probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) predictive_distribution Logical, random effects model fitted, predictive distribution relative effects new study returned? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relative treatment effects — relative_effects","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Relative treatment effects — relative_effects","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce relative effects smk_releff_RE <- relative_effects(smk_fit_RE) smk_releff_RE #>                           mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> d[Group counselling]      1.10 0.44  0.26 0.81 1.09 1.37  1.97     1889 #> d[Individual counselling] 0.85 0.24  0.40 0.68 0.85 1.01  1.34     1052 #> d[Self-help]              0.50 0.41 -0.30 0.23 0.48 0.76  1.34     1466 #>                           Tail_ESS Rhat #> d[Group counselling]          2027    1 #> d[Individual counselling]     1684    1 #> d[Self-help]                  1962    1 plot(smk_releff_RE, ref_line = 0)   # Relative effects for all pairwise comparisons relative_effects(smk_fit_RE, all_contrasts = TRUE) #>                                                  mean   sd  2.5%   25%   50% #> d[Group counselling vs. No intervention]         1.10 0.44  0.26  0.81  1.09 #> d[Individual counselling vs. No intervention]    0.85 0.24  0.40  0.68  0.85 #> d[Self-help vs. No intervention]                 0.50 0.41 -0.30  0.23  0.48 #> d[Individual counselling vs. Group counselling] -0.25 0.42 -1.07 -0.52 -0.25 #> d[Self-help vs. Group counselling]              -0.60 0.49 -1.56 -0.92 -0.60 #> d[Self-help vs. Individual counselling]         -0.35 0.43 -1.20 -0.63 -0.35 #>                                                   75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling vs. No intervention]         1.37  1.97     1889     2027 #> d[Individual counselling vs. No intervention]    1.01  1.34     1052     1684 #> d[Self-help vs. No intervention]                 0.76  1.34     1466     1962 #> d[Individual counselling vs. Group counselling]  0.02  0.61     2335     2601 #> d[Self-help vs. Group counselling]              -0.29  0.37     2321     2121 #> d[Self-help vs. Individual counselling]         -0.07  0.50     1900     2446 #>                                                 Rhat #> d[Group counselling vs. No intervention]           1 #> d[Individual counselling vs. No intervention]      1 #> d[Self-help vs. No intervention]                   1 #> d[Individual counselling vs. Group counselling]    1 #> d[Self-help vs. Group counselling]                 1 #> d[Self-help vs. Individual counselling]            1  # Relative effects against a different reference treatment relative_effects(smk_fit_RE, trt_ref = \"Self-help\") #>                            mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> d[No intervention]        -0.50 0.41 -1.34 -0.76 -0.48 -0.23  0.30     1466 #> d[Group counselling]       0.60 0.49 -0.37  0.29  0.60  0.92  1.56     2321 #> d[Individual counselling]  0.35 0.43 -0.50  0.07  0.35  0.63  1.20     1900 #>                           Tail_ESS Rhat #> d[No intervention]            1962    1 #> d[Group counselling]          2121    1 #> d[Individual counselling]     2446    1  # Transforming to odds ratios # We work with the array of relative effects samples LOR_array <- as.array(smk_releff_RE) OR_array <- exp(LOR_array)  # mcmc_array objects can be summarised to produce a nma_summary object smk_OR_RE <- summary(OR_array)  # This can then be printed or plotted smk_OR_RE #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling]      3.33 1.74 1.30 2.25 2.99 3.94  7.18     1889     2027 #> d[Individual counselling] 2.41 0.61 1.49 1.98 2.33 2.74  3.84     1052     1684 #> d[Self-help]              1.79 0.80 0.74 1.26 1.62 2.13  3.84     1466     1962 #>                           Rhat #> d[Group counselling]         1 #> d[Individual counselling]    1 #> d[Self-help]                 1 plot(smk_OR_RE, ref_line = 1)  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Produce population-adjusted relative effects for all study populations in # the network pso_releff <- relative_effects(pso_fit) pso_releff #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[FIXTURE: ETN]     1.66 0.09 1.48 1.60 1.66 1.72  1.84     3869     3170    1 #> d[FIXTURE: IXE_Q2W] 3.03 0.10 2.83 2.96 3.03 3.10  3.23     5181     3120    1 #> d[FIXTURE: IXE_Q4W] 2.62 0.10 2.43 2.55 2.62 2.68  2.81     5205     3515    1 #> d[FIXTURE: SEC_150] 2.22 0.12 1.99 2.14 2.22 2.30  2.46     3862     3415    1 #> d[FIXTURE: SEC_300] 2.52 0.12 2.28 2.44 2.52 2.61  2.77     4476     3172    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-1: ETN]     1.51 0.09 1.34 1.45 1.51 1.57  1.68     4126     3428 #> d[UNCOVER-1: IXE_Q2W] 2.92 0.09 2.75 2.86 2.93 2.99  3.10     4987     3049 #> d[UNCOVER-1: IXE_Q4W] 2.51 0.08 2.35 2.45 2.51 2.57  2.67     5390     3124 #> d[UNCOVER-1: SEC_150] 2.12 0.12 1.89 2.03 2.11 2.20  2.35     4297     3084 #> d[UNCOVER-1: SEC_300] 2.42 0.13 2.17 2.33 2.42 2.51  2.67     5048     3106 #>                       Rhat #> d[UNCOVER-1: ETN]        1 #> d[UNCOVER-1: IXE_Q2W]    1 #> d[UNCOVER-1: IXE_Q4W]    1 #> d[UNCOVER-1: SEC_150]    1 #> d[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-2: ETN]     1.51 0.08 1.35 1.45 1.51 1.57  1.67     4125     3163 #> d[UNCOVER-2: IXE_Q2W] 2.92 0.09 2.75 2.87 2.92 2.98  3.09     5023     3231 #> d[UNCOVER-2: IXE_Q4W] 2.51 0.08 2.35 2.45 2.51 2.57  2.67     5461     3242 #> d[UNCOVER-2: SEC_150] 2.11 0.12 1.89 2.03 2.11 2.19  2.35     4398     2861 #> d[UNCOVER-2: SEC_300] 2.42 0.12 2.18 2.33 2.42 2.50  2.66     5049     3171 #>                       Rhat #> d[UNCOVER-2: ETN]        1 #> d[UNCOVER-2: IXE_Q2W]    1 #> d[UNCOVER-2: IXE_Q4W]    1 #> d[UNCOVER-2: SEC_150]    1 #> d[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-3: ETN]     1.53 0.08 1.37 1.47 1.53 1.59  1.69     4167     3356 #> d[UNCOVER-3: IXE_Q2W] 2.94 0.09 2.77 2.88 2.94 3.00  3.11     5060     3396 #> d[UNCOVER-3: IXE_Q4W] 2.53 0.08 2.37 2.47 2.53 2.58  2.69     5416     3342 #> d[UNCOVER-3: SEC_150] 2.13 0.11 1.91 2.05 2.13 2.21  2.36     4387     3312 #> d[UNCOVER-3: SEC_300] 2.44 0.12 2.20 2.35 2.43 2.52  2.68     5011     3153 #>                       Rhat #> d[UNCOVER-3: ETN]        1 #> d[UNCOVER-3: IXE_Q2W]    1 #> d[UNCOVER-3: IXE_Q4W]    1 #> d[UNCOVER-3: SEC_150]    1 #> d[UNCOVER-3: SEC_300]    1 #>  plot(pso_releff, ref_line = 0)   # Produce population-adjusted relative effects for a different target # population new_agd_means <- data.frame(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3)  relative_effects(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[New 1: ETN]     1.26 0.22 0.82 1.11 1.25 1.40  1.70     5610     2984    1 #> d[New 1: IXE_Q2W] 2.89 0.22 2.48 2.74 2.89 3.03  3.35     5941     3168    1 #> d[New 1: IXE_Q4W] 2.48 0.22 2.08 2.33 2.47 2.62  2.92     5818     3333    1 #> d[New 1: SEC_150] 2.08 0.22 1.66 1.93 2.07 2.23  2.54     6344     3218    1 #> d[New 1: SEC_300] 2.39 0.23 1.96 2.23 2.38 2.54  2.85     6475     3017    1 #>  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up arm-based aggregate data — set_agd_arm","title":"Set up arm-based aggregate data — set_agd_arm","text":"Set network containing arm-based aggregate data (AgD), event counts mean outcomes arm. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up arm-based aggregate data — set_agd_arm","text":"","code":"set_agd_arm(   data,   study,   trt,   y = NULL,   se = NULL,   r = NULL,   n = NULL,   E = NULL,   sample_size = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up arm-based aggregate data — set_agd_arm","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome se column data specifying standard error continuous outcome r column data specifying binary Binomial outcome count n column data specifying Binomial outcome numerator E column data specifying total time risk Poisson outcomes sample_size column data giving sample size arm. Optional, see details. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up arm-based aggregate data — set_agd_arm","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up arm-based aggregate data — set_agd_arm","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). sample_size argument optional, specified: Enables automatic centering predictors (center = TRUE) nma() regression model given network combining IPD AgD Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Nodes plot.nma_data() may weighted sample size Binomial outcome specified sample_size omitted, n used sample size default. Multinomial outcome specified sample_size omitted, sample size determined automatically supplied counts default. arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up arm-based aggregate data — set_agd_arm","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected   # Plot network plot(smk_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up contrast-based aggregate data — set_agd_contrast","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"Set network containing contrast-based aggregate data (AgD), .e. summaries relative effects treatments log Odds Ratios. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"","code":"set_agd_contrast(   data,   study,   trt,   y = NULL,   se = NULL,   sample_size = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome se column data specifying standard error continuous outcome sample_size column data giving sample size arm. Optional, see details. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"study single reference/baseline treatment, relative effects arm(s) given. reference arm, include data row continuous outcome y equal NA. study three arms (two relative effects), set standard error se reference arm data row equal standard error mean outcome reference arm (determines covariance relative effects, expressed differences mean outcomes arms). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year) default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). sample_size argument optional, specified: Enables automatic centering predictors (center = TRUE) nma() regression model given network combining IPD AgD Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Nodes plot.nma_data() may weighted sample size","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"","code":"# Set up network of Parkinson's contrast data head(parkinsons) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718  park_net <- set_agd_contrast(parkinsons,                              study = studyn,                              trt = trtn,                              y = diff,                              se = se_diff,                              sample_size = n)  # Print details park_net #> A network with 7 AgD studies (contrast-based). #>  #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected  # Plot network plot(park_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up aggregate survival data — set_agd_surv","title":"Set up aggregate survival data — set_agd_surv","text":"Set network containing aggregate survival data (AgD) form event/censoring times (e.g. reconstructed digitized Kaplan-Meier curves) covariate summary statistics study. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up aggregate survival data — set_agd_surv","text":"","code":"set_agd_surv(   data,   study,   trt,   Surv,   covariates = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up aggregate survival data — set_agd_surv","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors Surv column data specifying survival time--event outcome, using Surv() function. Right/left/interval censoring left truncation (delayed entry) supported. covariates data frame covariate summary statistics study study arm, corresponding study trt columns match data trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up aggregate survival data — set_agd_surv","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up aggregate survival data — set_agd_surv","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up aggregate survival data — set_agd_surv","text":"","code":"## Newly diagnosed multiple myeloma  head(ndmm_agd)  # Reconstructed Kaplan-Meier data #>        study     studyf trt trtf eventtime status #> 1 Morgan2012 Morgan2012 Pbo  Pbo  18.72575      1 #> 2 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 3 Morgan2012 Morgan2012 Pbo  Pbo  34.35726      1 #> 4 Morgan2012 Morgan2012 Pbo  Pbo  10.77826      1 #> 5 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 6 Morgan2012 Morgan2012 Pbo  Pbo  14.52966      1 ndmm_agd_covs   # Summary covariate information on each arm #>         study      studyf  trt trtf sample_size  age_min age_iqr_l age_median #> 1 Jackson2019 Jackson2019  Len  Len        1137 17.28246  59.13164   65.76766 #> 2 Jackson2019 Jackson2019  Pbo  Pbo         864 21.18572  58.30991   65.47402 #> 3  Morgan2012  Morgan2012  Pbo  Pbo         410 33.88979  58.05696   64.15999 #> 4  Morgan2012  Morgan2012 Thal Thal         408 38.45127  59.30022   65.48736 #>   age_iqr_h  age_max age_mean   age_sd iss_stage3 response_cr_vgpr      male #> 1  72.00756 85.76095 65.16867 8.936962  0.2480211        0.8258575 0.6165347 #> 2  71.80261 86.23080 64.62894 9.399272  0.1921296        0.8310185 0.6215278 #> 3  70.44791 84.79372 63.92360 9.006311  0.3634146        0.7170732 0.6195122 #> 4  71.73597 84.69365 65.59387 8.384686  0.3186275        0.7450980 0.6151961  set_agd_surv(ndmm_agd,              study = studyf,              trt = trtf,              Surv = Surv(eventtime, status),              covariates = ndmm_agd_covs) #> A network with 2 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study       Treatment arms #>  Jackson2019 2: Pbo | Len   #>  Morgan2012  2: Pbo | Thal  #>  #>  Outcome type: survival #> ------------------------------------------------------------------------------------ #> Total number of treatments: 3 #> Total number of studies: 2 #> Reference treatment is: Pbo #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up individual patient data — set_ipd","title":"Set up individual patient data — set_ipd","text":"Set network containing individual patient data (IPD). Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up individual patient data — set_ipd","text":"","code":"set_ipd(   data,   study,   trt,   y = NULL,   r = NULL,   E = NULL,   Surv = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up individual patient data — set_ipd","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome r column data specifying binary outcome Poisson outcome count E column data specifying total time risk Poisson outcomes Surv column data specifying survival time--event outcome, using Surv() function. Right/left/interval censoring left truncation (delayed entry) supported. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up individual patient data — set_ipd","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up individual patient data — set_ipd","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up individual patient data — set_ipd","text":"","code":"# Set up network of plaque psoriasis IPD head(plaque_psoriasis_ipd) #>    studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  62 38.6    15.8 #> 2 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  38 23.2    28.2 #> 3 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  54 27.5    13.2 #> 4 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  44 24.6    41.0 #> 5 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  44 28.3    15.2 #> 6 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 23.6    30.4 #>    male bsa weight durnpso prevsys   psa #> 1 FALSE  13  111.2       8    TRUE  TRUE #> 2 FALSE  37   62.0       1    TRUE FALSE #> 3  TRUE  13   83.5      38    TRUE FALSE #> 4 FALSE  67   66.0       1    TRUE FALSE #> 5 FALSE  10   92.7      23    TRUE FALSE #> 6 FALSE  75   73.5      21    TRUE FALSE  pso_net <- set_ipd(plaque_psoriasis_ipd,                    study = studyc,                    trt = trtc,                    r = pasi75)  # Print network details pso_net #> A network with 4 IPD studies. #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 4 #> Reference treatment is: IXE_Q2W #> Network is connected  # Plot network plot(pso_net)   # Setting a different reference treatment set_ipd(plaque_psoriasis_ipd,         study = studyc,         trt = trtc,         r = pasi75,         trt_ref = \"PBO\") #> A network with 4 IPD studies. #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":null,"dir":"Reference","previous_headings":"","what":"Smoking cessation data — smoking","title":"Smoking cessation data — smoking","text":"Data frame containing results 24 trials 4 smoking cessation treatments (Hasselblad 1998; Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smoking cessation data — smoking","text":"","code":"smoking"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Smoking cessation data — smoking","text":"data frame 50 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Smoking cessation data — smoking","text":"Dias S, Welton NJ, Sutton AJ, Caldwell DM, Lu G, Ades AE (2011). “NICE DSU Technical Support Document 4: Inconsistency networks evidence based randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Hasselblad V (1998). “Meta-analysis Multitreatment Studies.” Medical Decision Making, 18(1), 37--43. doi:10.1177/0272989x9801800110 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/stan_nma-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The stan_nma class — stan_nma-class","title":"The stan_nma class — stan_nma-class","text":"stan_nma stan_mlnmr classes contains results running model function nma().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/stan_nma-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The stan_nma class — stan_nma-class","text":"Objects class stan_nma stan_mlnmr following components: network network data model run (class nma_data stan_nma, class mlnmr_data stan_mlnmr) stanfit stanfit object returned calling sampling() model trt_effects Whether fixed random effects used (character string) consistency consistency/inconsistency model used (character string) regression regression model used (formula) class_interactions treatment classes regression model specified, model used interactions within class (common, exchangeable, independent) xbar named vector values used centering likelihood likelihood used (character string) link link function used (character string) priors list containing priors used (nma_prior objects) basis mspline pexp models, named list spline bases study stan_mlnmr sub-class inherits stan_nma, differs class network object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":null,"dir":"Reference","previous_headings":"","what":"Statins for cholesterol lowering — statins","title":"Statins for cholesterol lowering — statins","text":"Data frame containing results 19 trials comparing statins placebo usual care (Dias et al. 2011) . number deaths (-cause mortality) recorded. studies aim primary prevention (patients previous heart disease), others aim secondary prevention (patients previous heart disease).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statins for cholesterol lowering — statins","text":"","code":"statins"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Statins for cholesterol lowering — statins","text":"data frame 38 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name prevention primary secondary prevention study r number deaths n sample size","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Statins for cholesterol lowering — statins","text":"Dias S, Sutton AJ, Welton NJ, Ades AE (2011). “NICE DSU Technical Support Document 3: Heterogeneity: subgroups, meta-regression, bias bias-adjustment.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"Posterior summaries node-splitting models (nma_nodesplit nma_nodesplit_df objects) can produced using summary() method, plotted using plot() method.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"","code":"# S3 method for nma_nodesplit_df summary(   object,   consistency = NULL,   ...,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975) )  # S3 method for nma_nodesplit summary(   object,   consistency = NULL,   ...,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975) )  # S3 method for nma_nodesplit plot(x, consistency = NULL, ...)  # S3 method for nma_nodesplit_df plot(x, consistency = NULL, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"consistency Optional, stan_nma object corresponding fitted consistency model, display network estimates alongside direct indirect estimates. fitted consistency model present nma_nodesplit_df object used present (see get_nodesplits()). ... Additional arguments passed methods probs Numeric vector specifying quantiles interest, default c(0.025, 0.25, 0.5, 0.75, 0.975) x, object nma_nodesplit nma_nodesplit_df object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"nodesplit_summary object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"plot() method shortcut plot(summary(nma_nodesplit)). details plotting options, see plot.nodesplit_summary().","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"","code":"# \\donttest{ # Run smoking node-splitting example if not already available if (!exists(\"smk_fit_RE_nodesplit\")) example(\"example_smk_nodesplit\", run.donttest = TRUE) # } # \\donttest{ # Summarise the node-splitting results summary(smk_fit_RE_nodesplit) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.10 0.43  0.26  0.81  1.09 1.38  1.96     2148     2137    1 #> d_dir            1.04 0.75 -0.37  0.54  1.01 1.51  2.59     2543     1931    1 #> d_ind            1.18 0.55  0.12  0.82  1.16 1.53  2.29     1749     2385    1 #> omega           -0.14 0.89 -1.85 -0.73 -0.16 0.43  1.68     2134     2282    1 #> tau              0.87 0.20  0.55  0.73  0.84 0.99  1.35     1152     1760    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82 0.95  1.29     1135     1734    1 #>  #> Residual deviance: 53.9 (on 50 data points) #>                pD: 44 #>               DIC: 97.9 #>  #> Bayesian p-value: 0.86 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.83 0.24  0.38  0.68 0.83 0.98  1.33     1318     1877 1.00 #> d_dir           0.89 0.26  0.41  0.72 0.88 1.05  1.43     1470     2358 1.00 #> d_ind           0.58 0.69 -0.77  0.14 0.57 1.01  1.98     1311     1709 1.00 #> omega           0.31 0.72 -1.15 -0.14 0.32 0.77  1.75     1396     1840 1.00 #> tau             0.85 0.19  0.55  0.71 0.82 0.96  1.29      934     1909 1.01 #> tau_consistency 0.84 0.19  0.54  0.71 0.82 0.95  1.29     1135     1734 1.00 #>  #> Residual deviance: 54.5 (on 50 data points) #>                pD: 44.4 #>               DIC: 98.9 #>  #> Bayesian p-value: 0.63 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.49 0.40 -0.27  0.23  0.48 0.75  1.30     1961     2380    1 #> d_dir            0.35 0.54 -0.70  0.00  0.35 0.69  1.49     3146     1798    1 #> d_ind            0.70 0.63 -0.54  0.29  0.69 1.10  2.00     2377     2626    1 #> omega           -0.35 0.83 -2.04 -0.86 -0.34 0.19  1.19     2302     2600    1 #> tau              0.87 0.19  0.57  0.73  0.85 0.97  1.32     1251     1812    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82 0.95  1.29     1135     1734    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44 #>               DIC: 97.6 #>  #> Bayesian p-value: 0.67 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.27 0.41 -1.10 -0.52 -0.26  0.00  0.53     2693     2005    1 #> d_dir           -0.11 0.48 -1.07 -0.41 -0.11  0.20  0.82     3490     3136    1 #> d_ind           -0.56 0.62 -1.79 -0.95 -0.56 -0.15  0.66     1642     1983    1 #> omega            0.44 0.68 -0.89  0.00  0.43  0.89  1.79     1656     2018    1 #> tau              0.86 0.19  0.56  0.72  0.84  0.96  1.32     1229     1755    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82  0.95  1.29     1135     1734    1 #>  #> Residual deviance: 54.3 (on 50 data points) #>                pD: 44.6 #>               DIC: 98.8 #>  #> Bayesian p-value: 0.5 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.60 0.47 -1.57 -0.91 -0.59 -0.30  0.30     3295     2567    1 #> d_dir           -0.59 0.66 -1.90 -1.02 -0.59 -0.17  0.73     3914     3278    1 #> d_ind           -0.64 0.68 -2.02 -1.07 -0.65 -0.20  0.66     1938     2087    1 #> omega            0.05 0.89 -1.65 -0.54  0.03  0.62  1.88     2089     1983    1 #> tau              0.87 0.20  0.56  0.73  0.84  0.99  1.36     1221     1940    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82  0.95  1.29     1135     1734    1 #>  #> Residual deviance: 53.7 (on 50 data points) #>                pD: 44.1 #>               DIC: 97.8 #>  #> Bayesian p-value: 0.97 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.34 0.41 -1.17 -0.60 -0.34 -0.08  0.46     2214     2651    1 #> d_dir            0.07 0.65 -1.22 -0.36  0.07  0.49  1.36     3658     2981    1 #> d_ind           -0.63 0.53 -1.71 -0.97 -0.62 -0.28  0.39     2161     2530    1 #> omega            0.70 0.81 -0.83  0.17  0.69  1.24  2.33     2519     2547    1 #> tau              0.85 0.19  0.54  0.71  0.82  0.95  1.29     1250     2163    1 #> tau_consistency  0.84 0.19  0.54  0.71  0.82  0.95  1.29     1135     1734    1 #>  #> Residual deviance: 53.8 (on 50 data points) #>                pD: 44 #>               DIC: 97.8 #>  #> Bayesian p-value: 0.38  # Plot the node-splitting results plot(smk_fit_RE_nodesplit)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of prior distributions — summary.nma_prior","title":"Summary of prior distributions — summary.nma_prior","text":"Print summary prior distribution details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of prior distributions — summary.nma_prior","text":"","code":"# S3 method for nma_prior summary(object, ..., probs = c(0.5, 0.95), digits = 2, trunc = NULL)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of prior distributions — summary.nma_prior","text":"object Prior distribution nma_prior object ... Additional arguments, used probs Numeric vector probabilities calculate prior intervals digits Number digits display trunc Optional numeric vector length 2, giving truncation limits prior distribution. Useful real-valued prior assigned positive-valued parameter, trunc = c(0, Inf) give correct prior intervals. default, truncation used.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of prior distributions — summary.nma_prior","text":"data frame returned invisibly, giving prior intervals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of prior distributions — summary.nma_prior","text":"","code":"summary(normal(location = 0, scale = 1)) #> A Normal prior distribution: location = 0, scale = 1. #> 50% of the prior density lies between -0.67 and 0.67. #> 95% of the prior density lies between -1.96 and 1.96. summary(half_normal(scale = 1)) #> A half-Normal prior distribution: location = 0, scale = 1. #> 50% of the prior density lies between 0 and 0.67. #> 95% of the prior density lies between 0 and 1.96. summary(log_normal(location = -3.93, scale = 1.51)) #> A log-Normal prior distribution: location = -3.93, scale = 1.51. #> 50% of the prior density lies between 0.01 and 0.05. #> 95% of the prior density lies between 0 and 0.38.  # Truncation limits may be set, for example to restrict a prior to positive values summary(normal(location = 0.5, scale = 1), trunc = c(0, Inf)) #> A Normal prior distribution: location = 0.5, scale = 1. #> 50% of the prior density lies between 0.45 and 1.44. #> 95% of the prior density lies between 0.05 and 2.61."},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior summaries from stan_nma objects — summary.stan_nma","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"Posterior summaries model parameters stan_nma objects may produced using summary() method plotted plot() method. NOTE: produce relative effects, absolute predictions, posterior ranks, see relative_effects(), predict.stan_nma(), posterior_ranks(), posterior_rank_probs().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"","code":"# S3 method for stan_nma summary(object, ..., pars, include, probs = c(0.025, 0.25, 0.5, 0.75, 0.975))  # S3 method for stan_nma plot(   x,   ...,   pars,   include,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"... Additional arguments passed methods pars, include See rstan::extract() probs Numeric vector specifying quantiles interest, default c(0.025, 0.25, 0.5, 0.75, 0.975) x, object stan_nma object stat Character string specifying ggdist plot stat use, default \"pointinterval\" orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\" ref_line Numeric vector positions reference lines, default reference lines drawn summary Logical, calculate posterior summaries? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"nma_summary object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"plot() method shortcut plot(summary(stan_nma)). details plotting options, see plot.nma_summary().","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Summary and plot of all model parameters summary(smk_fit_RE) #>                                    mean   sd  2.5%   25%   50%   75% 97.5% #> mu[1]                             -2.79 0.32 -3.47 -2.99 -2.77 -2.57 -2.17 #> mu[2]                             -2.56 0.78 -4.18 -3.05 -2.54 -2.07 -1.03 #> mu[3]                             -2.14 0.12 -2.38 -2.22 -2.14 -2.06 -1.92 #> mu[4]                             -4.06 0.58 -5.32 -4.43 -4.03 -3.66 -3.03 #> mu[5]                             -2.15 0.14 -2.43 -2.24 -2.15 -2.06 -1.89 #> mu[6]                             -3.41 0.73 -5.00 -3.84 -3.37 -2.91 -2.11 #> mu[7]                             -3.02 0.45 -4.00 -3.30 -3.00 -2.70 -2.25 #> mu[8]                             -2.73 0.60 -4.00 -3.11 -2.68 -2.32 -1.68 #> mu[9]                             -1.84 0.42 -2.73 -2.11 -1.83 -1.56 -1.07 #> mu[10]                            -2.08 0.12 -2.32 -2.16 -2.08 -2.00 -1.86 #> mu[11]                            -3.62 0.24 -4.13 -3.78 -3.62 -3.46 -3.16 #> mu[12]                            -2.22 0.13 -2.48 -2.30 -2.22 -2.13 -1.97 #> mu[13]                            -2.67 0.44 -3.58 -2.96 -2.66 -2.35 -1.86 #> mu[14]                            -2.41 0.23 -2.87 -2.56 -2.40 -2.25 -1.98 #> mu[15]                            -2.69 0.77 -4.33 -3.16 -2.63 -2.15 -1.39 #> mu[16]                            -2.62 0.35 -3.34 -2.84 -2.60 -2.37 -1.98 #> mu[17]                            -2.38 0.10 -2.58 -2.45 -2.37 -2.30 -2.17 #> mu[18]                            -2.57 0.27 -3.12 -2.74 -2.56 -2.38 -2.07 #> mu[19]                            -1.90 0.12 -2.13 -1.98 -1.90 -1.82 -1.67 #> mu[20]                            -2.80 0.13 -3.05 -2.89 -2.80 -2.72 -2.55 #> mu[21]                            -1.13 0.81 -2.73 -1.67 -1.13 -0.62  0.47 #> mu[22]                            -2.40 0.86 -4.16 -2.95 -2.38 -1.84 -0.72 #> mu[23]                            -2.33 0.85 -4.03 -2.89 -2.32 -1.77 -0.68 #> mu[24]                            -2.83 0.89 -4.61 -3.42 -2.82 -2.25 -1.07 #> d[Group counselling]               1.10 0.44  0.26  0.81  1.09  1.37  1.97 #> d[Individual counselling]          0.85 0.24  0.40  0.68  0.85  1.01  1.34 #> d[Self-help]                       0.50 0.41 -0.30  0.23  0.48  0.76  1.34 #> tau                                0.85 0.19  0.54  0.71  0.82  0.95  1.29 #> delta[1: Individual counselling]   1.07 0.38  0.36  0.82  1.06  1.31  1.87 #> delta[1: Group counselling]        0.37 0.43 -0.49  0.08  0.36  0.65  1.22 #> delta[2: Self-help]                0.65 0.80 -0.95  0.14  0.63  1.16  2.27 #> delta[2: Individual counselling]   0.75 0.79 -0.81  0.25  0.74  1.23  2.38 #> delta[2: Group counselling]        0.98 0.79 -0.57  0.49  0.97  1.48  2.58 #> delta[3: Individual counselling]   2.16 0.14  1.90  2.07  2.16  2.26  2.44 #> delta[4: Individual counselling]   0.92 0.60 -0.24  0.50  0.91  1.31  2.12 #> delta[5: Individual counselling]   0.44 0.15  0.14  0.33  0.43  0.54  0.74 #> delta[6: Individual counselling]   1.71 0.72  0.44  1.21  1.67  2.15  3.26 #> delta[7: Individual counselling]   2.15 0.49  1.27  1.82  2.12  2.46  3.20 #> delta[8: Individual counselling]   1.67 0.61  0.61  1.25  1.63  2.06  2.98 #> delta[9: Individual counselling]   0.59 0.46 -0.32  0.29  0.59  0.89  1.54 #> delta[10: Self-help]               0.01 0.17 -0.33 -0.10  0.01  0.12  0.33 #> delta[11: Self-help]               0.42 0.32 -0.22  0.21  0.41  0.63  1.03 #> delta[12: Individual counselling]  0.41 0.17  0.09  0.30  0.41  0.52  0.74 #> delta[13: Individual counselling]  0.38 0.51 -0.60  0.03  0.38  0.72  1.39 #> delta[14: Individual counselling]  0.63 0.29  0.07  0.44  0.62  0.81  1.20 #> delta[15: Group counselling]       2.15 0.79  0.77  1.60  2.10  2.62  3.86 #> delta[16: Self-help]               0.65 0.41 -0.08  0.37  0.64  0.92  1.47 #> delta[17: Individual counselling]  0.55 0.13  0.29  0.46  0.55  0.64  0.81 #> delta[18: Individual counselling]  0.03 0.31 -0.57 -0.18  0.03  0.23  0.65 #> delta[19: Individual counselling] -0.19 0.17 -0.54 -0.30 -0.19 -0.08  0.13 #> delta[20: Individual counselling]  0.08 0.18 -0.28 -0.05  0.07  0.20  0.44 #> delta[21: Self-help]               0.70 0.81 -0.91  0.18  0.70  1.24  2.29 #> delta[21: Individual counselling]  0.67 0.80 -0.98  0.16  0.69  1.19  2.17 #> delta[22: Self-help]               0.31 0.87 -1.44 -0.24  0.31  0.86  2.09 #> delta[22: Group counselling]       1.27 0.86 -0.43  0.72  1.28  1.83  3.01 #> delta[23: Individual counselling]  0.68 0.83 -0.94  0.15  0.68  1.22  2.34 #> delta[23: Group counselling]       1.28 0.84 -0.35  0.73  1.29  1.83  3.05 #> delta[24: Individual counselling]  1.07 0.87 -0.61  0.49  1.05  1.62  2.82 #> delta[24: Group counselling]       0.91 0.88 -0.79  0.33  0.89  1.48  2.70 #>                                   Bulk_ESS Tail_ESS Rhat #> mu[1]                                 5068     3240    1 #> mu[2]                                 2353     2353    1 #> mu[3]                                 8329     2837    1 #> mu[4]                                 4743     2492    1 #> mu[5]                                 8314     2957    1 #> mu[6]                                 3435     2611    1 #> mu[7]                                 4212     2555    1 #> mu[8]                                 2768     1636    1 #> mu[9]                                 4942     2609    1 #> mu[10]                                8019     2541    1 #> mu[11]                                7614     2918    1 #> mu[12]                                7791     2892    1 #> mu[13]                                5359     2840    1 #> mu[14]                                6296     2917    1 #> mu[15]                                2911     2364    1 #> mu[16]                                5582     2651    1 #> mu[17]                                7568     2843    1 #> mu[18]                                6718     3039    1 #> mu[19]                                8220     2919    1 #> mu[20]                                8570     2682    1 #> mu[21]                                2568     2522    1 #> mu[22]                                2319     2269    1 #> mu[23]                                2274     2337    1 #> mu[24]                                2803     2553    1 #> d[Group counselling]                  1889     2027    1 #> d[Individual counselling]             1052     1684    1 #> d[Self-help]                          1466     1962    1 #> tau                                   1153     1486    1 #> delta[1: Individual counselling]      4343     3293    1 #> delta[1: Group counselling]           4637     3338    1 #> delta[2: Self-help]                   2440     2449    1 #> delta[2: Individual counselling]      2436     2341    1 #> delta[2: Group counselling]           2485     2331    1 #> delta[3: Individual counselling]      6584     3323    1 #> delta[4: Individual counselling]      4677     2590    1 #> delta[5: Individual counselling]      7213     2894    1 #> delta[6: Individual counselling]      2963     2481    1 #> delta[7: Individual counselling]      4070     2768    1 #> delta[8: Individual counselling]      2425     1390    1 #> delta[9: Individual counselling]      4777     2967    1 #> delta[10: Self-help]                  5760     2833    1 #> delta[11: Self-help]                  5458     3437    1 #> delta[12: Individual counselling]     5767     3123    1 #> delta[13: Individual counselling]     4762     2981    1 #> delta[14: Individual counselling]     5560     3571    1 #> delta[15: Group counselling]          2685     1966    1 #> delta[16: Self-help]                  5055     2839    1 #> delta[17: Individual counselling]     5833     3685    1 #> delta[18: Individual counselling]     6086     3131    1 #> delta[19: Individual counselling]     5731     3610    1 #> delta[20: Individual counselling]     5549     3232    1 #> delta[21: Self-help]                  2596     2534    1 #> delta[21: Individual counselling]     2665     2477    1 #> delta[22: Self-help]                  2356     2688    1 #> delta[22: Group counselling]          2338     2428    1 #> delta[23: Individual counselling]     2091     1821    1 #> delta[23: Group counselling]          2230     2329    1 #> delta[24: Individual counselling]     2677     2418    1 #> delta[24: Group counselling]          2871     2382    1 plot(smk_fit_RE)   # Summary and plot of heterogeneity tau only summary(smk_fit_RE, pars = \"tau\") #>     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau 0.85 0.19 0.54 0.71 0.82 0.95  1.29     1153     1486    1 plot(smk_fit_RE, pars = \"tau\")   # Customising plot output plot(smk_fit_RE,      pars = c(\"d\", \"tau\"),      stat = \"halfeye\",      ref_line = 0)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot theme for multinma plots — theme_multinma","title":"Plot theme for multinma plots — theme_multinma","text":"simple ggplot2 theme plots multinma package.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot theme for multinma plots — theme_multinma","text":"","code":"theme_multinma(...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot theme for multinma plots — theme_multinma","text":"... Arguments passed ggplot2::theme_light()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot theme for multinma plots — theme_multinma","text":"ggplot2 theme","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot theme for multinma plots — theme_multinma","text":"","code":"library(ggplot2) theme_set(theme_multinma())"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":null,"dir":"Reference","previous_headings":"","what":"Thrombolytic treatments data — thrombolytics","title":"Thrombolytic treatments data — thrombolytics","text":"Data frame containing results 50 trials 8 thrombolytic drugs (streptokinase, SK; alteplase, t-PA; accelerated alteplase, Acc t-PA; streptokinase plus alteplase, SK+tPA; reteplase, r-PA; tenocteplase, TNK; urokinase, UK; anistreptilase, ASPAC) plus per-cutaneous transluminal coronary angioplasty (PTCA) (Boland et al. 2003; Lu Ades 2006; Dias et al. 2011) . number deaths 30 35 days following acute myocardial infarction recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Thrombolytic treatments data — thrombolytics","text":"","code":"thrombolytics"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Thrombolytic treatments data — thrombolytics","text":"data frame 102 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Thrombolytic treatments data — thrombolytics","text":"Boland , Dundar Y, Bagust , Haycox , Hill R, Mota RM, Walley T, Dickson R (2003). “Early thrombolysis treatment acute myocardial infarction: systematic review economic evaluation.” Health Technology Assessment, 7(15). doi:10.3310/hta7150 . Dias S, Welton NJ, Sutton AJ, Caldwell DM, Lu G, Ades AE (2011). “NICE DSU Technical Support Document 4: Inconsistency networks evidence based randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Lu GB, Ades AE (2006). “Assessing evidence inconsistency mixed treatment comparisons.” Journal American Statistical Association, 101(474), 447--459. doi:10.1198/016214505000001302 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":null,"dir":"Reference","previous_headings":"","what":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"Data frame containing number deaths 6 trials comparing transfusion granulocytes (white blood cells) control (Stanworth et al. 2005) . Previously used demonstrate informative prior distributions heterogeneity variance Turner et al. (2012) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"","code":"transfusion"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"data frame 12 rows 4 variables: studyc study name trtc treatment name r total number deaths n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"Stanworth S, Massey E, Hyde C, Brunskill SJ, Navarette C, Lucas G, Marks D, Paulus U (2005). “Granulocyte transfusions treating infections patients neutropenia neutrophil dysfunction.” Cochrane Database Systematic Reviews. ISSN 1465-1858, doi:10.1002/14651858.CD005339 . Turner RM, Davey J, Clarke MJ, Thompson SG, Higgins JPT (2012). “Predicting extent heterogeneity meta-analysis, using empirical data Cochrane Database Systematic Reviews.” International Journal Epidemiology, 41(3), 818--827. doi:10.1093/ije/dys041 .","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"feature-survivaltime-to-event-models-are-now-supported-0-5-1-9000","dir":"Changelog","previous_headings":"","what":"Feature: Survival/time-to-event models are now supported","title":"multinma 0.5.1.9000","text":"set_ipd() now Surv argument specifying survival outcomes using survival::Surv(), new function set_agd_surv() sets aggregate data form event/censoring times (e.g. digitized Kaplan-Meier curves) overall covariate summaries. Left, right, interval censoring well left truncation (delayed entry) supported. available likelihoods Exponential (PH AFT forms), Weibull (PH AFT forms), Gompertz, log-Normal, log-Logistic, Gamma, Generalised Gamma, flexible M-splines baseline hazard, piecewise exponential hazards. Auxiliary parameters (e.g. shapes, spline coefficients) always stratified study respect randomisation, may stratified treatment (e.g. relax proportional hazards assumption) /additional factors using aux_by argument nma(). predict() method produces estimates survival probabilities, hazards, cumulative hazards, mean survival times, restricted mean survival times, quantiles survival time distribution, median survival times. predictions can plotted using plot() method. new vignette demonstrates ML-NMR survival analysis example progression-free survival autologous stem cell transplant newly diagnosed multiple myeloma, corresponding datasets ndmm_ipd, ndmm_agd, ndmm_agd_covs.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"feature-automatic-checking-of-numerical-integration-for-ml-nmr-models-0-5-1-9000","dir":"Changelog","previous_headings":"","what":"Feature: Automatic checking of numerical integration for ML-NMR models","title":"multinma 0.5.1.9000","text":"accuracy numerical integration ML-NMR models can now checked automatically, default. , half chains run n_int half n_int/2 integration points. Rhat effective sample size warnings can ascribed either: non-convergence MCMC chains, requiring increased number iterations iter nma(), ; insufficient accuracy numerical integration, requiring increased number integration points n_int add_integration(). Descriptive warning messages indicate case. feature controlled new int_check argument nma(), enabled (TRUE) default. Saving thinned cumulative integration points can now disabled int_thin = 0, now disabled default. previous default int_thin = max(n_int %/% 10, 1). can now check sufficient accuracy automatically, default number integration points n_int add_integration() lowered 64. still conservative choice, sufficient many cases; previous default 1000 excessive. result, ML-NMR models now much faster run default, due lower n_int disabling saving cumulative integration points.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"other-updates-0-5-1-9000","dir":"Changelog","previous_headings":"","what":"Other updates","title":"multinma 0.5.1.9000","text":"Feature: dic() now includes option use pV penalty instead pD. Feature: baseline aux arguments predict() can now specified name study network, use parameter estimates study prediction. Improvement: predict() now produce aggregate-level predictions sample individuals newdata ML-NMR models (previously newdata include integration points). Fix: plot.nma_data(), using custom layout string (e.g.  data frame layout coordinates) now works expected nudge > 0.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-051","dir":"Changelog","previous_headings":"","what":"multinma 0.5.1","title":"multinma 0.5.1","text":"CRAN release: 2023-05-24 Fix: Now compatible latest StanHeaders v2.26.25 (fixes #23) Fix: Dealt various tidyverse deprecations Fix: Updated TSD URLs (thanks @ndunnewind)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-050","dir":"Changelog","previous_headings":"","what":"multinma 0.5.0","title":"multinma 0.5.0","text":"CRAN release: 2022-08-29 Feature: Treatment labels network plots can now nudged away nodes weight_nodes = TRUE, using new nudge argument plot.nma_data() (#15). Feature: data frame returned calling as_tibble() .data.frame() nma_summary object (relative effects predictions) now includes columns corresponding treatment (.trt) contrast (.trta .trtb), .category column may included multinomial models. Previously details present part parameter column Feature: Added log t prior distribution log_student_t(), can used positive-valued parameters (e.g. heterogeneity variance). Improvement: set_agd_contrast() now produces informative error message covariance matrix implied se column positive definite. Previously checked Stan calling nma() function. Improvement: Updated plaque psoriasis ML-NMR vignette include new analyses, including assessing assumptions population adjustment synthesising multinomial outcomes. Improvement: Improved behaviour .trtclass special regression formulas, now main effects .trtclass always removed since collinear .trt. allows expansion interactions * work properly, e.g. ~variable*.trtclass, whereas previously resulted -parametrised model. Fix: CRAN check note manual HTML5 compatibility. Fix: Residual deviance log likelihood parameters now named correctly contrast-based aggregate data present (PR #19).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-042","dir":"Changelog","previous_headings":"","what":"multinma 0.4.2","title":"multinma 0.4.2","text":"CRAN release: 2022-03-02 Fix: Error get_nodesplits() studies multiple arms treatment. Fix: print.nma_data() now prints repeated arms studies multiple arms treatment. Fix: CRAN warning regarding invalid img tag height attribute documentation.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-041","dir":"Changelog","previous_headings":"","what":"multinma 0.4.1","title":"multinma 0.4.1","text":"CRAN release: 2022-02-04 Fix: tidyr v1.2.0 breaks ordered multinomial models studies report categories (.e. multinomial category outcomes NA multi()) (PR #11)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-040","dir":"Changelog","previous_headings":"","what":"multinma 0.4.0","title":"multinma 0.4.0","text":"CRAN release: 2022-01-18 Feature: Node-splitting models assessing inconsistency now available consistency = \"nodesplit\" nma(). Comparisons split can chosen using nodesplit argument, default possibly inconsistent comparisons chosen using get_nodesplits(). Node-splitting results can summarised summary.nma_nodesplit() plotted plot.nodesplit_summary(). Feature: correlation matrix generating integration points add_integration() ML-NMR models now adjusted underlying Gaussian copula, output correlations integration points better match requested input correlations. new argument cor_adjust controls behaviour, options \"spearman\", \"pearson\", \"none\". Although correlations typically little impact results, strict reproducibility old behaviour version 0.3.0 available cor_adjust = \"legacy\". Feature: random effects models, predictive distribution relative/absolute effects new study can now obtained relative_effects() predict.stan_nma() respectively, using new argument predictive_distribution = TRUE. Feature: Added option calculate SUCRA values summarising posterior treatment ranks posterior_ranks() posterior_rank_probs(), argument sucra = TRUE. Improvement: Factor order now respected trt, study, trt_class factors, previously order levels reset natural sort order. Improvement: Update package website Bootstrap 5 release pkgdown 2.0.0 Fix: Model fitting now robust non-default settings options(\"contrasts\"). Fix: plot.nma_data() longer gives ggplot deprecation warning (PR #6). Fix: Bug predict.stan_nma() single covariate newdata data.frame (PR #7). Fix: Attempting call predict.stan_nma() regression model contrast data newdata baseline specified now throws descriptive error message.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-030","dir":"Changelog","previous_headings":"","what":"multinma 0.3.0","title":"multinma 0.3.0","text":"CRAN release: 2021-03-18 Feature: Added baseline_type baseline_level arguments predict.stan_nma(), allow baseline distributions specified response linear predictor scale, individual aggregate level. Feature: baseline argument predict.stan_nma() can now accept (named) list baseline distributions newdata contains multiple studies. Improvement: Misspecified newdata arguments functions like relative_effects() predict.stan_nma() now give informative error messages. Fix: Constructing models contrast-based data previously gave errors scenarios (ML-NMR models, UME models, cases AgD meta-regression models). Fix: Ensure CRAN additional checks --run-donttest run correctly.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-021","dir":"Changelog","previous_headings":"","what":"multinma 0.2.1","title":"multinma 0.2.1","text":"CRAN release: 2021-01-09 Fix: Producing relative effect estimates contrasts using relative_effects() all_contrasts = TRUE longer gives error regression models. Fix: Specifying covariate correlation matrix cor add_integration() required one covariate present. Improvement: Added detailed documentation likelihoods link functions available data type (likelihood link arguments nma()).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-020","dir":"Changelog","previous_headings":"","what":"multinma 0.2.0","title":"multinma 0.2.0","text":"CRAN release: 2020-12-04 Feature: set_*() functions now accept dplyr::mutate() style semantics, allowing inline variable transformations. Feature: Added ordered multinomial models, helper function multi() specifying outcomes. Accompanied new data set hta_psoriasis vignette. Feature: Implicit flat priors can now specified, parameter, using flat(). Improvement: .array.stan_nma() now much efficient, meaning many post-estimation functions also now much efficient. Improvement: plot.nma_dic() now efficient, particularly large numbers data points. Improvement: layering points producing “dev-dev” plots using plot.nma_dic() multiple data types reversed improved clarity (now AgD top IPD). Improvement: Aggregate-level predictions predict() ML-NMR / IPD regression models now calculated much memory-efficient manner. Improvement: Added overview examples given vignettes. Improvement: Network plots weight_edges = TRUE longer produce legends non-integer values number studies. Fix: plot.nma_dic() longer gives error attempting specify .width argument producing “dev-dev” plots.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-013","dir":"Changelog","previous_headings":"","what":"multinma 0.1.3","title":"multinma 0.1.3","text":"CRAN release: 2020-06-30 Format DESCRIPTION CRAN requirements","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-012","dir":"Changelog","previous_headings":"","what":"multinma 0.1.2","title":"multinma 0.1.2","text":"Wrapped long-running examples \\donttest{} instead \\dontrun{}","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-011","dir":"Changelog","previous_headings":"","what":"multinma 0.1.1","title":"multinma 0.1.1","text":"Reduced size vignettes Added methods paper reference DESCRIPTION Added zenodo DOI","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-010","dir":"Changelog","previous_headings":"","what":"multinma 0.1.0","title":"multinma 0.1.0","text":"Feature: Network plots, using plot() method nma_data objects. Feature: .igraph(), as_tbl_graph() methods nma_data objects. Feature: Produce relative effect estimates relative_effects(), posterior ranks posterior_ranks(), posterior rank probabilities posterior_rank_probs(). study-specific regression model given. Feature: Produce predictions absolute effects predict() method stan_nma objects. Feature: Plots relative effects, ranks, predictions, parameter estimates via plot.nma_summary(). Enables centering predictors (center = TRUE) nma() regression model given, replacing agd_sample_size argument nma() Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Allows nodes network plots weighted sample size Feature: Plots residual deviance contributions model “dev-dev” plots comparing residual deviance contributions two models, using plot() method nma_dic objects produced dic(). Feature: Complementary log-log (cloglog) link function link = \"cloglog\" binomial likelihoods. Feature: Option specify priors heterogeneity standard deviation, variance, precision, argument prior_het_type. Feature: Added log-Normal prior distribution. Feature: Plots prior distributions vs. posterior distributions plot_prior_posterior(). Feature: Pairs plot method pairs(). Feature: Added vignettes example analyses NICE TSDs . Fix: Random effects models even moderate numbers studies slow. now run much quickly, using sparse representation RE correlation matrix automatically enabled sparsity 90% (roughly equivalent 10 studies).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-001","dir":"Changelog","previous_headings":"","what":"multinma 0.0.1","title":"multinma 0.0.1","text":"Initial release.","code":""}]
