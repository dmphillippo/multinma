[{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Atrial fibrillation","text":"Whilst data patient-years risk study (E), ignore follow analysis Cooper et al. (2009), instead analysing number patients stroke (r) total (n) arm. use function set_agd_arm() set network, making sure specify treatment classes trt_class. remove WASPO study network arms zero events, study therefore contributes information. (better analysis, accounting differences patient-years risk studies, can performed specifying rate outcome r E set_agd_arm() . following code remains identical.) Plot network plot() method:","code":"af_net <- set_agd_arm(atrial_fibrillation[atrial_fibrillation$studyc != \"WASPO\", ],                        study = studyc,                       trt = trtc,                       r = r,                        n = n,                       trt_class = trt_class) af_net #> A network with 25 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                                                  #>  ACTIVE-W      2: Standard adjusted dose anti-coagulant | Low dose aspirin + copidogrel        #>  AFASAK 1      3: Standard adjusted dose anti-coagulant | Low dose aspirin | Placebo/Standa... #>  AFASAK 2      4: Standard adjusted dose anti-coagulant | Fixed dose warfarin | Fixed dose ... #>  BAATAF        2: Low adjusted dose anti-coagulant | Placebo/Standard care                     #>  BAFTA         2: Standard adjusted dose anti-coagulant | Low dose aspirin                     #>  CAFA          2: Standard adjusted dose anti-coagulant | Placebo/Standard care                #>  Chinese ATAFS 2: Standard adjusted dose anti-coagulant | Low dose aspirin                     #>  EAFT          3: Standard adjusted dose anti-coagulant | Medium dose aspirin | Placebo/Sta... #>  ESPS 2        4: Dipyridamole | Low dose aspirin | Low dose aspirin + dipyridamole | Place... #>  JAST          2: Low dose aspirin | Placebo/Standard care                                     #>  ... plus 15 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 17, in 4 classes #> Total number of studies: 25 #> Reference treatment is: Standard adjusted dose anti-coagulant #> Network is connected plot(af_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE) +    ggplot2::theme(legend.position = \"bottom\", legend.box = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Atrial fibrillation","text":"fit two (random effects) models: standard NMA model without covariates (model 1 Cooper et al. (2009)); meta-regression model adjusting proportion individuals study prior stroke, shared interaction coefficients treatment class (model 4b Cooper et al. (2009)).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"nma-with-no-covariates","dir":"Articles","previous_headings":"Meta-analysis models","what":"NMA with no covariates","title":"Example: Atrial fibrillation","text":"fit random effects model using nma() function trt_effects = \"random\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting model nma() function. increase target acceptance rate adapt_delta = 0.99 minimise divergent transition warnings. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  can compute relative effects placebo/standard care relative_effects() function trt_ref argument: estimates can easily plotted plot() method:  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. af_fit_1 <- nma(af_net,                  trt_effects = \"random\",                 prior_intercept = normal(scale = 100),                 prior_trt = normal(scale = 100),                 prior_het = half_normal(scale = 5),                 adapt_delta = 0.99) #> Note: Setting \"Standard adjusted dose anti-coagulant\" as the network reference treatment. af_fit_1 #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                  mean se_mean   sd     2.5%      25%      50% #> d[Acenocoumarol]                                -0.78    0.01 0.83    -2.48    -1.31    -0.75 #> d[Alternate day aspirin]                        -0.98    0.02 1.35    -4.12    -1.70    -0.82 #> d[Dipyridamole]                                  0.60    0.01 0.44    -0.30     0.32     0.60 #> d[Fixed dose warfarin]                           0.93    0.01 0.40     0.12     0.67     0.94 #> d[Fixed dose warfarin + low dose aspirin]        0.49    0.01 0.44    -0.42     0.22     0.49 #> d[Fixed dose warfarin + medium dose aspirin]     0.89    0.01 0.32     0.23     0.69     0.90 #> d[High dose aspirin]                             0.53    0.01 0.77    -1.04     0.03     0.54 #> d[Indobufen]                                     0.24    0.01 0.44    -0.62    -0.03     0.24 #> d[Low adjusted dose anti-coagulant]             -0.29    0.01 0.38    -1.02    -0.55    -0.30 #> d[Low dose aspirin]                              0.62    0.01 0.22     0.18     0.48     0.63 #> d[Low dose aspirin + copidogrel]                 0.51    0.01 0.34    -0.20     0.31     0.52 #> d[Low dose aspirin + dipyridamole]               0.27    0.01 0.46    -0.63    -0.02     0.27 #> d[Medium dose aspirin]                           0.39    0.00 0.20    -0.01     0.26     0.40 #> d[Placebo/Standard care]                         0.76    0.00 0.20     0.38     0.64     0.76 #> d[Triflusal]                                     0.64    0.01 0.63    -0.54     0.22     0.63 #> d[Ximelagatran]                                 -0.09    0.00 0.26    -0.61    -0.25    -0.08 #> lp__                                         -5000.74    0.23 7.21 -5015.58 -5005.34 -5000.40 #> tau                                              0.28    0.01 0.14     0.03     0.18     0.27 #>                                                   75%    97.5% n_eff Rhat #> d[Acenocoumarol]                                -0.22     0.81  3946 1.00 #> d[Alternate day aspirin]                        -0.03     1.20  3968 1.00 #> d[Dipyridamole]                                  0.89     1.51  3105 1.00 #> d[Fixed dose warfarin]                           1.20     1.72  3221 1.00 #> d[Fixed dose warfarin + low dose aspirin]        0.79     1.34  2643 1.00 #> d[Fixed dose warfarin + medium dose aspirin]     1.09     1.50  2492 1.00 #> d[High dose aspirin]                             1.05     2.04  4819 1.00 #> d[Indobufen]                                     0.52     1.15  4004 1.00 #> d[Low adjusted dose anti-coagulant]             -0.04     0.44  2853 1.00 #> d[Low dose aspirin]                              0.77     1.07  1903 1.00 #> d[Low dose aspirin + copidogrel]                 0.71     1.22  3089 1.00 #> d[Low dose aspirin + dipyridamole]               0.58     1.17  3034 1.00 #> d[Medium dose aspirin]                           0.52     0.76  2479 1.00 #> d[Placebo/Standard care]                         0.89     1.14  1601 1.00 #> d[Triflusal]                                     1.03     1.95  3413 1.00 #> d[Ximelagatran]                                  0.07     0.45  3680 1.00 #> lp__                                         -4995.68 -4987.55   962 1.00 #> tau                                              0.36     0.56   705 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:31:52 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(af_fit_1, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(af_fit_1, prior = c(\"trt\", \"het\")) (af_1_releff <- relative_effects(af_fit_1, trt_ref = \"Placebo/Standard care\")) #>                                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> d[Standard adjusted dose anti-coagulant]     -0.76 0.20 -1.14 -0.89 -0.76 -0.64 -0.38     1635 #> d[Acenocoumarol]                             -1.54 0.85 -3.29 -2.10 -1.52 -0.96  0.06     3642 #> d[Alternate day aspirin]                     -1.74 1.34 -4.94 -2.44 -1.57 -0.81  0.42     4991 #> d[Dipyridamole]                              -0.16 0.42 -0.98 -0.43 -0.17  0.11  0.65     5029 #> d[Fixed dose warfarin]                        0.17 0.43 -0.71 -0.11  0.17  0.46  1.02     3048 #> d[Fixed dose warfarin + low dose aspirin]    -0.27 0.40 -1.08 -0.51 -0.27 -0.02  0.51     4301 #> d[Fixed dose warfarin + medium dose aspirin]  0.13 0.36 -0.64 -0.10  0.14  0.37  0.82     2655 #> d[High dose aspirin]                         -0.23 0.76 -1.77 -0.73 -0.21  0.27  1.25     5735 #> d[Indobufen]                                 -0.52 0.49 -1.49 -0.83 -0.52 -0.21  0.46     3173 #> d[Low adjusted dose anti-coagulant]          -1.06 0.35 -1.73 -1.29 -1.06 -0.83 -0.39     5144 #> d[Low dose aspirin]                          -0.14 0.21 -0.56 -0.27 -0.14  0.00  0.27     4961 #> d[Low dose aspirin + copidogrel]             -0.25 0.40 -1.06 -0.49 -0.25  0.00  0.54     2532 #> d[Low dose aspirin + dipyridamole]           -0.49 0.44 -1.35 -0.77 -0.49 -0.21  0.37     4736 #> d[Medium dose aspirin]                       -0.37 0.22 -0.82 -0.51 -0.37 -0.23  0.05     2720 #> d[Triflusal]                                 -0.12 0.66 -1.40 -0.56 -0.13  0.30  1.21     3080 #> d[Ximelagatran]                              -0.85 0.33 -1.50 -1.06 -0.85 -0.64 -0.19     2862 #>                                              Tail_ESS Rhat #> d[Standard adjusted dose anti-coagulant]         2170    1 #> d[Acenocoumarol]                                 3217    1 #> d[Alternate day aspirin]                         2495    1 #> d[Dipyridamole]                                  2896    1 #> d[Fixed dose warfarin]                           2779    1 #> d[Fixed dose warfarin + low dose aspirin]        2738    1 #> d[Fixed dose warfarin + medium dose aspirin]     2306    1 #> d[High dose aspirin]                             3074    1 #> d[Indobufen]                                     2454    1 #> d[Low adjusted dose anti-coagulant]              3161    1 #> d[Low dose aspirin]                              2702    1 #> d[Low dose aspirin + copidogrel]                 2383    1 #> d[Low dose aspirin + dipyridamole]               3067    1 #> d[Medium dose aspirin]                           2704    1 #> d[Triflusal]                                     2869    1 #> d[Ximelagatran]                                  2279    1 plot(af_1_releff, ref_line = 0) (af_1_ranks <- posterior_ranks(af_fit_1)) #>                                                  mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS #> rank[Standard adjusted dose anti-coagulant]      5.27 1.45    3   4   5   6     8     2533 #> rank[Acenocoumarol]                              3.05 3.13    1   1   2   3    13     3646 #> rank[Alternate day aspirin]                      3.75 4.24    1   1   2   5    16     5001 #> rank[Dipyridamole]                              11.30 3.77    4   9  11  15    17     4497 #> rank[Fixed dose warfarin]                       14.13 3.04    6  12  15  16    17     3439 #> rank[Fixed dose warfarin + low dose aspirin]    10.25 3.80    3   8  10  13    17     3824 #> rank[Fixed dose warfarin + medium dose aspirin] 14.10 2.66    8  13  15  16    17     2354 #> rank[High dose aspirin]                         10.37 5.28    1   6  11  16    17     5236 #> rank[Indobufen]                                  7.98 3.92    2   5   8  10    16     3993 #> rank[Low adjusted dose anti-coagulant]           3.71 2.13    1   2   3   5     9     3643 #> rank[Low dose aspirin]                          11.76 2.25    7  10  12  13    16     3975 #> rank[Low dose aspirin + copidogrel]             10.50 3.41    4   8  10  13    17     3110 #> rank[Low dose aspirin + dipyridamole]            8.17 3.84    2   5   8  11    16     4103 #> rank[Medium dose aspirin]                        9.16 2.10    5   8   9  11    13     3717 #> rank[Placebo/Standard care]                     13.42 1.78   10  12  14  15    16     3565 #> rank[Triflusal]                                 11.28 4.65    3   7  12  16    17     3367 #> rank[Ximelagatran]                               4.82 2.25    2   3   4   6    10     2913 #>                                                 Tail_ESS Rhat #> rank[Standard adjusted dose anti-coagulant]         2697    1 #> rank[Acenocoumarol]                                 3409    1 #> rank[Alternate day aspirin]                         4048    1 #> rank[Dipyridamole]                                    NA    1 #> rank[Fixed dose warfarin]                             NA    1 #> rank[Fixed dose warfarin + low dose aspirin]        2831    1 #> rank[Fixed dose warfarin + medium dose aspirin]       NA    1 #> rank[High dose aspirin]                               NA    1 #> rank[Indobufen]                                     3258    1 #> rank[Low adjusted dose anti-coagulant]              2778    1 #> rank[Low dose aspirin]                              3209    1 #> rank[Low dose aspirin + copidogrel]                 2867    1 #> rank[Low dose aspirin + dipyridamole]               3349    1 #> rank[Medium dose aspirin]                           3154    1 #> rank[Placebo/Standard care]                         3380    1 #> rank[Triflusal]                                       NA    1 #> rank[Ximelagatran]                                  2821    1 plot(af_1_ranks) (af_1_rankprobs <- posterior_rank_probs(af_fit_1)) #>                                              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[Standard adjusted dose anti-coagulant]          0.00      0.02      0.08      0.20      0.29 #> d[Acenocoumarol]                                  0.38      0.29      0.10      0.05      0.04 #> d[Alternate day aspirin]                          0.46      0.18      0.07      0.04      0.04 #> d[Dipyridamole]                                   0.00      0.01      0.02      0.02      0.03 #> d[Fixed dose warfarin]                            0.00      0.00      0.00      0.01      0.01 #> d[Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.02      0.04      0.04 #> d[Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00      0.00      0.00 #> d[High dose aspirin]                              0.03      0.06      0.05      0.06      0.04 #> d[Indobufen]                                      0.01      0.04      0.07      0.08      0.09 #> d[Low adjusted dose anti-coagulant]               0.08      0.23      0.27      0.15      0.09 #> d[Low dose aspirin]                               0.00      0.00      0.00      0.00      0.00 #> d[Low dose aspirin + copidogrel]                  0.00      0.01      0.01      0.02      0.03 #> d[Low dose aspirin + dipyridamole]                0.01      0.04      0.07      0.08      0.08 #> d[Medium dose aspirin]                            0.00      0.00      0.00      0.01      0.02 #> d[Placebo/Standard care]                          0.00      0.00      0.00      0.00      0.00 #> d[Triflusal]                                      0.00      0.02      0.05      0.04      0.04 #> d[Ximelagatran]                                   0.02      0.10      0.18      0.21      0.17 #>                                              p_rank[6] p_rank[7] p_rank[8] p_rank[9] #> d[Standard adjusted dose anti-coagulant]          0.23      0.12      0.05      0.01 #> d[Acenocoumarol]                                  0.03      0.02      0.02      0.01 #> d[Alternate day aspirin]                          0.03      0.03      0.03      0.02 #> d[Dipyridamole]                                   0.04      0.06      0.07      0.08 #> d[Fixed dose warfarin]                            0.01      0.02      0.02      0.03 #> d[Fixed dose warfarin + low dose aspirin]         0.06      0.07      0.09      0.10 #> d[Fixed dose warfarin + medium dose aspirin]      0.01      0.01      0.02      0.03 #> d[High dose aspirin]                              0.05      0.06      0.05      0.05 #> d[Indobufen]                                      0.09      0.10      0.10      0.09 #> d[Low adjusted dose anti-coagulant]               0.07      0.05      0.02      0.01 #> d[Low dose aspirin]                               0.01      0.02      0.05      0.08 #> d[Low dose aspirin + copidogrel]                  0.05      0.09      0.09      0.11 #> d[Low dose aspirin + dipyridamole]                0.10      0.10      0.10      0.08 #> d[Medium dose aspirin]                            0.06      0.12      0.17      0.20 #> d[Placebo/Standard care]                          0.00      0.00      0.01      0.01 #> d[Triflusal]                                      0.05      0.06      0.06      0.06 #> d[Ximelagatran]                                   0.12      0.08      0.05      0.02 #>                                              p_rank[10] p_rank[11] p_rank[12] p_rank[13] #> d[Standard adjusted dose anti-coagulant]           0.00       0.00       0.00       0.00 #> d[Acenocoumarol]                                   0.01       0.01       0.01       0.01 #> d[Alternate day aspirin]                           0.02       0.02       0.01       0.01 #> d[Dipyridamole]                                    0.08       0.09       0.08       0.08 #> d[Fixed dose warfarin]                             0.04       0.05       0.06       0.07 #> d[Fixed dose warfarin + low dose aspirin]          0.09       0.09       0.07       0.08 #> d[Fixed dose warfarin + medium dose aspirin]       0.04       0.06       0.07       0.09 #> d[High dose aspirin]                               0.05       0.05       0.04       0.04 #> d[Indobufen]                                       0.07       0.05       0.04       0.04 #> d[Low adjusted dose anti-coagulant]                0.01       0.00       0.00       0.00 #> d[Low dose aspirin]                                0.13       0.16       0.18       0.14 #> d[Low dose aspirin + copidogrel]                   0.11       0.10       0.10       0.08 #> d[Low dose aspirin + dipyridamole]                 0.08       0.06       0.06       0.04 #> d[Medium dose aspirin]                             0.16       0.13       0.06       0.04 #> d[Placebo/Standard care]                           0.04       0.08       0.14       0.21 #> d[Triflusal]                                       0.06       0.05       0.06       0.05 #> d[Ximelagatran]                                    0.02       0.01       0.01       0.00 #>                                              p_rank[14] p_rank[15] p_rank[16] p_rank[17] #> d[Standard adjusted dose anti-coagulant]           0.00       0.00       0.00       0.00 #> d[Acenocoumarol]                                   0.01       0.01       0.00       0.00 #> d[Alternate day aspirin]                           0.01       0.01       0.02       0.02 #> d[Dipyridamole]                                    0.08       0.09       0.08       0.08 #> d[Fixed dose warfarin]                             0.09       0.13       0.21       0.25 #> d[Fixed dose warfarin + low dose aspirin]          0.08       0.06       0.06       0.04 #> d[Fixed dose warfarin + medium dose aspirin]       0.11       0.17       0.22       0.16 #> d[High dose aspirin]                               0.05       0.06       0.08       0.18 #> d[Indobufen]                                       0.03       0.03       0.03       0.02 #> d[Low adjusted dose anti-coagulant]                0.00       0.00       0.00       0.00 #> d[Low dose aspirin]                                0.12       0.07       0.03       0.01 #> d[Low dose aspirin + copidogrel]                   0.07       0.06       0.05       0.03 #> d[Low dose aspirin + dipyridamole]                 0.04       0.03       0.02       0.02 #> d[Medium dose aspirin]                             0.02       0.01       0.00       0.00 #> d[Placebo/Standard care]                           0.23       0.17       0.09       0.02 #> d[Triflusal]                                       0.06       0.08       0.10       0.17 #> d[Ximelagatran]                                    0.00       0.00       0.00       0.00 plot(af_1_rankprobs) (af_1_cumrankprobs <- posterior_rank_probs(af_fit_1, cumulative = TRUE)) #>                                              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[Standard adjusted dose anti-coagulant]          0.00      0.02      0.10      0.30      0.59 #> d[Acenocoumarol]                                  0.38      0.67      0.77      0.81      0.85 #> d[Alternate day aspirin]                          0.46      0.63      0.70      0.74      0.77 #> d[Dipyridamole]                                   0.00      0.01      0.02      0.05      0.08 #> d[Fixed dose warfarin]                            0.00      0.00      0.00      0.01      0.02 #> d[Fixed dose warfarin + low dose aspirin]         0.00      0.02      0.04      0.08      0.12 #> d[Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00      0.00      0.01 #> d[High dose aspirin]                              0.03      0.09      0.14      0.20      0.24 #> d[Indobufen]                                      0.01      0.06      0.13      0.21      0.30 #> d[Low adjusted dose anti-coagulant]               0.08      0.31      0.59      0.74      0.82 #> d[Low dose aspirin]                               0.00      0.00      0.00      0.00      0.00 #> d[Low dose aspirin + copidogrel]                  0.00      0.01      0.02      0.04      0.07 #> d[Low dose aspirin + dipyridamole]                0.01      0.05      0.12      0.19      0.27 #> d[Medium dose aspirin]                            0.00      0.00      0.00      0.01      0.03 #> d[Placebo/Standard care]                          0.00      0.00      0.00      0.00      0.00 #> d[Triflusal]                                      0.00      0.02      0.07      0.11      0.15 #> d[Ximelagatran]                                   0.02      0.12      0.30      0.52      0.68 #>                                              p_rank[6] p_rank[7] p_rank[8] p_rank[9] #> d[Standard adjusted dose anti-coagulant]          0.82      0.93      0.98      1.00 #> d[Acenocoumarol]                                  0.88      0.90      0.93      0.94 #> d[Alternate day aspirin]                          0.80      0.83      0.86      0.88 #> d[Dipyridamole]                                   0.12      0.17      0.25      0.33 #> d[Fixed dose warfarin]                            0.03      0.04      0.07      0.10 #> d[Fixed dose warfarin + low dose aspirin]         0.18      0.25      0.34      0.44 #> d[Fixed dose warfarin + medium dose aspirin]      0.01      0.02      0.05      0.07 #> d[High dose aspirin]                              0.29      0.34      0.39      0.44 #> d[Indobufen]                                      0.39      0.49      0.60      0.69 #> d[Low adjusted dose anti-coagulant]               0.89      0.94      0.96      0.98 #> d[Low dose aspirin]                               0.01      0.03      0.08      0.16 #> d[Low dose aspirin + copidogrel]                  0.12      0.20      0.30      0.40 #> d[Low dose aspirin + dipyridamole]                0.37      0.47      0.57      0.65 #> d[Medium dose aspirin]                            0.10      0.22      0.38      0.58 #> d[Placebo/Standard care]                          0.00      0.00      0.01      0.02 #> d[Triflusal]                                      0.20      0.26      0.31      0.37 #> d[Ximelagatran]                                   0.81      0.88      0.94      0.96 #>                                              p_rank[10] p_rank[11] p_rank[12] p_rank[13] #> d[Standard adjusted dose anti-coagulant]           1.00       1.00       1.00       1.00 #> d[Acenocoumarol]                                   0.95       0.96       0.97       0.98 #> d[Alternate day aspirin]                           0.90       0.91       0.92       0.94 #> d[Dipyridamole]                                    0.41       0.50       0.58       0.67 #> d[Fixed dose warfarin]                             0.14       0.19       0.25       0.32 #> d[Fixed dose warfarin + low dose aspirin]          0.53       0.61       0.69       0.76 #> d[Fixed dose warfarin + medium dose aspirin]       0.11       0.17       0.24       0.33 #> d[High dose aspirin]                               0.49       0.54       0.58       0.63 #> d[Indobufen]                                       0.75       0.80       0.85       0.89 #> d[Low adjusted dose anti-coagulant]                0.99       0.99       1.00       1.00 #> d[Low dose aspirin]                                0.29       0.45       0.62       0.77 #> d[Low dose aspirin + copidogrel]                   0.51       0.61       0.70       0.78 #> d[Low dose aspirin + dipyridamole]                 0.73       0.79       0.85       0.89 #> d[Medium dose aspirin]                             0.75       0.87       0.94       0.98 #> d[Placebo/Standard care]                           0.06       0.14       0.28       0.49 #> d[Triflusal]                                       0.42       0.48       0.54       0.59 #> d[Ximelagatran]                                    0.98       0.99       0.99       0.99 #>                                              p_rank[14] p_rank[15] p_rank[16] p_rank[17] #> d[Standard adjusted dose anti-coagulant]           1.00       1.00       1.00          1 #> d[Acenocoumarol]                                   0.98       0.99       1.00          1 #> d[Alternate day aspirin]                           0.95       0.96       0.98          1 #> d[Dipyridamole]                                    0.75       0.84       0.92          1 #> d[Fixed dose warfarin]                             0.41       0.55       0.75          1 #> d[Fixed dose warfarin + low dose aspirin]          0.84       0.90       0.96          1 #> d[Fixed dose warfarin + medium dose aspirin]       0.44       0.61       0.84          1 #> d[High dose aspirin]                               0.68       0.74       0.82          1 #> d[Indobufen]                                       0.92       0.95       0.98          1 #> d[Low adjusted dose anti-coagulant]                1.00       1.00       1.00          1 #> d[Low dose aspirin]                                0.89       0.96       0.99          1 #> d[Low dose aspirin + copidogrel]                   0.85       0.92       0.97          1 #> d[Low dose aspirin + dipyridamole]                 0.93       0.96       0.98          1 #> d[Medium dose aspirin]                             0.99       1.00       1.00          1 #> d[Placebo/Standard care]                           0.72       0.88       0.98          1 #> d[Triflusal]                                       0.65       0.73       0.83          1 #> d[Ximelagatran]                                    1.00       1.00       1.00          1 plot(af_1_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"network-meta-regression-adjusting-for-proportion-of-prior-stroke","dir":"Articles","previous_headings":"Meta-analysis models","what":"Network meta-regression adjusting for proportion of prior stroke","title":"Example: Atrial fibrillation","text":"now consider meta-regression model adjusting proportion individuals study prior stroke, shared interaction coefficients treatment class. regression model specified nma() function using formula regression argument. formula ~ .trt:stroke means interactions prior stroke treatment included; .trt special variable indicates treatment, stroke original data set. specify class_interactions = \"common\" denote interaction parameters common (.e. shared) treatments within class. (Setting class_interactions = \"independent\" fit model 2 Cooper et al. (2009) separate interactions treatment, data permitting.) use prior distributions , additionally require prior distribution regression coefficients prior_reg; use \\(\\mathrm{N}(0, 100^2)\\) prior distribution. QR decomposition can greatly improve efficiency sampling regression models decorrelating sampling space; specify used QR = TRUE, increase target acceptance rate adapt_delta = 0.99 minimise divergent transition warnings. Basic parameter summaries given print() method: estimated treatment effects d[] shown correspond relative effects reference level covariate, proportion prior stroke centered network mean value 0.296. default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  can compute relative effects placebo/standard care relative_effects() function trt_ref argument, default produces relative effects observed proportions prior stroke study: can produce estimated treatment effects particular covariate values using newdata argument. example, treatment effects individuals individuals prior stroke produced  estimated class interactions (reference “Mixed” class) uncertain.  interactions straightforward interpret transform interaction coefficients (using consistency equations) control class:  evidence effect anti-coagulants increases (compared control) prior stroke. little evidence effect anti-platelets reduces prior stroke, although point estimate represents substantial reduction effectiveness, 95% Credible Interval includes values correspond substantial increases treatment effect. interaction effect stroke mixed treatments uncertain, potentially indicates substantial reduction treatment effects prior stroke. can also produce treatment rankings, rank probabilities, cumulative rank probabilities. default (without newdata argument specified), produced value stroke study network turn. instead produce rankings individuals individuals prior stroke, specify newdata argument.","code":"af_fit_4b <- nma(af_net,                   trt_effects = \"random\",                  regression = ~ .trt:stroke,                  class_interactions = \"common\",                  QR = TRUE,                  prior_intercept = normal(scale = 100),                  prior_trt = normal(scale = 100),                  prior_reg = normal(scale = 100),                  prior_het = half_normal(scale = 5),                  adapt_delta = 0.99) #> Note: Setting \"Standard adjusted dose anti-coagulant\" as the network reference treatment. #> Warning: There were 4 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess af_fit_4b #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:stroke. #> Centred covariates at the following overall mean values: #>    stroke  #> 0.2957377  #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                  mean se_mean   sd     2.5%      25%      50% #> beta[.trtclassControl:stroke]                    0.71    0.01 0.45    -0.13     0.41     0.70 #> beta[.trtclassAnti-platelet:stroke]              0.94    0.01 0.43     0.12     0.67     0.94 #> beta[.trtclassMixed:stroke]                      3.93    0.03 2.07    -0.08     2.61     3.91 #> d[Acenocoumarol]                                 0.37    0.02 0.99    -1.63    -0.27     0.39 #> d[Alternate day aspirin]                        -0.93    0.03 1.41    -4.31    -1.66    -0.72 #> d[Dipyridamole]                                  0.57    0.01 0.41    -0.24     0.31     0.57 #> d[Fixed dose warfarin]                           0.65    0.01 0.38    -0.09     0.40     0.65 #> d[Fixed dose warfarin + low dose aspirin]        1.46    0.01 0.74    -0.01     0.99     1.46 #> d[Fixed dose warfarin + medium dose aspirin]     1.01    0.00 0.31     0.44     0.81     1.00 #> d[High dose aspirin]                             0.43    0.01 0.74    -1.03    -0.08     0.44 #> d[Indobufen]                                    -0.42    0.01 0.49    -1.39    -0.75    -0.42 #> d[Low adjusted dose anti-coagulant]             -0.43    0.01 0.38    -1.20    -0.67    -0.42 #> d[Low dose aspirin]                              0.72    0.00 0.20     0.30     0.59     0.72 #> d[Low dose aspirin + copidogrel]                 0.65    0.01 0.29     0.06     0.49     0.65 #> d[Low dose aspirin + dipyridamole]               0.25    0.01 0.43    -0.61    -0.02     0.26 #> d[Medium dose aspirin]                           0.35    0.00 0.17     0.00     0.24     0.35 #> d[Placebo/Standard care]                         0.79    0.00 0.19     0.41     0.67     0.79 #> d[Triflusal]                                     0.92    0.01 0.60    -0.24     0.51     0.92 #> d[Ximelagatran]                                 -0.09    0.00 0.22    -0.51    -0.22    -0.09 #> lp__                                         -5016.95    0.20 7.21 -5032.26 -5021.61 -5016.62 #> tau                                              0.18    0.01 0.13     0.01     0.08     0.16 #>                                                   75%    97.5% n_eff Rhat #> beta[.trtclassControl:stroke]                    1.00     1.63  3248 1.00 #> beta[.trtclassAnti-platelet:stroke]              1.20     1.81  3002 1.00 #> beta[.trtclassMixed:stroke]                      5.22     8.14  3768 1.00 #> d[Acenocoumarol]                                 1.03     2.31  4216 1.00 #> d[Alternate day aspirin]                         0.03     1.27  1709 1.00 #> d[Dipyridamole]                                  0.84     1.35  4724 1.00 #> d[Fixed dose warfarin]                           0.90     1.37  3881 1.00 #> d[Fixed dose warfarin + low dose aspirin]        1.94     2.92  3875 1.00 #> d[Fixed dose warfarin + medium dose aspirin]     1.20     1.63  4144 1.00 #> d[High dose aspirin]                             0.93     1.86  4371 1.00 #> d[Indobufen]                                    -0.09     0.56  4046 1.00 #> d[Low adjusted dose anti-coagulant]             -0.18     0.30  4103 1.00 #> d[Low dose aspirin]                              0.85     1.11  3504 1.00 #> d[Low dose aspirin + copidogrel]                 0.82     1.22  2053 1.00 #> d[Low dose aspirin + dipyridamole]               0.53     1.09  5423 1.00 #> d[Medium dose aspirin]                           0.45     0.70  3570 1.00 #> d[Placebo/Standard care]                         0.91     1.16  3425 1.00 #> d[Triflusal]                                     1.30     2.11  4532 1.00 #> d[Ximelagatran]                                  0.04     0.35  2281 1.00 #> lp__                                         -5011.84 -5003.95  1314 1.00 #> tau                                              0.26     0.50   304 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:32:21 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(af_fit_4b, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(af_fit_4b, prior = c(\"reg\", \"het\")) # Not run (af_4b_releff <- relative_effects(af_fit_4b, trt_ref = \"Placebo/Standard care\")) plot(af_4b_releff, ref_line = 0) (af_4b_releff_01 <- relative_effects(af_fit_4b,                                       trt_ref = \"Placebo/Standard care\",                                      newdata = data.frame(stroke = c(0, 1),                                                            label = c(\"stroke = 0\", \"stroke = 1\")),                                      study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                           mean   sd  2.5%   25%   50%   75% #> d[stroke = 0: Standard adjusted dose anti-coagulant]     -0.58 0.25 -1.05 -0.74 -0.59 -0.42 #> d[stroke = 0: Acenocoumarol]                             -1.37 0.83 -3.09 -1.90 -1.35 -0.80 #> d[stroke = 0: Alternate day aspirin]                     -1.79 1.41 -5.12 -2.50 -1.58 -0.82 #> d[stroke = 0: Dipyridamole]                              -0.28 0.44 -1.17 -0.58 -0.29 -0.01 #> d[stroke = 0: Fixed dose warfarin]                        0.07 0.44 -0.79 -0.21  0.07  0.35 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]    -0.29 0.33 -0.95 -0.49 -0.29 -0.08 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin] -0.73 0.66 -2.07 -1.17 -0.71 -0.30 #> d[stroke = 0: High dose aspirin]                         -0.43 0.78 -1.95 -0.96 -0.42  0.08 #> d[stroke = 0: Indobufen]                                 -1.28 0.58 -2.40 -1.65 -1.27 -0.91 #> d[stroke = 0: Low adjusted dose anti-coagulant]          -1.01 0.34 -1.68 -1.22 -1.00 -0.78 #> d[stroke = 0: Low dose aspirin]                          -0.14 0.22 -0.58 -0.29 -0.15  0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]             -0.21 0.36 -0.92 -0.43 -0.21  0.01 #> d[stroke = 0: Low dose aspirin + dipyridamole]           -0.60 0.46 -1.55 -0.90 -0.60 -0.30 #> d[stroke = 0: Medium dose aspirin]                       -0.51 0.27 -1.03 -0.69 -0.52 -0.34 #> d[stroke = 0: Triflusal]                                  0.06 0.63 -1.14 -0.37  0.05  0.48 #> d[stroke = 0: Ximelagatran]                              -0.66 0.33 -1.29 -0.87 -0.67 -0.47 #>                                                          97.5% Bulk_ESS Tail_ESS Rhat #> d[stroke = 0: Standard adjusted dose anti-coagulant]     -0.08     3806     2442    1 #> d[stroke = 0: Acenocoumarol]                              0.20     3710     2739    1 #> d[stroke = 0: Alternate day aspirin]                      0.40     2585     1386    1 #> d[stroke = 0: Dipyridamole]                               0.60     5094     2676    1 #> d[stroke = 0: Fixed dose warfarin]                        0.92     3948     2838    1 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]     0.37     3832     1728    1 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]  0.56     4084     2528    1 #> d[stroke = 0: High dose aspirin]                          1.15     4508     3017    1 #> d[stroke = 0: Indobufen]                                 -0.17     3818     2621    1 #> d[stroke = 0: Low adjusted dose anti-coagulant]          -0.35     5432     3171    1 #> d[stroke = 0: Low dose aspirin]                           0.31     3699     2192    1 #> d[stroke = 0: Low dose aspirin + copidogrel]              0.53     2764     1731    1 #> d[stroke = 0: Low dose aspirin + dipyridamole]            0.30     5043     2763    1 #> d[stroke = 0: Medium dose aspirin]                        0.03     3967     2454    1 #> d[stroke = 0: Triflusal]                                  1.35     4693     3101    1 #> d[stroke = 0: Ximelagatran]                               0.00     3525     2025    1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                           mean   sd  2.5%   25%   50%   75% #> d[stroke = 1: Standard adjusted dose anti-coagulant]     -1.29 0.35 -2.00 -1.51 -1.28 -1.06 #> d[stroke = 1: Acenocoumarol]                              1.85 2.22 -2.58  0.40  1.85  3.27 #> d[stroke = 1: Alternate day aspirin]                     -1.56 1.43 -4.98 -2.33 -1.34 -0.60 #> d[stroke = 1: Dipyridamole]                              -0.05 0.39 -0.87 -0.30 -0.05  0.20 #> d[stroke = 1: Fixed dose warfarin]                       -0.64 0.53 -1.69 -0.98 -0.63 -0.29 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]     2.94 2.14 -1.25  1.54  2.94  4.29 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]  2.49 1.58 -0.57  1.45  2.46  3.51 #> d[stroke = 1: High dose aspirin]                         -0.20 0.74 -1.65 -0.69 -0.19  0.29 #> d[stroke = 1: Indobufen]                                 -1.05 0.52 -2.07 -1.38 -1.05 -0.70 #> d[stroke = 1: Low adjusted dose anti-coagulant]          -1.72 0.52 -2.76 -2.05 -1.72 -1.37 #> d[stroke = 1: Low dose aspirin]                           0.09 0.29 -0.50 -0.10  0.10  0.28 #> d[stroke = 1: Low dose aspirin + copidogrel]              0.02 0.39 -0.77 -0.21  0.03  0.26 #> d[stroke = 1: Low dose aspirin + dipyridamole]           -0.37 0.43 -1.24 -0.64 -0.36 -0.10 #> d[stroke = 1: Medium dose aspirin]                       -0.28 0.24 -0.78 -0.43 -0.27 -0.12 #> d[stroke = 1: Triflusal]                                  0.29 0.65 -0.97 -0.14  0.30  0.71 #> d[stroke = 1: Ximelagatran]                              -1.37 0.41 -2.19 -1.63 -1.37 -1.12 #>                                                          97.5% Bulk_ESS Tail_ESS Rhat #> d[stroke = 1: Standard adjusted dose anti-coagulant]     -0.61     3439     1396    1 #> d[stroke = 1: Acenocoumarol]                              6.40     4058     2594    1 #> d[stroke = 1: Alternate day aspirin]                      0.71     2606     1396    1 #> d[stroke = 1: Dipyridamole]                               0.71     4355     2635    1 #> d[stroke = 1: Fixed dose warfarin]                        0.37     3789     2331    1 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]     7.20     3971     2586    1 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]  5.67     4097     2477    1 #> d[stroke = 1: High dose aspirin]                          1.24     4434     2747    1 #> d[stroke = 1: Indobufen]                                 -0.05     4212     2396    1 #> d[stroke = 1: Low adjusted dose anti-coagulant]          -0.73     3399     2607    1 #> d[stroke = 1: Low dose aspirin]                           0.66     3351     2391    1 #> d[stroke = 1: Low dose aspirin + copidogrel]              0.77     3389     2302    1 #> d[stroke = 1: Low dose aspirin + dipyridamole]            0.45     4673     2357    1 #> d[stroke = 1: Medium dose aspirin]                        0.18     4402     2529    1 #> d[stroke = 1: Triflusal]                                  1.54     4715     2889    1 #> d[stroke = 1: Ximelagatran]                              -0.59     3139     1879    1 plot(af_4b_releff_01, ref_line = 0) plot(af_fit_4b, pars = \"beta\", stat = \"halfeye\", ref_line = 0) af_4b_beta <- as.array(af_fit_4b, pars = \"beta\")  # Subtract beta[Control:stroke] from the other class interactions af_4b_beta[ , , 2:3] <- sweep(af_4b_beta[ , , 2:3], 1:2,                                af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"], FUN = \"-\")  # Set beta[Anti-coagulant:stroke] = -beta[Control:stroke] af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"] <- -af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"] names(af_4b_beta)[1] <- \"beta[.trtclassAnti-coagulant:stroke]\"  # Summarise summary(af_4b_beta) #>                                       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> beta[.trtclassAnti-coagulant:stroke] -0.71 0.45 -1.63 -1.00 -0.70 -0.41  0.13     3598 #> beta[.trtclassAnti-platelet:stroke]   0.23 0.34 -0.45  0.01  0.24  0.45  0.89     4291 #> beta[.trtclassMixed:stroke]           3.22 2.10 -0.86  1.85  3.21  4.58  7.36     3968 #>                                      Tail_ESS Rhat #> beta[.trtclassAnti-coagulant:stroke]     1866    1 #> beta[.trtclassAnti-platelet:stroke]      2370    1 #> beta[.trtclassMixed:stroke]              2960    1 plot(summary(af_4b_beta), stat = \"halfeye\", ref_line = 0) (af_4b_ranks <- posterior_ranks(af_fit_4b,                                 newdata = data.frame(stroke = c(0, 1),                                                       label = c(\"stroke = 0\", \"stroke = 1\")),                                  study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                              mean   sd 2.5% 25% 50% 75% 97.5% #> rank[stroke = 0: Standard adjusted dose anti-coagulant]      7.74 1.87    4   6   8   9    11 #> rank[stroke = 0: Acenocoumarol]                              4.01 3.71    1   1   3   5    15 #> rank[stroke = 0: Alternate day aspirin]                      3.96 4.41    1   1   2   5    16 #> rank[stroke = 0: Dipyridamole]                              11.08 3.68    4   9  11  14    17 #> rank[stroke = 0: Fixed dose warfarin]                       14.23 2.82    7  13  15  16    17 #> rank[stroke = 0: Fixed dose warfarin + low dose aspirin]    11.04 3.65    4   8  11  14    17 #> rank[stroke = 0: Fixed dose warfarin + medium dose aspirin]  7.23 4.52    1   3   6  11    16 #> rank[stroke = 0: High dose aspirin]                          9.66 5.32    1   5  10  15    17 #> rank[stroke = 0: Indobufen]                                  3.59 2.71    1   2   3   4    12 #> rank[stroke = 0: Low adjusted dose anti-coagulant]           4.53 2.43    1   3   4   6    11 #> rank[stroke = 0: Low dose aspirin]                          12.86 1.94    9  12  13  14    16 #> rank[stroke = 0: Low dose aspirin + copidogrel]             12.03 2.88    6  10  12  14    17 #> rank[stroke = 0: Low dose aspirin + dipyridamole]            7.90 3.70    2   5   7  11    16 #> rank[stroke = 0: Medium dose aspirin]                        8.61 2.18    4   7   9  10    13 #> rank[stroke = 0: Placebo/Standard care]                     14.26 1.93   10  13  15  16    17 #> rank[stroke = 0: Triflusal]                                 13.37 4.05    4  11  15  17    17 #> rank[stroke = 0: Ximelagatran]                               6.91 2.63    3   5   7   8    13 #>                                                             Bulk_ESS Tail_ESS Rhat #> rank[stroke = 0: Standard adjusted dose anti-coagulant]         3233     2928    1 #> rank[stroke = 0: Acenocoumarol]                                 3970     3031    1 #> rank[stroke = 0: Alternate day aspirin]                         4399     3039    1 #> rank[stroke = 0: Dipyridamole]                                  4657       NA    1 #> rank[stroke = 0: Fixed dose warfarin]                           3890       NA    1 #> rank[stroke = 0: Fixed dose warfarin + low dose aspirin]        3818     2629    1 #> rank[stroke = 0: Fixed dose warfarin + medium dose aspirin]     3878     3407    1 #> rank[stroke = 0: High dose aspirin]                             4590       NA    1 #> rank[stroke = 0: Indobufen]                                     3570     2166    1 #> rank[stroke = 0: Low adjusted dose anti-coagulant]              4137     3164    1 #> rank[stroke = 0: Low dose aspirin]                              2844     2771    1 #> rank[stroke = 0: Low dose aspirin + copidogrel]                 2698     2055    1 #> rank[stroke = 0: Low dose aspirin + dipyridamole]               5335     3527    1 #> rank[stroke = 0: Medium dose aspirin]                           3553     2910    1 #> rank[stroke = 0: Placebo/Standard care]                         2688       NA    1 #> rank[stroke = 0: Triflusal]                                     4347       NA    1 #> rank[stroke = 0: Ximelagatran]                                  3092     1980    1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                              mean   sd 2.5% 25% 50% 75% 97.5% #> rank[stroke = 1: Standard adjusted dose anti-coagulant]      3.64 1.12 2.00   3   4   4     6 #> rank[stroke = 1: Acenocoumarol]                             13.35 4.26 1.00  14  15  16    17 #> rank[stroke = 1: Alternate day aspirin]                      4.46 3.96 1.00   1   3   6    14 #> rank[stroke = 1: Dipyridamole]                              10.55 2.69 5.00   9  11  13    15 #> rank[stroke = 1: Fixed dose warfarin]                        7.15 2.71 3.00   5   6   8    14 #> rank[stroke = 1: Fixed dose warfarin + low dose aspirin]    15.76 2.97 5.98  16  17  17    17 #> rank[stroke = 1: Fixed dose warfarin + medium dose aspirin] 15.44 1.88 9.00  15  16  16    17 #> rank[stroke = 1: High dose aspirin]                          9.48 3.96 2.00   6   9  13    16 #> rank[stroke = 1: Indobufen]                                  4.89 2.15 1.00   4   5   6    10 #> rank[stroke = 1: Low adjusted dose anti-coagulant]           2.01 1.29 1.00   1   2   2     5 #> rank[stroke = 1: Low dose aspirin]                          11.87 1.84 8.00  11  12  13    15 #> rank[stroke = 1: Low dose aspirin + copidogrel]             11.17 2.41 6.00  10  11  13    15 #> rank[stroke = 1: Low dose aspirin + dipyridamole]            8.24 2.65 3.00   6   8  10    14 #> rank[stroke = 1: Medium dose aspirin]                        8.61 1.69 6.00   7   8  10    12 #> rank[stroke = 1: Placebo/Standard care]                     11.14 1.92 8.00  10  11  12    15 #> rank[stroke = 1: Triflusal]                                 12.11 3.14 5.00  10  13  14    17 #> rank[stroke = 1: Ximelagatran]                               3.14 1.40 1.00   2   3   4     6 #>                                                             Bulk_ESS Tail_ESS Rhat #> rank[stroke = 1: Standard adjusted dose anti-coagulant]         3205     2642    1 #> rank[stroke = 1: Acenocoumarol]                                 3958       NA    1 #> rank[stroke = 1: Alternate day aspirin]                         4128     2691    1 #> rank[stroke = 1: Dipyridamole]                                  4084     3335    1 #> rank[stroke = 1: Fixed dose warfarin]                           3576     2717    1 #> rank[stroke = 1: Fixed dose warfarin + low dose aspirin]        3072       NA    1 #> rank[stroke = 1: Fixed dose warfarin + medium dose aspirin]     3611       NA    1 #> rank[stroke = 1: High dose aspirin]                             4444     3221    1 #> rank[stroke = 1: Indobufen]                                     4075     1794    1 #> rank[stroke = 1: Low adjusted dose anti-coagulant]              3233     3096    1 #> rank[stroke = 1: Low dose aspirin]                              3557     2724    1 #> rank[stroke = 1: Low dose aspirin + copidogrel]                 3458     2470    1 #> rank[stroke = 1: Low dose aspirin + dipyridamole]               4561     2944    1 #> rank[stroke = 1: Medium dose aspirin]                           3459     3275    1 #> rank[stroke = 1: Placebo/Standard care]                         4317     3348    1 #> rank[stroke = 1: Triflusal]                                     4182       NA    1 #> rank[stroke = 1: Ximelagatran]                                  2708     1973    1 plot(af_4b_ranks) (af_4b_rankprobs <- posterior_rank_probs(af_fit_4b,                                          newdata = data.frame(stroke = c(0, 1),                                                                label = c(\"stroke = 0\", \"stroke = 1\")),                                           study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.00      0.00      0.01 #> d[stroke = 0: Acenocoumarol]                                  0.26      0.23      0.13 #> d[stroke = 0: Alternate day aspirin]                          0.44      0.15      0.09 #> d[stroke = 0: Dipyridamole]                                   0.00      0.01      0.01 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.00      0.00 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.05      0.09      0.11 #> d[stroke = 0: High dose aspirin]                              0.03      0.06      0.08 #> d[stroke = 0: Indobufen]                                      0.17      0.26      0.20 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.04      0.15      0.21 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.01      0.03      0.07 #> d[stroke = 0: Medium dose aspirin]                            0.00      0.00      0.00 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.00      0.01      0.01 #> d[stroke = 0: Ximelagatran]                                   0.00      0.02      0.05 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.03      0.08      0.15 #> d[stroke = 0: Acenocoumarol]                                  0.09      0.06      0.04 #> d[stroke = 0: Alternate day aspirin]                          0.06      0.05      0.03 #> d[stroke = 0: Dipyridamole]                                   0.02      0.04      0.05 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.00      0.01 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.03      0.04      0.05 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.11      0.10      0.07 #> d[stroke = 0: High dose aspirin]                              0.07      0.07      0.05 #> d[stroke = 0: Indobufen]                                      0.14      0.07      0.04 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.21      0.14      0.08 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.01      0.01      0.02 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.10      0.10      0.10 #> d[stroke = 0: Medium dose aspirin]                            0.02      0.05      0.10 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.02      0.02      0.03 #> d[stroke = 0: Ximelagatran]                                   0.10      0.16      0.17 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.20      0.20      0.17 #> d[stroke = 0: Acenocoumarol]                                  0.03      0.02      0.02 #> d[stroke = 0: Alternate day aspirin]                          0.02      0.02      0.02 #> d[stroke = 0: Dipyridamole]                                   0.05      0.06      0.08 #> d[stroke = 0: Fixed dose warfarin]                            0.01      0.02      0.03 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.05      0.06      0.07 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.06      0.05      0.05 #> d[stroke = 0: High dose aspirin]                              0.05      0.03      0.04 #> d[stroke = 0: Indobufen]                                      0.03      0.02      0.02 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.05      0.04      0.03 #> d[stroke = 0: Low dose aspirin]                               0.00      0.01      0.03 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.03      0.05      0.06 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.10      0.08      0.08 #> d[stroke = 0: Medium dose aspirin]                            0.13      0.17      0.18 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.01 #> d[stroke = 0: Triflusal]                                      0.03      0.03      0.04 #> d[stroke = 0: Ximelagatran]                                   0.14      0.11      0.09 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.10       0.05       0.01 #> d[stroke = 0: Acenocoumarol]                                   0.02       0.02       0.01 #> d[stroke = 0: Alternate day aspirin]                           0.02       0.02       0.01 #> d[stroke = 0: Dipyridamole]                                    0.09       0.09       0.11 #> d[stroke = 0: Fixed dose warfarin]                             0.04       0.05       0.07 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.09       0.10       0.10 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.05       0.04       0.04 #> d[stroke = 0: High dose aspirin]                               0.05       0.05       0.04 #> d[stroke = 0: Indobufen]                                       0.01       0.01       0.01 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.02       0.01       0.01 #> d[stroke = 0: Low dose aspirin]                                0.06       0.11       0.17 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.09       0.12       0.14 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.07       0.07       0.05 #> d[stroke = 0: Medium dose aspirin]                             0.14       0.11       0.06 #> d[stroke = 0: Placebo/Standard care]                           0.02       0.04       0.08 #> d[stroke = 0: Triflusal]                                       0.04       0.06       0.05 #> d[stroke = 0: Ximelagatran]                                    0.06       0.04       0.02 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.01       0.00       0.00 #> d[stroke = 0: Acenocoumarol]                                   0.01       0.01       0.02 #> d[stroke = 0: Alternate day aspirin]                           0.01       0.02       0.02 #> d[stroke = 0: Dipyridamole]                                    0.09       0.08       0.08 #> d[stroke = 0: Fixed dose warfarin]                             0.08       0.10       0.13 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.10       0.09       0.08 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.04       0.04       0.03 #> d[stroke = 0: High dose aspirin]                               0.05       0.05       0.06 #> d[stroke = 0: Indobufen]                                       0.00       0.01       0.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.00       0.00       0.00 #> d[stroke = 0: Low dose aspirin]                                0.22       0.18       0.13 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.13       0.12       0.11 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.04       0.03       0.03 #> d[stroke = 0: Medium dose aspirin]                             0.02       0.01       0.00 #> d[stroke = 0: Placebo/Standard care]                           0.12       0.19       0.23 #> d[stroke = 0: Triflusal]                                       0.05       0.06       0.09 #> d[stroke = 0: Ximelagatran]                                    0.01       0.01       0.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.00       0.00 #> d[stroke = 0: Acenocoumarol]                                   0.01       0.00 #> d[stroke = 0: Alternate day aspirin]                           0.02       0.02 #> d[stroke = 0: Dipyridamole]                                    0.08       0.05 #> d[stroke = 0: Fixed dose warfarin]                             0.20       0.24 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.07       0.04 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.04       0.02 #> d[stroke = 0: High dose aspirin]                               0.08       0.14 #> d[stroke = 0: Indobufen]                                       0.00       0.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.00       0.00 #> d[stroke = 0: Low dose aspirin]                                0.06       0.01 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.07       0.04 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.02       0.01 #> d[stroke = 0: Medium dose aspirin]                             0.00       0.00 #> d[stroke = 0: Placebo/Standard care]                           0.20       0.09 #> d[stroke = 0: Triflusal]                                       0.14       0.32 #> d[stroke = 0: Ximelagatran]                                    0.00       0.00 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.12      0.34 #> d[stroke = 1: Acenocoumarol]                                  0.04      0.02      0.01 #> d[stroke = 1: Alternate day aspirin]                          0.36      0.10      0.05 #> d[stroke = 1: Dipyridamole]                                   0.00      0.00      0.00 #> d[stroke = 1: Fixed dose warfarin]                            0.00      0.01      0.02 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.02      0.03      0.03 #> d[stroke = 1: Indobufen]                                      0.04      0.09      0.11 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.44      0.34      0.11 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.00      0.01      0.01 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.00      0.00 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 1: Triflusal]                                      0.00      0.00      0.01 #> d[stroke = 1: Ximelagatran]                                   0.09      0.26      0.31 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.34      0.14      0.03 #> d[stroke = 1: Acenocoumarol]                                  0.01      0.02      0.02 #> d[stroke = 1: Alternate day aspirin]                          0.06      0.10      0.09 #> d[stroke = 1: Dipyridamole]                                   0.00      0.02      0.04 #> d[stroke = 1: Fixed dose warfarin]                            0.07      0.17      0.24 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.00      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.03      0.06      0.10 #> d[stroke = 1: Indobufen]                                      0.18      0.27      0.15 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.06      0.04      0.01 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.01      0.02 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.03      0.06      0.15 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.01      0.06 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.01 #> d[stroke = 1: Triflusal]                                      0.01      0.01      0.03 #> d[stroke = 1: Ximelagatran]                                   0.20      0.09      0.04 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.00      0.00 #> d[stroke = 1: Acenocoumarol]                                  0.02      0.02      0.01 #> d[stroke = 1: Alternate day aspirin]                          0.06      0.03      0.03 #> d[stroke = 1: Dipyridamole]                                   0.08      0.10      0.11 #> d[stroke = 1: Fixed dose warfarin]                            0.15      0.09      0.07 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.01      0.01      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.01      0.01      0.01 #> d[stroke = 1: High dose aspirin]                              0.10      0.07      0.07 #> d[stroke = 1: Indobufen]                                      0.07      0.04      0.02 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin]                               0.01      0.03      0.06 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.04      0.07      0.09 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.18      0.16      0.11 #> d[stroke = 1: Medium dose aspirin]                            0.18      0.25      0.23 #> d[stroke = 1: Placebo/Standard care]                          0.02      0.06      0.12 #> d[stroke = 1: Triflusal]                                      0.05      0.05      0.06 #> d[stroke = 1: Ximelagatran]                                   0.01      0.00      0.00 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.01       0.01       0.01 #> d[stroke = 1: Alternate day aspirin]                           0.02       0.02       0.02 #> d[stroke = 1: Dipyridamole]                                    0.13       0.12       0.12 #> d[stroke = 1: Fixed dose warfarin]                             0.04       0.04       0.03 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.01       0.01       0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.01       0.01       0.01 #> d[stroke = 1: High dose aspirin]                               0.06       0.06       0.07 #> d[stroke = 1: Indobufen]                                       0.01       0.01       0.01 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.10       0.18       0.24 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.12       0.15       0.16 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.09       0.07       0.05 #> d[stroke = 1: Medium dose aspirin]                             0.14       0.07       0.03 #> d[stroke = 1: Placebo/Standard care]                           0.19       0.19       0.18 #> d[stroke = 1: Triflusal]                                       0.05       0.06       0.08 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00       0.00 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.02       0.04       0.46 #> d[stroke = 1: Alternate day aspirin]                           0.03       0.03       0.01 #> d[stroke = 1: Dipyridamole]                                    0.12       0.09       0.03 #> d[stroke = 1: Fixed dose warfarin]                             0.03       0.02       0.01 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.01       0.02       0.04 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.01       0.02       0.25 #> d[stroke = 1: High dose aspirin]                               0.09       0.14       0.04 #> d[stroke = 1: Indobufen]                                       0.00       0.00       0.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.21       0.11       0.03 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.16       0.11       0.03 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.04       0.02       0.01 #> d[stroke = 1: Medium dose aspirin]                             0.01       0.01       0.00 #> d[stroke = 1: Placebo/Standard care]                           0.14       0.07       0.02 #> d[stroke = 1: Triflusal]                                       0.12       0.32       0.06 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00       0.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.19       0.08 #> d[stroke = 1: Alternate day aspirin]                           0.00       0.00 #> d[stroke = 1: Dipyridamole]                                    0.01       0.01 #> d[stroke = 1: Fixed dose warfarin]                             0.00       0.00 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.18       0.66 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.51       0.16 #> d[stroke = 1: High dose aspirin]                               0.02       0.02 #> d[stroke = 1: Indobufen]                                       0.00       0.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.02       0.01 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.02       0.01 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.00       0.00 #> d[stroke = 1: Medium dose aspirin]                             0.00       0.00 #> d[stroke = 1: Placebo/Standard care]                           0.01       0.00 #> d[stroke = 1: Triflusal]                                       0.03       0.05 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00  # Modify the default output with ggplot2 functionality library(ggplot2) plot(af_4b_rankprobs) +    facet_grid(Treatment~Study, labeller = label_wrap_gen(20)) +    theme(strip.text.y = element_text(angle = 0)) (af_4b_cumrankprobs <- posterior_rank_probs(af_fit_4b, cumulative = TRUE,                                             newdata = data.frame(stroke = c(0, 1),                                                                   label = c(\"stroke = 0\", \"stroke = 1\")),                                              study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.00      0.00      0.01 #> d[stroke = 0: Acenocoumarol]                                  0.26      0.49      0.62 #> d[stroke = 0: Alternate day aspirin]                          0.44      0.59      0.67 #> d[stroke = 0: Dipyridamole]                                   0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.00      0.00 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.05      0.14      0.25 #> d[stroke = 0: High dose aspirin]                              0.03      0.09      0.17 #> d[stroke = 0: Indobufen]                                      0.17      0.43      0.63 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.04      0.18      0.39 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.01      0.04      0.11 #> d[stroke = 0: Medium dose aspirin]                            0.00      0.00      0.01 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.00      0.01      0.02 #> d[stroke = 0: Ximelagatran]                                   0.00      0.02      0.07 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.03      0.11      0.26 #> d[stroke = 0: Acenocoumarol]                                  0.72      0.78      0.82 #> d[stroke = 0: Alternate day aspirin]                          0.73      0.78      0.81 #> d[stroke = 0: Dipyridamole]                                   0.04      0.09      0.14 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.05      0.09      0.14 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.36      0.46      0.53 #> d[stroke = 0: High dose aspirin]                              0.24      0.31      0.36 #> d[stroke = 0: Indobufen]                                      0.77      0.84      0.88 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.60      0.74      0.83 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.01      0.02      0.04 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.21      0.31      0.41 #> d[stroke = 0: Medium dose aspirin]                            0.03      0.08      0.17 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.04      0.07      0.09 #> d[stroke = 0: Ximelagatran]                                   0.17      0.33      0.49 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.46      0.66      0.83 #> d[stroke = 0: Acenocoumarol]                                  0.84      0.87      0.89 #> d[stroke = 0: Alternate day aspirin]                          0.83      0.85      0.86 #> d[stroke = 0: Dipyridamole]                                   0.19      0.25      0.33 #> d[stroke = 0: Fixed dose warfarin]                            0.03      0.05      0.08 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.19      0.25      0.32 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.59      0.64      0.69 #> d[stroke = 0: High dose aspirin]                              0.41      0.44      0.48 #> d[stroke = 0: Indobufen]                                      0.91      0.94      0.95 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.88      0.92      0.95 #> d[stroke = 0: Low dose aspirin]                               0.01      0.02      0.05 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.07      0.12      0.18 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.51      0.59      0.67 #> d[stroke = 0: Medium dose aspirin]                            0.31      0.48      0.66 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.01      0.02 #> d[stroke = 0: Triflusal]                                      0.12      0.15      0.19 #> d[stroke = 0: Ximelagatran]                                   0.64      0.75      0.84 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.93       0.98       0.99 #> d[stroke = 0: Acenocoumarol]                                   0.91       0.93       0.94 #> d[stroke = 0: Alternate day aspirin]                           0.88       0.90       0.91 #> d[stroke = 0: Dipyridamole]                                    0.42       0.51       0.62 #> d[stroke = 0: Fixed dose warfarin]                             0.12       0.17       0.24 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.41       0.51       0.61 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.74       0.79       0.83 #> d[stroke = 0: High dose aspirin]                               0.54       0.59       0.63 #> d[stroke = 0: Indobufen]                                       0.97       0.97       0.98 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.97       0.98       0.99 #> d[stroke = 0: Low dose aspirin]                                0.11       0.22       0.39 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.27       0.39       0.54 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.75       0.82       0.87 #> d[stroke = 0: Medium dose aspirin]                             0.80       0.91       0.97 #> d[stroke = 0: Placebo/Standard care]                           0.05       0.09       0.17 #> d[stroke = 0: Triflusal]                                       0.23       0.29       0.34 #> d[stroke = 0: Ximelagatran]                                    0.90       0.94       0.97 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 0: Acenocoumarol]                                   0.96       0.97       0.99 #> d[stroke = 0: Alternate day aspirin]                           0.92       0.94       0.96 #> d[stroke = 0: Dipyridamole]                                    0.71       0.79       0.87 #> d[stroke = 0: Fixed dose warfarin]                             0.32       0.42       0.55 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.71       0.80       0.88 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.87       0.91       0.94 #> d[stroke = 0: High dose aspirin]                               0.68       0.73       0.78 #> d[stroke = 0: Indobufen]                                       0.99       0.99       1.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 0: Low dose aspirin]                                0.62       0.80       0.92 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.67       0.79       0.89 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.91       0.94       0.97 #> d[stroke = 0: Medium dose aspirin]                             0.99       1.00       1.00 #> d[stroke = 0: Placebo/Standard care]                           0.29       0.48       0.71 #> d[stroke = 0: Triflusal]                                       0.39       0.46       0.55 #> d[stroke = 0: Ximelagatran]                                    0.98       0.99       1.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           1.00          1 #> d[stroke = 0: Acenocoumarol]                                   1.00          1 #> d[stroke = 0: Alternate day aspirin]                           0.98          1 #> d[stroke = 0: Dipyridamole]                                    0.95          1 #> d[stroke = 0: Fixed dose warfarin]                             0.76          1 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.96          1 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.98          1 #> d[stroke = 0: High dose aspirin]                               0.86          1 #> d[stroke = 0: Indobufen]                                       1.00          1 #> d[stroke = 0: Low adjusted dose anti-coagulant]                1.00          1 #> d[stroke = 0: Low dose aspirin]                                0.99          1 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.96          1 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.99          1 #> d[stroke = 0: Medium dose aspirin]                             1.00          1 #> d[stroke = 0: Placebo/Standard care]                           0.91          1 #> d[stroke = 0: Triflusal]                                       0.68          1 #> d[stroke = 0: Ximelagatran]                                    1.00          1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.13      0.47 #> d[stroke = 1: Acenocoumarol]                                  0.04      0.06      0.07 #> d[stroke = 1: Alternate day aspirin]                          0.36      0.46      0.51 #> d[stroke = 1: Dipyridamole]                                   0.00      0.00      0.00 #> d[stroke = 1: Fixed dose warfarin]                            0.00      0.01      0.03 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.02 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.02      0.04      0.07 #> d[stroke = 1: Indobufen]                                      0.04      0.13      0.24 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.44      0.77      0.88 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.00      0.01      0.03 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.00      0.00 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 1: Triflusal]                                      0.00      0.01      0.01 #> d[stroke = 1: Ximelagatran]                                   0.09      0.35      0.66 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.81      0.95      0.98 #> d[stroke = 1: Acenocoumarol]                                  0.08      0.10      0.12 #> d[stroke = 1: Alternate day aspirin]                          0.58      0.67      0.76 #> d[stroke = 1: Dipyridamole]                                   0.01      0.03      0.06 #> d[stroke = 1: Fixed dose warfarin]                            0.10      0.27      0.52 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.02      0.03      0.03 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.01      0.01 #> d[stroke = 1: High dose aspirin]                              0.10      0.16      0.27 #> d[stroke = 1: Indobufen]                                      0.41      0.68      0.83 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.94      0.98      0.99 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.01 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.01      0.04 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.05      0.11      0.26 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.02      0.08 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.01 #> d[stroke = 1: Triflusal]                                      0.02      0.03      0.06 #> d[stroke = 1: Ximelagatran]                                   0.86      0.94      0.98 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          1.00      1.00      1.00 #> d[stroke = 1: Acenocoumarol]                                  0.14      0.15      0.17 #> d[stroke = 1: Alternate day aspirin]                          0.81      0.85      0.87 #> d[stroke = 1: Dipyridamole]                                   0.14      0.24      0.35 #> d[stroke = 1: Fixed dose warfarin]                            0.67      0.76      0.83 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.05      0.06      0.07 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.02      0.02      0.03 #> d[stroke = 1: High dose aspirin]                              0.37      0.44      0.51 #> d[stroke = 1: Indobufen]                                      0.91      0.95      0.96 #> d[stroke = 1: Low adjusted dose anti-coagulant]               1.00      1.00      1.00 #> d[stroke = 1: Low dose aspirin]                               0.01      0.04      0.10 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.08      0.15      0.24 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.44      0.60      0.71 #> d[stroke = 1: Medium dose aspirin]                            0.26      0.51      0.74 #> d[stroke = 1: Placebo/Standard care]                          0.02      0.08      0.20 #> d[stroke = 1: Triflusal]                                      0.11      0.16      0.22 #> d[stroke = 1: Ximelagatran]                                   0.99      1.00      1.00 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 1: Acenocoumarol]                                   0.18       0.20       0.21 #> d[stroke = 1: Alternate day aspirin]                           0.89       0.91       0.93 #> d[stroke = 1: Dipyridamole]                                    0.49       0.61       0.73 #> d[stroke = 1: Fixed dose warfarin]                             0.87       0.91       0.94 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.08       0.08       0.09 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.04       0.05       0.06 #> d[stroke = 1: High dose aspirin]                               0.57       0.63       0.69 #> d[stroke = 1: Indobufen]                                       0.98       0.99       0.99 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 1: Low dose aspirin]                                0.20       0.39       0.62 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.36       0.51       0.68 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.81       0.87       0.92 #> d[stroke = 1: Medium dose aspirin]                             0.88       0.95       0.98 #> d[stroke = 1: Placebo/Standard care]                           0.39       0.58       0.75 #> d[stroke = 1: Triflusal]                                       0.27       0.33       0.41 #> d[stroke = 1: Ximelagatran]                                    1.00       1.00       1.00 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 1: Acenocoumarol]                                   0.23       0.27       0.73 #> d[stroke = 1: Alternate day aspirin]                           0.95       0.98       0.99 #> d[stroke = 1: Dipyridamole]                                    0.86       0.95       0.98 #> d[stroke = 1: Fixed dose warfarin]                             0.97       0.98       0.99 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.10       0.12       0.16 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.06       0.08       0.33 #> d[stroke = 1: High dose aspirin]                               0.79       0.92       0.96 #> d[stroke = 1: Indobufen]                                       1.00       1.00       1.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 1: Low dose aspirin]                                0.84       0.94       0.98 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.84       0.95       0.98 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.96       0.98       0.99 #> d[stroke = 1: Medium dose aspirin]                             0.99       1.00       1.00 #> d[stroke = 1: Placebo/Standard care]                           0.89       0.97       0.99 #> d[stroke = 1: Triflusal]                                       0.53       0.86       0.92 #> d[stroke = 1: Ximelagatran]                                    1.00       1.00       1.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00          1 #> d[stroke = 1: Acenocoumarol]                                   0.92          1 #> d[stroke = 1: Alternate day aspirin]                           1.00          1 #> d[stroke = 1: Dipyridamole]                                    0.99          1 #> d[stroke = 1: Fixed dose warfarin]                             1.00          1 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.34          1 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.84          1 #> d[stroke = 1: High dose aspirin]                               0.98          1 #> d[stroke = 1: Indobufen]                                       1.00          1 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00          1 #> d[stroke = 1: Low dose aspirin]                                0.99          1 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.99          1 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 1.00          1 #> d[stroke = 1: Medium dose aspirin]                             1.00          1 #> d[stroke = 1: Placebo/Standard care]                           1.00          1 #> d[stroke = 1: Triflusal]                                       0.95          1 #> d[stroke = 1: Ximelagatran]                                    1.00          1  plot(af_4b_cumrankprobs) +    facet_grid(Treatment~Study, labeller = label_wrap_gen(20)) +    theme(strip.text.y = element_text(angle = 0))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: Atrial fibrillation","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC slightly lower meta-regression model, although couple points (substantial differences usually considered 3-5 points). estimated heterogeneity standard deviation much lower meta-regression model, suggesting adjusting proportion patients prior stroke explaining heterogeneity data. can also examine residual deviance contributions corresponding plot() method.","code":"(af_dic_1 <- dic(af_fit_1)) #> Residual deviance: 60.4 (on 61 data points) #>                pD: 48.4 #>               DIC: 108.8 (af_dic_4b <- dic(af_fit_4b)) #> Residual deviance: 58.1 (on 61 data points) #>                pD: 47.9 #>               DIC: 106.1 plot(af_dic_1) plot(af_dic_4b)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: BCG vaccine for tuberculosis","text":"data giving number diagnosed TB trial follow-(r) total (n) arm, use function set_agd_arm() set network. set “unvaccinated” network reference treatment. latitude variable bcg_vaccine data frame automatically available use meta-regression model.","code":"bcg_net <- set_agd_arm(bcg_vaccine,                         study = studyn,                        trt = trtc,                        r = r,                         n = n,                        trt_ref = \"Unvaccinated\") bcg_net #> A network with 13 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms               #>  1     2: Unvaccinated | Vaccinated #>  2     2: Unvaccinated | Vaccinated #>  3     2: Unvaccinated | Vaccinated #>  4     2: Unvaccinated | Vaccinated #>  5     2: Unvaccinated | Vaccinated #>  6     2: Unvaccinated | Vaccinated #>  7     2: Unvaccinated | Vaccinated #>  8     2: Unvaccinated | Vaccinated #>  9     2: Unvaccinated | Vaccinated #>  10    2: Unvaccinated | Vaccinated #>  ... plus 3 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 13 #> Reference treatment is: Unvaccinated #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: BCG vaccine for tuberculosis","text":"fit random effects (RE) models, firstly without covariates, meta-regression continuous covariate latitude.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"re-meta-analysis-no-covariate","dir":"Articles","previous_headings":"Meta-analysis models","what":"RE meta-analysis (no covariate)","title":"Example: BCG vaccine for tuberculosis","text":"start fitting standard RE model without covariates. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Vaccine}\\) study-specific intercepts \\(\\mu_j\\), \\(\\textrm{half-N}(0, 5^2)\\) prior distribution heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: model fitted nma() function, random effects model specified trt_effects = \"random\". Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) random effects \\(\\delta_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. bcg_fit_unadj <- nma(bcg_net,                       trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = half_normal(scale = 5)) bcg_fit_unadj #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                    mean se_mean   sd      2.5%       25%       50%       75%     97.5% n_eff #> d[Vaccinated]     -0.77    0.01 0.22     -1.23     -0.90     -0.77     -0.63     -0.36   984 #> lp__          -13533.58    0.15 4.47 -13542.90 -13536.48 -13533.39 -13530.40 -13525.66   931 #> tau                0.69    0.01 0.21      0.39      0.54      0.65      0.79      1.17  1106 #>               Rhat #> d[Vaccinated] 1.00 #> lp__          1.01 #> tau           1.00 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:33:01 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(bcg_fit_unadj, pars = c(\"d\", \"mu\", \"delta\", \"tau\")) plot_prior_posterior(bcg_fit_unadj, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"re-meta-regression-with-covariate-latitude","dir":"Articles","previous_headings":"Meta-analysis models","what":"RE meta-regression with covariate latitude","title":"Example: BCG vaccine for tuberculosis","text":"now fit RE meta-regression model, adjusting latitude. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Vaccine}\\), study-specific intercepts \\(\\mu_j\\), regression coefficient \\(\\beta\\). use \\(\\text{half-N}(0, 5^2)\\) prior distribution heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: , model fitted nma() function. regression formula ~ .trt:latitude means interaction latitude treatment included; .trt special variable indicates treatment, latitude original data set. increase adapt_delta 0.99 remove small number divergent transition errors (default RE models set 0.95). Basic parameter summaries given print() method: Note latitude automatically centered 33.46, mean value studies network. default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. bcg_fit_lat <- nma(bcg_net,                     trt_effects = \"random\",                    regression = ~.trt:latitude,                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_reg = normal(scale = 100),                    prior_het = half_normal(scale = 5),                    adapt_delta = 0.99) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. bcg_fit_lat #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:latitude. #> Centred covariates at the following overall mean values: #> latitude  #> 33.46154  #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                    mean se_mean   sd      2.5%       25%       50%       75% #> beta[.trtVaccinated:latitude]     -0.03    0.00 0.01     -0.05     -0.04     -0.03     -0.03 #> d[Vaccinated]                     -0.76    0.00 0.12     -1.01     -0.82     -0.75     -0.69 #> lp__                          -13542.71    0.18 4.98 -13552.83 -13546.04 -13542.52 -13539.19 #> tau                                0.29    0.01 0.18      0.03      0.16      0.26      0.39 #>                                   97.5% n_eff Rhat #> beta[.trtVaccinated:latitude]     -0.01  1950    1 #> d[Vaccinated]                     -0.53  1974    1 #> lp__                          -13533.59   771    1 #> tau                                0.70   876    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:33:14 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(bcg_fit_lat, pars = c(\"d\", \"beta\", \"mu\", \"delta\", \"tau\")) plot_prior_posterior(bcg_fit_lat, prior = c(\"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: BCG vaccine for tuberculosis","text":"Model fit can checked using dic() function: DIC similar two models, might first choose unadjusted model. posterior mean residual deviance larger model covariate, model also lower effective number parameters \\(p_D\\) allowing shrinkage random treatment effects. Moreover, model covariate much lower estimated heterogeneity standard deviation: Adjusting latitude explaining substantial amount heterogeneity data. 95% Credible Interval regression coefficient also excludes zero:  Altogether, might prefer model adjustment latitude. considering covariates random effects models important just look DIC (Dias et al. 2011). also consider reductions heterogeneity, estimated regression coefficients standard error. DIC sensitive changes heterogeneity, RE models flexible can fit data well whatever level heterogeneity.","code":"(bcg_dic_unadj <- dic(bcg_fit_unadj)) #> Residual deviance: 25.8 (on 26 data points) #>                pD: 23.3 #>               DIC: 49.1 (bcg_dic_lat <- dic(bcg_fit_lat)) #> Residual deviance: 30.7 (on 26 data points) #>                pD: 21.3 #>               DIC: 52.1 summary(bcg_fit_unadj, pars = \"tau\") #>     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau 0.69 0.21 0.39 0.54 0.65 0.79  1.17     1110     1720    1 summary(bcg_fit_lat, pars = \"tau\") #>     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau 0.29 0.18 0.03 0.16 0.26 0.39   0.7      785     1201    1 summary(bcg_fit_lat, pars = \"beta\") #>                                mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> beta[.trtVaccinated:latitude] -0.03 0.01 -0.05 -0.04 -0.03 -0.03 -0.01     2007     2047    1  plot(bcg_fit_lat,       pars = \"beta\",       ref_line = 0,      stat = \"halfeye\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: BCG vaccine for tuberculosis","text":"can produce estimates relative effect vaccination latitude using relative_effects() function. newdata argument specifies data frame containing values covariate latitude interested , study argument used specify column newdata informative label. plot() method may used visually compare estimates:  sophisticated plot shows regression line confidence band effect latitude, overlaid observed log odds ratios study:  presence heterogeneity, argued decision makers consider predictive distribution relative effects new study, instead posterior distribution mean treatment effects, reflects uncertainty due heterogeneity may better represent uncertainty future roll-treatment (see Dias et al. 2011). can produce predictive distributions using predictive_distribution = TRUE argument relative_effects(). Dias et al. (2018, sec. 8.3.2) consider predictive distributions BCG vaccine analysis. unadjusted analysis, whilst substantial evidence vaccination effective average essentially zero probability harm based mean effect, predictive distribution effectiveness new study wide covers range harmful effects: predictive probability new trial showing harmful effect : analysis adjusting latitude, predictive distribution relative effects now depends latitude; calculate increments 10 degrees equator: predictive probabilities new trial carried given latitude showing harmful effect can calculated : predictive probability new trial carried equator shows harmful effect around 80%, whereas 50 degrees latitude predictive probability 0.7%.","code":"bcg_releff_lat <- relative_effects(bcg_fit_lat,                                    newdata = tibble::tibble(latitude = seq(10, 50, by = 10),                                                             label = paste0(latitude, \"\\u00B0 latitude\")),                                    study = label)  bcg_releff_lat #> ----------------------------------------------------------- Study: 10° latitude ----  #>  #> Covariate values: #>  latitude #>        10 #>  #>                              mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[10° latitude: Vaccinated] -0.01 0.21 -0.46 -0.12 0.01 0.11  0.38     1925     1977    1 #>  #> ----------------------------------------------------------- Study: 20° latitude ----  #>  #> Covariate values: #>  latitude #>        20 #>  #>                              mean   sd  2.5%  25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[20° latitude: Vaccinated] -0.33 0.15 -0.65 -0.4 -0.32 -0.24 -0.06     1927     2103    1 #>  #> ----------------------------------------------------------- Study: 30° latitude ----  #>  #> Covariate values: #>  latitude #>        30 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[30° latitude: Vaccinated] -0.65 0.12 -0.91 -0.71 -0.64 -0.58 -0.43     2002     2155    1 #>  #> ----------------------------------------------------------- Study: 40° latitude ----  #>  #> Covariate values: #>  latitude #>        40 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[40° latitude: Vaccinated] -0.97 0.13 -1.25 -1.04 -0.96 -0.89  -0.7     2122     2097    1 #>  #> ----------------------------------------------------------- Study: 50° latitude ----  #>  #> Covariate values: #>  latitude #>        50 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[50° latitude: Vaccinated] -1.28 0.19 -1.66 -1.39 -1.28 -1.18 -0.91     2128     2153    1 plot(bcg_releff_lat,       ref_line = 0) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2)  # Get data for regression line lat_range <- range(bcg_vaccine$latitude) lat_dat <- tibble(latitude = seq(lat_range[1], lat_range[2], by = 1))  bcg_lat_reg <- relative_effects(bcg_fit_lat,                                  newdata = lat_dat) %>%    as_tibble() %>%    bind_cols(lat_dat)  # Get study log odds ratios bcg_lor <- bcg_vaccine %>%    group_by(studyn) %>%    mutate(lor = log(r / (n - r)) - log(first(r) / (first(n) - first(r))),          sample_size = sum(n)) %>%    slice(-1)  # Plot ggplot(aes(x = latitude), data = bcg_lor) +   geom_hline(yintercept = 0, colour = \"grey60\") +   geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), data = bcg_lat_reg,               fill = \"darkred\", alpha = 0.3) +   geom_line(aes(y = mean), data = bcg_lat_reg,             colour = \"darkred\") +   geom_point(aes(y = lor, size = sample_size), alpha = 0.6) +   coord_cartesian(xlim = c(0, 60)) +   xlab(\"Degrees Latitude\") + ylab(\"log Odds Ratio\") +   scale_size(\"Sample Size\") +   theme_multinma() (bcg_predeff_unadj <- relative_effects(bcg_fit_unadj, predictive_distribution = TRUE)) #>                        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> delta_new[Vaccinated] -0.78 0.75 -2.32 -1.22 -0.78 -0.31  0.72     3378     3143    1 mean(as.matrix(bcg_predeff_unadj) > 0) #> [1] 0.128 bcg_predeff_lat <- relative_effects(bcg_fit_lat,                                    newdata = tibble::tibble(latitude = seq(0, 50, by = 10),                                                             label = paste0(latitude, \"\\u00B0 latitude\")),                                    study = label,                                    predictive_distribution = TRUE)  bcg_predeff_lat #> ------------------------------------------------------------ Study: 0° latitude ----  #>  #> Covariate values: #>  latitude #>         0 #>  #>                                    mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> delta_new[0° latitude: Vaccinated]  0.3 0.44 -0.68 0.09 0.33 0.53  1.19     2971     2904    1 #>  #> ----------------------------------------------------------- Study: 10° latitude ----  #>  #> Covariate values: #>  latitude #>        10 #>  #>                                      mean  sd  2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> delta_new[10° latitude: Vaccinated] -0.01 0.4 -0.89 -0.2 0.01 0.19  0.78     3260     3093 #>                                     Rhat #> delta_new[10° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 20° latitude ----  #>  #> Covariate values: #>  latitude #>        20 #>  #>                                      mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[20° latitude: Vaccinated] -0.33 0.37 -1.16 -0.51 -0.31 -0.15   0.4     3556     3350 #>                                     Rhat #> delta_new[20° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 30° latitude ----  #>  #> Covariate values: #>  latitude #>        30 #>  #>                                      mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[30° latitude: Vaccinated] -0.65 0.35 -1.43 -0.82 -0.63 -0.48  0.07     3727     3353 #>                                     Rhat #> delta_new[30° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 40° latitude ----  #>  #> Covariate values: #>  latitude #>        40 #>  #>                                      mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[40° latitude: Vaccinated] -0.97 0.35 -1.73 -1.14 -0.95 -0.79 -0.23     3638     3533 #>                                     Rhat #> delta_new[40° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 50° latitude ----  #>  #> Covariate values: #>  latitude #>        50 #>  #>                                      mean   sd 2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS #> delta_new[50° latitude: Vaccinated] -1.29 0.38 -2.1 -1.47 -1.28 -1.1 -0.52     3313     3132 #>                                     Rhat #> delta_new[50° latitude: Vaccinated]    1 colMeans(as.matrix(bcg_predeff_lat) > 0) #>  delta_new[0° latitude: Vaccinated] delta_new[10° latitude: Vaccinated]  #>                             0.81200                             0.51925  #> delta_new[20° latitude: Vaccinated] delta_new[30° latitude: Vaccinated]  #>                             0.12950                             0.03075  #> delta_new[40° latitude: Vaccinated] delta_new[50° latitude: Vaccinated]  #>                             0.01075                             0.00500"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Beta blockers","text":"begin setting network - just pairwise meta-analysis. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). set “Control” reference treatment.","code":"blocker_net <- set_agd_arm(blocker,                             study = studyn,                            trt = trtc,                            r = r,                             n = n,                            trt_ref = \"Control\") blocker_net #> A network with 22 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms            #>  1     2: Control | Beta Blocker #>  2     2: Control | Beta Blocker #>  3     2: Control | Beta Blocker #>  4     2: Control | Beta Blocker #>  5     2: Control | Beta Blocker #>  6     2: Control | Beta Blocker #>  7     2: Control | Beta Blocker #>  8     2: Control | Beta Blocker #>  9     2: Control | Beta Blocker #>  10    2: Control | Beta Blocker #>  ... plus 12 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 22 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Beta blockers","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Beta blockers","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. blocker_fit_FE <- nma(blocker_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) blocker_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                     mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff Rhat #> d[Beta Blocker]    -0.26    0.00 0.05    -0.36    -0.29    -0.26    -0.23    -0.16  3601    1 #> lp__            -6087.45    0.09 3.33 -6094.80 -6089.59 -6087.10 -6085.06 -6081.85  1501    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:33:36 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(blocker_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(blocker_fit_FE, prior = \"trt\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Beta blockers","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. blocker_fit_RE <- nma(blocker_net,                     trt_effects = \"random\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_het = half_normal(scale = 5)) blocker_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                     mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff Rhat #> d[Beta Blocker]    -0.25    0.00 0.07    -0.37    -0.29    -0.25    -0.21    -0.12  2774    1 #> lp__            -6100.25    0.17 5.49 -6111.95 -6103.85 -6099.81 -6096.44 -6090.37  1000    1 #> tau                 0.13    0.00 0.08     0.01     0.07     0.13     0.18     0.32   895    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:33:45 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(blocker_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(blocker_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Beta blockers","text":"Model fit can checked using dic() function: residual deviance lower RE model, expected model flexible. However, comes increased effective number parameters (note increase \\(p_D\\)). result, DIC models similar FE model may preferred parsimony. can also examine residual deviance contributions corresponding plot() method.   number points well fit FE model, posterior mean residual deviance contributions greater 1. Study 14 particularly poor fit FE model, residual deviance reduced (although still high) RE model. evidence given careful examination, consideration given issues potential effect-modifying covariates (Dias et al. 2011).","code":"(dic_FE <- dic(blocker_fit_FE)) #> Residual deviance: 46.8 (on 44 data points) #>                pD: 23.2 #>               DIC: 70 (dic_RE <- dic(blocker_fit_RE)) #> Residual deviance: 41.9 (on 44 data points) #>                pD: 28.1 #>               DIC: 70 plot(dic_FE) plot(dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Beta blockers","text":"Dias et al. (2011) produce absolute predictions probability mortality beta blockers control, assuming Normal distribution baseline logit-probability mortality mean \\(-2.2\\) precision \\(3.3\\). can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted probabilities (type = \"link\" produce predicted log odds).   instead information baseline logit-probability mortality event counts, can use construct Beta distribution baseline probability mortality. example, 4 36 individuals died control treatment target population interest, appropriate Beta distribution probability \\(\\textrm{Beta}(4, 36-4)\\). can specify Beta distribution baseline response using baseline_type = \"reponse\" argument (default \"link\", used baseline logit-probability).   Notice results nearly equivalent calculated using Normal distribution baseline logit-probability, since event counts correspond approximately distribution logit-probability.","code":"pred_FE <- predict(blocker_fit_FE,                     baseline = distr(qnorm, mean = -2.2, sd = 3.3^-0.5),                     type = \"response\") pred_FE #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.04 0.07 0.10 0.14  0.24     3788     3933    1 #> pred[Beta Blocker] 0.09 0.05 0.03 0.06 0.08 0.11  0.20     3747     3853    1 plot(pred_FE) pred_RE <- predict(blocker_fit_RE,                     baseline = distr(qnorm, mean = -2.2, sd = 3.3^-0.5),                     type = \"response\") pred_RE #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.04 0.07 0.10 0.14  0.24     4078     4062    1 #> pred[Beta Blocker] 0.09 0.05 0.03 0.06 0.08 0.11  0.20     4046     4082    1 plot(pred_RE) pred_FE_beta <- predict(blocker_fit_FE,                          baseline = distr(qbeta, 4, 36-4),                         baseline_type = \"response\",                         type = \"response\") pred_FE_beta #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.03 0.07 0.10 0.14  0.23     4028     3799    1 #> pred[Beta Blocker] 0.09 0.04 0.03 0.06 0.08 0.11  0.19     4029     3863    1 plot(pred_FE_beta) pred_RE_beta <- predict(blocker_fit_RE,                          baseline = distr(qbeta, 4, 36-4),                         baseline_type = \"response\",                         type = \"response\") pred_RE_beta #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.03 0.07 0.10 0.14  0.22     3973     3906    1 #> pred[Beta Blocker] 0.09 0.04 0.02 0.06 0.08 0.11  0.19     3997     3813    1 plot(pred_RE_beta)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Diabetes","text":"begin setting network. arm-level count data giving number new cases diabetes (r) total (n) arm, use function set_agd_arm(). computational efficiency, let “Beta Blocker” set network reference treatment default. Elliott Meyer (2007) Dias et al. (2011) use “Diuretic” reference, simple matter transform results fitting NMA model.1 also details length follow-years trial (time), use offset cloglog link function model data rates. specify function set_agd_arm(): additional columns data (e.g. offsets covariates, column time) automatically made available network. Plot network structure.","code":"db_net <- set_agd_arm(diabetes,                        study = studyc,                       trt = trtc,                       r = r,                        n = n) db_net #> A network with 22 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study  Treatment arms                        #>  AASK   3: Beta Blocker | ACE Inhibitor | CCB #>  ALLHAT 3: ACE Inhibitor | CCB | Diuretic     #>  ALPINE 2: ARB | Diuretic                     #>  ANBP-2 2: ACE Inhibitor | Diuretic           #>  ASCOT  2: Beta Blocker | CCB                 #>  CAPPP  2: Beta Blocker | ACE Inhibitor       #>  CHARM  2: ARB | Placebo                      #>  DREAM  2: ACE Inhibitor | Placebo            #>  EWPH   2: Diuretic | Placebo                 #>  FEVER  2: CCB | Placebo                      #>  ... plus 12 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6 #> Total number of studies: 22 #> Reference treatment is: Beta Blocker #> Network is connected plot(db_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Diabetes","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Diabetes","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. specify cloglog link used link = \"cloglog\" (Binomial likelihood default data), specify log follow-time offset using regression formula regression = ~offset(log(time)). Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. db_fit_FE <- nma(db_net,                   trt_effects = \"fixed\",                  link = \"cloglog\",                  regression = ~offset(log(time)),                  prior_intercept = normal(scale = 100),                  prior_trt = normal(scale = 100)) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. #> Note: Setting \"Beta Blocker\" as the network reference treatment. db_fit_FE #> A fixed effects NMA with a binomial likelihood (cloglog link). #> Regression model: ~offset(log(time)). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                       mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[ACE Inhibitor]     -0.30    0.00 0.05     -0.39     -0.33     -0.30     -0.27     -0.21 #> d[ARB]               -0.39    0.00 0.05     -0.49     -0.43     -0.39     -0.36     -0.31 #> d[CCB]               -0.20    0.00 0.03     -0.26     -0.22     -0.20     -0.18     -0.13 #> d[Diuretic]           0.06    0.00 0.05     -0.05      0.02      0.06      0.09      0.16 #> d[Placebo]           -0.19    0.00 0.05     -0.29     -0.22     -0.19     -0.15     -0.09 #> lp__             -38119.43    0.09 3.71 -38127.59 -38121.75 -38119.14 -38116.84 -38113.15 #>                  n_eff Rhat #> d[ACE Inhibitor]  1669    1 #> d[ARB]            2404    1 #> d[CCB]            2265    1 #> d[Diuretic]       1904    1 #> d[Placebo]        1636    1 #> lp__              1768    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:34:09 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(db_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(db_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Diabetes","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. db_fit_RE <- nma(db_net,                   trt_effects = \"random\",                  link = \"cloglog\",                  regression = ~offset(log(time)),                  prior_intercept = normal(scale = 10),                  prior_trt = normal(scale = 10),                  prior_het = half_normal(scale = 5),                  init_r = 0.5) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. #> Note: Setting \"Beta Blocker\" as the network reference treatment. db_fit_RE #> A random effects NMA with a binomial likelihood (cloglog link). #> Regression model: ~offset(log(time)). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                       mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[ACE Inhibitor]     -0.33    0.00 0.08     -0.49     -0.38     -0.32     -0.28     -0.18 #> d[ARB]               -0.40    0.00 0.10     -0.61     -0.46     -0.40     -0.34     -0.21 #> d[CCB]               -0.17    0.00 0.07     -0.30     -0.21     -0.17     -0.13     -0.04 #> d[Diuretic]           0.07    0.00 0.09     -0.11      0.01      0.07      0.13      0.25 #> d[Placebo]           -0.22    0.00 0.09     -0.40     -0.27     -0.21     -0.16     -0.05 #> lp__             -38070.08    0.22 6.62 -38083.86 -38074.37 -38069.82 -38065.46 -38057.99 #> tau                   0.13    0.00 0.05      0.05      0.10      0.13      0.16      0.23 #>                  n_eff Rhat #> d[ACE Inhibitor]  1907    1 #> d[ARB]            2117    1 #> d[CCB]            1964    1 #> d[Diuretic]       1770    1 #> d[Placebo]        1590    1 #> lp__               917    1 #> tau                986    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:34:33 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(db_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(db_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Diabetes","text":"Model fit can checked using dic() function: FE model poor fit data, residual deviance much higher number data points. RE model fits data better, much lower DIC; prefer RE model. can also examine residual deviance contributions corresponding plot() method.","code":"(dic_FE <- dic(db_fit_FE)) #> Residual deviance: 78.2 (on 48 data points) #>                pD: 27 #>               DIC: 105.1 (dic_RE <- dic(db_fit_RE)) #> Residual deviance: 53.2 (on 48 data points) #>                pD: 37.9 #>               DIC: 91.1 plot(dic_FE) plot(dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Diabetes","text":"comparison Elliott Meyer (2007) Dias et al. (2011), can produce relative effects “Diuretic” using relative_effects() function trt_ref = \"Diuretic\":   Dias et al. (2011) produce absolute predictions probability developing diabetes three years, assuming Normal distribution baseline cloglog probability developing diabetes diuretic treatment mean \\(-4.2\\) precision \\(1.11\\). can replicate results using predict() method. specify data frame newdata, containing time offset(s) produce predictions (3 years). baseline argument takes distr() distribution object specify corresponding Normal distribution baseline cloglog probability, set trt_ref = \"Diuretic\" indicate baseline distribution corresponds “Diuretic” rather network reference “Beta Blocker”. set type = \"response\" produce predicted event probabilities (type = \"link\" produce predicted cloglog probabilities).   baseline newdata arguments omitted, predicted probabilities produced every study network based follow-times estimated baseline cloglog probabilities \\(\\mu_j\\):  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(db_releff_FE <- relative_effects(db_fit_FE, trt_ref = \"Diuretic\")) #>                   mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Beta Blocker]  -0.06 0.05 -0.16 -0.09 -0.06 -0.02  0.05     1920     2587    1 #> d[ACE Inhibitor] -0.36 0.05 -0.46 -0.39 -0.36 -0.32 -0.26     4871     3719    1 #> d[ARB]           -0.45 0.06 -0.57 -0.49 -0.45 -0.41 -0.33     3966     2870    1 #> d[CCB]           -0.25 0.05 -0.36 -0.29 -0.25 -0.22 -0.15     3251     3061    1 #> d[Placebo]       -0.25 0.05 -0.35 -0.28 -0.25 -0.21 -0.14     4399     3407    1 plot(db_releff_FE, ref_line = 0) (db_releff_RE <- relative_effects(db_fit_RE, trt_ref = \"Diuretic\")) #>                   mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Beta Blocker]  -0.07 0.09 -0.25 -0.13 -0.07 -0.01  0.11     1809     2473    1 #> d[ACE Inhibitor] -0.40 0.09 -0.58 -0.46 -0.40 -0.35 -0.23     4245     2829    1 #> d[ARB]           -0.47 0.11 -0.71 -0.54 -0.47 -0.40 -0.26     3694     2503    1 #> d[CCB]           -0.24 0.09 -0.41 -0.30 -0.24 -0.19 -0.07     4383     3290    1 #> d[Placebo]       -0.29 0.09 -0.49 -0.35 -0.29 -0.23 -0.12     3804     2726    1 plot(db_releff_RE, ref_line = 0) db_pred_FE <- predict(db_fit_FE,                        newdata = data.frame(time = 3),                       baseline = distr(qnorm, mean = -4.2, sd = 1.11^-0.5),                        trt_ref = \"Diuretic\",                       type = \"response\") db_pred_FE #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: Beta Blocker]  0.06 0.06 0.01 0.02 0.04 0.08  0.23     4188     3892    1 #> pred[New 1: ACE Inhibitor] 0.05 0.05 0.01 0.02 0.03 0.06  0.18     4201     3973    1 #> pred[New 1: ARB]           0.04 0.04 0.00 0.02 0.03 0.05  0.16     4199     3853    1 #> pred[New 1: CCB]           0.05 0.05 0.01 0.02 0.03 0.06  0.19     4189     3892    1 #> pred[New 1: Diuretic]      0.06 0.06 0.01 0.02 0.04 0.08  0.24     4191     3892    1 #> pred[New 1: Placebo]       0.05 0.05 0.01 0.02 0.03 0.06  0.19     4192     3892    1 plot(db_pred_FE) db_pred_RE <- predict(db_fit_RE,                        newdata = data.frame(time = 3),                       baseline = distr(qnorm, mean = -4.2, sd = 1.11^-0.5),                        trt_ref = \"Diuretic\",                       type = \"response\") db_pred_RE #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: Beta Blocker]  0.06 0.07 0.01 0.02 0.04 0.08  0.25     3964     3809    1 #> pred[New 1: ACE Inhibitor] 0.05 0.05 0.00 0.02 0.03 0.06  0.18     3984     3871    1 #> pred[New 1: ARB]           0.04 0.05 0.00 0.01 0.03 0.05  0.17     3971     3731    1 #> pred[New 1: CCB]           0.05 0.06 0.01 0.02 0.03 0.07  0.21     4007     3729    1 #> pred[New 1: Diuretic]      0.07 0.07 0.01 0.02 0.04 0.08  0.26     3997     3651    1 #> pred[New 1: Placebo]       0.05 0.06 0.00 0.02 0.03 0.06  0.20     3981     3723    1 plot(db_pred_RE) db_pred_RE_studies <- predict(db_fit_RE, type = \"response\") db_pred_RE_studies #> ------------------------------------------------------------------- Study: AASK ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[AASK: Beta Blocker]  0.17 0.01 0.14 0.16 0.17 0.18  0.20     5721     3000    1 #> pred[AASK: ACE Inhibitor] 0.12 0.01 0.10 0.12 0.12 0.13  0.15     4141     3178    1 #> pred[AASK: ARB]           0.12 0.01 0.09 0.11 0.12 0.13  0.15     4020     2727    1 #> pred[AASK: CCB]           0.14 0.01 0.12 0.13 0.14 0.15  0.17     5197     3245    1 #> pred[AASK: Diuretic]      0.18 0.02 0.14 0.17 0.18 0.19  0.22     4033     3214    1 #> pred[AASK: Placebo]       0.14 0.02 0.11 0.13 0.14 0.15  0.17     3656     3272    1 #>  #> ----------------------------------------------------------------- Study: ALLHAT ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ALLHAT: Beta Blocker]  0.04 0.01 0.03 0.04 0.04 0.05  0.06     3126     2478    1 #> pred[ALLHAT: ACE Inhibitor] 0.03 0.00 0.02 0.03 0.03 0.03  0.04     4716     2475    1 #> pred[ALLHAT: ARB]           0.03 0.00 0.02 0.03 0.03 0.03  0.04     4165     2815    1 #> pred[ALLHAT: CCB]           0.04 0.00 0.03 0.03 0.04 0.04  0.05     4525     2754    1 #> pred[ALLHAT: Diuretic]      0.05 0.01 0.04 0.04 0.05 0.05  0.06     4704     2823    1 #> pred[ALLHAT: Placebo]       0.03 0.00 0.03 0.03 0.03 0.04  0.04     3988     2697    1 #>  #> ----------------------------------------------------------------- Study: ALPINE ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ALPINE: Beta Blocker]  0.03 0.01 0.01 0.02 0.03 0.03  0.05     6244     2580    1 #> pred[ALPINE: ACE Inhibitor] 0.02 0.01 0.01 0.01 0.02 0.02  0.04     7133     2858    1 #> pred[ALPINE: ARB]           0.02 0.01 0.01 0.01 0.02 0.02  0.03     7008     2671    1 #> pred[ALPINE: CCB]           0.02 0.01 0.01 0.02 0.02 0.03  0.04     7049     2850    1 #> pred[ALPINE: Diuretic]      0.03 0.01 0.01 0.02 0.03 0.03  0.05     7439     2683    1 #> pred[ALPINE: Placebo]       0.02 0.01 0.01 0.02 0.02 0.03  0.04     7201     2749    1 #>  #> ----------------------------------------------------------------- Study: ANBP-2 ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ANBP-2: Beta Blocker]  0.07 0.01 0.05 0.06 0.07 0.07  0.09     3193     2691    1 #> pred[ANBP-2: ACE Inhibitor] 0.05 0.01 0.04 0.04 0.05 0.05  0.06     4791     2744    1 #> pred[ANBP-2: ARB]           0.05 0.01 0.03 0.04 0.05 0.05  0.06     4523     2877    1 #> pred[ANBP-2: CCB]           0.06 0.01 0.04 0.05 0.06 0.06  0.08     4447     2922    1 #> pred[ANBP-2: Diuretic]      0.07 0.01 0.06 0.07 0.07 0.08  0.09     4783     2424    1 #> pred[ANBP-2: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     4872     3022    1 #>  #> ------------------------------------------------------------------ Study: ASCOT ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ASCOT: Beta Blocker]  0.11 0.00 0.10 0.11 0.11 0.11  0.12     5065     2934    1 #> pred[ASCOT: ACE Inhibitor] 0.08 0.01 0.07 0.08 0.08 0.09  0.10     2331     3051    1 #> pred[ASCOT: ARB]           0.08 0.01 0.06 0.07 0.08 0.08  0.09     2520     2590    1 #> pred[ASCOT: CCB]           0.10 0.01 0.08 0.09 0.10 0.10  0.11     2381     2689    1 #> pred[ASCOT: Diuretic]      0.12 0.01 0.10 0.11 0.12 0.13  0.14     2030     2560    1 #> pred[ASCOT: Placebo]       0.09 0.01 0.08 0.09 0.09 0.10  0.11     1919     2428    1 #>  #> ------------------------------------------------------------------ Study: CAPPP ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[CAPPP: Beta Blocker]  0.07 0.00 0.07 0.07 0.07 0.08  0.08     5372     2985    1 #> pred[CAPPP: ACE Inhibitor] 0.05 0.00 0.05 0.05 0.05 0.06  0.06     2114     2411    1 #> pred[CAPPP: ARB]           0.05 0.01 0.04 0.05 0.05 0.05  0.06     2486     2486    1 #> pred[CAPPP: CCB]           0.06 0.00 0.05 0.06 0.06 0.07  0.07     2761     2508    1 #> pred[CAPPP: Diuretic]      0.08 0.01 0.07 0.08 0.08 0.09  0.10     2291     2904    1 #> pred[CAPPP: Placebo]       0.06 0.01 0.05 0.06 0.06 0.06  0.07     1952     2535    1 #>  #> ------------------------------------------------------------------ Study: CHARM ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[CHARM: Beta Blocker]  0.09 0.01 0.07 0.08 0.09 0.10  0.12     3051     2394    1 #> pred[CHARM: ACE Inhibitor] 0.07 0.01 0.05 0.06 0.07 0.07  0.09     4525     2808    1 #> pred[CHARM: ARB]           0.06 0.01 0.05 0.06 0.06 0.07  0.08     4989     2601    1 #> pred[CHARM: CCB]           0.08 0.01 0.06 0.07 0.08 0.08  0.10     4287     2537    1 #> pred[CHARM: Diuretic]      0.10 0.02 0.07 0.09 0.10 0.11  0.13     4619     2494    1 #> pred[CHARM: Placebo]       0.07 0.01 0.06 0.07 0.07 0.08  0.09     4983     2538    1 #>  #> ------------------------------------------------------------------ Study: DREAM ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[DREAM: Beta Blocker]  0.23 0.03 0.18 0.21 0.23 0.25  0.29     2687     2385    1 #> pred[DREAM: ACE Inhibitor] 0.17 0.02 0.13 0.16 0.17 0.18  0.22     4099     2619    1 #> pred[DREAM: ARB]           0.16 0.02 0.12 0.14 0.16 0.17  0.21     4052     2722    1 #> pred[DREAM: CCB]           0.20 0.03 0.15 0.18 0.19 0.21  0.26     3697     2392    1 #> pred[DREAM: Diuretic]      0.24 0.03 0.19 0.22 0.24 0.26  0.32     4213     2561    1 #> pred[DREAM: Placebo]       0.19 0.02 0.15 0.17 0.19 0.20  0.24     4589     2610    1 #>  #> ------------------------------------------------------------------- Study: EWPH ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[EWPH: Beta Blocker]  0.06 0.01 0.04 0.05 0.06 0.07  0.09     4766     3032    1 #> pred[EWPH: ACE Inhibitor] 0.05 0.01 0.03 0.04 0.04 0.05  0.07     5701     3155    1 #> pred[EWPH: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     5421     3122    1 #> pred[EWPH: CCB]           0.05 0.01 0.04 0.05 0.05 0.06  0.08     5754     3102    1 #> pred[EWPH: Diuretic]      0.07 0.01 0.05 0.06 0.07 0.07  0.10     5887     2764    1 #> pred[EWPH: Placebo]       0.05 0.01 0.03 0.04 0.05 0.06  0.07     5672     3081    1 #>  #> ------------------------------------------------------------------ Study: FEVER ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[FEVER: Beta Blocker]  0.04 0.01 0.03 0.04 0.04 0.05  0.06     2971     2556    1 #> pred[FEVER: ACE Inhibitor] 0.03 0.00 0.02 0.03 0.03 0.03  0.04     4217     2554    1 #> pred[FEVER: ARB]           0.03 0.00 0.02 0.03 0.03 0.03  0.04     4390     2856    1 #> pred[FEVER: CCB]           0.04 0.00 0.03 0.03 0.03 0.04  0.05     4497     2744    1 #> pred[FEVER: Diuretic]      0.04 0.01 0.03 0.04 0.04 0.05  0.06     4409     3022    1 #> pred[FEVER: Placebo]       0.03 0.00 0.03 0.03 0.03 0.04  0.04     4691     2658    1 #>  #> ----------------------------------------------------------------- Study: HAPPHY ----  #>  #>                             mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[HAPPHY: Beta Blocker]  0.02  0 0.02 0.02 0.02 0.03  0.03     5817     3411    1 #> pred[HAPPHY: ACE Inhibitor] 0.02  0 0.01 0.02 0.02 0.02  0.02     4313     3174    1 #> pred[HAPPHY: ARB]           0.02  0 0.01 0.02 0.02 0.02  0.02     4122     3144    1 #> pred[HAPPHY: CCB]           0.02  0 0.02 0.02 0.02 0.02  0.03     4654     3214    1 #> pred[HAPPHY: Diuretic]      0.03  0 0.02 0.02 0.03 0.03  0.03     3312     2576    1 #> pred[HAPPHY: Placebo]       0.02  0 0.02 0.02 0.02 0.02  0.02     3664     2865    1 #>  #> ------------------------------------------------------------------- Study: HOPE ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[HOPE: Beta Blocker]  0.06 0.01 0.04 0.05 0.06 0.06  0.08     2884     2420    1 #> pred[HOPE: ACE Inhibitor] 0.04 0.01 0.03 0.04 0.04 0.05  0.06     4293     2718    1 #> pred[HOPE: ARB]           0.04 0.01 0.03 0.04 0.04 0.04  0.05     4277     2393    1 #> pred[HOPE: CCB]           0.05 0.01 0.04 0.04 0.05 0.05  0.07     3976     2584    1 #> pred[HOPE: Diuretic]      0.06 0.01 0.05 0.06 0.06 0.07  0.08     4184     2871    1 #> pred[HOPE: Placebo]       0.05 0.01 0.04 0.04 0.05 0.05  0.06     4428     2316    1 #>  #> ---------------------------------------------------------------- Study: INSIGHT ----  #>  #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[INSIGHT: Beta Blocker]  0.07 0.01 0.05 0.06 0.06 0.07  0.08     2973     1967    1 #> pred[INSIGHT: ACE Inhibitor] 0.05 0.01 0.03 0.04 0.05 0.05  0.06     4135     2121    1 #> pred[INSIGHT: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     3947     2533    1 #> pred[INSIGHT: CCB]           0.06 0.01 0.04 0.05 0.05 0.06  0.07     4356     2543    1 #> pred[INSIGHT: Diuretic]      0.07 0.01 0.05 0.06 0.07 0.08  0.09     4525     2574    1 #> pred[INSIGHT: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     4152     2118    1 #>  #> ----------------------------------------------------------------- Study: INVEST ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[INVEST: Beta Blocker]  0.08 0.00 0.08 0.08 0.08 0.08  0.09     6700     2451    1 #> pred[INVEST: ACE Inhibitor] 0.06 0.00 0.05 0.06 0.06 0.06  0.07     2304     2632    1 #> pred[INVEST: ARB]           0.06 0.01 0.05 0.05 0.06 0.06  0.07     2464     2542    1 #> pred[INVEST: CCB]           0.07 0.00 0.06 0.07 0.07 0.07  0.08     2448     2584    1 #> pred[INVEST: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.09  0.11     2091     2810    1 #> pred[INVEST: Placebo]       0.07 0.01 0.06 0.06 0.07 0.07  0.08     1910     2426    1 #>  #> ------------------------------------------------------------------- Study: LIFE ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[LIFE: Beta Blocker]  0.08 0.00 0.07 0.08 0.08 0.08  0.09     6297     2964    1 #> pred[LIFE: ACE Inhibitor] 0.06 0.01 0.05 0.06 0.06 0.06  0.07     2713     2754    1 #> pred[LIFE: ARB]           0.06 0.01 0.04 0.05 0.06 0.06  0.07     2526     2678    1 #> pred[LIFE: CCB]           0.07 0.01 0.06 0.07 0.07 0.07  0.08     3487     2874    1 #> pred[LIFE: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.09  0.11     2743     3038    1 #> pred[LIFE: Placebo]       0.07 0.01 0.05 0.06 0.07 0.07  0.08     2154     2464    1 #>  #> ------------------------------------------------------------------ Study: MRC-E ----  #>  #>                            mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[MRC-E: Beta Blocker]  0.03  0 0.02 0.03 0.03 0.03  0.04     4472     2873    1 #> pred[MRC-E: ACE Inhibitor] 0.02  0 0.02 0.02 0.02 0.02  0.03     6043     3141    1 #> pred[MRC-E: ARB]           0.02  0 0.01 0.02 0.02 0.02  0.03     5041     2923    1 #> pred[MRC-E: CCB]           0.03  0 0.02 0.02 0.02 0.03  0.03     5341     3041    1 #> pred[MRC-E: Diuretic]      0.03  0 0.02 0.03 0.03 0.03  0.04     5127     3069    1 #> pred[MRC-E: Placebo]       0.02  0 0.02 0.02 0.02 0.03  0.03     5153     2709    1 #>  #> ----------------------------------------------------------------- Study: NORDIL ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[NORDIL: Beta Blocker]  0.05 0.00 0.04 0.05 0.05 0.05  0.06     5710     3370    1 #> pred[NORDIL: ACE Inhibitor] 0.04 0.00 0.03 0.03 0.04 0.04  0.04     2740     2743    1 #> pred[NORDIL: ARB]           0.03 0.00 0.03 0.03 0.03 0.04  0.04     2513     2580    1 #> pred[NORDIL: CCB]           0.04 0.00 0.04 0.04 0.04 0.04  0.05     3031     2973    1 #> pred[NORDIL: Diuretic]      0.05 0.01 0.04 0.05 0.05 0.06  0.07     2481     2362    1 #> pred[NORDIL: Placebo]       0.04 0.00 0.03 0.04 0.04 0.04  0.05     2166     2630    1 #>  #> ------------------------------------------------------------------ Study: PEACE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[PEACE: Beta Blocker]  0.14 0.02 0.10 0.13 0.14 0.15  0.18     2634     2190    1 #> pred[PEACE: ACE Inhibitor] 0.10 0.01 0.08 0.09 0.10 0.11  0.13     4115     2496    1 #> pred[PEACE: ARB]           0.10 0.01 0.07 0.09 0.09 0.10  0.13     3829     2350    1 #> pred[PEACE: CCB]           0.12 0.02 0.09 0.11 0.12 0.13  0.16     3554     2465    1 #> pred[PEACE: Diuretic]      0.15 0.02 0.11 0.13 0.15 0.16  0.20     3857     2693    1 #> pred[PEACE: Placebo]       0.11 0.01 0.09 0.10 0.11 0.12  0.14     4373     2515    1 #>  #> ------------------------------------------------------------------ Study: SCOPE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[SCOPE: Beta Blocker]  0.06 0.01 0.05 0.06 0.06 0.07  0.09     2758     2417    1 #> pred[SCOPE: ACE Inhibitor] 0.05 0.01 0.03 0.04 0.05 0.05  0.06     4332     2435    1 #> pred[SCOPE: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     3811     2766    1 #> pred[SCOPE: CCB]           0.06 0.01 0.04 0.05 0.05 0.06  0.08     3856     2255    1 #> pred[SCOPE: Diuretic]      0.07 0.01 0.05 0.06 0.07 0.08  0.10     4167     2509    1 #> pred[SCOPE: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     4335     2576    1 #>  #> ------------------------------------------------------------------- Study: SHEP ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[SHEP: Beta Blocker]  0.09 0.01 0.06 0.08 0.09 0.09  0.12     2650     2549    1 #> pred[SHEP: ACE Inhibitor] 0.06 0.01 0.05 0.06 0.06 0.07  0.08     4280     2610    1 #> pred[SHEP: ARB]           0.06 0.01 0.04 0.05 0.06 0.06  0.08     4039     2729    1 #> pred[SHEP: CCB]           0.07 0.01 0.05 0.07 0.07 0.08  0.10     4101     2278    1 #> pred[SHEP: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.10  0.12     4710     2722    1 #> pred[SHEP: Placebo]       0.07 0.01 0.05 0.06 0.07 0.08  0.09     4343     2652    1 #>  #> ----------------------------------------------------------------- Study: STOP-2 ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[STOP-2: Beta Blocker]  0.05 0.00 0.05 0.05 0.05 0.06  0.06     4489     2901    1 #> pred[STOP-2: ACE Inhibitor] 0.04 0.00 0.03 0.04 0.04 0.04  0.05     2632     2631    1 #> pred[STOP-2: ARB]           0.04 0.00 0.03 0.03 0.04 0.04  0.05     2732     2612    1 #> pred[STOP-2: CCB]           0.05 0.00 0.04 0.04 0.05 0.05  0.05     3314     2558    1 #> pred[STOP-2: Diuretic]      0.06 0.01 0.05 0.05 0.06 0.06  0.07     2605     2655    1 #> pred[STOP-2: Placebo]       0.04 0.00 0.03 0.04 0.04 0.05  0.05     2240     2284    1 #>  #> ------------------------------------------------------------------ Study: VALUE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[VALUE: Beta Blocker]  0.20 0.03 0.15 0.18 0.19 0.21  0.25     2770     2521    1 #> pred[VALUE: ACE Inhibitor] 0.15 0.02 0.11 0.13 0.14 0.16  0.19     3920     2280    1 #> pred[VALUE: ARB]           0.14 0.02 0.11 0.13 0.14 0.14  0.17     4671     2630    1 #> pred[VALUE: CCB]           0.17 0.02 0.13 0.16 0.17 0.18  0.21     3816     2396    1 #> pred[VALUE: Diuretic]      0.21 0.03 0.16 0.19 0.21 0.22  0.27     3864     2752    1 #> pred[VALUE: Placebo]       0.16 0.02 0.12 0.15 0.16 0.17  0.21     3805     2564    1 plot(db_pred_RE_studies) (db_ranks <- posterior_ranks(db_fit_RE)) #>                     mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[Beta Blocker]  5.19 0.42    5   5   5   5     6     2429       NA    1 #> rank[ACE Inhibitor] 1.85 0.53    1   2   2   2     3     3731     3681    1 #> rank[ARB]           1.27 0.52    1   1   1   1     3     3578     3159    1 #> rank[CCB]           3.70 0.52    3   3   4   4     4     3724     2833    1 #> rank[Diuretic]      5.80 0.41    5   6   6   6     6     2529       NA    1 #> rank[Placebo]       3.20 0.60    2   3   3   4     4     3504     2734    1 plot(db_ranks) (db_rankprobs <- posterior_rank_probs(db_fit_RE)) #>                  p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[Beta Blocker]       0.00      0.00      0.00      0.01      0.79       0.2 #> d[ACE Inhibitor]      0.22      0.71      0.06      0.00      0.00       0.0 #> d[ARB]                0.77      0.20      0.03      0.00      0.00       0.0 #> d[CCB]                0.00      0.02      0.27      0.70      0.01       0.0 #> d[Diuretic]           0.00      0.00      0.00      0.00      0.19       0.8 #> d[Placebo]            0.01      0.07      0.64      0.27      0.01       0.0 plot(db_rankprobs) (db_cumrankprobs <- posterior_rank_probs(db_fit_RE, cumulative = TRUE)) #>                  p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[Beta Blocker]       0.00      0.00      0.00      0.01       0.8         1 #> d[ACE Inhibitor]      0.22      0.93      1.00      1.00       1.0         1 #> d[ARB]                0.77      0.97      1.00      1.00       1.0         1 #> d[CCB]                0.00      0.02      0.29      0.99       1.0         1 #> d[Diuretic]           0.00      0.00      0.00      0.00       0.2         1 #> d[Placebo]            0.01      0.08      0.72      0.99       1.0         1 plot(db_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Dietary fat","text":"begin setting network - just pairwise meta-analysis. arm-level rate data giving number deaths (r) person-years risk (E) arm, use function set_agd_arm(). set “Control” reference treatment. also specify optional sample_size argument, although strictly necessary . case sample_size required produce network plot nodes weighted sample size, network plot particularly informative meta-analysis two treatments. (sample_size argument important regression model specified, since also enables automatic centering predictors production predictions studies network, see ?set_agd_arm.)","code":"diet_net <- set_agd_arm(dietary_fat,                          study = studyc,                         trt = trtc,                         r = r,                          E = E,                         trt_ref = \"Control\",                         sample_size = n) diet_net #> A network with 10 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study                   Treatment arms                         #>  DART                    2: Control | Reduced Fat               #>  London Corn/Olive       3: Control | Reduced Fat | Reduced Fat #>  London Low Fat          2: Control | Reduced Fat               #>  Minnesota Coronary      2: Control | Reduced Fat               #>  MRC Soya                2: Control | Reduced Fat               #>  Oslo Diet-Heart         2: Control | Reduced Fat               #>  STARS                   2: Control | Reduced Fat               #>  Sydney Diet-Heart       2: Control | Reduced Fat               #>  Veterans Administration 2: Control | Reduced Fat               #>  Veterans Diet & Skin CA 2: Control | Reduced Fat               #>  #>  Outcome type: rate #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 10 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Dietary fat","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Dietary fat","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Poisson likelihood log link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. diet_fit_FE <- nma(diet_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) diet_fit_FE #> A fixed effects NMA with a poisson likelihood (log link). #> Inference for Stan model: poisson. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Reduced Fat]   -0.01    0.00 0.05   -0.11   -0.04   -0.01    0.03    0.09  3105    1 #> lp__           5325.48    0.06 2.45 5319.80 5324.09 5325.86 5327.25 5329.22  1703    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:35:06 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(diet_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(diet_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Dietary fat","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. diet_fit_RE <- nma(diet_net,                     trt_effects = \"random\",                    prior_intercept = normal(scale = 10),                    prior_trt = normal(scale = 10),                    prior_het = half_normal(scale = 5)) diet_fit_RE #> A random effects NMA with a poisson likelihood (log link). #> Inference for Stan model: poisson. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Reduced Fat]   -0.02    0.00 0.09   -0.20   -0.07   -0.01    0.03    0.16  1962 1.00 #> lp__           5340.69    0.11 3.94 5332.42 5338.17 5340.98 5343.44 5347.76  1239 1.00 #> tau               0.14    0.01 0.13    0.00    0.05    0.10    0.18    0.49   659 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:35:15 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(diet_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(diet_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Dietary fat","text":"Model fit can checked using dic() function: models appear fit data well, residual deviance close number data points. DIC similar models, FE model may preferred parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(dic_FE <- dic(diet_fit_FE)) #> Residual deviance: 22.3 (on 21 data points) #>                pD: 11.1 #>               DIC: 33.4 (dic_RE <- dic(diet_fit_RE)) #> Residual deviance: 21.3 (on 21 data points) #>                pD: 13.6 #>               DIC: 34.9 plot(dic_FE) plot(dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Dietary fat","text":"Dias et al. (2011) produce absolute predictions mortality rates reduced fat control diets, assuming Normal distribution baseline log rate mortality mean \\(-3\\) precision \\(1.77\\). can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted rates (type = \"link\" produce predicted log rates).   baseline argument omitted, predicted rates produced every study network based estimated baseline log rate \\(\\mu_j\\):","code":"pred_FE <- predict(diet_fit_FE,                     baseline = distr(qnorm, mean = -3, sd = 1.77^-0.5),                     type = \"response\") pred_FE #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]     0.07 0.06 0.01 0.03 0.05 0.08  0.22     3658     3564    1 #> pred[Reduced Fat] 0.07 0.06 0.01 0.03 0.05 0.08  0.22     3661     3461    1 plot(pred_FE) pred_RE <- predict(diet_fit_RE,                     baseline = distr(qnorm, mean = -3, sd = 1.77^-0.5),                     type = \"response\") pred_RE #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]     0.06 0.05 0.01 0.03 0.05 0.08   0.2     4176     3690    1 #> pred[Reduced Fat] 0.06 0.05 0.01 0.03 0.05 0.08   0.2     4091     3487    1 plot(pred_RE) pred_FE_studies <- predict(diet_fit_FE, type = \"response\") pred_FE_studies #> ------------------------------------------------------------------- Study: DART ----  #>  #>                         mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[DART: Control]     0.06  0 0.05 0.06 0.06 0.06  0.07     5586     3046    1 #> pred[DART: Reduced Fat] 0.06  0 0.05 0.06 0.06 0.06  0.07     8262     3349    1 #>  #> ------------------------------------------------------ Study: London Corn/Olive ----  #>  #>                                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[London Corn/Olive: Control]     0.07 0.03 0.03 0.06 0.07 0.09  0.13     8091     2739 #> pred[London Corn/Olive: Reduced Fat] 0.07 0.03 0.03 0.06 0.07 0.09  0.13     8635     2738 #>                                      Rhat #> pred[London Corn/Olive: Control]        1 #> pred[London Corn/Olive: Reduced Fat]    1 #>  #> --------------------------------------------------------- Study: London Low Fat ----  #>  #>                                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[London Low Fat: Control]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     7675     2726    1 #> pred[London Low Fat: Reduced Fat] 0.06 0.01 0.04 0.05 0.06 0.06  0.08     8660     2983    1 #>  #> ----------------------------------------------------- Study: Minnesota Coronary ----  #>  #>                                       mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Minnesota Coronary: Control]     0.05  0 0.05 0.05 0.05 0.06  0.06     4412     3383    1 #> pred[Minnesota Coronary: Reduced Fat] 0.05  0 0.05 0.05 0.05 0.06  0.06     6808     3257    1 #>  #> --------------------------------------------------------------- Study: MRC Soya ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[MRC Soya: Control]     0.04 0.01 0.03 0.04 0.04 0.04  0.05     6449     2936    1 #> pred[MRC Soya: Reduced Fat] 0.04 0.01 0.03 0.04 0.04 0.04  0.05     7340     3029    1 #>  #> -------------------------------------------------------- Study: Oslo Diet-Heart ----  #>  #>                                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Oslo Diet-Heart: Control]     0.06 0.01 0.05 0.06 0.06 0.07  0.08     6903     2668    1 #> pred[Oslo Diet-Heart: Reduced Fat] 0.06 0.01 0.05 0.06 0.06 0.07  0.08     9653     3372    1 #>  #> ------------------------------------------------------------------ Study: STARS ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[STARS: Control]     0.02 0.01 0.01 0.01 0.02 0.03  0.05     7489     3068    1 #> pred[STARS: Reduced Fat] 0.02 0.01 0.01 0.01 0.02 0.03  0.05     7607     3093    1 #>  #> ------------------------------------------------------ Study: Sydney Diet-Heart ----  #>  #>                                      mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Sydney Diet-Heart: Control]     0.03  0 0.03 0.03 0.03 0.04  0.04     7569     2975    1 #> pred[Sydney Diet-Heart: Reduced Fat] 0.03  0 0.03 0.03 0.03 0.04  0.04     8405     3037    1 #>  #> ------------------------------------------------ Study: Veterans Administration ----  #>  #>                                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Veterans Administration: Control]     0.11 0.01  0.1 0.11 0.11 0.12  0.13     4412 #> pred[Veterans Administration: Reduced Fat] 0.11 0.01  0.1 0.11 0.11 0.12  0.12     6636 #>                                            Tail_ESS Rhat #> pred[Veterans Administration: Control]         3363    1 #> pred[Veterans Administration: Reduced Fat]     3410    1 #>  #> ------------------------------------------------ Study: Veterans Diet & Skin CA ----  #>  #>                                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Veterans Diet & Skin CA: Control]     0.01 0.01    0 0.01 0.01 0.02  0.03     7230 #> pred[Veterans Diet & Skin CA: Reduced Fat] 0.01 0.01    0 0.01 0.01 0.02  0.03     7293 #>                                            Tail_ESS Rhat #> pred[Veterans Diet & Skin CA: Control]         2875    1 #> pred[Veterans Diet & Skin CA: Reduced Fat]     2908    1 plot(pred_FE_studies) + ggplot2::facet_grid(Study~., labeller = ggplot2::label_wrap_gen(width = 10))"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Plaque psoriasis HTA report","text":"begin setting network. arm-level ordered multinomial count data, use function set_agd_arm(). function multi() helps us specify ordered outcomes correctly. Plot network structure.","code":"pso_net <- set_agd_arm(hta_psoriasis,                         study = paste(studyc, year),                         trt = trtc,                         r = multi(r0 = sample_size - rowSums(cbind(PASI50, PASI75, PASI90), na.rm = TRUE),                                   PASI50, PASI75, PASI90,                                  inclusive = FALSE,                                   type = \"ordered\")) pso_net #> A network with 16 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                           #>  ACD2058g 2004 2: Supportive care | Efalizumab                          #>  ACD2600g 2004 2: Supportive care | Efalizumab                          #>  Altmeyer 1994 2: Supportive care | Fumaderm                            #>  Chaudari 2001 2: Supportive care | Infliximab                          #>  Elewski 2004  3: Supportive care | Etanercept 25 mg | Etanercept 50 mg #>  Ellis 1991    3: Supportive care | Ciclosporin | Ciclosporin           #>  Gordon 2003   2: Supportive care | Efalizumab                          #>  Gottlieb 2003 2: Supportive care | Etanercept 25 mg                    #>  Gottlieb 2004 3: Supportive care | Infliximab | Infliximab             #>  Guenther 1991 2: Supportive care | Ciclosporin                         #>  ... plus 6 more studies #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 8 #> Total number of studies: 16 #> Reference treatment is: Supportive care #> Network is connected plot(pso_net, weight_edges = TRUE, weight_nodes = TRUE) +    # Nudge the legend over   ggplot2::theme(legend.box.spacing = ggplot2::unit(0.75, \"in\"),                  plot.margin = ggplot2::margin(0.1, 0, 0.1, 0.75, \"in\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Plaque psoriasis HTA report","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Plaque psoriasis HTA report","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\", using probit link function link = \"probit\". use \\(\\mathrm{N}(0, 10^2)\\) prior distributions treatment effects \\(d_k\\), \\(\\mathrm{N}(0, 100^2)\\) prior distributions study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: also need specify prior distributions latent cutpoints \\(c_\\textrm{PASI75}\\) \\(c_\\textrm{PASI90}\\) underlying scale - PASI standardised mean difference due probit link (cutpoint \\(c_\\textrm{PASI50}=0\\)). make easier reason , actually specify priors differences adjacent cutpoints, e.g. \\(c_\\textrm{PASI90} - c_\\textrm{PASI75}\\) \\(c_\\textrm{PASI75} - c_\\textrm{PASI50}\\). can given positive-valued prior distribution, Stan automatically impose necessary ordering constraints behind scenes. choose give implicit flat priors flat(). model fitted using nma() function. Basic parameter summaries given print() method: Note: treatment effects opposite sign TSD 2 (Dias et al. 2011). parameterise linear predictor \\(\\mu_j + d_k + c_m\\), rather \\(\\mu_j + d_k - c_m\\). interpretation thus follows standard binomial probit (logit) regression; SMDs (log ORs) greater zero mean treatment increases probability event compared comparator (less zero mean reduction probability). higher outcomes positive, active treatments estimated increase response (.e. greater reduction) PASI scale compared network reference (supportive care). default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Focusing specifically cutpoints see highly identified data, implicit flat priors work parameters.","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10),                   prior_aux = flat()) #> Note: Setting \"Supportive care\" as the network reference treatment. pso_fit_FE #> A fixed effects NMA with a ordered likelihood (probit link). #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff #> d[Ciclosporin]          1.92    0.01 0.33     1.32     1.70     1.91     2.13     2.63  1416 #> d[Efalizumab]           1.19    0.00 0.06     1.08     1.15     1.19     1.23     1.30  2233 #> d[Etanercept 25 mg]     1.51    0.00 0.10     1.32     1.45     1.51     1.58     1.70  2308 #> d[Etanercept 50 mg]     1.92    0.00 0.10     1.73     1.85     1.92     1.99     2.12  2481 #> d[Fumaderm]             1.47    0.01 0.48     0.63     1.14     1.44     1.76     2.50  2853 #> d[Infliximab]           2.34    0.00 0.27     1.83     2.15     2.33     2.52     2.87  3055 #> d[Methotrexate]         1.62    0.01 0.42     0.80     1.33     1.61     1.90     2.46  1735 #> lp__                -3516.08    0.09 3.55 -3524.10 -3518.24 -3515.74 -3513.59 -3510.19  1661 #> cc[PASI50]              0.00     NaN 0.00     0.00     0.00     0.00     0.00     0.00   NaN #> cc[PASI75]              0.76    0.00 0.03     0.70     0.73     0.76     0.78     0.82  5144 #> cc[PASI90]              1.57    0.00 0.05     1.46     1.53     1.57     1.60     1.66  6330 #>                     Rhat #> d[Ciclosporin]         1 #> d[Efalizumab]          1 #> d[Etanercept 25 mg]    1 #> d[Etanercept 50 mg]    1 #> d[Fumaderm]            1 #> d[Infliximab]          1 #> d[Methotrexate]        1 #> lp__                   1 #> cc[PASI50]           NaN #> cc[PASI75]             1 #> cc[PASI90]             1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:35:43 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_FE, pars = c(\"d\", \"mu\", \"cc\")) plot_prior_posterior(pso_fit_FE) plot_prior_posterior(pso_fit_FE, prior = \"aux\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Plaque psoriasis HTA report","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 10^2)\\) prior distributions treatment effects \\(d_k\\), \\(\\mathrm{N}(0, 100^2)\\) prior distributions study-specific intercepts \\(\\mu_j\\), implicit flat prior distributions latent cutpoints, additionally use \\(\\textrm{half-N}(2.5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 2.5)) #> A half-Normal prior distribution: location = 0, scale = 2.5. #> 50% of the prior density lies between 0 and 1.69. #> 95% of the prior density lies between 0 and 4.9. pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10),                   prior_aux = flat(),                   prior_het = half_normal(scale = 2.5),                   adapt_delta = 0.99) #> Note: Setting \"Supportive care\" as the network reference treatment. pso_fit_RE #> A random effects NMA with a ordered likelihood (probit link). #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=5000; warmup=2500; thin=1;  #> post-warmup draws per chain=2500, total post-warmup draws=10000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff #> d[Ciclosporin]          2.02    0.01 0.42     1.28     1.73     1.99     2.26     2.97  3349 #> d[Efalizumab]           1.19    0.00 0.18     0.81     1.10     1.19     1.27     1.56  4030 #> d[Etanercept 25 mg]     1.52    0.00 0.23     1.03     1.40     1.52     1.64     1.99  4678 #> d[Etanercept 50 mg]     1.92    0.00 0.27     1.34     1.79     1.92     2.05     2.46  4600 #> d[Fumaderm]             1.48    0.01 0.60     0.37     1.08     1.46     1.85     2.74  6822 #> d[Infliximab]           2.31    0.00 0.37     1.57     2.08     2.31     2.54     3.05  6872 #> d[Methotrexate]         1.70    0.01 0.61     0.57     1.30     1.68     2.06     2.97  4556 #> lp__                -3523.54    0.18 6.69 -3537.25 -3527.98 -3523.42 -3518.84 -3511.17  1324 #> tau                     0.30    0.01 0.21     0.02     0.14     0.26     0.42     0.82  1000 #> cc[PASI50]              0.00     NaN 0.00     0.00     0.00     0.00     0.00     0.00   NaN #> cc[PASI75]              0.76    0.00 0.03     0.70     0.74     0.76     0.78     0.82 15453 #> cc[PASI90]              1.56    0.00 0.05     1.46     1.53     1.56     1.60     1.67 18856 #>                     Rhat #> d[Ciclosporin]         1 #> d[Efalizumab]          1 #> d[Etanercept 25 mg]    1 #> d[Etanercept 50 mg]    1 #> d[Fumaderm]            1 #> d[Infliximab]          1 #> d[Methotrexate]        1 #> lp__                   1 #> tau                    1 #> cc[PASI50]           NaN #> cc[PASI75]             1 #> cc[PASI90]             1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:37:31 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_RE, pars = c(\"d\", \"cc\", \"mu\", \"delta\")) plot_prior_posterior(pso_fit_RE, prior = c(\"trt\", \"aux\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Plaque psoriasis HTA report","text":"Model fit can checked using dic() function: random effects model lower DIC residual deviance closer number data points, preferred case. can also examine residual deviance contributions corresponding plot() method.   data points fit well, posterior mean residual deviances close degrees freedom. Meffert 1997 study substantially higher residual deviance contribution, investigated see study appears outlier.","code":"(dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 74.9 (on 58 data points) #>                pD: 25.4 #>               DIC: 100.3 (dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 63.2 (on 58 data points) #>                pD: 33.3 #>               DIC: 96.4 plot(dic_FE) plot(dic_RE)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"predicted-probabilities-of-response","dir":"Articles","previous_headings":"Further results","what":"Predicted probabilities of response","title":"Example: Plaque psoriasis HTA report","text":"Dias et al. (2011) produce absolute predictions probability achieving responses PASI cutoff, assuming Normal distribution baseline probit probability PASI50 response supportive care mean \\(-1.097\\) precision \\(123\\). can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted probabilities (type = \"link\" produce predicted probit probabilities).   instead information baseline PASI 50 response probit probability PASI 50 event counts, can use construct Beta distribution baseline probability PASI 50 response. example, 56 408 individuals achieved PASI 50 response supportive care target population interest, appropriate Beta distribution response probability \\(\\textrm{Beta}(56, 408-56)\\). can specify Beta distribution baseline response using baseline_type = \"reponse\" argument (default \"link\", used baseline probit probability).  (Notice results equivalent calculated using Normal distribution baseline probit probability, since event counts correspond probit probability.) can modify plots using standard ggplot2 functions. example, plot cutpoints together colour coding (instead split facets):  baseline argument omitted, predicted probabilities produced every study network based estimated baseline probit probability \\(\\mu_j\\).","code":"pred_FE <- predict(pso_fit_FE,                     baseline = distr(qnorm, mean = -1.097, sd = 123^-0.5),                     type = \"response\") pred_FE #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.18     3631     3432    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05     3616     3597    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01     3973     3581    1 #> pred[Ciclosporin, PASI50]      0.78 0.09 0.57 0.72 0.79 0.85  0.94     1486     1791    1 #> pred[Ciclosporin, PASI75]      0.53 0.13 0.28 0.44 0.52 0.61  0.79     1529     1844    1 #> pred[Ciclosporin, PASI90]      0.24 0.10 0.08 0.17 0.23 0.30  0.49     1564     1852    1 #> pred[Efalizumab, PASI50]       0.54 0.04 0.45 0.51 0.54 0.57  0.62     3073     3408    1 #> pred[Efalizumab, PASI75]       0.25 0.04 0.19 0.23 0.25 0.28  0.33     3069     3472    1 #> pred[Efalizumab, PASI90]       0.07 0.02 0.04 0.06 0.07 0.08  0.11     3300     3573    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.05 0.56 0.63 0.66 0.69  0.75     2802     3330    1 #> pred[Etanercept 25 mg, PASI75] 0.37 0.05 0.28 0.33 0.37 0.40  0.47     2803     3274    1 #> pred[Etanercept 25 mg, PASI90] 0.13 0.03 0.08 0.11 0.13 0.15  0.19     3018     3307    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.04 0.71 0.77 0.80 0.82  0.86     2996     3419    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.05 0.42 0.49 0.53 0.56  0.63     3013     3513    1 #> pred[Etanercept 50 mg, PASI90] 0.23 0.04 0.16 0.20 0.23 0.26  0.32     3217     3271    1 #> pred[Fumaderm, PASI50]         0.63 0.16 0.31 0.51 0.64 0.75  0.92     3004     2600    1 #> pred[Fumaderm, PASI75]         0.36 0.17 0.11 0.23 0.34 0.46  0.74     3001     2550    1 #> pred[Fumaderm, PASI90]         0.14 0.11 0.02 0.06 0.11 0.19  0.44     3030     2449    1 #> pred[Infliximab, PASI50]       0.88 0.05 0.76 0.85 0.89 0.92  0.97     3175     2659    1 #> pred[Infliximab, PASI75]       0.68 0.10 0.48 0.61 0.68 0.75  0.86     3119     2647    1 #> pred[Infliximab, PASI90]       0.38 0.11 0.19 0.30 0.37 0.44  0.60     3175     2620    1 #> pred[Methotrexate, PASI50]     0.68 0.14 0.37 0.59 0.70 0.79  0.92     1777     2461    1 #> pred[Methotrexate, PASI75]     0.41 0.16 0.14 0.30 0.40 0.52  0.74     1804     2566    1 #> pred[Methotrexate, PASI90]     0.17 0.11 0.03 0.09 0.15 0.23  0.43     1825     2501    1 plot(pred_FE) pred_RE <- predict(pso_fit_RE,                     baseline = distr(qnorm, mean = -1.097, sd = 123^-0.5),                     type = \"response\") pred_RE #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.18     9886     9993    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05    10232     9932    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01    11095     9598    1 #> pred[Ciclosporin, PASI50]      0.80 0.11 0.56 0.73 0.82 0.88  0.97     3733     3514    1 #> pred[Ciclosporin, PASI75]      0.56 0.15 0.27 0.45 0.56 0.66  0.87     3753     3468    1 #> pred[Ciclosporin, PASI90]      0.28 0.14 0.08 0.17 0.25 0.35  0.63     3771     3547    1 #> pred[Efalizumab, PASI50]       0.53 0.08 0.38 0.49 0.54 0.58  0.69     4883     3996    1 #> pred[Efalizumab, PASI75]       0.26 0.06 0.14 0.22 0.25 0.29  0.40     4976     4262    1 #> pred[Efalizumab, PASI90]       0.07 0.03 0.03 0.06 0.07 0.09  0.15     5154     3936    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.09 0.46 0.61 0.66 0.71  0.82     5618     4862    1 #> pred[Etanercept 25 mg, PASI75] 0.37 0.09 0.20 0.32 0.37 0.42  0.56     5673     4992    1 #> pred[Etanercept 25 mg, PASI90] 0.13 0.05 0.05 0.10 0.13 0.16  0.26     5711     4954    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.08 0.59 0.75 0.80 0.84  0.92     5555     3622    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.10 0.30 0.47 0.53 0.59  0.73     5564     3595    1 #> pred[Etanercept 50 mg, PASI90] 0.24 0.08 0.09 0.19 0.23 0.28  0.43     5569     3680    1 #> pred[Fumaderm, PASI50]         0.63 0.19 0.23 0.49 0.64 0.78  0.95     7165     5227    1 #> pred[Fumaderm, PASI75]         0.37 0.20 0.07 0.22 0.34 0.50  0.81     7168     5158    1 #> pred[Fumaderm, PASI90]         0.16 0.14 0.01 0.06 0.11 0.21  0.54     7214     5214    1 #> pred[Infliximab, PASI50]       0.87 0.08 0.67 0.84 0.89 0.93  0.98     7159     5981    1 #> pred[Infliximab, PASI75]       0.67 0.13 0.38 0.59 0.68 0.76  0.89     7177     6101    1 #> pred[Infliximab, PASI90]       0.37 0.13 0.13 0.28 0.36 0.46  0.66     7214     5765    1 #> pred[Methotrexate, PASI50]     0.70 0.18 0.29 0.58 0.72 0.84  0.97     4718     4538    1 #> pred[Methotrexate, PASI75]     0.45 0.21 0.09 0.29 0.43 0.59  0.87     4726     4664    1 #> pred[Methotrexate, PASI90]     0.21 0.16 0.02 0.09 0.16 0.28  0.63     4722     4449    1 plot(pred_RE) pred_FE_beta <- predict(pso_fit_FE,                          baseline = distr(qbeta, 56, 408-56),                         baseline_type = \"response\",                         type = \"response\") pred_FE_beta #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.17     3940     4002    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05     4084     3877    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01     4634     3607    1 #> pred[Ciclosporin, PASI50]      0.78 0.09 0.58 0.72 0.79 0.85  0.94     1485     1664    1 #> pred[Ciclosporin, PASI75]      0.53 0.13 0.29 0.43 0.52 0.61  0.79     1521     1811    1 #> pred[Ciclosporin, PASI90]      0.24 0.10 0.09 0.16 0.22 0.30  0.49     1564     1699    1 #> pred[Efalizumab, PASI50]       0.54 0.04 0.46 0.51 0.54 0.56  0.61     3314     3885    1 #> pred[Efalizumab, PASI75]       0.25 0.03 0.19 0.23 0.25 0.28  0.32     3361     3897    1 #> pred[Efalizumab, PASI90]       0.07 0.02 0.05 0.06 0.07 0.08  0.10     3556     3809    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.04 0.57 0.63 0.66 0.69  0.75     3029     3466    1 #> pred[Etanercept 25 mg, PASI75] 0.37 0.05 0.28 0.34 0.37 0.40  0.46     3107     3621    1 #> pred[Etanercept 25 mg, PASI90] 0.13 0.03 0.08 0.11 0.13 0.14  0.18     3360     3550    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.04 0.72 0.77 0.80 0.82  0.86     3164     3649    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.05 0.43 0.49 0.53 0.56  0.62     3268     3617    1 #> pred[Etanercept 50 mg, PASI90] 0.23 0.04 0.16 0.20 0.23 0.26  0.31     3486     3785    1 #> pred[Fumaderm, PASI50]         0.63 0.16 0.32 0.51 0.64 0.75  0.92     3125     2462    1 #> pred[Fumaderm, PASI75]         0.36 0.17 0.11 0.23 0.34 0.47  0.74     3133     2400    1 #> pred[Fumaderm, PASI90]         0.14 0.11 0.02 0.06 0.11 0.19  0.43     3146     2371    1 #> pred[Infliximab, PASI50]       0.88 0.05 0.76 0.85 0.89 0.92  0.96     3270     2747    1 #> pred[Infliximab, PASI75]       0.68 0.10 0.48 0.61 0.68 0.75  0.85     3225     2690    1 #> pred[Infliximab, PASI90]       0.38 0.11 0.19 0.30 0.37 0.45  0.60     3265     2690    1 #> pred[Methotrexate, PASI50]     0.68 0.14 0.38 0.59 0.70 0.79  0.92     1734     2278    1 #> pred[Methotrexate, PASI75]     0.41 0.16 0.14 0.30 0.40 0.52  0.73     1766     2224    1 #> pred[Methotrexate, PASI90]     0.17 0.11 0.03 0.09 0.15 0.22  0.43     1779     2406    1 plot(pred_FE_beta) pred_RE_beta <- predict(pso_fit_RE,                          baseline = distr(qbeta, 56, 408-56),                         baseline_type = \"response\",                         type = \"response\") pred_RE_beta #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.11 0.13 0.14 0.15  0.17     9843     9606    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05    10409     9721    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01    11568     9176    1 #> pred[Ciclosporin, PASI50]      0.80 0.11 0.57 0.73 0.81 0.88  0.97     3885     3312    1 #> pred[Ciclosporin, PASI75]      0.56 0.15 0.28 0.45 0.55 0.66  0.87     3911     3327    1 #> pred[Ciclosporin, PASI90]      0.28 0.14 0.08 0.17 0.25 0.35  0.63     3930     3380    1 #> pred[Efalizumab, PASI50]       0.53 0.07 0.38 0.49 0.54 0.58  0.69     4725     3842    1 #> pred[Efalizumab, PASI75]       0.26 0.06 0.14 0.22 0.25 0.29  0.40     4853     3687    1 #> pred[Efalizumab, PASI90]       0.07 0.03 0.03 0.06 0.07 0.09  0.14     5086     3711    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.09 0.46 0.61 0.66 0.71  0.82     5176     4267    1 #> pred[Etanercept 25 mg, PASI75] 0.37 0.09 0.20 0.32 0.37 0.42  0.57     5178     4294    1 #> pred[Etanercept 25 mg, PASI90] 0.13 0.05 0.05 0.10 0.13 0.16  0.26     5364     4316    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.08 0.59 0.75 0.80 0.83  0.92     5228     3482    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.10 0.30 0.47 0.53 0.59  0.73     5238     3522    1 #> pred[Etanercept 50 mg, PASI90] 0.24 0.08 0.09 0.19 0.23 0.28  0.43     5242     3596    1 #> pred[Fumaderm, PASI50]         0.63 0.19 0.23 0.49 0.64 0.78  0.95     7183     5265    1 #> pred[Fumaderm, PASI75]         0.37 0.20 0.07 0.22 0.35 0.50  0.82     7183     5084    1 #> pred[Fumaderm, PASI90]         0.16 0.14 0.01 0.06 0.11 0.21  0.54     7238     5207    1 #> pred[Infliximab, PASI50]       0.87 0.08 0.67 0.84 0.89 0.93  0.98     7036     5485    1 #> pred[Infliximab, PASI75]       0.67 0.13 0.37 0.59 0.68 0.75  0.89     7063     5412    1 #> pred[Infliximab, PASI90]       0.37 0.13 0.13 0.28 0.37 0.45  0.66     6942     5407    1 #> pred[Methotrexate, PASI50]     0.70 0.18 0.30 0.58 0.72 0.83  0.97     4826     4663    1 #> pred[Methotrexate, PASI75]     0.45 0.21 0.10 0.29 0.43 0.59  0.87     4834     4774    1 #> pred[Methotrexate, PASI90]     0.20 0.16 0.02 0.09 0.16 0.28  0.63     4828     4635    1 plot(pred_RE_beta) library(ggplot2) plot(pred_RE, position = position_dodge(width = 0.75)) +   facet_null() +   aes(colour = Category) +   scale_colour_brewer(palette = \"Blues\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"ranks-and-rank-probabilities","dir":"Articles","previous_headings":"Further results","what":"Ranks and rank probabilities","title":"Example: Plaque psoriasis HTA report","text":"Treatment rankings, rank probabilities, cumulative rank probabilities can also produced. set lower_better = FALSE since higher outcome categories better (outcomes positive).","code":"(pso_ranks <- posterior_ranks(pso_fit_RE, lower_better = FALSE)) #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[Supportive care]  7.99 0.11    8   8   8   8     8     7122       NA    1 #> rank[Ciclosporin]      2.78 1.27    1   2   3   4     5     6116     6400    1 #> rank[Efalizumab]       6.33 0.82    4   6   7   7     7     5093       NA    1 #> rank[Etanercept 25 mg] 4.95 1.07    3   4   5   6     7     6384       NA    1 #> rank[Etanercept 50 mg] 3.04 1.19    1   2   3   4     5     4949     4192    1 #> rank[Fumaderm]         4.90 1.94    1   3   5   7     7     7331     5583    1 #> rank[Infliximab]       1.77 1.16    1   1   1   2     5     4128     4973    1 #> rank[Methotrexate]     4.25 1.88    1   3   4   6     7     5660     6544    1 plot(pso_ranks) (pso_rankprobs <- posterior_rank_probs(pso_fit_RE, lower_better = FALSE)) #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] #> d[Supportive care]       0.00      0.00      0.00      0.00      0.00      0.00      0.01 #> d[Ciclosporin]           0.16      0.29      0.28      0.17      0.08      0.02      0.00 #> d[Efalizumab]            0.00      0.00      0.01      0.02      0.10      0.36      0.51 #> d[Etanercept 25 mg]      0.00      0.01      0.08      0.20      0.39      0.26      0.05 #> d[Etanercept 50 mg]      0.07      0.31      0.27      0.24      0.08      0.02      0.01 #> d[Fumaderm]              0.07      0.09      0.10      0.12      0.16      0.19      0.27 #> d[Infliximab]            0.60      0.19      0.12      0.06      0.02      0.01      0.00 #> d[Methotrexate]          0.10      0.11      0.15      0.18      0.17      0.14      0.15 #>                     p_rank[8] #> d[Supportive care]       0.99 #> d[Ciclosporin]           0.00 #> d[Efalizumab]            0.00 #> d[Etanercept 25 mg]      0.00 #> d[Etanercept 50 mg]      0.00 #> d[Fumaderm]              0.01 #> d[Infliximab]            0.00 #> d[Methotrexate]          0.00 plot(pso_rankprobs) (pso_cumrankprobs <- posterior_rank_probs(pso_fit_RE, lower_better = FALSE, cumulative = TRUE)) #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] #> d[Supportive care]       0.00      0.00      0.00      0.00      0.00      0.00      0.01 #> d[Ciclosporin]           0.16      0.45      0.73      0.90      0.98      1.00      1.00 #> d[Efalizumab]            0.00      0.00      0.01      0.03      0.13      0.49      1.00 #> d[Etanercept 25 mg]      0.00      0.02      0.09      0.30      0.69      0.95      1.00 #> d[Etanercept 50 mg]      0.07      0.38      0.65      0.89      0.98      0.99      1.00 #> d[Fumaderm]              0.07      0.16      0.26      0.37      0.53      0.72      0.99 #> d[Infliximab]            0.60      0.79      0.90      0.96      0.99      1.00      1.00 #> d[Methotrexate]          0.10      0.21      0.36      0.54      0.71      0.85      1.00 #>                     p_rank[8] #> d[Supportive care]          1 #> d[Ciclosporin]              1 #> d[Efalizumab]               1 #> d[Etanercept 25 mg]         1 #> d[Etanercept 50 mg]         1 #> d[Fumaderm]                 1 #> d[Infliximab]               1 #> d[Methotrexate]             1 plot(pso_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"study-data","dir":"Articles","previous_headings":"","what":"Study data","title":"Example: Newly diagnosed multiple myeloma","text":"consider adjustment following covariates: Age Sex ISS stage, -II vs. III Response post-ASCT, complete good partial response vs. lesser response summary distributions characteristics study follows:","code":"bind_rows(   summarise(ndmm_ipd,             N = n(),             age_mean = mean(age), age_sd = sd(age),             iss_stage3 = mean(iss_stage3),             response_cr_vgpr = mean(response_cr_vgpr),             male = mean(male),             .by = c(studyf, trtf)),   transmute(ndmm_agd_covs,             studyf, trtf,             N = sample_size,             age_mean, age_sd, iss_stage3, response_cr_vgpr, male) ) %>%   mutate(across(where(is.double), ~round(., digits = 2))) #>          studyf trtf    N age_mean age_sd iss_stage3 response_cr_vgpr male #> 1  McCarthy2012  Pbo  229    57.39   5.56       0.18             0.71 0.55 #> 2  McCarthy2012  Len  231    57.93   6.33       0.27             0.62 0.52 #> 3     Attal2012  Pbo  307    54.22   5.24       0.16             0.54 0.58 #> 4     Attal2012  Len  307    54.35   6.06       0.24             0.55 0.55 #> 5   Palumbo2014  Pbo  125    54.44   8.98       0.12             0.38 0.63 #> 6   Palumbo2014  Len  126    53.90   9.69       0.10             0.42 0.46 #> 7   Jackson2019  Len 1137    65.17   8.94       0.25             0.83 0.62 #> 8   Jackson2019  Pbo  864    64.63   9.40       0.19             0.83 0.62 #> 9    Morgan2012  Pbo  410    63.92   9.01       0.36             0.72 0.62 #> 10   Morgan2012 Thal  408    65.59   8.38       0.32             0.75 0.62"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"preparing-treatment-classes","dir":"Articles","previous_headings":"Setup","what":"Preparing treatment classes","title":"Example: Newly diagnosed multiple myeloma","text":"start setting network analysis. Since IPD placebo vs. lenalidomide comparison, one AgD study placebo vs. thalidomide comparison, make shared effect modifier assumption two active treatments order estimate effect modifying treatment-covariate interactions thalidomide Phillippo et al. (2020). Since lenalidomide thalidomide class treatments, assumption may reasonable. impose assumption, create treatment class variable active treatments vs. placebo.","code":"ndmm_ipd$trtclass <- case_match(ndmm_ipd$trtf,                                 \"Pbo\" ~ \"Placebo\",                                 c(\"Len\", \"Thal\") ~ \"Active\")  ndmm_agd$trtclass <- case_match(ndmm_agd$trtf,                                 \"Pbo\" ~ \"Placebo\",                                 c(\"Len\", \"Thal\") ~ \"Active\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"Setup","what":"Setting up the network","title":"Example: Newly diagnosed multiple myeloma","text":"set network using set_ipd(), set_agd_surv(), combine_network() functions. Since survival data form event/censoring times censoring indicators, use Surv argument set_*() functions set outcome data using usual survival::Surv() function. AgD set similar fashion IPD, except summary covariate information (data frame ndmm_agd_covs) included using covariates argument. data frame passed covariates must matching study treatment columns outcome data set (ndmm_agd), case studyf trtf respectively, one row per arm, covariate information can matched corresponding arms outcome data. IPD AgD combined single network using combine_network().","code":"ndmm_net <- combine_network(   set_ipd(ndmm_ipd,           study = studyf,           trt = trtf,           trt_class = trtclass,           Surv = Surv(eventtime, status)),   set_agd_surv(ndmm_agd,                study = studyf,                trt = trtf,                trt_class = trtclass,                Surv = Surv(eventtime, status),                covariates = ndmm_agd_covs) )"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"adding-numerical-integration-for-ml-nmr","dir":"Articles","previous_headings":"Setup","what":"Adding numerical integration for ML-NMR","title":"Example: Newly diagnosed multiple myeloma","text":"perform ML-NMR, need create numerical integration points joint covariate distributions AgD study. used integrate (.e. average) individual-level model joint covariate distribution form aggregate-level model. done using add_integration() function, covariate specify marginal distribution using distr() function. Since age skewed, use gamma distribution covariate; remaining covariates binary given Bernoulli distributions. procedure also requires information correlations covariates. known, can specified using cor argument. However, default weighted average correlations IPD studies used.","code":"ndmm_net <- add_integration(ndmm_net,                             age = distr(qgamma, mean = age_mean, sd = age_sd),                             iss_stage3 = distr(qbern, iss_stage3),                             response_cr_vgpr = distr(qbern, response_cr_vgpr),                             male = distr(qbern, male)) #> Using weighted average correlation matrix computed from IPD studies.  ndmm_net #> A network with 3 IPD studies, and 2 AgD studies (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study        Treatment arms #>  Attal2012    2: Pbo | Len   #>  McCarthy2012 2: Pbo | Len   #>  Palumbo2014  2: Pbo | Len   #>  #>  Outcome type: survival #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study       Treatment arms #>  Jackson2019 2: Pbo | Len   #>  Morgan2012  2: Pbo | Thal  #>  #>  Outcome type: survival #> ------------------------------------------------------------------------------------ #> Total number of treatments: 3, in 2 classes #> Total number of studies: 5 #> Reference treatment is: Pbo #> Network is connected #>  #> --------------------------------------------------------- Numerical integration ----  #> Numerical integration points available for 4 covariates:  #>   age iss_stage3 response_cr_vgpr male #> Number of numerical integration points: 64"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"network-plot","dir":"Articles","previous_headings":"Setup","what":"Network plot","title":"Example: Newly diagnosed multiple myeloma","text":"can plot network diagram using plot() method.","code":"plot(ndmm_net,      weight_nodes = TRUE,      weight_edges = TRUE,      # Nudge treatment labels away from nodes      nudge = 0.1,      # Manual layout      layout = data.frame(x = c(0, -1, 1),                          y = c(-0.5, 0, 0))) +   guides(edge_colour = guide_legend(override.aes = list(edge_width = 2))) +   theme(legend.position = \"bottom\", legend.direction = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"kaplan-meier-plots","dir":"Articles","previous_headings":"Setup","what":"Kaplan-Meier plots","title":"Example: Newly diagnosed multiple myeloma","text":"can produce Kaplan-Meier plots data study, aid geom_km() function.  transform argument geom_km() can used transform Kaplan-Meier curves prior plotting, example transform = \"cloglog\" assess proportional hazards log-log plot.","code":"ggplot() +   geom_km(ndmm_net) +   facet_wrap(~.study) +   labs(y = \"Survival probability\", x = \"Time\") +   coord_cartesian(ylim = c(0, 1)) +   theme_multinma() +   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"ml-nmr-models-with-m-spline-baseline-hazards","dir":"Articles","previous_headings":"","what":"ML-NMR models with M-spline baseline hazards","title":"Example: Newly diagnosed multiple myeloma","text":"fit proportional hazards survival model cubic M-splines baseline hazard Phillippo et al. (n.d.). allows baseline hazard flexibly follow shape baseline hazard may take. ML-NMR models fit using nma() function, specify M-spline baseline hazard used likelihood = \"mspline\". Fitting spline models requires user specify number location knots. default, seven internal knots used (n_knots = 7) placed evenly spaced quantiles observed event times within study. Overfitting avoided use random walk prior distribution (inverse softmax transformed) spline coefficients penalises complexity shrinks towards constant baseline hazard (Phillippo et al., n.d.); practice means number knots can set sufficiently large number left shrink suitable level complexity controlled standard deviation random walk. number knots can changed using n_knots argument, custom knot locations can specified using knots argument. nma() function always place boundary knots earliest entry time study (0 delayed entry) maximum event/censoring time. default, nma() function fit cubic M-spline (mspline_degree = 3). Piecewise-constant hazards (.e. piecewise exponential hazards) special case degree 0 splines, specified using likelihood = \"pexp\" (equivalent mspline_degree = 0). specify regression model using regression argument includes main effects covariates (prognostic effects) treatment-covariate interactions (effect modifier interactions) covariate. place vague \\(\\operatorname{N}(0, 100^2)\\) priors parameters linear predictor. give standard deviation random walk prior spline coefficients \\(\\operatorname{half-N}(0, 1^2)\\) prior distribution. also set QR = TRUE, using QR decomposition can greatly increase sampling efficiency regression models. details spline coefficients printed default, can shown print() summary() using pars option:","code":"ndmm_fit <- nma(ndmm_net,                 regression = ~(age + iss_stage3 + response_cr_vgpr + male)*.trt,                 likelihood = \"mspline\",                 prior_intercept = normal(0, 100),                 prior_trt = normal(0, 100),                 prior_reg = normal(0, 100),                 prior_aux = half_normal(1),                 QR = TRUE) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Cubic M-spline baseline hazard with 7 internal knots. #> Regression model: ~(age + iss_stage3 + response_cr_vgpr + male) * .trt. #> Centred covariates at the following overall mean values: #>              age       iss_stage3 response_cr_vgpr             male  #>       61.6558571        0.2297184        0.7314265        0.6020451  #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd      2.5%       25%       50% #> beta[age]                                   0.08    0.00 0.01      0.06      0.07      0.08 #> beta[iss_stage3]                            0.35    0.00 0.13      0.10      0.26      0.35 #> beta[response_cr_vgpr]                     -0.13    0.00 0.10     -0.34     -0.20     -0.13 #> beta[male]                                  0.00    0.00 0.10     -0.20     -0.07      0.00 #> beta[age:.trtclassActive]                  -0.02    0.00 0.01     -0.03     -0.02     -0.02 #> beta[iss_stage3:.trtclassActive]            0.20    0.00 0.17     -0.14      0.09      0.20 #> beta[response_cr_vgpr:.trtclassActive]      0.20    0.00 0.14     -0.09      0.10      0.20 #> beta[male:.trtclassActive]                  0.14    0.00 0.15     -0.17      0.03      0.14 #> d[Len]                                     -0.66    0.00 0.05     -0.77     -0.70     -0.66 #> d[Thal]                                    -0.20    0.00 0.11     -0.40     -0.27     -0.20 #> lp__                                   -12499.11    0.23 7.32 -12514.14 -12504.05 -12498.73 #> sigma[Attal2012]                            0.88    0.01 0.39      0.29      0.60      0.82 #> sigma[McCarthy2012]                         1.75    0.01 0.56      0.83      1.34      1.68 #> sigma[Palumbo2014]                          0.59    0.01 0.52      0.02      0.20      0.45 #> sigma[Jackson2019]                          0.81    0.01 0.33      0.33      0.57      0.75 #> sigma[Morgan2012]                           0.77    0.02 0.50      0.04      0.41      0.70 #>                                              75%     97.5% n_eff Rhat #> beta[age]                                   0.08      0.09  4376 1.00 #> beta[iss_stage3]                            0.43      0.59  4972 1.00 #> beta[response_cr_vgpr]                     -0.06      0.07  5101 1.00 #> beta[male]                                  0.07      0.20  5881 1.00 #> beta[age:.trtclassActive]                  -0.01      0.00  3695 1.00 #> beta[iss_stage3:.trtclassActive]            0.32      0.54  4979 1.00 #> beta[response_cr_vgpr:.trtclassActive]      0.29      0.48  4627 1.00 #> beta[male:.trtclassActive]                  0.24      0.44  5149 1.00 #> d[Len]                                     -0.63     -0.56  4987 1.00 #> d[Thal]                                    -0.12      0.01  3918 1.01 #> lp__                                   -12493.85 -12485.92  1052 1.01 #> sigma[Attal2012]                            1.09      1.82  1936 1.00 #> sigma[McCarthy2012]                         2.11      2.98  2491 1.00 #> sigma[Palumbo2014]                          0.85      1.93  1445 1.00 #> sigma[Jackson2019]                          0.98      1.59  1734 1.01 #> sigma[Morgan2012]                           1.06      1.95   969 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Thu Oct 12 19:58:13 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). summary(ndmm_fit, pars = \"scoef\") #>                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> scoef[Attal2012, 1]     0.02 0.00 0.01 0.01 0.02 0.02  0.03     2468     1624 1.00 #> scoef[McCarthy2012, 1]  0.01 0.00 0.00 0.00 0.01 0.01  0.01     3523     3205 1.00 #> scoef[Palumbo2014, 1]   0.01 0.00 0.01 0.01 0.02 0.02  0.02     2116     3388 1.00 #> scoef[Jackson2019, 1]   0.01 0.00 0.01 0.01 0.01 0.01  0.02     2495     3269 1.01 #> scoef[Morgan2012, 1]    0.01 0.00 0.01 0.01 0.01 0.01  0.02     1165     2636 1.01 #> scoef[Attal2012, 2]     0.03 0.01 0.02 0.02 0.03 0.03  0.04     2661     1995 1.00 #> scoef[McCarthy2012, 2]  0.01 0.01 0.00 0.01 0.01 0.02  0.03     3293     3334 1.00 #> scoef[Palumbo2014, 2]   0.03 0.01 0.02 0.03 0.03 0.03  0.04     2465     3270 1.00 #> scoef[Jackson2019, 2]   0.02 0.00 0.02 0.02 0.02 0.03  0.03     2222     3147 1.01 #> scoef[Morgan2012, 2]    0.02 0.00 0.01 0.02 0.02 0.03  0.03     1342     2926 1.01 #> scoef[Attal2012, 3]     0.05 0.01 0.04 0.05 0.05 0.06  0.07     3837     3615 1.00 #> scoef[McCarthy2012, 3]  0.05 0.01 0.03 0.04 0.05 0.06  0.09     3373     3301 1.00 #> scoef[Palumbo2014, 3]   0.05 0.01 0.04 0.05 0.05 0.06  0.07     4695     3591 1.00 #> scoef[Jackson2019, 3]   0.04 0.00 0.04 0.04 0.04 0.05  0.05     3312     3224 1.00 #> scoef[Morgan2012, 3]    0.04 0.01 0.03 0.04 0.04 0.05  0.06     3584     3326 1.00 #> scoef[Attal2012, 4]     0.09 0.01 0.06 0.08 0.08 0.09  0.11     4699     2958 1.00 #> scoef[McCarthy2012, 4]  0.09 0.02 0.06 0.08 0.09 0.10  0.13     4182     3236 1.00 #> scoef[Palumbo2014, 4]   0.07 0.01 0.05 0.06 0.07 0.07  0.09     4427     3725 1.00 #> scoef[Jackson2019, 4]   0.06 0.01 0.05 0.06 0.06 0.07  0.08     3811     3104 1.00 #> scoef[Morgan2012, 4]    0.07 0.01 0.05 0.06 0.07 0.07  0.08     3657     3469 1.00 #> scoef[Attal2012, 5]     0.10 0.01 0.07 0.09 0.10 0.11  0.13     4416     3747 1.00 #> scoef[McCarthy2012, 5]  0.07 0.02 0.04 0.06 0.07 0.09  0.11     3400     3357 1.00 #> scoef[Palumbo2014, 5]   0.09 0.01 0.07 0.08 0.08 0.09  0.12     3100     3537 1.00 #> scoef[Jackson2019, 5]   0.08 0.01 0.07 0.08 0.08 0.09  0.10     3484     3268 1.00 #> scoef[Morgan2012, 5]    0.08 0.01 0.07 0.08 0.08 0.09  0.11     1542     2765 1.00 #> scoef[Attal2012, 6]     0.11 0.02 0.08 0.10 0.11 0.12  0.15     4130     3521 1.00 #> scoef[McCarthy2012, 6]  0.08 0.02 0.05 0.07 0.08 0.09  0.12     3733     3526 1.00 #> scoef[Palumbo2014, 6]   0.09 0.01 0.06 0.08 0.09 0.09  0.12     4718     3260 1.00 #> scoef[Jackson2019, 6]   0.11 0.01 0.09 0.10 0.11 0.11  0.13     3673     3629 1.00 #> scoef[Morgan2012, 6]    0.10 0.01 0.08 0.09 0.10 0.11  0.13     3914     3569 1.00 #> scoef[Attal2012, 7]     0.14 0.02 0.11 0.13 0.14 0.15  0.19     3454     3624 1.00 #> scoef[McCarthy2012, 7]  0.13 0.03 0.08 0.11 0.12 0.14  0.18     3538     3333 1.00 #> scoef[Palumbo2014, 7]   0.13 0.02 0.10 0.12 0.12 0.14  0.18     3550     3357 1.00 #> scoef[Jackson2019, 7]   0.13 0.01 0.10 0.12 0.13 0.13  0.15     3705     3604 1.00 #> scoef[Morgan2012, 7]    0.13 0.02 0.10 0.12 0.13 0.14  0.16     4651     3552 1.00 #> scoef[Attal2012, 8]     0.17 0.02 0.12 0.15 0.17 0.18  0.22     4415     3648 1.00 #> scoef[McCarthy2012, 8]  0.19 0.04 0.12 0.16 0.18 0.21  0.27     3589     3194 1.00 #> scoef[Palumbo2014, 8]   0.18 0.03 0.13 0.17 0.18 0.19  0.24     4096     3493 1.00 #> scoef[Jackson2019, 8]   0.19 0.02 0.15 0.18 0.19 0.20  0.23     3722     3896 1.00 #> scoef[Morgan2012, 8]    0.20 0.02 0.15 0.18 0.19 0.21  0.25     3894     3098 1.00 #> scoef[Attal2012, 9]     0.12 0.02 0.07 0.10 0.12 0.13  0.16     4005     3200 1.00 #> scoef[McCarthy2012, 9]  0.12 0.04 0.05 0.10 0.12 0.15  0.20     2951     3267 1.00 #> scoef[Palumbo2014, 9]   0.14 0.03 0.08 0.13 0.15 0.16  0.18     3351     3011 1.00 #> scoef[Jackson2019, 9]   0.15 0.02 0.11 0.13 0.15 0.16  0.19     3277     3337 1.00 #> scoef[Morgan2012, 9]    0.16 0.03 0.11 0.15 0.16 0.17  0.22     3822     3196 1.00 #> scoef[Attal2012, 10]    0.10 0.02 0.07 0.09 0.10 0.11  0.14     4864     3366 1.00 #> scoef[McCarthy2012, 10] 0.16 0.04 0.09 0.13 0.15 0.18  0.24     4056     3424 1.00 #> scoef[Palumbo2014, 10]  0.13 0.02 0.08 0.12 0.13 0.14  0.18     5155     3406 1.00 #> scoef[Jackson2019, 10]  0.12 0.02 0.09 0.11 0.12 0.13  0.16     3572     3232 1.00 #> scoef[Morgan2012, 10]   0.12 0.02 0.08 0.11 0.12 0.13  0.17     4044     3655 1.00 #> scoef[Attal2012, 11]    0.07 0.02 0.05 0.06 0.07 0.08  0.11     6035     3940 1.00 #> scoef[McCarthy2012, 11] 0.09 0.03 0.04 0.06 0.08 0.10  0.15     4969     3157 1.00 #> scoef[Palumbo2014, 11]  0.08 0.02 0.05 0.07 0.08 0.09  0.13     4934     3655 1.00 #> scoef[Jackson2019, 11]  0.08 0.01 0.06 0.07 0.08 0.09  0.12     4599     3791 1.00 #> scoef[Morgan2012, 11]   0.06 0.02 0.03 0.05 0.07 0.08  0.09     2666     3835 1.00"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"ploting-hazards","dir":"Articles","previous_headings":"ML-NMR models with M-spline baseline hazards","what":"Ploting hazards","title":"Example: Newly diagnosed multiple myeloma","text":"Let us look estimated hazard functions model. default, predict() function type = \"hazard\" produce plots population-average marginal hazards (level = \"aggregate\", default). can plotted using plot() function.  can also look individual-level baseline hazards. possible using predict() function, time level = \"individual\". Since want show baseline hazard reference level covariates, ’ll create data frame pass predict() newdata. Since providing new data frame prediction, also need provide times predict distributions baseline (intercept) auxiliary (spline coefficient) parameters. predict evenly spaced times time 0 last event/censoring time study. specify named list study names baseline aux, use posterior distributions study parameters. produce predictions plot:","code":"plot(predict(ndmm_fit, type = \"hazard\", level = \"aggregate\")) refdat <- tibble(study = ndmm_net$studies,                  age = ndmm_fit$xbar[\"age\"],                  iss_stage3 = 0,                  response_cr_vgpr = 0,                  male = 0) # At evenly spaced times between the boundary knots tdat <- purrr::imap_dfr(ndmm_fit$basis,                         ~tibble(study = factor(.y, levels = ndmm_net$studies),                                 lower = attr(.x, \"Boundary.knots\")[1],                                 upper = attr(.x, \"Boundary.knots\")[2],                                 times = seq(lower, upper, length = 50)))  refdat <- left_join(refdat, tdat, by = \"study\")  studies <- as.list(setNames(nm = levels(ndmm_net$studies))) plot(predict(ndmm_fit, type = \"hazard\", level = \"individual\",              newdata = refdat, study = study, times = times,              baseline = studies, aux = studies))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"assessing-the-proportional-hazards-assumption","dir":"Articles","previous_headings":"","what":"Assessing the proportional hazards assumption","title":"Example: Newly diagnosed multiple myeloma","text":"can relax assess proportional hazards (PH) assumption allowing spline coefficients vary treatment arms within study. may achieved using aux_by argument, aux_by = c(.study, .trt). Technically, aux_by = .study always assumed order respect randomisation (analogous stratifying intercept terms NMA study), simply write aux_by = .trt; choose make stratification study explicit instance. compare model fit models without PH using LOOIC. overall fit proportional hazards model better. check single study better fit non-PH model, case improved fit one study masked increased complexity others. LOOIC similar lower proportional hazards model compared non-proportional hazards model studies. Based LOOIC alone, evidence suggest proportional hazards assumption invalid . Later, visual inspection estimated survival curves also suggests model good fit data. Stratifying baseline hazards treatment arm (well study) results model produce absolute predictions treatments populations already observed; e.g. estimated survival curve thalidomide can produced Morgan2012 study population (study thalidomide arm), survival curve lenalidomide produced population. Instead, proportional hazards assumption deemed inappropriate, might consider instead modelling departures proportional hazards using aux_regression argument nma() places model (inverse softmax transformed) spline coefficients, shape parameters parametric model. example, can allow baseline hazard vary smoothly treatment arm (aux_regression = ~.trt) /covariates (e.g. aux_regression = ~.trt + iss_stage3). relaxes proportional hazards assumption (already relaxed inclusion patient-level covariates), whilst still allowing predictions produced every treatment population interest.","code":"ndmm_fit_nph <- nma(ndmm_net,                     regression = ~(age + iss_stage3 + response_cr_vgpr + male)*.trt,                     likelihood = \"mspline\",                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_reg = normal(0, 100),                     prior_aux = half_normal(1),                     aux_by = c(.study, .trt),                     QR = TRUE) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nph #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Cubic M-spline baseline hazard with 7 internal knots. #> Regression model: ~(age + iss_stage3 + response_cr_vgpr + male) * .trt. #> Centred covariates at the following overall mean values: #>              age       iss_stage3 response_cr_vgpr             male  #>       61.6558571        0.2297184        0.7314265        0.6020451  #> Stratified baseline hazards by .study and .trt. #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd      2.5%       25%       50% #> beta[age]                                   0.07    0.00 0.01      0.06      0.07      0.07 #> beta[iss_stage3]                            0.33    0.00 0.13      0.08      0.24      0.33 #> beta[response_cr_vgpr]                     -0.11    0.00 0.10     -0.30     -0.18     -0.11 #> beta[male]                                 -0.01    0.00 0.10     -0.21     -0.08     -0.01 #> beta[age:.trtclassActive]                  -0.01    0.00 0.01     -0.03     -0.02     -0.01 #> beta[iss_stage3:.trtclassActive]            0.24    0.00 0.17     -0.11      0.11      0.24 #> beta[response_cr_vgpr:.trtclassActive]      0.16    0.00 0.14     -0.12      0.06      0.16 #> beta[male:.trtclassActive]                  0.15    0.00 0.15     -0.14      0.05      0.15 #> d[Len]                                     -0.62    0.00 0.07     -0.75     -0.66     -0.62 #> d[Thal]                                    -0.26    0.00 0.12     -0.49     -0.33     -0.25 #> lp__                                   -12534.68    0.27 9.19 -12553.34 -12540.75 -12534.38 #> sigma[Attal2012: Pbo]                       0.93    0.01 0.42      0.17      0.64      0.89 #> sigma[Attal2012: Len]                       0.63    0.01 0.40      0.06      0.34      0.55 #> sigma[McCarthy2012: Pbo]                    1.38    0.01 0.53      0.56      0.98      1.31 #> sigma[McCarthy2012: Len]                    1.20    0.01 0.46      0.50      0.86      1.14 #> sigma[Palumbo2014: Pbo]                     0.60    0.01 0.49      0.02      0.24      0.49 #> sigma[Palumbo2014: Len]                     0.77    0.01 0.54      0.03      0.35      0.68 #> sigma[Jackson2019: Pbo]                     0.63    0.01 0.33      0.16      0.40      0.58 #> sigma[Jackson2019: Len]                     0.99    0.01 0.41      0.35      0.69      0.93 #> sigma[Morgan2012: Pbo]                      0.33    0.01 0.32      0.01      0.10      0.23 #> sigma[Morgan2012: Thal]                     1.02    0.01 0.49      0.19      0.67      0.97 #>                                              75%     97.5% n_eff Rhat #> beta[age]                                   0.08      0.09  3031    1 #> beta[iss_stage3]                            0.42      0.58  5960    1 #> beta[response_cr_vgpr]                     -0.04      0.08  6219    1 #> beta[male]                                  0.05      0.19  5980    1 #> beta[age:.trtclassActive]                  -0.01      0.01  3006    1 #> beta[iss_stage3:.trtclassActive]            0.36      0.58  5580    1 #> beta[response_cr_vgpr:.trtclassActive]      0.25      0.43  4989    1 #> beta[male:.trtclassActive]                  0.25      0.46  4670    1 #> d[Len]                                     -0.57     -0.49  2884    1 #> d[Thal]                                    -0.17     -0.03  5412    1 #> lp__                                   -12528.20 -12517.61  1138    1 #> sigma[Attal2012: Pbo]                       1.18      1.86  1319    1 #> sigma[Attal2012: Len]                       0.84      1.59  1986    1 #> sigma[McCarthy2012: Pbo]                    1.70      2.59  2816    1 #> sigma[McCarthy2012: Len]                    1.47      2.27  2672    1 #> sigma[Palumbo2014: Pbo]                     0.84      1.85  2023    1 #> sigma[Palumbo2014: Len]                     1.09      2.06  2084    1 #> sigma[Jackson2019: Pbo]                     0.80      1.42  1811    1 #> sigma[Jackson2019: Len]                     1.24      1.94  1921    1 #> sigma[Morgan2012: Pbo]                      0.45      1.22  2206    1 #> sigma[Morgan2012: Thal]                     1.31      2.12  1601    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Oct 12 22:47:57 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). (ndmm_fit_loo <- loo(ndmm_fit)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12398.8 116.0 #> p_loo        35.1   0.7 #> looic     24797.7 232.1 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details. (ndmm_fit_nph_loo <- loo(ndmm_fit_nph)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12405.4 116.1 #> p_loo        44.2   0.8 #> looic     24810.9 232.2 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  # Compare to PH model loo_compare(ndmm_fit_loo, ndmm_fit_nph_loo) #>        elpd_diff se_diff #> model1  0.0       0.0    #> model2 -6.6       3.5 studies_all <- c(ndmm_ipd$study, ndmm_agd$study) cbind(   PH = by(ndmm_fit_loo$pointwise[, \"looic\"], studies_all, sum),   `non-PH` = by(ndmm_fit_nph_loo$pointwise[, \"looic\"], studies_all, sum) ) #>                     PH    non-PH #> Attal2012     3345.132  3346.962 #> Jackson2019  12398.245 12400.166 #> McCarthy2012  2726.430  2737.793 #> Morgan2012    4991.066  4989.484 #> Palumbo2014   1336.786  1336.462"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"comparison-to-unadjusted-nma","dir":"Articles","previous_headings":"","what":"Comparison to unadjusted NMA","title":"Example: Newly diagnosed multiple myeloma","text":"comparison, also fit NMA models without covariate adjustment, without proportional hazards assumption. , compare model fit using LOOIC, overall within study. Whilst little difference overall model fit, non-PH model preferred Jackson2019 study substantially lower LOOIC. Including covariates ML-NMR model sufficient remove PH violation, even though covariates fixed time-varying, ML-NMR model much better fit overall. Note: test likely low power, substitute usual inspection proportional hazards prior analysis. Using transform = \"cloglog\" geom_km() produce log-log plots one option assess proportionality.","code":"ndmm_fit_nma <- nma(ndmm_net,                     likelihood = \"mspline\",                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_aux = half_normal(1)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nma #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Cubic M-spline baseline hazard with 7 internal knots. #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                          mean se_mean   sd      2.5%       25%       50%       75%     97.5% n_eff #> d[Len]                  -0.52    0.00 0.05     -0.61     -0.55     -0.52     -0.49     -0.43  3117 #> d[Thal]                 -0.11    0.00 0.09     -0.28     -0.17     -0.11     -0.05      0.07  4059 #> lp__                -12533.05    0.21 6.85 -12547.59 -12537.46 -12532.59 -12528.12 -12521.11  1032 #> sigma[Attal2012]         0.82    0.01 0.39      0.19      0.55      0.77      1.04      1.74  1573 #> sigma[McCarthy2012]      1.71    0.01 0.56      0.76      1.29      1.66      2.06      2.95  2142 #> sigma[Palumbo2014]       0.66    0.01 0.50      0.04      0.29      0.55      0.91      1.89  1794 #> sigma[Jackson2019]       0.85    0.01 0.31      0.41      0.62      0.80      1.01      1.59  1960 #> sigma[Morgan2012]        0.90    0.01 0.46      0.29      0.57      0.80      1.14      2.02  1424 #>                     Rhat #> d[Len]                 1 #> d[Thal]                1 #> lp__                   1 #> sigma[Attal2012]       1 #> sigma[McCarthy2012]    1 #> sigma[Palumbo2014]     1 #> sigma[Jackson2019]     1 #> sigma[Morgan2012]      1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Oct 12 23:00:43 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1).  ndmm_fit_nma_nph <- nma(ndmm_net,                         likelihood = \"mspline\",                         prior_intercept = normal(0, 100),                         prior_trt = normal(0, 100),                         prior_aux = half_normal(1),                         aux_by = c(.study, .trt)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nma_nph #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Cubic M-spline baseline hazard with 7 internal knots. #> Stratified baseline hazards by .study and .trt. #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[Len]                       -0.47    0.00 0.05     -0.57     -0.50     -0.47     -0.43     -0.37 #> d[Thal]                      -0.14    0.00 0.10     -0.34     -0.21     -0.14     -0.08      0.05 #> lp__                     -12563.41    0.25 8.85 -12581.68 -12569.30 -12563.15 -12557.29 -12547.02 #> sigma[Attal2012: Pbo]         0.95    0.01 0.43      0.22      0.65      0.91      1.20      1.94 #> sigma[Attal2012: Len]         0.51    0.01 0.38      0.03      0.23      0.43      0.70      1.44 #> sigma[McCarthy2012: Pbo]      1.26    0.01 0.55      0.40      0.86      1.19      1.60      2.57 #> sigma[McCarthy2012: Len]      1.13    0.01 0.47      0.42      0.78      1.06      1.39      2.22 #> sigma[Palumbo2014: Pbo]       0.87    0.01 0.50      0.13      0.51      0.78      1.14      2.07 #> sigma[Palumbo2014: Len]       0.72    0.01 0.56      0.03      0.28      0.59      1.05      2.06 #> sigma[Jackson2019: Pbo]       0.88    0.01 0.32      0.43      0.65      0.83      1.05      1.68 #> sigma[Jackson2019: Len]       1.06    0.01 0.43      0.45      0.75      0.98      1.30      2.09 #> sigma[Morgan2012: Pbo]        0.51    0.01 0.35      0.05      0.26      0.43      0.68      1.40 #> sigma[Morgan2012: Thal]       1.07    0.01 0.45      0.36      0.74      1.01      1.33      2.12 #>                          n_eff Rhat #> d[Len]                    2546    1 #> d[Thal]                   3304    1 #> lp__                      1252    1 #> sigma[Attal2012: Pbo]     1825    1 #> sigma[Attal2012: Len]     1854    1 #> sigma[McCarthy2012: Pbo]  2327    1 #> sigma[McCarthy2012: Len]  2396    1 #> sigma[Palumbo2014: Pbo]   2391    1 #> sigma[Palumbo2014: Len]   2302    1 #> sigma[Jackson2019: Pbo]   2060    1 #> sigma[Jackson2019: Len]   1774    1 #> sigma[Morgan2012: Pbo]    2150    1 #> sigma[Morgan2012: Thal]   2407    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Oct 12 23:07:04 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Compare overall model fit (ndmm_fit_nma_loo <- loo(ndmm_fit_nma)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12473.4 115.2 #> p_loo        27.1   0.4 #> looic     24946.7 230.5 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  (ndmm_fit_nma_nph_loo <- loo(ndmm_fit_nma_nph)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12475.9 115.3 #> p_loo        37.6   0.6 #> looic     24951.8 230.6 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  loo_compare(ndmm_fit_nma_loo, ndmm_fit_nma_nph_loo) #>        elpd_diff se_diff #> model1  0.0       0.0    #> model2 -2.5       4.4  # Compare model fit by study cbind(   PH = by(ndmm_fit_nma_loo$pointwise[, \"looic\"], studies_all, sum),   `non-PH` = by(ndmm_fit_nma_nph_loo$pointwise[, \"looic\"], studies_all, sum) ) #>                     PH    non-PH #> Attal2012     3410.058  3410.280 #> Jackson2019  12404.314 12398.934 #> McCarthy2012  2770.382  2781.407 #> Morgan2012    4989.289  4990.538 #> Palumbo2014   1372.698  1370.594"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"producing-population-average-estimates","dir":"Articles","previous_headings":"","what":"Producing population-average estimates","title":"Example: Newly diagnosed multiple myeloma","text":"now produce population-average estimates several different quantities interest. usual array posterior summary functions available, including relative_effects(), predict(), posterior_ranks() posterior_rank_probs(). predict() function particular numerous options working survival models, selected using type argument: \"survival\" survival probabilities \"hazard\" hazards \"cumhaz\" cumulative hazards \"rmst\" restricted mean survival times \"mean\" mean survival times (equivalent type = \"rmst\" time = Inf) \"quantile\" quantiles survival time distribution \"median\" median survival times (equivalent type = \"quantile\" quantiles = 0.5) \"link\" linear predictor producing population-average predictions (default level = \"aggregate\"), quantities corresponds population-average marginal survival function; see ?predict.stan_nma details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-survival-probabilities","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average survival probabilities","title":"Example: Newly diagnosed multiple myeloma","text":"produce population-average survival curves use predict() function type = \"survival\". marginal standardised survival curves. also overlay unadjusted Kaplan-Meier curves data using geom_km() helper function.  Whilst adjusted unadjusted curves exactly comparable (although marginal survival estimates, adjusted curves account differences covariate distributions arms relevant overall population study), estimated survival curves good fit data. baseline imbalance sex Palumbo2014 study accounted model, explains slight differences Kaplan-Meier curves .","code":"plot(predict(ndmm_fit, type = \"survival\")) +    geom_km(ndmm_net) +   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-median-survival-times","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average median survival times","title":"Example: Newly diagnosed multiple myeloma","text":"predict() function can produce range absolute effect summaries, example population-average median survival times:","code":"(medsurv <- predict(ndmm_fit, type = \"median\")) #> Warning: Evaluating M-spline at times beyond the boundary knots. #> Evaluating M-spline at times beyond the boundary knots. #> Evaluating M-spline at times beyond the boundary knots. #> Evaluating M-spline at times beyond the boundary knots. #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Attal2012: Pbo]  28.95 1.47 26.13 27.93 28.93 29.90 31.91     5299     3136 1.00 #> pred[Attal2012: Len]  46.74 2.33 42.20 45.14 46.78 48.29 51.41     7287     3045 1.00 #> pred[Attal2012: Thal] 32.35 3.42 26.30 29.99 32.11 34.43 39.96     2487     3264 1.01 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                           mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[McCarthy2012: Pbo]  33.79 2.11 29.63 32.37 33.74 35.16 38.05     4417     3185 1.00 #> pred[McCarthy2012: Len]  55.66 3.31 49.21 53.37 55.69 57.81 62.25     5297     3292 1.00 #> pred[McCarthy2012: Thal] 38.52 4.02 31.17 35.83 38.32 41.02 46.74     3925     3168 1.01 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Palumbo2014: Pbo]  22.29 2.21 18.29 20.75 22.14 23.76 26.91     4908     3445 1.00 #> pred[Palumbo2014: Len]  44.53 4.65 36.18 41.24 44.34 47.42 54.18     7050     2970 1.00 #> pred[Palumbo2014: Thal] 27.56 4.21 20.07 24.61 27.28 30.17 36.60     4591     3615 1.01 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Jackson2019: Pbo]  24.45 1.34 22.02 23.50 24.43 25.33 27.15     2035     3398 1.01 #> pred[Jackson2019: Len]  50.47 2.48 45.75 48.76 50.38 52.05 55.47      118     2795 1.03 #> pred[Jackson2019: Thal] 31.27 3.76 24.60 28.64 31.03 33.65 39.21     5212     3108 1.00 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                         mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Morgan2012: Pbo]  21.22 1.90 17.67 19.91 21.13 22.45 25.26     1157     3295 1.01 #> pred[Morgan2012: Len]  48.88 6.57 38.03 44.37 48.25 52.45 63.32      873     3187 1.01 #> pred[Morgan2012: Thal] 27.59 2.50 23.22 25.81 27.40 29.25 32.85     4950     3698 1.00  plot(medsurv)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-conditional-log-hazard-ratios","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average conditional log hazard ratios","title":"Example: Newly diagnosed multiple myeloma","text":"Relative effects produced using relative_effects() function. ML-NMR model (IPD meta-regression), population-average conditional log hazard ratios (log survival time ratios AFT models).","code":"(loghr <- relative_effects(ndmm_fit, all_contrasts = TRUE)) #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  54.29        0.2             0.54 0.57 #>  #>                             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Attal2012: Len vs. Pbo]  -0.60 0.07 -0.74 -0.64 -0.59 -0.54 -0.45     7342     3387 1.00 #> d[Attal2012: Thal vs. Pbo] -0.13 0.13 -0.39 -0.22 -0.13 -0.04  0.12     4188     3416 1.01 #> d[Attal2012: Thal vs. Len]  0.46 0.12  0.24  0.38  0.46  0.54  0.69     3631     3276 1.01 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  57.66       0.23             0.67 0.54 #>  #>                                mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[McCarthy2012: Len vs. Pbo]  -0.62 0.06 -0.74 -0.66 -0.62 -0.58 -0.51     7421     3243 1.00 #> d[McCarthy2012: Thal vs. Pbo] -0.16 0.12 -0.39 -0.24 -0.16 -0.08  0.07     4194     2877 1.01 #> d[McCarthy2012: Thal vs. Len]  0.46 0.12  0.24  0.38  0.46  0.54  0.69     3631     3276 1.01 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  54.17       0.11              0.4 0.55 #>  #>                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Palumbo2014: Len vs. Pbo]  -0.64 0.08 -0.80 -0.70 -0.64 -0.58 -0.48     7666     3354 1.00 #> d[Palumbo2014: Thal vs. Pbo] -0.18 0.14 -0.44 -0.27 -0.18 -0.08  0.09     4182     3321 1.01 #> d[Palumbo2014: Thal vs. Len]  0.46 0.12  0.24  0.38  0.46  0.54  0.69     3631     3276 1.01 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  64.63       0.21             0.84 0.62 #>  #>                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Jackson2019: Len vs. Pbo]  -0.69 0.06 -0.81 -0.72 -0.69 -0.64 -0.57     4040     3447 1.00 #> d[Jackson2019: Thal vs. Pbo] -0.22 0.11 -0.44 -0.29 -0.22 -0.15 -0.01     4339     2883 1.01 #> d[Jackson2019: Thal vs. Len]  0.46 0.12  0.24  0.38  0.46  0.54  0.69     3631     3276 1.01 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  64.46       0.33             0.73 0.62 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Morgan2012: Len vs. Pbo]  -0.68 0.06 -0.80 -0.72 -0.68 -0.64 -0.56     4134     3288 1.00 #> d[Morgan2012: Thal vs. Pbo] -0.22 0.10 -0.42 -0.28 -0.22 -0.15 -0.02     4430     2726 1.01 #> d[Morgan2012: Thal vs. Len]  0.46 0.12  0.24  0.38  0.46  0.54  0.69     3631     3276 1.01  plot(loghr)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-arm-based-data","dir":"Articles","previous_headings":"","what":"Analysis of arm-based data","title":"Example: Parkinson's disease","text":"begin analysis arm-based data - means standard errors.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"arm-level continuous data giving mean -time reduction (y) standard error (se) arm. use function set_agd_arm() set network. let treatment 4 set default network reference treatment, since results considerably improved sampling efficiency choosing treatment 1 network reference. sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"arm_net <- set_agd_arm(parkinsons,                        study = studyn,                       trt = trtn,                       y = y,                        se = se,                       sample_size = n) arm_net #> A network with 7 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(arm_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. arm_fit_FE <- nma(arm_net,                    trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10)) #> Note: Setting \"4\" as the network reference treatment. arm_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> d[1]   0.52    0.01 0.48  -0.42   0.20   0.52   0.84   1.48  1494    1 #> d[2]  -1.28    0.01 0.53  -2.33  -1.64  -1.29  -0.92  -0.27  1583    1 #> d[3]   0.04    0.01 0.33  -0.60  -0.18   0.04   0.26   0.68  2236    1 #> d[5]  -0.30    0.00 0.21  -0.71  -0.44  -0.31  -0.17   0.11  2949    1 #> lp__ -58.24    0.06 2.38 -63.79 -59.63 -57.90 -56.50 -54.63  1664    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:38:21 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(arm_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(arm_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. arm_fit_RE <- nma(arm_net,                    seed = 379394727,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = half_normal(scale = 5),                   adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. #> Warning: There were 2 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems pairs(arm_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\")) arm_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> d[1]   0.52    0.01 0.62  -0.67   0.15   0.52   0.91   1.72  1710 1.00 #> d[2]  -1.31    0.02 0.73  -2.69  -1.76  -1.31  -0.85   0.04  1711 1.00 #> d[3]   0.03    0.01 0.48  -0.92  -0.24   0.03   0.31   1.00  1856 1.00 #> d[5]  -0.29    0.01 0.41  -1.10  -0.51  -0.30  -0.08   0.63  1637 1.00 #> lp__ -76.16    0.10 3.51 -83.71 -78.35 -75.84 -73.72 -70.07  1146 1.00 #> tau    0.39    0.02 0.39   0.01   0.13   0.28   0.52   1.43   650 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:38:31 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(arm_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(arm_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(arm_dic_FE <- dic(arm_fit_FE)) #> Residual deviance: 13.3 (on 15 data points) #>                pD: 11 #>               DIC: 24.4 (arm_dic_RE <- dic(arm_fit_RE)) #> Residual deviance: 13.7 (on 15 data points) #>                pD: 12.5 #>               DIC: 26.3 plot(arm_dic_FE) plot(arm_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean \\(-0.73\\) precision \\(21\\). use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify trt_ref = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted, predictions mean -time reduction produced every study network based estimated baseline response \\(\\mu_j\\):  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(arm_releff_FE <- relative_effects(arm_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.52 0.48 -1.48 -0.84 -0.52 -0.20  0.42     1529     1987    1 #> d[2] -1.80 0.33 -2.47 -2.02 -1.81 -1.58 -1.17     5397     3202    1 #> d[3] -0.48 0.49 -1.45 -0.81 -0.48 -0.15  0.47     2182     2848    1 #> d[5] -0.83 0.52 -1.85 -1.18 -0.83 -0.49  0.21     1621     2358    1 plot(arm_releff_FE, ref_line = 0) (arm_releff_RE <- relative_effects(arm_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.52 0.62 -1.72 -0.91 -0.52 -0.15  0.67     1774     2046    1 #> d[2] -1.83 0.50 -2.83 -2.12 -1.82 -1.53 -0.88     3630     2352    1 #> d[3] -0.49 0.66 -1.76 -0.90 -0.49 -0.10  0.74     2630     1949    1 #> d[5] -0.81 0.76 -2.30 -1.26 -0.82 -0.38  0.71     1730     2076    1 plot(arm_releff_RE, ref_line = 0) arm_pred_FE <- predict(arm_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) arm_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.25 0.53 -2.27 -1.61 -1.26 -0.90 -0.20     1699     2397    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.58 -0.29     3910     3936    1 #> pred[2] -2.53 0.40 -3.31 -2.80 -2.55 -2.27 -1.74     4990     3869    1 #> pred[3] -1.21 0.54 -2.26 -1.57 -1.22 -0.84 -0.16     2408     2891    1 #> pred[5] -1.56 0.56 -2.65 -1.93 -1.55 -1.18 -0.46     1757     2382    1 plot(arm_pred_FE) arm_pred_RE <- predict(arm_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) arm_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.25 0.66 -2.57 -1.66 -1.26 -0.84  0.08     1941     2195    1 #> pred[1] -0.73 0.22 -1.16 -0.87 -0.73 -0.58 -0.30     3976     3867    1 #> pred[2] -2.55 0.56 -3.64 -2.89 -2.55 -2.21 -1.49     3511     2486    1 #> pred[3] -1.22 0.69 -2.58 -1.65 -1.22 -0.79  0.13     2647     2099    1 #> pred[5] -1.54 0.80 -3.16 -2.01 -1.55 -1.06  0.10     1911     2256    1 plot(arm_pred_RE) arm_pred_FE_studies <- predict(arm_fit_FE, type = \"response\") arm_pred_FE_studies #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[1: 4] -1.64 0.46 -2.57 -1.93 -1.64 -1.34 -0.71     2013     2736    1 #> pred[1: 1] -1.12 0.43 -1.97 -1.41 -1.13 -0.83 -0.27     3601     3334    1 #> pred[1: 2] -2.92 0.51 -3.93 -3.26 -2.92 -2.58 -1.95     3308     3245    1 #> pred[1: 3] -1.60 0.39 -2.40 -1.87 -1.59 -1.32 -0.83     3638     3119    1 #> pred[1: 5] -1.94 0.51 -2.97 -2.26 -1.94 -1.61 -0.96     2119     2751    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[2: 4] -1.17 0.52 -2.21 -1.52 -1.17 -0.81 -0.15     1559     2300    1 #> pred[2: 1] -0.65 0.26 -1.15 -0.82 -0.64 -0.47 -0.14     4763     3614    1 #> pred[2: 2] -2.45 0.24 -2.92 -2.61 -2.45 -2.29 -1.97     4993     3321    1 #> pred[2: 3] -1.13 0.54 -2.20 -1.49 -1.12 -0.77 -0.08     2155     2924    1 #> pred[2: 5] -1.47 0.56 -2.57 -1.84 -1.48 -1.09 -0.35     1646     2139    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[3: 4] -1.11 0.43 -1.95 -1.40 -1.11 -0.83 -0.25     1886     2390    1 #> pred[3: 1] -0.59 0.37 -1.31 -0.83 -0.59 -0.34  0.13     4325     3226    1 #> pred[3: 2] -2.39 0.39 -3.15 -2.65 -2.39 -2.13 -1.63     3704     3294    1 #> pred[3: 3] -1.07 0.48 -2.03 -1.39 -1.06 -0.75 -0.14     2763     3013    1 #> pred[3: 5] -1.41 0.47 -2.33 -1.72 -1.42 -1.11 -0.48     1952     2775    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4: 4] -0.39 0.30 -0.99 -0.59 -0.39 -0.19  0.19     2574     2835    1 #> pred[4: 1]  0.13 0.51 -0.87 -0.21  0.14  0.48  1.13     2020     2700    1 #> pred[4: 2] -1.67 0.56 -2.76 -2.04 -1.68 -1.29 -0.57     2066     2695    1 #> pred[4: 3] -0.35 0.24 -0.81 -0.51 -0.35 -0.19  0.14     5117     3445    1 #> pred[4: 5] -0.69 0.36 -1.39 -0.94 -0.69 -0.44 -0.01     2748     3217    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[5: 4] -0.55 0.34 -1.20 -0.79 -0.55 -0.33  0.13     2864     2908    1 #> pred[5: 1] -0.03 0.54 -1.09 -0.39 -0.02  0.33  1.03     2092     2697    1 #> pred[5: 2] -1.84 0.58 -2.98 -2.22 -1.84 -1.45 -0.69     2101     2601    1 #> pred[5: 3] -0.51 0.29 -1.07 -0.70 -0.51 -0.32  0.06     5638     3643    1 #> pred[5: 5] -0.86 0.40 -1.65 -1.13 -0.86 -0.59 -0.07     2993     3061    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[6: 4] -2.19 0.17 -2.53 -2.31 -2.20 -2.08 -1.85     3024     2980    1 #> pred[6: 1] -1.67 0.51 -2.71 -2.01 -1.67 -1.33 -0.66     1542     2189    1 #> pred[6: 2] -3.48 0.55 -4.57 -3.85 -3.48 -3.10 -2.39     1654     2402    1 #> pred[6: 3] -2.15 0.37 -2.88 -2.40 -2.16 -1.91 -1.43     2409     2796    1 #> pred[6: 5] -2.50 0.17 -2.83 -2.61 -2.50 -2.38 -2.17     5627     2766    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[7: 4] -1.79 0.18 -2.14 -1.91 -1.79 -1.67 -1.45     3542     2517    1 #> pred[7: 1] -1.27 0.52 -2.29 -1.62 -1.27 -0.92 -0.25     1673     2239    1 #> pred[7: 2] -3.08 0.56 -4.17 -3.46 -3.08 -2.68 -1.99     1717     2492    1 #> pred[7: 3] -1.75 0.37 -2.49 -2.00 -1.75 -1.51 -1.04     2466     2832    1 #> pred[7: 5] -2.10 0.20 -2.50 -2.23 -2.10 -1.96 -1.69     4762     3244    1 plot(arm_pred_FE_studies) (arm_ranks <- posterior_ranks(arm_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.51 0.70    2   3   3   4     5     2272       NA    1 #> rank[1] 4.63 0.78    2   5   5   5     5     2078       NA    1 #> rank[2] 1.06 0.29    1   1   1   1     2     2582     2644    1 #> rank[3] 3.53 0.92    2   3   4   4     5     3076       NA    1 #> rank[5] 2.27 0.67    1   2   2   2     4     2492     2805    1 plot(arm_ranks) (arm_rankprobs <- posterior_rank_probs(arm_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.48      0.40      0.08 #> d[1]      0.00      0.04      0.06      0.12      0.78 #> d[2]      0.96      0.03      0.01      0.00      0.00 #> d[3]      0.00      0.16      0.27      0.43      0.13 #> d[5]      0.04      0.72      0.17      0.05      0.01 plot(arm_rankprobs) (arm_cumrankprobs <- posterior_rank_probs(arm_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.53      0.92         1 #> d[1]      0.00      0.04      0.11      0.22         1 #> d[2]      0.96      0.99      1.00      1.00         1 #> d[3]      0.00      0.16      0.43      0.87         1 #> d[5]      0.04      0.76      0.94      0.99         1 plot(arm_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-contrast-based-data","dir":"Articles","previous_headings":"","what":"Analysis of contrast-based data","title":"Example: Parkinson's disease","text":"now perform analysis using contrast-based data (mean differences standard errors).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"contrast-level data giving mean difference -time reduction (diff) standard error (se_diff), use function set_agd_contrast() set network. sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"contr_net <- set_agd_contrast(parkinsons,                                study = studyn,                               trt = trtn,                               y = diff,                                se = se_diff,                               sample_size = n) contr_net #> A network with 7 AgD studies (contrast-based). #>  #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(contr_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. contr_fit_FE <- nma(contr_net,                      trt_effects = \"fixed\",                     prior_trt = normal(scale = 100)) #> Note: Setting \"4\" as the network reference treatment. contr_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> d[1]   0.51    0.01 0.48  -0.45   0.19   0.51   0.83   1.45  1960    1 #> d[2]  -1.30    0.01 0.52  -2.32  -1.65  -1.29  -0.94  -0.31  1929    1 #> d[3]   0.04    0.01 0.33  -0.59  -0.18   0.04   0.27   0.67  2585    1 #> d[5]  -0.30    0.00 0.21  -0.72  -0.45  -0.30  -0.16   0.10  3750    1 #> lp__ -25.25    0.03 1.40 -28.84 -25.94 -24.93 -24.22 -23.49  1923    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:38:51 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). plot_prior_posterior(contr_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. contr_fit_RE <- nma(contr_net,                      seed = 1150676438,                     trt_effects = \"random\",                     prior_trt = normal(scale = 100),                     prior_het = half_normal(scale = 5),                     adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. pairs(contr_fit_RE, pars = c(\"d[3]\", \"delta[4: 4 vs. 3]\", \"tau\")) contr_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> d[1]   0.53    0.02 0.63  -0.63   0.14   0.53   0.91   1.80  1729 1.00 #> d[2]  -1.30    0.02 0.68  -2.64  -1.72  -1.31  -0.89   0.07  1778 1.00 #> d[3]   0.04    0.01 0.46  -0.89  -0.23   0.04   0.30   1.00  1998 1.00 #> d[5]  -0.30    0.01 0.45  -1.12  -0.50  -0.29  -0.09   0.55  1245 1.00 #> lp__ -32.79    0.08 2.73 -38.78 -34.51 -32.54 -30.84 -28.11  1144 1.01 #> tau    0.39    0.02 0.40   0.01   0.12   0.28   0.51   1.50   628 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:38:58 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(contr_fit_RE, pars = c(\"d\", \"delta\")) plot_prior_posterior(contr_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(contr_dic_FE <- dic(contr_fit_FE)) #> Residual deviance: 6.3 (on 8 data points) #>                pD: 4 #>               DIC: 10.3 (contr_dic_RE <- dic(contr_fit_RE)) #> Residual deviance: 6.5 (on 8 data points) #>                pD: 5.3 #>               DIC: 11.9 plot(contr_dic_FE) plot(contr_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean \\(-0.73\\) precision \\(21\\). use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify trt_ref = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted error raised, study baselines estimated network. can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(contr_releff_FE <- relative_effects(contr_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.51 0.48 -1.45 -0.83 -0.51 -0.19  0.45     1992     2501    1 #> d[2] -1.81 0.33 -2.46 -2.02 -1.80 -1.59 -1.17     4600     3370    1 #> d[3] -0.46 0.48 -1.39 -0.79 -0.46 -0.13  0.50     2910     3175    1 #> d[5] -0.81 0.52 -1.82 -1.17 -0.82 -0.46  0.23     2306     2696    1 plot(contr_releff_FE, ref_line = 0) (contr_releff_RE <- relative_effects(contr_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.53 0.63 -1.80 -0.91 -0.53 -0.14  0.63     2077     1539    1 #> d[2] -1.84 0.50 -2.84 -2.11 -1.83 -1.55 -0.89     3782     2513    1 #> d[3] -0.50 0.65 -1.75 -0.89 -0.49 -0.12  0.75     3121     1834    1 #> d[5] -0.83 0.79 -2.32 -1.24 -0.82 -0.39  0.61     1834     1147    1 plot(contr_releff_RE, ref_line = 0) contr_pred_FE <- predict(contr_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) contr_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.24 0.52 -2.28 -1.59 -1.23 -0.90 -0.22     2141     2747    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.58 -0.30     3988     3629    1 #> pred[2] -2.53 0.39 -3.31 -2.80 -2.54 -2.26 -1.76     4307     3185    1 #> pred[3] -1.19 0.52 -2.21 -1.54 -1.20 -0.84 -0.14     3030     3120    1 #> pred[5] -1.54 0.56 -2.64 -1.93 -1.54 -1.17 -0.40     2437     2998    1 plot(contr_pred_FE) contr_pred_RE <- predict(contr_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) contr_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.27 0.67 -2.57 -1.67 -1.26 -0.85  0.00     2172     1664    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.59 -0.31     3715     3592    1 #> pred[2] -2.57 0.54 -3.68 -2.89 -2.57 -2.23 -1.53     3756     2658    1 #> pred[3] -1.23 0.68 -2.52 -1.65 -1.22 -0.81  0.09     3176     2175    1 #> pred[5] -1.56 0.82 -3.17 -2.00 -1.55 -1.10 -0.06     1977     1247    1 plot(contr_pred_RE) # Not run predict(contr_fit_FE, type = \"response\") (contr_ranks <- posterior_ranks(contr_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.52 0.72    2   3   3   4     5     2539       NA    1 #> rank[1] 4.62 0.80    2   5   5   5     5     2579       NA    1 #> rank[2] 1.04 0.23    1   1   1   1     2     2925     2905    1 #> rank[3] 3.52 0.92    2   3   4   4     5     3559       NA    1 #> rank[5] 2.29 0.67    1   2   2   3     4     2569     2771    1 plot(contr_ranks) (contr_rankprobs <- posterior_rank_probs(contr_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.49      0.38      0.09 #> d[1]      0.00      0.05      0.06      0.12      0.77 #> d[2]      0.96      0.03      0.00      0.00      0.00 #> d[3]      0.00      0.16      0.26      0.45      0.12 #> d[5]      0.03      0.72      0.19      0.05      0.01 plot(contr_rankprobs) (contr_cumrankprobs <- posterior_rank_probs(contr_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.53      0.91         1 #> d[1]      0.00      0.05      0.11      0.23         1 #> d[2]      0.96      1.00      1.00      1.00         1 #> d[3]      0.00      0.17      0.43      0.88         1 #> d[5]      0.03      0.75      0.94      0.99         1 plot(contr_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-mixed-arm-based-and-contrast-based-data","dir":"Articles","previous_headings":"","what":"Analysis of mixed arm-based and contrast-based data","title":"Example: Parkinson's disease","text":"now perform analysis studies contribute arm-based data, contribute contrast-based data. Replicating Dias et al. (2011), consider arm-based data studies 1-3, contrast-based data studies 4-7.","code":"studies <- parkinsons$studyn (parkinsons_arm <- parkinsons[studies %in% 1:3, ]) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718 #> 7      3    4 -1.20 0.478  81 -0.90   0.695 (parkinsons_contr <- parkinsons[studies %in% 4:7, ]) #>    studyn trtn     y    se   n  diff se_diff #> 8       4    3 -0.24 0.265 128    NA   0.265 #> 9       4    4 -0.59 0.354  72 -0.35   0.442 #> 10      5    3 -0.73 0.335  80    NA   0.335 #> 11      5    4 -0.18 0.442  46  0.55   0.555 #> 12      6    4 -2.20 0.197 137    NA   0.197 #> 13      6    5 -2.50 0.190 131 -0.30   0.274 #> 14      7    4 -1.80 0.200 154    NA   0.200 #> 15      7    5 -2.10 0.250 143 -0.30   0.320"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"use functions set_agd_arm() set_agd_contrast() set respective data sources within network, combine together combine_network(). sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"mix_arm_net <- set_agd_arm(parkinsons_arm,                             study = studyn,                            trt = trtn,                            y = y,                             se = se,                            sample_size = n)  mix_contr_net <- set_agd_contrast(parkinsons_contr,                                    study = studyn,                                   trt = trtn,                                   y = diff,                                    se = se_diff,                                   sample_size = n)  mix_net <- combine_network(mix_arm_net, mix_contr_net) mix_net #> A network with 3 AgD studies (arm-based), and 4 AgD studies (contrast-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  #>  Outcome type: continuous #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(mix_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. mix_fit_FE <- nma(mix_net,                    trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100)) #> Note: Setting \"4\" as the network reference treatment. mix_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> d[1]   0.53    0.01 0.48  -0.43   0.21   0.53   0.85   1.44  1314    1 #> d[2]  -1.29    0.01 0.52  -2.34  -1.64  -1.29  -0.93  -0.30  1432    1 #> d[3]   0.05    0.01 0.32  -0.58  -0.17   0.04   0.27   0.68  2217    1 #> d[5]  -0.30    0.00 0.21  -0.71  -0.44  -0.30  -0.17   0.11  2816    1 #> lp__ -43.30    0.04 1.88 -47.72 -44.33 -42.97 -41.90 -40.60  1859    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:39:12 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(mix_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(mix_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. mix_fit_RE <- nma(mix_net,                    seed = 437219664,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = half_normal(scale = 5),                   adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. #> Warning: There were 18 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess pairs(mix_fit_RE, pars = c(\"d[3]\", \"delta[4: 4 vs. 3]\", \"tau\")) mix_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat #> d[1]   0.56    0.02 0.67  -0.72   0.15   0.56   0.93   1.94   837 1.01 #> d[2]  -1.27    0.04 0.80  -2.74  -1.71  -1.29  -0.85   0.19   432 1.01 #> d[3]   0.04    0.02 0.52  -1.02  -0.24   0.05   0.30   1.00   715 1.00 #> d[5]  -0.33    0.02 0.50  -1.50  -0.53  -0.32  -0.10   0.60   742 1.01 #> lp__ -51.90    0.10 3.22 -59.12 -53.79 -51.62 -49.66 -46.36  1119 1.00 #> tau    0.43    0.04 0.55   0.01   0.13   0.29   0.53   1.69   234 1.04 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:39:21 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(mix_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(mix_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(mix_dic_FE <- dic(mix_fit_FE)) #> Residual deviance: 9.3 (on 11 data points) #>                pD: 7 #>               DIC: 16.2 (mix_dic_RE <- dic(mix_fit_RE)) #> Residual deviance: 9.7 (on 11 data points) #>                pD: 8.5 #>               DIC: 18.2 plot(mix_dic_FE) plot(mix_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean \\(-0.73\\) precision \\(21\\). use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify trt_ref = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted, predictions mean -time reduction produced every arm-based study network based estimated baseline response \\(\\mu_j\\):  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(mix_releff_FE <- relative_effects(mix_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.53 0.48 -1.44 -0.85 -0.53 -0.21  0.43     1324     1823    1 #> d[2] -1.82 0.33 -2.48 -2.04 -1.81 -1.59 -1.15     5822     3307    1 #> d[3] -0.48 0.49 -1.45 -0.80 -0.48 -0.16  0.46     2162     2697    1 #> d[5] -0.83 0.52 -1.85 -1.18 -0.84 -0.48  0.19     1410     1885    1 plot(mix_releff_FE, ref_line = 0) (mix_releff_RE <- relative_effects(mix_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.56 0.67 -1.94 -0.93 -0.56 -0.15  0.72     1260      678 1.00 #> d[2] -1.83 0.58 -2.88 -2.12 -1.85 -1.54 -0.71     1894      685 1.01 #> d[3] -0.53 0.74 -1.91 -0.91 -0.50 -0.11  0.80     1445      652 1.00 #> d[5] -0.89 0.89 -2.62 -1.32 -0.87 -0.40  0.70     1186      515 1.00 plot(mix_releff_RE, ref_line = 0) mix_pred_FE <- predict(mix_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) mix_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.25 0.53 -2.28 -1.61 -1.26 -0.90 -0.21     1445     2165    1 #> pred[1] -0.72 0.22 -1.14 -0.87 -0.72 -0.58 -0.29     3556     3638    1 #> pred[2] -2.54 0.40 -3.32 -2.81 -2.54 -2.26 -1.77     4860     3651    1 #> pred[3] -1.20 0.54 -2.26 -1.55 -1.21 -0.85 -0.13     2253     2980    1 #> pred[5] -1.55 0.57 -2.68 -1.92 -1.56 -1.16 -0.45     1523     2083    1 plot(mix_pred_FE) mix_pred_RE <- predict(mix_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) mix_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.29 0.71 -2.76 -1.69 -1.29 -0.87  0.04     1318      664    1 #> pred[1] -0.73 0.22 -1.17 -0.88 -0.73 -0.58 -0.31     4051     3817    1 #> pred[2] -2.56 0.62 -3.73 -2.90 -2.56 -2.24 -1.40     1832      874    1 #> pred[3] -1.26 0.77 -2.74 -1.65 -1.23 -0.81  0.15     1402      660    1 #> pred[5] -1.62 0.92 -3.50 -2.08 -1.60 -1.10  0.02     1201      532    1 plot(mix_pred_RE) mix_pred_FE_studies <- predict(mix_fit_FE, type = \"response\") mix_pred_FE_studies #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[1: 4] -1.65 0.45 -2.51 -1.94 -1.64 -1.34 -0.76     1839     2305    1 #> pred[1: 1] -1.12 0.43 -1.97 -1.41 -1.12 -0.83 -0.29     3298     2870    1 #> pred[1: 2] -2.94 0.52 -3.94 -3.28 -2.94 -2.59 -1.92     3294     2922    1 #> pred[1: 3] -1.60 0.38 -2.34 -1.86 -1.61 -1.34 -0.86     3407     2836    1 #> pred[1: 5] -1.95 0.49 -2.91 -2.27 -1.95 -1.62 -0.97     1881     2480    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[2: 4] -1.17 0.51 -2.14 -1.52 -1.16 -0.82 -0.18     1363     2079    1 #> pred[2: 1] -0.64 0.26 -1.15 -0.81 -0.64 -0.47 -0.12     4954     3729    1 #> pred[2: 2] -2.45 0.24 -2.93 -2.62 -2.45 -2.29 -1.98     4943     3529    1 #> pred[2: 3] -1.12 0.53 -2.15 -1.46 -1.12 -0.77 -0.10     2095     2633    1 #> pred[2: 5] -1.47 0.55 -2.55 -1.84 -1.47 -1.09 -0.41     1409     1834    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[3: 4] -1.11 0.42 -1.92 -1.40 -1.12 -0.84 -0.28     1579     2614    1 #> pred[3: 1] -0.59 0.36 -1.30 -0.83 -0.59 -0.34  0.13     4003     3062    1 #> pred[3: 2] -2.40 0.39 -3.16 -2.66 -2.40 -2.14 -1.61     4060     3202    1 #> pred[3: 3] -1.07 0.47 -1.98 -1.40 -1.07 -0.75 -0.14     2799     2406    1 #> pred[3: 5] -1.42 0.47 -2.35 -1.73 -1.42 -1.10 -0.51     1642     2070    1 plot(mix_pred_FE_studies) (mix_ranks <- posterior_ranks(mix_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.50 0.71    2   3   3   4     5     1961       NA    1 #> rank[1] 4.66 0.75    2   5   5   5     5     2078       NA    1 #> rank[2] 1.05 0.26    1   1   1   1     2     1812     1600    1 #> rank[3] 3.52 0.92    2   3   4   4     5     3057       NA    1 #> rank[5] 2.27 0.65    1   2   2   2     4     2220     2540    1 plot(mix_ranks) (mix_rankprobs <- posterior_rank_probs(mix_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.49      0.39      0.08 #> d[1]      0.00      0.04      0.06      0.12      0.79 #> d[2]      0.96      0.03      0.01      0.00      0.00 #> d[3]      0.00      0.16      0.27      0.45      0.12 #> d[5]      0.04      0.72      0.18      0.05      0.01 plot(mix_rankprobs) (mix_cumrankprobs <- posterior_rank_probs(mix_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.53      0.92         1 #> d[1]      0.00      0.04      0.10      0.21         1 #> d[2]      0.96      0.99      1.00      1.00         1 #> d[3]      0.00      0.16      0.43      0.88         1 #> d[5]      0.04      0.76      0.94      0.99         1 plot(mix_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"initial_analysis","dir":"Articles","previous_headings":"","what":"Initial analysis","title":"Example: Plaque psoriasis ML-NMR","text":"start recreating analysis presented Phillippo et al. (2020). analyse IPD three studies, UNCOVER-1, UNCOVER-2, UNCOVER-3 (Griffiths et al. 2015; Gordon et al. 2016), AgD one study, FIXTURE (Langley et al. 2014). consider running ML-NMR adjusting five potential effect-modifying covariates: duration psoriasis durnpso, weight weight, previous systemic treatment prevsys, body surface area bsa, psoriatic arthritis psa.","code":"pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0  male bsa #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2  TRUE  18 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4  TRUE  33 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8  TRUE  33 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 FALSE  50 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 FALSE  35 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2  TRUE  29 #>   weight durnpso prevsys   psa #> 1   98.1     6.7    TRUE  TRUE #> 2  129.6    14.5   FALSE  TRUE #> 3   78.0    26.5    TRUE FALSE #> 4  139.9    25.0    TRUE  TRUE #> 5   54.2    11.9    TRUE FALSE #> 6   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n pasi100_r #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323        14 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324         0 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327        47 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323        78 #>   pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd pasi_w0_mean pasi_w0_sd male #> 1       323            326     43.8   13.0     28.7    5.9         23.2        9.8 71.2 #> 2       324            326     44.1   12.6     27.9    6.1         24.1       10.5 72.7 #> 3       327            327     45.4   12.9     28.4    5.9         23.7       10.5 72.2 #> 4       323            327     44.5   13.2     28.4    6.4         23.9        9.9 68.5 #>   bsa_mean bsa_sd weight_mean weight_sd durnpso_mean durnpso_sd prevsys  psa #> 1     33.6   18.0        84.6      20.5         16.4       12.0    65.6 13.5 #> 2     35.2   19.1        82.0      20.4         16.6       11.6    62.6 15.0 #> 3     34.5   19.4        83.6      20.8         17.3       12.2    64.8 15.0 #> 4     34.3   19.2        83.0      21.6         15.8       12.3    63.0 15.3"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"preparing-the-data","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Preparing the data","title":"Example: Plaque psoriasis ML-NMR","text":"need prepare data acceptable format run ML-NMR model. Firstly, need handle binary covariates prevsys psa. IPD, coded TRUE FALSE, AgD coded percentages (100). need transform sets variables numeric lie interval \\([0,1]\\), variables compatible across data sources. Whilst , also transform body surface area bsa (percentage) lie \\([0,1]\\), since make specifying appropriate marginal distribution easier later, rescale weight duration aid interpretation regression coefficients (terms 10 kilos 10 years respectively). also add trtclass variable, indicating treatments belong classes. Finally, check missing values IPD. small number individuals missing covariates: Since proportion missing data small, simply exclude individuals analysis.","code":"pso_ipd <- pso_ipd %>%    mutate(# Variable transformations          bsa = bsa / 100,          prevsys = as.numeric(prevsys),          psa = as.numeric(psa),          weight = weight / 10,          durnpso = durnpso / 10,          # Treatment classes          trtclass = case_when(trtn == 1 ~ \"Placebo\",                               trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                               trtn == 4 ~ \"TNFa blocker\"),          # Check complete cases for covariates of interest          complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%    mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                               trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                               trtn == 4 ~ \"TNFa blocker\")   ) sum(!pso_ipd$complete) #> [1] 4 mean(!pso_ipd$complete) #> [1] 0.001036807 pso_ipd <- filter(pso_ipd, complete)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"creating-the-network","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Creating the network","title":"Example: Plaque psoriasis ML-NMR","text":"Set network, setting IPD set_ipd(), AgD (arm-based) set_agd_arm(), combining together using combine_network(). specify binary pasi75 outcome r IPD, count outcome pasi75_r denominator pasi75_n r n AgD. specify treatment classes trt_class = trtclass. can produce network plot plot() method:","code":"pso_net <- combine_network(   set_ipd(pso_ipd,            study = studyc,            trt = trtc,            r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,                study = studyc,                trt = trtc,                r = pasi75_r,                n = pasi75_n,               trt_class = trtclass) )  pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE) +    ggplot2::theme(legend.position = \"bottom\", legend.box = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"numerical-integration-for-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Numerical integration for ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"ML-NMR models define meta-regression model individual level, exactly manner full-IPD meta-regression. ML-NMR incorporates AgD model integrating individual-level model covariate distribution AgD study (Phillippo et al. 2020; Phillippo 2019). Using integration, instead simply “plugging-” mean covariate values AgD studies, avoids aggregation bias link function identity function. package utilises numerical integration incorporate aggregate data - specifically, quasi-Monte Carlo (QMC) integration Gaussian copula (Phillippo et al. 2020; Phillippo 2019). QMC integration general flexible integration approach, typically requires far fewer integration points standard (pseudo-random) Monte-Carlo integration achieve numerical accuracy.1 Gaussian copula allows us account correlations covariates, may specified marginal distributions. now set numerical integration network. five covariates consider adjusting body surface area bsa, duration psoriasis durnpso, previous systemic treatment prevsys, psoriatic arthritis psa, weight weight. need choose suitable marginal distributions covariates draw integration points . prevsys psa binary covariates, given Bernoulli distribution. bsa percentage, choose logit-Normal distribution (note, requires logitnorm package installed). choose Gamma distributions durnpso weight account skewness. choices seem match well marginal distributions observed IPD:  add integration points AgD studies network using add_integration() function. Marginal distributions covariate specified using distr() function, takes cumulative distribution function corresponding chosen marginal distribution, arguments distribution column names aggregate data. Since know correlations covariates AgD studies, impute weighted mean correlations IPD studies (default option). Note: package provides several convenience functions specifying distributions, including qgamma() allows parameterisation Gamma distribution terms mean standard deviation, qbern() provides Bernoulli distribution, qlogitnorm() provides logit-Normal distribution allowing parameterisation terms mean standard deviation (requires logitnorm package installed).","code":"# Get mean and sd of covariates in each study ipd_summary <- pso_ipd %>%    group_by(studyc) %>%    summarise_at(vars(weight, durnpso, bsa), list(mean = mean, sd = sd, min = min, max = max)) %>%    pivot_longer(weight_mean:bsa_max, names_sep = \"_\", names_to = c(\"covariate\", \".value\")) %>%    # Assign distributions   mutate(dist = recode(covariate,                        bsa = \"dlogitnorm\",                        durnpso = \"dgamma\",                        weight = \"dgamma\")) %>%    # Compute density curves   group_by(studyc, covariate) %>%    mutate(value = if_else(dist == \"dlogitnorm\",                          list(seq(0, 1, length.out = 101)),                          list(seq(min*0.8, max*1.2, length.out = 101)))) %>%    unnest(cols = value) %>%    mutate(dens = eval(call(first(dist), x = value, mean = first(mean), sd = first(sd))))  # Plot histograms and assumed densities pso_ipd %>%    pivot_longer(c(weight, durnpso, bsa), names_to = \"covariate\", values_to = \"value\") %>%  ggplot(aes(x = value)) +   geom_histogram(aes(y = after_stat(density)),                   binwidth = function(x) diff(range(x)) / nclass.Sturges(x),                  boundary = 0,                  fill = \"grey50\") +   geom_line(aes(y = dens), data = ipd_summary,             colour = \"darkred\", linewidth = 0.5) +   facet_wrap(~studyc + covariate, scales = \"free\", ncol = 3) +   theme_multinma() pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64 ) #> Using weighted average correlation matrix computed from IPD studies."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"ml-nmr-models","dir":"Articles","previous_headings":"Initial analysis","what":"ML-NMR models","title":"Example: Plaque psoriasis ML-NMR","text":"fit fixed effect (FE) random effects (RE) ML-NMR models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"fixed-effect-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > ML-NMR models","what":"Fixed effect ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"First, fit FE ML-NMR model using function nma(). Following (Phillippo et al. 2020) specify weakly-informative \\(N(0, 10^2)\\) priors parameter. range parameter values implied prior distributions can checked using summary() method: regression model specified regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt, include main (prognostic) effects covariate well interactions treatment. use probit link function (link = \"probit\"), specify two-parameter Binomial approximation aggregate-level likelihood used (likelihood = \"bernoulli2\", “bernoulli” refers individual-level likelihood, “2” denotes two-parameter adjustment aggregate-level likelihood) (Phillippo et al. 2020). utilise shared effect modifier assumption help identify model, setting treatment-covariate interactions equal within class (class_interactions = \"common\"). narrow possible range random initial values init_r = 0.1 (default init_r = 2), since probit models particular often hard initialise. Using QR decomposition (QR = TRUE) greatly improves sampling efficiency , often case regression models. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  now recommend assessing sufficient accuracy numerical integration running half chains n_int / 2 integration points half full n_int. Rhat n_eff diagnostic warnings can either attributed insufficient MCMC iterations (argument iter nma()) insufficient integration points (n_int add_integration()), depending whether occur within two groups chains chains combined. feature enabled default (int_check = TRUE). case, warnings content number iterations number integration points. (Phillippo et al. (2020) used alternative approach based saving cumulative integration points plotting empirical integration error, can achieved setting int_thin nma() using plot_integration_error() function.)","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                    likelihood = \"bernoulli2\",                   regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   init_r = 0.1,                   QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. print(pso_fit_FE) #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                           0.04    0.00 0.06    -0.08     0.00     0.04     0.08 #> beta[prevsys]                          -0.14    0.00 0.16    -0.46    -0.25    -0.14    -0.03 #> beta[bsa]                              -0.07    0.01 0.43    -0.93    -0.36    -0.06     0.22 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02     0.04     0.06 #> beta[psa]                              -0.08    0.00 0.17    -0.42    -0.19    -0.08     0.03 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08    -0.03     0.02 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.14    -0.06    -0.01     0.04 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.19    -0.19     0.06     0.19     0.32 #> beta[prevsys:.trtclassIL blocker]       0.07    0.00 0.18    -0.29    -0.05     0.06     0.19 #> beta[bsa:.trtclassTNFa blocker]         0.06    0.01 0.50    -0.93    -0.28     0.05     0.39 #> beta[bsa:.trtclassIL blocker]           0.30    0.01 0.47    -0.62    -0.01     0.29     0.60 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.19    -0.17    -0.14 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12    -0.10    -0.08 #> beta[psa:.trtclassTNFa blocker]        -0.05    0.00 0.21    -0.46    -0.19    -0.06     0.09 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.18    -0.35    -0.11     0.01     0.13 #> d[ETN]                                  1.55    0.00 0.08     1.39     1.50     1.55     1.60 #> d[IXE_Q2W]                              2.95    0.00 0.09     2.78     2.89     2.95     3.01 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.38     2.49     2.54     2.60 #> d[SEC_150]                              2.14    0.00 0.12     1.91     2.06     2.14     2.22 #> d[SEC_300]                              2.45    0.00 0.12     2.21     2.37     2.45     2.53 #> lp__                                -1653.75    0.09 3.58 -1661.81 -1656.01 -1653.36 -1651.23 #>                                        97.5% n_eff Rhat #> beta[durnpso]                           0.16  5406    1 #> beta[prevsys]                           0.19  5480    1 #> beta[bsa]                               0.76  6530    1 #> beta[weight]                            0.09  4711    1 #> beta[psa]                               0.25  5844    1 #> beta[durnpso:.trtclassTNFa blocker]     0.11  6416    1 #> beta[durnpso:.trtclassIL blocker]       0.12  6718    1 #> beta[prevsys:.trtclassTNFa blocker]     0.55  5549    1 #> beta[prevsys:.trtclassIL blocker]       0.43  6916    1 #> beta[bsa:.trtclassTNFa blocker]         1.07  6885    1 #> beta[bsa:.trtclassIL blocker]           1.23  8119    1 #> beta[weight:.trtclassTNFa blocker]     -0.10  4448    1 #> beta[weight:.trtclassIL blocker]       -0.03  5797    1 #> beta[psa:.trtclassTNFa blocker]         0.35  5226    1 #> beta[psa:.trtclassIL blocker]           0.37  6683    1 #> d[ETN]                                  1.70  3844    1 #> d[IXE_Q2W]                              3.12  4971    1 #> d[IXE_Q4W]                              2.70  4010    1 #> d[SEC_150]                              2.37  3853    1 #> d[SEC_300]                              2.68  4551    1 #> lp__                                -1647.92  1522    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:40:23 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_FE, pars = c(\"d\", \"beta\", \"mu\")) plot_prior_posterior(pso_fit_FE, prior = c(\"intercept\", \"trt\", \"reg\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"random-effects-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > ML-NMR models","what":"Random effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"now fit RE model. , specify weakly-informative \\(N(0, 10^2)\\) priors parameter, now specify \\(\\textrm{half-N}(0, 2.5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). range parameter values implied prior distributions can checked using summary() method: Fitting model uses call nma() , except now trt_effects = \"random\". Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: number divergent transitions, can investigate using pairs() method:  divergent transition errors (red crosses) seem concentrated upper tail heterogeneity standard deviation parameter. suggests information identify heterogeneity parameter weak - four studies network - informative prior distribution might aid estimation. prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(half_normal(scale = 2.5)) #> A half-Normal prior distribution: location = 0, scale = 2.5. #> 50% of the prior density lies between 0 and 1.69. #> 95% of the prior density lies between 0 and 4.9. pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                    likelihood = \"bernoulli2\",                   regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_het = half_normal(scale = 2.5),                   init_r = 0.1,                   QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. #> Warning: There were 11 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems print(pso_fit_RE) #> A random effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                           0.05    0.00 0.06    -0.08     0.00     0.05     0.09 #> beta[prevsys]                          -0.12    0.00 0.16    -0.42    -0.23    -0.12    -0.01 #> beta[bsa]                              -0.09    0.01 0.45    -1.01    -0.39    -0.08     0.22 #> beta[weight]                            0.04    0.00 0.03    -0.01     0.02     0.04     0.06 #> beta[psa]                              -0.06    0.00 0.16    -0.39    -0.17    -0.06     0.05 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.18    -0.08    -0.03     0.02 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.15    -0.06    -0.01     0.03 #> beta[prevsys:.trtclassTNFa blocker]     0.18    0.00 0.18    -0.17     0.05     0.18     0.30 #> beta[prevsys:.trtclassIL blocker]       0.05    0.00 0.17    -0.29    -0.07     0.04     0.17 #> beta[bsa:.trtclassTNFa blocker]         0.08    0.01 0.53    -0.91    -0.29     0.06     0.43 #> beta[bsa:.trtclassIL blocker]           0.33    0.01 0.49    -0.59    -0.01     0.32     0.67 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.20    -0.17    -0.15 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.17    -0.13    -0.10    -0.08 #> beta[psa:.trtclassTNFa blocker]        -0.07    0.00 0.20    -0.46    -0.21    -0.08     0.06 #> beta[psa:.trtclassIL blocker]          -0.01    0.00 0.18    -0.37    -0.13    -0.02     0.11 #> d[ETN]                                  1.56    0.00 0.15     1.28     1.48     1.56     1.65 #> d[IXE_Q2W]                              2.98    0.00 0.15     2.69     2.88     2.97     3.07 #> d[IXE_Q4W]                              2.57    0.00 0.15     2.29     2.48     2.57     2.65 #> d[SEC_150]                              2.14    0.00 0.22     1.71     2.01     2.13     2.26 #> d[SEC_300]                              2.44    0.01 0.22     1.96     2.31     2.44     2.57 #> lp__                                -1659.38    0.15 4.82 -1669.61 -1662.36 -1659.01 -1656.04 #> tau                                     0.19    0.00 0.12     0.01     0.10     0.17     0.25 #>                                        97.5% n_eff Rhat #> beta[durnpso]                           0.17  5220    1 #> beta[prevsys]                           0.18  4624    1 #> beta[bsa]                               0.74  4269    1 #> beta[weight]                            0.10  4574    1 #> beta[psa]                               0.25  4703    1 #> beta[durnpso:.trtclassTNFa blocker]     0.11  5202    1 #> beta[durnpso:.trtclassIL blocker]       0.12  5296    1 #> beta[prevsys:.trtclassTNFa blocker]     0.54  4906    1 #> beta[prevsys:.trtclassIL blocker]       0.37  5427    1 #> beta[bsa:.trtclassTNFa blocker]         1.17  4285    1 #> beta[bsa:.trtclassIL blocker]           1.31  5181    1 #> beta[weight:.trtclassTNFa blocker]     -0.10  4662    1 #> beta[weight:.trtclassIL blocker]       -0.04  5232    1 #> beta[psa:.trtclassTNFa blocker]         0.32  4940    1 #> beta[psa:.trtclassIL blocker]           0.35  5892    1 #> d[ETN]                                  1.87  1989    1 #> d[IXE_Q2W]                              3.30  1787    1 #> d[IXE_Q4W]                              2.89  1732    1 #> d[SEC_150]                              2.60  2338    1 #> d[SEC_300]                              2.87  1908    1 #> lp__                                -1650.74   972    1 #> tau                                     0.47   737    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:45:02 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_RE, pars = c(\"d\", \"beta\", \"tau\", \"mu\", \"delta\")) pairs(pso_fit_RE, pars = c(\"delta[UNCOVER-2: ETN]\", \"d[ETN]\", \"tau\", \"lp__\")) plot_prior_posterior(pso_fit_RE, prior = c(\"intercept\", \"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"model-comparison","dir":"Articles","previous_headings":"Initial analysis","what":"Model comparison","title":"Example: Plaque psoriasis ML-NMR","text":"model fit FE RE models can checked using dic() function. DIC similar FE RE models, suggesting little evidence residual heterogeneity.","code":"(pso_dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 3129.7 (on 3858 data points) #>                pD: 24.4 #>               DIC: 3154 (pso_dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 3123.4 (on 3858 data points) #>                pD: 28 #>               DIC: 3151.4"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"producing-relative-effects-and-event-probabilities","dir":"Articles","previous_headings":"Initial analysis","what":"Producing relative effects and event probabilities","title":"Example: Plaque psoriasis ML-NMR","text":"Parameter estimates can plotted using plot() method, example examine estimated regression coefficients:  Plots posterior summaries based ggdist package, allows great degree flexibility, can customised using ggplot2 commands. command specify \"halfeye\" plot, shows posterior density along posterior medians (points) 95% Credible Intervals (thin line) 66% inner bands (thicker line) default. details plotting options see ?plot.nma_summary. can produce population-adjusted relative effects study population network using relative_effects() function.  Predicted probabilities achieving PASI 75 study population treatment produced using predict() method. argument type = \"reponse\" specifies want predicted probabilities, rather probit probabilities.  can produce population-adjusted ranks, rank probabilities, cumulative rank probabilities study population using posterior_ranks() posterior_rank_probs() functions (although ranks unchanged populations, distributions effect modifiers similar). specify lower_better = FALSE, since higher outcome better (higher chance achieving PASI 75).    estimates (relative effects, predictions, rankings) can also produced specific target population populations providing suitable newdata argument function (baseline distribution predict()). produce population-adjusted relative effects (corresponding rankings) chosen target population, require mean covariate values population. example, newdata provide following mean covariate values: Population-adjusted relative effects target population calculated using relative_effects() function, can plotted corresponding plot() method:  absolute predictions, require information full covariate distribution target population, just mean values. IPD available target population, newdata simply data frame IPD. AgD available target population, newdata must data frame added integration points created using add_integration() function. example, suppose aggregate target population introduced following covariate means standard deviations (continuous covariates) proportions (discrete covariates): add integration points data frame similar manner . , need supply correlation matrix joint covariate distribution; use weighted mean correlation matrix computed earlier IPD network, stored network object int_cor. Predicted probabilities achieving PASI 75 target population, given \\(N(-1.75, 0.08^2)\\) distribution baseline probit-probability response Placebo (reference levels covariates), produced using predict() method:","code":"plot(pso_fit_FE,      pars = \"beta\",      stat = \"halfeye\",      ref_line = 0) (pso_releff_FE <- relative_effects(pso_fit_FE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[FIXTURE: ETN]     1.66 0.09 1.49 1.60 1.65 1.72  1.83     3673     3090    1 #> d[FIXTURE: IXE_Q2W] 3.03 0.10 2.83 2.96 3.03 3.10  3.22     5015     3048    1 #> d[FIXTURE: IXE_Q4W] 2.61 0.09 2.44 2.55 2.61 2.68  2.80     4074     3049    1 #> d[FIXTURE: SEC_150] 2.22 0.12 1.98 2.14 2.22 2.29  2.44     3645     2730    1 #> d[FIXTURE: SEC_300] 2.52 0.12 2.28 2.44 2.52 2.60  2.76     4101     3406    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-1: ETN]     1.51 0.08 1.34 1.45 1.51 1.56  1.67     4214     3198    1 #> d[UNCOVER-1: IXE_Q2W] 2.92 0.09 2.75 2.86 2.92 2.98  3.09     5172     3019    1 #> d[UNCOVER-1: IXE_Q4W] 2.51 0.08 2.35 2.46 2.51 2.57  2.67     4388     3407    1 #> d[UNCOVER-1: SEC_150] 2.11 0.12 1.87 2.03 2.11 2.19  2.35     4264     3001    1 #> d[UNCOVER-1: SEC_300] 2.42 0.12 2.18 2.34 2.42 2.50  2.66     4965     3213    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-2: ETN]     1.51 0.08 1.35 1.45 1.51 1.56  1.66     4076     3134    1 #> d[UNCOVER-2: IXE_Q2W] 2.92 0.09 2.75 2.86 2.92 2.98  3.09     5157     2982    1 #> d[UNCOVER-2: IXE_Q4W] 2.51 0.08 2.35 2.46 2.51 2.56  2.66     4489     3532    1 #> d[UNCOVER-2: SEC_150] 2.11 0.12 1.87 2.03 2.11 2.19  2.34     4251     3005    1 #> d[UNCOVER-2: SEC_300] 2.42 0.12 2.18 2.34 2.42 2.50  2.65     5018     3162    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-3: ETN]     1.53 0.08 1.37 1.48 1.53 1.58  1.68     3958     3522    1 #> d[UNCOVER-3: IXE_Q2W] 2.94 0.09 2.77 2.88 2.94 3.00  3.11     5227     2861    1 #> d[UNCOVER-3: IXE_Q4W] 2.53 0.08 2.37 2.47 2.53 2.58  2.68     4296     3643    1 #> d[UNCOVER-3: SEC_150] 2.13 0.12 1.89 2.05 2.13 2.21  2.35     4125     3036    1 #> d[UNCOVER-3: SEC_300] 2.43 0.12 2.20 2.36 2.44 2.51  2.67     4857     3324    1 plot(pso_releff_FE, ref_line = 0) (pso_pred_FE <- predict(pso_fit_FE, type = \"response\")) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[FIXTURE: PBO]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     3405     3361    1 #> pred[FIXTURE: ETN]     0.46 0.02 0.41 0.44 0.46 0.47  0.50     7493     3313    1 #> pred[FIXTURE: IXE_Q2W] 0.89 0.02 0.85 0.88 0.89 0.90  0.92     6426     3281    1 #> pred[FIXTURE: IXE_Q4W] 0.80 0.03 0.74 0.78 0.80 0.81  0.84     6621     3171    1 #> pred[FIXTURE: SEC_150] 0.67 0.03 0.62 0.65 0.67 0.69  0.72     9946     3075    1 #> pred[FIXTURE: SEC_300] 0.77 0.02 0.72 0.75 0.77 0.79  0.81    10857     3223    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-1: PBO]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     4628     3082    1 #> pred[UNCOVER-1: ETN]     0.46 0.03 0.41 0.44 0.46 0.48  0.52     6483     3102    1 #> pred[UNCOVER-1: IXE_Q2W] 0.90 0.01 0.88 0.89 0.90 0.91  0.92     7784     3003    1 #> pred[UNCOVER-1: IXE_Q4W] 0.81 0.01 0.78 0.80 0.81 0.82  0.84     8895     3156    1 #> pred[UNCOVER-1: SEC_150] 0.69 0.04 0.60 0.66 0.69 0.72  0.76     6987     3087    1 #> pred[UNCOVER-1: SEC_300] 0.78 0.04 0.71 0.76 0.79 0.81  0.85     7271     3300    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-2: PBO]     0.05 0.01 0.03 0.04 0.05 0.05  0.06     4948     3285    1 #> pred[UNCOVER-2: ETN]     0.42 0.02 0.38 0.41 0.42 0.43  0.46     7887     2626    1 #> pred[UNCOVER-2: IXE_Q2W] 0.88 0.01 0.86 0.87 0.88 0.89  0.91     6600     2938    1 #> pred[UNCOVER-2: IXE_Q4W] 0.78 0.02 0.75 0.77 0.78 0.79  0.81     9116     3033    1 #> pred[UNCOVER-2: SEC_150] 0.65 0.04 0.56 0.62 0.65 0.68  0.73     7311     3282    1 #> pred[UNCOVER-2: SEC_300] 0.75 0.04 0.68 0.73 0.75 0.78  0.82     8585     3570    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-3: PBO]     0.08 0.01 0.06 0.07 0.08 0.08  0.10     5027     3726    1 #> pred[UNCOVER-3: ETN]     0.53 0.02 0.49 0.52 0.53 0.54  0.57     7831     2953    1 #> pred[UNCOVER-3: IXE_Q2W] 0.93 0.01 0.91 0.92 0.93 0.93  0.94     6683     3363    1 #> pred[UNCOVER-3: IXE_Q4W] 0.85 0.01 0.83 0.85 0.85 0.86  0.88     7353     3033    1 #> pred[UNCOVER-3: SEC_150] 0.75 0.03 0.67 0.72 0.75 0.77  0.81     6870     2755    1 #> pred[UNCOVER-3: SEC_300] 0.83 0.03 0.77 0.81 0.83 0.85  0.88     8173     2868    1 plot(pso_pred_FE, ref_line = c(0, 1)) (pso_ranks_FE <- posterior_ranks(pso_fit_FE, lower_better = FALSE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[FIXTURE: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[FIXTURE: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[FIXTURE: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[FIXTURE: IXE_Q4W] 2.21 0.41    2   2   2   2     3     4361     4016    1 #> rank[FIXTURE: SEC_150] 4.00 0.06    4   4   4   4     4     3159       NA    1 #> rank[FIXTURE: SEC_300] 2.79 0.42    2   3   3   3     3     4347     3063    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-1: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-1: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-1: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[UNCOVER-1: IXE_Q4W] 2.21 0.41    2   2   2   2     3     4361     4016    1 #> rank[UNCOVER-1: SEC_150] 4.00 0.06    4   4   4   4     4     3159       NA    1 #> rank[UNCOVER-1: SEC_300] 2.79 0.42    2   3   3   3     3     4347     3063    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-2: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-2: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-2: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[UNCOVER-2: IXE_Q4W] 2.21 0.41    2   2   2   2     3     4361     4016    1 #> rank[UNCOVER-2: SEC_150] 4.00 0.06    4   4   4   4     4     3159       NA    1 #> rank[UNCOVER-2: SEC_300] 2.79 0.42    2   3   3   3     3     4347     3063    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-3: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-3: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-3: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[UNCOVER-3: IXE_Q4W] 2.21 0.41    2   2   2   2     3     4361     4016    1 #> rank[UNCOVER-3: SEC_150] 4.00 0.06    4   4   4   4     4     3159       NA    1 #> rank[UNCOVER-3: SEC_300] 2.79 0.42    2   3   3   3     3     4347     3063    1 plot(pso_ranks_FE) (pso_rankprobs_FE <- posterior_rank_probs(pso_fit_FE, lower_better = FALSE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             0      0.00      0.00         0         0         1 #> d[FIXTURE: ETN]             0      0.00      0.00         0         1         0 #> d[FIXTURE: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[FIXTURE: IXE_Q4W]         0      0.79      0.21         0         0         0 #> d[FIXTURE: SEC_150]         0      0.00      0.00         1         0         0 #> d[FIXTURE: SEC_300]         0      0.21      0.78         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-1: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-1: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-1: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-1: IXE_Q4W]         0      0.79      0.21         0         0         0 #> d[UNCOVER-1: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-1: SEC_300]         0      0.21      0.78         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-2: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-2: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-2: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-2: IXE_Q4W]         0      0.79      0.21         0         0         0 #> d[UNCOVER-2: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-2: SEC_300]         0      0.21      0.78         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-3: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-3: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-3: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-3: IXE_Q4W]         0      0.79      0.21         0         0         0 #> d[UNCOVER-3: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-3: SEC_300]         0      0.21      0.78         0         0         0 plot(pso_rankprobs_FE) (pso_cumrankprobs_FE <- posterior_rank_probs(pso_fit_FE, lower_better = FALSE, cumulative = TRUE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             0      0.00         0         0         0         1 #> d[FIXTURE: ETN]             0      0.00         0         0         1         1 #> d[FIXTURE: IXE_Q2W]         1      1.00         1         1         1         1 #> d[FIXTURE: IXE_Q4W]         0      0.79         1         1         1         1 #> d[FIXTURE: SEC_150]         0      0.00         0         1         1         1 #> d[FIXTURE: SEC_300]         0      0.21         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-1: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-1: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-1: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-1: IXE_Q4W]         0      0.79         1         1         1         1 #> d[UNCOVER-1: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-1: SEC_300]         0      0.21         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-2: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-2: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-2: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-2: IXE_Q4W]         0      0.79         1         1         1         1 #> d[UNCOVER-2: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-2: SEC_300]         0      0.21         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-3: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-3: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-3: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-3: IXE_Q4W]         0      0.79         1         1         1         1 #> d[UNCOVER-3: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-3: SEC_300]         0      0.21         1         1         1         1 plot(pso_cumrankprobs_FE) new_agd_means <- tibble(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3) (pso_releff_FE_new <- relative_effects(pso_fit_FE, newdata = new_agd_means)) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[New 1: ETN]     1.25 0.23 0.82 1.10 1.25 1.41  1.73     6466     2970    1 #> d[New 1: IXE_Q2W] 2.89 0.22 2.44 2.74 2.89 3.04  3.34     7435     2861    1 #> d[New 1: IXE_Q4W] 2.48 0.22 2.05 2.33 2.47 2.63  2.91     7708     2788    1 #> d[New 1: SEC_150] 2.08 0.23 1.65 1.92 2.08 2.23  2.53     6597     2683    1 #> d[New 1: SEC_300] 2.39 0.23 1.96 2.23 2.38 2.54  2.85     6889     2848    1 plot(pso_releff_FE_new, ref_line = 0) new_agd_int <- tibble(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1 ) new_agd_int <- add_integration(new_agd_int,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   cor = pso_net$int_cor,   n_int = 64) (pso_pred_FE_new <- predict(pso_fit_FE,                              type = \"response\",                             newdata = new_agd_int,                             baseline = distr(qnorm, -1.75, 0.08))) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: PBO]     0.06 0.02 0.03 0.04 0.06 0.07  0.12     5611     2898    1 #> pred[New 1: ETN]     0.37 0.06 0.26 0.33 0.37 0.41  0.49     6195     3518    1 #> pred[New 1: IXE_Q2W] 0.90 0.03 0.84 0.88 0.90 0.92  0.94     6010     3709    1 #> pred[New 1: IXE_Q4W] 0.81 0.04 0.73 0.78 0.81 0.83  0.88     5825     3688    1 #> pred[New 1: SEC_150] 0.68 0.06 0.57 0.64 0.68 0.72  0.78     5546     3990    1 #> pred[New 1: SEC_300] 0.78 0.05 0.68 0.75 0.78 0.81  0.86     6040     3645    1 plot(pso_pred_FE_new, ref_line = c(0, 1))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"extended_analysis","dir":"Articles","previous_headings":"","what":"Extended analysis","title":"Example: Plaque psoriasis ML-NMR","text":"now extend network include five studies (four AgD one IPD), recreating analysis Phillippo et al. (2022). larger network allows us assess key assumptions underlying population adjustment.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"preparing-the-data-1","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Preparing the data","title":"Example: Plaque psoriasis ML-NMR","text":"begin, , data transformations covariates set treatment class variable trtclass. small number individuals missing values IPD, simply exclude analysis.","code":"# IPD studies pso_ipd <- plaque_psoriasis_ipd %>%    mutate(     # Variable transformations     bsa = bsa / 100,     weight = weight / 10,     durnpso = durnpso / 10,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL-17 blocker\",                          trtn == 4 ~ \"TNFa blocker\",                          trtn == 7 ~ \"IL-12/23 blocker\"),     # Check complete cases for covariates of interest     is_complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   ) %>%    arrange(studyc, trtn)  # AgD studies pso_agd <- plaque_psoriasis_agd %>%    mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,      bsa_sd = bsa_sd / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     prevsys = prevsys / 100,     psa = psa / 100,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL-17 blocker\",                          trtn == 4 ~ \"TNFa blocker\",                          trtn == 7 ~ \"IL-12/23 blocker\")     ) %>%    arrange(studyc, trtn) pso_ipd %>%    group_by(studyc) %>%    summarise(n_total = n(),             n_missing = sum(!is_complete),              pct_missing = mean(!is_complete) * 100) #> # A tibble: 4 × 4 #>   studyc    n_total n_missing pct_missing #>   <chr>       <int>     <int>       <dbl> #> 1 IXORA-S       260         0       0     #> 2 UNCOVER-1    1296         0       0     #> 3 UNCOVER-2    1221         2       0.164 #> 4 UNCOVER-3    1341         2       0.149  pso_ipd <- filter(pso_ipd, is_complete)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"creating-the-network-1","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Creating the network","title":"Example: Plaque psoriasis ML-NMR","text":"Next set network. set IPD set_ipd() AgD (arm-based) set_agd_arm(), combine together using combine_network(). specify ordered categorical (multinomial) outcome using multi() helper function. outcome data “inclusive” format, .e. lowest category sample size (1 IPD), second category counts achieving PASI 75 greater (\\(\\ge 75\\%\\) reduction symptoms), third counts achieving PASI 90 greater (\\(\\ge 90\\%\\) reduction), final category counts achieving PASI 100 (\\(100\\%\\) reduction).2 specify treatment classes trt_class = trtclass. create network plot using plot() function applied pso_net network object, choosing scale edges nodes number studies/sample size (weight_edges weight_nodes = TRUE), colour treatment nodes class (show_trt_class = TRUE), nudge treatment names away nodes (nudge = 0.1). customise plot using ggplot syntax alter colour scheme.","code":"pso_net <- combine_network(   set_ipd(pso_ipd,     study = studyc,     trt = trtc,     r = multi(r0 = 1,                PASI75 = pasi75,               PASI90 = pasi90,               PASI100 = pasi100,               type = \"ordered\", inclusive = TRUE),     trt_class = trtclass),   set_agd_arm(pso_agd,     study = studyc,     trt = trtc,     r = multi(r0 = pasi75_n,                PASI75 = pasi75_r,               PASI90 = pasi90_r,               PASI100 = pasi100_r,               type = \"ordered\", inclusive = TRUE),     trt_class = trtclass) )  pso_net #> A network with 4 IPD studies, and 5 AgD studies (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: PBO | IXE_Q2W | IXE_Q4W       #>  UNCOVER-2 4: PBO | IXE_Q2W | IXE_Q4W | ETN #>  UNCOVER-3 4: PBO | IXE_Q2W | IXE_Q4W | ETN #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study    Treatment arms                   #>  CLEAR    2: SEC_300 | UST                 #>  ERASURE  3: PBO | SEC_150 | SEC_300       #>  FEATURE  3: PBO | SEC_150 | SEC_300       #>  FIXTURE  4: PBO | ETN | SEC_150 | SEC_300 #>  JUNCTURE 3: PBO | SEC_150 | SEC_300       #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 7, in 4 classes #> Total number of studies: 9 #> Reference treatment is: PBO #> Network is connected class_pal <- c(\"#D95F02\", \"#7570B3\", \"#E7298A\", \"#E6AB02\")  plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE, nudge = 0.1) +   ggraph::scale_edge_colour_manual(\"Data\",                                     values = c(AgD = \"#113259\", IPD = \"#55A480\"),                                    guide = guide_legend(override.aes = list(edge_width = 2))) +   scale_fill_manual(\"Treatment class\",                      values = class_pal,                     aesthetics = c(\"fill\", \"colour\"),                     guide = guide_legend(override.aes = list(size = 2))) #> Scale for edge_colour is already present. #> Adding another scale for edge_colour, which will replace the existing scale. #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale. #> Warning: Duplicated `override.aes` is ignored."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"numerical-integration-for-ml-nmr-models","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Numerical integration for ML-NMR models","title":"Example: Plaque psoriasis ML-NMR","text":"add integration points AgD studies network using add_integration() function, specifying chosen marginal distribution covariate using distr() function. , specify Gamma distributions weight duration psoriasis, logit-Normal distribution body surface area, Bernoulli distributions previous systemic treatment psoriatic arthritis binary covariates. Since know correlations covariates AgD studies, impute weighted mean correlations IPD studies (default option).","code":"pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"ml-nmr-model","dir":"Articles","previous_headings":"Extended analysis","what":"ML-NMR model","title":"Example: Plaque psoriasis ML-NMR","text":"Using nma() function, fit (fixed effect) ML-NMR model includes main effects (prognostic terms) covariate-treatment interactions (effect-modifying terms) five covariates. Ideally, fit independent interaction terms treatment; however, requires either IPD several AgD studies range covariate values treatment. data insufficient fit independent interaction terms treatment, make shared effect modifier assumption within class treatments (Phillippo et al. 2016) specify common interaction terms within treatment class (class_interactions = \"common\"). , specify \\(\\mathrm{N}(0, 10^2)\\) prior distributions study-specific intercepts, treatment effects, regression parameters. However, since now ordered multinomial likelihood also need specify priors differences latent cutoffs outcome category; choose improper flat prior \\(\\mathrm{U}(-\\infty,\\infty)\\) automatically truncated meet ordering constraints (prior_aux = flat()).","code":"pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                    regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_aux = flat(),                   QR = TRUE,                   init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit_FE #> A fixed effects ML-NMR with a ordered likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8159830 0.6576489 0.2987820 8.9097263 0.2104826  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.03    0.00 0.06    -0.08    -0.01     0.03     0.08 #> beta[prevsys]                              -0.17    0.00 0.16    -0.49    -0.28    -0.17    -0.06 #> beta[bsa]                                  -0.10    0.01 0.45    -1.01    -0.40    -0.08     0.21 #> beta[weight]                                0.04    0.00 0.03    -0.01     0.02     0.04     0.06 #> beta[psa]                                  -0.08    0.00 0.17    -0.42    -0.20    -0.08     0.03 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.16    -0.07    -0.02     0.03 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.06    0.00 0.10    -0.26    -0.13    -0.07     0.00 #> beta[durnpso:.trtclassIL-17 blocker]       -0.02    0.00 0.06    -0.14    -0.07    -0.02     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.19    0.00 0.19    -0.18     0.07     0.19     0.32 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.45    0.01 0.34    -0.24     0.24     0.47     0.68 #> beta[prevsys:.trtclassIL-17 blocker]        0.16    0.00 0.17    -0.17     0.05     0.16     0.28 #> beta[bsa:.trtclassTNFa blocker]             0.24    0.01 0.51    -0.73    -0.11     0.22     0.57 #> beta[bsa:.trtclassIL-12/23 blocker]         0.61    0.01 0.68    -0.71     0.14     0.61     1.07 #> beta[bsa:.trtclassIL-17 blocker]            0.27    0.01 0.47    -0.63    -0.06     0.26     0.58 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.18    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.18    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.05    0.00 0.20    -0.43    -0.18    -0.04     0.08 #> beta[psa:.trtclassIL-12/23 blocker]         0.12    0.01 0.33    -0.51    -0.11     0.12     0.36 #> beta[psa:.trtclassIL-17 blocker]            0.10    0.00 0.18    -0.24    -0.02     0.10     0.21 #> d[ETN]                                      1.58    0.00 0.07     1.44     1.53     1.58     1.63 #> d[IXE_Q2W]                                  2.91    0.00 0.07     2.76     2.86     2.91     2.96 #> d[IXE_Q4W]                                  2.69    0.00 0.08     2.54     2.64     2.69     2.74 #> d[SEC_150]                                  2.19    0.00 0.08     2.03     2.13     2.19     2.24 #> d[SEC_300]                                  2.60    0.00 0.08     2.45     2.54     2.60     2.65 #> d[UST]                                      2.13    0.00 0.11     1.91     2.06     2.13     2.20 #> lp__                                    -7640.27    0.11 4.31 -7649.63 -7642.96 -7639.97 -7637.16 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.65     0.68     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.49     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.15  2512    1 #> beta[prevsys]                               0.14  2701    1 #> beta[bsa]                                   0.77  2254    1 #> beta[weight]                                0.10  2331    1 #> beta[psa]                                   0.24  3019    1 #> beta[durnpso:.trtclassTNFa blocker]         0.12  2678    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.14  3490    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.10  2899    1 #> beta[prevsys:.trtclassTNFa blocker]         0.55  2824    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.11  4293    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.48  3128    1 #> beta[bsa:.trtclassTNFa blocker]             1.27  2433    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.93  2921    1 #> beta[bsa:.trtclassIL-17 blocker]            1.25  2728    1 #> beta[weight:.trtclassTNFa blocker]         -0.10  2590    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.01  3473    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  2731    1 #> beta[psa:.trtclassTNFa blocker]             0.33  2990    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.77  3967    1 #> beta[psa:.trtclassIL-17 blocker]            0.46  3516    1 #> d[ETN]                                      1.72  1969    1 #> d[IXE_Q2W]                                  3.06  2104    1 #> d[IXE_Q4W]                                  2.84  2327    1 #> d[SEC_150]                                  2.36  2267    1 #> d[SEC_300]                                  2.76  2396    1 #> d[UST]                                      2.34  3215    1 #> lp__                                    -7632.94  1664    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  3323    1 #> cc[PASI100]                                 1.58  2862    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Aug 28 12:56:36 2022. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1)."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-assumptions","dir":"Articles","previous_headings":"Extended analysis","what":"Assessing assumptions","title":"Example: Plaque psoriasis ML-NMR","text":"first analysis, small network made assessing assumptions difficult. larger network (although still nine studies) greater opportunity assess key assumptions. key assumption made ML-NMR (indeed population adjustment methods connected networks) conditional constancy relative effects assumption (Phillippo et al. 2016). means unobserved effect modifiers, relative effects constant given included effect-modifying covariates. assumption implies residual heterogeneity inconsistency, can assessed using standard network meta-analysis techniques. assess residual heterogeneity using random effects model, residual inconsistency using unrelated mean effects (UME) model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-residual-heterogeneity-with-a-random-effects-ml-nmr","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Assessing residual heterogeneity with a random effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"First, fit random effects model assess residual heterogeneity. call nma() function identical fixed effect model , except now specify trt_effects = \"random\" need provide prior -study heterogeneity (choose \\(\\textrm{half-N}(0, 2.5^2)\\) prior prior_het = half_normal(scale = 2.5). estimated -study heterogeneity standard deviation tau small compared relative treatment effects. compare model fit using DIC: DIC lower RE model, indicating may residual heterogeneity network conditional constancy relative effects assumption may invalid—may additional effect modifiers accounted . result different actual analysis reported Phillippo et al. (2022), since using synthetic IPD simulated closely resemble original IPD. actual analysis DIC similar FE RE models, might choose parsimonious FE model based DIC alone, evidence residual heterogeneity network.","code":"pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                    regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_aux = flat(),                   prior_het = half_normal(scale = 2.5),                   QR = TRUE,                   init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. #> Warning: There were 1 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems pso_fit_RE #> A random effects ML-NMR with a ordered likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8159830 0.6576489 0.2987820 8.9097263 0.2104826  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.04    0.00 0.06    -0.08    -0.01     0.04     0.08 #> beta[prevsys]                              -0.16    0.00 0.16    -0.46    -0.26    -0.15    -0.06 #> beta[bsa]                                  -0.14    0.01 0.46    -1.09    -0.45    -0.13     0.17 #> beta[weight]                                0.05    0.00 0.03    -0.01     0.03     0.05     0.07 #> beta[psa]                                  -0.07    0.00 0.17    -0.40    -0.18    -0.06     0.04 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.17    -0.07    -0.02     0.03 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.07    0.00 0.10    -0.27    -0.14    -0.07     0.01 #> beta[durnpso:.trtclassIL-17 blocker]       -0.03    0.00 0.06    -0.15    -0.07    -0.02     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.19    0.00 0.18    -0.17     0.07     0.19     0.31 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.43    0.00 0.35    -0.27     0.20     0.44     0.67 #> beta[prevsys:.trtclassIL-17 blocker]        0.15    0.00 0.16    -0.18     0.04     0.15     0.26 #> beta[bsa:.trtclassTNFa blocker]             0.27    0.01 0.53    -0.73    -0.08     0.25     0.61 #> beta[bsa:.trtclassIL-12/23 blocker]         0.66    0.01 0.66    -0.65     0.21     0.67     1.09 #> beta[bsa:.trtclassIL-17 blocker]            0.32    0.01 0.48    -0.58    -0.01     0.31     0.63 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.19    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.18    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.06    0.00 0.20    -0.46    -0.20    -0.06     0.07 #> beta[psa:.trtclassIL-12/23 blocker]         0.11    0.00 0.33    -0.53    -0.10     0.11     0.34 #> beta[psa:.trtclassIL-17 blocker]            0.08    0.00 0.18    -0.27    -0.04     0.08     0.20 #> d[ETN]                                      1.59    0.00 0.11     1.38     1.52     1.59     1.66 #> d[IXE_Q2W]                                  2.93    0.00 0.11     2.73     2.86     2.93     3.00 #> d[IXE_Q4W]                                  2.71    0.00 0.12     2.49     2.64     2.71     2.78 #> d[SEC_150]                                  2.21    0.00 0.12     1.99     2.13     2.21     2.28 #> d[SEC_300]                                  2.64    0.00 0.12     2.42     2.56     2.63     2.71 #> d[UST]                                      2.17    0.00 0.17     1.85     2.06     2.16     2.27 #> lp__                                    -7646.77    0.21 6.32 -7660.09 -7650.88 -7646.44 -7642.40 #> tau                                         0.13    0.00 0.07     0.02     0.09     0.13     0.17 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.66     0.68     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.49     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.16  3817    1 #> beta[prevsys]                               0.16  4212    1 #> beta[bsa]                                   0.73  3325    1 #> beta[weight]                                0.10  3585    1 #> beta[psa]                                   0.27  4167    1 #> beta[durnpso:.trtclassTNFa blocker]         0.12  3797    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.13  5280    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.10  4181    1 #> beta[prevsys:.trtclassTNFa blocker]         0.54  4064    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.06  5604    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.46  4509    1 #> beta[bsa:.trtclassTNFa blocker]             1.31  3573    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.98  4347    1 #> beta[bsa:.trtclassIL-17 blocker]            1.29  3634    1 #> beta[weight:.trtclassTNFa blocker]         -0.10  3833    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.00  5021    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  4493    1 #> beta[psa:.trtclassTNFa blocker]             0.35  4225    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.75  6190    1 #> beta[psa:.trtclassIL-17 blocker]            0.43  4403    1 #> d[ETN]                                      1.81  2805    1 #> d[IXE_Q2W]                                  3.15  3031    1 #> d[IXE_Q4W]                                  2.95  2966    1 #> d[SEC_150]                                  2.47  2726    1 #> d[SEC_300]                                  2.88  2575    1 #> d[UST]                                      2.52  2667    1 #> lp__                                    -7635.39   899    1 #> tau                                         0.29   620    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  5665    1 #> cc[PASI100]                                 1.58  6212    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Aug 28 14:09:25 2022. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). (pso_dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 8811.4 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.4 (pso_dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 8800.1 (on 12387 data points) #>                pD: 42.3 #>               DIC: 8842.4"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-residual-inconsistency-with-an-unrelated-mean-effects-ml-nmr","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Assessing residual inconsistency with an unrelated mean effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"assess residual inconsistency using unrelated mean effects model (Dias et al. 2011). , call nma() function identical, except time specify consistency = \"ume\". Node-splitting also possibility (consistency = \"nodesplit\"), takes substantially longer since model re-run node-split comparison. proceed analysis Phillippo et al. (2022) fit fixed effect UME model (since evidence heterogeneity actual analysis); however, recreated analysis using synthetic IPD evidence heterogeneity really fit random effects UME model instead. compare model fit FE ML-NMR model using DIC. DIC values similar FE model (assuming consistency) UME (inconsistency) model, suggests evidence inconsistency overall. also important compare residual deviance contributions model see whether points fit better UME model, can also indicate inconsistency. Using plot() function produces “dev-dev” plot residual deviance contributions either model.  points lie line equality, evidence inconsistency. random effects models fitted heterogeneity estimates also compared drop tau UME model can also indicate inconsistency.","code":"pso_fit_UME <- nma(pso_net,                     trt_effects = \"fixed\",                    consistency = \"ume\",                    link = \"probit\",                     regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                    class_interactions = \"common\",                    prior_intercept = normal(scale = 10),                    prior_trt = normal(scale = 10),                    prior_reg = normal(scale = 10),                    prior_aux = flat(),                    QR = TRUE,                    init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit_UME #> A fixed effects ML-NMR with a ordered likelihood (probit link). #> An inconsistency model ('ume') was fitted. #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8159830 0.6576489 0.2987820 8.9097263 0.2104826  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.03    0.00 0.06    -0.09    -0.01     0.03     0.07 #> beta[prevsys]                              -0.17    0.00 0.16    -0.47    -0.27    -0.17    -0.06 #> beta[bsa]                                  -0.09    0.01 0.44    -0.98    -0.38    -0.08     0.21 #> beta[weight]                                0.04    0.00 0.03    -0.01     0.02     0.04     0.06 #> beta[psa]                                  -0.08    0.00 0.17    -0.42    -0.20    -0.08     0.03 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.16    -0.07    -0.02     0.03 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.06    0.00 0.10    -0.26    -0.13    -0.06     0.01 #> beta[durnpso:.trtclassIL-17 blocker]       -0.02    0.00 0.06    -0.14    -0.06    -0.02     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.19    0.00 0.18    -0.16     0.07     0.19     0.31 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.45    0.01 0.35    -0.24     0.21     0.46     0.70 #> beta[prevsys:.trtclassIL-17 blocker]        0.16    0.00 0.16    -0.16     0.05     0.16     0.27 #> beta[bsa:.trtclassTNFa blocker]             0.22    0.01 0.50    -0.76    -0.12     0.20     0.56 #> beta[bsa:.trtclassIL-12/23 blocker]         0.59    0.01 0.67    -0.72     0.13     0.60     1.05 #> beta[bsa:.trtclassIL-17 blocker]            0.26    0.01 0.46    -0.64    -0.05     0.25     0.56 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.18    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.18    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.05    0.00 0.20    -0.44    -0.18    -0.05     0.09 #> beta[psa:.trtclassIL-12/23 blocker]         0.12    0.01 0.35    -0.54    -0.12     0.12     0.36 #> beta[psa:.trtclassIL-17 blocker]            0.10    0.00 0.18    -0.26    -0.03     0.09     0.22 #> d[ETN vs. PBO]                              1.58    0.00 0.07     1.44     1.53     1.58     1.63 #> d[IXE_Q2W vs. PBO]                          2.91    0.00 0.07     2.77     2.86     2.91     2.96 #> d[IXE_Q4W vs. PBO]                          2.69    0.00 0.07     2.54     2.64     2.69     2.74 #> d[SEC_150 vs. PBO]                          2.19    0.00 0.08     2.02     2.13     2.19     2.25 #> d[SEC_300 vs. PBO]                          2.60    0.00 0.08     2.44     2.54     2.60     2.65 #> d[UST vs. IXE_Q2W]                         -0.78    0.00 0.16    -1.09    -0.89    -0.78    -0.68 #> d[UST vs. SEC_300]                         -0.47    0.00 0.09    -0.65    -0.53    -0.47    -0.41 #> lp__                                    -7640.40    0.10 4.39 -7650.22 -7643.16 -7639.97 -7637.34 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.65     0.68     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.49     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.15  2591    1 #> beta[prevsys]                               0.14  2698    1 #> beta[bsa]                                   0.74  2778    1 #> beta[weight]                                0.10  2854    1 #> beta[psa]                                   0.25  2997    1 #> beta[durnpso:.trtclassTNFa blocker]         0.12  2850    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.13  3732    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.11  3146    1 #> beta[prevsys:.trtclassTNFa blocker]         0.54  2803    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.09  4034    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.48  3191    1 #> beta[bsa:.trtclassTNFa blocker]             1.20  2846    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.91  3889    1 #> beta[bsa:.trtclassIL-17 blocker]            1.19  3282    1 #> beta[weight:.trtclassTNFa blocker]         -0.09  3169    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.00  4218    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  3421    1 #> beta[psa:.trtclassTNFa blocker]             0.35  3036    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.81  4680    1 #> beta[psa:.trtclassIL-17 blocker]            0.45  3454    1 #> d[ETN vs. PBO]                              1.73  2815    1 #> d[IXE_Q2W vs. PBO]                          3.05  2892    1 #> d[IXE_Q4W vs. PBO]                          2.84  3286    1 #> d[SEC_150 vs. PBO]                          2.36  2992    1 #> d[SEC_300 vs. PBO]                          2.76  3203    1 #> d[UST vs. IXE_Q2W]                         -0.47  4990    1 #> d[UST vs. SEC_300]                         -0.29  6387    1 #> lp__                                    -7633.00  1771    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  3712    1 #> cc[PASI100]                                 1.58  3257    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Aug 28 14:26:48 2022. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). pso_dic_FE #> Residual deviance: 8811.4 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.4 (pso_dic_UME <- dic(pso_fit_UME)) #> Residual deviance: 8811.7 (on 12387 data points) #>                pD: 36.3 #>               DIC: 8848 plot(pso_dic_FE, pso_dic_UME, show_uncertainty = FALSE) +   xlab(\"Residual deviance - consistency model\") +   ylab(\"Residual deviance - inconsistency (UME) model\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"relaxing-the-shared-effect-modifier-assumption","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Relaxing the shared effect modifier assumption","title":"Example: Plaque psoriasis ML-NMR","text":"treatment classes network follows: fitted common interaction terms within treatment class, shared effect modifier assumption, order make model estimable available data. Note interleukin-17 blocker class one treatment; etanercept ustekinumab classes unaffected specifying class_interactions = \"common\". assess assumption simply fit independent interaction terms treatments effect modifiers sufficient data. Instead, relax assumption one covariate time, estimating independent interactions one covariate whilst keeping shared effect modifier assumption (common interactions within treatment class) covariates. specify relaxed models, need somehow mix class_interactions = \"common\" class_interactions = \"independent\" different covariates. way .trt .trtclass specials specifying regression model. see works, first note model making shared effect modifiers assumption can written equivalently using .trtclass special .trtclass special essentially factor variable containing treatment classes, available time treatment classes specified network; regression formula therefore single interaction term covariate within treatment class (result specifying class_interactions = \"common\" ). Finally, fit independent interactions single covariate, say durnpso, split using .trt special class_interactions = \"independent\" (.e. telling model combine interactions .trt within classes): Since fitting several models, let us set list model specifications iterate . Comparing model fit using DIC models similar higher DIC original model making shared effect modifier assumption covariates, exception model independent interactions weight slightly lower DIC. also visually examine differences estimated interaction terms original model (shared effect modifier assumption covariates) relaxed models (independent interactions, one covariate time).  independent interaction estimates similar common interaction estimates, much uncertainty—particularly secukinumab regimens estimated aggregate data. exception weight, suggestion covariate may interact differently secukinumab treatment regimens ixekizumab regimens. However, credible intervals secukinumab interactions wide overlap ixekizumab regimens common interaction. Overall, weak evidence shared effect modifier assumption (class interleukin-17 blockers) may invalid weight. Since fitting multiple models mindful multiple testing possibility differences occurred chance. hand, approach likely low power detect violations shared effect modifier assumption, particularly data lacking. case, results model relaxing shared effect modifier assumption weight similar original model (see Phillippo et al. 2022).","code":"data.frame(classes = pso_net$classes, treatments = pso_net$treatments) #>            classes treatments #> 1          Placebo        PBO #> 2     TNFa blocker        ETN #> 3    IL-17 blocker    IXE_Q2W #> 4    IL-17 blocker    IXE_Q4W #> 5    IL-17 blocker    SEC_150 #> 6    IL-17 blocker    SEC_300 #> 7 IL-12/23 blocker        UST regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt, class_interactions = \"common\" regression = ~(durnpso + prevsys + bsa + weight + psa)*.trtclass regression = ~(prevsys + bsa + weight + psa)*.trtclass + durnpso*.trt, class_interactions = \"independent\" noSEM_mods <- list(   durnpso = ~(prevsys + bsa + weight + psa)*.trtclass + durnpso*.trt,   prevsys = ~(durnpso + bsa + weight + psa)*.trtclass + prevsys*.trt,   bsa = ~(durnpso + prevsys + weight + psa)*.trtclass + bsa*.trt,   weight = ~(durnpso + prevsys + bsa + psa)*.trtclass + weight*.trt,   psa = ~(durnpso + prevsys + bsa + weight)*.trtclass + psa*.trt   )  noSEM_fits <- noSEM_mods  for (m in 1:length(noSEM_mods)) {   cat(\"Fitting model with independent interactions for\", names(noSEM_mods)[m], \"\\n\")      noSEM_fits[[m]] <-      nma(pso_net,          trt_effects = \"fixed\",         link = \"probit\",          regression = noSEM_mods[[m]],         class_interactions = \"independent\",         prior_intercept = normal(scale = 10),         prior_trt = normal(scale = 10),         prior_reg = normal(scale = 10),         prior_aux = flat(),         QR = TRUE,         init_r = 0.5,         # Using save_warmup = FALSE reduces memory footprint when          # fitting many models in one session         save_warmup = FALSE) } #> Fitting model with independent interactions for durnpso #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for prevsys #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for bsa #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for weight #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for psa #> Note: Setting \"PBO\" as the network reference treatment. pso_dic_FE #> Residual deviance: 8811.4 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.4 lapply(noSEM_fits, dic) #> $durnpso #> Residual deviance: 8812.5 (on 12387 data points) #>                pD: 37.7 #>               DIC: 8850.3 #>  #> $prevsys #> Residual deviance: 8813.4 (on 12387 data points) #>                pD: 37.8 #>               DIC: 8851.2 #>  #> $bsa #> Residual deviance: 8813 (on 12387 data points) #>                pD: 37.8 #>               DIC: 8850.8 #>  #> $weight #> Residual deviance: 8807.5 (on 12387 data points) #>                pD: 37.9 #>               DIC: 8845.4 #>  #> $psa #> Residual deviance: 8812.2 (on 12387 data points) #>                pD: 37.8 #>               DIC: 8850 library(purrr) library(stringr) library(forcats)  # Extract draws from relaxed models imap_dfr(noSEM_fits,         ~as_tibble(as.matrix(.x, pars = \"beta\")) %>%             pivot_longer(cols = everything(), names_to = \"parameter\", values_to = \"value\") %>%             filter(str_detect(parameter, paste0(\"(IXE|SEC).+:\", .y))) %>%             mutate(model = .y)) %>%       # Add in draws from the original model   bind_rows(     as_tibble(as.matrix(pso_fit_FE, pars = \"beta\")) %>%      pivot_longer(cols = everything(), names_to = \"parameter\", values_to = \"value\") %>%      filter(str_detect(parameter, \":.+IL\\\\-17 blocker\")) %>%      mutate(model = \"all\")   ) %>%       mutate(     # Rescale BSA to per 10%      value = if_else(str_detect(parameter, \"bsa\"), value / 10, value),     # Create labels     covariate = str_extract(parameter, \"durnpso|prevsys|bsa|weight|psa\"),     covariatef = recode_factor(covariate,                                durnpso = \"Duration of psoriasis, per 10 years\",                                prevsys = \"Previous systemic use\",                                bsa = \"Body surface area, per 10%\",                                weight = \"Weight, per 10 kg\",                                psa = \"Psoriatic arthritis\"),     treatment = str_remove(str_extract(parameter, \"\\\\.trt(class)?.+?(?=[\\\\]:])\"),                            \"\\\\.trt(class)?\"),     Interactions = fct_collapse(factor(model),                                  Common = \"all\",                                  other_level = \"Independent\")) %>%     # Plot ggplot(aes(x = value, y = fct_rev(treatment), colour = Interactions, fill = Interactions)) +   geom_vline(xintercept = 0, colour = \"grey70\") +   ggdist::stat_halfeye(normalize = \"panels\", slab_alpha = 0.3, .width = c(0, 0.95)) +   facet_wrap(\"covariatef\", scales = \"free\") +   xlab(\"Interaction effect (SMD)\") +    ylab(\"Treatment / Class\") +   scale_colour_manual(values = c(Common = \"#7B3294\", Independent = \"#91D388\"),                       aesthetics = c(\"colour\", \"fill\")) +   theme_multinma() +   theme(legend.position = c(0.85, 0.2))"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"study-populations-included-in-the-network","dir":"Articles","previous_headings":"Extended analysis > Producing relative effects and event probabilities","what":"Study populations included in the network","title":"Example: Plaque psoriasis ML-NMR","text":"Population-average treatment effects can produced study populations represented network using relative_effects() function. relative effects can plotted using plot() function.  Similarly, average response probabilities treatment, study population, PASI cutoff can produced using predict() function. specify type = \"response\" produce predicted probabilities (rather probit-probabilities). , can plotted using plot() function.","code":"(pso_releff_FE <- relative_effects(pso_fit_FE)) plot(pso_releff_FE, ref_line = 0) (pso_pred_FE <- predict(pso_fit_FE, type = \"response\")) plot(pso_pred_FE, ref_line = c(0, 1))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"external-target-populations","dir":"Articles","previous_headings":"Extended analysis > Producing relative effects and event probabilities","what":"External target populations","title":"Example: Plaque psoriasis ML-NMR","text":"purposes decision-making crucial population-average estimates produced decision target population interest. decision target population may represented study populations network, indeed likely best represented external registry cohort study, perhaps expert knowledge (Phillippo et al. 2016). example, Phillippo et al. (2022) produce estimates three external target populations represented PsoBest registry (Reich et al. 2015; Augustin et al. 2014), PROSPECT (Thaçi et al. 2019) Chiricozzi 2019 (Chiricozzi et al. 2019) cohort studies. First , need covariate means standard deviations populations: produce estimates population-average treatment effects, use relative_effects() function data frame covariate means target populations newdata argument. need covariate means, variable names matching regression. estimates plotted using plot() function.  Estimates average event probabilities produced integrating predictions joint covariate distribution population. Since marginal summary statistics available, rather full IPD, create integration points using add_integration() function specifying forms marginal distributions correlation matrix. choose use forms marginal distributions used specifying integration points AgD studies network, weighted correlation matrix IPD studies. use predict() function produce average event probabilities (type = \"response\", level = \"aggregate\" default) target populations. , also need specify distribution baseline event probabilities (.e. probability achieving PASI 75 response) target populations. PASI 75 event counts individuals receiving secukinumab 300 mg treatment available PROSPECT (1156 achieved PASI 75 1509) Chiricozzi 2019 (243 330), use construct beta distributions baseline average response probabilities (specify baseline_level = \"aggregate\" population averages, rather specific reference individual, baseline_type = \"response\" probabilities rather transformed probit probabilities). information baseline response available PsoBest, predictions absolute response rates made. , plot estimates using plot() function, customisation using ggplot syntax.","code":"new_agd_means <- tibble::tribble(              ~study, ~covariate,  ~mean,   ~sd,           \"PsoBest\",      \"bsa\",     24,  20.5,           \"PsoBest\",  \"durnpso\",   18.2,  14.1,           \"PsoBest\",  \"prevsys\",   0.54,    NA,           \"PsoBest\",      \"psa\",  0.207,    NA,           \"PsoBest\",   \"weight\",     85,  19.1,          \"PROSPECT\",      \"bsa\",   18.7,  18.4,          \"PROSPECT\",  \"durnpso\",   19.6,  13.5,          \"PROSPECT\",  \"prevsys\", 0.9095,    NA,          \"PROSPECT\",      \"psa\",  0.202,    NA,          \"PROSPECT\",   \"weight\",   87.5,  20.3,   \"Chiricozzi 2019\",      \"bsa\",     23, 16.79,   \"Chiricozzi 2019\",  \"durnpso\",  16.93, 10.82,   \"Chiricozzi 2019\",  \"prevsys\", 0.9061,    NA,   \"Chiricozzi 2019\",      \"psa\", 0.2152,    NA,   \"Chiricozzi 2019\",   \"weight\",   78.3, 15.87   ) %>%   # Tidy up   pivot_wider(id_cols = study,                names_from = covariate,                values_from = c(mean, sd),               names_glue = \"{covariate}_{.value}\") %>%    # Rescale as per analysis   transmute(study,             bsa_mean = bsa_mean / 100,              bsa_sd = bsa_sd / 100,             weight_mean = weight_mean / 10,             weight_sd = weight_sd / 10,             durnpso_mean = durnpso_mean / 10,             durnpso_sd = durnpso_sd / 10,             prevsys = prevsys_mean,             psa = psa_mean) (pso_releff_FE_new <- relative_effects(pso_fit_FE,                                         newdata = transmute(new_agd_means,                                                            study,                                                            bsa = bsa_mean,                                                            weight = weight_mean,                                                            durnpso = durnpso_mean,                                                            prevsys,                                                            psa),                                        study = study)) #> -------------------------------------------------------- Study: Chiricozzi 2019 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.69    0.91 0.23   7.83 0.22 #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Chiricozzi 2019: ETN]     1.79 0.11 1.58 1.71 1.79 1.86  2.01     1618     2360    1 #> d[Chiricozzi 2019: IXE_Q2W] 3.07 0.10 2.87 3.00 3.07 3.14  3.28     1623     2630    1 #> d[Chiricozzi 2019: IXE_Q4W] 2.85 0.10 2.65 2.78 2.85 2.92  3.06     1782     2447    1 #> d[Chiricozzi 2019: SEC_150] 2.35 0.11 2.13 2.28 2.35 2.43  2.58     2248     2749    1 #> d[Chiricozzi 2019: SEC_300] 2.76 0.11 2.55 2.69 2.76 2.84  2.98     1883     2739    1 #> d[Chiricozzi 2019: UST]     2.30 0.15 2.02 2.20 2.30 2.40  2.58     2569     2878    1 #>  #> --------------------------------------------------------------- Study: PROSPECT ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.96    0.91 0.19   8.75 0.2 #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[PROSPECT: ETN]     1.62 0.11 1.42 1.55 1.62 1.70  1.84     2215     2573    1 #> d[PROSPECT: IXE_Q2W] 2.94 0.10 2.74 2.87 2.93 3.00  3.13     2128     2844    1 #> d[PROSPECT: IXE_Q4W] 2.72 0.10 2.52 2.65 2.72 2.78  2.92     2329     2929    1 #> d[PROSPECT: SEC_150] 2.22 0.11 2.00 2.14 2.22 2.29  2.44     2719     3321    1 #> d[PROSPECT: SEC_300] 2.63 0.11 2.41 2.55 2.63 2.70  2.85     2295     3224    1 #> d[PROSPECT: UST]     2.18 0.15 1.89 2.08 2.18 2.28  2.47     3205     3089    1 #>  #> ---------------------------------------------------------------- Study: PsoBest ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.82    0.54 0.24    8.5 0.21 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[PsoBest: ETN]     1.61 0.08 1.46 1.56 1.61 1.66  1.77     2021     2876    1 #> d[PsoBest: IXE_Q2W] 2.93 0.08 2.78 2.87 2.93 2.98  3.08     1857     2249    1 #> d[PsoBest: IXE_Q4W] 2.71 0.08 2.56 2.66 2.71 2.76  2.86     2164     2259    1 #> d[PsoBest: SEC_150] 2.21 0.09 2.04 2.15 2.21 2.27  2.39     2451     2706    1 #> d[PsoBest: SEC_300] 2.62 0.09 2.45 2.56 2.62 2.67  2.79     2016     2919    1 #> d[PsoBest: UST]     2.08 0.13 1.82 1.99 2.08 2.17  2.34     2852     3123    1 #> plot(pso_releff_FE_new, ref_line = 0) + facet_wrap(\"Study\") new_agd_int <- add_integration(filter(new_agd_means, study != \"PsoBest\"),                                durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),                                prevsys = distr(qbern, prob = prevsys),                                bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),                                weight = distr(qgamma, mean = weight_mean, sd = weight_sd),                                psa = distr(qbern, prob = psa),                                n_int = 64,                                cor = pso_net$int_cor) (pso_pred_FE_new <- predict(pso_fit_FE,          type = \"response\",          newdata = new_agd_int,         study = study,         baseline = list(PROSPECT = distr(qbeta, 1156, 1509-1156),                         \"Chiricozzi 2019\" = distr(qbeta, 243, 330-243)),         baseline_type = \"response\",         baseline_level = \"aggregate\",         trt_ref = \"SEC_300\")) #> -------------------------------------------------------- Study: Chiricozzi 2019 ----  #>  #>                                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Chiricozzi 2019: PBO, PASI75]      0.02 0.01 0.01 0.01 0.02 0.02  0.03     2564     3595    1 #> pred[Chiricozzi 2019: PBO, PASI90]      0.00 0.00 0.00 0.00 0.00 0.00  0.01     2643     3414    1 #> pred[Chiricozzi 2019: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     2763     3690    1 #> pred[Chiricozzi 2019: ETN, PASI75]      0.37 0.04 0.30 0.34 0.37 0.40  0.46     4758     3892    1 #> pred[Chiricozzi 2019: ETN, PASI90]      0.16 0.03 0.11 0.14 0.16 0.18  0.22     4762     3997    1 #> pred[Chiricozzi 2019: ETN, PASI100]     0.03 0.01 0.02 0.03 0.03 0.04  0.05     4701     3931    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI75]  0.83 0.03 0.77 0.81 0.83 0.84  0.88     4481     3929    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI90]  0.60 0.04 0.52 0.57 0.60 0.63  0.68     4458     4057    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI100] 0.28 0.04 0.21 0.26 0.28 0.31  0.36     4418     4016    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI75]  0.76 0.03 0.70 0.74 0.77 0.79  0.83     4476     3773    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI90]  0.52 0.04 0.43 0.49 0.52 0.55  0.60     4444     3737    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI100] 0.22 0.03 0.16 0.19 0.21 0.24  0.28     4393     3701    1 #> pred[Chiricozzi 2019: SEC_150, PASI75]  0.59 0.04 0.52 0.57 0.59 0.62  0.66     4949     3965    1 #> pred[Chiricozzi 2019: SEC_150, PASI90]  0.33 0.03 0.26 0.30 0.33 0.35  0.40     4810     3887    1 #> pred[Chiricozzi 2019: SEC_150, PASI100] 0.10 0.02 0.07 0.09 0.10 0.11  0.14     4741     3846    1 #> pred[Chiricozzi 2019: SEC_300, PASI75]  0.74 0.02 0.69 0.72 0.74 0.75  0.78     3923     3931    1 #> pred[Chiricozzi 2019: SEC_300, PASI90]  0.48 0.03 0.42 0.46 0.48 0.50  0.54     3912     3974    1 #> pred[Chiricozzi 2019: SEC_300, PASI100] 0.19 0.02 0.15 0.17 0.19 0.20  0.23     3885     3933    1 #> pred[Chiricozzi 2019: UST, PASI75]      0.57 0.05 0.47 0.53 0.57 0.60  0.67     5538     3835    1 #> pred[Chiricozzi 2019: UST, PASI90]      0.31 0.05 0.22 0.28 0.31 0.34  0.41     5591     3798    1 #> pred[Chiricozzi 2019: UST, PASI100]     0.10 0.02 0.06 0.08 0.09 0.11  0.15     5462     3920    1 #>  #> --------------------------------------------------------------- Study: PROSPECT ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[PROSPECT: PBO, PASI75]      0.03 0.01 0.02 0.03 0.03 0.04  0.05     2902     3561    1 #> pred[PROSPECT: PBO, PASI90]      0.01 0.00 0.00 0.00 0.01 0.01  0.01     3098     3528    1 #> pred[PROSPECT: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3269     3415    1 #> pred[PROSPECT: ETN, PASI75]      0.40 0.03 0.33 0.38 0.40 0.42  0.47     5199     3240    1 #> pred[PROSPECT: ETN, PASI90]      0.18 0.02 0.14 0.16 0.18 0.20  0.23     5147     3365    1 #> pred[PROSPECT: ETN, PASI100]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     4967     3490    1 #> pred[PROSPECT: IXE_Q2W, PASI75]  0.85 0.02 0.81 0.84 0.85 0.86  0.88     5001     3224    1 #> pred[PROSPECT: IXE_Q2W, PASI90]  0.64 0.03 0.57 0.62 0.64 0.66  0.70     4949     3615    1 #> pred[PROSPECT: IXE_Q2W, PASI100] 0.32 0.03 0.26 0.30 0.32 0.34  0.38     4883     3727    1 #> pred[PROSPECT: IXE_Q4W, PASI75]  0.79 0.02 0.74 0.78 0.79 0.81  0.84     5310     3627    1 #> pred[PROSPECT: IXE_Q4W, PASI90]  0.56 0.03 0.49 0.53 0.56 0.58  0.62     5152     3587    1 #> pred[PROSPECT: IXE_Q4W, PASI100] 0.25 0.03 0.19 0.23 0.24 0.26  0.30     4930     3584    1 #> pred[PROSPECT: SEC_150, PASI75]  0.63 0.03 0.58 0.61 0.63 0.65  0.68     5720     3577    1 #> pred[PROSPECT: SEC_150, PASI90]  0.36 0.03 0.31 0.35 0.36 0.38  0.42     5332     3598    1 #> pred[PROSPECT: SEC_150, PASI100] 0.12 0.01 0.09 0.11 0.12 0.13  0.15     5036     3554    1 #> pred[PROSPECT: SEC_300, PASI75]  0.77 0.01 0.74 0.76 0.77 0.77  0.79     3785     4056    1 #> pred[PROSPECT: SEC_300, PASI90]  0.52 0.02 0.49 0.51 0.52 0.53  0.55     3560     3888    1 #> pred[PROSPECT: SEC_300, PASI100] 0.22 0.01 0.19 0.21 0.22 0.23  0.24     3510     3811    1 #> pred[PROSPECT: UST, PASI75]      0.61 0.05 0.52 0.58 0.61 0.64  0.70     5992     3337    1 #> pred[PROSPECT: UST, PASI90]      0.35 0.04 0.27 0.32 0.35 0.38  0.44     6096     3471    1 #> pred[PROSPECT: UST, PASI100]     0.12 0.02 0.08 0.10 0.11 0.13  0.17     5841     3581    1 plot(pso_pred_FE_new, ref_line = c(0, 1)) +    facet_grid(rows = \"Study\") +    aes(colour = Category) +   scale_colour_brewer(palette = \"Blues\")"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Smoking cessation","text":"begin setting network. arm-level count data giving number quitting smoking (r) total (n) arm, use function set_agd_arm(). Treatment “intervention” set network reference treatment. Plot network structure.","code":"smknet <- set_agd_arm(smoking,                        study = studyn,                       trt = trtc,                       r = r,                        n = n,                       trt_ref = \"No intervention\") smknet #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected plot(smknet, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"random-effects-nma","dir":"Articles","previous_headings":"","what":"Random effects NMA","title":"Example: Smoking cessation","text":"Following TSD 4, fit random effects NMA model, using nma() function trt_effects = \"random\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), \\(\\textrm{half-N}(5^2)\\) prior distribution -study heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  default, displays model parameters given prior distributions (case \\(d_k\\), \\(\\mu_j\\), \\(\\tau\\)), may changed using prior argument:  Model fit can checked using dic() function residual deviance contributions examined corresponding plot() method  Overall model fit seems adequate, almost points showing good fit (mean residual deviance contribution 1). two points higher residual deviance (.e. worse fit) correspond two zero counts data:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. smkfit <- nma(smknet,                trt_effects = \"random\",               prior_intercept = normal(scale = 100),               prior_trt = normal(scale = 100),               prior_het = normal(scale = 5)) smkfit #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50%      75%    97.5% #> d[Group counselling]          1.10    0.01 0.44     0.28     0.80     1.09     1.39     1.98 #> d[Individual counselling]     0.84    0.01 0.23     0.40     0.68     0.83     0.99     1.32 #> d[Self-help]                  0.49    0.01 0.40    -0.28     0.24     0.49     0.75     1.29 #> lp__                      -5919.87    0.19 6.41 -5933.13 -5924.08 -5919.63 -5915.27 -5908.31 #> tau                           0.84    0.01 0.19     0.55     0.70     0.81     0.94     1.27 #>                           n_eff Rhat #> d[Group counselling]       2385    1 #> d[Individual counselling]  1294    1 #> d[Self-help]               1907    1 #> lp__                       1156    1 #> tau                        1352    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:47:42 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(smkfit, pars = c(\"d\", \"tau\", \"mu\", \"delta\")) plot_prior_posterior(smkfit) plot_prior_posterior(smkfit, prior = \"het\") (dic_consistency <- dic(smkfit)) #> Residual deviance: 54.2 (on 50 data points) #>                pD: 43.9 #>               DIC: 98 plot(dic_consistency) smoking[smoking$r == 0, ] #>    studyn trtn            trtc r  n #> 13      6    1 No intervention 0 33 #> 31     15    1 No intervention 0 20"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"checking-for-inconsistency","dir":"Articles","previous_headings":"","what":"Checking for inconsistency","title":"Example: Smoking cessation","text":"Note: results inconsistency models slightly different Dias et al. (2010, 2011), although overall conclusions . due presence multi-arm trials different ordering treatments, meaning inconsistency parameterised differently within multi-arm trials. results Dias et al. obtained network instead set trtn treatment variable.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"unrelated-mean-effects","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Unrelated mean effects","title":"Example: Smoking cessation","text":"first fit unrelated mean effects (UME) model (Dias et al. 2011) assess consistency assumption. , use function nma(), now argument consistency = \"ume\". Comparing model fit statistics see little choose two models. However, also important examine individual contributions model fit data point two models (-called “dev-dev” plot). Passing two nma_dic objects produced dic() function plot() method produces dev-dev plot:  points lie roughly line equality, evidence inconsistency .","code":"smkfit_ume <- nma(smknet,                    consistency = \"ume\",                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = normal(scale = 5)) smkfit_ume #> A random effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                     mean se_mean   sd     2.5%      25% #> d[Group counselling vs. No intervention]            1.12    0.01 0.78    -0.34     0.59 #> d[Individual counselling vs. No intervention]       0.90    0.01 0.28     0.37     0.72 #> d[Self-help vs. No intervention]                    0.34    0.01 0.57    -0.81    -0.03 #> d[Individual counselling vs. Group counselling]    -0.29    0.01 0.60    -1.49    -0.68 #> d[Self-help vs. Group counselling]                 -0.64    0.01 0.71    -2.09    -1.08 #> d[Self-help vs. Individual counselling]             0.16    0.02 1.07    -1.96    -0.52 #> lp__                                            -5933.67    0.19 6.32 -5946.90 -5937.66 #> tau                                                 0.93    0.01 0.23     0.59     0.77 #>                                                      50%      75%    97.5% n_eff Rhat #> d[Group counselling vs. No intervention]            1.09     1.63     2.78  2797    1 #> d[Individual counselling vs. No intervention]       0.89     1.08     1.47  1065    1 #> d[Self-help vs. No intervention]                    0.34     0.70     1.49  2087    1 #> d[Individual counselling vs. Group counselling]    -0.28     0.10     0.90  2703    1 #> d[Self-help vs. Group counselling]                 -0.64    -0.18     0.73  2491    1 #> d[Self-help vs. Individual counselling]             0.15     0.82     2.28  3533    1 #> lp__                                            -5933.38 -5929.22 -5922.31  1105    1 #> tau                                                 0.89     1.06     1.47  1229    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:48:03 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). dic_consistency #> Residual deviance: 54.2 (on 50 data points) #>                pD: 43.9 #>               DIC: 98 (dic_ume <- dic(smkfit_ume)) #> Residual deviance: 53.9 (on 50 data points) #>                pD: 45.2 #>               DIC: 99.1 plot(dic_consistency, dic_ume, point_alpha = 0.5, interval_alpha = 0.2)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"node-splitting","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Node-splitting","title":"Example: Smoking cessation","text":"Another method assessing inconsistency node-splitting (Dias et al. 2011, 2010). Whereas UME model assesses inconsistency globally, node-splitting assesses inconsistency locally potentially inconsistent comparison (direct indirect evidence) turn. Node-splitting can performed using nma() function argument consistency = \"nodesplit\". default, possible comparisons split (determined get_nodesplits() function). Alternatively, specific comparison comparisons split can provided nodesplit argument. summary() method summarises node-splitting results, displaying direct indirect estimates \\(d_\\mathrm{dir}\\) \\(d_\\mathrm{ind}\\) node-split model, network estimate \\(d_\\mathrm{net}\\) consistency model, inconsistency factor \\(\\omega = d_\\mathrm{dir} - d_\\mathrm{ind}\\), Bayesian \\(p\\)-value inconsistency comparison. Since random effects models fitted, heterogeneity standard deviation \\(\\tau\\) node-split model consistency model also displayed. DIC model fit statistics also provided. DIC inconsistency model unchanged consistency model, node-splits result reduced heterogeneity standard deviation \\(\\tau\\) compared consistency model, Bayesian \\(p\\)-values large. evidence inconsistency. can visually compare posterior distributions direct, indirect, network estimates using plot() method. agreement; posterior densities direct indirect estimates overlap. Notice much indirect information Individual counselling vs. intervention comparison, network (consistency) estimate similar direct estimate comparison.","code":"smk_nodesplit <- nma(smknet,                       consistency = \"nodesplit\",                      trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = normal(scale = 5)) #> Fitting model 1 of 7, node-split: Group counselling vs. No intervention #> Fitting model 2 of 7, node-split: Individual counselling vs. No intervention #> Fitting model 3 of 7, node-split: Self-help vs. No intervention #> Fitting model 4 of 7, node-split: Individual counselling vs. Group counselling #> Fitting model 5 of 7, node-split: Self-help vs. Group counselling #> Fitting model 6 of 7, node-split: Self-help vs. Individual counselling #> Fitting model 7 of 7, consistency model summary(smk_nodesplit) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.12 0.43  0.30  0.83  1.10 1.38  2.00     1911     2373    1 #> d_dir            1.06 0.74 -0.31  0.55  1.04 1.54  2.57     2991     2689    1 #> d_ind            1.16 0.53  0.12  0.81  1.15 1.50  2.25     1414     2206    1 #> omega           -0.10 0.89 -1.81 -0.70 -0.11 0.46  1.67     2405     2481    1 #> tau              0.87 0.20  0.55  0.73  0.84 0.98  1.33     1193     1616    1 #> tau_consistency  0.85 0.20  0.55  0.71  0.82 0.95  1.31     1159     1530    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.4 #>  #> Bayesian p-value: 0.91 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.85 0.25  0.37  0.69 0.85 1.01  1.35      977     1684    1 #> d_dir           0.89 0.25  0.42  0.73 0.89 1.06  1.42     1731     2030    1 #> d_ind           0.56 0.68 -0.71  0.10 0.54 0.98  1.99     1378     1900    1 #> omega           0.33 0.71 -1.19 -0.10 0.35 0.80  1.68     1276     1858    1 #> tau             0.85 0.19  0.55  0.71 0.83 0.97  1.29     1200     1934    1 #> tau_consistency 0.85 0.20  0.55  0.71 0.82 0.95  1.31     1159     1530    1 #>  #> Residual deviance: 54.5 (on 50 data points) #>                pD: 44.4 #>               DIC: 98.8 #>  #> Bayesian p-value: 0.6 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.51 0.40 -0.26  0.24  0.50 0.77  1.30     1813     2494    1 #> d_dir            0.34 0.55 -0.71 -0.02  0.34 0.70  1.41     3603     2527    1 #> d_ind            0.69 0.63 -0.52  0.27  0.68 1.10  1.97     2280     2599    1 #> omega           -0.35 0.84 -2.02 -0.91 -0.33 0.21  1.31     2637     2601    1 #> tau              0.87 0.19  0.57  0.73  0.84 0.98  1.34     1224     2117    1 #> tau_consistency  0.85 0.20  0.55  0.71  0.82 0.95  1.31     1159     1530    1 #>  #> Residual deviance: 53.4 (on 50 data points) #>                pD: 43.9 #>               DIC: 97.3 #>  #> Bayesian p-value: 0.68 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.27 0.40 -1.10 -0.52 -0.26  0.00  0.50     2574     2513    1 #> d_dir           -0.12 0.50 -1.14 -0.43 -0.12  0.21  0.85     3548     2700    1 #> d_ind           -0.53 0.63 -1.74 -0.93 -0.53 -0.13  0.72     1586     2133    1 #> omega            0.41 0.70 -1.00 -0.03  0.41  0.88  1.77     1635     2118    1 #> tau              0.88 0.20  0.57  0.73  0.85  0.98  1.33     1047     1675    1 #> tau_consistency  0.85 0.20  0.55  0.71  0.82  0.95  1.31     1159     1530    1 #>  #> Residual deviance: 53.3 (on 50 data points) #>                pD: 43.8 #>               DIC: 97.1 #>  #> Bayesian p-value: 0.52 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.61 0.47 -1.58 -0.91 -0.60 -0.31  0.30     2969     2470    1 #> d_dir           -0.61 0.67 -1.96 -1.03 -0.59 -0.18  0.67     3748     3129    1 #> d_ind           -0.61 0.69 -1.98 -1.06 -0.61 -0.16  0.79     1833     2044    1 #> omega            0.00 0.88 -1.65 -0.57 -0.02  0.57  1.73     2073     2030    1 #> tau              0.86 0.20  0.56  0.72  0.84  0.97  1.32     1045     1757    1 #> tau_consistency  0.85 0.20  0.55  0.71  0.82  0.95  1.31     1159     1530    1 #>  #> Residual deviance: 54.4 (on 50 data points) #>                pD: 44.5 #>               DIC: 99 #>  #> Bayesian p-value: 0.98 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.34 0.41 -1.16 -0.61 -0.35 -0.08  0.46     2152     2293    1 #> d_dir            0.07 0.65 -1.25 -0.36  0.07  0.48  1.35     3516     3058    1 #> d_ind           -0.63 0.52 -1.66 -0.96 -0.62 -0.30  0.39     1901     2080    1 #> omega            0.69 0.81 -0.89  0.17  0.69  1.21  2.30     2255     2403    1 #> tau              0.86 0.19  0.55  0.72  0.83  0.96  1.30     1196     2092    1 #> tau_consistency  0.85 0.20  0.55  0.71  0.82  0.95  1.31     1159     1530    1 #>  #> Residual deviance: 54.2 (on 50 data points) #>                pD: 44.5 #>               DIC: 98.6 #>  #> Bayesian p-value: 0.37 plot(smk_nodesplit) +   ggplot2::theme(legend.position = \"bottom\", legend.direct = \"horizontal\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Smoking cessation","text":"Pairwise relative effects, pairwise contrasts all_contrasts = TRUE.  Treatment rankings, rank probabilities, cumulative rank probabilities. set lower_better = FALSE since higher log odds cessation better (outcome positive).","code":"(smk_releff <- relative_effects(smkfit, all_contrasts = TRUE)) #>                                                  mean   sd  2.5%   25%   50%   75% 97.5% #> d[Group counselling vs. No intervention]         1.10 0.44  0.28  0.80  1.09  1.39  1.98 #> d[Individual counselling vs. No intervention]    0.84 0.23  0.40  0.68  0.83  0.99  1.32 #> d[Self-help vs. No intervention]                 0.49 0.40 -0.28  0.24  0.49  0.75  1.29 #> d[Individual counselling vs. Group counselling] -0.26 0.41 -1.08 -0.53 -0.26  0.01  0.53 #> d[Self-help vs. Group counselling]              -0.60 0.48 -1.58 -0.91 -0.59 -0.29  0.31 #> d[Self-help vs. Individual counselling]         -0.34 0.41 -1.20 -0.60 -0.33 -0.08  0.46 #>                                                 Bulk_ESS Tail_ESS Rhat #> d[Group counselling vs. No intervention]            2445     2480    1 #> d[Individual counselling vs. No intervention]       1328     2078    1 #> d[Self-help vs. No intervention]                    1963     2507    1 #> d[Individual counselling vs. Group counselling]     3190     3112    1 #> d[Self-help vs. Group counselling]                  3277     2821    1 #> d[Self-help vs. Individual counselling]             2421     2832    1 plot(smk_releff, ref_line = 0) (smk_ranks <- posterior_ranks(smkfit, lower_better = FALSE)) #>                              mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[No intervention]        3.89 0.32    3   4   4   4     4     2549       NA    1 #> rank[Group counselling]      1.36 0.62    1   1   1   2     3     3430     3537    1 #> rank[Individual counselling] 1.93 0.63    1   2   2   2     3     2669       NA    1 #> rank[Self-help]              2.82 0.68    1   3   3   3     4     2778       NA    1 plot(smk_ranks) (smk_rankprobs <- posterior_rank_probs(smkfit, lower_better = FALSE)) #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.10       0.9 #> d[Group counselling]           0.71      0.22      0.06       0.0 #> d[Individual counselling]      0.23      0.60      0.16       0.0 #> d[Self-help]                   0.06      0.17      0.67       0.1 plot(smk_rankprobs) (smk_cumrankprobs <- posterior_rank_probs(smkfit, lower_better = FALSE, cumulative = TRUE)) #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00       0.1         1 #> d[Group counselling]           0.71      0.93       1.0         1 #> d[Individual counselling]      0.23      0.84       1.0         1 #> d[Self-help]                   0.06      0.23       0.9         1 plot(smk_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Statins for cholesterol lowering","text":"data giving number deaths (r) total (n) arm, use function set_agd_arm() set network. set placebo network reference treatment. prevention variable statins data frame automatically available use meta-regression model.","code":"statin_net <- set_agd_arm(statins,                            study = studyc,                           trt = trtc,                           r = r,                            n = n,                           trt_ref = \"Placebo\") statin_net #> A network with 19 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study     Treatment arms      #>  4S        2: Placebo | Statin #>  Bestehorn 2: Placebo | Statin #>  Brown     2: Placebo | Statin #>  CCAIT     2: Placebo | Statin #>  Downs     2: Placebo | Statin #>  EXCEL     2: Placebo | Statin #>  Furberg   2: Placebo | Statin #>  Haskell   2: Placebo | Statin #>  Jones     2: Placebo | Statin #>  KAPS      2: Placebo | Statin #>  ... plus 9 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 19 #> Reference treatment is: Placebo #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Statins for cholesterol lowering","text":"fit fixed effect (FE) random effects (RE) models, meta-regression binary covariate prevention.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"fixed-effect-meta-regression","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-regression","title":"Example: Statins for cholesterol lowering","text":"start fitting FE model. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Statin}\\), study-specific intercepts \\(\\mu_j\\), regression coefficient \\(\\beta\\). can examine range parameter values implied prior distributions summary() method: model fitted nma() function, fixed effect model specified trt_effects = \"fixed\". regression formula ~ .trt:prevention means interaction primary/secondary prevention treatment included; .trt special variable indicates treatment, prevention original data set. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. statin_fit_FE <- nma(statin_net,                       trt_effects = \"fixed\",                      regression = ~.trt:prevention,                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_reg = normal(scale = 100)) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. statin_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:prevention. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                          mean se_mean   sd     2.5%      25%      50%      75% #> beta[.trtStatin:preventionSecondary]    -0.21    0.00 0.11    -0.43    -0.28    -0.21    -0.13 #> d[Statin]                               -0.11    0.00 0.10    -0.29    -0.17    -0.10    -0.04 #> lp__                                 -7362.61    0.08 3.30 -7370.09 -7364.68 -7362.17 -7360.23 #>                                         97.5% n_eff Rhat #> beta[.trtStatin:preventionSecondary]     0.01  2111    1 #> d[Statin]                                0.09  2053    1 #> lp__                                 -7357.21  1631    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:50:19 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(statin_fit_FE, pars = c(\"d\", \"beta\", \"mu\")) plot_prior_posterior(statin_fit_FE, prior = c(\"trt\", \"reg\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"random-effects-meta-regression","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-regression","title":"Example: Statins for cholesterol lowering","text":"now fit RE model. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Statin}\\), study-specific intercepts \\(\\mu_j\\), regression coefficient \\(\\beta\\). use \\(\\textrm{half-N}(0, 5^2)\\) prior distribution heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: , model fitted nma() function, now trt_effects = \"random\". increase adapt_delta 0.99 remove small number divergent transition errors (default RE models set 0.95). Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. statin_fit_RE <- nma(statin_net,                       trt_effects = \"random\",                      regression = ~.trt:prevention,                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_reg = normal(scale = 100),                      prior_het = half_normal(scale = 5),                      adapt_delta = 0.99) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. statin_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:prevention. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                          mean se_mean   sd     2.5%      25%      50%      75% #> beta[.trtStatin:preventionSecondary]    -0.29    0.01 0.26    -0.89    -0.42    -0.27    -0.14 #> d[Statin]                               -0.07    0.01 0.21    -0.47    -0.19    -0.08     0.04 #> lp__                                 -7374.50    0.17 5.22 -7385.62 -7377.90 -7374.34 -7370.83 #> tau                                      0.25    0.01 0.21     0.01     0.09     0.19     0.34 #>                                         97.5% n_eff Rhat #> beta[.trtStatin:preventionSecondary]     0.18  1133 1.00 #> d[Statin]                                0.40  1305 1.00 #> lp__                                 -7365.25   909 1.00 #> tau                                      0.79   578 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:50:34 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(statin_fit_RE, pars = c(\"d\", \"beta\", \"mu\", \"delta\")) plot_prior_posterior(statin_fit_RE, prior = c(\"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: Statins for cholesterol lowering","text":"Model fit can checked using dic() function: DIC similar FE RE models, might choose FE model based parsimony. residual deviance statistics larger number data points, suggesting data points fit well. can also examine residual deviance contributions corresponding plot() method.   number studies fit well either model, posterior mean residual deviance contributions greater 1, investigated see substantive differences studies.","code":"(statin_dic_FE <- dic(statin_fit_FE)) #> Residual deviance: 45.8 (on 38 data points) #>                pD: 21.5 #>               DIC: 67.4 (statin_dic_RE <- dic(statin_fit_RE)) #> Residual deviance: 42.7 (on 38 data points) #>                pD: 25.2 #>               DIC: 67.9 plot(statin_dic_FE) plot(statin_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Statins for cholesterol lowering","text":"can produce estimates relative effect statins vs. placebo either primary secondary prevention, using relative_effects() function. newdata argument specifies data frame containing levels covariate prevention interested , study argument used specify column newdata informative label. plot() method may used visually compare estimates:  Model parameters may plotted corresponding plot() method:  Whilst 95% Credible Interval includes zero, suggestion statins effective secondary prevention.","code":"statin_releff_FE <- relative_effects(statin_fit_FE,                                      newdata = data.frame(prevention = c(\"Primary\", \"Secondary\")),                                      study = prevention)  statin_releff_FE #> ---------------------------------------------------------------- Study: Primary ----  #>  #> Covariate values: #>  prevention #>     Primary #>  #>                     mean  sd  2.5%   25%  50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Primary: Statin] -0.11 0.1 -0.29 -0.17 -0.1 -0.04  0.09     2083     3037    1 #>  #> -------------------------------------------------------------- Study: Secondary ----  #>  #> Covariate values: #>  prevention #>   Secondary #>  #>                       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Secondary: Statin] -0.31 0.05 -0.42 -0.35 -0.31 -0.28 -0.21     4613     3483    1 plot(statin_releff_FE,       ref_line = 0) plot(statin_fit_FE,       pars = \"beta\",       ref_line = 0,      stat = \"halfeye\")"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Thrombolytic treatments","text":"begin setting network. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). default, SK set network reference treatment. Plot network structure.","code":"thrombo_net <- set_agd_arm(thrombolytics,                             study = studyn,                            trt = trtc,                            r = r,                             n = n) thrombo_net #> A network with 50 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms               #>  1     3: SK | Acc t-PA | SK + t-PA #>  2     2: SK | t-PA                 #>  3     2: SK | t-PA                 #>  4     2: SK | t-PA                 #>  5     2: SK | t-PA                 #>  6     3: SK | ASPAC | t-PA         #>  7     2: SK | t-PA                 #>  8     2: SK | t-PA                 #>  9     2: SK | t-PA                 #>  10    2: SK | SK + t-PA            #>  ... plus 40 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 9 #> Total number of studies: 50 #> Reference treatment is: SK #> Network is connected plot(thrombo_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"fixed-effects-nma","dir":"Articles","previous_headings":"","what":"Fixed effects NMA","title":"Example: Thrombolytic treatments","text":"Following TSD 4 (Dias et al. 2011), fit fixed effects NMA model, using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Model fit can checked using dic() function residual deviance contributions examined corresponding plot() method.  number points well fit model, posterior mean residual deviance contributions greater 1.","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. thrombo_fit <- nma(thrombo_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) #> Note: Setting \"SK\" as the network reference treatment. thrombo_fit #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd      2.5%       25%       50%       75%     97.5% n_eff #> d[Acc t-PA]      -0.18    0.00 0.04     -0.26     -0.21     -0.18     -0.15     -0.09  2746 #> d[ASPAC]          0.02    0.00 0.04     -0.06     -0.01      0.02      0.04      0.08  5120 #> d[PTCA]          -0.48    0.00 0.10     -0.67     -0.54     -0.48     -0.41     -0.28  3824 #> d[r-PA]          -0.12    0.00 0.06     -0.24     -0.16     -0.12     -0.08     -0.01  3994 #> d[SK + t-PA]     -0.05    0.00 0.05     -0.14     -0.08     -0.05     -0.02      0.04  6751 #> d[t-PA]           0.00    0.00 0.03     -0.06     -0.02      0.00      0.02      0.06  4466 #> d[TNK]           -0.17    0.00 0.08     -0.33     -0.22     -0.17     -0.12     -0.02  3771 #> d[UK]            -0.21    0.00 0.22     -0.63     -0.35     -0.21     -0.06      0.22  4330 #> lp__         -43363.14    0.14 5.44 -43374.53 -43366.58 -43362.79 -43359.33 -43353.59  1475 #>              Rhat #> d[Acc t-PA]     1 #> d[ASPAC]        1 #> d[PTCA]         1 #> d[r-PA]         1 #> d[SK + t-PA]    1 #> d[t-PA]         1 #> d[TNK]          1 #> d[UK]           1 #> lp__            1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:51:00 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(thrombo_fit, pars = c(\"d\", \"mu\")) plot_prior_posterior(thrombo_fit, prior = \"trt\") (dic_consistency <- dic(thrombo_fit)) #> Residual deviance: 105.7 (on 102 data points) #>                pD: 58.5 #>               DIC: 164.2 plot(dic_consistency)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"checking-for-inconsistency","dir":"Articles","previous_headings":"","what":"Checking for inconsistency","title":"Example: Thrombolytic treatments","text":"Note: results inconsistency models slightly different Dias et al. (2010, 2011), although overall conclusions . due presence multi-arm trials different ordering treatments, meaning inconsistency parameterised differently within multi-arm trials. results Dias et al. obtained network instead set trtn treatment variable.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"unrelated-mean-effects-model","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Unrelated mean effects model","title":"Example: Thrombolytic treatments","text":"first fit unrelated mean effects (UME) model (Dias et al. 2011) assess consistency assumption. , use function nma(), now argument consistency = \"ume\". Comparing model fit statistics Whilst UME model fits data better, lower residual deviance, additional parameters UME model mean DIC similar models. However, also important examine individual contributions model fit data point two models (-called “dev-dev” plot). Passing two nma_dic objects produced dic() function plot() method produces dev-dev plot:  four points lying lower right corner plot much lower posterior mean residual deviance UME model, indicating data potentially inconsistent. points correspond trials 44 45, two trials comparing Acc t-PA ASPAC. ASPAC vs. Acc t-PA estimates different consistency model inconsistency (UME) model, suggesting two trials may systematically different others network.","code":"thrombo_fit_ume <- nma(thrombo_net,                         consistency = \"ume\",                        trt_effects = \"fixed\",                        prior_intercept = normal(scale = 100),                        prior_trt = normal(scale = 100)) #> Note: Setting \"SK\" as the network reference treatment. thrombo_fit_ume #> A fixed effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                            mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[Acc t-PA vs. SK]        -0.16    0.00 0.05     -0.25     -0.19     -0.16     -0.13     -0.07 #> d[ASPAC vs. SK]            0.01    0.00 0.04     -0.07     -0.02      0.01      0.03      0.08 #> d[PTCA vs. SK]            -0.67    0.00 0.19     -1.04     -0.79     -0.67     -0.54     -0.30 #> d[r-PA vs. SK]            -0.06    0.00 0.09     -0.24     -0.12     -0.06      0.00      0.12 #> d[SK + t-PA vs. SK]       -0.04    0.00 0.05     -0.14     -0.07     -0.04     -0.01      0.05 #> d[t-PA vs. SK]             0.00    0.00 0.03     -0.06     -0.03      0.00      0.02      0.06 #> d[UK vs. SK]              -0.37    0.01 0.50     -1.37     -0.70     -0.37     -0.04      0.60 #> d[ASPAC vs. Acc t-PA]      1.40    0.01 0.42      0.61      1.11      1.38      1.67      2.27 #> d[PTCA vs. Acc t-PA]      -0.21    0.00 0.12     -0.45     -0.30     -0.22     -0.13      0.02 #> d[r-PA vs. Acc t-PA]       0.02    0.00 0.07     -0.11     -0.03      0.02      0.07      0.15 #> d[TNK vs. Acc t-PA]        0.00    0.00 0.07     -0.12     -0.04      0.00      0.05      0.13 #> d[UK vs. Acc t-PA]         0.14    0.01 0.35     -0.54     -0.10      0.12      0.37      0.86 #> d[t-PA vs. ASPAC]          0.29    0.01 0.36     -0.43      0.06      0.28      0.53      1.02 #> d[t-PA vs. PTCA]           0.54    0.01 0.43     -0.27      0.25      0.53      0.83      1.40 #> d[UK vs. t-PA]            -0.30    0.00 0.36     -1.00     -0.54     -0.29     -0.06      0.40 #> lp__                  -43398.84    0.14 5.73 -43410.91 -43402.64 -43398.46 -43394.81 -43388.61 #>                       n_eff Rhat #> d[Acc t-PA vs. SK]     5479    1 #> d[ASPAC vs. SK]        4876    1 #> d[PTCA vs. SK]         5831    1 #> d[r-PA vs. SK]         5608    1 #> d[SK + t-PA vs. SK]    5446    1 #> d[t-PA vs. SK]         4319    1 #> d[UK vs. SK]           4704    1 #> d[ASPAC vs. Acc t-PA]  3650    1 #> d[PTCA vs. Acc t-PA]   4549    1 #> d[r-PA vs. Acc t-PA]   5079    1 #> d[TNK vs. Acc t-PA]    6746    1 #> d[UK vs. Acc t-PA]     4348    1 #> d[t-PA vs. ASPAC]      4667    1 #> d[t-PA vs. PTCA]       4093    1 #> d[UK vs. t-PA]         5227    1 #> lp__                   1662    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:51:14 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). dic_consistency #> Residual deviance: 105.7 (on 102 data points) #>                pD: 58.5 #>               DIC: 164.2 (dic_ume <- dic(thrombo_fit_ume)) #> Residual deviance: 99.7 (on 102 data points) #>                pD: 66 #>               DIC: 165.7 plot(dic_consistency, dic_ume, show_uncertainty = FALSE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"node-splitting","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Node-splitting","title":"Example: Thrombolytic treatments","text":"Another method assessing inconsistency node-splitting (Dias et al. 2011, 2010). Whereas UME model assesses inconsistency globally, node-splitting assesses inconsistency locally potentially inconsistent comparison (direct indirect evidence) turn. Node-splitting can performed using nma() function argument consistency = \"nodesplit\". default, possible comparisons split (determined get_nodesplits() function). Alternatively, specific comparison comparisons split can provided nodesplit argument. summary() method summarises node-splitting results, displaying direct indirect estimates \\(d_\\mathrm{dir}\\) \\(d_\\mathrm{ind}\\) node-split model, network estimate \\(d_\\mathrm{net}\\) consistency model, inconsistency factor \\(\\omega = d_\\mathrm{dir} - d_\\mathrm{ind}\\), Bayesian \\(p\\)-value inconsistency comparison. DIC model fit statistics also provided. (random effects model fitted, heterogeneity standard deviation \\(\\tau\\) node-split model consistency model also displayed.) Node-splitting ASPAC vs. Acc t-PA comparison results lowest DIC, lower consistency model. posterior distribution inconsistency factor \\(\\omega\\) comparison lies far 0 Bayesian \\(p\\)-value inconsistency small (< 0.01), meaning substantial disagreement direct indirect evidence comparison. can visually compare direct, indirect, network estimates using plot() method.  can also plot posterior distributions inconsistency factors \\(\\omega\\), using plot() method. , specify “halfeye” plot posterior density median credible intervals, customise plot layout standard ggplot2 functions.  Notice posterior distribution inconsistency factor ASPAC vs. Acc t-PA comparison lies far 0, indicating substantial inconsistency direct indirect evidence comparison.","code":"thrombo_nodesplit <- nma(thrombo_net,                           consistency = \"nodesplit\",                          trt_effects = \"fixed\",                          prior_intercept = normal(scale = 100),                          prior_trt = normal(scale = 100)) #> Fitting model 1 of 15, node-split: Acc t-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 2 of 15, node-split: ASPAC vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 3 of 15, node-split: PTCA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 4 of 15, node-split: r-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 5 of 15, node-split: t-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 6 of 15, node-split: UK vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 7 of 15, node-split: ASPAC vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 8 of 15, node-split: PTCA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 9 of 15, node-split: r-PA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 10 of 15, node-split: SK + t-PA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 11 of 15, node-split: UK vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 12 of 15, node-split: t-PA vs. ASPAC #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 13 of 15, node-split: t-PA vs. PTCA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 14 of 15, node-split: UK vs. t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 15 of 15, consistency model #> Note: Setting \"SK\" as the network reference treatment. summary(thrombo_nodesplit) #> Node-splitting models fitted for 14 comparisons. #>  #> ---------------------------------------------------- Node-split Acc t-PA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.18 0.04 -0.26 -0.21 -0.18 -0.15 -0.09     2638     3078 1.00 #> d_dir -0.16 0.05 -0.25 -0.19 -0.16 -0.12 -0.06     4543     3695 1.00 #> d_ind -0.25 0.09 -0.43 -0.31 -0.25 -0.19 -0.06      847     1255 1.01 #> omega  0.09 0.11 -0.12  0.02  0.09  0.16  0.29      980     1459 1.01 #>  #> Residual deviance: 106.4 (on 102 data points) #>                pD: 60 #>               DIC: 166.4 #>  #> Bayesian p-value: 0.38 #>  #> ------------------------------------------------------- Node-split ASPAC vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.02 0.04 -0.06 -0.01  0.02  0.04  0.09     5396     3521    1 #> d_dir  0.01 0.04 -0.06 -0.02  0.01  0.03  0.08     4581     3519    1 #> d_ind  0.42 0.25 -0.08  0.25  0.42  0.59  0.92     2757     2893    1 #> omega -0.41 0.25 -0.90 -0.58 -0.41 -0.24  0.10     2784     2792    1 #>  #> Residual deviance: 104.3 (on 102 data points) #>                pD: 59.7 #>               DIC: 164 #>  #> Bayesian p-value: 0.1 #>  #> -------------------------------------------------------- Node-split PTCA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.47 0.10 -0.66 -0.54 -0.47 -0.41 -0.28     4039     2968    1 #> d_dir -0.66 0.18 -1.03 -0.78 -0.66 -0.54 -0.31     5135     3572    1 #> d_ind -0.39 0.12 -0.63 -0.47 -0.39 -0.31 -0.17     3811     3487    1 #> omega -0.27 0.22 -0.71 -0.42 -0.27 -0.12  0.16     4666     3520    1 #>  #> Residual deviance: 105.9 (on 102 data points) #>                pD: 60.2 #>               DIC: 166.2 #>  #> Bayesian p-value: 0.23 #>  #> -------------------------------------------------------- Node-split r-PA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.12 0.06 -0.24 -0.16 -0.12 -0.08 -0.01     3294     3171    1 #> d_dir -0.06 0.09 -0.24 -0.12 -0.06  0.00  0.12     5619     3529    1 #> d_ind -0.17 0.08 -0.33 -0.23 -0.17 -0.12 -0.02     2647     3193    1 #> omega  0.11 0.12 -0.12  0.03  0.11  0.20  0.36     3266     3153    1 #>  #> Residual deviance: 106.3 (on 102 data points) #>                pD: 60 #>               DIC: 166.4 #>  #> Bayesian p-value: 0.35 #>  #> -------------------------------------------------------- Node-split t-PA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.00 0.03 -0.06 -0.02  0.00  0.02  0.06     4270     3573    1 #> d_dir  0.00 0.03 -0.06 -0.02  0.00  0.02  0.06     4243     3596    1 #> d_ind  0.18 0.24 -0.28  0.03  0.19  0.35  0.64     1483     2122    1 #> omega -0.18 0.24 -0.63 -0.35 -0.19 -0.03  0.28     1531     2140    1 #>  #> Residual deviance: 106.5 (on 102 data points) #>                pD: 60 #>               DIC: 166.5 #>  #> Bayesian p-value: 0.42 #>  #> ---------------------------------------------------------- Node-split UK vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.20 0.22 -0.65 -0.35 -0.20 -0.06  0.23     4849     3543    1 #> d_dir -0.35 0.52 -1.39 -0.70 -0.34  0.00  0.65     5302     3179    1 #> d_ind -0.16 0.25 -0.66 -0.32 -0.16  0.00  0.32     4868     3522    1 #> omega -0.19 0.58 -1.33 -0.57 -0.18  0.20  0.90     4792     3359    1 #>  #> Residual deviance: 107 (on 102 data points) #>                pD: 60 #>               DIC: 167 #>  #> Bayesian p-value: 0.74 #>  #> ------------------------------------------------- Node-split ASPAC vs. Acc t-PA ----  #>  #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net 0.19 0.06 0.08 0.16 0.19 0.23  0.30     3623     2858    1 #> d_dir 1.40 0.42 0.63 1.11 1.38 1.67  2.26     4261     2663    1 #> d_ind 0.16 0.06 0.05 0.12 0.16 0.20  0.27     3606     3148    1 #> omega 1.24 0.43 0.45 0.94 1.22 1.51  2.11     4175     2516    1 #>  #> Residual deviance: 96.9 (on 102 data points) #>                pD: 59.8 #>               DIC: 156.8 #>  #> Bayesian p-value: <0.01 #>  #> -------------------------------------------------- Node-split PTCA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.30 0.10 -0.49 -0.36 -0.30 -0.23 -0.11     4958     3055    1 #> d_dir -0.22 0.12 -0.45 -0.30 -0.22 -0.14  0.02     4335     3222    1 #> d_ind -0.47 0.18 -0.83 -0.59 -0.47 -0.35 -0.13     3101     2977    1 #> omega  0.26 0.21 -0.17  0.12  0.25  0.40  0.68     2878     3011    1 #>  #> Residual deviance: 105.6 (on 102 data points) #>                pD: 59.9 #>               DIC: 165.5 #>  #> Bayesian p-value: 0.22 #>  #> -------------------------------------------------- Node-split r-PA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.05 0.06 -0.06  0.02  0.05  0.09  0.17     5145     3906    1 #> d_dir  0.02 0.07 -0.11 -0.03  0.02  0.06  0.15     4647     3294    1 #> d_ind  0.14 0.10 -0.07  0.07  0.14  0.21  0.34     1901     2297    1 #> omega -0.12 0.12 -0.35 -0.20 -0.12 -0.04  0.13     1922     2340    1 #>  #> Residual deviance: 106.2 (on 102 data points) #>                pD: 59.9 #>               DIC: 166.1 #>  #> Bayesian p-value: 0.33 #>  #> --------------------------------------------- Node-split SK + t-PA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.13 0.05  0.03  0.09  0.13  0.17  0.23     5601     3396    1 #> d_dir  0.13 0.05  0.03  0.09  0.13  0.16  0.23     3172     3367    1 #> d_ind  0.64 0.69 -0.66  0.17  0.61  1.09  2.04     3108     2644    1 #> omega -0.52 0.69 -1.93 -0.97 -0.49 -0.04  0.79     3102     2626    1 #>  #> Residual deviance: 106.5 (on 102 data points) #>                pD: 59.9 #>               DIC: 166.4 #>  #> Bayesian p-value: 0.46 #>  #> ---------------------------------------------------- Node-split UK vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.02 0.22 -0.48 -0.17 -0.02 0.12  0.41     4985     3301    1 #> d_dir  0.14 0.35 -0.55 -0.10  0.14 0.38  0.83     5036     3015    1 #> d_ind -0.13 0.28 -0.69 -0.32 -0.14 0.06  0.42     4085     3331    1 #> omega  0.27 0.45 -0.63 -0.03  0.27 0.58  1.14     3986     2983    1 #>  #> Residual deviance: 106.6 (on 102 data points) #>                pD: 59.8 #>               DIC: 166.4 #>  #> Bayesian p-value: 0.55 #>  #> ----------------------------------------------------- Node-split t-PA vs. ASPAC ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.01 0.04 -0.09 -0.04 -0.01  0.01  0.06     6916     3295    1 #> d_dir -0.02 0.04 -0.10 -0.05 -0.02  0.00  0.05     5038     3345    1 #> d_ind  0.02 0.06 -0.10 -0.02  0.02  0.07  0.15     3282     2839    1 #> omega -0.05 0.06 -0.17 -0.09 -0.05 -0.01  0.08     3410     3102    1 #>  #> Residual deviance: 106.6 (on 102 data points) #>                pD: 60 #>               DIC: 166.6 #>  #> Bayesian p-value: 0.44 #>  #> ------------------------------------------------------ Node-split t-PA vs. PTCA ----  #>  #>       mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net 0.48 0.10  0.28  0.41 0.48 0.54  0.68     4183     2950    1 #> d_dir 0.54 0.41 -0.22  0.27 0.54 0.80  1.37     4755     3275    1 #> d_ind 0.47 0.11  0.27  0.40 0.48 0.55  0.68     3601     3325    1 #> omega 0.07 0.42 -0.72 -0.21 0.06 0.34  0.93     4134     3106    1 #>  #> Residual deviance: 106.5 (on 102 data points) #>                pD: 59.4 #>               DIC: 165.9 #>  #> Bayesian p-value: 0.89 #>  #> -------------------------------------------------------- Node-split UK vs. t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.20 0.22 -0.65 -0.35 -0.21 -0.06  0.22     4943     3303    1 #> d_dir -0.30 0.36 -1.01 -0.53 -0.29 -0.06  0.38     5960     3471    1 #> d_ind -0.14 0.29 -0.69 -0.34 -0.15  0.05  0.43     4138     3303    1 #> omega -0.15 0.46 -1.07 -0.46 -0.16  0.16  0.77     4942     3621    1 #>  #> Residual deviance: 107.3 (on 102 data points) #>                pD: 60.2 #>               DIC: 167.5 #>  #> Bayesian p-value: 0.73 plot(thrombo_nodesplit) plot(thrombo_nodesplit, pars = \"omega\", stat = \"halfeye\", ref_line = 0) +   ggplot2::aes(y = comparison) +   ggplot2::facet_null()"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Thrombolytic treatments","text":"Relative effects pairwise contrasts treatments can produced using relative_effects() function, all_contrasts = TRUE.  Treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(thrombo_releff <- relative_effects(thrombo_fit, all_contrasts = TRUE)) #>                            mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Acc t-PA vs. SK]        -0.18 0.04 -0.26 -0.21 -0.18 -0.15 -0.09     2761     3025    1 #> d[ASPAC vs. SK]            0.02 0.04 -0.06 -0.01  0.02  0.04  0.08     5145     3409    1 #> d[PTCA vs. SK]            -0.48 0.10 -0.67 -0.54 -0.48 -0.41 -0.28     3892     3322    1 #> d[r-PA vs. SK]            -0.12 0.06 -0.24 -0.16 -0.12 -0.08 -0.01     4038     3188    1 #> d[SK + t-PA vs. SK]       -0.05 0.05 -0.14 -0.08 -0.05 -0.02  0.04     6658     2968    1 #> d[t-PA vs. SK]             0.00 0.03 -0.06 -0.02  0.00  0.02  0.06     4487     3522    1 #> d[TNK vs. SK]             -0.17 0.08 -0.33 -0.22 -0.17 -0.12 -0.02     3753     3040    1 #> d[UK vs. SK]              -0.21 0.22 -0.63 -0.35 -0.21 -0.06  0.22     4365     3657    1 #> d[ASPAC vs. Acc t-PA]      0.19 0.06  0.08  0.16  0.19  0.23  0.30     3345     3392    1 #> d[PTCA vs. Acc t-PA]      -0.30 0.10 -0.49 -0.36 -0.30 -0.23 -0.10     5066     3550    1 #> d[r-PA vs. Acc t-PA]       0.05 0.06 -0.06  0.02  0.05  0.09  0.16     6568     3251    1 #> d[SK + t-PA vs. Acc t-PA]  0.13 0.05  0.02  0.09  0.13  0.17  0.23     5497     3588    1 #> d[t-PA vs. Acc t-PA]       0.18 0.05  0.08  0.14  0.18  0.22  0.28     3240     2998    1 #> d[TNK vs. Acc t-PA]        0.01 0.06 -0.12 -0.04  0.01  0.05  0.13     5522     3505    1 #> d[UK vs. Acc t-PA]        -0.03 0.22 -0.45 -0.17 -0.03  0.12  0.39     4377     3572    1 #> d[PTCA vs. ASPAC]         -0.49 0.11 -0.70 -0.56 -0.49 -0.42 -0.28     4056     3211    1 #> d[r-PA vs. ASPAC]         -0.14 0.07 -0.28 -0.19 -0.14 -0.09 -0.01     4112     3273    1 #> d[SK + t-PA vs. ASPAC]    -0.06 0.06 -0.18 -0.10 -0.07 -0.03  0.05     5751     3337    1 #> d[t-PA vs. ASPAC]         -0.01 0.04 -0.08 -0.04 -0.01  0.01  0.06     6502     3369    1 #> d[TNK vs. ASPAC]          -0.19 0.08 -0.36 -0.24 -0.19 -0.13 -0.02     3891     3286    1 #> d[UK vs. ASPAC]           -0.22 0.22 -0.65 -0.37 -0.22 -0.07  0.20     4484     3619    1 #> d[r-PA vs. PTCA]           0.35 0.11  0.14  0.28  0.35  0.43  0.57     5694     3615    1 #> d[SK + t-PA vs. PTCA]      0.43 0.11  0.22  0.35  0.43  0.50  0.64     4856     3294    1 #> d[t-PA vs. PTCA]           0.48 0.11  0.27  0.41  0.48  0.55  0.68     3975     3305    1 #> d[TNK vs. PTCA]            0.30 0.12  0.08  0.23  0.30  0.38  0.54     5733     3332    1 #> d[UK vs. PTCA]             0.27 0.24 -0.19  0.11  0.27  0.43  0.74     4395     3571    1 #> d[SK + t-PA vs. r-PA]      0.08 0.07 -0.06  0.03  0.08  0.12  0.22     6212     3107    1 #> d[t-PA vs. r-PA]           0.13 0.07  0.00  0.08  0.13  0.17  0.26     4055     3160    1 #> d[TNK vs. r-PA]           -0.05 0.09 -0.22 -0.10 -0.05  0.01  0.13     7795     3074    1 #> d[UK vs. r-PA]            -0.08 0.22 -0.52 -0.23 -0.08  0.07  0.34     4418     3533    1 #> d[t-PA vs. SK + t-PA]      0.05 0.06 -0.05  0.01  0.05  0.09  0.16     5597     2883    1 #> d[TNK vs. SK + t-PA]      -0.12 0.08 -0.29 -0.18 -0.12 -0.07  0.04     5396     3047    1 #> d[UK vs. SK + t-PA]       -0.16 0.22 -0.58 -0.31 -0.16 -0.01  0.27     4460     3552    1 #> d[TNK vs. t-PA]           -0.17 0.08 -0.34 -0.23 -0.18 -0.12 -0.01     3787     2841    1 #> d[UK vs. t-PA]            -0.21 0.22 -0.62 -0.35 -0.21 -0.06  0.22     4467     3567    1 #> d[UK vs. TNK]             -0.03 0.23 -0.47 -0.19 -0.03  0.13  0.41     4493     3255    1 plot(thrombo_releff, ref_line = 0) (thrombo_ranks <- posterior_ranks(thrombo_fit)) #>                 mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[SK]        7.44 0.94    6   7   7   8     9     4020       NA    1 #> rank[Acc t-PA]  3.19 0.80    2   3   3   4     5     4145     3611    1 #> rank[ASPAC]     7.99 1.14    5   7   8   9     9     4323       NA    1 #> rank[PTCA]      1.13 0.35    1   1   1   1     2     3769     3739    1 #> rank[r-PA]      4.39 1.16    2   4   4   5     7     6122     3377    1 #> rank[SK + t-PA] 6.00 1.23    4   5   6   6     9     4838       NA    1 #> rank[t-PA]      7.48 1.11    5   7   8   8     9     4221       NA    1 #> rank[TNK]       3.49 1.29    2   3   3   4     6     4627     2860    1 #> rank[UK]        3.89 2.67    1   2   2   5     9     4306       NA    1 plot(thrombo_ranks) (thrombo_rankprobs <- posterior_rank_probs(thrombo_fit)) #>              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] p_rank[8] #> d[SK]             0.00      0.00      0.00      0.00      0.01      0.13      0.39      0.32 #> d[Acc t-PA]       0.00      0.20      0.46      0.30      0.05      0.00      0.00      0.00 #> d[ASPAC]          0.00      0.00      0.00      0.01      0.03      0.09      0.18      0.26 #> d[PTCA]           0.87      0.12      0.00      0.00      0.00      0.00      0.00      0.00 #> d[r-PA]           0.00      0.05      0.15      0.30      0.38      0.08      0.01      0.01 #> d[SK + t-PA]      0.00      0.00      0.01      0.06      0.24      0.46      0.09      0.07 #> d[t-PA]           0.00      0.00      0.00      0.00      0.04      0.15      0.29      0.32 #> d[TNK]            0.00      0.24      0.31      0.24      0.15      0.03      0.01      0.01 #> d[UK]             0.12      0.38      0.07      0.09      0.10      0.05      0.02      0.03 #>              p_rank[9] #> d[SK]             0.14 #> d[Acc t-PA]       0.00 #> d[ASPAC]          0.44 #> d[PTCA]           0.00 #> d[r-PA]           0.01 #> d[SK + t-PA]      0.06 #> d[t-PA]           0.20 #> d[TNK]            0.01 #> d[UK]             0.14 plot(thrombo_rankprobs) (thrombo_cumrankprobs <- posterior_rank_probs(thrombo_fit, cumulative = TRUE)) #>              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] p_rank[8] #> d[SK]             0.00      0.00      0.00      0.00      0.01      0.15      0.54      0.86 #> d[Acc t-PA]       0.00      0.20      0.66      0.95      1.00      1.00      1.00      1.00 #> d[ASPAC]          0.00      0.00      0.00      0.01      0.03      0.12      0.30      0.56 #> d[PTCA]           0.87      1.00      1.00      1.00      1.00      1.00      1.00      1.00 #> d[r-PA]           0.00      0.05      0.20      0.51      0.89      0.97      0.99      0.99 #> d[SK + t-PA]      0.00      0.00      0.01      0.08      0.32      0.78      0.87      0.94 #> d[t-PA]           0.00      0.00      0.00      0.01      0.04      0.19      0.48      0.80 #> d[TNK]            0.00      0.24      0.55      0.79      0.95      0.98      0.99      0.99 #> d[UK]             0.12      0.50      0.57      0.66      0.76      0.81      0.83      0.86 #>              p_rank[9] #> d[SK]                1 #> d[Acc t-PA]          1 #> d[ASPAC]             1 #> d[PTCA]              1 #> d[r-PA]              1 #> d[SK + t-PA]         1 #> d[t-PA]              1 #> d[TNK]               1 #> d[UK]                1 plot(thrombo_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: White blood cell transfusion","text":"begin setting network - just pairwise meta-analysis. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). set “Control” reference treatment.","code":"tr_net <- set_agd_arm(transfusion,                             study = studyc,                            trt = trtc,                            r = r,                             n = n,                            trt_ref = \"Control\") tr_net #> A network with 6 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms           #>  Bow 1984      2: Control | Transfusion #>  Herzig 1977   2: Control | Transfusion #>  Higby 1975    2: Control | Transfusion #>  Scali 1978    2: Control | Transfusion #>  Vogler 1977   2: Control | Transfusion #>  Winston 1982a 2: Control | Transfusion #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 6 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: White blood cell transfusion","text":"fit two random effects models, first non-informative prior heterogeneity, using informative prior described Turner et al. (2012).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"random-effects-meta-analysis-with-non-informative-heterogeneity-prior","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis with non-informative heterogeneity prior","title":"Example: White blood cell transfusion","text":"fit random effects model using nma() function trt_effects = \"random\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), non-informative \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  posterior distribution heterogeneity variance \\(\\tau^2\\) summarised ","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. tr_fit_RE_noninf <- nma(tr_net,                          trt_effects = \"random\",                         prior_intercept = normal(scale = 100),                         prior_trt = normal(scale = 100),                         prior_het = half_normal(scale = 5)) tr_fit_RE_noninf #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Transfusion]   -1.17    0.03 0.99   -3.55   -1.67   -1.07   -0.57    0.61  1236    1 #> lp__           -175.56    0.10 3.16 -182.58 -177.37 -175.20 -173.28 -170.42  1048    1 #> tau               1.87    0.03 1.04    0.56    1.16    1.62    2.30    4.53  1251    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:54:06 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(tr_fit_RE_noninf, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(tr_fit_RE_noninf, prior = \"het\") noninf_tau <- as.array(tr_fit_RE_noninf, pars = \"tau\") noninf_tausq <- noninf_tau^2 names(noninf_tausq) <- \"tausq\" summary(noninf_tausq) #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq 4.57 5.97 0.32 1.35 2.64 5.29 20.52     1169     1910    1"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"random-effects-meta-analysis-with-informative-heterogeneity-prior","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis with informative heterogeneity prior","title":"Example: White blood cell transfusion","text":"Keeping rest model setup , now use informative \\(\\textrm{log-N}(-3.93, 1.51^2)\\) prior heterogeneity variance \\(\\tau^2\\). can examine range parameter values implied prior distribution summary() method: Fitting RE model, specify log_normal prior distribution prior_het argument, set prior_het_type = \"var\" indicate prior distribution variance scale (instead standard deviation, default). Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Note: heterogeneity variance \\(\\tau^2\\) plotted since prior specified \\(\\tau^2\\). posterior distribution heterogeneity variance \\(\\tau^2\\) summarised ","code":"summary(log_normal(-3.93, 1.51)) #> A log-Normal prior distribution: location = -3.93, scale = 1.51. #> 50% of the prior density lies between 0.01 and 0.05. #> 95% of the prior density lies between 0 and 0.38. tr_fit_RE_inf <- nma(tr_net,                       trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = log_normal(-3.93, 1.51),                      prior_het_type = \"var\") tr_fit_RE_inf #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%    75%   97.5% n_eff Rhat #> d[Transfusion]   -0.78    0.01 0.43   -1.72   -1.03   -0.76   -0.5    0.00  2075    1 #> lp__           -180.19    0.07 2.77 -186.32 -181.82 -179.88 -178.2 -175.67  1544    1 #> tau               0.50    0.01 0.35    0.05    0.23    0.45    0.7    1.36  1683    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:54:12 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(tr_fit_RE_inf, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(tr_fit_RE_inf, prior = \"het\") inf_tau <- as.array(tr_fit_RE_inf, pars = \"tau\") inf_tausq <- inf_tau^2 names(inf_tausq) <- \"tausq\" summary(inf_tausq) #>       mean   sd 2.5%  25% 50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq 0.37 0.52    0 0.05 0.2 0.49  1.84     1463     2457    1"},{"path":[]},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David M. Phillippo. Author, maintainer.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Phillippo DM (2023). multinma: Bayesian Network Meta-Analysis Individual Aggregate Data. doi:10.5281/zenodo.3904454, R package version 0.5.1.9004, https://dmphillippo.github.io/multinma/. Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189-1210. doi:10.1111/rssa.12579.","code":"@Manual{,   title = {multinma: Bayesian Network Meta-Analysis of Individual and Aggregate Data},   author = {David M. Phillippo},   year = {2023},   note = {R package version 0.5.1.9004},   url = {https://dmphillippo.github.io/multinma/},   doi = {10.5281/zenodo.3904454}, } @Article{,   title = {Multilevel Network Meta-Regression for population-adjusted treatment comparisons},   author = {David M. Phillippo and Sofia Dias and A. E. Ades and Mark Belger and Alan Brnabic and Alexander Schacht and Daniel Saure and Zbigniew Kadziola and Nicky J. Welton},   year = {2020},   doi = {10.1111/rssa.12579},   journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},   volume = {183},   number = {3},   pages = {1189-1210}, }"},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"multinma-network-meta-analysis-of-individual-and-aggregate-data-in-stan-","dir":"","previous_headings":"","what":"Bayesian network meta-analysis of individual and aggregate data","title":"Bayesian network meta-analysis of individual and aggregate data","text":"multinma package implements network meta-analysis, network meta-regression, multilevel network meta-regression models combine evidence network studies treatments using either aggregate data individual patient data study (Phillippo et al. 2020; Phillippo 2019). Models estimated Bayesian framework using Stan (Carpenter et al. 2017).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian network meta-analysis of individual and aggregate data","text":"can install released version multinma CRAN : development version can installed R-universe : source GitHub : Installing source requires rstan package installed configured. See installation guide .","code":"install.packages(\"multinma\") install.packages(\"multinma\", repos = c(\"https://dmphillippo.r-universe.dev\", getOption(\"repos\"))) # install.packages(\"devtools\") devtools::install_github(\"dmphillippo/multinma\")"},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting started","title":"Bayesian network meta-analysis of individual and aggregate data","text":"good place start package vignettes walk example analyses, see vignette(\"vignette_overview\") overview. series NICE Technical Support Documents evidence synthesis gives detailed introduction network meta-analysis: Dias, S. et al. (2011). “NICE DSU Technical Support Documents 1-7: Evidence Synthesis Decision Making.” National Institute Health Care Excellence. Available https://www.sheffield.ac.uk/nice-dsu/tsds. Multilevel network meta-regression set following methods paper: Phillippo, D. M. et al. (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3):1189-1210. doi: 10.1111/rssa.12579.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"citing-multinma","dir":"","previous_headings":"","what":"Citing multinma","title":"Bayesian network meta-analysis of individual and aggregate data","text":"multinma package can cited follows: Phillippo, D. M. (2023). multinma: Bayesian Network Meta-Analysis Individual Aggregate Data. R package version 0.5.1.9000, doi: 10.5281/zenodo.3904454. fitting ML-NMR models, please cite methods paper: Phillippo, D. M. et al. (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3):1189-1210. doi: 10.1111/rssa.12579.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":null,"dir":"Reference","previous_headings":"","what":"The Bernoulli Distribution — qbern","title":"The Bernoulli Distribution — qbern","text":"quantile function qbern Bernoulli distribution, success probability prob. equivalent qbinom(p, 1, prob).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Bernoulli Distribution — qbern","text":"","code":"qbern(p, prob, lower.tail = TRUE, log.p = FALSE)  pbern(q, prob, lower.tail = TRUE, log.p = FALSE)  dbern(x, prob, log = FALSE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Bernoulli Distribution — qbern","text":"p vector probabilities prob probability success lower.tail, log.p, log see stats::Binomial x, q vector quantiles","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":null,"dir":"Reference","previous_headings":"","what":"The Gamma distribution — qgamma","title":"The Gamma distribution — qgamma","text":"provide convenient extensions [dpq]gamma functions, allow distribution specified terms mean standard deviation, instead shape rate/scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Gamma distribution — qgamma","text":"","code":"qgamma(   p,   shape,   rate = 1,   scale = 1/rate,   lower.tail = TRUE,   log.p = FALSE,   mean,   sd )  dgamma(x, shape, rate = 1, scale = 1/rate, log = FALSE, mean, sd)  pgamma(   q,   shape,   rate = 1,   scale = 1/rate,   lower.tail = TRUE,   log.p = FALSE,   mean,   sd )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Gamma distribution — qgamma","text":"p vector probabilities shape, rate, scale, log, lower.tail, log.p see stats::GammaDist mean, sd mean standard deviation, overriding shape rate scale specified x, q vector quantiles","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_ndmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Example newly-diagnosed multiple myeloma — example_ndmm","title":"Example newly-diagnosed multiple myeloma — example_ndmm","text":"Calling example(\"example_ndmm\") run proportional hazards Weibull NMA model newly-diagnosed multiple myeloma data, using code Examples section . resulting stan_nma object ndmm_fit available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_ndmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example newly-diagnosed multiple myeloma — example_ndmm","text":"","code":"# \\donttest{ # Fit Weibull (PH) model ndmm_fit <- nma(ndmm_net, refresh = if (interactive()) 200 else 0,                 likelihood = \"weibull\",                 prior_intercept = normal(scale = 100),                 prior_trt = normal(scale = 10),                 prior_aux = half_normal(scale = 10)) #> Error in eval(expr, envir, enclos): object 'ndmm_net' not found  ndmm_fit #> Error in eval(expr, envir, enclos): object 'ndmm_fit' not found # } # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"ndmm_net\", ndmm_net, .GlobalEnv)   assign(\"ndmm_fit\", ndmm_fit, .GlobalEnv) } #> Error in eval(expr, envir, enclos): object 'ndmm_net' not found # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_pso_mlnmr.html","id":null,"dir":"Reference","previous_headings":"","what":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","title":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","text":"Calling example(\"example_pso_mlnmr\") run ML-NMR model plaque psoriasis IPD AgD, using code Examples section . resulting stan_nma object pso_fit available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_pso_mlnmr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","text":"Plaque psoriasis ML-NMR use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_pso_mlnmr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","text":"","code":"# Set up plaque psoriasis network combining IPD and AgD library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.  # \\donttest{ # Fitting a ML-NMR model. # Specify a regression model to include effect modifier interactions for five # covariates, along with main (prognostic) effects. We use a probit link and # specify that the two-parameter Binomial approximation for the aggregate-level # likelihood should be used. We set treatment-covariate interactions to be equal # within each class. We narrow the possible range for random initial values with # init_r = 0.1, since probit models in particular are often hard to initialise. # Using the QR decomposition greatly improves sampling efficiency here, as is # often the case for regression models. pso_fit <- nma(pso_net, refresh = if (interactive()) 200 else 0,                trt_effects = \"fixed\",                link = \"probit\",                likelihood = \"bernoulli2\",                regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                class_interactions = \"common\",                prior_intercept = normal(scale = 10),                prior_trt = normal(scale = 10),                prior_reg = normal(scale = 10),                init_r = 0.1,                QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25% #> beta[durnpso]                           0.04    0.00 0.06    -0.08     0.00 #> beta[prevsys]                          -0.14    0.00 0.16    -0.44    -0.25 #> beta[bsa]                              -0.06    0.01 0.45    -0.98    -0.36 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02 #> beta[psa]                              -0.08    0.00 0.17    -0.42    -0.19 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.14    -0.05 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.19    -0.18     0.06 #> beta[prevsys:.trtclassIL blocker]       0.07    0.00 0.17    -0.27    -0.05 #> beta[bsa:.trtclassTNFa blocker]         0.05    0.01 0.51    -0.92    -0.30 #> beta[bsa:.trtclassIL blocker]           0.29    0.01 0.50    -0.66    -0.05 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.03    -0.24    -0.19 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12 #> beta[psa:.trtclassTNFa blocker]        -0.05    0.00 0.20    -0.44    -0.19 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.18    -0.34    -0.11 #> d[ETN]                                  1.55    0.00 0.08     1.39     1.50 #> d[IXE_Q2W]                              2.95    0.00 0.09     2.78     2.89 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.38     2.48 #> d[SEC_150]                              2.14    0.00 0.12     1.92     2.06 #> d[SEC_300]                              2.45    0.00 0.12     2.22     2.37 #> lp__                                -1653.59    0.09 3.46 -1661.35 -1655.74 #>                                          50%      75%    97.5% n_eff Rhat #> beta[durnpso]                           0.04     0.08     0.16  6172    1 #> beta[prevsys]                          -0.13    -0.03     0.18  4777    1 #> beta[bsa]                              -0.05     0.24     0.77  5161    1 #> beta[weight]                            0.04     0.06     0.10  5897    1 #> beta[psa]                              -0.08     0.03     0.24  4822    1 #> beta[durnpso:.trtclassTNFa blocker]    -0.03     0.02     0.11  5826    1 #> beta[durnpso:.trtclassIL blocker]      -0.01     0.03     0.12  7573    1 #> beta[prevsys:.trtclassTNFa blocker]     0.19     0.32     0.55  5256    1 #> beta[prevsys:.trtclassIL blocker]       0.06     0.18     0.40  5580    1 #> beta[bsa:.trtclassTNFa blocker]         0.04     0.37     1.11  5623    1 #> beta[bsa:.trtclassIL blocker]           0.28     0.62     1.30  6362    1 #> beta[weight:.trtclassTNFa blocker]     -0.17    -0.14    -0.10  6403    1 #> beta[weight:.trtclassIL blocker]       -0.10    -0.08    -0.04  7167    1 #> beta[psa:.trtclassTNFa blocker]        -0.05     0.09     0.34  5148    1 #> beta[psa:.trtclassIL blocker]           0.01     0.13     0.37  5831    1 #> d[ETN]                                  1.55     1.60     1.71  3974    1 #> d[IXE_Q2W]                              2.95     3.01     3.12  4700    1 #> d[IXE_Q4W]                              2.54     2.60     2.70  5093    1 #> d[SEC_150]                              2.14     2.22     2.37  4872    1 #> d[SEC_300]                              2.45     2.53     2.68  5633    1 #> lp__                                -1653.29 -1651.12 -1647.80  1637    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:17:03 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"pso_net\", pso_net, .GlobalEnv)   assign(\"pso_fit\", pso_fit, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_fe.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking FE NMA — example_smk_fe","title":"Example smoking FE NMA — example_smk_fe","text":"Calling example(\"example_smk_fe\") run fixed effects NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_FE available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_fe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking FE NMA — example_smk_fe","text":"Smoking FE NMA use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_fe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking FE NMA — example_smk_fe","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting a fixed effect model smk_fit_FE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100))  smk_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          0.85    0.00 0.18     0.50     0.72     0.85 #> d[Individual counselling]     0.77    0.00 0.06     0.66     0.73     0.77 #> d[Self-help]                  0.23    0.00 0.13    -0.03     0.14     0.22 #> lp__                      -6008.54    0.09 3.69 -6016.70 -6010.75 -6008.25 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          0.97     1.19  2170    1 #> d[Individual counselling]     0.81     0.89  1787    1 #> d[Self-help]                  0.31     0.49  2712    1 #> lp__                      -6005.90 -6002.34  1636    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:18:36 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_FE\", smk_fit_FE, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_nodesplit.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking node-splitting — example_smk_nodesplit","title":"Example smoking node-splitting — example_smk_nodesplit","text":"Calling example(\"example_smk_nodesplit\") run node-splitting models smoking cessation data, using code Examples section . resulting nma_nodesplit_df object smk_fit_RE_nodesplit available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_nodesplit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking node-splitting — example_smk_nodesplit","text":"Smoking node-splitting use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_nodesplit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking node-splitting — example_smk_nodesplit","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting all possible node-splitting models smk_fit_RE_nodesplit <- nma(smk_net, refresh = if (interactive()) 200 else 0,                             consistency = \"nodesplit\",                             trt_effects = \"random\",                             prior_intercept = normal(scale = 100),                             prior_trt = normal(scale = 100),                             prior_het = normal(scale = 5)) #> Fitting model 1 of 7, node-split: Group counselling vs. No intervention #> Fitting model 2 of 7, node-split: Individual counselling vs. No intervention #> Fitting model 3 of 7, node-split: Self-help vs. No intervention #> Fitting model 4 of 7, node-split: Individual counselling vs. Group counselling #> Fitting model 5 of 7, node-split: Self-help vs. Group counselling #> Fitting model 6 of 7, node-split: Self-help vs. Individual counselling #> Fitting model 7 of 7, consistency model # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_RE_nodesplit\", smk_fit_RE_nodesplit, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_re.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking RE NMA — example_smk_re","title":"Example smoking RE NMA — example_smk_re","text":"Calling example(\"example_smk_re\") run random effects NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_RE available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_re.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking RE NMA — example_smk_re","text":"Smoking RE NMA use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_re.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking RE NMA — example_smk_re","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting a random effects model smk_fit_RE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = normal(scale = 5))  smk_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          1.09    0.01 0.44     0.25     0.79     1.08 #> d[Individual counselling]     0.84    0.01 0.23     0.37     0.69     0.83 #> d[Self-help]                  0.49    0.01 0.40    -0.29     0.23     0.48 #> lp__                      -5919.90    0.19 6.56 -5933.59 -5924.14 -5919.38 #> tau                           0.84    0.01 0.19     0.54     0.71     0.82 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          1.36     2.01  1954    1 #> d[Individual counselling]     0.98     1.31  1243    1 #> d[Self-help]                  0.73     1.32  2162    1 #> lp__                      -5915.15 -5908.35  1137    1 #> tau                           0.95     1.28  1128    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:20:45 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_RE\", smk_fit_RE, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_ume.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking UME NMA — example_smk_ume","title":"Example smoking UME NMA — example_smk_ume","text":"Calling example(\"example_smk_ume\") run unrelated mean effects (inconsistency) NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_RE_UME available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_ume.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking UME NMA — example_smk_ume","text":"Smoking UME NMA use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_ume.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking UME NMA — example_smk_ume","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting an unrelated mean effects (inconsistency) model smk_fit_RE_UME <- nma(smk_net, refresh = if (interactive()) 200 else 0,                       consistency = \"ume\",                       trt_effects = \"random\",                       prior_intercept = normal(scale = 100),                       prior_trt = normal(scale = 100),                       prior_het = normal(scale = 5))  smk_fit_RE_UME #> A random effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                     mean se_mean   sd     2.5% #> d[Group counselling vs. No intervention]            1.14    0.02 0.83    -0.37 #> d[Individual counselling vs. No intervention]       0.90    0.01 0.28     0.36 #> d[Self-help vs. No intervention]                    0.34    0.01 0.58    -0.87 #> d[Individual counselling vs. Group counselling]    -0.30    0.01 0.61    -1.52 #> d[Self-help vs. Group counselling]                 -0.62    0.01 0.72    -2.04 #> d[Self-help vs. Individual counselling]             0.14    0.02 1.06    -2.00 #> lp__                                            -5933.49    0.19 6.37 -5947.10 #> tau                                                 0.94    0.01 0.23     0.58 #>                                                      25%      50%      75% #> d[Group counselling vs. No intervention]            0.59     1.11     1.64 #> d[Individual counselling vs. No intervention]       0.71     0.89     1.07 #> d[Self-help vs. No intervention]                   -0.04     0.34     0.71 #> d[Individual counselling vs. Group counselling]    -0.69    -0.30     0.10 #> d[Self-help vs. Group counselling]                 -1.08    -0.61    -0.15 #> d[Self-help vs. Individual counselling]            -0.52     0.15     0.85 #> lp__                                            -5937.59 -5933.16 -5929.10 #> tau                                                 0.78     0.91     1.07 #>                                                    97.5% n_eff Rhat #> d[Group counselling vs. No intervention]            2.89  2706    1 #> d[Individual counselling vs. No intervention]       1.47  1275    1 #> d[Self-help vs. No intervention]                    1.48  2579    1 #> d[Individual counselling vs. Group counselling]     0.92  2838    1 #> d[Self-help vs. Group counselling]                  0.82  2957    1 #> d[Self-help vs. Individual counselling]             2.23  3818    1 #> lp__                                            -5922.16  1183    1 #> tau                                                 1.48  1304    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:20:57 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_RE_UME\", smk_fit_RE_UME, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/adapt_delta.html","id":null,"dir":"Reference","previous_headings":"","what":"Target average acceptance probability — adapt_delta","title":"Target average acceptance probability — adapt_delta","text":"Stan control argument adapt_delta sets target average acceptance probability -U-Turn Sampler (NUTS) used Stan.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/adapt_delta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Target average acceptance probability — adapt_delta","text":"default value adapt_delta used nma() 0.8 fixed effect models, 0.95 random effects models. need change adapt_delta unless see warning message divergent transitions. Increasing adapt_delta default value closer 1 means Stan use smaller step size, making sampling slower robust, resulting fewer divergent transitions. details see Stan documentation available https://mc-stan.org/users/documentation/.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":null,"dir":"Reference","previous_headings":"","what":"Add numerical integration points to aggregate data — add_integration","title":"Add numerical integration points to aggregate data — add_integration","text":"add_integration() generic creates Quasi-Monte Carlo numerical integration points using Gaussian copula Sobol' sequences, described Phillippo et al. (2020) . Methods available networks stored nma_data objects, data frames. function unnest_integration() unnests integration points stored data frame, aid plotting exploration.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add numerical integration points to aggregate data — add_integration","text":"","code":"add_integration(x, ...)  # S3 method for default add_integration(x, ...)  # S3 method for data.frame add_integration(   x,   ...,   cor = NULL,   cor_adjust = NULL,   n_int = 64L,   int_args = list() )  # S3 method for nma_data add_integration(   x,   ...,   cor = NULL,   cor_adjust = NULL,   n_int = 64L,   int_args = list() )  unnest_integration(data)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add numerical integration points to aggregate data — add_integration","text":"x nma_data object, created set_*() functions combine_network(), data frame ... Distributions covariates, see \"Details\" cor Correlation matrix use generating integration points. default, takes weighted correlation matrix IPD studies. Rows columns match order covariates specified .... cor_adjust Adjustment apply correlation matrix given cor (computed IPD cor = NULL) obtain Gaussian copula correlations, either \"spearman\", \"pearson\", \"none\", see \"Details\". default cor = NULL \"spearman\", otherwise default \"pearson\". n_int Number integration points generate, default 64. Powers 2 recommended, expected particularly efficient QMC integration. int_args named list arguments pass sobol() data Data frame nested integration points, stored list columns .int_<variable name>","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add numerical integration points to aggregate data — add_integration","text":"nma_data method, object class nma_data. data.frame method, input data frame returned (tibble) added column covariate (prefixed \".int_\"), containing numerical integration points nested length-n_int vectors within row. unnest_integration(), data frame integration points unnested.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add numerical integration points to aggregate data — add_integration","text":"arguments passed ... specify distributions covariates. Argument names specify name covariate, match covariate name IPD (IPD present). required marginal distribution specified using function distr(). argument cor_adjust specifies correlation matrix given cor (computed IPD cor = NULL) adjusted obtain correlation matrix Gaussian copula, using formulae Xiao Zhou (2018) . cor_adjust = \"spearman\" used correlations cor computed using Spearman's rank correlation. Correlations continuous covariates reproduced exactly integration points. Correlations discrete covariates reproduced approximately. default cor = NULL correlations calculated IPD studies. cor_adjust = \"pearson\" used correlations cor computed using Pearson's product-moment correlation. Correlations Normal covariates reproduced exactly integration points, others reproduced approximately. Correlations discrete covariates reproduced approximately (identically cor_adjust   = \"spearman\"). default cor provided user, since cor() defaults method = \"pearson\" Pearson correlations likely reported published data. However, recommend providing Spearman correlations (e.g. cor(., method = \"spearman\")) using cor_adjust = \"spearman\" possible. cor_adjust = \"none\" allows user specify correlation matrix Gaussian copula directly; adjustment applied. cor_adjust = \"legacy\" also available, reproduces exactly behaviour version 0.3.0 earlier. similar cor_adjust =   \"none\", unadjusted Spearman correlations used cor = NULL. adding integration points network object correlation matrix used stored $int_cor, copula correlation matrix adjustment used stored attributes $int_cor. correlation matrix passed add_integration() (e.g. reuse correlations external target population) detected, correct setting cor_adjust automatically applied.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Add numerical integration points to aggregate data — add_integration","text":"Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 . Xiao Q, Zhou S (2018). “Matching correlation coefficient Gaussian copula.” Communications Statistics - Theory Methods, 48(7), 1728--1747. doi:10.1080/03610926.2018.1439962 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add numerical integration points to aggregate data — add_integration","text":"","code":"## Plaque psoriasis ML-NMR - network setup and adding integration points # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.   ## Adding integration points to a data frame, e.g. for prediction # Define a data frame of covariate summaries new_agd_int <- data.frame(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1)  # Adding integration points, using the weighted average correlation matrix # computed for the plaque psoriasis network new_agd_int <- add_integration(new_agd_int,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   cor = pso_net$int_cor,   n_int = 64)  # Here, since we reused the correlation matrix pso_net$int_cor from the # network, the correct setting of cor_adjust = \"spearman\" is automatically # applied  new_agd_int #> # A tibble: 1 × 13 #>   bsa_mean bsa_sd prevsys   psa weight_mean weight_sd durnpso_mean durnpso_sd #>      <dbl>  <dbl>   <dbl> <dbl>       <dbl>     <dbl>        <dbl>      <dbl> #> 1      0.6    0.3     0.1   0.2          10         1            3          1 #> # ℹ 5 more variables: .int_durnpso <list>, .int_prevsys <list>, #> #   .int_bsa <list>, .int_weight <list>, .int_psa <list>"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"Samples (post warm-) stan_nma model object can coerced array, matrix, data frame.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"","code":"# S3 method for stan_nma as.array(x, ..., pars, include = TRUE)  # S3 method for stan_nma as.data.frame(x, ..., pars, include = TRUE)  # S3 method for stan_nma as.matrix(x, ..., pars, include = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"x stan_nma object ... Additional arguments passed .array.stanfit() pars Optional character vector parameter names include output. specified, parameters used. include Logical, parameters pars included (TRUE, default) excluded (FALSE)?","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":".array() method produces 3D array [Iteration, Chain, Parameter] containing posterior samples parameter (class mcmc_array). side effect enabling bayesplot functions seamlessly work stan_nma objects. .data.frame() method produces data frame containing posterior samples parameter, combined chains. .matrix() method produces matrix containing posterior samples parameter, combined chains.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":null,"dir":"Reference","previous_headings":"","what":"as.stanfit — as.stanfit","title":"as.stanfit — as.stanfit","text":"Attempt turn object stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"as.stanfit — as.stanfit","text":"","code":"as.stanfit(x, ...)  # S3 method for stan_nma as.stanfit(x, ...)  # S3 method for default as.stanfit(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"as.stanfit — as.stanfit","text":"x object ... additional arguments","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"as.stanfit — as.stanfit","text":"stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":null,"dir":"Reference","previous_headings":"","what":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"Data frame containing results 26 trials comparing 17 treatments 4 classes prevention stroke patients atrial fibrillation (Cooper et al. 2009) . data corrected versions given van Valkenhoef Kuiper (2016) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"","code":"atrial_fibrillation"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"data frame 63 rows 11 variables: studyc study name studyn numeric study ID trtc treatment name trtn numeric treatment code trt_class treatment class r number events n sample size E person-years risk stroke proportion individuals prior stroke year year study publication followup mean length follow-(years)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"Cooper NJ, Sutton AJ, Morris D, Ades AE, Welton NJ (2009). “Addressing -study heterogeneity inconsistency mixed treatment comparisons: Application stroke prevention treatments individuals non-rheumatic atrial fibrillation.” Statistics Medicine, 28(14), 1861--1881. doi:10.1002/sim.3594 . van Valkenhoef G, Kuiper J (2016). gemtc: Network Meta-Analysis Using Bayesian Methods. R package version 0.8-2, https://CRAN.R-project.org/package=gemtc.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":null,"dir":"Reference","previous_headings":"","what":"BCG vaccination — bcg_vaccine","title":"BCG vaccination — bcg_vaccine","text":"Data frame containing results 13 trials comparing BCG vaccination vaccination preventing tuberculosis (TB) (Dias et al. 2011; Berkey et al. 1995) . numbers individuals diagnosed TB arm study follow-period recorded. absolute degrees latitude study conducted also recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BCG vaccination — bcg_vaccine","text":"","code":"bcg_vaccine"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"BCG vaccination — bcg_vaccine","text":"data frame 26 rows 6 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name latitude absolute degrees latitude r number diagnosed TB n sample size","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"BCG vaccination — bcg_vaccine","text":"Berkey CS, Hoaglin DC, Mosteller F, Colditz GA (1995). “random-effects regression model meta-analysis.” Statistics Medicine, 14(4), 395--411. doi:10.1002/sim.4780140406 . Dias S, Sutton AJ, Welton NJ, Ades AE (2011). “NICE DSU Technical Support Document 3: Heterogeneity: subgroups, meta-regression, bias bias-adjustment.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":null,"dir":"Reference","previous_headings":"","what":"Beta blockers to prevent mortality after MI — blocker","title":"Beta blockers to prevent mortality after MI — blocker","text":"Data frame containing number deaths 22 trials comparing beta blockers vs. control preventing mortality myocardial infarction (Carlin 1992; Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Beta blockers to prevent mortality after MI — blocker","text":"","code":"blocker"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Beta blockers to prevent mortality after MI — blocker","text":"data frame 44 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Beta blockers to prevent mortality after MI — blocker","text":"Carlin JB (1992). “Meta-analysis 2 x 2 tables: bayesian approach.” Statistics Medicine, 11(2), 141--158. doi:10.1002/sim.4780110202 . Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine multiple data sources into one network — combine_network","title":"Combine multiple data sources into one network — combine_network","text":"Multiple data sources created using set_ipd(), set_agd_arm(), set_agd_contrast() can combined single network analysis.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine multiple data sources into one network — combine_network","text":"","code":"combine_network(..., trt_ref)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine multiple data sources into one network — combine_network","text":"... multiple data sources, defined using set_* functions trt_ref reference treatment entire network, string (coerced ) referring levels treatment factor variable","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine multiple data sources into one network — combine_network","text":"object class nma_data","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine multiple data sources into one network — combine_network","text":"","code":"## Parkinson's - combining contrast- and arm-based data studies <- parkinsons$studyn (parkinsons_arm <- parkinsons[studies %in% 1:3, ]) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718 #> 7      3    4 -1.20 0.478  81 -0.90   0.695 (parkinsons_contr <- parkinsons[studies %in% 4:7, ]) #>    studyn trtn     y    se   n  diff se_diff #> 8       4    3 -0.24 0.265 128    NA   0.265 #> 9       4    4 -0.59 0.354  72 -0.35   0.442 #> 10      5    3 -0.73 0.335  80    NA   0.335 #> 11      5    4 -0.18 0.442  46  0.55   0.555 #> 12      6    4 -2.20 0.197 137    NA   0.197 #> 13      6    5 -2.50 0.190 131 -0.30   0.274 #> 14      7    4 -1.80 0.200 154    NA   0.200 #> 15      7    5 -2.10 0.250 143 -0.30   0.320  park_arm_net <- set_agd_arm(parkinsons_arm,                             study = studyn,                             trt = trtn,                             y = y,                             se = se,                             sample_size = n)  park_contr_net <- set_agd_contrast(parkinsons_contr,                                    study = studyn,                                    trt = trtn,                                    y = diff,                                    se = se_diff,                                    sample_size = n)  park_net <- combine_network(park_arm_net, park_contr_net)  # Print network details park_net #> A network with 3 AgD studies (arm-based), and 4 AgD studies (contrast-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  #>  Outcome type: continuous #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected  # Plot network plot(park_net, weight_edges = TRUE, weight_nodes = TRUE)   ## Plaque Psoriasis - combining IPD and AgD in a network # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected   # Plot network plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Set default values — .default","title":"Set default values — .default","text":".default() function used internally mark certain values default, user may notified default values used. example, choosing default reference treatment network, using default prior distributions. function .is_default() checks whether argument/object set default value. Neither functions intended called user.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set default values — .default","text":"","code":".default(x = list())  .is_default(x)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set default values — .default","text":"x object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set default values — .default","text":".default(), identical object additional attribute .default. .is_default(), logical value (TRUE FALSE).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":null,"dir":"Reference","previous_headings":"","what":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"Data frame containing number new cases diabetes 22 trials 6 antihypertensive drugs (Elliott Meyer 2007; Dias et al. 2011) . trial duration (years) also recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"","code":"diabetes"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"data frame 48 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name r total number events n total number individuals time trial follow-(years)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Elliott WJ, Meyer PM (2007). “Incident diabetes clinical trials antihypertensive drugs: network meta-analysis.” Lancet, 369(9557), 201--207. doi:10.1016/s0140-6736(07)60108-1 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Deviance Information Criterion (DIC) — dic","title":"Deviance Information Criterion (DIC) — dic","text":"Calculate DIC model fitted using nma() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deviance Information Criterion (DIC) — dic","text":"","code":"dic(x, penalty = c(\"pD\", \"pV\"), ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deviance Information Criterion (DIC) — dic","text":"x fitted model object, inheriting class stan_nma penalty method estimating effective number parameters, used penalise model fit DIC. Either \"pD\" (default), \"pV\". survival likelihoods \"pV\" currently available. ... arguments (used)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deviance Information Criterion (DIC) — dic","text":"nma_dic object.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deviance Information Criterion (DIC) — dic","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking FE NMA example if not already available if (!exists(\"smk_fit_FE\")) example(\"example_smk_fe\", run.donttest = TRUE) # } # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC of FE and RE models (smk_dic_FE <- dic(smk_fit_FE)) #> Residual deviance: 267.2 (on 50 data points) #>                pD: 27.1 #>               DIC: 294.3 (smk_dic_RE <- dic(smk_fit_RE))   # substantially better fit #> Residual deviance: 54.3 (on 50 data points) #>                pD: 44.1 #>               DIC: 98.5  # Plot residual deviance contributions under RE model plot(smk_dic_RE)   # Check for inconsistency using UME model # } # \\donttest{ # Run smoking UME NMA example if not already available if (!exists(\"smk_fit_RE_UME\")) example(\"example_smk_ume\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC smk_dic_RE #> Residual deviance: 54.3 (on 50 data points) #>                pD: 44.1 #>               DIC: 98.5 (smk_dic_RE_UME <- dic(smk_fit_RE_UME))  # no difference in fit #> Residual deviance: 53.7 (on 50 data points) #>                pD: 45 #>               DIC: 98.7  # Compare residual deviance contributions plot(smk_dic_RE, smk_dic_RE_UME, show_uncertainty = FALSE)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduced dietary fat to prevent mortality — dietary_fat","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"Data frame containing number deaths person-years risk 10 trials comparing reduced fat diets vs. control (non-reduced fat diet) preventing mortality (Hooper et al. 2000; Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"","code":"dietary_fat"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"data frame 21 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name r number events n number randomised E person-years risk","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Hooper L, Summerbell CD, Higgins JPT, Thompson RL, Clements G, Capps N, Davey Smith G, Riemersma R, Ebrahim S (2000). “Reduced modified dietary fat preventing cardiovascular disease.” Cochrane Database Systematic Reviews. ISSN 1465-1858, doi:10.1002/14651858.CD002137 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":null,"dir":"Reference","previous_headings":"","what":"Specify a general marginal distribution — distr","title":"Specify a general marginal distribution — distr","text":"distr() used within function add_integration() specify marginal distributions covariates, via corresponding inverse CDF. also used predict.stan_nma() specify distribution baseline response (intercept) predicting absolute outcomes.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specify a general marginal distribution — distr","text":"","code":"distr(qfun, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specify a general marginal distribution — distr","text":"qfun inverse CDF, either function name string ... parameters distribution arguments qfun, quoted evaluated later context aggregate data sources","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specify a general marginal distribution — distr","text":"object class distr.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Specify a general marginal distribution — distr","text":"function qfun formal argument called p. restriction serves crude check inverse CDFs (e.g. error given dnorm used instead qnorm). user-written CDF supplied, must argument p takes vector probabilities.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Specify a general marginal distribution — distr","text":"","code":"## Specifying marginal distributions for integration  df <- data.frame(x1_mean = 2, x1_sd = 0.5, x2 = 0.8)  # Distribution parameters are evaluated in the context of the data frame add_integration(df,                 x1 = distr(qnorm, mean = x1_mean, sd = x1_sd),                 x2 = distr(qbern, prob = x2),                 cor = diag(2)) #> # A tibble: 1 × 5 #>   x1_mean x1_sd    x2 .int_x1    .int_x2    #>     <dbl> <dbl> <dbl> <list>     <list>     #> 1       2   0.5   0.8 <dbl [64]> <dbl [64]>"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalised Student's t distribution (with location and scale) — dgent","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"Density, distribution, quantile function generalised t distribution degrees freedom df, shifted location scaled scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"","code":"dgent(x, df, location = 0, scale = 1)  pgent(q, df, location = 0, scale = 1)  qgent(p, df, location = 0, scale = 1)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"x, q Vector quantiles df Degrees freedom, greater zero location Location parameter scale Scale parameter, greater zero p Vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"dgent() gives density, pgent() gives distribution function, qgent() gives quantile function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":null,"dir":"Reference","previous_headings":"","what":"Kaplan-Meier curves of survival data — geom_km","title":"Kaplan-Meier curves of survival data — geom_km","text":"helper function constructs ggplot2 geom plot Kaplan-Meier curves network containing survival time--event outcomes. useful overlaying \"raw\" survival data estimated survival functions created plotted plot.surv_nma_summary(), can also used standalone plot Kaplan-Meier curves fitting model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kaplan-Meier curves of survival data — geom_km","text":"","code":"geom_km(   network,   ...,   transform = c(\"identity\", \"cloglog\", \"log\", \"cumhaz\"),   curve_args = list(),   cens_args = list() )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kaplan-Meier curves of survival data — geom_km","text":"network nma_data network object containing survival outcomes ... Additional arguments passed survival::survfit() transform Character string giving transformation apply KM curves plotting. default \"identity\" transformation; options \"cloglog\" \\(\\log(-\\log(S))\\), \"log\" \\(\\log(S)\\), \"cumhaz\" cumulative hazard \\(-\\log(S)\\). curve_args Optional list arguments customise curves plotted ggplot2::geom_step() cens_args Optional list arguments customise censoring marks plotted ggplot2::geom_point()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kaplan-Meier curves of survival data — geom_km","text":"ggplot2 geom list can added ggplot2 plot object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kaplan-Meier curves of survival data — geom_km","text":"","code":"# Set up newly-diagnosed multiple myeloma network  head(ndmm_ipd) #>          study trt       studyf trtf      age iss_stage3 response_cr_vgpr male #> 1 McCarthy2012 Pbo McCarthy2012  Pbo 50.81625          0                1    0 #> 2 McCarthy2012 Pbo McCarthy2012  Pbo 62.18165          0                0    0 #> 3 McCarthy2012 Pbo McCarthy2012  Pbo 51.53762          1                1    1 #> 4 McCarthy2012 Pbo McCarthy2012  Pbo 46.74128          0                1    1 #> 5 McCarthy2012 Pbo McCarthy2012  Pbo 62.62561          0                1    1 #> 6 McCarthy2012 Pbo McCarthy2012  Pbo 49.24520          1                1    0 #>   eventtime status #> 1 31.106516      1 #> 2  3.299623      0 #> 3 57.400000      0 #> 4 57.400000      0 #> 5 57.400000      0 #> 6 30.714460      0 head(ndmm_agd) #>        study     studyf trt trtf eventtime status #> 1 Morgan2012 Morgan2012 Pbo  Pbo  18.72575      1 #> 2 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 3 Morgan2012 Morgan2012 Pbo  Pbo  34.35726      1 #> 4 Morgan2012 Morgan2012 Pbo  Pbo  10.77826      1 #> 5 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 6 Morgan2012 Morgan2012 Pbo  Pbo  14.52966      1  ndmm_net <- combine_network(   set_ipd(ndmm_ipd,           study, trt,           Surv = Surv(eventtime / 12, status)),   set_agd_surv(ndmm_agd,                study, trt,                Surv = Surv(eventtime / 12, status),                covariates = ndmm_agd_covs)) # Plot KM curves using ggplot2 library(ggplot2)  # We need to create an empty ggplot object to add the curves to ggplot() + geom_km(ndmm_net)   # Adding plotting options, facets, axis labels, and a plot theme ggplot() +   geom_km(ndmm_net,           curve_args = list(linewidth = 0.5),           cens_args = list(size = 3, shape = 124)) +   facet_wrap(vars(Study)) +   labs(xlab = \"Time\", ylab = \"Survival Probability\") +   theme_multinma()   # Using the transform argument to produce log-log plots (e.g. to assess the # proportional hazards assumption) ggplot() +   geom_km(ndmm_net, transform = \"cloglog\") +   facet_wrap(vars(Study)) +   theme_multinma()   # Using the transform argument to produce cumulative hazard plots ggplot() +   geom_km(ndmm_net, transform = \"cumhaz\") +   facet_wrap(vars(Study)) +   theme_multinma()   # This function can also be used to add KM data to plots of estimated survival # curves from a fitted model, in a similar manner # \\donttest{ # Run newly-diagnosed multiple myeloma example if not already available if (!exists(\"ndmm_fit\")) example(\"example_ndmm\", run.donttest = TRUE) #>  #> exmpl_> ## No test:  #> exmpl_> # Fit Weibull (PH) model #> exmpl_> ndmm_fit <- nma(ndmm_net, ## Don't show:  #> exmpl_+ refresh = if (interactive()) 200 else 0, #> exmpl_+ ## End(Don't show) #> exmpl_+                 likelihood = \"weibull\", #> exmpl_+                 prior_intercept = normal(scale = 100), #> exmpl_+                 prior_trt = normal(scale = 10), #> exmpl_+                 prior_aux = half_normal(scale = 10)) #> Error in eval(ei, envir): object 'ndmm_net' not found # } # Plot estimated survival curves, and overlay the KM data # \\donttest{ plot(predict(ndmm_fit, type = \"survival\")) + geom_km(ndmm_net) #> Error in eval(expr, envir, enclos): object 'ndmm_fit' not found # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":null,"dir":"Reference","previous_headings":"","what":"Direct and indirect evidence — get_nodesplits","title":"Direct and indirect evidence — get_nodesplits","text":"Determine whether two treatments network connected direct /indirect evidence, generate list comparisons direct indirect evidence (.e. potential inconsistency) node-splitting.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Direct and indirect evidence — get_nodesplits","text":"","code":"get_nodesplits(network, include_consistency = FALSE)  has_direct(network, trt1, trt2)  has_indirect(network, trt1, trt2)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Direct and indirect evidence — get_nodesplits","text":"network nma_data object, created functions set_*() combine_network(). include_consistency Logical, whether include row NAs indicate consistency model (.e. model node-splitting) also fitted nma() function. Default FALSE calling get_nodesplits() hand, nma() sets TRUE default. trt1, trt2 Treatments, single integer, string, factor","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Direct and indirect evidence — get_nodesplits","text":"has_direct() has_indirect(), single logical value. get_nodesplits(), data frame two columns giving comparisons node-splitting.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Direct and indirect evidence — get_nodesplits","text":"list comparisons node-splitting generated following algorithm van Valkenhoef et al. (2016) . comparison two treatments potential inconsistency, thus considered node-splitting, comparison direct evidence independent indirect evidence. notion independent indirect evidence necessary multi-arm trials present, since design trials internally consistent. comparison two treatments independent indirect evidence , removing studies comparing two treatments network, two treatments still connected path evidence. criterion considered has_indirect() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Direct and indirect evidence — get_nodesplits","text":"van Valkenhoef G, Dias S, Ades AE, Welton NJ (2016). “Automated generation node-splitting models assessment inconsistency network meta-analysis.” Research Synthesis Methods, 7(1), 80--93. doi:10.1002/jrsm.1167 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Direct and indirect evidence — get_nodesplits","text":"","code":"# Parkinsons example park_net <- set_agd_arm(parkinsons,                         study = studyn,                         trt = trtn,                         y = y,                         se = se,                         trt_ref = 1) #> Note: Optional argument `sample_size` not provided, some features may not be available (see ?set_agd_arm).  # View the network plot plot(park_net)   # The 4 vs. 5 comparison is a spur on the network has_direct(park_net, 4, 5) #> [1] TRUE has_indirect(park_net, 4, 5) #> [1] FALSE  # 1 and 5 are not directly connected has_direct(park_net, 1, 5) #> [1] FALSE has_indirect(park_net, 1, 5) #> [1] TRUE  # The 1 vs. 2 comparison does not have independent indirect evidence, since # the 1-2-4 loop is a multi-arm study has_indirect(park_net, 1, 2) #> [1] FALSE  # Get a list of comparisons with potential inconsistency for node-splitting get_nodesplits(park_net) #> # A tibble: 4 × 2 #>   trt1  trt2  #>   <fct> <fct> #> 1 1     3     #> 2 1     4     #> 3 2     4     #> 4 3     4      # See van Valkenhoef (2016) for a discussion of this example"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert networks to graph objects — as.igraph.nma_data","title":"Convert networks to graph objects — as.igraph.nma_data","text":"method .igraph() converts nma_data objects form used igraph package. method as_tbl_graph() converts nma_data objects form used ggraph tidygraph packages.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert networks to graph objects — as.igraph.nma_data","text":"","code":"# S3 method for nma_data as.igraph(x, ..., collapse = TRUE)  # S3 method for nma_data as_tbl_graph(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert networks to graph objects — as.igraph.nma_data","text":"x nma_data object convert ... Additional arguments collapse Logical, collapse edges studies? Default TRUE, one edge produced comparison (IPD AgD study type) .nstudy attribute giving number studies making comparison. FALSE, repeated edges added study making comparison.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert networks to graph objects — as.igraph.nma_data","text":"igraph object .igraph(), tbl_graph object as_tbl_graph().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert networks to graph objects — as.igraph.nma_data","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # Convert to igraph object igraph::as.igraph(smk_net)  # Edges combined by default #> IGRAPH 0ef4c7a UN-- 4 6 --  #> + attr: name (v/c), .sample_size (v/n), .nstudy (e/n), .type (e/c) #> + edges from 0ef4c7a (vertex names): #> [1] No intervention       --Group counselling      #> [2] No intervention       --Individual counselling #> [3] Group counselling     --Individual counselling #> [4] No intervention       --Self-help              #> [5] Group counselling     --Self-help              #> [6] Individual counselling--Self-help              igraph::as.igraph(smk_net, collapse = FALSE)  # Without combining edges #> IGRAPH 832c532 UN-- 4 28 --  #> + attr: name (v/c), .sample_size (v/n), .study (e/c), .type (e/c) #> + edges from 832c532 (vertex names): #>  [1] No intervention       --Group counselling      #>  [2] No intervention       --Individual counselling #>  [3] Group counselling     --Individual counselling #>  [4] Group counselling     --Individual counselling #>  [5] Group counselling     --Self-help              #>  [6] Individual counselling--Self-help              #>  [7] No intervention       --Individual counselling #>  [8] No intervention       --Individual counselling #> + ... omitted several edges  # Convert to tbl_graph object tidygraph::as_tbl_graph(smk_net)  # Edges combined by default #> # A tbl_graph: 4 nodes and 6 edges #> # #> # An undirected simple graph with 1 component #> # #> # A tibble: 4 × 2 #>   name                   .sample_size #>   <chr>                         <dbl> #> 1 No intervention                7231 #> 2 Group counselling               555 #> 3 Individual counselling         7383 #> 4 Self-help                      1571 #> # #> # A tibble: 6 × 4 #>    from    to .nstudy .type #>   <int> <int>   <int> <chr> #> 1     1     2       2 AgD   #> 2     1     3      15 AgD   #> 3     2     3       4 AgD   #> # ℹ 3 more rows tidygraph::as_tbl_graph(smk_net, collapse = FALSE)  # Without combining edges #> # A tbl_graph: 4 nodes and 28 edges #> # #> # An undirected multigraph with 1 component #> # #> # A tibble: 4 × 2 #>   name                   .sample_size #>   <chr>                         <dbl> #> 1 No intervention                7231 #> 2 Group counselling               555 #> 3 Individual counselling         7383 #> 4 Self-help                      1571 #> # #> # A tibble: 28 × 4 #>    from    to .study .type #>   <int> <int> <chr>  <chr> #> 1     1     2 1      AgD   #> 2     1     3 1      AgD   #> 3     2     3 1      AgD   #> # ℹ 25 more rows"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":null,"dir":"Reference","previous_headings":"","what":"HTA Plaque Psoriasis — hta_psoriasis","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"Data frame containing results 16 trials comparing 8 treatments moderate--severe plaque psoriasis HTA report (Woolacott et al. 2006) , analysed TSD2 (Dias et al. 2011) . Outcomes success/failure achieve 50%, 75%, 90% reduction symptoms Psoriasis Area Severity Index (PASI) scale. studies report three ordered outcomes, others one two. latter coded missing values (see details).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"","code":"hta_psoriasis"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"data frame 36 rows 9 variables: studyn numeric study ID studyc study name year year publication trtn numeric treatment code trtc treatment name sample_size sample size arm PASI50, PASI75, PASI90 ordered multinomial outcome counts (exclusive, see details)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"Outcome counts \"exclusive\"; , study reporting outcomes, counts represent categories 50 < PASI < 75, 75 < PASI < 90, 90 < PASI < 100, named lower end interval. (opposed \"inclusive\" counts, represent overlapping categories PASI > 50, PASI > 70, PASI > 90.) count fourth category (lowest), 0 < PASI < 50, equal sample_size - PASI50 - PASI75 - PASI90. Missing values used studies report subset outcomes. study reporting two outcomes, say 50 75, counts represent 50 < PASI < 75 75 < PASI < 100. study reporting one outcome, say PASI 75, count represents 75 < PASI < 100.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Woolacott N, Hawkins N, Mason , Kainth , Khadjesari Z, Bravo Vergel Y, Misso K, Light K, Chalmers R, Sculpher M, Riemsma R (2006). “Etanercept efalizumab treatment psoriasis: systematic review.” Health Technology Assessment, 10(46). doi:10.3310/hta10460 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":null,"dir":"Reference","previous_headings":"","what":"Check network connectedness — is_network_connected","title":"Check network connectedness — is_network_connected","text":"Check whether network connected - whether path study evidence linking every pair treatments network.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check network connectedness — is_network_connected","text":"","code":"is_network_connected(network)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check network connectedness — is_network_connected","text":"network nma_data object, created functions set_*() combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check network connectedness — is_network_connected","text":"Logical TRUE FALSE","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check network connectedness — is_network_connected","text":"Models still run disconnected networks. However, estimated relative effects treatments across disconnected parts network entirely based prior distribution (typically uncertain), information update prior distribution. Relative effects within connected sub-network estimated sub-network analysed separately.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check network connectedness — is_network_connected","text":"","code":"## Smoking cessation # Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  is_network_connected(smk_net)  # TRUE, network is connected #> [1] TRUE ## A disconnected network disc_net <- set_agd_arm(smoking[smoking$studyn %in% c(15, 21), ],                         study = studyn,                         trt = trtc,                         r = r,                         n = n) is_network_connected(disc_net)  # FALSE, network is disconnected #> [1] FALSE disc_net #> A network with 2 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                         #>  15    2: Group counselling | No intervention #>  21    2: Individual counselling | Self-help  #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 2 #> Reference treatment is: Group counselling #> Network is disconnected plot(disc_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Student's t distribution — dlogt","title":"Log Student's t distribution — dlogt","text":"Density, distribution, quantile function log t distribution, whose logarithm degrees freedom df, mean location, standard deviation scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Student's t distribution — dlogt","text":"","code":"dlogt(x, df, location = 0, scale = 1)  plogt(q, df, location = 0, scale = 1)  qlogt(p, df, location = 0, scale = 1)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Student's t distribution — dlogt","text":"x, q Vector quantiles df Degrees freedom, greater zero location Location parameter scale Scale parameter, greater zero p Vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Student's t distribution — dlogt","text":"dlogt() gives density, plogt() gives distribution function, qlogt() gives quantile function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log Student's t distribution — dlogt","text":"\\(\\log(Y) \\sim t_\\nu(\\mu, \\sigma^2)\\), \\(Y\\) log t distribution location \\(\\mu\\), scale \\(\\sigma\\), df \\(\\nu\\). mean higher moments log t distribution undefined infinite. df = 1 distribution log Cauchy distribution. df tends infinity, approaches log Normal distribution.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":null,"dir":"Reference","previous_headings":"","what":"The logit Normal distribution — qlogitnorm","title":"The logit Normal distribution — qlogitnorm","text":"provide convenient extensions [dpq]logitnorm functions package logitnorm, allow distribution specified terms mean standard deviation, instead logit-mean logit-sd.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The logit Normal distribution — qlogitnorm","text":"","code":"qlogitnorm(p, mu = 0, sigma = 1, ..., mean, sd)  dlogitnorm(x, mu = 0, sigma = 1, ..., mean, sd)  plogitnorm(q, mu = 0, sigma = 1, ..., mean, sd)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The logit Normal distribution — qlogitnorm","text":"p, x vector quantiles mu, sigma, ... see logitnorm mean, sd mean standard deviation, overriding mu sigma specified q vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":null,"dir":"Reference","previous_headings":"","what":"Model comparison using the loo package — loo.stan_nma","title":"Model comparison using the loo package — loo.stan_nma","text":"loo() waic() functions loo package may called directly stan_nma stan_mlnmr objects.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model comparison using the loo package — loo.stan_nma","text":"","code":"# S3 method for stan_nma loo(x, ...)  # S3 method for stan_nma waic(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model comparison using the loo package — loo.stan_nma","text":"x object class stan_nma stan_mlnmr ... arguments loo() waic()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Working with 3D MCMC arrays — mcmc_array-class","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"3D MCMC arrays (Iterations, Chains, Parameters) produced .array() methods applied stan_nma nma_summary objects.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"","code":"# S3 method for mcmc_array summary(object, ..., probs = c(0.025, 0.25, 0.5, 0.75, 0.975))  # S3 method for mcmc_array print(x, ...)  # S3 method for mcmc_array names(x)  # S3 method for mcmc_array names(x) <- value"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"... arguments passed methods probs Numeric vector quantiles interest x, object 3D MCMC array class mcmc_array value Character vector replacement parameter names","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"summary() method returns nma_summary object, print() method returns x invisibly. names() method returns character vector parameter names, names()<- returns object updated parameter names.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Working with arrays of posterior draws (as mcmc_array objects) is # convenient when transforming parameters  # Transforming log odds ratios to odds ratios LOR_array <- as.array(relative_effects(smk_fit_RE)) OR_array <- exp(LOR_array)  # mcmc_array objects can be summarised to produce a nma_summary object smk_OR_RE <- summary(OR_array)  # This can then be printed or plotted smk_OR_RE #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling]      3.28 1.62 1.28 2.21 2.94 3.91  7.48     1983     2631 #> d[Individual counselling] 2.37 0.58 1.45 1.99 2.30 2.66  3.69     1279     1721 #> d[Self-help]              1.76 0.76 0.75 1.26 1.62 2.07  3.73     2167     2566 #>                           Rhat #> d[Group counselling]         1 #> d[Individual counselling]    1 #> d[Self-help]                 1 plot(smk_OR_RE, ref_line = 1)   # Transforming heterogeneity SD to variance tau_array <- as.array(smk_fit_RE, pars = \"tau\") tausq_array <- tau_array^2  # Correct parameter names names(tausq_array) <- \"tausq\"  # Summarise summary(tausq_array) #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq 0.75 0.35 0.29 0.51 0.67 0.91  1.63     1154     2195    1 # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":null,"dir":"Reference","previous_headings":"","what":"Distribution functions for M-spline baseline hazards — dmspline","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"Density, distribution, quantile, hazard, cumulative hazard, restricted mean survival time functions M-spline baseline hazards model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"","code":"dmspline(x, basis, scoef, rate, log = FALSE)  pmspline(q, basis, scoef, rate, lower.tail = TRUE, log.p = FALSE)  qmspline(p, basis, scoef, rate, lower.tail = TRUE, log.p = FALSE)  hmspline(x, basis, scoef, rate, log = FALSE)  Hmspline(x, basis, scoef, rate, log = FALSE)  rmst_mspline(t, basis, scoef, rate, start = 0)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"x, q Vector quantiles basis M-spline basis produced splines2::mSpline() scoef Vector (matrix) spline coefficients length (number columns) equal dimension basis rate Vector rate parameters log, log.p Logical; TRUE, probabilities p given \\(\\log(p)\\) lower.tail Logical; TRUE (default), probabilities \\(P(X \\le x)\\), otherwise \\(P(X > x)\\) p Vector probabilities t Vector times restricted mean survival time calculated start Optional left-truncation time times. returned restricted mean survival conditioned survival time","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"dmspline() gives density, pmspline() gives distribution function (CDF), qmspline() gives quantile function (inverse-CDF), hmspline() gives hazard function, Hmspline() gives cumulative hazard function, rmst_mspline() gives restricted mean survival times.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"Survival models flexible M-spline baseline hazard described Brilleman et al. (2020) . Piecewise-exponential baseline hazards special case degree M-spline polynomial 0. d/p/h/H functions calculated definitions. qmspline() uses numerical inversion via flexsurv::qgeneric(). rmst_mspline()uses numerical integration via flexsurv::rmst_generic(), except special case piecewise-exponential hazard (.e. degree 0 M-splines) uses explicit formula Royston Parmar (2013) . Beyond boundary knots, hazard assumed constant. (differs approach splines2::mSpline() extrapolates polynomial basis functions, numerically unstable highly dependent data just boundary knots.) extrapolation, care taken evaluating splines times beyond boundary knots (either directly d/p/h/H/rmst functions, indirectly requesting quantiles qmspline() correspond times beyond boundary knots). reason evaluating (unrestricted) mean survival time generally recommended requires integrating infinite time horizon (.e. rmst_mspline() t = Inf).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"Brilleman SL, Elci EM, Novik JB, Wolfe R (2020). “Bayesian Survival Analysis Using rstanarm R Package.” arXiv. doi:10.48550/arXiv.2002.09633 , 2002.09633. Royston P, Parmar MKB (2013). “Restricted mean survival time: alternative hazard ratio design analysis randomized trials time--event outcome.” BMC Medical Research Methodology, 13(1). doi:10.1186/1471-2288-13-152 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial outcome data — multi","title":"Multinomial outcome data — multi","text":"function aids specification multinomial outcome data setting network set_agd_arm() set_ipd(). takes set columns (, generally, numeric vectors length) outcome counts category, binds together produce matrix.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multinomial outcome data — multi","text":"","code":"multi(..., inclusive = FALSE, type = c(\"ordered\", \"competing\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multinomial outcome data — multi","text":"... Two numeric columns (vectors) category counts. Argument names (optional) used label categories. inclusive Logical, ordered category counts inclusive (TRUE) exclusive (FALSE)? Default FALSE. used type = \"ordered\". See details. type String, indicating whether categories \"ordered\" \"competing\". Currently ordered categorical outcomes supported modelling functions package.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multinomial outcome data — multi","text":"matrix (exclusive) category counts","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multinomial outcome data — multi","text":"specifying ordered categorical counts, can either given exclusive counts (inclusive = FALSE, default) individuals counted highest category achieve, inclusive counts (inclusive = TRUE) individuals counted every category including highest category achieved. (Competing outcomes, nature, always specified exclusive counts.) NA values can used indicate categories/cutpoints measured.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multinomial outcome data — multi","text":"","code":"# These two data sets specify the same ordered categorical data for outcomes # r0 < r1 < r2, but the first uses the \"inclusive\" format and the second the # \"exclusive\" format. df_inclusive <- tibble::tribble(~r0, ~r1, ~r2,                                 1, 1, 1,                                 5, 4, 1,                                 5, 2, 2,                                 10, 5, 0,                                 5, 5, 0,                                 7, NA, 6,   # Achieved r2 or not (no r1)                                 10, 4, NA)  # Achieved r1 or not (no r2)  df_exclusive <- tibble::tribble(~r0, ~r1, ~r2,                                 0, 0, 1,                                 1, 3, 1,                                 3, 0, 2,                                 5, 5, 0,                                 0, 5, 0,                                 1, NA, 6,   # Achieved r2 or not (no r1)                                 6, 4, NA)   # Achieved r1 or not (no r2)  (r_inclusive <- with(df_inclusive, multi(r0, r1, r2, inclusive = TRUE))) #>      r0 r1 r2 #> [1,]  0  0  1 #> [2,]  1  3  1 #> [3,]  3  0  2 #> [4,]  5  5  0 #> [5,]  0  5  0 #> [6,]  1 NA  6 #> [7,]  6  4 NA #> attr(,\"class\") #> [1] \"multi_ordered\" \"matrix\"        \"array\"         (r_exclusive <- with(df_exclusive, multi(r0, r1, r2, inclusive = FALSE))) #>      r0 r1 r2 #> [1,]  0  0  1 #> [2,]  1  3  1 #> [3,]  3  0  2 #> [4,]  5  5  0 #> [5,]  0  5  0 #> [6,]  1 NA  6 #> [7,]  6  4 NA #> attr(,\"class\") #> [1] \"multi_ordered\" \"matrix\"        \"array\"          # Counts are always stored in exclusive format stopifnot(isTRUE(all.equal(r_inclusive, r_exclusive)))   ## HTA Plaque Psoriasis library(dplyr)  # Ordered outcomes here are given as \"exclusive\" counts head(hta_psoriasis) #>   studyn   studyc year trtn             trtc sample_size PASI50 PASI75 PASI90 #> 1      1  Elewski 2004    1  Supportive care         193     12      5      1 #> 2      1  Elewski 2004    2 Etanercept 25 mg         196     59     46     21 #> 3      1  Elewski 2004    3 Etanercept 50 mg         194     54     56     40 #> 4      2 Gottlieb 2003    1  Supportive care          55      5      1      0 #> 5      2 Gottlieb 2003    2 Etanercept 25 mg          57     23     11      6 #> 6      3  Lebwohl 2003    1  Supportive care         122     13      5      1  # Calculate lowest category count (failure to achieve PASI 50) pso_dat <- hta_psoriasis %>%   mutate(`PASI<50` = sample_size - rowSums(cbind(PASI50, PASI75, PASI90), na.rm = TRUE))  # Set up network pso_net <- set_agd_arm(pso_dat,                        study = paste(studyc, year),                        trt = trtc,                        r = multi(`PASI<50`, PASI50, PASI75, PASI90,                                  inclusive = FALSE,                                  type = \"ordered\"))  pso_net #> A network with 16 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                           #>  ACD2058g 2004 2: Supportive care | Efalizumab                          #>  ACD2600g 2004 2: Supportive care | Efalizumab                          #>  Altmeyer 1994 2: Supportive care | Fumaderm                            #>  Chaudari 2001 2: Supportive care | Infliximab                          #>  Elewski 2004  3: Supportive care | Etanercept 25 mg | Etanercept 50 mg #>  Ellis 1991    3: Supportive care | Ciclosporin | Ciclosporin           #>  Gordon 2003   2: Supportive care | Efalizumab                          #>  Gottlieb 2003 2: Supportive care | Etanercept 25 mg                    #>  Gottlieb 2004 3: Supportive care | Infliximab | Infliximab             #>  Guenther 1991 2: Supportive care | Ciclosporin                         #>  ... plus 6 more studies #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 8 #> Total number of studies: 16 #> Reference treatment is: Supportive care #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":null,"dir":"Reference","previous_headings":"","what":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"R package performing network meta-analysis network meta-regression aggregate data, individual patient data, mixtures .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"Network meta-analysis (NMA) combines (aggregate) data multiple studies multiple treatments order produce consistent estimates relative treatment effects pair treatments network (Dias et al. 2011) . Network meta-regression (NMR) extends NMA include covariates, allowing adjustment differences effect-modifying variables studies (Dias et al. 2011) . NMR typically performed using aggregate data (AgD), lacks power prone ecological bias. NMR individual patient data (IPD) gold standard, data available. Multilevel network meta-regression (ML-NMR) allows IPD AgD incorporated together network meta-regression (Phillippo et al. 2020; Phillippo 2019) . IPD NMR, individual-level regression model defined. AgD studies fitted integrating individual-level model respective covariate distributions. correctly links two levels model (instead \"plugging \" mean covariate values), avoiding aggregation bias. Population-adjusted treatment effects (Phillippo et al. 2016)  can produced study population network, external target population. Models estimated Bayesian framework using Stan (Carpenter et al. 2017) . Quasi-Monte Carlo numerical integration based Sobol' sequences used integration ML-NMR models, Gaussian copula account correlations covariates (Phillippo et al. 2020; Phillippo 2019) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"getting-started","dir":"Reference","previous_headings":"","what":"Getting Started","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"good place start package vignettes walk example analyses, see vignette(\"vignette_overview\") overview. series NICE Technical Support Documents evidence synthesis gives detailed introduction network meta-analysis: Dias S, Welton NJ, Sutton AJ, Caldwell DM, Lu G, Reken S, Ades AE (2011). “NICE DSU Technical Support Documents 1-7: Evidence Synthesis Decision Making.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Multilevel network meta-regression set following methods paper: Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"Carpenter B, Gelman , Hoffman MD, Lee D, Goodrich B, Betancourt M, Brubaker M, Guo J, Li P, Riddell (2017). “Stan: Probabilistic Programming Language.” Journal Statistical Software, 76(1). doi:10.18637/jss.v076.i01 . Dias S, Sutton AJ, Welton NJ, Ades AE (2011). “NICE DSU Technical Support Document 3: Heterogeneity: subgroups, meta-regression, bias bias-adjustment.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Phillippo DM (2019). Calibration Treatment Effects Network Meta-Analysis using Individual Patient Data. Ph.D. thesis, University Bristol. Available https://research-information.bris.ac.uk/. Phillippo DM, Ades AE, Dias S, Palmer S, Abrams KR, Welton NJ (2016). “NICE DSU Technical Support Document 18: Methods population-adjusted indirect comparisons submission NICE.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Newly diagnosed multiple myeloma — ndmm_ipd","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"Three data frames, ndmm_ipd, ndmm_agd, ndmm_agd_covs containing (simulated) individual patient data (IPD) three studies aggregate data (AgD) two studies newly diagnosed multiple myeloma. outcome interest progression-free survival autologous stem cell transplant. IPD studies ndmm_ipd provide event/censoring times covariate values individual. AgD studies provide reconstructed event/censoring times digitized Kaplan-Meier curves ndmm_agd covariate summaries ndmm_agd_covs, obtained published trial reports. data constructed resemble used Leahy Walsh (2019) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"","code":"ndmm_ipd  ndmm_agd  ndmm_agd_covs"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"individual patient data contained data frame ndmm_ipd 1325 rows, one per individual, 10 variables: study, studyf study name trt, trtf treatment name eventtime event/censoring time status censoring indicator (0 = censored, 1 = event) age age (years) iss_stage3 ISS stage 3 (0 = , 1 = yes) response_cr_vgpr complete good partial response (0 = , 1 = yes) male male sex (0 = , 1 = yes) reconstructed Kaplan-Meier data aggregate studies contained data frame ndmm_agd 2819 rows 6 variables: study, studyf study name trt, trtf treatment name eventtime event/censoring time status censoring indicator (0 = censored, 1 = event) covariate summaries extracted published reportes aggregate studies contained data frame ndmm_agd_covs 4 rows, one per study arm, 15 columns: study, studyf study name trt, trtf treatment name sample_size sample size arm age_min, age_iqr_l, age_median, age_iqr_h, age_max, age_mean, age_sd summary statistics age (years) iss_stage3 proportion participants ISS stage 3 response_cr_vgpr proportion participants complete good partial response male proportion male participants","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"Leahy J, Walsh C (2019). “Assessing impact matching-adjusted indirect comparison Bayesian network meta-analysis.” Research Synthesis Methods, 10(4), 546--568. doi:10.1002/jrsm.1372 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Network meta-analysis models — nma","title":"Network meta-analysis models — nma","text":"nma function fits network meta-analysis (multilevel) network meta-regression models Stan.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Network meta-analysis models — nma","text":"","code":"nma(   network,   consistency = c(\"consistency\", \"ume\", \"nodesplit\"),   trt_effects = c(\"fixed\", \"random\"),   regression = NULL,   class_interactions = c(\"common\", \"exchangeable\", \"independent\"),   likelihood = NULL,   link = NULL,   ...,   nodesplit = get_nodesplits(network, include_consistency = TRUE),   prior_intercept = .default(normal(scale = 100)),   prior_trt = .default(normal(scale = 10)),   prior_het = .default(half_normal(scale = 5)),   prior_het_type = c(\"sd\", \"var\", \"prec\"),   prior_reg = .default(normal(scale = 10)),   prior_aux = .default(),   prior_aux_reg = .default(),   aux_by = NULL,   aux_regression = NULL,   QR = FALSE,   center = TRUE,   adapt_delta = NULL,   int_thin = 0,   int_check = TRUE,   mspline_degree = 3,   n_knots = 7,   knots = NULL,   mspline_basis = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Network meta-analysis models — nma","text":"network nma_data object, created functions set_*(), combine_network(), add_integration() consistency Character string specifying type ()consistency model fit, either \"consistency\", \"ume\", \"nodesplit\" trt_effects Character string specifying either \"fixed\" \"random\" effects regression one-sided model formula, specifying prognostic effect-modifying terms regression model. references treatment use .trt special variable, example specifying effect modifier interactions variable:.trt (see details). class_interactions Character string specifying whether effect modifier interactions specified \"common\", \"exchangeable\", \"independent\". likelihood Character string specifying likelihood, unspecified inferred data (see details) link Character string specifying link function, unspecified default canonical link (see details) ... arguments passed sampling(), iter, chains, cores, etc. nodesplit consistency = \"nodesplit\", comparison(s) split node-splitting model(s). Either length 2 vector giving treatments single comparison, 2 column data frame listing multiple treatment comparisons split turn. default, possible comparisons chosen (see get_nodesplits()). prior_intercept Specification prior distribution intercept prior_trt Specification prior distribution treatment effects prior_het Specification prior distribution heterogeneity (trt_effects = \"random\") prior_het_type Character string specifying whether prior distribution prior_het placed heterogeneity standard deviation \\(\\tau\\) (\"sd\", default), variance \\(\\tau^2\\) (\"var\"), precision \\(1/\\tau^2\\) (\"prec\"). prior_reg Specification prior distribution regression coefficients (regression formula specified) prior_aux Specification prior distribution auxiliary parameter, applicable (see details). likelihood = \"gengamma\" list prior distributions elements sigma k. prior_aux_reg Specification prior distribution auxiliary regression parameters, aux_regression specified (see details). aux_by Vector variable names listing variables stratify auxiliary parameters . Currently used survival models, see details. used aux_regression. aux_regression one-sided model formula giving regression model auxiliary parameters. Currently used survival models, see details. used aux_by. QR Logical scalar (default FALSE), whether apply QR decomposition model design matrix center Logical scalar (default TRUE), whether center (numeric) regression terms overall means adapt_delta See adapt_delta details int_thin single integer value, thinning factor returning cumulative estimates integration error. Saving cumulative estimates disabled int_thin = 0, default. int_check Logical, check sufficient accuracy numerical integration fitting half chains n_int/2? TRUE, Rhat n_eff diagnostic warnings given numerical integration sufficiently converged (suggesting increasing n_int add_integration()). Default TRUE, disabled (FALSE) int_thin > 0. mspline_degree Non-negative integer giving degree M-spline polynomial likelihood = \"mspline\". Piecewise exponential hazards (likelihood = \"pexp\") special case mspline_degree = 0. n_knots mspline pexp likelihoods, non-negative integer giving number internal knots partitioning baseline hazard intervals. knot locations within study determined corresponding quantiles observed event times, plus boundary knots earliest entry time (0 delayed entry) maximum event/censoring time. example, n_knots = 3, internal knot locations 25%, 50%, 75% quantiles observed event times. default n_knots = 7; overfitting avoided shrinking towards constant hazard random walk prior (see details). aux_regression specified single set knot locations calculated across studies network. Ignored knots specified. knots mspline pexp likelihoods, named list numeric vectors internal knot locations studies network. Currently, vector must length (.e. study must use number knots). unspecified (default), knots chosen based n_knots described . aux_regression specified knots single numeric vector knot locations shared across studies network. mspline_basis Instead specifying mspline_degree n_knots knots, named list M-spline bases (one study) can provided mspline_basis used directly. case, M-spline options ignored.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Network meta-analysis models — nma","text":"nma() returns stan_nma object, except consistency = \"nodesplit\" nma_nodesplit nma_nodesplit_df object returned. nma.fit() returns stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Network meta-analysis models — nma","text":"specifying model formula regression argument, usual formula syntax available (interpreted model.matrix()). additional requirement special variable .trt used refer treatment. example, effect modifier interactions specified variable:.trt. Prognostic (main) effects interactions can included together compactly variable*.trt, expands variable + variable:.trt (plus .trt, already NMA model). advanced user, additional specials .study .trtclass also available, refer studies (specified) treatment classes respectively. node-splitting models fitted (consistency = \"nodesplit\") special .omega available, indicating arms node-splitting inconsistency factor added. See ?priors details prior specification. Default prior distributions available, may appropriate particular setting raise warning used. attempt made tailor defaults data provided. Please consider appropriate prior distributions particular setting, accounting scales outcomes covariates, etc. function plot_prior_posterior() may useful examining influence chosen prior distributions posterior distributions, summary() method nma_prior objects prints prior intervals.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"likelihoods-and-link-functions","dir":"Reference","previous_headings":"","what":"Likelihoods and link functions","title":"Network meta-analysis models — nma","text":"Currently, following likelihoods link functions supported data type: bernoulli2 binomial2 likelihoods correspond two-parameter Binomial likelihood arm-based AgD, closely matches underlying Poisson Binomial distribution summarised aggregate outcomes ML-NMR model typical (one parameter) Binomial distribution (see Phillippo et al. 2020) . cloglog link used, including offset log follow-time (.e. regression = ~offset(log(time))) results model log hazard (see Dias et al. 2011) . survival data, accelerated failure time models (exponential-aft, weibull-aft, lognormal, loglogistic, gamma, gengamma) parameterised treatment effects regression parameters log Survival Time Ratios (.e. coefficient \\(\\log(2)\\) means treatment covariate associated doubling expected survival time). can converted log Acceleration Factors using relation \\(\\log(\\mathrm{AF}) = -\\log(\\mathrm{STR})\\) (equivalently \\(\\mathrm{AF} = 1/\\mathrm{STR}\\)). details likelihood link function given Dias et al. (2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"auxiliary-parameters","dir":"Reference","previous_headings":"","what":"Auxiliary parameters","title":"Network meta-analysis models — nma","text":"Auxiliary parameters present following models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"normal-likelihood-with-ipd","dir":"Reference","previous_headings":"","what":"Normal likelihood with IPD","title":"Network meta-analysis models — nma","text":"Normal likelihood fitted IPD, auxiliary parameters arm-level standard deviations \\(\\sigma_{jk}\\) treatment \\(k\\) study \\(j\\).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"ordered-multinomial-likelihood","dir":"Reference","previous_headings":"","what":"Ordered multinomial likelihood","title":"Network meta-analysis models — nma","text":"fitting model \\(M\\) ordered outcomes, auxiliary parameters latent cutoffs category, \\(c_0 < c_1 < \\dots <   c_M\\). \\(c_2\\) \\(c_{M-1}\\) estimated; fix \\(c_0 =   -\\infty\\), \\(c_1 = 0\\), \\(c_M = \\infty\\). specifying priors latent cutoffs, choose specify priors differences \\(c_{m+1} - c_m\\). Stan automatically truncates priors ordering constraints satisfied.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"survival-time-to-event-likelihoods","dir":"Reference","previous_headings":"","what":"Survival (time-to-event) likelihoods","title":"Network meta-analysis models — nma","text":"survival likelihoods except exponential exponential-aft likelihoods auxiliary parameters. typically study-specific shape parameters \\(\\gamma_j>0\\), except lognormal likelihood auxiliary parameters study-specific standard deviations log scale \\(\\sigma_j>0\\). gengamma likelihood two sets auxiliary parameters, study-specific scale parameters \\(\\sigma_j>0\\) shape parameters \\(k_j\\), following parameterisation Lawless (1980) , permits range behaviours baseline hazard including increasing, decreasing, bathtub arc-shaped hazards. parameterisation related discussed Cox et al. (2007)  implemented flexsurv package \\(Q = k^{-0.5}\\). parameterisation used effectively bounds shape parameter \\(k\\) away numerical instabilities \\(k \\rightarrow \\infty\\) (.e. away \\(Q   \\rightarrow 0\\), log-Normal distribution) via prior distribution. Implicitly, parameterisation restricted \\(Q > 0\\) certain survival distributions like inverse-Gamma inverse-Weibull part parameter space; however, \\(Q > 0\\) still encompasses survival distributions implemented package. mspline pexp likelihoods, auxiliary parameters spline coefficients study. form unit simplex (.e. lie 0 1, sum 1), given random walk prior distribution. prior_aux specifies hyperprior random walk standard deviation \\(\\sigma\\) controls level smoothing baseline hazard, \\(\\sigma = 0\\) corresponding constant baseline hazard. auxiliary parameters can stratified additional factors aux_by argument. example, allow shape baseline hazard vary treatment arms well studies, use aux_by = c(\".study\", \".trt\"). (Technically, .study always included stratification even omitted aux_by, choose make stratification explicit.) common way relaxing proportional hazards assumption. default equivalent aux_by = \".study\" stratifies auxiliary parameters study, described . regression model may specified auxiliary parameters using aux_regression. useful wish model departures non-proportionality, rather allowing baseline hazards completely independent using aux_by. necessary absolute predictions (e.g. survival curves) required population unobserved combinations covariates; example, aux_by = .trt absolute predictions may produced observed treatment arms study population, whereas aux_regression = ~.trt absolute predictions can produced treatments population. mspline pexp likelihoods, regression coefficients smoothed time using random walk prior avoid overfitting: prior_aux_reg specifies hyperprior random walk standard deviation. parametric likelihoods, prior_aux_reg specifies prior auxiliary regression coefficients.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Network meta-analysis models — nma","text":"Cox C, Chu H, Schneider MF, Mu~noz (2007). “Parametric survival analysis taxonomy hazard functions generalized gamma distribution.” Statistics Medicine, 26(23), 4352--4374. doi:10.1002/sim.2836 . Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Lawless JF (1980). “Inference Generalized Gamma Log Gamma Distributions.” Technometrics, 22(3), 409--419. doi:10.1080/00401706.1980.10486173 . Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Network meta-analysis models — nma","text":"","code":"## Smoking cessation NMA # Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting a fixed effect model smk_fit_FE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100))  smk_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          0.84    0.00 0.18     0.49     0.72     0.85 #> d[Individual counselling]     0.77    0.00 0.06     0.65     0.73     0.77 #> d[Self-help]                  0.23    0.00 0.13    -0.03     0.14     0.23 #> lp__                      -6008.29    0.08 3.65 -6016.22 -6010.48 -6007.97 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          0.96     1.18  2031    1 #> d[Individual counselling]     0.81     0.89  1753    1 #> d[Self-help]                  0.31     0.47  2477    1 #> lp__                      -6005.75 -6002.11  1877    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:21:35 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\donttest{ # Fitting a random effects model smk_fit_RE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = normal(scale = 5))  smk_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          1.10    0.01 0.43     0.24     0.82     1.09 #> d[Individual counselling]     0.84    0.01 0.23     0.38     0.69     0.84 #> d[Self-help]                  0.51    0.01 0.40    -0.26     0.23     0.51 #> lp__                      -5920.03    0.21 6.58 -5933.67 -5924.50 -5919.68 #> tau                           0.83    0.01 0.19     0.54     0.70     0.81 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          1.37     1.98  2103 1.00 #> d[Individual counselling]     0.99     1.31  1197 1.01 #> d[Self-help]                  0.77     1.32  1748 1.00 #> lp__                      -5915.39 -5907.86  1015 1.00 #> tau                           0.94     1.26  1298 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:21:47 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\donttest{ # Fitting an unrelated mean effects (inconsistency) model smk_fit_RE_UME <- nma(smk_net, refresh = if (interactive()) 200 else 0,                       consistency = \"ume\",                       trt_effects = \"random\",                       prior_intercept = normal(scale = 100),                       prior_trt = normal(scale = 100),                       prior_het = normal(scale = 5))  smk_fit_RE_UME #> A random effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                     mean se_mean   sd     2.5% #> d[Group counselling vs. No intervention]            1.13    0.02 0.79    -0.36 #> d[Individual counselling vs. No intervention]       0.90    0.01 0.27     0.41 #> d[Self-help vs. No intervention]                    0.34    0.01 0.58    -0.79 #> d[Individual counselling vs. Group counselling]    -0.29    0.01 0.59    -1.40 #> d[Self-help vs. Group counselling]                 -0.66    0.01 0.71    -2.09 #> d[Self-help vs. Individual counselling]             0.16    0.02 1.04    -1.86 #> lp__                                            -5933.58    0.20 6.38 -5946.70 #> tau                                                 0.93    0.01 0.21     0.59 #>                                                      25%      50%      75% #> d[Group counselling vs. No intervention]            0.59     1.12     1.62 #> d[Individual counselling vs. No intervention]       0.73     0.89     1.07 #> d[Self-help vs. No intervention]                   -0.04     0.34     0.70 #> d[Individual counselling vs. Group counselling]    -0.70    -0.31     0.09 #> d[Self-help vs. Group counselling]                 -1.11    -0.65    -0.20 #> d[Self-help vs. Individual counselling]            -0.52     0.15     0.83 #> lp__                                            -5937.76 -5933.13 -5929.13 #> tau                                                 0.78     0.90     1.05 #>                                                    97.5% n_eff Rhat #> d[Group counselling vs. No intervention]            2.78  2582 1.00 #> d[Individual counselling vs. No intervention]       1.45  1067 1.00 #> d[Self-help vs. No intervention]                    1.55  1753 1.00 #> d[Individual counselling vs. Group counselling]     0.91  2627 1.00 #> d[Self-help vs. Group counselling]                  0.75  2645 1.00 #> d[Self-help vs. Individual counselling]             2.18  4172 1.00 #> lp__                                            -5921.84  1048 1.00 #> tau                                                 1.41  1082 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:22:00 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\donttest{ # Fitting all possible node-splitting models smk_fit_RE_nodesplit <- nma(smk_net, refresh = if (interactive()) 200 else 0,                             consistency = \"nodesplit\",                             trt_effects = \"random\",                             prior_intercept = normal(scale = 100),                             prior_trt = normal(scale = 100),                             prior_het = normal(scale = 5)) #> Fitting model 1 of 7, node-split: Group counselling vs. No intervention #> Fitting model 2 of 7, node-split: Individual counselling vs. No intervention #> Fitting model 3 of 7, node-split: Self-help vs. No intervention #> Fitting model 4 of 7, node-split: Individual counselling vs. Group counselling #> Fitting model 5 of 7, node-split: Self-help vs. Group counselling #> Fitting model 6 of 7, node-split: Self-help vs. Individual counselling #> Fitting model 7 of 7, consistency model # }  # \\donttest{ # Summarise the node-splitting results summary(smk_fit_RE_nodesplit) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.10 0.44  0.26  0.81  1.08 1.38  2.02     1991     2299    1 #> d_dir            1.05 0.74 -0.31  0.57  1.03 1.52  2.55     3298     2479    1 #> d_ind            1.14 0.56  0.05  0.78  1.13 1.49  2.26     1506     1740    1 #> omega           -0.08 0.90 -1.80 -0.65 -0.10 0.48  1.64     2439     2515    1 #> tau              0.86 0.20  0.55  0.73  0.83 0.97  1.34     1180     2024    1 #> tau_consistency  0.84 0.18  0.55  0.71  0.82 0.94  1.25     1324     1977    1 #>  #> Residual deviance: 54.9 (on 50 data points) #>                pD: 44.8 #>               DIC: 99.7 #>  #> Bayesian p-value: 0.91 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.84 0.24  0.41  0.68 0.84 0.99  1.33     1179     1661    1 #> d_dir           0.88 0.25  0.41  0.71 0.87 1.03  1.38     1751     2285    1 #> d_ind           0.57 0.68 -0.73  0.13 0.54 1.00  1.93     1494     2080    1 #> omega           0.31 0.70 -1.09 -0.16 0.32 0.77  1.68     1472     1772    1 #> tau             0.86 0.19  0.56  0.72 0.84 0.98  1.30     1208     1651    1 #> tau_consistency 0.84 0.18  0.55  0.71 0.82 0.94  1.25     1324     1977    1 #>  #> Residual deviance: 54 (on 50 data points) #>                pD: 44 #>               DIC: 98 #>  #> Bayesian p-value: 0.64 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.49 0.40 -0.28  0.23  0.48 0.74  1.31     1900     2357    1 #> d_dir            0.32 0.55 -0.76 -0.04  0.31 0.66  1.43     2979     2574    1 #> d_ind            0.72 0.64 -0.53  0.29  0.70 1.13  2.01     1790     2306    1 #> omega           -0.40 0.85 -2.14 -0.94 -0.38 0.16  1.22     1944     1936    1 #> tau              0.87 0.20  0.57  0.73  0.84 0.98  1.34     1096     1738    1 #> tau_consistency  0.84 0.18  0.55  0.71  0.82 0.94  1.25     1324     1977    1 #>  #> Residual deviance: 54 (on 50 data points) #>                pD: 44.5 #>               DIC: 98.4 #>  #> Bayesian p-value: 0.64 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.26 0.41 -1.11 -0.53 -0.25  0.02  0.54     2579     2347    1 #> d_dir           -0.11 0.48 -1.05 -0.43 -0.11  0.21  0.86     4055     3165    1 #> d_ind           -0.54 0.61 -1.82 -0.93 -0.52 -0.14  0.64     1490     2115    1 #> omega            0.43 0.67 -0.91  0.00  0.44  0.88  1.77     1479     1967    1 #> tau              0.85 0.19  0.55  0.72  0.83  0.96  1.30     1277     1929    1 #> tau_consistency  0.84 0.18  0.55  0.71  0.82  0.94  1.25     1324     1977    1 #>  #> Residual deviance: 54.2 (on 50 data points) #>                pD: 44.4 #>               DIC: 98.6 #>  #> Bayesian p-value: 0.5 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.61 0.49 -1.60 -0.93 -0.60 -0.29  0.34     2901     2833 1.00 #> d_dir           -0.61 0.65 -1.91 -1.04 -0.59 -0.18  0.67     4111     2929 1.00 #> d_ind           -0.65 0.67 -1.97 -1.07 -0.64 -0.21  0.62     2052     2067 1.00 #> omega            0.04 0.88 -1.63 -0.54  0.01  0.60  1.84     2149     2439 1.00 #> tau              0.88 0.21  0.57  0.73  0.85  0.99  1.36     1173     1993 1.01 #> tau_consistency  0.84 0.18  0.55  0.71  0.82  0.94  1.25     1324     1977 1.00 #>  #> Residual deviance: 53.8 (on 50 data points) #>                pD: 44.2 #>               DIC: 98 #>  #> Bayesian p-value: 0.99 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.36 0.41 -1.15 -0.61 -0.35 -0.10  0.44     2275     2489    1 #> d_dir            0.07 0.67 -1.29 -0.36  0.06  0.50  1.40     3098     2655    1 #> d_ind           -0.63 0.54 -1.76 -0.97 -0.62 -0.29  0.42     1876     2188    1 #> omega            0.70 0.85 -0.99  0.14  0.69  1.23  2.47     1995     2187    1 #> tau              0.86 0.21  0.54  0.72  0.83  0.97  1.32     1083     1380    1 #> tau_consistency  0.84 0.18  0.55  0.71  0.82  0.94  1.25     1324     1977    1 #>  #> Residual deviance: 53.7 (on 50 data points) #>                pD: 44 #>               DIC: 97.8 #>  #> Bayesian p-value: 0.4 # }  ## Plaque psoriasis ML-NMR # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.  # \\donttest{ # Fitting a ML-NMR model. # Specify a regression model to include effect modifier interactions for five # covariates, along with main (prognostic) effects. We use a probit link and # specify that the two-parameter Binomial approximation for the aggregate-level # likelihood should be used. We set treatment-covariate interactions to be equal # within each class. We narrow the possible range for random initial values with # init_r = 0.1, since probit models in particular are often hard to initialise. # Using the QR decomposition greatly improves sampling efficiency here, as is # often the case for regression models. pso_fit <- nma(pso_net, refresh = if (interactive()) 200 else 0,                trt_effects = \"fixed\",                link = \"probit\",                likelihood = \"bernoulli2\",                regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                class_interactions = \"common\",                prior_intercept = normal(scale = 10),                prior_trt = normal(scale = 10),                prior_reg = normal(scale = 10),                init_r = 0.1,                QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25% #> beta[durnpso]                           0.04    0.00 0.06    -0.08     0.00 #> beta[prevsys]                          -0.14    0.00 0.16    -0.44    -0.24 #> beta[bsa]                              -0.07    0.01 0.44    -1.00    -0.36 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02 #> beta[psa]                              -0.08    0.00 0.17    -0.42    -0.19 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.14    -0.06 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.18    -0.17     0.07 #> beta[prevsys:.trtclassIL blocker]       0.06    0.00 0.17    -0.27    -0.06 #> beta[bsa:.trtclassTNFa blocker]         0.06    0.01 0.52    -0.93    -0.29 #> beta[bsa:.trtclassIL blocker]           0.29    0.01 0.49    -0.64    -0.05 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.03    -0.24    -0.19 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12 #> beta[psa:.trtclassTNFa blocker]        -0.06    0.00 0.21    -0.48    -0.20 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.19    -0.35    -0.12 #> d[ETN]                                  1.55    0.00 0.08     1.40     1.50 #> d[IXE_Q2W]                              2.95    0.00 0.09     2.79     2.89 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.39     2.49 #> d[SEC_150]                              2.15    0.00 0.12     1.92     2.07 #> d[SEC_300]                              2.45    0.00 0.12     2.22     2.37 #> lp__                                -1653.65    0.09 3.56 -1661.40 -1655.79 #>                                          50%      75%    97.5% n_eff Rhat #> beta[durnpso]                           0.04     0.09     0.16  5940    1 #> beta[prevsys]                          -0.14    -0.03     0.17  5461    1 #> beta[bsa]                              -0.06     0.23     0.75  5448    1 #> beta[weight]                            0.04     0.06     0.10  5671    1 #> beta[psa]                              -0.07     0.04     0.24  5144    1 #> beta[durnpso:.trtclassTNFa blocker]    -0.03     0.02     0.12  6072    1 #> beta[durnpso:.trtclassIL blocker]      -0.01     0.03     0.12  6969    1 #> beta[prevsys:.trtclassTNFa blocker]     0.19     0.31     0.54  5249    1 #> beta[prevsys:.trtclassIL blocker]       0.06     0.18     0.40  6469    1 #> beta[bsa:.trtclassTNFa blocker]         0.05     0.40     1.09  6195    1 #> beta[bsa:.trtclassIL blocker]           0.28     0.61     1.27  7162    1 #> beta[weight:.trtclassTNFa blocker]     -0.17    -0.14    -0.10  6095    1 #> beta[weight:.trtclassIL blocker]       -0.10    -0.08    -0.04  6446    1 #> beta[psa:.trtclassTNFa blocker]        -0.06     0.09     0.36  5825    1 #> beta[psa:.trtclassIL blocker]           0.01     0.13     0.38  6109    1 #> d[ETN]                                  1.55     1.61     1.71  4239    1 #> d[IXE_Q2W]                              2.95     3.01     3.12  4800    1 #> d[IXE_Q4W]                              2.54     2.59     2.70  5544    1 #> d[SEC_150]                              2.15     2.22     2.38  4956    1 #> d[SEC_300]                              2.45     2.53     2.69  5411    1 #> lp__                                -1653.30 -1651.11 -1647.79  1494    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:24:24 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  ## Newly-diagnosed multiple myeloma NMA # Set up newly-diagnosed multiple myeloma network  head(ndmm_ipd) #>          study trt       studyf trtf      age iss_stage3 response_cr_vgpr male #> 1 McCarthy2012 Pbo McCarthy2012  Pbo 50.81625          0                1    0 #> 2 McCarthy2012 Pbo McCarthy2012  Pbo 62.18165          0                0    0 #> 3 McCarthy2012 Pbo McCarthy2012  Pbo 51.53762          1                1    1 #> 4 McCarthy2012 Pbo McCarthy2012  Pbo 46.74128          0                1    1 #> 5 McCarthy2012 Pbo McCarthy2012  Pbo 62.62561          0                1    1 #> 6 McCarthy2012 Pbo McCarthy2012  Pbo 49.24520          1                1    0 #>   eventtime status #> 1 31.106516      1 #> 2  3.299623      0 #> 3 57.400000      0 #> 4 57.400000      0 #> 5 57.400000      0 #> 6 30.714460      0 head(ndmm_agd) #>        study     studyf trt trtf eventtime status #> 1 Morgan2012 Morgan2012 Pbo  Pbo  18.72575      1 #> 2 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 3 Morgan2012 Morgan2012 Pbo  Pbo  34.35726      1 #> 4 Morgan2012 Morgan2012 Pbo  Pbo  10.77826      1 #> 5 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 6 Morgan2012 Morgan2012 Pbo  Pbo  14.52966      1  ndmm_net <- combine_network(   set_ipd(ndmm_ipd,           study, trt,           Surv = Surv(eventtime / 12, status)),   set_agd_surv(ndmm_agd,                study, trt,                Surv = Surv(eventtime / 12, status),                covariates = ndmm_agd_covs)) # \\donttest{ # Fit Weibull (PH) model ndmm_fit <- nma(ndmm_net, refresh = if (interactive()) 200 else 0,                 likelihood = \"weibull\",                 prior_intercept = normal(scale = 100),                 prior_trt = normal(scale = 10),                 prior_aux = half_normal(scale = 10)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit #> A fixed effects NMA with a weibull likelihood (log link). #> Inference for Stan model: survival_param. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75% #> d[Len]                 -0.54    0.00 0.04    -0.63    -0.57    -0.54    -0.51 #> d[Thal]                -0.11    0.00 0.09    -0.28    -0.17    -0.11    -0.05 #> lp__                -6280.16    0.06 2.44 -6285.76 -6281.57 -6279.83 -6278.39 #> shape[Attal2012]        1.30    0.00 0.06     1.18     1.25     1.30     1.34 #> shape[Jackson2019]      0.93    0.00 0.02     0.89     0.92     0.93     0.95 #> shape[McCarthy2012]     1.29    0.00 0.07     1.17     1.25     1.29     1.34 #> shape[Morgan2012]       0.88    0.00 0.03     0.82     0.86     0.88     0.90 #> shape[Palumbo2014]      1.02    0.00 0.07     0.88     0.97     1.01     1.06 #>                        97.5% n_eff Rhat #> d[Len]                 -0.45  6122    1 #> d[Thal]                 0.06  5072    1 #> lp__                -6276.32  1769    1 #> shape[Attal2012]        1.42  5217    1 #> shape[Jackson2019]      0.98  4605    1 #> shape[McCarthy2012]     1.43  4892    1 #> shape[Morgan2012]       0.94  5711    1 #> shape[Palumbo2014]      1.16  4957    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:26:59 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_data-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_data class — nma_data-class","title":"The nma_data class — nma_data-class","text":"nma_data class contains data NMA standard format, created using functions set_ipd(), set_agd_arm(), set_agd_contrast(), set_agd_surv(), combine_network(). sub-class mlnmr_data created function add_integration(), contains numerical integration points aggregate data.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_data-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_data class — nma_data-class","text":"Objects class nma_data following components: agd_arm data studies aggregate data (arm format) agd_contrast data studies aggregate data (contrast format) ipd data studies individual patient data treatments treatment coding factor entire network classes treatment class coding factor (length treatments entire network) studies study coding factor entire network outcome outcome type data source, named list agd_arm, agd_contrast, ipd components tibbles following columns: .study study (factor) .trt treatment (factor) .trtclass treatment class (factor), specified .y continuous outcome .se standard error (continuous) .r event count (discrete) .n event count denominator (discrete, agd_arm ) .E time risk (discrete) .Surv survival outcome type Surv (time--event), nested study arm .sample_size sample size (agd_* ) ... columns (typically covariates) original data frame Objects class mlnmr_data additionally components: n_int number numerical integration points int_names names covariates numerical integration points int_cor correlation matrix covariates used generate numerical integration points agd_arm agd_contrast tibbles additional list columns prefix .int_, one covariate, contain numerical integration points nested length-n_int vectors within row.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_dic-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_dic class — nma_dic-class","title":"The nma_dic class — nma_dic-class","text":"nma_dic class contains details Deviance Information Criterion (DIC), produced using dic() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_dic-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_dic class — nma_dic-class","text":"Objects class nma_dic following components: dic DIC value pd, pv effective number parameters resdev total residual deviance pointwise list data frames containing pointwise contributions IPD AgD. resdev_array 3D MCMC array [Iterations, Chains, Parameters] posterior residual deviance samples.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_nodesplit-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_nodesplit class — nma_nodesplit-class","title":"The nma_nodesplit class — nma_nodesplit-class","text":"nma_nodesplit nma_nodesplit_df classes contains results running node-splitting model function nma().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_nodesplit-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_nodesplit class — nma_nodesplit-class","text":"Objects class nma_nodesplit inherit stan_nma class, contain results fitting single node-split model. one additional component, nodesplit, gives comparison node-split length 2 vector. Objects class nma_nodesplit_df tibble data frames one row node-split comparison columns: trt1, trt2 Treatments forming comparison model list column containing results model nma_nodesplit object Optionally, additional row consistency model fitted (e.g. get_nodesplits(., include_consistency = TRUE)) trt1 trt2 NA.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_prior-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_prior class — nma_prior-class","title":"The nma_prior class — nma_prior-class","text":"nma_prior class used specify prior distributions.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_prior-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_prior class — nma_prior-class","text":"Objects class nma_prior following components: dist Distribution name fun Name constructor function, string (e.g. \"normal\") ... Parameters distribution distribution parameters, specified named components ..., match constructor functions (see priors).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_summary class — nma_summary-class","title":"The nma_summary class — nma_summary-class","text":"nma_summary class contains posterior summary statistics model parameters quantities interest, draws used obtain statistics.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_summary class — nma_summary-class","text":"Objects class nma_summary following components: summary data frame containing computed summary statistics. Column .trt indicates corresponding treatment, columns .trta .trtb indicate corresponding contrast (.trtb vs. .trta). regression model fitted effect modifier interactions treatment, summaries study-specific. case, corresponding study population indicated .study column. multinomial model fitted, .category column indicates corresponding category. sims 3D array [Iteration, Chain, Parameter] MCMC simulations studies (Optional) data frame containing study information, printed along corresponding summary statistics summary contains .study column. matching .study column. following attributes may also set: xlab Label x axis plots, usually either \"Treatment\" \"Contrast\". ylab Label y axis plots, usually used scale e.g. \"log Odds Ratio\". subclass nma_rank_probs used function posterior_rank_probs(), contains posterior rank probabilities. subclass sims component, rank probabilities posterior summaries ranks (.e. posterior distribution). posterior ranks rank probabilities calculated may obtained posterior_ranks().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for nma_summary objects — print.nma_summary","title":"Methods for nma_summary objects — print.nma_summary","text":".data.frame(), as_tibble(), .tibble() methods return posterior summary statistics data frame tibble. .matrix() method returns matrix posterior draws. .array() method returns 3D array [Iteration, Chain, Parameter] posterior draws (class mcmc_array).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for nma_summary objects — print.nma_summary","text":"","code":"# S3 method for nma_summary print(x, ..., digits = 2, pars, include = TRUE)  # S3 method for nma_summary as.data.frame(x, ...)  # S3 method for nma_summary as.tibble(x, ...)  # S3 method for nma_summary as_tibble(x, ...)  # S3 method for nma_summary as.array(x, ...)  # S3 method for nma_summary as.matrix(x, ...)  # S3 method for nma_rank_probs as.array(x, ...)  # S3 method for nma_rank_probs as.matrix(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for nma_summary objects — print.nma_summary","text":"x nma_summary object ... Additional arguments passed methods digits Integer number digits display pars Character vector parameters display printed summary include Logical, parameters named pars included (TRUE) excluded (FALSE)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for nma_summary objects — print.nma_summary","text":"data.frame .data.frame(), tbl_df .tibble() as_tibble(), matrix .matrix(), mcmc_array .array(). print() method returns x invisibly.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nodesplit_summary class — nodesplit_summary-class","title":"The nodesplit_summary class — nodesplit_summary-class","text":"nodesplit_summary class contains posterior summary statistics node-splitting models, result calling summary() nma_nodesplit nma_nodesplit_df object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nodesplit_summary class — nodesplit_summary-class","text":"Objects class nodesplit_summary tibble data frames, one row node-split comparison columns: trt1, trt2 Treatments forming comparison summary list column containing nma_summary objects posterior summaries draws node-splitting parameters p_value Bayesian p-value inconsistency dic list column containing nma_dic objects, giving model fit statistics parameters included summary : d_net Network estimate corresponding consistency model, available d_dir Direct estimate node-splitting model d_ind Indirect estimate node-splitting model omega Inconsistency factor \\(\\omega = d_\\mathrm{dir} -   d_\\mathrm{ind}\\) tau Heterogeneity standard deviation node-splitting model, random effects model fitted tau_consistency Heterogeneity standard deviation corresponding consistency model, available random effects model fitted","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for nodesplit_summary objects — print.nodesplit_summary","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":".data.frame(), as_tibble(), .tibble() methods return node-splitting summaries data frame tibble.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"","code":"# S3 method for nodesplit_summary print(x, ..., digits = 2)  # S3 method for nodesplit_summary as_tibble(x, ..., nest = FALSE)  as.tibble.nodesplit_summary(x, ..., nest = FALSE)  # S3 method for nodesplit_summary as.data.frame(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"x nodesplit_summary object ... Additional arguments passed methods digits Integer number digits display nest Whether return nested tibble, full nma_summary nma_dic objects, unnest summaries, default FALSE","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"data.frame .data.frame(), tbl_df .tibble() as_tibble(). print() method returns x invisibly.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix of plots for a stan_nma object — pairs.stan_nma","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"pairs() method stan_nma objects, calls bayesplot::mcmc_pairs() underlying stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"","code":"# S3 method for stan_nma pairs(x, ..., pars, include = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"x object class stan_nma ... arguments passed bayesplot::mcmc_pairs() pars Optional character vector parameter names include output. specified, parameters used. include Logical, parameters pars included (TRUE, default) excluded (FALSE)?","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"grid ggplot objects produced bayesplot::mcmc_pairs().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"","code":"if (FALSE) { ## Parkinson's mean off time reduction park_net <- set_agd_arm(parkinsons,                         study = studyn,                         trt = trtn,                         y = y,                         se = se,                         sample_size = n)  # Fitting a RE model park_fit_RE <- nma(park_net,                    trt_effects = \"random\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_het = half_normal(scale = 5))  # We see a small number of divergent transition errors # These do not go away entirely when adapt_delta is increased  # Try to diagnose with a pairs plot pairs(park_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\"))  # Transforming tau onto log scale pairs(park_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\"),       transformations = list(tau = \"log\"))  # The divergent transitions occur in the upper tail of the heterogeneity # standard deviation. In this case, with only a small number of studies, there # is not very much information to estimate the heterogeneity standard deviation # and the prior distribution may be too heavy-tailed. We could consider a more # informative prior distribution for the heterogeneity variance to aid # estimation. }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean off-time reduction in Parkison's disease — parkinsons","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"Data frame containing mean -time reduction patients given dopamine agonists adjunct therapy Parkinson's disease, 7 trials comparing four active drugs placebo (Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"","code":"parkinsons"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"data frame 15 rows 7 variables: studyn numeric study ID trtn numeric treatment code (placebo = 1) y mean -time reduction se standard error n sample size diff mean difference vs. treatment reference arm se_diff standard error mean difference, see details","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"dataset may analysed using either arm-based likelihood using y se, contrast-based likelihood using diff se_diff (combination two across different studies). contrast-based data formatted described set_agd_contrast(). , chosen reference arm study, mean difference diff set NA, se_diff set standard error se outcome reference arm.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":null,"dir":"Reference","previous_headings":"","what":"Plaque psoriasis data — plaque_psoriasis_ipd","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"Two data frames, plaque_psoriasis_ipd plaque_psoriasis_agd, containing (simulated) individual patient data four studies aggregate data five studies (Phillippo 2019) . Outcomes binary success/failure achieve 75%, 90%, 100% reduction symptoms Psoriasis Area Severity Index (PASI) scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"","code":"plaque_psoriasis_ipd  plaque_psoriasis_agd"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"individual patient data contained data frame plaque_psoriasis_ipd 4118 rows, one per individual, 16 variables: studyc study name trtc_long treatment name (long format) trtc treatment name trtn numeric treatment code pasi75 binary PASI 75 outcome pasi90 binary PASI 90 outcome pasi100 binary PASI 100 outcome age age (years) bmi body mass index (BMI) pasi_w0 PASI score week 0 male male sex (TRUE FALSE) bsa body surface area (percent) weight weight (kilograms) durnpso duration psoriasis (years) prevsys previous systemic treatment (TRUE FALSE) psa psoriatic arthritis (TRUE FALSE) aggregate data contained data frame plaque_psoriasis_agd 15 rows, one per study arm, 26 variables: studyc study name trtc_long treatment name (long format) trtc treatment name trtn numeric treatment code pasi75_r, pasi75_n PASI 75 outcome count denominator pasi90_r, pasi90_n PASI 75 outcome count denominator pasi100_r, pasi100_n PASI 75 outcome count denominator sample_size_w0 sample size week zero age_mean, age_sd mean standard deviation age (years) bmi_mean, bmi_sd mean standard deviation BMI pasi_w0_mean, pasi_w0_sd mean standard deviation PASI score week 0 male percentage males bsa_mean, bsa_sd mean standard deviation body surface area (percent) weight_mean, weight_sd mean standard deviation weight (kilograms) durnpso_mean, durnpso_sd mean standard deviation duration psoriasis (years) prevsys percentage individuals previous systemic treatment psa percentage individuals psoriatic arthritis object class data.frame 15 rows 26 columns.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"Phillippo DM (2019). Calibration Treatment Effects Network Meta-Analysis using Individual Patient Data. Ph.D. thesis, University Bristol. Available https://research-information.bris.ac.uk/.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Network plots — plot.nma_data","title":"Network plots — plot.nma_data","text":"Create network plot nma_data network object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Network plots — plot.nma_data","text":"","code":"# S3 method for nma_data plot(   x,   ...,   layout,   circular,   weight_edges = TRUE,   weight_nodes = FALSE,   show_trt_class = FALSE,   nudge = 0 )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Network plots — plot.nma_data","text":"x nma_data object plot ... Additional arguments passed ggraph() layout function layout type layout create. layout accepted ggraph() may used, including layout functions provided igraph. circular Whether use circular representation. See ggraph(). weight_edges Weight edges number studies? Default TRUE. weight_nodes Weight nodes total sample size? Default FALSE. show_trt_class Colour treatment nodes class, trt_class set? Default FALSE. nudge Numeric value nudge treatment labels away nodes weight_nodes = TRUE. Default 0 (adjustment label position). small value like 0.1 usually sufficient.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Network plots — plot.nma_data","text":"ggplot object, produced ggraph().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Network plots — plot.nma_data","text":"default equivalent layout = \"linear\" circular = TRUE, places treatment nodes circle order defined treatment factor variable. alternative layout may give good results simple networks \"sugiyama\", attempts minimise number edge crossings. weight_nodes = TRUE requires sample sizes specified aggregate data network, using sample_size option set_agd_*().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Network plots — plot.nma_data","text":"","code":"## Stroke prevention in atrial fibrillation # Setting up the network af_net <- set_agd_arm(atrial_fibrillation,                       study = studyc,                       trt = abbreviate(trtc, minlength = 3),                       r = r,                       n = n,                       trt_class = trt_class) af_net #> A network with 26 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                #>  ACTIVE-W      2: Sada | Lda+c               #>  AFASAK 1      3: Sada | Lda | P/c           #>  AFASAK 2      4: Sada | Fdw | Fdw+mda | Mda #>  BAATAF        2: Lada | P/c                 #>  BAFTA         2: Sada | Lda                 #>  CAFA          2: Sada | P/c                 #>  Chinese ATAFS 2: Sada | Lda                 #>  EAFT          3: Sada | Mda | P/c           #>  ESPS 2        4: Dpy | Lda | Lda+d | P/c    #>  JAST          2: Lda | P/c                  #>  ... plus 16 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 17, in 4 classes #> Total number of studies: 26 #> Reference treatment is: Sada #> Network is connected  # Basic plot plot(af_net)   # Turn off weighting edges by number of studies plot(af_net, weight_edges = FALSE)   # Turn on weighting nodes by sample size plot(af_net, weight_nodes = TRUE)   # Colour treatment nodes by class plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE)   # Nudge the treatment labels away from the nodes plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE, nudge = 0.1)   # Output may be customised using standard ggplot commands # For example, to display the legends below the plot: plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE) +   ggplot2::theme(legend.position = \"bottom\",                  legend.box = \"vertical\",                  legend.margin = ggplot2::margin(0, 0, 0, 0),                  legend.spacing = ggplot2::unit(0.5, \"lines\"))   # Choosing a different ggraph layout, hiding some legends plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE,      layout = \"star\") +   ggplot2::guides(edge_width = \"none\", size = \"none\")"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of model fit diagnostics — plot.nma_dic","title":"Plots of model fit diagnostics — plot.nma_dic","text":"plot() method nma_dic objects produced dic() produces several useful diagnostic plots checking model fit model comparison. detail plots interpretation given Dias et al. (2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of model fit diagnostics — plot.nma_dic","text":"","code":"# S3 method for nma_dic plot(   x,   y,   ...,   show_uncertainty = TRUE,   stat = \"pointinterval\",   orientation = c(\"vertical\", \"horizontal\", \"x\", \"y\") )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of model fit diagnostics — plot.nma_dic","text":"x nma_dic object y (Optional) second nma_dic object, produce \"dev-dev\" plots model comparison. ... Additional arguments passed methods show_uncertainty Logical, show uncertainty ggdist plot stat? Default TRUE. stat Character string specifying ggdist plot stat use show_uncertainty = TRUE, default \"pointinterval\". y provided, currently \"pointinterval\" supported. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"). used residual deviance plots, default \"vertical\".","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of model fit diagnostics — plot.nma_dic","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of model fit diagnostics — plot.nma_dic","text":"single nma_dic object given, plot residual deviance contribution data point produced. good fitting model, data point expected residual deviance 1; larger values indicate data points fit poorly model. two nma_dic objects given, \"dev-dev\" plot comparing residual deviance contributions model produced. Data points residual deviance contributions lying line equality fit equally well either model. Data points lying line equality indicate better fit second model (y); conversely, data points lying line equality indicate better fit first model (x). common use case compare standard consistency model (fitted using nma() consistency = \"consistency\") unrelated mean effects (UME) inconsistency model (fitted using nma() consistency = \"ume\"), check potential inconsistency. See Dias et al. (2011)  details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plots of model fit diagnostics — plot.nma_dic","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of model fit diagnostics — plot.nma_dic","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking FE NMA example if not already available if (!exists(\"smk_fit_FE\")) example(\"example_smk_fe\", run.donttest = TRUE) # } # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC of FE and RE models (smk_dic_FE <- dic(smk_fit_FE)) #> Residual deviance: 267.2 (on 50 data points) #>                pD: 27.1 #>               DIC: 294.3 (smk_dic_RE <- dic(smk_fit_RE))   # substantially better fit #> Residual deviance: 54.3 (on 50 data points) #>                pD: 44.1 #>               DIC: 98.5  # Plot residual deviance contributions under RE model plot(smk_dic_RE)   # Further customisation is possible using ggplot commands # For example, highlighting data points with residual deviance above a certain threshold plot(smk_dic_RE) +   ggplot2::aes(colour = ggplot2::after_stat(ifelse(y > 1.5, \"darkorange\", \"black\"))) +   ggplot2::scale_colour_identity()   # Or by posterior probability, for example here a central probability of 0.6 # corresponds to a lower tail probability of (1 - 0.6)/2 = 0.2 plot(smk_dic_RE, .width = c(0.6, 0.95)) +   ggplot2::aes(colour = ggplot2::after_stat(ifelse(ymin > 1, \"darkorange\", \"black\"))) +   ggplot2::scale_colour_identity()   # Check for inconsistency using UME model # } # \\donttest{ # Run smoking UME NMA example if not already available if (!exists(\"smk_fit_RE_UME\")) example(\"example_smk_ume\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC smk_dic_RE #> Residual deviance: 54.3 (on 50 data points) #>                pD: 44.1 #>               DIC: 98.5 (smk_dic_RE_UME <- dic(smk_fit_RE_UME))  # no difference in fit #> Residual deviance: 53.7 (on 50 data points) #>                pD: 45 #>               DIC: 98.7  # Compare residual deviance contributions with a \"dev-dev\" plot plot(smk_dic_RE, smk_dic_RE_UME)   # By default the dev-dev plot can be a little cluttered # Hiding the credible intervals plot(smk_dic_RE, smk_dic_RE_UME, show_uncertainty = FALSE)   # Changing transparency plot(smk_dic_RE, smk_dic_RE_UME, point_alpha = 0.5, interval_alpha = 0.1)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of summary results — plot.nma_summary","title":"Plots of summary results — plot.nma_summary","text":"plot method nma_summary objects used produce plots parameter estimates (called stan_nma object summary), relative effects (called output relative_effects()), absolute predictions (called output predict.stan_nma()), posterior ranks rank probabilities (called output posterior_ranks() posterior_rank_probs()).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of summary results — plot.nma_summary","text":"","code":"# S3 method for nma_summary plot(   x,   ...,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )  # S3 method for nma_parameter_summary plot(   x,   ...,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )  # S3 method for nma_rank_probs plot(x, ...)  # S3 method for surv_nma_summary plot(x, ..., stat = \"lineribbon\")"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of summary results — plot.nma_summary","text":"x nma_summary object ... Additional arguments passed underlying ggdist plot stat, see Details stat Character string specifying ggdist plot stat use, default \"pointinterval\", except plotting estimated survival/hazard/cumulative hazard curves survival models default \"lineribbon\" orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\" ref_line Numeric vector positions reference lines, default reference lines drawn","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of summary results — plot.nma_summary","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of summary results — plot.nma_summary","text":"Plotting handled ggplot2 stats geoms provided ggdist package. result, output flexible. plotting stats provided ggdist may used, via argument stat. default uses ggdist::stat_pointinterval(), produce medians 95% Credible Intervals 66% inner bands. Additional arguments ... passed ggdist stat, customise output. example, produce means Credible Intervals, specify point_interval = \"mean_qi\". produce 80% Credible Interval inner band, specify .width = c(0, 0.8). Alternative stats can specified produce different summaries. example, specify stat = \"[half]eye\" produce (half) eye plots, stat = \"histinterval\" produce histograms intervals. full list options examples found ggdist vignette vignette(\"slabinterval\", package = \"ggdist\"). survival/hazard/cumulative hazard curves estimated survival models, default uses ggdist::stat_lineribbon() produces curves posterior medians 50%, 80%, 95% Credible Interval bands. , additional arguments ... passed ggdist stat. example, produce posterior means 95% Credible bands, specify point_interval = \"mean_qi\" .width = 0.95. ggplot object returned can modified usual ggplot2 functions add aesthetics, geoms, themes, etc.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of summary results — plot.nma_summary","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce relative effects smk_releff_RE <- relative_effects(smk_fit_RE) plot(smk_releff_RE, ref_line = 0)   # Customise plot options plot(smk_releff_RE, ref_line = 0, stat = \"halfeye\")   # Further customisation is possible with ggplot commands plot(smk_releff_RE, ref_line = 0, stat = \"halfeye\", slab_alpha = 0.6) +   ggplot2::aes(slab_fill = ggplot2::after_stat(ifelse(x < 0, \"darkred\", \"grey60\")))   # Produce posterior ranks smk_rank_RE <- posterior_ranks(smk_fit_RE, lower_better = FALSE) plot(smk_rank_RE)   # Produce rank probabilities smk_rankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE) plot(smk_rankprob_RE)   # Produce cumulative rank probabilities smk_cumrankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE,                                            cumulative = TRUE) plot(smk_cumrankprob_RE)   # Further customisation is possible with ggplot commands plot(smk_cumrankprob_RE) +   ggplot2::facet_null() +   ggplot2::aes(colour = Treatment)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of node-splitting models — plot.nodesplit_summary","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"Produce summary plots node-splitting models","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"","code":"# S3 method for nodesplit_summary plot(   x,   ...,   pars = \"d\",   stat = \"dens_overlay\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"x nodesplit_summary object. ... Additional arguments passed underlying ggdist plot stat, see Details. pars Character vector specifying parameters include plot, choices include \"d\" direct, indirect, network estimates relative effects, \"omega\" inconsistency factor, \"tau\" heterogeneity standard deviation random effects models. Default \"d\". stat Character string specifying ggdist plot stat use. default \"dens_overlay\" special case, producing overlaid density plot. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\". ref_line Numeric vector positions reference lines, default reference lines drawn.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"Plotting handled ggplot2 stats geoms provided ggdist package. result, output flexible. plotting stats provided ggdist may used, via argument stat. default \"dens_overlay\" special exception, uses ggplot2::geom_density(), plot overlaid densities. Additional arguments ... passed ggdist stat, customise output. Alternative stats can specified produce different summaries. example, specify stat = \"[half]eye\" produce (half) eye plots, stat = \"pointinterval\" produce point estimates credible intervals. full list options examples found ggdist vignette vignette(\"slabinterval\", package = \"ggdist\"). ggplot object returned can modified usual ggplot2 functions add aesthetics, geoms, themes, etc.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"","code":"# \\donttest{ # Run smoking node-splitting example if not already available if (!exists(\"smk_fit_RE_nodesplit\")) example(\"example_smk_nodesplit\", run.donttest = TRUE) # } # \\donttest{ # Summarise the node-splitting results (smk_nodesplit_summary <- summary(smk_fit_RE_nodesplit)) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.09 0.43  0.27  0.81  1.08 1.36  1.98     1817     2155    1 #> d_dir            1.08 0.77 -0.34  0.56  1.04 1.57  2.76     3665     2342    1 #> d_ind            1.13 0.55  0.09  0.77  1.11 1.48  2.21     1928     2360    1 #> omega           -0.04 0.91 -1.85 -0.65 -0.08 0.53  1.83     2544     2154    1 #> tau              0.87 0.21  0.55  0.72  0.84 0.98  1.34     1019     1538    1 #> tau_consistency  0.84 0.18  0.55  0.71  0.82 0.95  1.25     1440     2021    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.5 #>  #> Bayesian p-value: 0.92 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.84 0.23  0.39  0.68 0.83 0.98  1.33     1005     1385    1 #> d_dir           0.88 0.26  0.40  0.71 0.86 1.04  1.41     1842     2451    1 #> d_ind           0.59 0.67 -0.70  0.16 0.57 1.01  1.97     1554     2014    1 #> omega           0.28 0.70 -1.11 -0.14 0.30 0.74  1.59     1660     1866    1 #> tau             0.85 0.20  0.55  0.71 0.83 0.96  1.30      995     1603    1 #> tau_consistency 0.84 0.18  0.55  0.71 0.82 0.95  1.25     1440     2021    1 #>  #> Residual deviance: 54.6 (on 50 data points) #>                pD: 44.6 #>               DIC: 99.2 #>  #> Bayesian p-value: 0.65 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.48 0.40 -0.27  0.21  0.49 0.74  1.30     2095     2635    1 #> d_dir            0.34 0.54 -0.69  0.00  0.33 0.68  1.44     3060     2594    1 #> d_ind            0.69 0.63 -0.50  0.28  0.67 1.09  1.99     1943     2631    1 #> omega           -0.35 0.82 -1.95 -0.87 -0.36 0.18  1.29     1973     2374    1 #> tau              0.86 0.19  0.57  0.73  0.84 0.97  1.29     1370     2052    1 #> tau_consistency  0.84 0.18  0.55  0.71  0.82 0.95  1.25     1440     2021    1 #>  #> Residual deviance: 54.2 (on 50 data points) #>                pD: 44.6 #>               DIC: 98.8 #>  #> Bayesian p-value: 0.66 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.26 0.41 -1.08 -0.51 -0.25  0.00  0.52     2621     2732    1 #> d_dir           -0.12 0.48 -1.05 -0.43 -0.11  0.19  0.81     3552     3113    1 #> d_ind           -0.54 0.60 -1.75 -0.93 -0.54 -0.15  0.65     1674     1981    1 #> omega            0.42 0.67 -0.88  0.00  0.40  0.87  1.78     1676     1701    1 #> tau              0.86 0.19  0.56  0.73  0.84  0.97  1.30      905     1487    1 #> tau_consistency  0.84 0.18  0.55  0.71  0.82  0.95  1.25     1440     2021    1 #>  #> Residual deviance: 54.4 (on 50 data points) #>                pD: 44.6 #>               DIC: 99 #>  #> Bayesian p-value: 0.51 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.61 0.49 -1.57 -0.93 -0.60 -0.29  0.32     2840     2576    1 #> d_dir           -0.61 0.67 -1.96 -1.04 -0.60 -0.16  0.68     3880     3087    1 #> d_ind           -0.62 0.66 -2.00 -1.03 -0.60 -0.17  0.66     2114     2351    1 #> omega            0.01 0.87 -1.72 -0.56  0.01  0.55  1.80     2224     2511    1 #> tau              0.86 0.19  0.57  0.73  0.84  0.97  1.32     1038     1627    1 #> tau_consistency  0.84 0.18  0.55  0.71  0.82  0.95  1.25     1440     2021    1 #>  #> Residual deviance: 54 (on 50 data points) #>                pD: 44.2 #>               DIC: 98.2 #>  #> Bayesian p-value: 0.99 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.35 0.41 -1.15 -0.62 -0.36 -0.08  0.47     2343     2619 1.00 #> d_dir            0.07 0.65 -1.20 -0.34  0.06  0.49  1.38     3573     3185 1.00 #> d_ind           -0.61 0.53 -1.67 -0.95 -0.59 -0.26  0.40     1634     2009 1.00 #> omega            0.68 0.80 -0.85  0.15  0.67  1.18  2.27     1982     2413 1.00 #> tau              0.86 0.19  0.56  0.72  0.83  0.96  1.31     1195     1716 1.01 #> tau_consistency  0.84 0.18  0.55  0.71  0.82  0.95  1.25     1440     2021 1.00 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44 #>               DIC: 97.6 #>  #> Bayesian p-value: 0.38  # Plot the node-splitting results plot(smk_nodesplit_summary)   # Plot the inconsistency factors instead, change the plot stat to half-eye, # and add a reference line at 0 plot(smk_nodesplit_summary, pars = \"omega\", stat = \"halfeye\", ref_line = 0)   # Plot a comparison of the heterogeneity under the node-split models vs. # the consistency model plot(smk_nodesplit_summary, pars = \"tau\")  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot numerical integration error — plot_integration_error","title":"Plot numerical integration error — plot_integration_error","text":"ML-NMR models, plot estimated numerical integration error entire posterior distribution, number integration points increases. See (Phillippo et al. 2020; Phillippo 2019)  details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot numerical integration error — plot_integration_error","text":"","code":"plot_integration_error(   x,   ...,   stat = \"violin\",   orientation = c(\"vertical\", \"horizontal\", \"x\", \"y\"),   show_expected_rate = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot numerical integration error — plot_integration_error","text":"x object type stan_mlnmr ... Additional arguments passed ggdist plot stat. stat Character string specifying ggdist plot stat used summarise integration error posterior. Default \"violin\", equivalent \"eye\" cosmetic tweaks. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"vertical\" show_expected_rate Logical, show typical convergence rate \\(1/N\\)? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot numerical integration error — plot_integration_error","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot numerical integration error — plot_integration_error","text":"total number integration points set n_int argument add_integration(), intervals integration error estimated set int_thin argument nma(). typical convergence rate Quasi-Monte Carlo integration (used ) \\(1/N\\), default displayed plot output. integration error thinning interval \\(N_\\mathrm{thin}\\) estimated point posterior distribution subtracting final estimate (using n_int points) estimate using first \\(N_\\mathrm{thin}\\) points.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"note-for-survival-models","dir":"Reference","previous_headings":"","what":"Note for survival models","title":"Plot numerical integration error — plot_integration_error","text":"function supported survival/time--event models. save cumulative integration points efficiency reasons (time memory).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot numerical integration error — plot_integration_error","text":"","code":"## Plaque psoriasis ML-NMR # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.  # \\donttest{ # Fit the ML-NMR model pso_fit <- nma(pso_net, refresh = if (interactive()) 200 else 0,                trt_effects = \"fixed\",                link = \"probit\",                likelihood = \"bernoulli2\",                regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                class_interactions = \"common\",                prior_intercept = normal(scale = 10),                prior_trt = normal(scale = 10),                prior_reg = normal(scale = 10),                init_r = 0.1,                QR = TRUE,                # Set the thinning factor for saving the cumulative results                # (This also sets int_check = FALSE)                int_thin = 8) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25% #> beta[durnpso]                           0.04    0.00 0.06    -0.07     0.00 #> beta[prevsys]                          -0.14    0.00 0.16    -0.45    -0.24 #> beta[bsa]                              -0.06    0.01 0.45    -0.97    -0.36 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02 #> beta[psa]                              -0.08    0.00 0.17    -0.41    -0.19 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.08    -0.18    -0.08 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.15    -0.06 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.19    -0.18     0.06 #> beta[prevsys:.trtclassIL blocker]       0.07    0.00 0.17    -0.28    -0.05 #> beta[bsa:.trtclassTNFa blocker]         0.05    0.01 0.52    -0.97    -0.31 #> beta[bsa:.trtclassIL blocker]           0.29    0.01 0.50    -0.65    -0.05 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.19 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12 #> beta[psa:.trtclassTNFa blocker]        -0.06    0.00 0.20    -0.46    -0.19 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.18    -0.34    -0.11 #> d[ETN]                                  1.55    0.00 0.08     1.40     1.50 #> d[IXE_Q2W]                              2.95    0.00 0.09     2.79     2.89 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.39     2.49 #> d[SEC_150]                              2.14    0.00 0.12     1.92     2.07 #> d[SEC_300]                              2.45    0.00 0.12     2.21     2.37 #> lp__                                -1653.67    0.09 3.37 -1661.09 -1655.80 #>                                          50%      75%    97.5% n_eff Rhat #> beta[durnpso]                           0.04     0.09     0.16  5260    1 #> beta[prevsys]                          -0.14    -0.03     0.18  6026    1 #> beta[bsa]                              -0.06     0.24     0.78  5554    1 #> beta[weight]                            0.04     0.06     0.10  5249    1 #> beta[psa]                              -0.08     0.04     0.24  6402    1 #> beta[durnpso:.trtclassTNFa blocker]    -0.03     0.02     0.12  6022    1 #> beta[durnpso:.trtclassIL blocker]      -0.01     0.03     0.12  6576    1 #> beta[prevsys:.trtclassTNFa blocker]     0.19     0.32     0.56  6033    1 #> beta[prevsys:.trtclassIL blocker]       0.07     0.18     0.41  7532    1 #> beta[bsa:.trtclassTNFa blocker]         0.05     0.42     1.08  5729    1 #> beta[bsa:.trtclassIL blocker]           0.28     0.61     1.25  6801    1 #> beta[weight:.trtclassTNFa blocker]     -0.17    -0.14    -0.10  6450    1 #> beta[weight:.trtclassIL blocker]       -0.10    -0.08    -0.04  6755    1 #> beta[psa:.trtclassTNFa blocker]        -0.06     0.08     0.35  6233    1 #> beta[psa:.trtclassIL blocker]           0.01     0.12     0.37  6947    1 #> d[ETN]                                  1.55     1.61     1.71  3991    1 #> d[IXE_Q2W]                              2.95     3.01     3.13  5422    1 #> d[IXE_Q4W]                              2.54     2.59     2.71  4794    1 #> d[SEC_150]                              2.15     2.22     2.37  4511    1 #> d[SEC_300]                              2.45     2.53     2.69  5018    1 #> lp__                                -1653.38 -1651.29 -1647.77  1366    1 #>  #> Samples were drawn using NUTS(diag_e) at Fri Oct 13 12:28:57 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1).  # Plot numerical integration error plot_integration_error(pso_fit)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot prior vs posterior distribution — plot_prior_posterior","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"Produce plots comparing prior posterior distributions model parameters.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"","code":"plot_prior_posterior(   x,   ...,   prior = NULL,   post_args = list(),   prior_args = list(),   overlay = c(\"prior\", \"posterior\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"x stan_nma object ... Additional arguments passed methods prior Character vector selecting prior posterior distribution(s) plot. May include \"intercept\", \"trt\", \"het\", \"reg\", \"aux\", appropriate. post_args List arguments passed ggplot2::geom_histogram control plot output posterior distribution prior_args List arguments passed ggplot2::geom_path control plot output prior distribution. Additionally, n controls number points density curve evaluated (default 500), p_limits controls endpoints curve quantiles (default c(.001, .999)). overlay String, prior posterior shown top? Default \"prior\". ref_line Numeric vector positions reference lines, default reference lines drawn","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"Prior distributions displayed lines, posterior distributions displayed histograms.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"","code":"## Smoking cessation NMA # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Plot prior vs. posterior, by default all parameters are plotted plot_prior_posterior(smk_fit_RE)   # Plot prior vs. posterior for heterogeneity SD only plot_prior_posterior(smk_fit_RE, prior = \"het\")   # Customise plot plot_prior_posterior(smk_fit_RE, prior = \"het\",                      prior_args = list(colour = \"darkred\", size = 2),                      post_args = list(alpha = 0.6))  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":null,"dir":"Reference","previous_headings":"","what":"Treatment rankings and rank probabilities — posterior_ranks","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"Produce posterior treatment rankings rank probabilities fitted NMA model. meta-regression fitted effect modifier interactions treatment, differ study population.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"","code":"posterior_ranks(   x,   newdata = NULL,   study = NULL,   lower_better = TRUE,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   sucra = FALSE,   summary = TRUE )  posterior_rank_probs(   x,   newdata = NULL,   study = NULL,   lower_better = TRUE,   cumulative = FALSE,   sucra = FALSE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"x stan_nma object created nma() newdata used regression model fitted. data frame study details, one row per study, giving covariate values produce relative effects. Column names must match variables regression model. NULL, relative effects produced studies network. study Column newdata specifies study names, otherwise studies labelled row number. lower_better Logical, lower treatment effects better (TRUE; default) higher better (FALSE)? See details. probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) sucra Logical, calculate surface cumulative ranking curve (SUCRA) treatment? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE. cumulative Logical, return cumulative rank probabilities? Default FALSE, return posterior probabilities treatment given rank. TRUE, cumulative posterior rank probabilities returned treatment given rank better.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"function posterior_ranks() produces posterior rankings, distribution (e.g. mean/median rank 95% Credible Interval). function posterior_rank_probs() produces rank probabilities, give posterior probabilities ranked first, second, etc. treatments. argument lower_better specifies whether lower treatment effects higher treatment effects preferred. example, negative binary outcome lower (negative) log odds ratios preferred, lower_better = TRUE. Conversely, example, treatments aim increase rate positive outcome lower_better = FALSE.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce posterior ranks smk_rank_RE <- posterior_ranks(smk_fit_RE, lower_better = FALSE) smk_rank_RE #>                              mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[No intervention]        3.88 0.33    3   4   4   4     4     2457       NA #> rank[Group counselling]      1.38 0.63    1   1   1   2     3     2851     2955 #> rank[Individual counselling] 1.92 0.64    1   2   2   2     3     2469       NA #> rank[Self-help]              2.82 0.69    1   3   3   3     4     2720       NA #>                              Rhat #> rank[No intervention]           1 #> rank[Group counselling]         1 #> rank[Individual counselling]    1 #> rank[Self-help]                 1 plot(smk_rank_RE)   # Produce rank probabilities smk_rankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE) smk_rankprob_RE #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.11      0.88 #> d[Group counselling]           0.70      0.23      0.07      0.01 #> d[Individual counselling]      0.25      0.59      0.17      0.00 #> d[Self-help]                   0.05      0.18      0.65      0.11 plot(smk_rankprob_RE)   # Produce cumulative rank probabilities smk_cumrankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE,                                            cumulative = TRUE) smk_cumrankprob_RE #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.12         1 #> d[Group counselling]           0.70      0.93      0.99         1 #> d[Individual counselling]      0.25      0.83      1.00         1 #> d[Self-help]                   0.05      0.24      0.89         1 plot(smk_cumrankprob_RE)   # Further customisation is possible with ggplot commands plot(smk_cumrankprob_RE) +   ggplot2::facet_null() +   ggplot2::aes(colour = Treatment)  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Produce population-adjusted rankings for all study populations in # the network  # Ranks pso_rank <- posterior_ranks(pso_fit) pso_rank #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[FIXTURE: PBO]     1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[FIXTURE: ETN]     2.00 0.00    2   2   2   2     2       NA       NA   NA #> rank[FIXTURE: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[FIXTURE: IXE_Q4W] 4.78 0.42    4   5   5   5     5     4323       NA    1 #> rank[FIXTURE: SEC_150] 3.00 0.04    3   3   3   3     3     3163     3163    1 #> rank[FIXTURE: SEC_300] 4.22 0.42    4   4   4   4     5     4292       NA    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-1: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-1: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-1: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA #> rank[UNCOVER-1: IXE_Q4W] 4.78 0.42    4   5   5   5     5     4323       NA #> rank[UNCOVER-1: SEC_150] 3.00 0.04    3   3   3   3     3     3163     3163 #> rank[UNCOVER-1: SEC_300] 4.22 0.42    4   4   4   4     5     4292       NA #>                          Rhat #> rank[UNCOVER-1: PBO]       NA #> rank[UNCOVER-1: ETN]       NA #> rank[UNCOVER-1: IXE_Q2W]   NA #> rank[UNCOVER-1: IXE_Q4W]    1 #> rank[UNCOVER-1: SEC_150]    1 #> rank[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-2: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-2: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-2: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA #> rank[UNCOVER-2: IXE_Q4W] 4.78 0.42    4   5   5   5     5     4323       NA #> rank[UNCOVER-2: SEC_150] 3.00 0.04    3   3   3   3     3     3163     3163 #> rank[UNCOVER-2: SEC_300] 4.22 0.42    4   4   4   4     5     4292       NA #>                          Rhat #> rank[UNCOVER-2: PBO]       NA #> rank[UNCOVER-2: ETN]       NA #> rank[UNCOVER-2: IXE_Q2W]   NA #> rank[UNCOVER-2: IXE_Q4W]    1 #> rank[UNCOVER-2: SEC_150]    1 #> rank[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-3: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-3: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-3: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA #> rank[UNCOVER-3: IXE_Q4W] 4.78 0.42    4   5   5   5     5     4323       NA #> rank[UNCOVER-3: SEC_150] 3.00 0.04    3   3   3   3     3     3163     3163 #> rank[UNCOVER-3: SEC_300] 4.22 0.42    4   4   4   4     5     4292       NA #>                          Rhat #> rank[UNCOVER-3: PBO]       NA #> rank[UNCOVER-3: ETN]       NA #> rank[UNCOVER-3: IXE_Q2W]   NA #> rank[UNCOVER-3: IXE_Q4W]    1 #> rank[UNCOVER-3: SEC_150]    1 #> rank[UNCOVER-3: SEC_300]    1 #>  plot(pso_rank)   # Rank probabilities pso_rankprobs <- posterior_rank_probs(pso_fit) pso_rankprobs #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             1         0         0      0.00      0.00         0 #> d[FIXTURE: ETN]             0         1         0      0.00      0.00         0 #> d[FIXTURE: IXE_Q2W]         0         0         0      0.00      0.00         1 #> d[FIXTURE: IXE_Q4W]         0         0         0      0.22      0.78         0 #> d[FIXTURE: SEC_150]         0         0         1      0.00      0.00         0 #> d[FIXTURE: SEC_300]         0         0         0      0.78      0.22         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-1: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-1: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-1: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-1: IXE_Q4W]         0         0         0      0.22      0.78 #> d[UNCOVER-1: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-1: SEC_300]         0         0         0      0.78      0.22 #>                       p_rank[6] #> d[UNCOVER-1: PBO]             0 #> d[UNCOVER-1: ETN]             0 #> d[UNCOVER-1: IXE_Q2W]         1 #> d[UNCOVER-1: IXE_Q4W]         0 #> d[UNCOVER-1: SEC_150]         0 #> d[UNCOVER-1: SEC_300]         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-2: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-2: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-2: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-2: IXE_Q4W]         0         0         0      0.22      0.78 #> d[UNCOVER-2: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-2: SEC_300]         0         0         0      0.78      0.22 #>                       p_rank[6] #> d[UNCOVER-2: PBO]             0 #> d[UNCOVER-2: ETN]             0 #> d[UNCOVER-2: IXE_Q2W]         1 #> d[UNCOVER-2: IXE_Q4W]         0 #> d[UNCOVER-2: SEC_150]         0 #> d[UNCOVER-2: SEC_300]         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-3: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-3: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-3: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-3: IXE_Q4W]         0         0         0      0.22      0.78 #> d[UNCOVER-3: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-3: SEC_300]         0         0         0      0.78      0.22 #>                       p_rank[6] #> d[UNCOVER-3: PBO]             0 #> d[UNCOVER-3: ETN]             0 #> d[UNCOVER-3: IXE_Q2W]         1 #> d[UNCOVER-3: IXE_Q4W]         0 #> d[UNCOVER-3: SEC_150]         0 #> d[UNCOVER-3: SEC_300]         0 #>  plot(pso_rankprobs)   # Cumulative rank probabilities pso_cumrankprobs <- posterior_rank_probs(pso_fit, cumulative = TRUE) pso_cumrankprobs #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             1         1         1      1.00         1         1 #> d[FIXTURE: ETN]             0         1         1      1.00         1         1 #> d[FIXTURE: IXE_Q2W]         0         0         0      0.00         0         1 #> d[FIXTURE: IXE_Q4W]         0         0         0      0.22         1         1 #> d[FIXTURE: SEC_150]         0         0         1      1.00         1         1 #> d[FIXTURE: SEC_300]         0         0         0      0.78         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-1: PBO]             1         1         1      1.00         1 #> d[UNCOVER-1: ETN]             0         1         1      1.00         1 #> d[UNCOVER-1: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-1: IXE_Q4W]         0         0         0      0.22         1 #> d[UNCOVER-1: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-1: SEC_300]         0         0         0      0.78         1 #>                       p_rank[6] #> d[UNCOVER-1: PBO]             1 #> d[UNCOVER-1: ETN]             1 #> d[UNCOVER-1: IXE_Q2W]         1 #> d[UNCOVER-1: IXE_Q4W]         1 #> d[UNCOVER-1: SEC_150]         1 #> d[UNCOVER-1: SEC_300]         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-2: PBO]             1         1         1      1.00         1 #> d[UNCOVER-2: ETN]             0         1         1      1.00         1 #> d[UNCOVER-2: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-2: IXE_Q4W]         0         0         0      0.22         1 #> d[UNCOVER-2: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-2: SEC_300]         0         0         0      0.78         1 #>                       p_rank[6] #> d[UNCOVER-2: PBO]             1 #> d[UNCOVER-2: ETN]             1 #> d[UNCOVER-2: IXE_Q2W]         1 #> d[UNCOVER-2: IXE_Q4W]         1 #> d[UNCOVER-2: SEC_150]         1 #> d[UNCOVER-2: SEC_300]         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-3: PBO]             1         1         1      1.00         1 #> d[UNCOVER-3: ETN]             0         1         1      1.00         1 #> d[UNCOVER-3: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-3: IXE_Q4W]         0         0         0      0.22         1 #> d[UNCOVER-3: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-3: SEC_300]         0         0         0      0.78         1 #>                       p_rank[6] #> d[UNCOVER-3: PBO]             1 #> d[UNCOVER-3: ETN]             1 #> d[UNCOVER-3: IXE_Q2W]         1 #> d[UNCOVER-3: IXE_Q4W]         1 #> d[UNCOVER-3: SEC_150]         1 #> d[UNCOVER-3: SEC_300]         1 #>  plot(pso_cumrankprobs)   # Produce population-adjusted rankings for a different target # population new_agd_means <- data.frame(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3)  # Ranks posterior_ranks(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                      mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[New 1: PBO]     1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[New 1: ETN]     2.00 0.00    2   2   2   2     2       NA       NA   NA #> rank[New 1: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[New 1: IXE_Q4W] 4.78 0.42    4   5   5   5     5     4323       NA    1 #> rank[New 1: SEC_150] 3.00 0.04    3   3   3   3     3     3163     3163    1 #> rank[New 1: SEC_300] 4.22 0.42    4   4   4   4     5     4292       NA    1 #>   # Rank probabilities posterior_rank_probs(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[New 1: PBO]             1         0         0      0.00      0.00         0 #> d[New 1: ETN]             0         1         0      0.00      0.00         0 #> d[New 1: IXE_Q2W]         0         0         0      0.00      0.00         1 #> d[New 1: IXE_Q4W]         0         0         0      0.22      0.78         0 #> d[New 1: SEC_150]         0         0         1      0.00      0.00         0 #> d[New 1: SEC_300]         0         0         0      0.78      0.22         0 #>   # Cumulative rank probabilities posterior_rank_probs(pso_fit, newdata = new_agd_means,                      cumulative = TRUE) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[New 1: PBO]             1         1         1      1.00         1         1 #> d[New 1: ETN]             0         1         1      1.00         1         1 #> d[New 1: IXE_Q2W]         0         0         0      0.00         0         1 #> d[New 1: IXE_Q4W]         0         0         0      0.22         1         1 #> d[New 1: SEC_150]         0         0         1      1.00         1         1 #> d[New 1: SEC_300]         0         0         0      0.78         1         1 #>  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions of absolute effects from NMA models — predict.stan_nma","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Obtain predictions absolute effects NMA models fitted nma(). example, model fitted binary data logit link, predicted outcome probabilities log odds can produced. survival models, predictions can made survival probabilities, (cumulative) hazards, (restricted) mean survival times, quantiles including median survival times. IPD NMA ML-NMR model fitted, predictions can produced either individual level aggregate level. Aggregate-level predictions population-average absolute effects; marginalised standardised population. example, average event probabilities logistic regression, marginal (standardised) survival probabilities survival model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"","code":"# S3 method for stan_nma predict(   object,   ...,   baseline = NULL,   newdata = NULL,   study = NULL,   trt_ref = NULL,   type = c(\"link\", \"response\"),   level = c(\"aggregate\", \"individual\"),   baseline_type = c(\"link\", \"response\"),   baseline_level = c(\"individual\", \"aggregate\"),   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE )  # S3 method for stan_nma_surv predict(   object,   times = NULL,   ...,   baseline = NULL,   aux = NULL,   newdata = NULL,   study = NULL,   trt_ref = NULL,   type = c(\"survival\", \"hazard\", \"cumhaz\", \"mean\", \"median\", \"quantile\", \"rmst\", \"link\"),   quantiles = c(0.25, 0.5, 0.75),   level = c(\"aggregate\", \"individual\"),   times_seq = NULL,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"object stan_nma object created nma(). ... Additional arguments, passed uniroot() regression models baseline_level = \"aggregate\". baseline optional distr() distribution baseline response (.e. intercept), produce absolute effects. Can also character string naming study network take estimated baseline response distribution . NULL, predictions produced using baseline response study network IPD arm-based AgD. regression models, may list distr() distributions (study names network use baseline distributions ) length number studies newdata, possibly named studies newdata otherwise order appearance newdata. Use baseline_type baseline_level arguments specify whether distribution response linear predictor scale, (ML-NMR models including IPD) whether applies individual reference level covariates entire newdata population, respectively. example, model logit link baseline_type = \"link\", distribution baseline log odds event. survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_type always \"link\", baseline_level \"individual\" IPD NMA ML-NMR, \"aggregate\" AgD NMA). Use trt_ref argument specify treatment distribution applies . newdata required regression model fitted baseline specified. data frame covariate details, produce predictions. Column names must match variables regression model. level = \"aggregate\" either data frame integration points produced add_integration() (one row per study), data frame individual covariate values (one row per individual) summarised . level = \"individual\" data frame individual covariate values, one row per individual. NULL, predictions produced studies IPD /arm-based AgD network, depending value level. study Column newdata specifies study names IDs. specified: newdata contains integration points produced add_integration(), studies labelled sequentially row; otherwise data assumed come single study. trt_ref Treatment baseline response distribution refers, baseline specified. default, baseline response distribution refer network reference treatment. Coerced character string. type Whether produce predictions \"link\" scale (default, e.g. log odds) \"response\" scale (e.g. probabilities). survival models, options \"survival\" survival probabilities (default), \"hazard\" hazards, \"cumhaz\" cumulative hazards, \"mean\" mean survival times, \"quantile\" quantiles survival time distribution, \"median\" median survival times (equivalent type = \"quantile\" quantiles = 0.5), \"rmst\" restricted mean survival times, \"link\" linear predictor. type = \"survival\", \"hazard\" \"cumhaz\", predictions given times specified times event/censoring times network times = NULL. type = \"rmst\", restricted time horizon specified times, times = NULL earliest last follow-time amongst studies network used. level = \"aggregate\", correspond standardised survival function (see details). level level predictions produced, either \"aggregate\" (default), \"individual\". baseline specified, predictions produced IPD studies network level \"individual\" \"aggregate\", arm-based AgD studies network level \"aggregate\". baseline_type baseline distribution given, specifies whether corresponds \"link\" scale (default, e.g. log odds) \"response\" scale (e.g. probabilities). survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_type always \"link\"). baseline_level baseline distribution given, specifies whether corresponds individual reference level covariates (\"individual\", default), (unadjusted) average outcome reference treatment newdata population (\"aggregate\"). Ignored AgD NMA, since option \"aggregate\" instance. survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_level \"individual\" IPD NMA ML-NMR, \"aggregate\" AgD NMA). probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) predictive_distribution Logical, random effects model fitted, predictive distribution absolute effects new study returned? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE. times numeric vector times evaluate predictions . Alternatively, newdata specified, times can name column newdata contains times. NULL (default) predictions made event/censoring times studies included network (according times_seq). used type \"survival\", \"hazard\", \"cumhaz\" \"rmst\". aux optional distr() distribution auxiliary parameter(s) baseline hazard (e.g. shapes). Can also character string naming study network take estimated auxiliary parameter distribution . NULL, predictions produced using parameter estimates study network IPD arm-based AgD. regression models, may list distr() distributions (study names network use auxiliary parameters ) length number studies newdata, possibly named study names otherwise order appearance newdata. quantiles numeric vector quantiles survival time distribution produce estimates type = \"quantile\". times_seq positive integer, specified evaluate predictions many evenly-spaced event times 0 latest follow-time study, instead every observed event/censoring time. used newdata = NULL type \"survival\", \"hazard\" \"cumhaz\". can useful plotting survival (cumulative) hazard curves, prediction every observed even/censoring time unnecessary can slow. call within plot() detected, e.g. like plot(predict(fit, type = \"survival\")), times_seq default 50.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"aggregate-level-predictions-from-ipd-nma-and-ml-nmr-models","dir":"Reference","previous_headings":"","what":"Aggregate-level predictions from IPD NMA and ML-NMR models","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Population-average absolute effects can produced IPD NMA ML-NMR models level = \"aggregate\". Predictions averaged target population (.e. standardised/marginalised), either (numerical) integration joint covariate distribution (AgD studies network ML-NMR, AgD newdata integration points created add_integration()), averaging predictions sample individuals (IPD studies network IPD NMA/ML-NMR, IPD newdata). example, binary outcome, population-average event probabilities treatment \\(k\\) study/population \\(j\\) $$\\bar{p}_{jk} = \\int_\\mathfrak{X} p_{jk}(\\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x}$$ joint covariate distribution \\(f_{jk}(\\mathbf{x})\\) support \\(\\mathfrak{X}\\) $$\\bar{p}_{jk} = \\sum_i p_{jk}(\\mathbf{x}_i)$$ sample individuals covariates \\(\\mathbf{x}_i\\). Population-average absolute predictions follow similarly types outcomes, however survival outcomes specific considerations.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"standardised-survival-predictions","dir":"Reference","previous_headings":"","what":"Standardised survival predictions","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Different types population-average survival predictions, often called standardised survival predictions, follow standardised survival function created integrating (equivalently averaging) individual-level survival functions time \\(t\\): $$\\bar{S}_{jk}(t) = \\int_\\mathfrak{X} S_{jk}(t | \\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x}$$ produced using type = \"survival\". standardised hazard function corresponding standardised survival function weighted average individual-level hazard functions $$\\bar{h}_{jk}(t) = \\frac{\\int_\\mathfrak{X} S_{jk}(t | \\mathbf{x}) h_{jk}(t | \\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x} }{\\bar{S}_{jk}(t)}$$ weighted probability surviving time \\(t\\). produced using type = \"hazard\". corresponding standardised cumulative hazard function $$\\bar{H}_{jk}(t) = -\\log(\\bar{S}_{jk}(t))$$ produced using type = \"cumhaz\". Quantiles medians standardised survival times found solving $$\\bar{S}_{jk}(t) = 1-\\alpha$$ \\(\\alpha\\%\\) quantile, using numerical root finding. produced using type = \"quantile\" \"median\". (Restricted) means standardised survival times found integrating $$\\mathrm{RMST}_{jk}(t^*) = \\int_0^{t^*} \\bar{S}_{jk}(t) dt$$ restricted time horizon \\(t^*\\), \\(t^*=\\infty\\) mean standardised survival time. produced using type = \"rmst\" \"mean\".","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Predicted log odds of success in each study in the network predict(smk_fit_RE) #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[1: No intervention]        -2.78 0.33 -3.48 -2.99 -2.76 -2.55 -2.15 #> pred[1: Group counselling]      -1.69 0.52 -2.72 -2.04 -1.68 -1.34 -0.63 #> pred[1: Individual counselling] -1.94 0.39 -2.73 -2.19 -1.93 -1.68 -1.20 #> pred[1: Self-help]              -2.29 0.52 -3.34 -2.62 -2.28 -1.95 -1.27 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[1: No intervention]            3611     2962    1 #> pred[1: Group counselling]          2246     2387    1 #> pred[1: Individual counselling]     1948     2688    1 #> pred[1: Self-help]                  2474     2470    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[2: No intervention]        -2.57 0.79 -4.19 -3.07 -2.56 -2.06 -1.06 #> pred[2: Group counselling]      -1.49 0.79 -3.02 -2.00 -1.49 -0.99  0.07 #> pred[2: Individual counselling] -1.74 0.77 -3.28 -2.22 -1.74 -1.24 -0.22 #> pred[2: Self-help]              -2.09 0.78 -3.61 -2.60 -2.10 -1.58 -0.51 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[2: No intervention]            2602     2492    1 #> pred[2: Group counselling]          2757     2417    1 #> pred[2: Individual counselling]     2794     2456    1 #> pred[2: Self-help]                  2918     2585    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[3: No intervention]        -2.14 0.12 -2.39 -2.23 -2.14 -2.06 -1.92 #> pred[3: Group counselling]      -1.06 0.45 -1.94 -1.35 -1.06 -0.78 -0.10 #> pred[3: Individual counselling] -1.31 0.26 -1.83 -1.47 -1.31 -1.14 -0.79 #> pred[3: Self-help]              -1.66 0.41 -2.45 -1.92 -1.66 -1.40 -0.78 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[3: No intervention]            6693     2691    1 #> pred[3: Group counselling]          2057     2621    1 #> pred[3: Individual counselling]     1571     1998    1 #> pred[3: Self-help]                  2295     2617    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[4: No intervention]        -4.05 0.59 -5.28 -4.41 -4.00 -3.63 -3.03 #> pred[4: Group counselling]      -2.96 0.71 -4.43 -3.42 -2.94 -2.48 -1.61 #> pred[4: Individual counselling] -3.21 0.60 -4.46 -3.59 -3.19 -2.80 -2.14 #> pred[4: Self-help]              -3.56 0.69 -4.95 -4.01 -3.55 -3.10 -2.24 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[4: No intervention]            3873     2558    1 #> pred[4: Group counselling]          3000     2675    1 #> pred[4: Individual counselling]     3507     2483    1 #> pred[4: Self-help]                  3411     2998    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[5: No intervention]        -2.16 0.14 -2.43 -2.25 -2.15 -2.06 -1.88 #> pred[5: Group counselling]      -1.07 0.46 -1.95 -1.38 -1.08 -0.78 -0.12 #> pred[5: Individual counselling] -1.32 0.27 -1.85 -1.50 -1.32 -1.14 -0.78 #> pred[5: Self-help]              -1.67 0.42 -2.49 -1.94 -1.69 -1.40 -0.80 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[5: No intervention]            6330     3088    1 #> pred[5: Group counselling]          2081     2520    1 #> pred[5: Individual counselling]     1606     1838    1 #> pred[5: Self-help]                  2309     2633    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[6: No intervention]        -3.42 0.74 -5.06 -3.88 -3.36 -2.90 -2.13 #> pred[6: Group counselling]      -2.34 0.83 -4.10 -2.85 -2.28 -1.75 -0.87 #> pred[6: Individual counselling] -2.59 0.74 -4.23 -3.03 -2.52 -2.07 -1.29 #> pred[6: Self-help]              -2.94 0.83 -4.63 -3.46 -2.88 -2.37 -1.44 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[6: No intervention]            3196     2772    1 #> pred[6: Group counselling]          3348     2846    1 #> pred[6: Individual counselling]     3504     2546    1 #> pred[6: Self-help]                  3094     2729    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[7: No intervention]        -3.04 0.45 -4.02 -3.31 -3.00 -2.72 -2.23 #> pred[7: Group counselling]      -1.95 0.60 -3.23 -2.32 -1.92 -1.55 -0.85 #> pred[7: Individual counselling] -2.20 0.47 -3.17 -2.49 -2.17 -1.88 -1.37 #> pred[7: Self-help]              -2.55 0.59 -3.76 -2.92 -2.53 -2.15 -1.45 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[7: No intervention]            2962     2937    1 #> pred[7: Group counselling]          2764     2652    1 #> pred[7: Individual counselling]     2967     2936    1 #> pred[7: Self-help]                  2860     2285    1 #>  #> ---------------------------------------------------------------------- Study: 8 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[8: No intervention]        -2.71 0.60 -3.99 -3.10 -2.69 -2.30 -1.64 #> pred[8: Group counselling]      -1.63 0.71 -3.09 -2.07 -1.60 -1.15 -0.28 #> pred[8: Individual counselling] -1.88 0.60 -3.16 -2.26 -1.84 -1.46 -0.82 #> pred[8: Self-help]              -2.23 0.71 -3.68 -2.67 -2.19 -1.74 -0.97 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[8: No intervention]            3762     2960    1 #> pred[8: Group counselling]          3203     2855    1 #> pred[8: Individual counselling]     3937     3058    1 #> pred[8: Self-help]                  3200     2770    1 #>  #> ---------------------------------------------------------------------- Study: 9 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[9: No intervention]        -1.85 0.42 -2.71 -2.13 -1.83 -1.56 -1.06 #> pred[9: Group counselling]      -0.76 0.60 -1.90 -1.17 -0.77 -0.36  0.46 #> pred[9: Individual counselling] -1.01 0.46 -1.92 -1.32 -1.01 -0.70 -0.14 #> pred[9: Self-help]              -1.36 0.57 -2.51 -1.74 -1.37 -0.99 -0.24 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[9: No intervention]            4419     2852    1 #> pred[9: Group counselling]          2771     2684    1 #> pred[9: Individual counselling]     3026     3120    1 #> pred[9: Self-help]                  2991     2455    1 #>  #> --------------------------------------------------------------------- Study: 10 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[10: No intervention]        -2.08 0.12 -2.33 -2.16 -2.08 -2.00 -1.85 #> pred[10: Group counselling]      -0.99 0.45 -1.88 -1.30 -1.01 -0.71 -0.06 #> pred[10: Individual counselling] -1.24 0.26 -1.77 -1.42 -1.25 -1.07 -0.71 #> pred[10: Self-help]              -1.60 0.40 -2.38 -1.85 -1.60 -1.34 -0.74 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[10: No intervention]            7182     2444    1 #> pred[10: Group counselling]          2104     2735    1 #> pred[10: Individual counselling]     1629     1980    1 #> pred[10: Self-help]                  2245     2671    1 #>  #> --------------------------------------------------------------------- Study: 11 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[11: No intervention]        -3.62 0.23 -4.08 -3.77 -3.61 -3.46 -3.19 #> pred[11: Group counselling]      -2.53 0.49 -3.50 -2.86 -2.53 -2.22 -1.55 #> pred[11: Individual counselling] -2.78 0.32 -3.41 -2.99 -2.78 -2.58 -2.14 #> pred[11: Self-help]              -3.13 0.44 -3.98 -3.42 -3.13 -2.85 -2.25 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[11: No intervention]            6167     2846    1 #> pred[11: Group counselling]          2313     2592    1 #> pred[11: Individual counselling]     2270     2653    1 #> pred[11: Self-help]                  2589     2723    1 #>  #> --------------------------------------------------------------------- Study: 12 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[12: No intervention]        -2.22 0.14 -2.49 -2.31 -2.22 -2.13 -1.96 #> pred[12: Group counselling]      -1.13 0.46 -2.03 -1.43 -1.14 -0.85 -0.18 #> pred[12: Individual counselling] -1.38 0.26 -1.90 -1.55 -1.38 -1.22 -0.85 #> pred[12: Self-help]              -1.73 0.42 -2.55 -2.01 -1.74 -1.47 -0.85 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[12: No intervention]            6018     2585    1 #> pred[12: Group counselling]          2091     2579    1 #> pred[12: Individual counselling]     1501     2131    1 #> pred[12: Self-help]                  2282     2418    1 #>  #> --------------------------------------------------------------------- Study: 13 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[13: No intervention]        -2.67 0.46 -3.62 -2.97 -2.65 -2.35 -1.85 #> pred[13: Group counselling]      -1.59 0.62 -2.78 -1.99 -1.59 -1.19 -0.32 #> pred[13: Individual counselling] -1.84 0.49 -2.83 -2.16 -1.83 -1.50 -0.90 #> pred[13: Self-help]              -2.19 0.61 -3.38 -2.59 -2.19 -1.77 -1.03 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[13: No intervention]            4552     3488    1 #> pred[13: Group counselling]          3096     3140    1 #> pred[13: Individual counselling]     3186     2844    1 #> pred[13: Self-help]                  3207     3009    1 #>  #> --------------------------------------------------------------------- Study: 14 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[14: No intervention]        -2.40 0.23 -2.86 -2.56 -2.40 -2.24 -1.97 #> pred[14: Group counselling]      -1.32 0.49 -2.26 -1.64 -1.33 -1.00 -0.32 #> pred[14: Individual counselling] -1.57 0.32 -2.22 -1.77 -1.56 -1.35 -0.97 #> pred[14: Self-help]              -1.92 0.46 -2.81 -2.22 -1.92 -1.63 -1.02 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[14: No intervention]            4451     3033    1 #> pred[14: Group counselling]          2085     2751    1 #> pred[14: Individual counselling]     1937     2283    1 #> pred[14: Self-help]                  2439     2773    1 #>  #> --------------------------------------------------------------------- Study: 15 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[15: No intervention]        -2.68 0.75 -4.42 -3.12 -2.60 -2.15 -1.40 #> pred[15: Group counselling]      -1.59 0.74 -3.17 -2.06 -1.54 -1.08 -0.25 #> pred[15: Individual counselling] -1.84 0.76 -3.53 -2.30 -1.78 -1.32 -0.53 #> pred[15: Self-help]              -2.19 0.82 -4.01 -2.66 -2.13 -1.62 -0.80 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[15: No intervention]            3237     2511    1 #> pred[15: Group counselling]          3408     2695    1 #> pred[15: Individual counselling]     3197     2566    1 #> pred[15: Self-help]                  3342     2581    1 #>  #> --------------------------------------------------------------------- Study: 16 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[16: No intervention]        -2.61 0.34 -3.32 -2.83 -2.60 -2.37 -1.99 #> pred[16: Group counselling]      -1.53 0.54 -2.58 -1.88 -1.52 -1.18 -0.45 #> pred[16: Individual counselling] -1.78 0.40 -2.58 -2.04 -1.77 -1.51 -1.00 #> pred[16: Self-help]              -2.13 0.48 -3.07 -2.44 -2.13 -1.81 -1.15 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[16: No intervention]            4999     2879    1 #> pred[16: Group counselling]          2509     2797    1 #> pred[16: Individual counselling]     2855     2629    1 #> pred[16: Self-help]                  2664     2813    1 #>  #> --------------------------------------------------------------------- Study: 17 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[17: No intervention]        -2.38 0.11 -2.59 -2.45 -2.37 -2.30 -2.18 #> pred[17: Group counselling]      -1.29 0.45 -2.16 -1.58 -1.30 -1.01 -0.36 #> pred[17: Individual counselling] -1.54 0.25 -2.04 -1.70 -1.54 -1.39 -1.03 #> pred[17: Self-help]              -1.89 0.41 -2.67 -2.16 -1.89 -1.64 -1.05 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[17: No intervention]            6069     2774    1 #> pred[17: Group counselling]          2084     2550    1 #> pred[17: Individual counselling]     1498     1707    1 #> pred[17: Self-help]                  2308     2450    1 #>  #> --------------------------------------------------------------------- Study: 18 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[18: No intervention]        -2.57 0.27 -3.12 -2.75 -2.56 -2.37 -2.08 #> pred[18: Group counselling]      -1.48 0.51 -2.45 -1.82 -1.49 -1.15 -0.44 #> pred[18: Individual counselling] -1.73 0.35 -2.38 -1.96 -1.74 -1.50 -1.03 #> pred[18: Self-help]              -2.08 0.48 -3.02 -2.40 -2.09 -1.77 -1.08 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[18: No intervention]            4285     3341    1 #> pred[18: Group counselling]          2381     2894    1 #> pred[18: Individual counselling]     1988     2669    1 #> pred[18: Self-help]                  2570     2637    1 #>  #> --------------------------------------------------------------------- Study: 19 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[19: No intervention]        -1.90 0.12 -2.14 -1.98 -1.90 -1.82 -1.67 #> pred[19: Group counselling]      -0.81 0.45 -1.69 -1.11 -0.83 -0.53  0.12 #> pred[19: Individual counselling] -1.07 0.26 -1.58 -1.24 -1.07 -0.90 -0.54 #> pred[19: Self-help]              -1.42 0.42 -2.22 -1.68 -1.42 -1.16 -0.56 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[19: No intervention]            6323     2743    1 #> pred[19: Group counselling]          2083     2635    1 #> pred[19: Individual counselling]     1590     1948    1 #> pred[19: Self-help]                  2320     2419    1 #>  #> --------------------------------------------------------------------- Study: 20 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[20: No intervention]        -2.80 0.12 -3.05 -2.88 -2.80 -2.72 -2.56 #> pred[20: Group counselling]      -1.71 0.46 -2.60 -2.00 -1.73 -1.41 -0.75 #> pred[20: Individual counselling] -1.97 0.26 -2.48 -2.13 -1.97 -1.80 -1.45 #> pred[20: Self-help]              -2.32 0.42 -3.13 -2.59 -2.32 -2.05 -1.44 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[20: No intervention]            7119     2880    1 #> pred[20: Group counselling]          2099     2631    1 #> pred[20: Individual counselling]     1609     2005    1 #> pred[20: Self-help]                  2288     2335    1 #>  #> --------------------------------------------------------------------- Study: 21 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[21: No intervention]        -1.12 0.81 -2.80 -1.61 -1.11 -0.60  0.50 #> pred[21: Group counselling]      -0.03 0.87 -1.78 -0.58 -0.03  0.51  1.72 #> pred[21: Individual counselling] -0.28 0.80 -1.89 -0.78 -0.28  0.24  1.30 #> pred[21: Self-help]              -0.63 0.80 -2.30 -1.13 -0.62 -0.12  0.94 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[21: No intervention]            2957     2614    1 #> pred[21: Group counselling]          3120     2854    1 #> pred[21: Individual counselling]     3220     2597    1 #> pred[21: Self-help]                  3377     2578    1 #>  #> --------------------------------------------------------------------- Study: 22 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[22: No intervention]        -2.37 0.88 -4.09 -2.92 -2.36 -1.81 -0.54 #> pred[22: Group counselling]      -1.28 0.84 -2.89 -1.83 -1.28 -0.75  0.39 #> pred[22: Individual counselling] -1.53 0.88 -3.26 -2.08 -1.54 -0.98  0.28 #> pred[22: Self-help]              -1.88 0.85 -3.56 -2.43 -1.89 -1.33 -0.21 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[22: No intervention]            2630     2450    1 #> pred[22: Group counselling]          3312     2373    1 #> pred[22: Individual counselling]     2883     2456    1 #> pred[22: Self-help]                  3201     2669    1 #>  #> --------------------------------------------------------------------- Study: 23 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[23: No intervention]        -2.31 0.84 -3.98 -2.85 -2.29 -1.78 -0.67 #> pred[23: Group counselling]      -1.22 0.81 -2.80 -1.75 -1.21 -0.71  0.43 #> pred[23: Individual counselling] -1.47 0.82 -3.12 -1.98 -1.46 -0.95  0.12 #> pred[23: Self-help]              -1.82 0.88 -3.56 -2.40 -1.81 -1.26 -0.10 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[23: No intervention]            2882     2211    1 #> pred[23: Group counselling]          3567     2753    1 #> pred[23: Individual counselling]     3275     2797    1 #> pred[23: Self-help]                  3085     2210    1 #>  #> --------------------------------------------------------------------- Study: 24 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[24: No intervention]        -2.80 0.87 -4.50 -3.35 -2.81 -2.22 -1.05 #> pred[24: Group counselling]      -1.71 0.87 -3.44 -2.27 -1.72 -1.15  0.01 #> pred[24: Individual counselling] -1.96 0.85 -3.60 -2.51 -1.97 -1.42 -0.29 #> pred[24: Self-help]              -2.31 0.93 -4.16 -2.90 -2.31 -1.72 -0.50 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[24: No intervention]            3082     2842    1 #> pred[24: Group counselling]          3721     2786    1 #> pred[24: Individual counselling]     3848     3080    1 #> pred[24: Self-help]                  3407     2896    1 #>   # Predicted probabilities of success in each study in the network predict(smk_fit_RE, type = \"response\") #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[1: No intervention]        0.06 0.02 0.03 0.05 0.06 0.07  0.10     3611 #> pred[1: Group counselling]      0.17 0.07 0.06 0.12 0.16 0.21  0.35     2246 #> pred[1: Individual counselling] 0.13 0.04 0.06 0.10 0.13 0.16  0.23     1948 #> pred[1: Self-help]              0.10 0.05 0.03 0.07 0.09 0.12  0.22     2474 #>                                 Tail_ESS Rhat #> pred[1: No intervention]            2962    1 #> pred[1: Group counselling]          2387    1 #> pred[1: Individual counselling]     2688    1 #> pred[1: Self-help]                  2470    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[2: No intervention]        0.09 0.07 0.01 0.04 0.07 0.11  0.26     2602 #> pred[2: Group counselling]      0.21 0.12 0.05 0.12 0.18 0.27  0.52     2757 #> pred[2: Individual counselling] 0.17 0.11 0.04 0.10 0.15 0.22  0.44     2794 #> pred[2: Self-help]              0.13 0.09 0.03 0.07 0.11 0.17  0.38     2918 #>                                 Tail_ESS Rhat #> pred[2: No intervention]            2492    1 #> pred[2: Group counselling]          2417    1 #> pred[2: Individual counselling]     2456    1 #> pred[2: Self-help]                  2585    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[3: No intervention]        0.11 0.01 0.08 0.10 0.11 0.11  0.13     6693 #> pred[3: Group counselling]      0.27 0.09 0.13 0.21 0.26 0.32  0.48     2057 #> pred[3: Individual counselling] 0.22 0.04 0.14 0.19 0.21 0.24  0.31     1571 #> pred[3: Self-help]              0.17 0.06 0.08 0.13 0.16 0.20  0.31     2295 #>                                 Tail_ESS Rhat #> pred[3: No intervention]            2691    1 #> pred[3: Group counselling]          2621    1 #> pred[3: Individual counselling]     1998    1 #> pred[3: Self-help]                  2617    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[4: No intervention]        0.02 0.01 0.01 0.01 0.02 0.03  0.05     3873 #> pred[4: Group counselling]      0.06 0.04 0.01 0.03 0.05 0.08  0.17     3000 #> pred[4: Individual counselling] 0.04 0.02 0.01 0.03 0.04 0.06  0.10     3507 #> pred[4: Self-help]              0.03 0.02 0.01 0.02 0.03 0.04  0.10     3411 #>                                 Tail_ESS Rhat #> pred[4: No intervention]            2558    1 #> pred[4: Group counselling]          2675    1 #> pred[4: Individual counselling]     2483    1 #> pred[4: Self-help]                  2998    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[5: No intervention]        0.10 0.01 0.08 0.10 0.10 0.11  0.13     6330 #> pred[5: Group counselling]      0.26 0.09 0.12 0.20 0.25 0.31  0.47     2081 #> pred[5: Individual counselling] 0.21 0.05 0.14 0.18 0.21 0.24  0.31     1606 #> pred[5: Self-help]              0.17 0.06 0.08 0.13 0.16 0.20  0.31     2309 #>                                 Tail_ESS Rhat #> pred[5: No intervention]            3088    1 #> pred[5: Group counselling]          2520    1 #> pred[5: Individual counselling]     1838    1 #> pred[5: Self-help]                  2633    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[6: No intervention]        0.04 0.03 0.01 0.02 0.03 0.05  0.11     3196 #> pred[6: Group counselling]      0.11 0.07 0.02 0.05 0.09 0.15  0.29     3348 #> pred[6: Individual counselling] 0.08 0.05 0.01 0.05 0.07 0.11  0.22     3504 #> pred[6: Self-help]              0.06 0.05 0.01 0.03 0.05 0.09  0.19     3094 #>                                 Tail_ESS Rhat #> pred[6: No intervention]            2772    1 #> pred[6: Group counselling]          2846    1 #> pred[6: Individual counselling]     2546    1 #> pred[6: Self-help]                  2729    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[7: No intervention]        0.05 0.02 0.02 0.04 0.05 0.06  0.10     2962 #> pred[7: Group counselling]      0.14 0.07 0.04 0.09 0.13 0.18  0.30     2764 #> pred[7: Individual counselling] 0.11 0.04 0.04 0.08 0.10 0.13  0.20     2967 #> pred[7: Self-help]              0.08 0.04 0.02 0.05 0.07 0.10  0.19     2860 #>                                 Tail_ESS Rhat #> pred[7: No intervention]            2937    1 #> pred[7: Group counselling]          2652    1 #> pred[7: Individual counselling]     2936    1 #> pred[7: Self-help]                  2285    1 #>  #> ---------------------------------------------------------------------- Study: 8 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[8: No intervention]        0.07 0.04 0.02 0.04 0.06 0.09  0.16     3762 #> pred[8: Group counselling]      0.19 0.10 0.04 0.11 0.17 0.24  0.43     3203 #> pred[8: Individual counselling] 0.15 0.07 0.04 0.09 0.14 0.19  0.31     3937 #> pred[8: Self-help]              0.11 0.07 0.02 0.06 0.10 0.15  0.27     3200 #>                                 Tail_ESS Rhat #> pred[8: No intervention]            2960    1 #> pred[8: Group counselling]          2855    1 #> pred[8: Individual counselling]     3058    1 #> pred[8: Self-help]                  2770    1 #>  #> ---------------------------------------------------------------------- Study: 9 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[9: No intervention]        0.14 0.05 0.06 0.11 0.14 0.17  0.26     4419 #> pred[9: Group counselling]      0.33 0.13 0.13 0.24 0.32 0.41  0.61     2771 #> pred[9: Individual counselling] 0.28 0.09 0.13 0.21 0.27 0.33  0.47     3026 #> pred[9: Self-help]              0.22 0.10 0.08 0.15 0.20 0.27  0.44     2991 #>                                 Tail_ESS Rhat #> pred[9: No intervention]            2852    1 #> pred[9: Group counselling]          2684    1 #> pred[9: Individual counselling]     3120    1 #> pred[9: Self-help]                  2455    1 #>  #> --------------------------------------------------------------------- Study: 10 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[10: No intervention]        0.11 0.01 0.09 0.10 0.11 0.12  0.14     7182 #> pred[10: Group counselling]      0.28 0.09 0.13 0.21 0.27 0.33  0.48     2104 #> pred[10: Individual counselling] 0.23 0.05 0.15 0.19 0.22 0.25  0.33     1629 #> pred[10: Self-help]              0.18 0.06 0.08 0.14 0.17 0.21  0.32     2245 #>                                  Tail_ESS Rhat #> pred[10: No intervention]            2444    1 #> pred[10: Group counselling]          2735    1 #> pred[10: Individual counselling]     1980    1 #> pred[10: Self-help]                  2671    1 #>  #> --------------------------------------------------------------------- Study: 11 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[11: No intervention]        0.03 0.01 0.02 0.02 0.03 0.03  0.04     6167 #> pred[11: Group counselling]      0.08 0.04 0.03 0.05 0.07 0.10  0.18     2313 #> pred[11: Individual counselling] 0.06 0.02 0.03 0.05 0.06 0.07  0.11     2270 #> pred[11: Self-help]              0.05 0.02 0.02 0.03 0.04 0.05  0.10     2589 #>                                  Tail_ESS Rhat #> pred[11: No intervention]            2846    1 #> pred[11: Group counselling]          2592    1 #> pred[11: Individual counselling]     2653    1 #> pred[11: Self-help]                  2723    1 #>  #> --------------------------------------------------------------------- Study: 12 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[12: No intervention]        0.10 0.01 0.08 0.09 0.10 0.11  0.12     6018 #> pred[12: Group counselling]      0.25 0.09 0.12 0.19 0.24 0.30  0.46     2091 #> pred[12: Individual counselling] 0.20 0.04 0.13 0.17 0.20 0.23  0.30     1501 #> pred[12: Self-help]              0.16 0.06 0.07 0.12 0.15 0.19  0.30     2282 #>                                  Tail_ESS Rhat #> pred[12: No intervention]            2585    1 #> pred[12: Group counselling]          2579    1 #> pred[12: Individual counselling]     2131    1 #> pred[12: Self-help]                  2418    1 #>  #> --------------------------------------------------------------------- Study: 13 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[13: No intervention]        0.07 0.03 0.03 0.05 0.07 0.09  0.14     4552 #> pred[13: Group counselling]      0.19 0.09 0.06 0.12 0.17 0.23  0.42     3096 #> pred[13: Individual counselling] 0.15 0.06 0.06 0.10 0.14 0.18  0.29     3186 #> pred[13: Self-help]              0.11 0.06 0.03 0.07 0.10 0.14  0.26     3207 #>                                  Tail_ESS Rhat #> pred[13: No intervention]            3488    1 #> pred[13: Group counselling]          3140    1 #> pred[13: Individual counselling]     2844    1 #> pred[13: Self-help]                  3009    1 #>  #> --------------------------------------------------------------------- Study: 14 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[14: No intervention]        0.08 0.02 0.05 0.07 0.08 0.10  0.12     4451 #> pred[14: Group counselling]      0.22 0.08 0.09 0.16 0.21 0.27  0.42     2085 #> pred[14: Individual counselling] 0.18 0.05 0.10 0.15 0.17 0.21  0.27     1937 #> pred[14: Self-help]              0.14 0.05 0.06 0.10 0.13 0.16  0.26     2439 #>                                  Tail_ESS Rhat #> pred[14: No intervention]            3033    1 #> pred[14: Group counselling]          2751    1 #> pred[14: Individual counselling]     2283    1 #> pred[14: Self-help]                  2773    1 #>  #> --------------------------------------------------------------------- Study: 15 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[15: No intervention]        0.08 0.05 0.01 0.04 0.07 0.10  0.20     3237 #> pred[15: Group counselling]      0.19 0.10 0.04 0.11 0.18 0.25  0.44     3408 #> pred[15: Individual counselling] 0.16 0.09 0.03 0.09 0.14 0.21  0.37     3197 #> pred[15: Self-help]              0.12 0.08 0.02 0.07 0.11 0.16  0.31     3342 #>                                  Tail_ESS Rhat #> pred[15: No intervention]            2511    1 #> pred[15: Group counselling]          2695    1 #> pred[15: Individual counselling]     2566    1 #> pred[15: Self-help]                  2581    1 #>  #> --------------------------------------------------------------------- Study: 16 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[16: No intervention]        0.07 0.02 0.04 0.06 0.07 0.09  0.12     4999 #> pred[16: Group counselling]      0.19 0.08 0.07 0.13 0.18 0.24  0.39     2509 #> pred[16: Individual counselling] 0.15 0.05 0.07 0.12 0.14 0.18  0.27     2855 #> pred[16: Self-help]              0.12 0.05 0.04 0.08 0.11 0.14  0.24     2664 #>                                  Tail_ESS Rhat #> pred[16: No intervention]            2879    1 #> pred[16: Group counselling]          2797    1 #> pred[16: Individual counselling]     2629    1 #> pred[16: Self-help]                  2813    1 #>  #> --------------------------------------------------------------------- Study: 17 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[17: No intervention]        0.09 0.01 0.07 0.08 0.09 0.09  0.10     6069 #> pred[17: Group counselling]      0.23 0.08 0.10 0.17 0.21 0.27  0.41     2084 #> pred[17: Individual counselling] 0.18 0.04 0.11 0.15 0.18 0.20  0.26     1498 #> pred[17: Self-help]              0.14 0.05 0.06 0.10 0.13 0.16  0.26     2308 #>                                  Tail_ESS Rhat #> pred[17: No intervention]            2774    1 #> pred[17: Group counselling]          2550    1 #> pred[17: Individual counselling]     1707    1 #> pred[17: Self-help]                  2450    1 #>  #> --------------------------------------------------------------------- Study: 18 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[18: No intervention]        0.07 0.02 0.04 0.06 0.07 0.09  0.11     4285 #> pred[18: Group counselling]      0.20 0.08 0.08 0.14 0.18 0.24  0.39     2381 #> pred[18: Individual counselling] 0.16 0.05 0.08 0.12 0.15 0.18  0.26     1988 #> pred[18: Self-help]              0.12 0.05 0.05 0.08 0.11 0.15  0.25     2570 #>                                  Tail_ESS Rhat #> pred[18: No intervention]            3341    1 #> pred[18: Group counselling]          2894    1 #> pred[18: Individual counselling]     2669    1 #> pred[18: Self-help]                  2637    1 #>  #> --------------------------------------------------------------------- Study: 19 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[19: No intervention]        0.13 0.01 0.11 0.12 0.13 0.14  0.16     6323 #> pred[19: Group counselling]      0.31 0.10 0.16 0.25 0.30 0.37  0.53     2083 #> pred[19: Individual counselling] 0.26 0.05 0.17 0.23 0.26 0.29  0.37     1590 #> pred[19: Self-help]              0.20 0.07 0.10 0.16 0.19 0.24  0.36     2320 #>                                  Tail_ESS Rhat #> pred[19: No intervention]            2743    1 #> pred[19: Group counselling]          2635    1 #> pred[19: Individual counselling]     1948    1 #> pred[19: Self-help]                  2419    1 #>  #> --------------------------------------------------------------------- Study: 20 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[20: No intervention]        0.06 0.01 0.05 0.05 0.06 0.06  0.07     7119 #> pred[20: Group counselling]      0.16 0.06 0.07 0.12 0.15 0.20  0.32     2099 #> pred[20: Individual counselling] 0.13 0.03 0.08 0.11 0.12 0.14  0.19     1609 #> pred[20: Self-help]              0.10 0.04 0.04 0.07 0.09 0.11  0.19     2288 #>                                  Tail_ESS Rhat #> pred[20: No intervention]            2880    1 #> pred[20: Group counselling]          2631    1 #> pred[20: Individual counselling]     2005    1 #> pred[20: Self-help]                  2335    1 #>  #> --------------------------------------------------------------------- Study: 21 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[21: No intervention]        0.27 0.14 0.06 0.17 0.25 0.35  0.62     2957 #> pred[21: Group counselling]      0.49 0.18 0.14 0.36 0.49 0.62  0.85     3120 #> pred[21: Individual counselling] 0.44 0.17 0.13 0.31 0.43 0.56  0.79     3220 #> pred[21: Self-help]              0.36 0.16 0.09 0.24 0.35 0.47  0.72     3377 #>                                  Tail_ESS Rhat #> pred[21: No intervention]            2614    1 #> pred[21: Group counselling]          2854    1 #> pred[21: Individual counselling]     2597    1 #> pred[21: Self-help]                  2578    1 #>  #> --------------------------------------------------------------------- Study: 22 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[22: No intervention]        0.11 0.09 0.02 0.05 0.09 0.14  0.37     2630 #> pred[22: Group counselling]      0.25 0.14 0.05 0.14 0.22 0.32  0.60     3312 #> pred[22: Individual counselling] 0.21 0.14 0.04 0.11 0.18 0.27  0.57     2883 #> pred[22: Self-help]              0.16 0.11 0.03 0.08 0.13 0.21  0.45     3201 #>                                  Tail_ESS Rhat #> pred[22: No intervention]            2450    1 #> pred[22: Group counselling]          2373    1 #> pred[22: Individual counselling]     2456    1 #> pred[22: Self-help]                  2669    1 #>  #> --------------------------------------------------------------------- Study: 23 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[23: No intervention]        0.11 0.08 0.02 0.05 0.09 0.14  0.34     2882 #> pred[23: Group counselling]      0.25 0.14 0.06 0.15 0.23 0.33  0.61     3567 #> pred[23: Individual counselling] 0.21 0.13 0.04 0.12 0.19 0.28  0.53     3275 #> pred[23: Self-help]              0.17 0.12 0.03 0.08 0.14 0.22  0.47     3085 #>                                  Tail_ESS Rhat #> pred[23: No intervention]            2211    1 #> pred[23: Group counselling]          2753    1 #> pred[23: Individual counselling]     2797    1 #> pred[23: Self-help]                  2210    1 #>  #> --------------------------------------------------------------------- Study: 24 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[24: No intervention]        0.08 0.07 0.01 0.03 0.06 0.10  0.26     3082 #> pred[24: Group counselling]      0.18 0.12 0.03 0.09 0.15 0.24  0.50     3721 #> pred[24: Individual counselling] 0.15 0.11 0.03 0.08 0.12 0.19  0.43     3848 #> pred[24: Self-help]              0.12 0.10 0.02 0.05 0.09 0.15  0.38     3407 #>                                  Tail_ESS Rhat #> pred[24: No intervention]            2842    1 #> pred[24: Group counselling]          2786    1 #> pred[24: Individual counselling]     3080    1 #> pred[24: Self-help]                  2896    1 #>   # Predicted probabilities in a population with 67 observed events out of 566 # individuals on No Intervention, corresponding to a Beta(67, 566 - 67) # distribution on the baseline probability of response, using # `baseline_type = \"response\"` (smk_pred_RE <- predict(smk_fit_RE,                         baseline = distr(qbeta, 67, 566 - 67),                         baseline_type = \"response\",                         type = \"response\")) #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[No intervention]        0.12 0.01 0.09 0.11 0.12 0.13  0.15     4121 #> pred[Group counselling]      0.29 0.09 0.14 0.23 0.28 0.34  0.50     2085 #> pred[Individual counselling] 0.24 0.05 0.16 0.21 0.23 0.27  0.35     1627 #> pred[Self-help]              0.19 0.06 0.09 0.14 0.18 0.22  0.34     2291 #>                              Tail_ESS Rhat #> pred[No intervention]            3625    1 #> pred[Group counselling]          2448    1 #> pred[Individual counselling]     2165    1 #> pred[Self-help]                  2691    1 plot(smk_pred_RE, ref_line = c(0, 1))   # Predicted probabilities in a population with a baseline log odds of # response on No Intervention given a Normal distribution with mean -2 # and SD 0.13, using `baseline_type = \"link\"` (the default) # Note: this is approximately equivalent to the above Beta distribution on # the baseline probability (smk_pred_RE2 <- predict(smk_fit_RE,                          baseline = distr(qnorm, mean = -2, sd = 0.13),                          type = \"response\")) #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[No intervention]        0.12 0.01 0.10 0.11 0.12 0.13  0.15     3840 #> pred[Group counselling]      0.30 0.09 0.14 0.23 0.28 0.35  0.51     2003 #> pred[Individual counselling] 0.24 0.05 0.16 0.21 0.24 0.27  0.34     1373 #> pred[Self-help]              0.19 0.06 0.09 0.14 0.18 0.22  0.34     2150 #>                              Tail_ESS Rhat #> pred[No intervention]            3926    1 #> pred[Group counselling]          2748    1 #> pred[Individual counselling]     2061    1 #> pred[Self-help]                  2664    1 plot(smk_pred_RE2, ref_line = c(0, 1))  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Predicted probabilities of response in each study in the network (pso_pred <- predict(pso_fit, type = \"response\")) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[FIXTURE: PBO]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     4323     2861 #> pred[FIXTURE: ETN]     0.46 0.02 0.41 0.44 0.46 0.47  0.50     8191     3126 #> pred[FIXTURE: IXE_Q2W] 0.89 0.02 0.85 0.88 0.89 0.90  0.92     6576     3146 #> pred[FIXTURE: IXE_Q4W] 0.80 0.03 0.74 0.78 0.80 0.81  0.84     8159     2820 #> pred[FIXTURE: SEC_150] 0.67 0.03 0.62 0.65 0.67 0.69  0.72    10316     2753 #> pred[FIXTURE: SEC_300] 0.77 0.02 0.72 0.75 0.77 0.79  0.81     8799     3071 #>                        Rhat #> pred[FIXTURE: PBO]        1 #> pred[FIXTURE: ETN]        1 #> pred[FIXTURE: IXE_Q2W]    1 #> pred[FIXTURE: IXE_Q4W]    1 #> pred[FIXTURE: SEC_150]    1 #> pred[FIXTURE: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-1: PBO]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     5144     3209 #> pred[UNCOVER-1: ETN]     0.46 0.03 0.41 0.44 0.46 0.48  0.52     6614     3319 #> pred[UNCOVER-1: IXE_Q2W] 0.90 0.01 0.88 0.89 0.90 0.91  0.92     7398     3411 #> pred[UNCOVER-1: IXE_Q4W] 0.81 0.02 0.78 0.80 0.81 0.82  0.84     9186     3221 #> pred[UNCOVER-1: SEC_150] 0.69 0.04 0.60 0.66 0.69 0.72  0.76     7396     3477 #> pred[UNCOVER-1: SEC_300] 0.78 0.04 0.71 0.76 0.79 0.81  0.85     8285     3444 #>                          Rhat #> pred[UNCOVER-1: PBO]        1 #> pred[UNCOVER-1: ETN]        1 #> pred[UNCOVER-1: IXE_Q2W]    1 #> pred[UNCOVER-1: IXE_Q4W]    1 #> pred[UNCOVER-1: SEC_150]    1 #> pred[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-2: PBO]     0.05 0.01 0.03 0.04 0.05 0.05  0.06     5064     3106 #> pred[UNCOVER-2: ETN]     0.42 0.02 0.38 0.41 0.42 0.43  0.46     7482     3363 #> pred[UNCOVER-2: IXE_Q2W] 0.88 0.01 0.86 0.87 0.88 0.89  0.91     8188     3361 #> pred[UNCOVER-2: IXE_Q4W] 0.78 0.02 0.75 0.77 0.78 0.79  0.81     8068     3361 #> pred[UNCOVER-2: SEC_150] 0.65 0.04 0.57 0.62 0.65 0.68  0.73     8674     3311 #> pred[UNCOVER-2: SEC_300] 0.75 0.04 0.68 0.73 0.75 0.78  0.82     9284     3184 #>                          Rhat #> pred[UNCOVER-2: PBO]        1 #> pred[UNCOVER-2: ETN]        1 #> pred[UNCOVER-2: IXE_Q2W]    1 #> pred[UNCOVER-2: IXE_Q4W]    1 #> pred[UNCOVER-2: SEC_150]    1 #> pred[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-3: PBO]     0.08 0.01 0.06 0.07 0.08 0.08  0.10     5432     2944 #> pred[UNCOVER-3: ETN]     0.53 0.02 0.49 0.52 0.53 0.54  0.57     8417     2713 #> pred[UNCOVER-3: IXE_Q2W] 0.93 0.01 0.91 0.92 0.93 0.93  0.94     7057     3385 #> pred[UNCOVER-3: IXE_Q4W] 0.85 0.01 0.83 0.85 0.85 0.86  0.88     8768     3254 #> pred[UNCOVER-3: SEC_150] 0.75 0.03 0.67 0.72 0.75 0.77  0.81     8866     3304 #> pred[UNCOVER-3: SEC_300] 0.83 0.03 0.77 0.81 0.83 0.85  0.88     9476     3277 #>                          Rhat #> pred[UNCOVER-3: PBO]        1 #> pred[UNCOVER-3: ETN]        1 #> pred[UNCOVER-3: IXE_Q2W]    1 #> pred[UNCOVER-3: IXE_Q4W]    1 #> pred[UNCOVER-3: SEC_150]    1 #> pred[UNCOVER-3: SEC_300]    1 #>  plot(pso_pred, ref_line = c(0, 1))   # Predicted probabilites of response in a new target population, with means # and SDs or proportions given by new_agd_int <- data.frame(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1 )  # We need to add integration points to this data frame of new data # We use the weighted mean correlation matrix computed from the IPD studies new_agd_int <- add_integration(new_agd_int,                                durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),                                prevsys = distr(qbern, prob = prevsys),                                bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),                                weight = distr(qgamma, mean = weight_mean, sd = weight_sd),                                psa = distr(qbern, prob = psa),                                cor = pso_net$int_cor,                                n_int = 64)  # Predicted probabilities of achieving PASI 75 in this target population, given # a Normal(-1.75, 0.08^2) distribution on the baseline probit-probability of # response on Placebo (at the reference levels of the covariates), are given by (pso_pred_new <- predict(pso_fit,                          type = \"response\",                          newdata = new_agd_int,                          baseline = distr(qnorm, -1.75, 0.08))) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: PBO]     0.06 0.02 0.03 0.04 0.06 0.07  0.12     4888     3097    1 #> pred[New 1: ETN]     0.37 0.06 0.26 0.33 0.37 0.41  0.48     5899     3914    1 #> pred[New 1: IXE_Q2W] 0.90 0.03 0.84 0.88 0.90 0.92  0.94     4881     3450    1 #> pred[New 1: IXE_Q4W] 0.81 0.04 0.72 0.78 0.81 0.83  0.87     5012     3722    1 #> pred[New 1: SEC_150] 0.68 0.06 0.57 0.64 0.68 0.72  0.78     4733     3549    1 #> pred[New 1: SEC_300] 0.78 0.05 0.68 0.75 0.78 0.81  0.86     5165     3646    1 #>  plot(pso_pred_new, ref_line = c(0, 1))  # }  ## Progression free survival with newly-diagnosed multiple myeloma # \\donttest{ # Run newly-diagnosed multiple myeloma example if not already available if (!exists(\"ndmm_fit\")) example(\"example_ndmm\", run.donttest = TRUE) #>  #> exmpl_> ## No test:  #> exmpl_> # Fit Weibull (PH) model #> exmpl_> ndmm_fit <- nma(ndmm_net, ## Don't show:  #> exmpl_+ refresh = if (interactive()) 200 else 0, #> exmpl_+ ## End(Don't show) #> exmpl_+                 likelihood = \"weibull\", #> exmpl_+                 prior_intercept = normal(scale = 100), #> exmpl_+                 prior_trt = normal(scale = 10), #> exmpl_+                 prior_aux = half_normal(scale = 10)) #> Error in eval(ei, envir): object 'ndmm_net' not found # } # \\donttest{ # We can produce a range of predictions from models with survival outcomes, # chosen with the type argument to predict  # Predicted survival probabilities at 5 years predict(ndmm_fit, type = \"survival\", times = 5) #> Error in eval(expr, envir, enclos): object 'ndmm_fit' not found  # Survival curves plot(predict(ndmm_fit, type = \"survival\")) #> Error in eval(expr, envir, enclos): object 'ndmm_fit' not found  # Hazard curves # Here we specify a vector of times to avoid attempting to plot infinite # hazards for some studies at t=0 plot(predict(ndmm_fit, type = \"hazard\", times = seq(0.001, 6, length.out = 50))) #> Error in eval(expr, envir, enclos): object 'ndmm_fit' not found  # Cumulative hazard curves plot(predict(ndmm_fit, type = \"cumhaz\")) #> Error in eval(expr, envir, enclos): object 'ndmm_fit' not found  # Survival time quantiles and median survival predict(ndmm_fit, type = \"quantile\", quantiles = c(0.2, 0.5, 0.8)) #> Error in eval(expr, envir, enclos): object 'ndmm_fit' not found plot(predict(ndmm_fit, type = \"median\")) #> Error in eval(expr, envir, enclos): object 'ndmm_fit' not found  # Mean survival time predict(ndmm_fit, type = \"mean\") #> Error in eval(expr, envir, enclos): object 'ndmm_fit' not found  # Restricted mean survival time # By default, the time horizon is the shortest follow-up time in the network predict(ndmm_fit, type = \"rmst\") #> Error in eval(expr, envir, enclos): object 'ndmm_fit' not found  # An alternative restriction time can be set using the times argument predict(ndmm_fit, type = \"rmst\", times = 5)  # 5-year RMST #> Error in eval(expr, envir, enclos): object 'ndmm_fit' not found # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Print nma_data objects — print.nma_data","title":"Print nma_data objects — print.nma_data","text":"Print details networks stored nma_data objects, created set_ipd(), set_agd_arm(), set_agd_contrast(), set_agd_surv(), combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print nma_data objects — print.nma_data","text":"","code":"# S3 method for nma_data print(x, ..., n = 10)  # S3 method for mlnmr_data print(x, ..., n = 10)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print nma_data objects — print.nma_data","text":"x nma_data object ... options (used) n number studies type print","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Print DIC details — print.nma_dic","title":"Print DIC details — print.nma_dic","text":"Print details DIC model fit statistics, computed dic() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print DIC details — print.nma_dic","text":"","code":"# S3 method for nma_dic print(x, digits = 1, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print DIC details — print.nma_dic","text":"x object class nma_dic digits integer passed round() ... Ignored","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print DIC details — print.nma_dic","text":"x returned invisibly.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"Print nma_nodesplit_df objects","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"","code":"# S3 method for nma_nodesplit_df print(x, ...)  # S3 method for nma_nodesplit print(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"x nma_nodesplit_df object ... arguments passed print.stanfit()","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Print stan_nma objects — print.stan_nma","title":"Print stan_nma objects — print.stan_nma","text":"Print stan_nma objects","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print stan_nma objects — print.stan_nma","text":"","code":"# S3 method for stan_nma print(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print stan_nma objects — print.stan_nma","text":"x stan_nma object ... arguments passed print.stanfit()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":null,"dir":"Reference","previous_headings":"","what":"Prior distributions — priors","title":"Prior distributions — priors","text":"functions used specify prior distributions model parameters.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prior distributions — priors","text":"","code":"normal(location = 0, scale)  half_normal(scale)  log_normal(location, scale)  cauchy(location = 0, scale)  half_cauchy(scale)  student_t(location = 0, scale, df)  half_student_t(scale, df)  log_student_t(location, scale, df)  exponential(scale = 1/rate, rate = 1/scale)  flat()"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prior distributions — priors","text":"location Prior location. Typically prior mean (see details). scale Prior scale. Typically prior standard deviation (see details). df Prior degrees freedom. rate Prior rate.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prior distributions — priors","text":"Object class nma_prior.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prior distributions — priors","text":"location scale parameters typically prior mean standard deviation, following exceptions: Cauchy distribution location prior median scale prior scale. log-Normal distribution, location scale prior mean standard deviation logarithm.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"compatibility-with-model-parameters","dir":"Reference","previous_headings":"","what":"Compatibility with model parameters","title":"Prior distributions — priors","text":"following table summarises prior distributions may used model parameters. Essentially, priors take non-negative values (e.g. half-Normal) may used non-negative parameters (heterogeneity SD/variance/precision, auxiliary parameter). real-valued prior distribution specified non-negative parameter, truncated 0 non-negative. flat() prior special case prior information added model, resulting implicit flat uniform prior distribution entire support parameter. improper prior parameter unbounded, generally advised. See Stan user's guide details.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Random effects structure — RE_cor","title":"Random effects structure — RE_cor","text":"Use RE_cor generate random effects correlation matrix, assumption common heterogeneity variance (.e. within-study correlations 0.5). Use which_RE return vector IDs RE deltas (0 means RE delta arm).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random effects structure — RE_cor","text":"","code":"RE_cor(study, trt, contrast, type = c(\"reftrt\", \"blshift\"))  which_RE(study, trt, contrast, type = c(\"reftrt\", \"blshift\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random effects structure — RE_cor","text":"study vector study IDs (integer, character, factor) trt factor vector treatment codes (coercible ), first level indicating reference treatment contrast logical vector, length study trt, indicating whether corresponding data contrast rather arm format. type Character string, whether generate RE structure \"reference treatment\" parameterisation, \"baseline shift\" parameterisation.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random effects structure — RE_cor","text":"RE_cor(), correlation matrix dimension equal number random effects deltas (excluding set equal zero). which_RE(), integer vector IDs indexing rows columns correlation matrix returned RE_cor().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random effects structure — RE_cor","text":"","code":"RE_cor(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking))) #> Coerced `trt` to factor. #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #>  [1,]  1.0  0.5  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>  [2,]  0.5  1.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>  [3,]  0.0  0.0  1.0  0.5  0.5    0    0    0    0     0     0     0     0 #>  [4,]  0.0  0.0  0.5  1.0  0.5    0    0    0    0     0     0     0     0 #>  [5,]  0.0  0.0  0.5  0.5  1.0    0    0    0    0     0     0     0     0 #>  [6,]  0.0  0.0  0.0  0.0  0.0    1    0    0    0     0     0     0     0 #>  [7,]  0.0  0.0  0.0  0.0  0.0    0    1    0    0     0     0     0     0 #>  [8,]  0.0  0.0  0.0  0.0  0.0    0    0    1    0     0     0     0     0 #>  [9,]  0.0  0.0  0.0  0.0  0.0    0    0    0    1     0     0     0     0 #> [10,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     1     0     0     0 #> [11,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     1     0     0 #> [12,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     1     0 #> [13,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     1 #> [14,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [15,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [16,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [17,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [18,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [19,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [20,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [21,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [22,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [23,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [24,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [25,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [26,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [27,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [28,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [29,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [30,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [31,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] #>  [1,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [2,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [3,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [4,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [5,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [6,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [7,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [8,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [9,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [10,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [11,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [12,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [13,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [14,]     1     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [15,]     0     1     0     0     0     0     0     0     0     0   0.0   0.0 #> [16,]     0     0     1     0     0     0     0     0     0     0   0.0   0.0 #> [17,]     0     0     0     1     0     0     0     0     0     0   0.0   0.0 #> [18,]     0     0     0     0     1     0     0     0     0     0   0.0   0.0 #> [19,]     0     0     0     0     0     1     0     0     0     0   0.0   0.0 #> [20,]     0     0     0     0     0     0     1     0     0     0   0.0   0.0 #> [21,]     0     0     0     0     0     0     0     1     0     0   0.0   0.0 #> [22,]     0     0     0     0     0     0     0     0     1     0   0.0   0.0 #> [23,]     0     0     0     0     0     0     0     0     0     1   0.0   0.0 #> [24,]     0     0     0     0     0     0     0     0     0     0   1.0   0.5 #> [25,]     0     0     0     0     0     0     0     0     0     0   0.5   1.0 #> [26,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [27,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [28,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [29,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [30,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [31,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>       [,26] [,27] [,28] [,29] [,30] [,31] #>  [1,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [2,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [3,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [4,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [5,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [6,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [7,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [8,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [9,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [10,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [11,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [12,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [13,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [14,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [15,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [16,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [17,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [18,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [19,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [20,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [21,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [22,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [23,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [24,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [25,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [26,]   1.0   0.5   0.0   0.0   0.0   0.0 #> [27,]   0.5   1.0   0.0   0.0   0.0   0.0 #> [28,]   0.0   0.0   1.0   0.5   0.0   0.0 #> [29,]   0.0   0.0   0.5   1.0   0.0   0.0 #> [30,]   0.0   0.0   0.0   0.0   1.0   0.5 #> [31,]   0.0   0.0   0.0   0.0   0.5   1.0 RE_cor(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking)), type = \"blshift\") #> Coerced `trt` to factor. #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #>  [1,]  1.0  0.5  0.0  0.0    0    0    0    0    0     0     0     0     0 #>  [2,]  0.5  1.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #>  [3,]  0.0  0.0  1.0  0.5    0    0    0    0    0     0     0     0     0 #>  [4,]  0.0  0.0  0.5  1.0    0    0    0    0    0     0     0     0     0 #>  [5,]  0.0  0.0  0.0  0.0    1    0    0    0    0     0     0     0     0 #>  [6,]  0.0  0.0  0.0  0.0    0    1    0    0    0     0     0     0     0 #>  [7,]  0.0  0.0  0.0  0.0    0    0    1    0    0     0     0     0     0 #>  [8,]  0.0  0.0  0.0  0.0    0    0    0    1    0     0     0     0     0 #>  [9,]  0.0  0.0  0.0  0.0    0    0    0    0    1     0     0     0     0 #> [10,]  0.0  0.0  0.0  0.0    0    0    0    0    0     1     0     0     0 #> [11,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     1     0     0 #> [12,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     1     0 #> [13,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     1 #> [14,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [15,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [16,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [17,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [18,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [19,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [20,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [21,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [22,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [23,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [24,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [25,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [26,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #>       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] #>  [1,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [2,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [3,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [4,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [5,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [6,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [7,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [8,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [9,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [10,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [11,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [12,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [13,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [14,]     1     0     0     0     0     0     0     0     0     0     0     0 #> [15,]     0     1     0     0     0     0     0     0     0     0     0     0 #> [16,]     0     0     1     0     0     0     0     0     0     0     0     0 #> [17,]     0     0     0     1     0     0     0     0     0     0     0     0 #> [18,]     0     0     0     0     1     0     0     0     0     0     0     0 #> [19,]     0     0     0     0     0     1     0     0     0     0     0     0 #> [20,]     0     0     0     0     0     0     1     0     0     0     0     0 #> [21,]     0     0     0     0     0     0     0     1     0     0     0     0 #> [22,]     0     0     0     0     0     0     0     0     1     0     0     0 #> [23,]     0     0     0     0     0     0     0     0     0     1     0     0 #> [24,]     0     0     0     0     0     0     0     0     0     0     1     0 #> [25,]     0     0     0     0     0     0     0     0     0     0     0     1 #> [26,]     0     0     0     0     0     0     0     0     0     0     0     0 #>       [,26] #>  [1,]     0 #>  [2,]     0 #>  [3,]     0 #>  [4,]     0 #>  [5,]     0 #>  [6,]     0 #>  [7,]     0 #>  [8,]     0 #>  [9,]     0 #> [10,]     0 #> [11,]     0 #> [12,]     0 #> [13,]     0 #> [14,]     0 #> [15,]     0 #> [16,]     0 #> [17,]     0 #> [18,]     0 #> [19,]     0 #> [20,]     0 #> [21,]     0 #> [22,]     0 #> [23,]     0 #> [24,]     0 #> [25,]     0 #> [26,]     1 which_RE(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking))) #> Coerced `trt` to factor. #>  [1]  0  1  2  3  4  5  0  6  0  7  0  8  0  9  0 10  0 11  0 12  0 13  0 14  0 #> [26] 15  0 16  0 17  0 18  0 19  0 20  0 21  0 22  0 23 24 25 26 27 28 29 30 31 which_RE(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking)), type = \"blshift\") #> Coerced `trt` to factor. #>  [1]  0  1  2  0  3  4  0  5  0  6  0  7  0  8  0  9  0 10  0 11  0 12  0 13  0 #> [26] 14  0 15  0 16  0 17  0 18  0 19  0 20  0 21  0 22  0 23  0 24  0 25  0 26"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. survival Surv","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Relative treatment effects — relative_effects","title":"Relative treatment effects — relative_effects","text":"Generate (population-average) relative treatment effects. ML-NMR meta-regression model fitted, specific study population.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relative treatment effects — relative_effects","text":"","code":"relative_effects(   x,   newdata = NULL,   study = NULL,   all_contrasts = FALSE,   trt_ref = NULL,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relative treatment effects — relative_effects","text":"x stan_nma object created nma() newdata used regression model fitted. data frame study details, one row per study, giving covariate values produce relative effects. Column names must match variables regression model. NULL, relative effects produced studies network. study Column newdata specifies study names, otherwise studies labelled row number. all_contrasts Logical, generate estimates contrasts (TRUE), just \"basic\" contrasts network reference treatment (FALSE)? Default FALSE. trt_ref Reference treatment construct relative effects , all_contrasts = FALSE. default, relative effects network reference treatment. Coerced character string. probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) predictive_distribution Logical, random effects model fitted, predictive distribution relative effects new study returned? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relative treatment effects — relative_effects","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Relative treatment effects — relative_effects","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce relative effects smk_releff_RE <- relative_effects(smk_fit_RE) smk_releff_RE #>                           mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> d[Group counselling]      1.09 0.44  0.25 0.79 1.08 1.36  2.01     1983 #> d[Individual counselling] 0.84 0.23  0.37 0.69 0.83 0.98  1.31     1279 #> d[Self-help]              0.49 0.40 -0.29 0.23 0.48 0.73  1.32     2167 #>                           Tail_ESS Rhat #> d[Group counselling]          2631    1 #> d[Individual counselling]     1721    1 #> d[Self-help]                  2566    1 plot(smk_releff_RE, ref_line = 0)   # Relative effects for all pairwise comparisons relative_effects(smk_fit_RE, all_contrasts = TRUE) #>                                                  mean   sd  2.5%   25%   50% #> d[Group counselling vs. No intervention]         1.09 0.44  0.25  0.79  1.08 #> d[Individual counselling vs. No intervention]    0.84 0.23  0.37  0.69  0.83 #> d[Self-help vs. No intervention]                 0.49 0.40 -0.29  0.23  0.48 #> d[Individual counselling vs. Group counselling] -0.25 0.42 -1.11 -0.52 -0.24 #> d[Self-help vs. Group counselling]              -0.60 0.48 -1.59 -0.90 -0.60 #> d[Self-help vs. Individual counselling]         -0.35 0.41 -1.16 -0.62 -0.35 #>                                                   75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling vs. No intervention]         1.36  2.01     1983     2631 #> d[Individual counselling vs. No intervention]    0.98  1.31     1279     1721 #> d[Self-help vs. No intervention]                 0.73  1.32     2167     2566 #> d[Individual counselling vs. Group counselling]  0.02  0.55     2586     2813 #> d[Self-help vs. Group counselling]              -0.29  0.29     2747     2887 #> d[Self-help vs. Individual counselling]         -0.09  0.45     2314     2725 #>                                                 Rhat #> d[Group counselling vs. No intervention]           1 #> d[Individual counselling vs. No intervention]      1 #> d[Self-help vs. No intervention]                   1 #> d[Individual counselling vs. Group counselling]    1 #> d[Self-help vs. Group counselling]                 1 #> d[Self-help vs. Individual counselling]            1  # Relative effects against a different reference treatment relative_effects(smk_fit_RE, trt_ref = \"Self-help\") #>                            mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> d[No intervention]        -0.49 0.40 -1.32 -0.73 -0.48 -0.23  0.29     2167 #> d[Group counselling]       0.60 0.48 -0.29  0.29  0.60  0.90  1.59     2747 #> d[Individual counselling]  0.35 0.41 -0.45  0.09  0.35  0.62  1.16     2314 #>                           Tail_ESS Rhat #> d[No intervention]            2566    1 #> d[Group counselling]          2887    1 #> d[Individual counselling]     2725    1  # Transforming to odds ratios # We work with the array of relative effects samples LOR_array <- as.array(smk_releff_RE) OR_array <- exp(LOR_array)  # mcmc_array objects can be summarised to produce a nma_summary object smk_OR_RE <- summary(OR_array)  # This can then be printed or plotted smk_OR_RE #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling]      3.28 1.62 1.28 2.21 2.94 3.91  7.48     1983     2631 #> d[Individual counselling] 2.37 0.58 1.45 1.99 2.30 2.66  3.69     1279     1721 #> d[Self-help]              1.76 0.76 0.75 1.26 1.62 2.07  3.73     2167     2566 #>                           Rhat #> d[Group counselling]         1 #> d[Individual counselling]    1 #> d[Self-help]                 1 plot(smk_OR_RE, ref_line = 1)  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Produce population-adjusted relative effects for all study populations in # the network pso_releff <- relative_effects(pso_fit) pso_releff #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[FIXTURE: ETN]     1.66 0.09 1.49 1.60 1.66 1.72  1.84     4274     3586    1 #> d[FIXTURE: IXE_Q2W] 3.03 0.10 2.84 2.96 3.03 3.09  3.23     4898     3002    1 #> d[FIXTURE: IXE_Q4W] 2.61 0.10 2.43 2.55 2.61 2.68  2.80     5531     3397    1 #> d[FIXTURE: SEC_150] 2.22 0.12 1.99 2.14 2.22 2.30  2.45     4811     3132    1 #> d[FIXTURE: SEC_300] 2.52 0.12 2.29 2.44 2.52 2.60  2.76     5488     3252    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-1: ETN]     1.51 0.09 1.34 1.45 1.50 1.56  1.68     4044     3166 #> d[UNCOVER-1: IXE_Q2W] 2.92 0.09 2.75 2.86 2.92 2.98  3.10     4617     2867 #> d[UNCOVER-1: IXE_Q4W] 2.51 0.08 2.35 2.45 2.51 2.57  2.67     4967     3175 #> d[UNCOVER-1: SEC_150] 2.11 0.12 1.88 2.03 2.11 2.20  2.35     4908     3334 #> d[UNCOVER-1: SEC_300] 2.42 0.13 2.18 2.33 2.42 2.51  2.66     5659     3343 #>                       Rhat #> d[UNCOVER-1: ETN]        1 #> d[UNCOVER-1: IXE_Q2W]    1 #> d[UNCOVER-1: IXE_Q4W]    1 #> d[UNCOVER-1: SEC_150]    1 #> d[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-2: ETN]     1.51 0.08 1.35 1.45 1.51 1.56  1.67     4126     3176 #> d[UNCOVER-2: IXE_Q2W] 2.92 0.09 2.75 2.86 2.92 2.98  3.10     4819     2960 #> d[UNCOVER-2: IXE_Q4W] 2.51 0.08 2.35 2.45 2.51 2.56  2.67     5129     3102 #> d[UNCOVER-2: SEC_150] 2.11 0.12 1.89 2.03 2.11 2.19  2.34     5000     3320 #> d[UNCOVER-2: SEC_300] 2.42 0.12 2.18 2.33 2.42 2.50  2.66     5818     3291 #>                       Rhat #> d[UNCOVER-2: ETN]        1 #> d[UNCOVER-2: IXE_Q2W]    1 #> d[UNCOVER-2: IXE_Q4W]    1 #> d[UNCOVER-2: SEC_150]    1 #> d[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-3: ETN]     1.53 0.08 1.37 1.47 1.53 1.58  1.69     4172     3146 #> d[UNCOVER-3: IXE_Q2W] 2.94 0.09 2.77 2.88 2.94 3.00  3.11     4877     2880 #> d[UNCOVER-3: IXE_Q4W] 2.53 0.08 2.37 2.47 2.53 2.58  2.69     5294     3411 #> d[UNCOVER-3: SEC_150] 2.13 0.12 1.91 2.05 2.13 2.21  2.36     5025     3216 #> d[UNCOVER-3: SEC_300] 2.43 0.12 2.20 2.35 2.44 2.52  2.67     5844     3143 #>                       Rhat #> d[UNCOVER-3: ETN]        1 #> d[UNCOVER-3: IXE_Q2W]    1 #> d[UNCOVER-3: IXE_Q4W]    1 #> d[UNCOVER-3: SEC_150]    1 #> d[UNCOVER-3: SEC_300]    1 #>  plot(pso_releff, ref_line = 0)   # Produce population-adjusted relative effects for a different target # population new_agd_means <- data.frame(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3)  relative_effects(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[New 1: ETN]     1.25 0.23 0.83 1.10 1.25 1.40  1.70     5835     3061    1 #> d[New 1: IXE_Q2W] 2.89 0.22 2.46 2.74 2.89 3.03  3.33     6313     2802    1 #> d[New 1: IXE_Q4W] 2.48 0.22 2.06 2.33 2.47 2.62  2.91     6619     2894    1 #> d[New 1: SEC_150] 2.08 0.23 1.64 1.92 2.08 2.23  2.54     6362     3008    1 #> d[New 1: SEC_300] 2.38 0.23 1.95 2.23 2.38 2.53  2.84     6611     3045    1 #>  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up arm-based aggregate data — set_agd_arm","title":"Set up arm-based aggregate data — set_agd_arm","text":"Set network containing arm-based aggregate data (AgD), event counts mean outcomes arm. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up arm-based aggregate data — set_agd_arm","text":"","code":"set_agd_arm(   data,   study,   trt,   y = NULL,   se = NULL,   r = NULL,   n = NULL,   E = NULL,   sample_size = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up arm-based aggregate data — set_agd_arm","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome se column data specifying standard error continuous outcome r column data specifying binary Binomial outcome count n column data specifying Binomial outcome numerator E column data specifying total time risk Poisson outcomes sample_size column data giving sample size arm. Optional, see details. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up arm-based aggregate data — set_agd_arm","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up arm-based aggregate data — set_agd_arm","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). sample_size argument optional, specified: Enables automatic centering predictors (center = TRUE) nma() regression model given network combining IPD AgD Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Nodes plot.nma_data() may weighted sample size Binomial outcome specified sample_size omitted, n used sample size default. Multinomial outcome specified sample_size omitted, sample size determined automatically supplied counts default. arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up arm-based aggregate data — set_agd_arm","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected   # Plot network plot(smk_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up contrast-based aggregate data — set_agd_contrast","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"Set network containing contrast-based aggregate data (AgD), .e. summaries relative effects treatments log Odds Ratios. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"","code":"set_agd_contrast(   data,   study,   trt,   y = NULL,   se = NULL,   sample_size = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome se column data specifying standard error continuous outcome sample_size column data giving sample size arm. Optional, see details. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"study single reference/baseline treatment, relative effects arm(s) given. reference arm, include data row continuous outcome y equal NA. study three arms (two relative effects), set standard error se reference arm data row equal standard error mean outcome reference arm (determines covariance relative effects, expressed differences mean outcomes arms). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year) default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). sample_size argument optional, specified: Enables automatic centering predictors (center = TRUE) nma() regression model given network combining IPD AgD Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Nodes plot.nma_data() may weighted sample size","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"","code":"# Set up network of Parkinson's contrast data head(parkinsons) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718  park_net <- set_agd_contrast(parkinsons,                              study = studyn,                              trt = trtn,                              y = diff,                              se = se_diff,                              sample_size = n)  # Print details park_net #> A network with 7 AgD studies (contrast-based). #>  #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected  # Plot network plot(park_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up aggregate survival data — set_agd_surv","title":"Set up aggregate survival data — set_agd_surv","text":"Set network containing aggregate survival data (AgD) form event/censoring times (e.g. reconstructed digitized Kaplan-Meier curves) covariate summary statistics study. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up aggregate survival data — set_agd_surv","text":"","code":"set_agd_surv(   data,   study,   trt,   Surv,   covariates = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up aggregate survival data — set_agd_surv","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors Surv column data specifying survival time--event outcome, using Surv() function. Right/left/interval censoring left truncation (delayed entry) supported. covariates data frame covariate summary statistics study study arm, corresponding study trt columns match data trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up aggregate survival data — set_agd_surv","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up aggregate survival data — set_agd_surv","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up aggregate survival data — set_agd_surv","text":"","code":"## Newly diagnosed multiple myeloma  head(ndmm_agd)  # Reconstructed Kaplan-Meier data #>        study     studyf trt trtf eventtime status #> 1 Morgan2012 Morgan2012 Pbo  Pbo  18.72575      1 #> 2 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 3 Morgan2012 Morgan2012 Pbo  Pbo  34.35726      1 #> 4 Morgan2012 Morgan2012 Pbo  Pbo  10.77826      1 #> 5 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 6 Morgan2012 Morgan2012 Pbo  Pbo  14.52966      1 ndmm_agd_covs   # Summary covariate information on each arm #>         study      studyf  trt trtf sample_size  age_min age_iqr_l age_median #> 1 Jackson2019 Jackson2019  Len  Len        1137 17.28246  59.13164   65.76766 #> 2 Jackson2019 Jackson2019  Pbo  Pbo         864 21.18572  58.30991   65.47402 #> 3  Morgan2012  Morgan2012  Pbo  Pbo         410 33.88979  58.05696   64.15999 #> 4  Morgan2012  Morgan2012 Thal Thal         408 38.45127  59.30022   65.48736 #>   age_iqr_h  age_max age_mean   age_sd iss_stage3 response_cr_vgpr      male #> 1  72.00756 85.76095 65.16867 8.936962  0.2480211        0.8258575 0.6165347 #> 2  71.80261 86.23080 64.62894 9.399272  0.1921296        0.8310185 0.6215278 #> 3  70.44791 84.79372 63.92360 9.006311  0.3634146        0.7170732 0.6195122 #> 4  71.73597 84.69365 65.59387 8.384686  0.3186275        0.7450980 0.6151961  set_agd_surv(ndmm_agd,              study = studyf,              trt = trtf,              Surv = Surv(eventtime, status),              covariates = ndmm_agd_covs) #> A network with 2 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study       Treatment arms #>  Jackson2019 2: Pbo | Len   #>  Morgan2012  2: Pbo | Thal  #>  #>  Outcome type: survival #> ------------------------------------------------------------------------------------ #> Total number of treatments: 3 #> Total number of studies: 2 #> Reference treatment is: Pbo #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up individual patient data — set_ipd","title":"Set up individual patient data — set_ipd","text":"Set network containing individual patient data (IPD). Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up individual patient data — set_ipd","text":"","code":"set_ipd(   data,   study,   trt,   y = NULL,   r = NULL,   E = NULL,   Surv = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up individual patient data — set_ipd","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome r column data specifying binary outcome Poisson outcome count E column data specifying total time risk Poisson outcomes Surv column data specifying survival time--event outcome, using Surv() function. Right/left/interval censoring left truncation (delayed entry) supported. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up individual patient data — set_ipd","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up individual patient data — set_ipd","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up individual patient data — set_ipd","text":"","code":"# Set up network of plaque psoriasis IPD head(plaque_psoriasis_ipd) #>    studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  62 38.6    15.8 #> 2 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  38 23.2    28.2 #> 3 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  54 27.5    13.2 #> 4 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  44 24.6    41.0 #> 5 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  44 28.3    15.2 #> 6 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 23.6    30.4 #>    male bsa weight durnpso prevsys   psa #> 1 FALSE  13  111.2       8    TRUE  TRUE #> 2 FALSE  37   62.0       1    TRUE FALSE #> 3  TRUE  13   83.5      38    TRUE FALSE #> 4 FALSE  67   66.0       1    TRUE FALSE #> 5 FALSE  10   92.7      23    TRUE FALSE #> 6 FALSE  75   73.5      21    TRUE FALSE  pso_net <- set_ipd(plaque_psoriasis_ipd,                    study = studyc,                    trt = trtc,                    r = pasi75)  # Print network details pso_net #> A network with 4 IPD studies. #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 4 #> Reference treatment is: IXE_Q2W #> Network is connected  # Plot network plot(pso_net)   # Setting a different reference treatment set_ipd(plaque_psoriasis_ipd,         study = studyc,         trt = trtc,         r = pasi75,         trt_ref = \"PBO\") #> A network with 4 IPD studies. #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":null,"dir":"Reference","previous_headings":"","what":"Smoking cessation data — smoking","title":"Smoking cessation data — smoking","text":"Data frame containing results 24 trials 4 smoking cessation treatments (Hasselblad 1998; Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smoking cessation data — smoking","text":"","code":"smoking"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Smoking cessation data — smoking","text":"data frame 50 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Smoking cessation data — smoking","text":"Dias S, Welton NJ, Sutton AJ, Caldwell DM, Lu G, Ades AE (2011). “NICE DSU Technical Support Document 4: Inconsistency networks evidence based randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Hasselblad V (1998). “Meta-analysis Multitreatment Studies.” Medical Decision Making, 18(1), 37--43. doi:10.1177/0272989x9801800110 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/stan_nma-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The stan_nma class — stan_nma-class","title":"The stan_nma class — stan_nma-class","text":"stan_nma stan_mlnmr classes contains results running model function nma().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/stan_nma-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The stan_nma class — stan_nma-class","text":"Objects class stan_nma stan_mlnmr following components: network network data model run (class nma_data stan_nma, class mlnmr_data stan_mlnmr) stanfit stanfit object returned calling sampling() model trt_effects Whether fixed random effects used (character string) consistency consistency/inconsistency model used (character string) regression regression model used (formula) class_interactions treatment classes regression model specified, model used interactions within class (common, exchangeable, independent) xbar named vector values used centering likelihood likelihood used (character string) link link function used (character string) priors list containing priors used (nma_prior objects) basis mspline pexp models, named list spline bases study stan_mlnmr sub-class inherits stan_nma, differs class network object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":null,"dir":"Reference","previous_headings":"","what":"Statins for cholesterol lowering — statins","title":"Statins for cholesterol lowering — statins","text":"Data frame containing results 19 trials comparing statins placebo usual care (Dias et al. 2011) . number deaths (-cause mortality) recorded. studies aim primary prevention (patients previous heart disease), others aim secondary prevention (patients previous heart disease).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statins for cholesterol lowering — statins","text":"","code":"statins"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Statins for cholesterol lowering — statins","text":"data frame 38 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name prevention primary secondary prevention study r number deaths n sample size","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Statins for cholesterol lowering — statins","text":"Dias S, Sutton AJ, Welton NJ, Ades AE (2011). “NICE DSU Technical Support Document 3: Heterogeneity: subgroups, meta-regression, bias bias-adjustment.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"Posterior summaries node-splitting models (nma_nodesplit nma_nodesplit_df objects) can produced using summary() method, plotted using plot() method.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"","code":"# S3 method for nma_nodesplit_df summary(   object,   consistency = NULL,   ...,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975) )  # S3 method for nma_nodesplit summary(   object,   consistency = NULL,   ...,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975) )  # S3 method for nma_nodesplit plot(x, consistency = NULL, ...)  # S3 method for nma_nodesplit_df plot(x, consistency = NULL, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"consistency Optional, stan_nma object corresponding fitted consistency model, display network estimates alongside direct indirect estimates. fitted consistency model present nma_nodesplit_df object used present (see get_nodesplits()). ... Additional arguments passed methods probs Numeric vector specifying quantiles interest, default c(0.025, 0.25, 0.5, 0.75, 0.975) x, object nma_nodesplit nma_nodesplit_df object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"nodesplit_summary object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"plot() method shortcut plot(summary(nma_nodesplit)). details plotting options, see plot.nodesplit_summary().","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"","code":"# \\donttest{ # Run smoking node-splitting example if not already available if (!exists(\"smk_fit_RE_nodesplit\")) example(\"example_smk_nodesplit\", run.donttest = TRUE) # } # \\donttest{ # Summarise the node-splitting results summary(smk_fit_RE_nodesplit) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.09 0.43  0.27  0.81  1.08 1.36  1.98     1817     2155    1 #> d_dir            1.08 0.77 -0.34  0.56  1.04 1.57  2.76     3665     2342    1 #> d_ind            1.13 0.55  0.09  0.77  1.11 1.48  2.21     1928     2360    1 #> omega           -0.04 0.91 -1.85 -0.65 -0.08 0.53  1.83     2544     2154    1 #> tau              0.87 0.21  0.55  0.72  0.84 0.98  1.34     1019     1538    1 #> tau_consistency  0.84 0.18  0.55  0.71  0.82 0.95  1.25     1440     2021    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.5 #>  #> Bayesian p-value: 0.92 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.84 0.23  0.39  0.68 0.83 0.98  1.33     1005     1385    1 #> d_dir           0.88 0.26  0.40  0.71 0.86 1.04  1.41     1842     2451    1 #> d_ind           0.59 0.67 -0.70  0.16 0.57 1.01  1.97     1554     2014    1 #> omega           0.28 0.70 -1.11 -0.14 0.30 0.74  1.59     1660     1866    1 #> tau             0.85 0.20  0.55  0.71 0.83 0.96  1.30      995     1603    1 #> tau_consistency 0.84 0.18  0.55  0.71 0.82 0.95  1.25     1440     2021    1 #>  #> Residual deviance: 54.6 (on 50 data points) #>                pD: 44.6 #>               DIC: 99.2 #>  #> Bayesian p-value: 0.65 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.48 0.40 -0.27  0.21  0.49 0.74  1.30     2095     2635    1 #> d_dir            0.34 0.54 -0.69  0.00  0.33 0.68  1.44     3060     2594    1 #> d_ind            0.69 0.63 -0.50  0.28  0.67 1.09  1.99     1943     2631    1 #> omega           -0.35 0.82 -1.95 -0.87 -0.36 0.18  1.29     1973     2374    1 #> tau              0.86 0.19  0.57  0.73  0.84 0.97  1.29     1370     2052    1 #> tau_consistency  0.84 0.18  0.55  0.71  0.82 0.95  1.25     1440     2021    1 #>  #> Residual deviance: 54.2 (on 50 data points) #>                pD: 44.6 #>               DIC: 98.8 #>  #> Bayesian p-value: 0.66 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.26 0.41 -1.08 -0.51 -0.25  0.00  0.52     2621     2732    1 #> d_dir           -0.12 0.48 -1.05 -0.43 -0.11  0.19  0.81     3552     3113    1 #> d_ind           -0.54 0.60 -1.75 -0.93 -0.54 -0.15  0.65     1674     1981    1 #> omega            0.42 0.67 -0.88  0.00  0.40  0.87  1.78     1676     1701    1 #> tau              0.86 0.19  0.56  0.73  0.84  0.97  1.30      905     1487    1 #> tau_consistency  0.84 0.18  0.55  0.71  0.82  0.95  1.25     1440     2021    1 #>  #> Residual deviance: 54.4 (on 50 data points) #>                pD: 44.6 #>               DIC: 99 #>  #> Bayesian p-value: 0.51 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.61 0.49 -1.57 -0.93 -0.60 -0.29  0.32     2840     2576    1 #> d_dir           -0.61 0.67 -1.96 -1.04 -0.60 -0.16  0.68     3880     3087    1 #> d_ind           -0.62 0.66 -2.00 -1.03 -0.60 -0.17  0.66     2114     2351    1 #> omega            0.01 0.87 -1.72 -0.56  0.01  0.55  1.80     2224     2511    1 #> tau              0.86 0.19  0.57  0.73  0.84  0.97  1.32     1038     1627    1 #> tau_consistency  0.84 0.18  0.55  0.71  0.82  0.95  1.25     1440     2021    1 #>  #> Residual deviance: 54 (on 50 data points) #>                pD: 44.2 #>               DIC: 98.2 #>  #> Bayesian p-value: 0.99 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.35 0.41 -1.15 -0.62 -0.36 -0.08  0.47     2343     2619 1.00 #> d_dir            0.07 0.65 -1.20 -0.34  0.06  0.49  1.38     3573     3185 1.00 #> d_ind           -0.61 0.53 -1.67 -0.95 -0.59 -0.26  0.40     1634     2009 1.00 #> omega            0.68 0.80 -0.85  0.15  0.67  1.18  2.27     1982     2413 1.00 #> tau              0.86 0.19  0.56  0.72  0.83  0.96  1.31     1195     1716 1.01 #> tau_consistency  0.84 0.18  0.55  0.71  0.82  0.95  1.25     1440     2021 1.00 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44 #>               DIC: 97.6 #>  #> Bayesian p-value: 0.38  # Plot the node-splitting results plot(smk_fit_RE_nodesplit)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of prior distributions — summary.nma_prior","title":"Summary of prior distributions — summary.nma_prior","text":"Print summary prior distribution details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of prior distributions — summary.nma_prior","text":"","code":"# S3 method for nma_prior summary(object, ..., probs = c(0.5, 0.95), digits = 2, trunc = NULL)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of prior distributions — summary.nma_prior","text":"object Prior distribution nma_prior object ... Additional arguments, used probs Numeric vector probabilities calculate prior intervals digits Number digits display trunc Optional numeric vector length 2, giving truncation limits prior distribution. Useful real-valued prior assigned positive-valued parameter, trunc = c(0, Inf) give correct prior intervals. default, truncation used.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of prior distributions — summary.nma_prior","text":"data frame returned invisibly, giving prior intervals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of prior distributions — summary.nma_prior","text":"","code":"summary(normal(location = 0, scale = 1)) #> A Normal prior distribution: location = 0, scale = 1. #> 50% of the prior density lies between -0.67 and 0.67. #> 95% of the prior density lies between -1.96 and 1.96. summary(half_normal(scale = 1)) #> A half-Normal prior distribution: location = 0, scale = 1. #> 50% of the prior density lies between 0 and 0.67. #> 95% of the prior density lies between 0 and 1.96. summary(log_normal(location = -3.93, scale = 1.51)) #> A log-Normal prior distribution: location = -3.93, scale = 1.51. #> 50% of the prior density lies between 0.01 and 0.05. #> 95% of the prior density lies between 0 and 0.38.  # Truncation limits may be set, for example to restrict a prior to positive values summary(normal(location = 0.5, scale = 1), trunc = c(0, Inf)) #> A Normal prior distribution: location = 0.5, scale = 1. #> 50% of the prior density lies between 0.45 and 1.44. #> 95% of the prior density lies between 0.05 and 2.61."},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior summaries from stan_nma objects — summary.stan_nma","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"Posterior summaries model parameters stan_nma objects may produced using summary() method plotted plot() method. NOTE: produce relative effects, absolute predictions, posterior ranks, see relative_effects(), predict.stan_nma(), posterior_ranks(), posterior_rank_probs().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"","code":"# S3 method for stan_nma summary(object, ..., pars, include, probs = c(0.025, 0.25, 0.5, 0.75, 0.975))  # S3 method for stan_nma plot(   x,   ...,   pars,   include,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"... Additional arguments passed methods pars, include See rstan::extract() probs Numeric vector specifying quantiles interest, default c(0.025, 0.25, 0.5, 0.75, 0.975) x, object stan_nma object stat Character string specifying ggdist plot stat use, default \"pointinterval\" orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\" ref_line Numeric vector positions reference lines, default reference lines drawn summary Logical, calculate posterior summaries? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"nma_summary object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"plot() method shortcut plot(summary(stan_nma)). details plotting options, see plot.nma_summary().","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Summary and plot of all model parameters summary(smk_fit_RE) #>                                    mean   sd  2.5%   25%   50%   75% 97.5% #> mu[1]                             -2.78 0.33 -3.48 -2.99 -2.76 -2.55 -2.15 #> mu[2]                             -2.57 0.79 -4.19 -3.07 -2.56 -2.06 -1.06 #> mu[3]                             -2.14 0.12 -2.39 -2.23 -2.14 -2.06 -1.92 #> mu[4]                             -4.05 0.59 -5.28 -4.41 -4.00 -3.63 -3.03 #> mu[5]                             -2.16 0.14 -2.43 -2.25 -2.15 -2.06 -1.88 #> mu[6]                             -3.42 0.74 -5.06 -3.88 -3.36 -2.90 -2.13 #> mu[7]                             -3.04 0.45 -4.02 -3.31 -3.00 -2.72 -2.23 #> mu[8]                             -2.71 0.60 -3.99 -3.10 -2.69 -2.30 -1.64 #> mu[9]                             -1.85 0.42 -2.71 -2.13 -1.83 -1.56 -1.06 #> mu[10]                            -2.08 0.12 -2.33 -2.16 -2.08 -2.00 -1.85 #> mu[11]                            -3.62 0.23 -4.08 -3.77 -3.61 -3.46 -3.19 #> mu[12]                            -2.22 0.14 -2.49 -2.31 -2.22 -2.13 -1.96 #> mu[13]                            -2.67 0.46 -3.62 -2.97 -2.65 -2.35 -1.85 #> mu[14]                            -2.40 0.23 -2.86 -2.56 -2.40 -2.24 -1.97 #> mu[15]                            -2.68 0.75 -4.42 -3.12 -2.60 -2.15 -1.40 #> mu[16]                            -2.61 0.34 -3.32 -2.83 -2.60 -2.37 -1.99 #> mu[17]                            -2.38 0.11 -2.59 -2.45 -2.37 -2.30 -2.18 #> mu[18]                            -2.57 0.27 -3.12 -2.75 -2.56 -2.37 -2.08 #> mu[19]                            -1.90 0.12 -2.14 -1.98 -1.90 -1.82 -1.67 #> mu[20]                            -2.80 0.12 -3.05 -2.88 -2.80 -2.72 -2.56 #> mu[21]                            -1.12 0.81 -2.80 -1.61 -1.11 -0.60  0.50 #> mu[22]                            -2.37 0.88 -4.09 -2.92 -2.36 -1.81 -0.54 #> mu[23]                            -2.31 0.84 -3.98 -2.85 -2.29 -1.78 -0.67 #> mu[24]                            -2.80 0.87 -4.50 -3.35 -2.81 -2.22 -1.05 #> d[Group counselling]               1.09 0.44  0.25  0.79  1.08  1.36  2.01 #> d[Individual counselling]          0.84 0.23  0.37  0.69  0.83  0.98  1.31 #> d[Self-help]                       0.49 0.40 -0.29  0.23  0.48  0.73  1.32 #> tau                                0.84 0.19  0.54  0.71  0.82  0.95  1.28 #> delta[1: Individual counselling]   1.07 0.39  0.33  0.81  1.07  1.31  1.86 #> delta[1: Group counselling]        0.36 0.43 -0.47  0.07  0.36  0.65  1.19 #> delta[2: Self-help]                0.67 0.81 -0.93  0.14  0.66  1.18  2.35 #> delta[2: Individual counselling]   0.76 0.79 -0.77  0.24  0.76  1.25  2.39 #> delta[2: Group counselling]        0.99 0.79 -0.55  0.48  0.99  1.49  2.63 #> delta[3: Individual counselling]   2.17 0.14  1.89  2.07  2.16  2.26  2.45 #> delta[4: Individual counselling]   0.90 0.60 -0.19  0.48  0.88  1.29  2.14 #> delta[5: Individual counselling]   0.44 0.15  0.14  0.33  0.43  0.54  0.75 #> delta[6: Individual counselling]   1.72 0.74  0.41  1.21  1.65  2.17  3.29 #> delta[7: Individual counselling]   2.16 0.49  1.30  1.82  2.13  2.47  3.17 #> delta[8: Individual counselling]   1.66 0.62  0.56  1.23  1.63  2.05  2.96 #> delta[9: Individual counselling]   0.60 0.46 -0.30  0.29  0.60  0.90  1.52 #> delta[10: Self-help]               0.00 0.17 -0.33 -0.11  0.01  0.12  0.34 #> delta[11: Self-help]               0.41 0.30 -0.21  0.21  0.41  0.61  1.00 #> delta[12: Individual counselling]  0.41 0.17  0.08  0.30  0.41  0.53  0.74 #> delta[13: Individual counselling]  0.39 0.52 -0.62  0.05  0.39  0.74  1.40 #> delta[14: Individual counselling]  0.62 0.28  0.08  0.43  0.62  0.80  1.19 #> delta[15: Group counselling]       2.14 0.78  0.78  1.60  2.07  2.60  3.89 #> delta[16: Self-help]               0.65 0.40 -0.10  0.38  0.64  0.91  1.44 #> delta[17: Individual counselling]  0.55 0.14  0.29  0.46  0.55  0.65  0.82 #> delta[18: Individual counselling]  0.03 0.31 -0.56 -0.19  0.02  0.24  0.63 #> delta[19: Individual counselling] -0.19 0.17 -0.52 -0.31 -0.19 -0.07  0.14 #> delta[20: Individual counselling]  0.08 0.18 -0.29 -0.04  0.09  0.21  0.43 #> delta[21: Self-help]               0.69 0.82 -0.84  0.15  0.69  1.19  2.36 #> delta[21: Individual counselling]  0.65 0.80 -0.92  0.16  0.65  1.15  2.26 #> delta[22: Self-help]               0.28 0.87 -1.49 -0.26  0.29  0.83  1.99 #> delta[22: Group counselling]       1.25 0.88 -0.52  0.70  1.25  1.79  2.99 #> delta[23: Individual counselling]  0.66 0.82 -0.96  0.14  0.66  1.18  2.32 #> delta[23: Group counselling]       1.27 0.85 -0.40  0.73  1.24  1.80  2.97 #> delta[24: Individual counselling]  1.05 0.83 -0.58  0.49  1.02  1.58  2.74 #> delta[24: Group counselling]       0.89 0.86 -0.82  0.33  0.90  1.46  2.57 #>                                   Bulk_ESS Tail_ESS Rhat #> mu[1]                                 3611     2962    1 #> mu[2]                                 2602     2492    1 #> mu[3]                                 6693     2691    1 #> mu[4]                                 3873     2558    1 #> mu[5]                                 6330     3088    1 #> mu[6]                                 3196     2772    1 #> mu[7]                                 2962     2937    1 #> mu[8]                                 3762     2960    1 #> mu[9]                                 4419     2852    1 #> mu[10]                                7182     2444    1 #> mu[11]                                6167     2846    1 #> mu[12]                                6018     2585    1 #> mu[13]                                4552     3488    1 #> mu[14]                                4451     3033    1 #> mu[15]                                3237     2511    1 #> mu[16]                                4999     2879    1 #> mu[17]                                6069     2774    1 #> mu[18]                                4285     3341    1 #> mu[19]                                6323     2743    1 #> mu[20]                                7119     2880    1 #> mu[21]                                2957     2614    1 #> mu[22]                                2630     2450    1 #> mu[23]                                2882     2211    1 #> mu[24]                                3082     2842    1 #> d[Group counselling]                  1983     2631    1 #> d[Individual counselling]             1279     1721    1 #> d[Self-help]                          2167     2566    1 #> tau                                   1154     2195    1 #> delta[1: Individual counselling]      3714     3193    1 #> delta[1: Group counselling]           4127     3521    1 #> delta[2: Self-help]                   2687     2694    1 #> delta[2: Individual counselling]      2715     2427    1 #> delta[2: Group counselling]           2644     2425    1 #> delta[3: Individual counselling]      5876     3299    1 #> delta[4: Individual counselling]      3567     2322    1 #> delta[5: Individual counselling]      5731     3675    1 #> delta[6: Individual counselling]      3140     2558    1 #> delta[7: Individual counselling]      2773     2477    1 #> delta[8: Individual counselling]      3557     2492    1 #> delta[9: Individual counselling]      4378     3207    1 #> delta[10: Self-help]                  5708     3419    1 #> delta[11: Self-help]                  5572     3316    1 #> delta[12: Individual counselling]     5067     2494    1 #> delta[13: Individual counselling]     4399     3243    1 #> delta[14: Individual counselling]     4197     3207    1 #> delta[15: Group counselling]          2919     2082    1 #> delta[16: Self-help]                  4640     3133    1 #> delta[17: Individual counselling]     4351     3123    1 #> delta[18: Individual counselling]     4260     3187    1 #> delta[19: Individual counselling]     5110     3295    1 #> delta[20: Individual counselling]     5692     3380    1 #> delta[21: Self-help]                  3094     2713    1 #> delta[21: Individual counselling]     2874     2788    1 #> delta[22: Self-help]                  2725     2280    1 #> delta[22: Group counselling]          2635     2289    1 #> delta[23: Individual counselling]     2986     2403    1 #> delta[23: Group counselling]          2882     2562    1 #> delta[24: Individual counselling]     3425     2918    1 #> delta[24: Group counselling]          3397     3053    1 plot(smk_fit_RE)   # Summary and plot of heterogeneity tau only summary(smk_fit_RE, pars = \"tau\") #>     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau 0.84 0.19 0.54 0.71 0.82 0.95  1.28     1154     2195    1 plot(smk_fit_RE, pars = \"tau\")   # Customising plot output plot(smk_fit_RE,      pars = c(\"d\", \"tau\"),      stat = \"halfeye\",      ref_line = 0)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot theme for multinma plots — theme_multinma","title":"Plot theme for multinma plots — theme_multinma","text":"simple ggplot2 theme plots multinma package.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot theme for multinma plots — theme_multinma","text":"","code":"theme_multinma(...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot theme for multinma plots — theme_multinma","text":"... Arguments passed ggplot2::theme_light()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot theme for multinma plots — theme_multinma","text":"ggplot2 theme","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot theme for multinma plots — theme_multinma","text":"","code":"library(ggplot2) theme_set(theme_multinma())"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":null,"dir":"Reference","previous_headings":"","what":"Thrombolytic treatments data — thrombolytics","title":"Thrombolytic treatments data — thrombolytics","text":"Data frame containing results 50 trials 8 thrombolytic drugs (streptokinase, SK; alteplase, t-PA; accelerated alteplase, Acc t-PA; streptokinase plus alteplase, SK+tPA; reteplase, r-PA; tenocteplase, TNK; urokinase, UK; anistreptilase, ASPAC) plus per-cutaneous transluminal coronary angioplasty (PTCA) (Boland et al. 2003; Lu Ades 2006; Dias et al. 2011) . number deaths 30 35 days following acute myocardial infarction recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Thrombolytic treatments data — thrombolytics","text":"","code":"thrombolytics"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Thrombolytic treatments data — thrombolytics","text":"data frame 102 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Thrombolytic treatments data — thrombolytics","text":"Boland , Dundar Y, Bagust , Haycox , Hill R, Mota RM, Walley T, Dickson R (2003). “Early thrombolysis treatment acute myocardial infarction: systematic review economic evaluation.” Health Technology Assessment, 7(15). doi:10.3310/hta7150 . Dias S, Welton NJ, Sutton AJ, Caldwell DM, Lu G, Ades AE (2011). “NICE DSU Technical Support Document 4: Inconsistency networks evidence based randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Lu GB, Ades AE (2006). “Assessing evidence inconsistency mixed treatment comparisons.” Journal American Statistical Association, 101(474), 447--459. doi:10.1198/016214505000001302 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":null,"dir":"Reference","previous_headings":"","what":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"Data frame containing number deaths 6 trials comparing transfusion granulocytes (white blood cells) control (Stanworth et al. 2005) . Previously used demonstrate informative prior distributions heterogeneity variance Turner et al. (2012) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"","code":"transfusion"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"data frame 12 rows 4 variables: studyc study name trtc treatment name r total number deaths n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"Stanworth S, Massey E, Hyde C, Brunskill SJ, Navarette C, Lucas G, Marks D, Paulus U (2005). “Granulocyte transfusions treating infections patients neutropenia neutrophil dysfunction.” Cochrane Database Systematic Reviews. ISSN 1465-1858, doi:10.1002/14651858.CD005339 . Turner RM, Davey J, Clarke MJ, Thompson SG, Higgins JPT (2012). “Predicting extent heterogeneity meta-analysis, using empirical data Cochrane Database Systematic Reviews.” International Journal Epidemiology, 41(3), 818--827. doi:10.1093/ije/dys041 .","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"feature-survivaltime-to-event-models-are-now-supported-0-5-1-9000","dir":"Changelog","previous_headings":"","what":"Feature: Survival/time-to-event models are now supported","title":"multinma 0.5.1.9000","text":"set_ipd() now Surv argument specifying survival outcomes using survival::Surv(), new function set_agd_surv() sets aggregate data form event/censoring times (e.g. digitized Kaplan-Meier curves) overall covariate summaries. Left, right, interval censoring well left truncation (delayed entry) supported. available likelihoods Exponential (PH AFT forms), Weibull (PH AFT forms), Gompertz, log-Normal, log-Logistic, Gamma, Generalised Gamma, flexible M-splines baseline hazard, piecewise exponential hazards. Auxiliary parameters (e.g. shapes, spline coefficients) always stratified study respect randomisation, may stratified treatment (e.g. relax proportional hazards assumption) /additional factors using aux_by argument nma(). regression model may defined auxiliary parameters using aux_regression argument nma(), allowing non-proportionality modelled treatment /covariate effects shapes spline coefficients. predict() method produces estimates survival probabilities, hazards, cumulative hazards, mean survival times, restricted mean survival times, quantiles survival time distribution, median survival times. predictions can plotted using plot() method. geom_km() function assists plotting Kaplan-Meier curves network object, example overlay estimated survival curves. transform argument can used produce log-log plots assessing proportional hazards assumption, along cumulative hazards log survival curves. new vignette demonstrates ML-NMR survival analysis example progression-free survival autologous stem cell transplant newly diagnosed multiple myeloma, corresponding datasets ndmm_ipd, ndmm_agd, ndmm_agd_covs.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"feature-automatic-checking-of-numerical-integration-for-ml-nmr-models-0-5-1-9000","dir":"Changelog","previous_headings":"","what":"Feature: Automatic checking of numerical integration for ML-NMR models","title":"multinma 0.5.1.9000","text":"accuracy numerical integration ML-NMR models can now checked automatically, default. , half chains run n_int half n_int/2 integration points. Rhat effective sample size warnings can ascribed either: non-convergence MCMC chains, requiring increased number iterations iter nma(), ; insufficient accuracy numerical integration, requiring increased number integration points n_int add_integration(). Descriptive warning messages indicate case. feature controlled new int_check argument nma(), enabled (TRUE) default. Saving thinned cumulative integration points can now disabled int_thin = 0, now disabled default. previous default int_thin = max(n_int %/% 10, 1). can now check sufficient accuracy automatically, default number integration points n_int add_integration() lowered 64. still conservative choice, sufficient many cases; previous default 1000 excessive. result, ML-NMR models now much faster run default, due lower n_int disabling saving cumulative integration points.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"other-updates-0-5-1-9000","dir":"Changelog","previous_headings":"","what":"Other updates","title":"multinma 0.5.1.9000","text":"Feature: dic() now includes option use pV penalty instead pD. Feature: baseline aux arguments predict() can now specified name study network, use parameter estimates study prediction. Improvement: predict() now produce aggregate-level predictions sample individuals newdata ML-NMR models (previously newdata include integration points). Improvement: Compatibility future rstan versions (PR #25). Fix: plot.nma_data(), using custom layout string (e.g.  data frame layout coordinates) now works expected nudge > 0. Fix: Documentation corrections (PR #24).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-051","dir":"Changelog","previous_headings":"","what":"multinma 0.5.1","title":"multinma 0.5.1","text":"CRAN release: 2023-05-24 Fix: Now compatible latest StanHeaders v2.26.25 (fixes #23) Fix: Dealt various tidyverse deprecations Fix: Updated TSD URLs (thanks @ndunnewind)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-050","dir":"Changelog","previous_headings":"","what":"multinma 0.5.0","title":"multinma 0.5.0","text":"CRAN release: 2022-08-29 Feature: Treatment labels network plots can now nudged away nodes weight_nodes = TRUE, using new nudge argument plot.nma_data() (#15). Feature: data frame returned calling as_tibble() .data.frame() nma_summary object (relative effects predictions) now includes columns corresponding treatment (.trt) contrast (.trta .trtb), .category column may included multinomial models. Previously details present part parameter column Feature: Added log t prior distribution log_student_t(), can used positive-valued parameters (e.g. heterogeneity variance). Improvement: set_agd_contrast() now produces informative error message covariance matrix implied se column positive definite. Previously checked Stan calling nma() function. Improvement: Updated plaque psoriasis ML-NMR vignette include new analyses, including assessing assumptions population adjustment synthesising multinomial outcomes. Improvement: Improved behaviour .trtclass special regression formulas, now main effects .trtclass always removed since collinear .trt. allows expansion interactions * work properly, e.g. ~variable*.trtclass, whereas previously resulted -parametrised model. Fix: CRAN check note manual HTML5 compatibility. Fix: Residual deviance log likelihood parameters now named correctly contrast-based aggregate data present (PR #19).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-042","dir":"Changelog","previous_headings":"","what":"multinma 0.4.2","title":"multinma 0.4.2","text":"CRAN release: 2022-03-02 Fix: Error get_nodesplits() studies multiple arms treatment. Fix: print.nma_data() now prints repeated arms studies multiple arms treatment. Fix: CRAN warning regarding invalid img tag height attribute documentation.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-041","dir":"Changelog","previous_headings":"","what":"multinma 0.4.1","title":"multinma 0.4.1","text":"CRAN release: 2022-02-04 Fix: tidyr v1.2.0 breaks ordered multinomial models studies report categories (.e. multinomial category outcomes NA multi()) (PR #11)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-040","dir":"Changelog","previous_headings":"","what":"multinma 0.4.0","title":"multinma 0.4.0","text":"CRAN release: 2022-01-18 Feature: Node-splitting models assessing inconsistency now available consistency = \"nodesplit\" nma(). Comparisons split can chosen using nodesplit argument, default possibly inconsistent comparisons chosen using get_nodesplits(). Node-splitting results can summarised summary.nma_nodesplit() plotted plot.nodesplit_summary(). Feature: correlation matrix generating integration points add_integration() ML-NMR models now adjusted underlying Gaussian copula, output correlations integration points better match requested input correlations. new argument cor_adjust controls behaviour, options \"spearman\", \"pearson\", \"none\". Although correlations typically little impact results, strict reproducibility old behaviour version 0.3.0 available cor_adjust = \"legacy\". Feature: random effects models, predictive distribution relative/absolute effects new study can now obtained relative_effects() predict.stan_nma() respectively, using new argument predictive_distribution = TRUE. Feature: Added option calculate SUCRA values summarising posterior treatment ranks posterior_ranks() posterior_rank_probs(), argument sucra = TRUE. Improvement: Factor order now respected trt, study, trt_class factors, previously order levels reset natural sort order. Improvement: Update package website Bootstrap 5 release pkgdown 2.0.0 Fix: Model fitting now robust non-default settings options(\"contrasts\"). Fix: plot.nma_data() longer gives ggplot deprecation warning (PR #6). Fix: Bug predict.stan_nma() single covariate newdata data.frame (PR #7). Fix: Attempting call predict.stan_nma() regression model contrast data newdata baseline specified now throws descriptive error message.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-030","dir":"Changelog","previous_headings":"","what":"multinma 0.3.0","title":"multinma 0.3.0","text":"CRAN release: 2021-03-18 Feature: Added baseline_type baseline_level arguments predict.stan_nma(), allow baseline distributions specified response linear predictor scale, individual aggregate level. Feature: baseline argument predict.stan_nma() can now accept (named) list baseline distributions newdata contains multiple studies. Improvement: Misspecified newdata arguments functions like relative_effects() predict.stan_nma() now give informative error messages. Fix: Constructing models contrast-based data previously gave errors scenarios (ML-NMR models, UME models, cases AgD meta-regression models). Fix: Ensure CRAN additional checks --run-donttest run correctly.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-021","dir":"Changelog","previous_headings":"","what":"multinma 0.2.1","title":"multinma 0.2.1","text":"CRAN release: 2021-01-09 Fix: Producing relative effect estimates contrasts using relative_effects() all_contrasts = TRUE longer gives error regression models. Fix: Specifying covariate correlation matrix cor add_integration() required one covariate present. Improvement: Added detailed documentation likelihoods link functions available data type (likelihood link arguments nma()).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-020","dir":"Changelog","previous_headings":"","what":"multinma 0.2.0","title":"multinma 0.2.0","text":"CRAN release: 2020-12-04 Feature: set_*() functions now accept dplyr::mutate() style semantics, allowing inline variable transformations. Feature: Added ordered multinomial models, helper function multi() specifying outcomes. Accompanied new data set hta_psoriasis vignette. Feature: Implicit flat priors can now specified, parameter, using flat(). Improvement: .array.stan_nma() now much efficient, meaning many post-estimation functions also now much efficient. Improvement: plot.nma_dic() now efficient, particularly large numbers data points. Improvement: layering points producing “dev-dev” plots using plot.nma_dic() multiple data types reversed improved clarity (now AgD top IPD). Improvement: Aggregate-level predictions predict() ML-NMR / IPD regression models now calculated much memory-efficient manner. Improvement: Added overview examples given vignettes. Improvement: Network plots weight_edges = TRUE longer produce legends non-integer values number studies. Fix: plot.nma_dic() longer gives error attempting specify .width argument producing “dev-dev” plots.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-013","dir":"Changelog","previous_headings":"","what":"multinma 0.1.3","title":"multinma 0.1.3","text":"CRAN release: 2020-06-30 Format DESCRIPTION CRAN requirements","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-012","dir":"Changelog","previous_headings":"","what":"multinma 0.1.2","title":"multinma 0.1.2","text":"Wrapped long-running examples \\donttest{} instead \\dontrun{}","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-011","dir":"Changelog","previous_headings":"","what":"multinma 0.1.1","title":"multinma 0.1.1","text":"Reduced size vignettes Added methods paper reference DESCRIPTION Added zenodo DOI","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-010","dir":"Changelog","previous_headings":"","what":"multinma 0.1.0","title":"multinma 0.1.0","text":"Feature: Network plots, using plot() method nma_data objects. Feature: .igraph(), as_tbl_graph() methods nma_data objects. Feature: Produce relative effect estimates relative_effects(), posterior ranks posterior_ranks(), posterior rank probabilities posterior_rank_probs(). study-specific regression model given. Feature: Produce predictions absolute effects predict() method stan_nma objects. Feature: Plots relative effects, ranks, predictions, parameter estimates via plot.nma_summary(). Enables centering predictors (center = TRUE) nma() regression model given, replacing agd_sample_size argument nma() Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Allows nodes network plots weighted sample size Feature: Plots residual deviance contributions model “dev-dev” plots comparing residual deviance contributions two models, using plot() method nma_dic objects produced dic(). Feature: Complementary log-log (cloglog) link function link = \"cloglog\" binomial likelihoods. Feature: Option specify priors heterogeneity standard deviation, variance, precision, argument prior_het_type. Feature: Added log-Normal prior distribution. Feature: Plots prior distributions vs. posterior distributions plot_prior_posterior(). Feature: Pairs plot method pairs(). Feature: Added vignettes example analyses NICE TSDs . Fix: Random effects models even moderate numbers studies slow. now run much quickly, using sparse representation RE correlation matrix automatically enabled sparsity 90% (roughly equivalent 10 studies).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-001","dir":"Changelog","previous_headings":"","what":"multinma 0.0.1","title":"multinma 0.0.1","text":"Initial release.","code":""}]
