[{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Atrial fibrillation","text":"Whilst data patient-years risk study (E), ignore follow analysis Cooper et al. (2009), instead analysing number patients stroke (r) total (n) arm. use function set_agd_arm() set network, making sure specify treatment classes trt_class. remove WASPO study network arms zero events, study therefore contributes information. (better analysis, accounting differences patient-years risk studies, can performed specifying rate outcome r E set_agd_arm() . following code remains identical.) Plot network plot() method:","code":"af_net <- set_agd_arm(atrial_fibrillation[atrial_fibrillation$studyc != \"WASPO\", ],                        study = studyc,                       trt = trtc,                       r = r,                        n = n,                       trt_class = trt_class) af_net #> A network with 25 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                                                  #>  ACTIVE-W      2: Standard adjusted dose anti-coagulant | Low dose aspirin + copidogrel        #>  AFASAK 1      3: Standard adjusted dose anti-coagulant | Low dose aspirin | Placebo/Standa... #>  AFASAK 2      4: Standard adjusted dose anti-coagulant | Fixed dose warfarin | Fixed dose ... #>  BAATAF        2: Low adjusted dose anti-coagulant | Placebo/Standard care                     #>  BAFTA         2: Standard adjusted dose anti-coagulant | Low dose aspirin                     #>  CAFA          2: Standard adjusted dose anti-coagulant | Placebo/Standard care                #>  Chinese ATAFS 2: Standard adjusted dose anti-coagulant | Low dose aspirin                     #>  EAFT          3: Standard adjusted dose anti-coagulant | Medium dose aspirin | Placebo/Sta... #>  ESPS 2        4: Dipyridamole | Low dose aspirin | Low dose aspirin + dipyridamole | Place... #>  JAST          2: Low dose aspirin | Placebo/Standard care                                     #>  ... plus 15 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 17, in 4 classes #> Total number of studies: 25 #> Reference treatment is: Standard adjusted dose anti-coagulant #> Network is connected plot(af_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE) +    ggplot2::theme(legend.position = \"bottom\", legend.box = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Atrial fibrillation","text":"fit two (random effects) models: standard NMA model without covariates (model 1 Cooper et al. (2009)); meta-regression model adjusting proportion individuals study prior stroke, shared interaction coefficients treatment class (model 4b Cooper et al. (2009)).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"nma-with-no-covariates","dir":"Articles","previous_headings":"Meta-analysis models","what":"NMA with no covariates","title":"Example: Atrial fibrillation","text":"fit random effects model using nma() function trt_effects = \"random\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting model nma() function. increase target acceptance rate adapt_delta = 0.99 minimise divergent transition warnings. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  can compute relative effects placebo/standard care relative_effects() function trt_ref argument: estimates can easily plotted plot() method:  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. af_fit_1 <- nma(af_net,                  trt_effects = \"random\",                 prior_intercept = normal(scale = 100),                 prior_trt = normal(scale = 100),                 prior_het = half_normal(scale = 5),                 adapt_delta = 0.99) #> Note: Setting \"Standard adjusted dose anti-coagulant\" as the network reference treatment. af_fit_1 #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                  mean se_mean   sd     2.5%      25%      50% #> d[Acenocoumarol]                                -0.78    0.01 0.82    -2.47    -1.31    -0.76 #> d[Alternate day aspirin]                        -1.02    0.03 1.39    -4.21    -1.78    -0.87 #> d[Dipyridamole]                                  0.59    0.01 0.45    -0.31     0.30     0.60 #> d[Fixed dose warfarin]                           0.93    0.01 0.40     0.14     0.67     0.93 #> d[Fixed dose warfarin + low dose aspirin]        0.47    0.01 0.44    -0.38     0.18     0.47 #> d[Fixed dose warfarin + medium dose aspirin]     0.89    0.01 0.32     0.24     0.70     0.90 #> d[High dose aspirin]                             0.51    0.01 0.77    -1.01    -0.01     0.50 #> d[Indobufen]                                     0.25    0.01 0.44    -0.59    -0.04     0.25 #> d[Low adjusted dose anti-coagulant]             -0.29    0.01 0.37    -1.04    -0.54    -0.30 #> d[Low dose aspirin]                              0.62    0.00 0.22     0.20     0.48     0.62 #> d[Low dose aspirin + copidogrel]                 0.52    0.01 0.34    -0.18     0.31     0.51 #> d[Low dose aspirin + dipyridamole]               0.27    0.01 0.47    -0.67    -0.04     0.27 #> d[Medium dose aspirin]                           0.38    0.00 0.20    -0.02     0.26     0.39 #> d[Placebo/Standard care]                         0.75    0.00 0.19     0.37     0.63     0.75 #> d[Triflusal]                                     0.64    0.01 0.61    -0.54     0.23     0.63 #> d[Ximelagatran]                                 -0.07    0.00 0.26    -0.61    -0.23    -0.08 #> lp__                                         -4771.55    0.22 7.03 -4785.66 -4776.28 -4771.25 #> tau                                              0.27    0.01 0.13     0.04     0.18     0.27 #>                                                   75%    97.5% n_eff Rhat #> d[Acenocoumarol]                                -0.22     0.76  3837 1.00 #> d[Alternate day aspirin]                        -0.05     1.19  3058 1.00 #> d[Dipyridamole]                                  0.88     1.46  3089 1.00 #> d[Fixed dose warfarin]                           1.20     1.73  4029 1.00 #> d[Fixed dose warfarin + low dose aspirin]        0.75     1.32  2682 1.00 #> d[Fixed dose warfarin + medium dose aspirin]     1.10     1.50  3928 1.00 #> d[High dose aspirin]                             1.03     2.01  4243 1.00 #> d[Indobufen]                                     0.53     1.12  4288 1.00 #> d[Low adjusted dose anti-coagulant]             -0.05     0.44  3068 1.00 #> d[Low dose aspirin]                              0.76     1.04  2186 1.00 #> d[Low dose aspirin + copidogrel]                 0.73     1.22  3661 1.00 #> d[Low dose aspirin + dipyridamole]               0.58     1.18  3138 1.00 #> d[Medium dose aspirin]                           0.51     0.76  3162 1.00 #> d[Placebo/Standard care]                         0.89     1.13  1749 1.00 #> d[Triflusal]                                     1.04     1.86  3421 1.00 #> d[Ximelagatran]                                  0.09     0.44  3525 1.00 #> lp__                                         -4766.65 -4758.41  1027 1.00 #> tau                                              0.36     0.56   648 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:33:56 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(af_fit_1, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(af_fit_1, prior = c(\"trt\", \"het\")) (af_1_releff <- relative_effects(af_fit_1, trt_ref = \"Placebo/Standard care\")) #>                                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> d[Standard adjusted dose anti-coagulant]     -0.75 0.19 -1.13 -0.89 -0.75 -0.63 -0.37     1760 #> d[Acenocoumarol]                             -1.54 0.84 -3.26 -2.09 -1.50 -0.95  0.07     3694 #> d[Alternate day aspirin]                     -1.77 1.38 -5.00 -2.54 -1.61 -0.81  0.38     4107 #> d[Dipyridamole]                              -0.16 0.42 -1.01 -0.44 -0.16  0.12  0.64     4861 #> d[Fixed dose warfarin]                        0.18 0.44 -0.68 -0.12  0.18  0.47  1.04     3802 #> d[Fixed dose warfarin + low dose aspirin]    -0.29 0.39 -1.04 -0.53 -0.29 -0.04  0.51     4484 #> d[Fixed dose warfarin + medium dose aspirin]  0.14 0.37 -0.62 -0.09  0.14  0.38  0.85     3297 #> d[High dose aspirin]                         -0.25 0.76 -1.71 -0.75 -0.25  0.25  1.25     5163 #> d[Indobufen]                                 -0.51 0.47 -1.44 -0.82 -0.50 -0.21  0.46     3463 #> d[Low adjusted dose anti-coagulant]          -1.05 0.34 -1.77 -1.28 -1.04 -0.82 -0.37     5181 #> d[Low dose aspirin]                          -0.13 0.21 -0.55 -0.27 -0.13  0.00  0.27     4870 #> d[Low dose aspirin + copidogrel]             -0.24 0.39 -0.99 -0.48 -0.24  0.00  0.57     3307 #> d[Low dose aspirin + dipyridamole]           -0.49 0.44 -1.38 -0.77 -0.48 -0.20  0.35     5048 #> d[Medium dose aspirin]                       -0.37 0.22 -0.82 -0.51 -0.37 -0.23  0.05     2796 #> d[Triflusal]                                 -0.11 0.64 -1.34 -0.54 -0.12  0.30  1.16     3176 #> d[Ximelagatran]                              -0.83 0.32 -1.46 -1.04 -0.83 -0.62 -0.17     2751 #>                                              Tail_ESS Rhat #> d[Standard adjusted dose anti-coagulant]         2574    1 #> d[Acenocoumarol]                                 2776    1 #> d[Alternate day aspirin]                         2066    1 #> d[Dipyridamole]                                  3188    1 #> d[Fixed dose warfarin]                           3133    1 #> d[Fixed dose warfarin + low dose aspirin]        2775    1 #> d[Fixed dose warfarin + medium dose aspirin]     2562    1 #> d[High dose aspirin]                             2326    1 #> d[Indobufen]                                     2950    1 #> d[Low adjusted dose anti-coagulant]              3181    1 #> d[Low dose aspirin]                              3264    1 #> d[Low dose aspirin + copidogrel]                 2940    1 #> d[Low dose aspirin + dipyridamole]               3057    1 #> d[Medium dose aspirin]                           2798    1 #> d[Triflusal]                                     2936    1 #> d[Ximelagatran]                                  2221    1 plot(af_1_releff, ref_line = 0) (af_1_ranks <- posterior_ranks(af_fit_1)) #>                                                  mean   sd 2.5% 25% 50%   75% 97.5% Bulk_ESS #> rank[Standard adjusted dose anti-coagulant]      5.29 1.47    3   4   5  6.00     8     2775 #> rank[Acenocoumarol]                              2.99 3.01    1   1   2  3.00    13     3301 #> rank[Alternate day aspirin]                      3.69 4.22    1   1   2  4.00    16     5023 #> rank[Dipyridamole]                              11.31 3.77    4   9  11 15.00    17     4027 #> rank[Fixed dose warfarin]                       14.14 3.01    7  12  15 16.00    17     3848 #> rank[Fixed dose warfarin + low dose aspirin]    10.04 3.81    3   7  10 13.00    17     3686 #> rank[Fixed dose warfarin + medium dose aspirin] 14.15 2.68    7  13  15 16.00    17     3153 #> rank[High dose aspirin]                         10.23 5.28    2   5  10 15.00    17     4839 #> rank[Indobufen]                                  8.03 3.93    2   5   8 11.00    16     3761 #> rank[Low adjusted dose anti-coagulant]           3.71 2.14    1   2   3  5.00     9     3696 #> rank[Low dose aspirin]                          11.80 2.24    7  10  12 13.00    16     4130 #> rank[Low dose aspirin + copidogrel]             10.57 3.38    4   8  11 13.00    17     3589 #> rank[Low dose aspirin + dipyridamole]            8.19 3.86    2   5   8 11.00    16     4163 #> rank[Medium dose aspirin]                        9.13 2.13    5   8   9 10.25    13     3980 #> rank[Placebo/Standard care]                     13.41 1.77   10  12  14 15.00    17     3397 #> rank[Triflusal]                                 11.43 4.58    3   8  12 16.00    17     3418 #> rank[Ximelagatran]                               4.89 2.25    2   3   4  6.00    10     3089 #>                                                 Tail_ESS Rhat #> rank[Standard adjusted dose anti-coagulant]         3301    1 #> rank[Acenocoumarol]                                 2889    1 #> rank[Alternate day aspirin]                         3673    1 #> rank[Dipyridamole]                                    NA    1 #> rank[Fixed dose warfarin]                             NA    1 #> rank[Fixed dose warfarin + low dose aspirin]        3045    1 #> rank[Fixed dose warfarin + medium dose aspirin]       NA    1 #> rank[High dose aspirin]                               NA    1 #> rank[Indobufen]                                     2786    1 #> rank[Low adjusted dose anti-coagulant]              3304    1 #> rank[Low dose aspirin]                              3604    1 #> rank[Low dose aspirin + copidogrel]                 3002    1 #> rank[Low dose aspirin + dipyridamole]               3265    1 #> rank[Medium dose aspirin]                           3276    1 #> rank[Placebo/Standard care]                         3564    1 #> rank[Triflusal]                                       NA    1 #> rank[Ximelagatran]                                  2704    1 plot(af_1_ranks) (af_1_rankprobs <- posterior_rank_probs(af_fit_1)) #>                                              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[Standard adjusted dose anti-coagulant]          0.00      0.02      0.08      0.21      0.27 #> d[Acenocoumarol]                                  0.38      0.29      0.09      0.05      0.04 #> d[Alternate day aspirin]                          0.46      0.18      0.06      0.04      0.03 #> d[Dipyridamole]                                   0.00      0.01      0.02      0.02      0.03 #> d[Fixed dose warfarin]                            0.00      0.00      0.00      0.00      0.01 #> d[Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.03      0.04      0.05 #> d[Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00      0.00      0.00 #> d[High dose aspirin]                              0.02      0.06      0.06      0.06      0.05 #> d[Indobufen]                                      0.01      0.04      0.07      0.08      0.09 #> d[Low adjusted dose anti-coagulant]               0.08      0.24      0.27      0.15      0.09 #> d[Low dose aspirin]                               0.00      0.00      0.00      0.00      0.00 #> d[Low dose aspirin + copidogrel]                  0.00      0.00      0.01      0.02      0.03 #> d[Low dose aspirin + dipyridamole]                0.01      0.04      0.07      0.08      0.08 #> d[Medium dose aspirin]                            0.00      0.00      0.00      0.01      0.03 #> d[Placebo/Standard care]                          0.00      0.00      0.00      0.00      0.00 #> d[Triflusal]                                      0.00      0.02      0.04      0.04      0.04 #> d[Ximelagatran]                                   0.02      0.10      0.19      0.21      0.16 #>                                              p_rank[6] p_rank[7] p_rank[8] p_rank[9] #> d[Standard adjusted dose anti-coagulant]          0.23      0.12      0.05      0.01 #> d[Acenocoumarol]                                  0.03      0.03      0.02      0.01 #> d[Alternate day aspirin]                          0.03      0.03      0.02      0.02 #> d[Dipyridamole]                                   0.04      0.06      0.07      0.09 #> d[Fixed dose warfarin]                            0.01      0.02      0.02      0.04 #> d[Fixed dose warfarin + low dose aspirin]         0.06      0.09      0.09      0.09 #> d[Fixed dose warfarin + medium dose aspirin]      0.01      0.01      0.02      0.03 #> d[High dose aspirin]                              0.04      0.05      0.05      0.05 #> d[Indobufen]                                      0.10      0.10      0.10      0.08 #> d[Low adjusted dose anti-coagulant]               0.06      0.04      0.03      0.01 #> d[Low dose aspirin]                               0.01      0.02      0.04      0.08 #> d[Low dose aspirin + copidogrel]                  0.05      0.07      0.09      0.11 #> d[Low dose aspirin + dipyridamole]                0.09      0.11      0.10      0.09 #> d[Medium dose aspirin]                            0.06      0.11      0.18      0.19 #> d[Placebo/Standard care]                          0.00      0.00      0.00      0.01 #> d[Triflusal]                                      0.05      0.06      0.06      0.06 #> d[Ximelagatran]                                   0.12      0.09      0.06      0.03 #>                                              p_rank[10] p_rank[11] p_rank[12] p_rank[13] #> d[Standard adjusted dose anti-coagulant]           0.00       0.00       0.00       0.00 #> d[Acenocoumarol]                                   0.01       0.01       0.01       0.01 #> d[Alternate day aspirin]                           0.02       0.01       0.02       0.01 #> d[Dipyridamole]                                    0.09       0.09       0.08       0.07 #> d[Fixed dose warfarin]                             0.04       0.05       0.06       0.07 #> d[Fixed dose warfarin + low dose aspirin]          0.09       0.09       0.07       0.07 #> d[Fixed dose warfarin + medium dose aspirin]       0.04       0.05       0.06       0.08 #> d[High dose aspirin]                               0.05       0.04       0.04       0.05 #> d[Indobufen]                                       0.07       0.05       0.05       0.04 #> d[Low adjusted dose anti-coagulant]                0.01       0.01       0.00       0.00 #> d[Low dose aspirin]                                0.12       0.17       0.17       0.16 #> d[Low dose aspirin + copidogrel]                   0.10       0.11       0.09       0.09 #> d[Low dose aspirin + dipyridamole]                 0.07       0.07       0.05       0.05 #> d[Medium dose aspirin]                             0.16       0.12       0.07       0.04 #> d[Placebo/Standard care]                           0.04       0.08       0.15       0.21 #> d[Triflusal]                                       0.06       0.05       0.06       0.05 #> d[Ximelagatran]                                    0.01       0.01       0.01       0.00 #>                                              p_rank[14] p_rank[15] p_rank[16] p_rank[17] #> d[Standard adjusted dose anti-coagulant]           0.00       0.00       0.00       0.00 #> d[Acenocoumarol]                                   0.01       0.01       0.00       0.00 #> d[Alternate day aspirin]                           0.01       0.02       0.01       0.02 #> d[Dipyridamole]                                    0.09       0.09       0.09       0.07 #> d[Fixed dose warfarin]                             0.10       0.14       0.20       0.25 #> d[Fixed dose warfarin + low dose aspirin]          0.07       0.06       0.05       0.04 #> d[Fixed dose warfarin + medium dose aspirin]       0.11       0.18       0.22       0.17 #> d[High dose aspirin]                               0.05       0.06       0.08       0.17 #> d[Indobufen]                                       0.04       0.03       0.03       0.02 #> d[Low adjusted dose anti-coagulant]                0.00       0.00       0.00       0.00 #> d[Low dose aspirin]                                0.12       0.07       0.03       0.01 #> d[Low dose aspirin + copidogrel]                   0.07       0.07       0.05       0.03 #> d[Low dose aspirin + dipyridamole]                 0.04       0.03       0.03       0.01 #> d[Medium dose aspirin]                             0.01       0.01       0.00       0.00 #> d[Placebo/Standard care]                           0.23       0.16       0.09       0.03 #> d[Triflusal]                                       0.06       0.07       0.11       0.18 #> d[Ximelagatran]                                    0.00       0.00       0.00       0.00 plot(af_1_rankprobs) (af_1_cumrankprobs <- posterior_rank_probs(af_fit_1, cumulative = TRUE)) #>                                              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[Standard adjusted dose anti-coagulant]          0.00      0.02      0.10      0.30      0.58 #> d[Acenocoumarol]                                  0.38      0.67      0.76      0.81      0.86 #> d[Alternate day aspirin]                          0.46      0.65      0.71      0.75      0.78 #> d[Dipyridamole]                                   0.00      0.01      0.02      0.05      0.08 #> d[Fixed dose warfarin]                            0.00      0.00      0.00      0.01      0.01 #> d[Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.04      0.08      0.13 #> d[Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00      0.00      0.01 #> d[High dose aspirin]                              0.02      0.08      0.15      0.21      0.25 #> d[Indobufen]                                      0.01      0.05      0.13      0.21      0.30 #> d[Low adjusted dose anti-coagulant]               0.08      0.32      0.59      0.74      0.83 #> d[Low dose aspirin]                               0.00      0.00      0.00      0.00      0.00 #> d[Low dose aspirin + copidogrel]                  0.00      0.01      0.02      0.04      0.07 #> d[Low dose aspirin + dipyridamole]                0.01      0.05      0.12      0.20      0.27 #> d[Medium dose aspirin]                            0.00      0.00      0.00      0.01      0.04 #> d[Placebo/Standard care]                          0.00      0.00      0.00      0.00      0.00 #> d[Triflusal]                                      0.00      0.02      0.06      0.10      0.13 #> d[Ximelagatran]                                   0.02      0.11      0.30      0.51      0.66 #>                                              p_rank[6] p_rank[7] p_rank[8] p_rank[9] #> d[Standard adjusted dose anti-coagulant]          0.81      0.93      0.98      1.00 #> d[Acenocoumarol]                                  0.89      0.91      0.93      0.95 #> d[Alternate day aspirin]                          0.81      0.84      0.86      0.88 #> d[Dipyridamole]                                   0.12      0.17      0.24      0.33 #> d[Fixed dose warfarin]                            0.02      0.04      0.06      0.10 #> d[Fixed dose warfarin + low dose aspirin]         0.19      0.28      0.37      0.46 #> d[Fixed dose warfarin + medium dose aspirin]      0.02      0.03      0.05      0.07 #> d[High dose aspirin]                              0.30      0.35      0.41      0.46 #> d[Indobufen]                                      0.40      0.49      0.59      0.67 #> d[Low adjusted dose anti-coagulant]               0.89      0.93      0.96      0.98 #> d[Low dose aspirin]                               0.01      0.03      0.08      0.15 #> d[Low dose aspirin + copidogrel]                  0.12      0.19      0.28      0.39 #> d[Low dose aspirin + dipyridamole]                0.36      0.47      0.57      0.66 #> d[Medium dose aspirin]                            0.10      0.21      0.39      0.58 #> d[Placebo/Standard care]                          0.00      0.00      0.01      0.02 #> d[Triflusal]                                      0.18      0.24      0.30      0.36 #> d[Ximelagatran]                                   0.79      0.88      0.93      0.96 #>                                              p_rank[10] p_rank[11] p_rank[12] p_rank[13] #> d[Standard adjusted dose anti-coagulant]           1.00       1.00       1.00       1.00 #> d[Acenocoumarol]                                   0.96       0.97       0.97       0.98 #> d[Alternate day aspirin]                           0.90       0.91       0.93       0.94 #> d[Dipyridamole]                                    0.42       0.50       0.59       0.66 #> d[Fixed dose warfarin]                             0.14       0.19       0.25       0.32 #> d[Fixed dose warfarin + low dose aspirin]          0.55       0.64       0.71       0.78 #> d[Fixed dose warfarin + medium dose aspirin]       0.11       0.16       0.23       0.31 #> d[High dose aspirin]                               0.50       0.54       0.59       0.63 #> d[Indobufen]                                       0.74       0.79       0.84       0.88 #> d[Low adjusted dose anti-coagulant]                0.99       0.99       1.00       1.00 #> d[Low dose aspirin]                                0.27       0.44       0.61       0.77 #> d[Low dose aspirin + copidogrel]                   0.50       0.60       0.69       0.78 #> d[Low dose aspirin + dipyridamole]                 0.72       0.79       0.84       0.89 #> d[Medium dose aspirin]                             0.75       0.87       0.94       0.98 #> d[Placebo/Standard care]                           0.06       0.14       0.29       0.50 #> d[Triflusal]                                       0.42       0.47       0.53       0.58 #> d[Ximelagatran]                                    0.98       0.99       0.99       1.00 #>                                              p_rank[14] p_rank[15] p_rank[16] p_rank[17] #> d[Standard adjusted dose anti-coagulant]           1.00       1.00       1.00          1 #> d[Acenocoumarol]                                   0.99       0.99       1.00          1 #> d[Alternate day aspirin]                           0.95       0.97       0.98          1 #> d[Dipyridamole]                                    0.75       0.84       0.93          1 #> d[Fixed dose warfarin]                             0.41       0.55       0.75          1 #> d[Fixed dose warfarin + low dose aspirin]          0.85       0.91       0.96          1 #> d[Fixed dose warfarin + medium dose aspirin]       0.42       0.60       0.83          1 #> d[High dose aspirin]                               0.69       0.75       0.83          1 #> d[Indobufen]                                       0.92       0.95       0.98          1 #> d[Low adjusted dose anti-coagulant]                1.00       1.00       1.00          1 #> d[Low dose aspirin]                                0.89       0.96       0.99          1 #> d[Low dose aspirin + copidogrel]                   0.85       0.92       0.97          1 #> d[Low dose aspirin + dipyridamole]                 0.93       0.96       0.99          1 #> d[Medium dose aspirin]                             0.99       1.00       1.00          1 #> d[Placebo/Standard care]                           0.72       0.88       0.97          1 #> d[Triflusal]                                       0.65       0.72       0.82          1 #> d[Ximelagatran]                                    1.00       1.00       1.00          1 plot(af_1_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"network-meta-regression-adjusting-for-proportion-of-prior-stroke","dir":"Articles","previous_headings":"Meta-analysis models","what":"Network meta-regression adjusting for proportion of prior stroke","title":"Example: Atrial fibrillation","text":"now consider meta-regression model adjusting proportion individuals study prior stroke, shared interaction coefficients treatment class. regression model specified nma() function using formula regression argument. formula ~ .trt:stroke means interactions prior stroke treatment included; .trt special variable indicates treatment, stroke original data set. specify class_interactions = \"common\" denote interaction parameters common (.e. shared) treatments within class. (Setting class_interactions = \"independent\" fit model 2 Cooper et al. (2009) separate interactions treatment, data permitting.) use prior distributions , additionally require prior distribution regression coefficients prior_reg; use \\(\\mathrm{N}(0, 100^2)\\) prior distribution. QR decomposition can greatly improve efficiency sampling regression models decorrelating sampling space; specify used QR = TRUE, increase target acceptance rate adapt_delta = 0.99 minimise divergent transition warnings. Basic parameter summaries given print() method: estimated treatment effects d[] shown correspond relative effects reference level covariate, proportion prior stroke centered network mean value 0.296. default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  can compute relative effects placebo/standard care relative_effects() function trt_ref argument, default produces relative effects observed proportions prior stroke study: can produce estimated treatment effects particular covariate values using newdata argument. example, treatment effects individuals individuals prior stroke produced  estimated class interactions (reference “Mixed” class) uncertain.  interactions straightforward interpret transform interaction coefficients (using consistency equations) control class:  evidence effect anti-coagulants increases (compared control) prior stroke. little evidence effect anti-platelets reduces prior stroke, although point estimate represents substantial reduction effectiveness, 95% Credible Interval includes values correspond substantial increases treatment effect. interaction effect stroke mixed treatments uncertain, potentially indicates substantial reduction treatment effects prior stroke. can also produce treatment rankings, rank probabilities, cumulative rank probabilities. default (without newdata argument specified), produced value stroke study network turn. instead produce rankings individuals individuals prior stroke, specify newdata argument.","code":"af_fit_4b <- nma(af_net,                   trt_effects = \"random\",                  regression = ~ .trt:stroke,                  class_interactions = \"common\",                  QR = TRUE,                  prior_intercept = normal(scale = 100),                  prior_trt = normal(scale = 100),                  prior_reg = normal(scale = 100),                  prior_het = half_normal(scale = 5),                  adapt_delta = 0.99) #> Note: Setting \"Standard adjusted dose anti-coagulant\" as the network reference treatment. af_fit_4b #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:stroke. #> Centred covariates at the following overall mean values: #>    stroke  #> 0.2957377  #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                  mean se_mean   sd     2.5%      25%      50% #> beta[.trtclassControl:stroke]                    0.71    0.01 0.44    -0.13     0.43     0.71 #> beta[.trtclassAnti-platelet:stroke]              0.95    0.01 0.41     0.16     0.67     0.95 #> beta[.trtclassMixed:stroke]                      3.90    0.03 2.13    -0.16     2.47     3.82 #> d[Acenocoumarol]                                 0.36    0.02 1.02    -1.72    -0.30     0.37 #> d[Alternate day aspirin]                        -0.88    0.03 1.36    -4.05    -1.64    -0.70 #> d[Dipyridamole]                                  0.58    0.01 0.40    -0.21     0.32     0.59 #> d[Fixed dose warfarin]                           0.63    0.01 0.38    -0.12     0.38     0.63 #> d[Fixed dose warfarin + low dose aspirin]        1.45    0.01 0.76    -0.03     0.95     1.45 #> d[Fixed dose warfarin + medium dose aspirin]     1.00    0.00 0.30     0.43     0.81     1.00 #> d[High dose aspirin]                             0.43    0.01 0.72    -0.99    -0.04     0.44 #> d[Indobufen]                                    -0.42    0.01 0.49    -1.36    -0.74    -0.42 #> d[Low adjusted dose anti-coagulant]             -0.43    0.01 0.37    -1.16    -0.67    -0.42 #> d[Low dose aspirin]                              0.72    0.00 0.20     0.33     0.59     0.72 #> d[Low dose aspirin + copidogrel]                 0.65    0.01 0.28     0.11     0.49     0.65 #> d[Low dose aspirin + dipyridamole]               0.25    0.01 0.42    -0.55    -0.03     0.25 #> d[Medium dose aspirin]                           0.35    0.00 0.17     0.01     0.24     0.35 #> d[Placebo/Standard care]                         0.79    0.00 0.18     0.43     0.67     0.78 #> d[Triflusal]                                     0.93    0.01 0.58    -0.16     0.53     0.91 #> d[Ximelagatran]                                 -0.08    0.00 0.21    -0.49    -0.20    -0.08 #> lp__                                         -4771.66    0.21 7.07 -4786.20 -4776.29 -4771.38 #> tau                                              0.17    0.01 0.12     0.01     0.08     0.15 #>                                                   75%    97.5% n_eff Rhat #> beta[.trtclassControl:stroke]                    1.00     1.60  4599    1 #> beta[.trtclassAnti-platelet:stroke]              1.22     1.76  4635    1 #> beta[.trtclassMixed:stroke]                      5.29     8.17  4773    1 #> d[Acenocoumarol]                                 1.04     2.34  4462    1 #> d[Alternate day aspirin]                         0.06     1.32  2699    1 #> d[Dipyridamole]                                  0.84     1.36  5997    1 #> d[Fixed dose warfarin]                           0.89     1.40  4508    1 #> d[Fixed dose warfarin + low dose aspirin]        1.95     2.97  4606    1 #> d[Fixed dose warfarin + medium dose aspirin]     1.19     1.60  4942    1 #> d[High dose aspirin]                             0.91     1.81  6693    1 #> d[Indobufen]                                    -0.10     0.54  4997    1 #> d[Low adjusted dose anti-coagulant]             -0.18     0.30  4555    1 #> d[Low dose aspirin]                              0.85     1.10  4815    1 #> d[Low dose aspirin + copidogrel]                 0.81     1.18  2698    1 #> d[Low dose aspirin + dipyridamole]               0.53     1.06  5000    1 #> d[Medium dose aspirin]                           0.46     0.69  3871    1 #> d[Placebo/Standard care]                         0.91     1.15  4697    1 #> d[Triflusal]                                     1.31     2.08  4366    1 #> d[Ximelagatran]                                  0.04     0.33  3023    1 #> lp__                                         -4766.69 -4758.41  1097    1 #> tau                                              0.24     0.46   408    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:34:13 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(af_fit_4b, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(af_fit_4b, prior = c(\"reg\", \"het\")) # Not run (af_4b_releff <- relative_effects(af_fit_4b, trt_ref = \"Placebo/Standard care\")) plot(af_4b_releff, ref_line = 0) (af_4b_releff_01 <- relative_effects(af_fit_4b,                                       trt_ref = \"Placebo/Standard care\",                                      newdata = data.frame(stroke = c(0, 1),                                                            label = c(\"stroke = 0\", \"stroke = 1\")),                                      study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                           mean   sd  2.5%   25%   50%   75% #> d[stroke = 0: Standard adjusted dose anti-coagulant]     -0.58 0.24 -1.05 -0.73 -0.58 -0.42 #> d[stroke = 0: Acenocoumarol]                             -1.36 0.82 -3.11 -1.89 -1.34 -0.81 #> d[stroke = 0: Alternate day aspirin]                     -1.74 1.36 -4.86 -2.48 -1.56 -0.79 #> d[stroke = 0: Dipyridamole]                              -0.28 0.43 -1.17 -0.55 -0.28 -0.01 #> d[stroke = 0: Fixed dose warfarin]                        0.05 0.44 -0.81 -0.24  0.05  0.36 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]    -0.28 0.33 -0.94 -0.49 -0.28 -0.07 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin] -0.73 0.66 -2.05 -1.16 -0.72 -0.29 #> d[stroke = 0: High dose aspirin]                         -0.43 0.74 -1.93 -0.91 -0.42  0.07 #> d[stroke = 0: Indobufen]                                 -1.28 0.56 -2.37 -1.65 -1.27 -0.90 #> d[stroke = 0: Low adjusted dose anti-coagulant]          -1.00 0.33 -1.66 -1.22 -1.00 -0.79 #> d[stroke = 0: Low dose aspirin]                          -0.14 0.22 -0.56 -0.28 -0.14  0.01 #> d[stroke = 0: Low dose aspirin + copidogrel]             -0.21 0.35 -0.87 -0.43 -0.21  0.01 #> d[stroke = 0: Low dose aspirin + dipyridamole]           -0.61 0.45 -1.48 -0.91 -0.60 -0.31 #> d[stroke = 0: Medium dose aspirin]                       -0.51 0.26 -1.01 -0.68 -0.51 -0.34 #> d[stroke = 0: Triflusal]                                  0.07 0.61 -1.10 -0.35  0.05  0.48 #> d[stroke = 0: Ximelagatran]                              -0.66 0.32 -1.27 -0.87 -0.66 -0.46 #>                                                          97.5% Bulk_ESS Tail_ESS Rhat #> d[stroke = 0: Standard adjusted dose anti-coagulant]     -0.11     4265     2999    1 #> d[stroke = 0: Acenocoumarol]                              0.16     4028     2895    1 #> d[stroke = 0: Alternate day aspirin]                      0.45     3394     2102    1 #> d[stroke = 0: Dipyridamole]                               0.56     6148     2774    1 #> d[stroke = 0: Fixed dose warfarin]                        0.91     4679     2904    1 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]     0.37     4257     2502    1 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]  0.55     4377     2785    1 #> d[stroke = 0: High dose aspirin]                          1.01     6545     3306    1 #> d[stroke = 0: Indobufen]                                 -0.16     5596     3033    1 #> d[stroke = 0: Low adjusted dose anti-coagulant]          -0.38     5064     3204    1 #> d[stroke = 0: Low dose aspirin]                           0.29     4928     2829    1 #> d[stroke = 0: Low dose aspirin + copidogrel]              0.48     3386     2525    1 #> d[stroke = 0: Low dose aspirin + dipyridamole]            0.23     5139     2844    1 #> d[stroke = 0: Medium dose aspirin]                        0.00     4980     3009    1 #> d[stroke = 0: Triflusal]                                  1.30     4349     2704    1 #> d[stroke = 0: Ximelagatran]                              -0.03     3468     2268    1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                           mean   sd  2.5%   25%   50%   75% #> d[stroke = 1: Standard adjusted dose anti-coagulant]     -1.29 0.34 -1.96 -1.51 -1.30 -1.07 #> d[stroke = 1: Acenocoumarol]                              1.82 2.32 -2.80  0.25  1.78  3.35 #> d[stroke = 1: Alternate day aspirin]                     -1.51 1.37 -4.69 -2.27 -1.34 -0.59 #> d[stroke = 1: Dipyridamole]                              -0.05 0.39 -0.82 -0.30 -0.04  0.21 #> d[stroke = 1: Fixed dose warfarin]                       -0.66 0.51 -1.68 -0.99 -0.66 -0.32 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]     2.90 2.22 -1.39  1.43  2.85  4.35 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]  2.45 1.65 -0.74  1.32  2.40  3.53 #> d[stroke = 1: High dose aspirin]                         -0.20 0.70 -1.62 -0.67 -0.19  0.27 #> d[stroke = 1: Indobufen]                                 -1.05 0.51 -2.08 -1.38 -1.04 -0.71 #> d[stroke = 1: Low adjusted dose anti-coagulant]          -1.72 0.51 -2.73 -2.05 -1.72 -1.38 #> d[stroke = 1: Low dose aspirin]                           0.10 0.28 -0.47 -0.08  0.10  0.28 #> d[stroke = 1: Low dose aspirin + copidogrel]              0.03 0.38 -0.75 -0.19  0.03  0.26 #> d[stroke = 1: Low dose aspirin + dipyridamole]           -0.38 0.41 -1.19 -0.64 -0.36 -0.11 #> d[stroke = 1: Medium dose aspirin]                       -0.27 0.24 -0.76 -0.43 -0.27 -0.12 #> d[stroke = 1: Triflusal]                                  0.30 0.63 -0.95 -0.11  0.28  0.73 #> d[stroke = 1: Ximelagatran]                              -1.37 0.39 -2.13 -1.62 -1.38 -1.12 #>                                                          97.5% Bulk_ESS Tail_ESS Rhat #> d[stroke = 1: Standard adjusted dose anti-coagulant]     -0.64     4969     2795    1 #> d[stroke = 1: Acenocoumarol]                              6.43     4933     3140    1 #> d[stroke = 1: Alternate day aspirin]                      0.75     3468     2196    1 #> d[stroke = 1: Dipyridamole]                               0.73     6253     2641    1 #> d[stroke = 1: Fixed dose warfarin]                        0.36     4667     2758    1 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]     7.39     4808     2796    1 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]  5.75     5105     2994    1 #> d[stroke = 1: High dose aspirin]                          1.17     6920     3115    1 #> d[stroke = 1: Indobufen]                                 -0.07     5280     3052    1 #> d[stroke = 1: Low adjusted dose anti-coagulant]          -0.72     4900     2475    1 #> d[stroke = 1: Low dose aspirin]                           0.64     5973     2725    1 #> d[stroke = 1: Low dose aspirin + copidogrel]              0.77     3618     1945    1 #> d[stroke = 1: Low dose aspirin + dipyridamole]            0.41     5740     2775    1 #> d[stroke = 1: Medium dose aspirin]                        0.19     4689     2670    1 #> d[stroke = 1: Triflusal]                                  1.57     5015     3266    1 #> d[stroke = 1: Ximelagatran]                              -0.60     4303     3027    1 plot(af_4b_releff_01, ref_line = 0) plot(af_fit_4b, pars = \"beta\", stat = \"halfeye\", ref_line = 0) af_4b_beta <- as.array(af_fit_4b, pars = \"beta\")  # Subtract beta[Control:stroke] from the other class interactions af_4b_beta[ , , 2:3] <- sweep(af_4b_beta[ , , 2:3], 1:2,                                af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"], FUN = \"-\")  # Set beta[Anti-coagulant:stroke] = -beta[Control:stroke] af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"] <- -af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"] names(af_4b_beta)[1] <- \"beta[.trtclassAnti-coagulant:stroke]\"  # Summarise summary(af_4b_beta) #>                                       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> beta[.trtclassAnti-coagulant:stroke] -0.71 0.44 -1.60 -1.00 -0.71 -0.43  0.13     4685 #> beta[.trtclassAnti-platelet:stroke]   0.23 0.32 -0.43  0.02  0.24  0.45  0.85     6011 #> beta[.trtclassMixed:stroke]           3.18 2.18 -1.04  1.75  3.12  4.61  7.53     4906 #>                                      Tail_ESS Rhat #> beta[.trtclassAnti-coagulant:stroke]     2869    1 #> beta[.trtclassAnti-platelet:stroke]      2899    1 #> beta[.trtclassMixed:stroke]              2683    1 plot(summary(af_4b_beta), stat = \"halfeye\", ref_line = 0) (af_4b_ranks <- posterior_ranks(af_fit_4b,                                 newdata = data.frame(stroke = c(0, 1),                                                       label = c(\"stroke = 0\", \"stroke = 1\")),                                  study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                              mean   sd 2.5%   25% 50% 75% #> rank[stroke = 0: Standard adjusted dose anti-coagulant]      7.71 1.83    4  6.00   8   9 #> rank[stroke = 0: Acenocoumarol]                              3.96 3.68    1  1.00   2   5 #> rank[stroke = 0: Alternate day aspirin]                      4.11 4.58    1  1.00   2   5 #> rank[stroke = 0: Dipyridamole]                              11.12 3.69    4  8.75  11  14 #> rank[stroke = 0: Fixed dose warfarin]                       14.02 2.98    6 12.00  15  16 #> rank[stroke = 0: Fixed dose warfarin + low dose aspirin]    11.01 3.70    4  8.00  11  14 #> rank[stroke = 0: Fixed dose warfarin + medium dose aspirin]  7.27 4.60    1  3.00   6  11 #> rank[stroke = 0: High dose aspirin]                          9.61 5.25    1  5.00  10  15 #> rank[stroke = 0: Indobufen]                                  3.57 2.70    1  2.00   3   4 #> rank[stroke = 0: Low adjusted dose anti-coagulant]           4.49 2.42    1  3.00   4   5 #> rank[stroke = 0: Low dose aspirin]                          12.92 1.93    9 12.00  13  14 #> rank[stroke = 0: Low dose aspirin + copidogrel]             12.06 2.89    6 10.00  12  14 #> rank[stroke = 0: Low dose aspirin + dipyridamole]            7.79 3.65    2  5.00   7  10 #> rank[stroke = 0: Medium dose aspirin]                        8.63 2.17    5  7.00   9  10 #> rank[stroke = 0: Placebo/Standard care]                     14.29 1.88   10 13.00  15  16 #> rank[stroke = 0: Triflusal]                                 13.50 3.92    4 11.00  15  17 #> rank[stroke = 0: Ximelagatran]                               6.93 2.52    3  5.00   7   8 #>                                                             97.5% Bulk_ESS Tail_ESS Rhat #> rank[stroke = 0: Standard adjusted dose anti-coagulant]        11     4172     3418    1 #> rank[stroke = 0: Acenocoumarol]                                15     4521     3356    1 #> rank[stroke = 0: Alternate day aspirin]                        17     4540     3207    1 #> rank[stroke = 0: Dipyridamole]                                 17     5488       NA    1 #> rank[stroke = 0: Fixed dose warfarin]                          17     4421       NA    1 #> rank[stroke = 0: Fixed dose warfarin + low dose aspirin]       17     4294       NA    1 #> rank[stroke = 0: Fixed dose warfarin + medium dose aspirin]    17     4383     3131    1 #> rank[stroke = 0: High dose aspirin]                            17     6552       NA    1 #> rank[stroke = 0: Indobufen]                                    11     4497     3058    1 #> rank[stroke = 0: Low adjusted dose anti-coagulant]             11     4515     3367    1 #> rank[stroke = 0: Low dose aspirin]                             16     3462     2942    1 #> rank[stroke = 0: Low dose aspirin + copidogrel]                17     3318     2099    1 #> rank[stroke = 0: Low dose aspirin + dipyridamole]              16     4788     3219    1 #> rank[stroke = 0: Medium dose aspirin]                          13     3806     3024    1 #> rank[stroke = 0: Placebo/Standard care]                        17     3231       NA    1 #> rank[stroke = 0: Triflusal]                                    17     4627       NA    1 #> rank[stroke = 0: Ximelagatran]                                 12     3270     2289    1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                              mean   sd 2.5% 25% 50% 75% 97.5% #> rank[stroke = 1: Standard adjusted dose anti-coagulant]      3.61 1.11    2   3   4   4  6.00 #> rank[stroke = 1: Acenocoumarol]                             13.11 4.43    1  13  15  16 17.00 #> rank[stroke = 1: Alternate day aspirin]                      4.57 4.07    1   1   3   6 14.00 #> rank[stroke = 1: Dipyridamole]                              10.61 2.70    6   9  11  13 15.00 #> rank[stroke = 1: Fixed dose warfarin]                        6.98 2.72    3   5   6   8 14.00 #> rank[stroke = 1: Fixed dose warfarin + low dose aspirin]    15.71 3.02    5  16  17  17 17.00 #> rank[stroke = 1: Fixed dose warfarin + medium dose aspirin] 15.40 2.00    8  15  16  16 17.00 #> rank[stroke = 1: High dose aspirin]                          9.49 3.95    2   6   9  13 16.00 #> rank[stroke = 1: Indobufen]                                  4.95 2.14    1   4   5   6 10.00 #> rank[stroke = 1: Low adjusted dose anti-coagulant]           2.02 1.33    1   1   2   2  6.00 #> rank[stroke = 1: Low dose aspirin]                          11.93 1.81    8  11  12  13 15.00 #> rank[stroke = 1: Low dose aspirin + copidogrel]             11.20 2.36    6  10  11  13 15.00 #> rank[stroke = 1: Low dose aspirin + dipyridamole]            8.20 2.64    3   6   8  10 14.00 #> rank[stroke = 1: Medium dose aspirin]                        8.68 1.70    6   8   8  10 12.03 #> rank[stroke = 1: Placebo/Standard care]                     11.14 1.94    8  10  11  12 15.00 #> rank[stroke = 1: Triflusal]                                 12.27 3.01    6  11  13  14 17.00 #> rank[stroke = 1: Ximelagatran]                               3.13 1.35    1   2   3   4  6.00 #>                                                             Bulk_ESS Tail_ESS Rhat #> rank[stroke = 1: Standard adjusted dose anti-coagulant]         3649     3315    1 #> rank[stroke = 1: Acenocoumarol]                                 4427       NA    1 #> rank[stroke = 1: Alternate day aspirin]                         4492     2947    1 #> rank[stroke = 1: Dipyridamole]                                  5190     3430    1 #> rank[stroke = 1: Fixed dose warfarin]                           3711     3037    1 #> rank[stroke = 1: Fixed dose warfarin + low dose aspirin]        3423       NA    1 #> rank[stroke = 1: Fixed dose warfarin + medium dose aspirin]     3325       NA    1 #> rank[stroke = 1: High dose aspirin]                             5661     3010    1 #> rank[stroke = 1: Indobufen]                                     4286     3019    1 #> rank[stroke = 1: Low adjusted dose anti-coagulant]              3271     3218    1 #> rank[stroke = 1: Low dose aspirin]                              3943     3352    1 #> rank[stroke = 1: Low dose aspirin + copidogrel]                 3510     2397    1 #> rank[stroke = 1: Low dose aspirin + dipyridamole]               4593     2902    1 #> rank[stroke = 1: Medium dose aspirin]                           4089     2859    1 #> rank[stroke = 1: Placebo/Standard care]                         5326     3356    1 #> rank[stroke = 1: Triflusal]                                     4535       NA    1 #> rank[stroke = 1: Ximelagatran]                                  3117     3403    1 plot(af_4b_ranks) (af_4b_rankprobs <- posterior_rank_probs(af_fit_4b,                                          newdata = data.frame(stroke = c(0, 1),                                                                label = c(\"stroke = 0\", \"stroke = 1\")),                                           study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.00      0.00      0.01 #> d[stroke = 0: Acenocoumarol]                                  0.27      0.23      0.13 #> d[stroke = 0: Alternate day aspirin]                          0.44      0.14      0.09 #> d[stroke = 0: Dipyridamole]                                   0.00      0.01      0.01 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.00      0.00 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.01 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.05      0.10      0.11 #> d[stroke = 0: High dose aspirin]                              0.03      0.06      0.07 #> d[stroke = 0: Indobufen]                                      0.17      0.27      0.21 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.04      0.14      0.22 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.00      0.00      0.01 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.01      0.03      0.07 #> d[stroke = 0: Medium dose aspirin]                            0.00      0.00      0.00 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.00      0.00      0.01 #> d[stroke = 0: Ximelagatran]                                   0.00      0.01      0.05 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.03      0.08      0.14 #> d[stroke = 0: Acenocoumarol]                                  0.09      0.06      0.04 #> d[stroke = 0: Alternate day aspirin]                          0.06      0.04      0.03 #> d[stroke = 0: Dipyridamole]                                   0.02      0.04      0.05 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.01      0.01 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.03      0.04      0.06 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.11      0.09      0.07 #> d[stroke = 0: High dose aspirin]                              0.07      0.07      0.05 #> d[stroke = 0: Indobufen]                                      0.13      0.07      0.04 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.21      0.14      0.08 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.01      0.01      0.02 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.11      0.12      0.11 #> d[stroke = 0: Medium dose aspirin]                            0.01      0.05      0.10 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.02      0.03      0.02 #> d[stroke = 0: Ximelagatran]                                   0.10      0.15      0.17 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.20      0.22      0.15 #> d[stroke = 0: Acenocoumarol]                                  0.03      0.02      0.03 #> d[stroke = 0: Alternate day aspirin]                          0.02      0.02      0.02 #> d[stroke = 0: Dipyridamole]                                   0.06      0.06      0.07 #> d[stroke = 0: Fixed dose warfarin]                            0.02      0.02      0.03 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.05      0.06      0.08 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.06      0.05      0.05 #> d[stroke = 0: High dose aspirin]                              0.05      0.04      0.04 #> d[stroke = 0: Indobufen]                                      0.02      0.02      0.02 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.05      0.04      0.03 #> d[stroke = 0: Low dose aspirin]                               0.00      0.01      0.03 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.03      0.04      0.06 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.09      0.08      0.07 #> d[stroke = 0: Medium dose aspirin]                            0.14      0.16      0.19 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.01 #> d[stroke = 0: Triflusal]                                      0.03      0.03      0.04 #> d[stroke = 0: Ximelagatran]                                   0.16      0.12      0.09 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.10       0.04       0.02 #> d[stroke = 0: Acenocoumarol]                                   0.02       0.01       0.01 #> d[stroke = 0: Alternate day aspirin]                           0.02       0.02       0.01 #> d[stroke = 0: Dipyridamole]                                    0.09       0.10       0.10 #> d[stroke = 0: Fixed dose warfarin]                             0.04       0.05       0.07 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.08       0.10       0.10 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.05       0.05       0.05 #> d[stroke = 0: High dose aspirin]                               0.05       0.05       0.05 #> d[stroke = 0: Indobufen]                                       0.01       0.01       0.01 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.02       0.02       0.01 #> d[stroke = 0: Low dose aspirin]                                0.06       0.11       0.17 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.10       0.12       0.13 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.08       0.07       0.06 #> d[stroke = 0: Medium dose aspirin]                             0.15       0.10       0.05 #> d[stroke = 0: Placebo/Standard care]                           0.02       0.05       0.08 #> d[stroke = 0: Triflusal]                                       0.04       0.05       0.06 #> d[stroke = 0: Ximelagatran]                                    0.07       0.04       0.02 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.00       0.00       0.00 #> d[stroke = 0: Acenocoumarol]                                   0.01       0.01       0.01 #> d[stroke = 0: Alternate day aspirin]                           0.02       0.01       0.02 #> d[stroke = 0: Dipyridamole]                                    0.09       0.09       0.08 #> d[stroke = 0: Fixed dose warfarin]                             0.08       0.10       0.13 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.10       0.08       0.09 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.03       0.03       0.04 #> d[stroke = 0: High dose aspirin]                               0.05       0.05       0.06 #> d[stroke = 0: Indobufen]                                       0.01       0.00       0.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.00       0.00       0.00 #> d[stroke = 0: Low dose aspirin]                                0.21       0.19       0.14 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.14       0.12       0.10 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.04       0.03       0.03 #> d[stroke = 0: Medium dose aspirin]                             0.03       0.01       0.00 #> d[stroke = 0: Placebo/Standard care]                           0.13       0.19       0.23 #> d[stroke = 0: Triflusal]                                       0.06       0.07       0.08 #> d[stroke = 0: Ximelagatran]                                    0.01       0.01       0.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.00       0.00 #> d[stroke = 0: Acenocoumarol]                                   0.02       0.00 #> d[stroke = 0: Alternate day aspirin]                           0.02       0.03 #> d[stroke = 0: Dipyridamole]                                    0.08       0.05 #> d[stroke = 0: Fixed dose warfarin]                             0.20       0.23 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.07       0.05 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.04       0.03 #> d[stroke = 0: High dose aspirin]                               0.08       0.13 #> d[stroke = 0: Indobufen]                                       0.00       0.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.00       0.00 #> d[stroke = 0: Low dose aspirin]                                0.06       0.02 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.08       0.04 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.02       0.01 #> d[stroke = 0: Medium dose aspirin]                             0.00       0.00 #> d[stroke = 0: Placebo/Standard care]                           0.20       0.09 #> d[stroke = 0: Triflusal]                                       0.13       0.33 #> d[stroke = 0: Ximelagatran]                                    0.00       0.00 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.13      0.34 #> d[stroke = 1: Acenocoumarol]                                  0.04      0.02      0.01 #> d[stroke = 1: Alternate day aspirin]                          0.36      0.10      0.05 #> d[stroke = 1: Dipyridamole]                                   0.00      0.00      0.00 #> d[stroke = 1: Fixed dose warfarin]                            0.00      0.02      0.03 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.02      0.02      0.03 #> d[stroke = 1: Indobufen]                                      0.04      0.08      0.11 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.45      0.33      0.10 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.00      0.01      0.02 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.00      0.00 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 1: Triflusal]                                      0.00      0.00      0.00 #> d[stroke = 1: Ximelagatran]                                   0.07      0.28      0.31 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.33      0.14      0.03 #> d[stroke = 1: Acenocoumarol]                                  0.01      0.02      0.02 #> d[stroke = 1: Alternate day aspirin]                          0.07      0.09      0.09 #> d[stroke = 1: Dipyridamole]                                   0.00      0.01      0.04 #> d[stroke = 1: Fixed dose warfarin]                            0.07      0.18      0.25 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.04      0.06      0.09 #> d[stroke = 1: Indobufen]                                      0.18      0.26      0.18 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.06      0.03      0.02 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.01      0.02 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.03      0.07      0.13 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.01      0.06 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 1: Triflusal]                                      0.01      0.01      0.03 #> d[stroke = 1: Ximelagatran]                                   0.19      0.09      0.03 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.00      0.00 #> d[stroke = 1: Acenocoumarol]                                  0.02      0.02      0.02 #> d[stroke = 1: Alternate day aspirin]                          0.05      0.03      0.03 #> d[stroke = 1: Dipyridamole]                                   0.08      0.10      0.11 #> d[stroke = 1: Fixed dose warfarin]                            0.15      0.09      0.06 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.01      0.01      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.01      0.01      0.01 #> d[stroke = 1: High dose aspirin]                              0.11      0.08      0.07 #> d[stroke = 1: Indobufen]                                      0.08      0.03      0.02 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.01      0.00      0.00 #> d[stroke = 1: Low dose aspirin]                               0.01      0.02      0.06 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.04      0.07      0.11 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.19      0.16      0.11 #> d[stroke = 1: Medium dose aspirin]                            0.17      0.26      0.21 #> d[stroke = 1: Placebo/Standard care]                          0.02      0.06      0.13 #> d[stroke = 1: Triflusal]                                      0.04      0.05      0.05 #> d[stroke = 1: Ximelagatran]                                   0.01      0.00      0.00 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.01       0.01       0.02 #> d[stroke = 1: Alternate day aspirin]                           0.02       0.02       0.02 #> d[stroke = 1: Dipyridamole]                                    0.13       0.12       0.12 #> d[stroke = 1: Fixed dose warfarin]                             0.04       0.03       0.02 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.01       0.01       0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.01       0.01       0.01 #> d[stroke = 1: High dose aspirin]                               0.07       0.06       0.06 #> d[stroke = 1: Indobufen]                                       0.01       0.01       0.01 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.11       0.18       0.24 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.13       0.14       0.16 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.09       0.07       0.05 #> d[stroke = 1: Medium dose aspirin]                             0.14       0.08       0.04 #> d[stroke = 1: Placebo/Standard care]                           0.18       0.19       0.17 #> d[stroke = 1: Triflusal]                                       0.05       0.07       0.08 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00       0.00 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.02       0.04       0.44 #> d[stroke = 1: Alternate day aspirin]                           0.03       0.03       0.01 #> d[stroke = 1: Dipyridamole]                                    0.12       0.10       0.03 #> d[stroke = 1: Fixed dose warfarin]                             0.03       0.02       0.01 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.01       0.02       0.04 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.01       0.02       0.27 #> d[stroke = 1: High dose aspirin]                               0.09       0.13       0.04 #> d[stroke = 1: Indobufen]                                       0.00       0.00       0.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.21       0.11       0.04 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.16       0.11       0.03 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.04       0.02       0.01 #> d[stroke = 1: Medium dose aspirin]                             0.02       0.00       0.00 #> d[stroke = 1: Placebo/Standard care]                           0.13       0.07       0.03 #> d[stroke = 1: Triflusal]                                       0.12       0.33       0.06 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00       0.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.20       0.07 #> d[stroke = 1: Alternate day aspirin]                           0.00       0.01 #> d[stroke = 1: Dipyridamole]                                    0.01       0.01 #> d[stroke = 1: Fixed dose warfarin]                             0.00       0.00 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.19       0.65 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.48       0.17 #> d[stroke = 1: High dose aspirin]                               0.02       0.02 #> d[stroke = 1: Indobufen]                                       0.00       0.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.02       0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.02       0.01 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.00       0.00 #> d[stroke = 1: Medium dose aspirin]                             0.00       0.00 #> d[stroke = 1: Placebo/Standard care]                           0.01       0.00 #> d[stroke = 1: Triflusal]                                       0.04       0.05 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00  # Modify the default output with ggplot2 functionality library(ggplot2) plot(af_4b_rankprobs) +    facet_grid(Treatment~Study, labeller = label_wrap_gen(20)) +    theme(strip.text.y = element_text(angle = 0)) (af_4b_cumrankprobs <- posterior_rank_probs(af_fit_4b, cumulative = TRUE,                                             newdata = data.frame(stroke = c(0, 1),                                                                   label = c(\"stroke = 0\", \"stroke = 1\")),                                              study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.00      0.00      0.01 #> d[stroke = 0: Acenocoumarol]                                  0.27      0.50      0.63 #> d[stroke = 0: Alternate day aspirin]                          0.44      0.58      0.67 #> d[stroke = 0: Dipyridamole]                                   0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.00      0.00 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.05      0.15      0.26 #> d[stroke = 0: High dose aspirin]                              0.03      0.09      0.16 #> d[stroke = 0: Indobufen]                                      0.17      0.43      0.64 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.04      0.18      0.40 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.00      0.00      0.01 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.01      0.03      0.11 #> d[stroke = 0: Medium dose aspirin]                            0.00      0.00      0.00 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.00      0.00      0.01 #> d[stroke = 0: Ximelagatran]                                   0.00      0.02      0.06 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.03      0.11      0.26 #> d[stroke = 0: Acenocoumarol]                                  0.72      0.78      0.82 #> d[stroke = 0: Alternate day aspirin]                          0.73      0.77      0.79 #> d[stroke = 0: Dipyridamole]                                   0.04      0.09      0.14 #> d[stroke = 0: Fixed dose warfarin]                            0.01      0.01      0.03 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.05      0.09      0.15 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.37      0.46      0.53 #> d[stroke = 0: High dose aspirin]                              0.23      0.31      0.36 #> d[stroke = 0: Indobufen]                                      0.77      0.84      0.89 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.61      0.75      0.83 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.01      0.02      0.04 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.21      0.33      0.43 #> d[stroke = 0: Medium dose aspirin]                            0.02      0.07      0.17 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.03      0.06      0.08 #> d[stroke = 0: Ximelagatran]                                   0.16      0.31      0.48 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.46      0.68      0.83 #> d[stroke = 0: Acenocoumarol]                                  0.85      0.87      0.90 #> d[stroke = 0: Alternate day aspirin]                          0.81      0.83      0.85 #> d[stroke = 0: Dipyridamole]                                   0.19      0.25      0.32 #> d[stroke = 0: Fixed dose warfarin]                            0.04      0.06      0.09 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.20      0.26      0.34 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.59      0.64      0.68 #> d[stroke = 0: High dose aspirin]                              0.41      0.45      0.49 #> d[stroke = 0: Indobufen]                                      0.91      0.93      0.95 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.88      0.92      0.95 #> d[stroke = 0: Low dose aspirin]                               0.01      0.02      0.05 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.07      0.11      0.18 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.52      0.60      0.67 #> d[stroke = 0: Medium dose aspirin]                            0.31      0.47      0.66 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.01      0.02 #> d[stroke = 0: Triflusal]                                      0.11      0.14      0.18 #> d[stroke = 0: Ximelagatran]                                   0.63      0.75      0.84 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.93       0.98       1.00 #> d[stroke = 0: Acenocoumarol]                                   0.92       0.93       0.94 #> d[stroke = 0: Alternate day aspirin]                           0.87       0.89       0.90 #> d[stroke = 0: Dipyridamole]                                    0.41       0.51       0.61 #> d[stroke = 0: Fixed dose warfarin]                             0.14       0.19       0.26 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.42       0.52       0.61 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.73       0.78       0.83 #> d[stroke = 0: High dose aspirin]                               0.54       0.59       0.64 #> d[stroke = 0: Indobufen]                                       0.97       0.98       0.98 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.97       0.98       0.99 #> d[stroke = 0: Low dose aspirin]                                0.11       0.22       0.39 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.27       0.39       0.53 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.75       0.82       0.88 #> d[stroke = 0: Medium dose aspirin]                             0.81       0.91       0.96 #> d[stroke = 0: Placebo/Standard care]                           0.04       0.08       0.16 #> d[stroke = 0: Triflusal]                                       0.22       0.27       0.33 #> d[stroke = 0: Ximelagatran]                                    0.91       0.95       0.98 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 0: Acenocoumarol]                                   0.96       0.97       0.98 #> d[stroke = 0: Alternate day aspirin]                           0.92       0.93       0.95 #> d[stroke = 0: Dipyridamole]                                    0.70       0.78       0.87 #> d[stroke = 0: Fixed dose warfarin]                             0.35       0.44       0.58 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.71       0.79       0.88 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.86       0.90       0.93 #> d[stroke = 0: High dose aspirin]                               0.69       0.73       0.79 #> d[stroke = 0: Indobufen]                                       0.99       0.99       1.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 0: Low dose aspirin]                                0.60       0.79       0.92 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.66       0.78       0.88 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.92       0.95       0.97 #> d[stroke = 0: Medium dose aspirin]                             0.98       1.00       1.00 #> d[stroke = 0: Placebo/Standard care]                           0.29       0.48       0.71 #> d[stroke = 0: Triflusal]                                       0.39       0.46       0.54 #> d[stroke = 0: Ximelagatran]                                    0.99       0.99       1.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           1.00          1 #> d[stroke = 0: Acenocoumarol]                                   1.00          1 #> d[stroke = 0: Alternate day aspirin]                           0.97          1 #> d[stroke = 0: Dipyridamole]                                    0.95          1 #> d[stroke = 0: Fixed dose warfarin]                             0.77          1 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.95          1 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.97          1 #> d[stroke = 0: High dose aspirin]                               0.87          1 #> d[stroke = 0: Indobufen]                                       1.00          1 #> d[stroke = 0: Low adjusted dose anti-coagulant]                1.00          1 #> d[stroke = 0: Low dose aspirin]                                0.98          1 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.96          1 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.99          1 #> d[stroke = 0: Medium dose aspirin]                             1.00          1 #> d[stroke = 0: Placebo/Standard care]                           0.91          1 #> d[stroke = 0: Triflusal]                                       0.67          1 #> d[stroke = 0: Ximelagatran]                                    1.00          1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.14      0.48 #> d[stroke = 1: Acenocoumarol]                                  0.04      0.06      0.07 #> d[stroke = 1: Alternate day aspirin]                          0.36      0.46      0.51 #> d[stroke = 1: Dipyridamole]                                   0.00      0.00      0.00 #> d[stroke = 1: Fixed dose warfarin]                            0.00      0.02      0.05 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.02 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.02      0.04      0.07 #> d[stroke = 1: Indobufen]                                      0.04      0.12      0.22 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.45      0.78      0.87 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.00      0.01      0.03 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.00      0.00 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 1: Triflusal]                                      0.00      0.00      0.01 #> d[stroke = 1: Ximelagatran]                                   0.07      0.36      0.66 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.82      0.96      0.99 #> d[stroke = 1: Acenocoumarol]                                  0.09      0.11      0.13 #> d[stroke = 1: Alternate day aspirin]                          0.57      0.66      0.75 #> d[stroke = 1: Dipyridamole]                                   0.01      0.02      0.06 #> d[stroke = 1: Fixed dose warfarin]                            0.11      0.29      0.54 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.02      0.03      0.04 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.01      0.01      0.01 #> d[stroke = 1: High dose aspirin]                              0.10      0.17      0.26 #> d[stroke = 1: Indobufen]                                      0.40      0.66      0.84 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.94      0.97      0.99 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.01      0.03 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.05      0.12      0.26 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.01      0.07 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 1: Triflusal]                                      0.01      0.02      0.05 #> d[stroke = 1: Ximelagatran]                                   0.86      0.95      0.98 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          1.00      1.00      1.00 #> d[stroke = 1: Acenocoumarol]                                  0.15      0.17      0.19 #> d[stroke = 1: Alternate day aspirin]                          0.80      0.83      0.86 #> d[stroke = 1: Dipyridamole]                                   0.14      0.24      0.35 #> d[stroke = 1: Fixed dose warfarin]                            0.69      0.78      0.84 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.05      0.06      0.07 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.02      0.03      0.04 #> d[stroke = 1: High dose aspirin]                              0.37      0.44      0.51 #> d[stroke = 1: Indobufen]                                      0.91      0.95      0.96 #> d[stroke = 1: Low adjusted dose anti-coagulant]               1.00      1.00      1.00 #> d[stroke = 1: Low dose aspirin]                               0.01      0.03      0.09 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.07      0.13      0.24 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.45      0.61      0.72 #> d[stroke = 1: Medium dose aspirin]                            0.24      0.51      0.72 #> d[stroke = 1: Placebo/Standard care]                          0.02      0.08      0.21 #> d[stroke = 1: Triflusal]                                      0.09      0.14      0.20 #> d[stroke = 1: Ximelagatran]                                   1.00      1.00      1.00 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 1: Acenocoumarol]                                   0.20       0.22       0.23 #> d[stroke = 1: Alternate day aspirin]                           0.88       0.90       0.92 #> d[stroke = 1: Dipyridamole]                                    0.48       0.60       0.73 #> d[stroke = 1: Fixed dose warfarin]                             0.88       0.92       0.94 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.08       0.09       0.09 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.04       0.05       0.06 #> d[stroke = 1: High dose aspirin]                               0.58       0.63       0.70 #> d[stroke = 1: Indobufen]                                       0.98       0.99       0.99 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 1: Low dose aspirin]                                0.20       0.38       0.61 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.37       0.51       0.67 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.81       0.88       0.93 #> d[stroke = 1: Medium dose aspirin]                             0.86       0.94       0.98 #> d[stroke = 1: Placebo/Standard care]                           0.39       0.58       0.76 #> d[stroke = 1: Triflusal]                                       0.25       0.32       0.40 #> d[stroke = 1: Ximelagatran]                                    1.00       1.00       1.00 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 1: Acenocoumarol]                                   0.26       0.30       0.73 #> d[stroke = 1: Alternate day aspirin]                           0.95       0.98       0.99 #> d[stroke = 1: Dipyridamole]                                    0.85       0.95       0.98 #> d[stroke = 1: Fixed dose warfarin]                             0.97       0.99       0.99 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.10       0.12       0.16 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.07       0.08       0.35 #> d[stroke = 1: High dose aspirin]                               0.79       0.92       0.96 #> d[stroke = 1: Indobufen]                                       1.00       1.00       1.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 1: Low dose aspirin]                                0.83       0.94       0.98 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.84       0.94       0.98 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.97       0.98       0.99 #> d[stroke = 1: Medium dose aspirin]                             0.99       1.00       1.00 #> d[stroke = 1: Placebo/Standard care]                           0.89       0.96       0.98 #> d[stroke = 1: Triflusal]                                       0.52       0.85       0.91 #> d[stroke = 1: Ximelagatran]                                    1.00       1.00       1.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00          1 #> d[stroke = 1: Acenocoumarol]                                   0.93          1 #> d[stroke = 1: Alternate day aspirin]                           0.99          1 #> d[stroke = 1: Dipyridamole]                                    0.99          1 #> d[stroke = 1: Fixed dose warfarin]                             1.00          1 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.35          1 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.83          1 #> d[stroke = 1: High dose aspirin]                               0.98          1 #> d[stroke = 1: Indobufen]                                       1.00          1 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00          1 #> d[stroke = 1: Low dose aspirin]                                1.00          1 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.99          1 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 1.00          1 #> d[stroke = 1: Medium dose aspirin]                             1.00          1 #> d[stroke = 1: Placebo/Standard care]                           1.00          1 #> d[stroke = 1: Triflusal]                                       0.95          1 #> d[stroke = 1: Ximelagatran]                                    1.00          1  plot(af_4b_cumrankprobs) +    facet_grid(Treatment~Study, labeller = label_wrap_gen(20)) +    theme(strip.text.y = element_text(angle = 0))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: Atrial fibrillation","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC slightly lower meta-regression model, although couple points (substantial differences usually considered 3-5 points). estimated heterogeneity standard deviation much lower meta-regression model, suggesting adjusting proportion patients prior stroke explaining heterogeneity data. can also examine residual deviance contributions corresponding plot() method.","code":"(af_dic_1 <- dic(af_fit_1)) #> Residual deviance: 59.9 (on 61 data points) #>                pD: 48 #>               DIC: 107.9 (af_dic_4b <- dic(af_fit_4b)) #> Residual deviance: 58.7 (on 61 data points) #>                pD: 48.2 #>               DIC: 106.9 plot(af_dic_1) plot(af_dic_4b)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: BCG vaccine for tuberculosis","text":"data giving number diagnosed TB trial follow-(r) total (n) arm, use function set_agd_arm() set network. set “unvaccinated” network reference treatment. latitude variable bcg_vaccine data frame automatically available use meta-regression model.","code":"bcg_net <- set_agd_arm(bcg_vaccine,                         study = studyn,                        trt = trtc,                        r = r,                         n = n,                        trt_ref = \"Unvaccinated\") bcg_net #> A network with 13 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms               #>  1     2: Unvaccinated | Vaccinated #>  2     2: Unvaccinated | Vaccinated #>  3     2: Unvaccinated | Vaccinated #>  4     2: Unvaccinated | Vaccinated #>  5     2: Unvaccinated | Vaccinated #>  6     2: Unvaccinated | Vaccinated #>  7     2: Unvaccinated | Vaccinated #>  8     2: Unvaccinated | Vaccinated #>  9     2: Unvaccinated | Vaccinated #>  10    2: Unvaccinated | Vaccinated #>  ... plus 3 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 13 #> Reference treatment is: Unvaccinated #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: BCG vaccine for tuberculosis","text":"fit random effects (RE) models, firstly without covariates, meta-regression continuous covariate latitude.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"re-meta-analysis-no-covariate","dir":"Articles","previous_headings":"Meta-analysis models","what":"RE meta-analysis (no covariate)","title":"Example: BCG vaccine for tuberculosis","text":"start fitting standard RE model without covariates. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Vaccine}\\) study-specific intercepts \\(\\mu_j\\), \\(\\textrm{half-N}(0, 5^2)\\) prior distribution heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: model fitted nma() function, random effects model specified trt_effects = \"random\". Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) random effects \\(\\delta_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. bcg_fit_unadj <- nma(bcg_net,                       trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = half_normal(scale = 5)) bcg_fit_unadj #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=10000; warmup=5000; thin=1;  #> post-warmup draws per chain=5000, total post-warmup draws=20000. #>  #>                    mean se_mean   sd      2.5%       25%       50%       75%     97.5% n_eff #> d[Vaccinated]     -0.76    0.00 0.21     -1.20     -0.90     -0.76     -0.63     -0.35  6648 #> lp__          -13453.97    0.06 4.48 -13463.82 -13456.70 -13453.68 -13450.82 -13446.11  5366 #> tau                0.68    0.00 0.20      0.39      0.54      0.64      0.78      1.17  7183 #>               Rhat #> d[Vaccinated]    1 #> lp__             1 #> tau              1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:34:45 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(bcg_fit_unadj, pars = c(\"d\", \"mu\", \"delta\", \"tau\")) plot_prior_posterior(bcg_fit_unadj, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"re-meta-regression-with-covariate-latitude","dir":"Articles","previous_headings":"Meta-analysis models","what":"RE meta-regression with covariate latitude","title":"Example: BCG vaccine for tuberculosis","text":"now fit RE meta-regression model, adjusting latitude. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Vaccine}\\), study-specific intercepts \\(\\mu_j\\), regression coefficient \\(\\beta\\). use \\(\\text{half-N}(0, 5^2)\\) prior distribution heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: , model fitted nma() function. regression formula ~ .trt:latitude means interaction latitude treatment included; .trt special variable indicates treatment, latitude original data set. increase adapt_delta 0.99 remove small number divergent transition errors (default RE models set 0.95). Basic parameter summaries given print() method: Note latitude automatically centered 33.46, mean value studies network. default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. bcg_fit_lat <- nma(bcg_net,                     trt_effects = \"random\",                    regression = ~.trt:latitude,                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_reg = normal(scale = 100),                    prior_het = half_normal(scale = 5),                    adapt_delta = 0.99) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. bcg_fit_lat #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:latitude. #> Centred covariates at the following overall mean values: #> latitude  #> 33.46154  #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=5000; warmup=2500; thin=1;  #> post-warmup draws per chain=2500, total post-warmup draws=10000. #>  #>                                    mean se_mean   sd      2.5%       25%       50%       75% #> beta[.trtVaccinated:latitude]     -0.03    0.00 0.01     -0.05     -0.04     -0.03     -0.03 #> d[Vaccinated]                     -0.76    0.00 0.12     -1.02     -0.83     -0.76     -0.69 #> lp__                          -13457.37    0.12 5.07 -13467.76 -13460.75 -13457.14 -13453.74 #> tau                                0.29    0.00 0.18      0.03      0.16      0.26      0.39 #>                                   97.5% n_eff Rhat #> beta[.trtVaccinated:latitude]     -0.01  3907    1 #> d[Vaccinated]                     -0.53  3687    1 #> lp__                          -13448.40  1807    1 #> tau                                0.73  1683    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:35:00 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(bcg_fit_lat, pars = c(\"d\", \"beta\", \"mu\", \"delta\", \"tau\")) plot_prior_posterior(bcg_fit_lat, prior = c(\"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: BCG vaccine for tuberculosis","text":"Model fit can checked using dic() function: DIC similar two models, might first choose unadjusted model. posterior mean residual deviance larger model covariate, model also lower effective number parameters \\(p_D\\) allowing shrinkage random treatment effects. Moreover, model covariate much lower estimated heterogeneity standard deviation: Adjusting latitude explaining substantial amount heterogeneity data. 95% Credible Interval regression coefficient also excludes zero:  Altogether, might prefer model adjustment latitude. considering covariates random effects models important just look DIC (Dias et al. 2011). also consider reductions heterogeneity, estimated regression coefficients standard error. DIC sensitive changes heterogeneity, RE models flexible can fit data well whatever level heterogeneity.","code":"(bcg_dic_unadj <- dic(bcg_fit_unadj)) #> Residual deviance: 26.1 (on 26 data points) #>                pD: 23.6 #>               DIC: 49.7 (bcg_dic_lat <- dic(bcg_fit_lat)) #> Residual deviance: 30.9 (on 26 data points) #>                pD: 21.4 #>               DIC: 52.3 summary(bcg_fit_unadj, pars = \"tau\") #>     mean  sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau 0.68 0.2 0.39 0.54 0.64 0.78  1.17     7054    10406    1 summary(bcg_fit_lat, pars = \"tau\") #>     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau 0.29 0.18 0.03 0.16 0.26 0.39  0.73     1565     2721    1 summary(bcg_fit_lat, pars = \"beta\") #>                                mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> beta[.trtVaccinated:latitude] -0.03 0.01 -0.05 -0.04 -0.03 -0.03 -0.01     4034     3991    1  plot(bcg_fit_lat,       pars = \"beta\",       ref_line = 0,      stat = \"halfeye\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: BCG vaccine for tuberculosis","text":"can produce estimates relative effect vaccination latitude using relative_effects() function. newdata argument specifies data frame containing values covariate latitude interested , study argument used specify column newdata informative label. plot() method may used visually compare estimates:  sophisticated plot shows regression line confidence band effect latitude, overlaid observed log odds ratios study:  presence heterogeneity, argued decision makers consider predictive distribution relative effects new study, instead posterior distribution mean treatment effects, reflects uncertainty due heterogeneity may better represent uncertainty future roll-treatment (see Dias et al. 2011). can produce predictive distributions using predictive_distribution = TRUE argument relative_effects(). Dias et al. (2018, sec. 8.3.2) consider predictive distributions BCG vaccine analysis. unadjusted analysis, whilst substantial evidence vaccination effective average essentially zero probability harm based mean effect, predictive distribution effectiveness new study wide covers range harmful effects: predictive probability new trial showing harmful effect : analysis adjusting latitude, predictive distribution relative effects now depends latitude; calculate increments 10 degrees equator: predictive probabilities new trial carried given latitude showing harmful effect can calculated : predictive probability new trial carried equator shows harmful effect around 80%, whereas 50 degrees latitude predictive probability 0.7%.","code":"bcg_releff_lat <- relative_effects(bcg_fit_lat,                                    newdata = tibble::tibble(latitude = seq(10, 50, by = 10),                                                             label = paste0(latitude, \"\\u00B0 latitude\")),                                    study = label)  bcg_releff_lat #> ----------------------------------------------------------- Study: 10° latitude ----  #>  #> Covariate values: #>  latitude #>        10 #>  #>                              mean   sd 2.5%   25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[10° latitude: Vaccinated] -0.02 0.22 -0.5 -0.13   0 0.1  0.39     3693     4073    1 #>  #> ----------------------------------------------------------- Study: 20° latitude ----  #>  #> Covariate values: #>  latitude #>        20 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[20° latitude: Vaccinated] -0.34 0.16 -0.68 -0.42 -0.32 -0.25 -0.05     3619     4769    1 #>  #> ----------------------------------------------------------- Study: 30° latitude ----  #>  #> Covariate values: #>  latitude #>        30 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[30° latitude: Vaccinated] -0.65 0.12 -0.91 -0.72 -0.64 -0.58 -0.42     3739     4276    1 #>  #> ----------------------------------------------------------- Study: 40° latitude ----  #>  #> Covariate values: #>  latitude #>        40 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[40° latitude: Vaccinated] -0.97 0.14 -1.27 -1.05 -0.96 -0.89  -0.7     4158     4291    1 #>  #> ----------------------------------------------------------- Study: 50° latitude ----  #>  #> Covariate values: #>  latitude #>        50 #>  #>                              mean   sd  2.5%  25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[50° latitude: Vaccinated] -1.29 0.19 -1.69 -1.4 -1.28 -1.18 -0.88     4266     4176    1 plot(bcg_releff_lat,       ref_line = 0) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2)  # Get data for regression line lat_range <- range(bcg_vaccine$latitude) lat_dat <- tibble(latitude = seq(lat_range[1], lat_range[2], by = 1))  bcg_lat_reg <- relative_effects(bcg_fit_lat,                                  newdata = lat_dat) %>%    as_tibble() %>%    bind_cols(lat_dat)  # Get study log odds ratios bcg_lor <- bcg_vaccine %>%    group_by(studyn) %>%    mutate(lor = log(r / (n - r)) - log(first(r) / (first(n) - first(r))),          sample_size = sum(n)) %>%    slice(-1)  # Plot ggplot(aes(x = latitude), data = bcg_lor) +   geom_hline(yintercept = 0, colour = \"grey60\") +   geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), data = bcg_lat_reg,               fill = \"darkred\", alpha = 0.3) +   geom_line(aes(y = mean), data = bcg_lat_reg,             colour = \"darkred\") +   geom_point(aes(y = lor, size = sample_size), alpha = 0.6) +   coord_cartesian(xlim = c(0, 60)) +   xlab(\"Degrees Latitude\") + ylab(\"log Odds Ratio\") +   scale_size(\"Sample Size\") +   theme_multinma() (bcg_predeff_unadj <- relative_effects(bcg_fit_unadj, predictive_distribution = TRUE)) #>                        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> delta_new[Vaccinated] -0.77 0.75 -2.27 -1.22 -0.76 -0.32  0.72    17433    18382    1 mean(as.matrix(bcg_predeff_unadj) > 0) #> [1] 0.1323 bcg_predeff_lat <- relative_effects(bcg_fit_lat,                                    newdata = tibble::tibble(latitude = seq(0, 50, by = 10),                                                             label = paste0(latitude, \"\\u00B0 latitude\")),                                    study = label,                                    predictive_distribution = TRUE)  bcg_predeff_lat #> ------------------------------------------------------------ Study: 0° latitude ----  #>  #> Covariate values: #>  latitude #>         0 #>  #>                                    mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> delta_new[0° latitude: Vaccinated]  0.3 0.45 -0.68 0.08 0.33 0.52   1.2     6045     5871    1 #>  #> ----------------------------------------------------------- Study: 10° latitude ----  #>  #> Covariate values: #>  latitude #>        10 #>  #>                                      mean   sd  2.5%   25% 50%  75% 97.5% Bulk_ESS Tail_ESS #> delta_new[10° latitude: Vaccinated] -0.02 0.41 -0.88 -0.21   0 0.18  0.79     7028     6604 #>                                     Rhat #> delta_new[10° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 20° latitude ----  #>  #> Covariate values: #>  latitude #>        20 #>  #>                                      mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[20° latitude: Vaccinated] -0.34 0.37 -1.12 -0.51 -0.32 -0.16  0.42     8288     7226 #>                                     Rhat #> delta_new[20° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 30° latitude ----  #>  #> Covariate values: #>  latitude #>        30 #>  #>                                      mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[30° latitude: Vaccinated] -0.65 0.36 -1.41 -0.82 -0.64 -0.49  0.09     9253     7799 #>                                     Rhat #> delta_new[30° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 40° latitude ----  #>  #> Covariate values: #>  latitude #>        40 #>  #>                                      mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS #> delta_new[40° latitude: Vaccinated] -0.97 0.36 -1.75 -1.14 -0.96 -0.8 -0.21     8791     6952 #>                                     Rhat #> delta_new[40° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 50° latitude ----  #>  #> Covariate values: #>  latitude #>        50 #>  #>                                      mean   sd 2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[50° latitude: Vaccinated] -1.29 0.38 -2.1 -1.47 -1.28 -1.11 -0.46     7550     6224 #>                                     Rhat #> delta_new[50° latitude: Vaccinated]    1 colMeans(as.matrix(bcg_predeff_lat) > 0) #>  delta_new[0° latitude: Vaccinated] delta_new[10° latitude: Vaccinated]  #>                              0.8035                              0.5060  #> delta_new[20° latitude: Vaccinated] delta_new[30° latitude: Vaccinated]  #>                              0.1264                              0.0344  #> delta_new[40° latitude: Vaccinated] delta_new[50° latitude: Vaccinated]  #>                              0.0121                              0.0052"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Beta blockers","text":"begin setting network - just pairwise meta-analysis. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). set “Control” reference treatment.","code":"blocker_net <- set_agd_arm(blocker,                             study = studyn,                            trt = trtc,                            r = r,                             n = n,                            trt_ref = \"Control\") blocker_net #> A network with 22 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms            #>  1     2: Control | Beta Blocker #>  2     2: Control | Beta Blocker #>  3     2: Control | Beta Blocker #>  4     2: Control | Beta Blocker #>  5     2: Control | Beta Blocker #>  6     2: Control | Beta Blocker #>  7     2: Control | Beta Blocker #>  8     2: Control | Beta Blocker #>  9     2: Control | Beta Blocker #>  10    2: Control | Beta Blocker #>  ... plus 12 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 22 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Beta blockers","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Beta blockers","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. blocker_fit_FE <- nma(blocker_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) blocker_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                     mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff Rhat #> d[Beta Blocker]    -0.26    0.00 0.05    -0.36    -0.30    -0.26    -0.23    -0.16  3225    1 #> lp__            -5960.46    0.09 3.45 -5968.32 -5962.54 -5960.12 -5957.90 -5954.97  1606    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:35:16 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(blocker_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(blocker_fit_FE, prior = \"trt\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Beta blockers","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. blocker_fit_RE <- nma(blocker_net,                     trt_effects = \"random\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_het = half_normal(scale = 5)) blocker_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                     mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff Rhat #> d[Beta Blocker]    -0.25    0.00 0.07    -0.38    -0.30    -0.25    -0.21    -0.11  2941 1.00 #> lp__            -5970.69    0.17 5.54 -5982.46 -5974.26 -5970.39 -5966.71 -5960.79  1088 1.01 #> tau                 0.14    0.00 0.08     0.01     0.07     0.13     0.19     0.31  1002 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:35:20 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(blocker_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(blocker_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Beta blockers","text":"Model fit can checked using dic() function: residual deviance lower RE model, expected model flexible. However, comes increased effective number parameters (note increase \\(p_D\\)). result, DIC models similar FE model may preferred parsimony. can also examine residual deviance contributions corresponding plot() method.   number points well fit FE model, posterior mean residual deviance contributions greater 1. Study 14 particularly poor fit FE model, residual deviance reduced (although still high) RE model. evidence given careful examination, consideration given issues potential effect-modifying covariates (Dias et al. 2011).","code":"(dic_FE <- dic(blocker_fit_FE)) #> Residual deviance: 46.9 (on 44 data points) #>                pD: 23.3 #>               DIC: 70.2 (dic_RE <- dic(blocker_fit_RE)) #> Residual deviance: 41.9 (on 44 data points) #>                pD: 28.4 #>               DIC: 70.3 plot(dic_FE) plot(dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Beta blockers","text":"Dias et al. (2011) produce absolute predictions probability mortality beta blockers control, assuming Normal distribution baseline logit-probability mortality mean \\(-2.2\\) precision \\(3.3\\). can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted probabilities (type = \"link\" produce predicted log odds).   instead information baseline logit-probability mortality event counts, can use construct Beta distribution baseline probability mortality. example, 4 36 individuals died control treatment target population interest, appropriate Beta distribution probability \\(\\textrm{Beta}(4, 36-4)\\). can specify Beta distribution baseline response using baseline_type = \"reponse\" argument (default \"link\", used baseline logit-probability).   Notice results nearly equivalent calculated using Normal distribution baseline logit-probability, since event counts correspond approximately distribution logit-probability.","code":"pred_FE <- predict(blocker_fit_FE,                     baseline = distr(qnorm, mean = -2.2, sd = 3.3^-0.5),                     type = \"response\") pred_FE #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.06 0.03 0.07 0.10 0.14  0.25     4166     3925    1 #> pred[Beta Blocker] 0.09 0.05 0.03 0.06 0.08 0.11  0.21     4141     3859    1 plot(pred_FE) pred_RE <- predict(blocker_fit_RE,                     baseline = distr(qnorm, mean = -2.2, sd = 3.3^-0.5),                     type = \"response\") pred_RE #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.06 0.04 0.07 0.10 0.14  0.25     4128     3417    1 #> pred[Beta Blocker] 0.09 0.05 0.03 0.06 0.08 0.11  0.20     4034     3387    1 plot(pred_RE) pred_FE_beta <- predict(blocker_fit_FE,                          baseline = distr(qbeta, 4, 36-4),                         baseline_type = \"response\",                         type = \"response\") pred_FE_beta #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.03 0.07 0.10 0.14  0.23     3774     3686    1 #> pred[Beta Blocker] 0.09 0.04 0.02 0.06 0.08 0.11  0.19     3721     3790    1 plot(pred_FE_beta) pred_RE_beta <- predict(blocker_fit_RE,                          baseline = distr(qbeta, 4, 36-4),                         baseline_type = \"response\",                         type = \"response\") pred_RE_beta #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.03 0.07 0.10 0.14  0.23     3901     3892    1 #> pred[Beta Blocker] 0.09 0.04 0.02 0.06 0.08 0.11  0.19     3912     3972    1 plot(pred_RE_beta)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Diabetes","text":"begin setting network. arm-level count data giving number new cases diabetes (r) total (n) arm, use function set_agd_arm(). computational efficiency, let “Beta Blocker” set network reference treatment default. Elliott Meyer (2007) Dias et al. (2011) use “Diuretic” reference, simple matter transform results fitting NMA model.1 also details length follow-years trial (time), use offset cloglog link function model data rates. specify function set_agd_arm(): additional columns data (e.g. offsets covariates, column time) automatically made available network. Plot network structure.","code":"db_net <- set_agd_arm(diabetes,                        study = studyc,                       trt = trtc,                       r = r,                        n = n) db_net #> A network with 22 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study  Treatment arms                        #>  AASK   3: Beta Blocker | ACE Inhibitor | CCB #>  ALLHAT 3: ACE Inhibitor | CCB | Diuretic     #>  ALPINE 2: ARB | Diuretic                     #>  ANBP-2 2: ACE Inhibitor | Diuretic           #>  ASCOT  2: Beta Blocker | CCB                 #>  CAPPP  2: Beta Blocker | ACE Inhibitor       #>  CHARM  2: ARB | Placebo                      #>  DREAM  2: ACE Inhibitor | Placebo            #>  EWPH   2: Diuretic | Placebo                 #>  FEVER  2: CCB | Placebo                      #>  ... plus 12 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6 #> Total number of studies: 22 #> Reference treatment is: Beta Blocker #> Network is connected plot(db_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Diabetes","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Diabetes","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. specify cloglog link used link = \"cloglog\" (Binomial likelihood default data), specify log follow-time offset using regression formula regression = ~offset(log(time)). Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. db_fit_FE <- nma(db_net,                   trt_effects = \"fixed\",                  link = \"cloglog\",                  regression = ~offset(log(time)),                  prior_intercept = normal(scale = 100),                  prior_trt = normal(scale = 100)) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. #> Note: Setting \"Beta Blocker\" as the network reference treatment. db_fit_FE #> A fixed effects NMA with a binomial likelihood (cloglog link). #> Regression model: ~offset(log(time)). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                       mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[ACE Inhibitor]     -0.30    0.00 0.05     -0.39     -0.33     -0.30     -0.27     -0.22 #> d[ARB]               -0.40    0.00 0.05     -0.49     -0.43     -0.40     -0.36     -0.31 #> d[CCB]               -0.20    0.00 0.03     -0.26     -0.22     -0.20     -0.18     -0.13 #> d[Diuretic]           0.06    0.00 0.06     -0.05      0.02      0.06      0.09      0.16 #> d[Placebo]           -0.19    0.00 0.05     -0.28     -0.22     -0.19     -0.16     -0.09 #> lp__             -37970.19    0.09 3.73 -37978.54 -37972.50 -37969.78 -37967.53 -37964.08 #>                  n_eff Rhat #> d[ACE Inhibitor]  1639    1 #> d[ARB]            1972    1 #> d[CCB]            1919    1 #> d[Diuretic]       1826    1 #> d[Placebo]        1487    1 #> lp__              1729    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:35:35 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(db_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(db_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Diabetes","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. db_fit_RE <- nma(db_net,                   trt_effects = \"random\",                  link = \"cloglog\",                  regression = ~offset(log(time)),                  prior_intercept = normal(scale = 10),                  prior_trt = normal(scale = 10),                  prior_het = half_normal(scale = 5),                  init_r = 0.5) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. #> Note: Setting \"Beta Blocker\" as the network reference treatment. db_fit_RE #> A random effects NMA with a binomial likelihood (cloglog link). #> Regression model: ~offset(log(time)). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                       mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[ACE Inhibitor]     -0.33    0.00 0.08     -0.49     -0.38     -0.33     -0.28     -0.18 #> d[ARB]               -0.40    0.00 0.09     -0.59     -0.46     -0.40     -0.34     -0.23 #> d[CCB]               -0.17    0.00 0.06     -0.29     -0.21     -0.17     -0.13     -0.04 #> d[Diuretic]           0.07    0.00 0.09     -0.10      0.01      0.07      0.13      0.24 #> d[Placebo]           -0.21    0.00 0.09     -0.39     -0.27     -0.21     -0.16     -0.05 #> lp__             -37981.01    0.22 6.86 -37995.53 -37985.63 -37980.56 -37976.12 -37968.64 #> tau                   0.13    0.00 0.04      0.06      0.10      0.12      0.15      0.23 #>                  n_eff Rhat #> d[ACE Inhibitor]  1268 1.01 #> d[ARB]            1780 1.00 #> d[CCB]            1818 1.00 #> d[Diuretic]       1784 1.00 #> d[Placebo]        1567 1.00 #> lp__               966 1.00 #> tau                823 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:35:49 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(db_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(db_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Diabetes","text":"Model fit can checked using dic() function: FE model poor fit data, residual deviance much higher number data points. RE model fits data better, much lower DIC; prefer RE model. can also examine residual deviance contributions corresponding plot() method.","code":"(dic_FE <- dic(db_fit_FE)) #> Residual deviance: 78 (on 48 data points) #>                pD: 26.8 #>               DIC: 104.8 (dic_RE <- dic(db_fit_RE)) #> Residual deviance: 53.7 (on 48 data points) #>                pD: 38.1 #>               DIC: 91.8 plot(dic_FE) plot(dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Diabetes","text":"comparison Elliott Meyer (2007) Dias et al. (2011), can produce relative effects “Diuretic” using relative_effects() function trt_ref = \"Diuretic\":   Dias et al. (2011) produce absolute predictions probability developing diabetes three years, assuming Normal distribution baseline cloglog probability developing diabetes diuretic treatment mean \\(-4.2\\) precision \\(1.11\\). can replicate results using predict() method. specify data frame newdata, containing time offset(s) produce predictions (3 years). baseline argument takes distr() distribution object specify corresponding Normal distribution baseline cloglog probability, set trt_ref = \"Diuretic\" indicate baseline distribution corresponds “Diuretic” rather network reference “Beta Blocker”. set type = \"response\" produce predicted event probabilities (type = \"link\" produce predicted cloglog probabilities).   baseline newdata arguments omitted, predicted probabilities produced every study network based follow-times estimated baseline cloglog probabilities \\(\\mu_j\\):  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(db_releff_FE <- relative_effects(db_fit_FE, trt_ref = \"Diuretic\")) #>                   mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Beta Blocker]  -0.06 0.06 -0.16 -0.09 -0.06 -0.02  0.05     1860     2666    1 #> d[ACE Inhibitor] -0.36 0.05 -0.46 -0.39 -0.36 -0.32 -0.26     5055     3633    1 #> d[ARB]           -0.45 0.06 -0.58 -0.49 -0.45 -0.41 -0.33     4087     3221    1 #> d[CCB]           -0.25 0.05 -0.36 -0.29 -0.25 -0.22 -0.14     3463     3128    1 #> d[Placebo]       -0.25 0.05 -0.35 -0.28 -0.25 -0.21 -0.14     4909     3548    1 plot(db_releff_FE, ref_line = 0) (db_releff_RE <- relative_effects(db_fit_RE, trt_ref = \"Diuretic\")) #>                   mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Beta Blocker]  -0.07 0.09 -0.24 -0.13 -0.07 -0.01  0.10     1943     2368    1 #> d[ACE Inhibitor] -0.40 0.09 -0.58 -0.45 -0.40 -0.34 -0.24     4419     2927    1 #> d[ARB]           -0.47 0.11 -0.71 -0.55 -0.47 -0.40 -0.26     4245     2642    1 #> d[CCB]           -0.24 0.08 -0.41 -0.29 -0.24 -0.19 -0.08     4671     3235    1 #> d[Placebo]       -0.29 0.09 -0.47 -0.35 -0.28 -0.23 -0.11     4433     2902    1 plot(db_releff_RE, ref_line = 0) db_pred_FE <- predict(db_fit_FE,                        newdata = data.frame(time = 3),                       baseline = distr(qnorm, mean = -4.2, sd = 1.11^-0.5),                        trt_ref = \"Diuretic\",                       type = \"response\") db_pred_FE #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: Beta Blocker]  0.06 0.07 0.01 0.02 0.04 0.08  0.24     3975     3771    1 #> pred[New 1: ACE Inhibitor] 0.05 0.05 0.00 0.02 0.03 0.06  0.18     3986     3850    1 #> pred[New 1: ARB]           0.04 0.05 0.00 0.01 0.03 0.05  0.16     3976     3931    1 #> pred[New 1: CCB]           0.05 0.06 0.01 0.02 0.03 0.06  0.20     3976     3851    1 #> pred[New 1: Diuretic]      0.07 0.07 0.01 0.02 0.04 0.08  0.25     3979     3812    1 #> pred[New 1: Placebo]       0.05 0.06 0.01 0.02 0.03 0.06  0.20     3986     3890    1 plot(db_pred_FE) db_pred_RE <- predict(db_fit_RE,                        newdata = data.frame(time = 3),                       baseline = distr(qnorm, mean = -4.2, sd = 1.11^-0.5),                        trt_ref = \"Diuretic\",                       type = \"response\") db_pred_RE #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: Beta Blocker]  0.06 0.06 0.01 0.02 0.04 0.08  0.23     3864     3934    1 #> pred[New 1: ACE Inhibitor] 0.05 0.05 0.00 0.02 0.03 0.06  0.18     3879     3744    1 #> pred[New 1: ARB]           0.04 0.05 0.00 0.01 0.03 0.05  0.16     3856     3897    1 #> pred[New 1: CCB]           0.05 0.06 0.01 0.02 0.04 0.07  0.20     3888     3726    1 #> pred[New 1: Diuretic]      0.07 0.07 0.01 0.02 0.05 0.09  0.25     3863     4062    1 #> pred[New 1: Placebo]       0.05 0.05 0.01 0.02 0.03 0.06  0.20     3888     3937    1 plot(db_pred_RE) db_pred_RE_studies <- predict(db_fit_RE, type = \"response\") db_pred_RE_studies #> ------------------------------------------------------------------- Study: AASK ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[AASK: Beta Blocker]  0.17 0.02 0.14 0.16 0.17 0.18  0.20     6275     3068    1 #> pred[AASK: ACE Inhibitor] 0.13 0.01 0.10 0.12 0.12 0.13  0.15     4189     2963    1 #> pred[AASK: ARB]           0.12 0.01 0.09 0.11 0.12 0.13  0.15     4268     2799    1 #> pred[AASK: CCB]           0.15 0.01 0.12 0.14 0.14 0.15  0.18     5011     3002    1 #> pred[AASK: Diuretic]      0.18 0.02 0.14 0.17 0.18 0.19  0.22     4424     3289    1 #> pred[AASK: Placebo]       0.14 0.02 0.11 0.13 0.14 0.15  0.17     3840     2976    1 #>  #> ----------------------------------------------------------------- Study: ALLHAT ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ALLHAT: Beta Blocker]  0.04 0.01 0.03 0.04 0.04 0.05  0.05     2602     2680    1 #> pred[ALLHAT: ACE Inhibitor] 0.03 0.00 0.02 0.03 0.03 0.03  0.04     4726     2948    1 #> pred[ALLHAT: ARB]           0.03 0.00 0.02 0.03 0.03 0.03  0.04     4243     3149    1 #> pred[ALLHAT: CCB]           0.04 0.00 0.03 0.03 0.04 0.04  0.05     4293     2695    1 #> pred[ALLHAT: Diuretic]      0.05 0.01 0.04 0.04 0.05 0.05  0.06     5039     3060    1 #> pred[ALLHAT: Placebo]       0.03 0.00 0.03 0.03 0.03 0.04  0.04     4351     3014    1 #>  #> ----------------------------------------------------------------- Study: ALPINE ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ALPINE: Beta Blocker]  0.03 0.01 0.01 0.02 0.03 0.03  0.05     6326     2812    1 #> pred[ALPINE: ACE Inhibitor] 0.02 0.01 0.01 0.01 0.02 0.02  0.03     7580     2989    1 #> pred[ALPINE: ARB]           0.02 0.01 0.01 0.01 0.02 0.02  0.03     7030     2854    1 #> pred[ALPINE: CCB]           0.02 0.01 0.01 0.02 0.02 0.03  0.04     7023     2925    1 #> pred[ALPINE: Diuretic]      0.03 0.01 0.01 0.02 0.03 0.03  0.05     7412     2785    1 #> pred[ALPINE: Placebo]       0.02 0.01 0.01 0.02 0.02 0.03  0.04     6795     3111    1 #>  #> ----------------------------------------------------------------- Study: ANBP-2 ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ANBP-2: Beta Blocker]  0.07 0.01 0.05 0.06 0.07 0.07  0.09     2640     1988    1 #> pred[ANBP-2: ACE Inhibitor] 0.05 0.01 0.04 0.04 0.05 0.05  0.06     4648     2569    1 #> pred[ANBP-2: ARB]           0.05 0.01 0.03 0.04 0.05 0.05  0.06     3832     2425    1 #> pred[ANBP-2: CCB]           0.06 0.01 0.04 0.05 0.06 0.06  0.07     4146     2252    1 #> pred[ANBP-2: Diuretic]      0.07 0.01 0.06 0.07 0.07 0.08  0.09     4708     2738    1 #> pred[ANBP-2: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     4501     2658    1 #>  #> ------------------------------------------------------------------ Study: ASCOT ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ASCOT: Beta Blocker]  0.11 0.00 0.10 0.11 0.11 0.11  0.12     5304     3161    1 #> pred[ASCOT: ACE Inhibitor] 0.08 0.01 0.07 0.08 0.08 0.09  0.10     1540     2496    1 #> pred[ASCOT: ARB]           0.08 0.01 0.06 0.07 0.08 0.08  0.09     2262     2256    1 #> pred[ASCOT: CCB]           0.10 0.01 0.08 0.09 0.10 0.10  0.11     2206     2189    1 #> pred[ASCOT: Diuretic]      0.12 0.01 0.10 0.11 0.12 0.13  0.14     1991     2473    1 #> pred[ASCOT: Placebo]       0.09 0.01 0.08 0.09 0.09 0.10  0.11     1839     2098    1 #>  #> ------------------------------------------------------------------ Study: CAPPP ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[CAPPP: Beta Blocker]  0.07 0.00 0.07 0.07 0.07 0.08  0.08     4864     2915    1 #> pred[CAPPP: ACE Inhibitor] 0.05 0.00 0.05 0.05 0.05 0.06  0.06     1721     2235    1 #> pred[CAPPP: ARB]           0.05 0.01 0.04 0.05 0.05 0.05  0.06     2366     2151    1 #> pred[CAPPP: CCB]           0.06 0.00 0.05 0.06 0.06 0.07  0.07     2654     2365    1 #> pred[CAPPP: Diuretic]      0.08 0.01 0.07 0.08 0.08 0.08  0.10     2699     2402    1 #> pred[CAPPP: Placebo]       0.06 0.01 0.05 0.06 0.06 0.06  0.07     1930     2065    1 #>  #> ------------------------------------------------------------------ Study: CHARM ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[CHARM: Beta Blocker]  0.09 0.01 0.07 0.08 0.09 0.10  0.12     2471     2259    1 #> pred[CHARM: ACE Inhibitor] 0.07 0.01 0.05 0.06 0.07 0.07  0.09     4172     2448    1 #> pred[CHARM: ARB]           0.06 0.01 0.05 0.06 0.06 0.07  0.08     4407     2955    1 #> pred[CHARM: CCB]           0.08 0.01 0.06 0.07 0.08 0.08  0.10     3896     2856    1 #> pred[CHARM: Diuretic]      0.10 0.01 0.07 0.09 0.10 0.11  0.13     4191     2785    1 #> pred[CHARM: Placebo]       0.07 0.01 0.06 0.07 0.07 0.08  0.09     4388     2773    1 #>  #> ------------------------------------------------------------------ Study: DREAM ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[DREAM: Beta Blocker]  0.23 0.03 0.17 0.21 0.23 0.24  0.29     2249     1921    1 #> pred[DREAM: ACE Inhibitor] 0.17 0.02 0.13 0.16 0.17 0.18  0.21     3694     2446    1 #> pred[DREAM: ARB]           0.16 0.02 0.12 0.14 0.16 0.17  0.21     3827     2683    1 #> pred[DREAM: CCB]           0.20 0.03 0.15 0.18 0.19 0.21  0.25     3225     2128    1 #> pred[DREAM: Diuretic]      0.24 0.03 0.19 0.22 0.24 0.26  0.31     3549     2154    1 #> pred[DREAM: Placebo]       0.19 0.02 0.15 0.18 0.19 0.20  0.23     4404     2715    1 #>  #> ------------------------------------------------------------------- Study: EWPH ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[EWPH: Beta Blocker]  0.06 0.01 0.04 0.05 0.06 0.07  0.09     3854     2963    1 #> pred[EWPH: ACE Inhibitor] 0.05 0.01 0.03 0.04 0.04 0.05  0.07     6328     3582    1 #> pred[EWPH: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     6034     3019    1 #> pred[EWPH: CCB]           0.05 0.01 0.04 0.05 0.05 0.06  0.08     5899     2701    1 #> pred[EWPH: Diuretic]      0.07 0.01 0.05 0.06 0.07 0.07  0.09     6223     3119    1 #> pred[EWPH: Placebo]       0.05 0.01 0.03 0.04 0.05 0.06  0.07     6571     3181    1 #>  #> ------------------------------------------------------------------ Study: FEVER ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[FEVER: Beta Blocker]  0.04 0.01 0.03 0.04 0.04 0.04  0.05     2623     1841    1 #> pred[FEVER: ACE Inhibitor] 0.03 0.00 0.02 0.03 0.03 0.03  0.04     4195     2542    1 #> pred[FEVER: ARB]           0.03 0.00 0.02 0.03 0.03 0.03  0.04     4128     2240    1 #> pred[FEVER: CCB]           0.04 0.00 0.03 0.03 0.03 0.04  0.05     4003     2485    1 #> pred[FEVER: Diuretic]      0.04 0.01 0.03 0.04 0.04 0.05  0.06     4225     2645    1 #> pred[FEVER: Placebo]       0.03 0.00 0.03 0.03 0.03 0.04  0.04     4307     2422    1 #>  #> ----------------------------------------------------------------- Study: HAPPHY ----  #>  #>                             mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[HAPPHY: Beta Blocker]  0.02  0 0.02 0.02 0.02 0.03  0.03     4903     3330    1 #> pred[HAPPHY: ACE Inhibitor] 0.02  0 0.01 0.02 0.02 0.02  0.02     3803     2924    1 #> pred[HAPPHY: ARB]           0.02  0 0.01 0.02 0.02 0.02  0.02     4049     2976    1 #> pred[HAPPHY: CCB]           0.02  0 0.02 0.02 0.02 0.02  0.03     4211     3116    1 #> pred[HAPPHY: Diuretic]      0.03  0 0.02 0.02 0.03 0.03  0.03     3575     2619    1 #> pred[HAPPHY: Placebo]       0.02  0 0.02 0.02 0.02 0.02  0.02     3653     2859    1 #>  #> ------------------------------------------------------------------- Study: HOPE ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[HOPE: Beta Blocker]  0.06 0.01 0.04 0.05 0.06 0.06  0.08     2698     2498    1 #> pred[HOPE: ACE Inhibitor] 0.04 0.01 0.03 0.04 0.04 0.05  0.06     4422     2493    1 #> pred[HOPE: ARB]           0.04 0.01 0.03 0.04 0.04 0.04  0.05     4137     2436    1 #> pred[HOPE: CCB]           0.05 0.01 0.04 0.04 0.05 0.05  0.07     3728     2770    1 #> pred[HOPE: Diuretic]      0.06 0.01 0.05 0.06 0.06 0.07  0.08     4448     2962    1 #> pred[HOPE: Placebo]       0.05 0.01 0.04 0.04 0.05 0.05  0.06     4538     2538    1 #>  #> ---------------------------------------------------------------- Study: INSIGHT ----  #>  #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[INSIGHT: Beta Blocker]  0.07 0.01 0.05 0.06 0.06 0.07  0.09     3105     2467    1 #> pred[INSIGHT: ACE Inhibitor] 0.05 0.01 0.04 0.04 0.05 0.05  0.06     4365     2716    1 #> pred[INSIGHT: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     4119     2620    1 #> pred[INSIGHT: CCB]           0.06 0.01 0.04 0.05 0.05 0.06  0.07     4376     2633    1 #> pred[INSIGHT: Diuretic]      0.07 0.01 0.05 0.06 0.07 0.08  0.09     4798     2505    1 #> pred[INSIGHT: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     4434     2767    1 #>  #> ----------------------------------------------------------------- Study: INVEST ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[INVEST: Beta Blocker]  0.08 0.00 0.08 0.08 0.08 0.08  0.09     8817     2482    1 #> pred[INVEST: ACE Inhibitor] 0.06 0.00 0.05 0.06 0.06 0.06  0.07     1774     2077    1 #> pred[INVEST: ARB]           0.06 0.01 0.05 0.05 0.06 0.06  0.07     2248     2200    1 #> pred[INVEST: CCB]           0.07 0.00 0.06 0.07 0.07 0.07  0.08     2266     2301    1 #> pred[INVEST: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.09  0.10     2379     2263    1 #> pred[INVEST: Placebo]       0.07 0.01 0.06 0.06 0.07 0.07  0.08     1861     2301    1 #>  #> ------------------------------------------------------------------- Study: LIFE ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[LIFE: Beta Blocker]  0.08 0.00 0.07 0.08 0.08 0.08  0.09     7563     2625    1 #> pred[LIFE: ACE Inhibitor] 0.06 0.01 0.05 0.06 0.06 0.06  0.07     2007     2592    1 #> pred[LIFE: ARB]           0.06 0.01 0.05 0.05 0.06 0.06  0.07     2174     2423    1 #> pred[LIFE: CCB]           0.07 0.01 0.06 0.07 0.07 0.07  0.08     2853     2343    1 #> pred[LIFE: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.09  0.11     2948     2558    1 #> pred[LIFE: Placebo]       0.07 0.01 0.05 0.06 0.07 0.07  0.08     2154     2249    1 #>  #> ------------------------------------------------------------------ Study: MRC-E ----  #>  #>                            mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[MRC-E: Beta Blocker]  0.03  0 0.02 0.03 0.03 0.03  0.04     4245     2963    1 #> pred[MRC-E: ACE Inhibitor] 0.02  0 0.02 0.02 0.02 0.02  0.03     5654     2957    1 #> pred[MRC-E: ARB]           0.02  0 0.01 0.02 0.02 0.02  0.03     4769     3056    1 #> pred[MRC-E: CCB]           0.03  0 0.02 0.02 0.02 0.03  0.03     4640     3055    1 #> pred[MRC-E: Diuretic]      0.03  0 0.02 0.03 0.03 0.03  0.04     4760     2789    1 #> pred[MRC-E: Placebo]       0.02  0 0.02 0.02 0.02 0.03  0.03     4934     3001    1 #>  #> ----------------------------------------------------------------- Study: NORDIL ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[NORDIL: Beta Blocker]  0.05 0.00 0.04 0.05 0.05 0.05  0.06     6613     3156    1 #> pred[NORDIL: ACE Inhibitor] 0.04 0.00 0.03 0.03 0.04 0.04  0.04     2278     2536    1 #> pred[NORDIL: ARB]           0.03 0.00 0.03 0.03 0.03 0.04  0.04     2599     2613    1 #> pred[NORDIL: CCB]           0.04 0.00 0.04 0.04 0.04 0.04  0.05     2920     2105    1 #> pred[NORDIL: Diuretic]      0.05 0.01 0.04 0.05 0.05 0.06  0.06     3020     2681    1 #> pred[NORDIL: Placebo]       0.04 0.00 0.03 0.04 0.04 0.04  0.05     2201     2536    1 #>  #> ------------------------------------------------------------------ Study: PEACE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[PEACE: Beta Blocker]  0.14 0.02 0.10 0.13 0.14 0.15  0.18     2516     2328    1 #> pred[PEACE: ACE Inhibitor] 0.10 0.01 0.08 0.09 0.10 0.11  0.13     4330     2230    1 #> pred[PEACE: ARB]           0.09 0.01 0.07 0.09 0.09 0.10  0.13     3993     2260    1 #> pred[PEACE: CCB]           0.12 0.02 0.09 0.11 0.12 0.13  0.15     3741     2775    1 #> pred[PEACE: Diuretic]      0.15 0.02 0.11 0.13 0.15 0.16  0.19     4628     2372    1 #> pred[PEACE: Placebo]       0.11 0.01 0.09 0.10 0.11 0.12  0.14     4593     2254    1 #>  #> ------------------------------------------------------------------ Study: SCOPE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[SCOPE: Beta Blocker]  0.06 0.01 0.05 0.06 0.06 0.07  0.09     2799     2221    1 #> pred[SCOPE: ACE Inhibitor] 0.05 0.01 0.03 0.04 0.05 0.05  0.06     4398     2608    1 #> pred[SCOPE: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     4552     2862    1 #> pred[SCOPE: CCB]           0.06 0.01 0.04 0.05 0.05 0.06  0.07     4147     2273    1 #> pred[SCOPE: Diuretic]      0.07 0.01 0.05 0.06 0.07 0.08  0.10     4371     2273    1 #> pred[SCOPE: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     4781     2480    1 #>  #> ------------------------------------------------------------------- Study: SHEP ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[SHEP: Beta Blocker]  0.09 0.01 0.06 0.08 0.09 0.09  0.11     2697     2106    1 #> pred[SHEP: ACE Inhibitor] 0.06 0.01 0.05 0.06 0.06 0.07  0.08     4422     2387    1 #> pred[SHEP: ARB]           0.06 0.01 0.04 0.05 0.06 0.06  0.08     4142     2097    1 #> pred[SHEP: CCB]           0.07 0.01 0.05 0.07 0.07 0.08  0.10     4077     2210    1 #> pred[SHEP: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.10  0.12     4784     2590    1 #> pred[SHEP: Placebo]       0.07 0.01 0.05 0.06 0.07 0.08  0.09     4673     2293    1 #>  #> ----------------------------------------------------------------- Study: STOP-2 ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[STOP-2: Beta Blocker]  0.05 0.00 0.05 0.05 0.05 0.06  0.06     4116     3000    1 #> pred[STOP-2: ACE Inhibitor] 0.04 0.00 0.03 0.04 0.04 0.04  0.05     2352     2423    1 #> pred[STOP-2: ARB]           0.04 0.00 0.03 0.03 0.04 0.04  0.04     2766     2688    1 #> pred[STOP-2: CCB]           0.05 0.00 0.04 0.04 0.05 0.05  0.05     3332     2854    1 #> pred[STOP-2: Diuretic]      0.06 0.01 0.05 0.05 0.06 0.06  0.07     3300     2815    1 #> pred[STOP-2: Placebo]       0.04 0.00 0.03 0.04 0.04 0.05  0.05     2436     2256    1 #>  #> ------------------------------------------------------------------ Study: VALUE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[VALUE: Beta Blocker]  0.20 0.02 0.15 0.18 0.20 0.21  0.25     2831     2090    1 #> pred[VALUE: ACE Inhibitor] 0.15 0.02 0.11 0.13 0.14 0.16  0.19     4288     2392    1 #> pred[VALUE: ARB]           0.14 0.02 0.10 0.13 0.14 0.15  0.17     4599     2440    1 #> pred[VALUE: CCB]           0.17 0.02 0.13 0.16 0.17 0.18  0.22     4575     2188    1 #> pred[VALUE: Diuretic]      0.21 0.03 0.16 0.19 0.21 0.23  0.28     4436     2459    1 #> pred[VALUE: Placebo]       0.16 0.02 0.12 0.15 0.16 0.17  0.21     4265     2639    1 plot(db_pred_RE_studies) (db_ranks <- posterior_ranks(db_fit_RE)) #>                     mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[Beta Blocker]  5.19 0.43    5   5   5   5     6     2209       NA    1 #> rank[ACE Inhibitor] 1.86 0.53    1   2   2   2     3     3873     3257    1 #> rank[ARB]           1.25 0.50    1   1   1   1     3     3560     3408    1 #> rank[CCB]           3.71 0.52    3   3   4   4     4     3459     2498    1 #> rank[Diuretic]      5.79 0.41    5   6   6   6     6     2523       NA    1 #> rank[Placebo]       3.20 0.60    2   3   3   4     4     3373     2479    1 plot(db_ranks) (db_rankprobs <- posterior_rank_probs(db_fit_RE)) #>                  p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[Beta Blocker]       0.00      0.00      0.00      0.01      0.78       0.2 #> d[ACE Inhibitor]      0.22      0.72      0.06      0.01      0.00       0.0 #> d[ARB]                0.78      0.20      0.02      0.00      0.00       0.0 #> d[CCB]                0.00      0.01      0.27      0.70      0.01       0.0 #> d[Diuretic]           0.00      0.00      0.00      0.00      0.20       0.8 #> d[Placebo]            0.01      0.07      0.64      0.27      0.01       0.0 plot(db_rankprobs) (db_cumrankprobs <- posterior_rank_probs(db_fit_RE, cumulative = TRUE)) #>                  p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[Beta Blocker]       0.00      0.00      0.00      0.01       0.8         1 #> d[ACE Inhibitor]      0.22      0.93      0.99      1.00       1.0         1 #> d[ARB]                0.78      0.97      1.00      1.00       1.0         1 #> d[CCB]                0.00      0.02      0.29      0.99       1.0         1 #> d[Diuretic]           0.00      0.00      0.00      0.00       0.2         1 #> d[Placebo]            0.01      0.08      0.72      0.99       1.0         1 plot(db_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Dietary fat","text":"begin setting network - just pairwise meta-analysis. arm-level rate data giving number deaths (r) person-years risk (E) arm, use function set_agd_arm(). set “Control” reference treatment. also specify optional sample_size argument, although strictly necessary . case sample_size required produce network plot nodes weighted sample size, network plot particularly informative meta-analysis two treatments. (sample_size argument important regression model specified, since also enables automatic centering predictors production predictions studies network, see ?set_agd_arm.)","code":"diet_net <- set_agd_arm(dietary_fat,                          study = studyc,                         trt = trtc,                         r = r,                          E = E,                         trt_ref = \"Control\",                         sample_size = n) diet_net #> A network with 10 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study                   Treatment arms                         #>  DART                    2: Control | Reduced Fat               #>  London Corn/Olive       3: Control | Reduced Fat | Reduced Fat #>  London Low Fat          2: Control | Reduced Fat               #>  Minnesota Coronary      2: Control | Reduced Fat               #>  MRC Soya                2: Control | Reduced Fat               #>  Oslo Diet-Heart         2: Control | Reduced Fat               #>  STARS                   2: Control | Reduced Fat               #>  Sydney Diet-Heart       2: Control | Reduced Fat               #>  Veterans Administration 2: Control | Reduced Fat               #>  Veterans Diet & Skin CA 2: Control | Reduced Fat               #>  #>  Outcome type: rate #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 10 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Dietary fat","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Dietary fat","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Poisson likelihood log link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. diet_fit_FE <- nma(diet_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) diet_fit_FE #> A fixed effects NMA with a poisson likelihood (log link). #> Inference for Stan model: poisson. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Reduced Fat]   -0.01    0.00 0.05   -0.11   -0.05   -0.01    0.03    0.10  3393    1 #> lp__           5386.25    0.06 2.37 5380.55 5384.93 5386.62 5387.98 5389.77  1724    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:36:13 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(diet_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(diet_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Dietary fat","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. diet_fit_RE <- nma(diet_net,                     trt_effects = \"random\",                    prior_intercept = normal(scale = 10),                    prior_trt = normal(scale = 10),                    prior_het = half_normal(scale = 5)) diet_fit_RE #> A random effects NMA with a poisson likelihood (log link). #> Inference for Stan model: poisson. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Reduced Fat]   -0.01    0.00 0.09   -0.19   -0.07   -0.01    0.04    0.15  1808 1.00 #> lp__           5378.70    0.13 3.91 5370.52 5376.08 5378.88 5381.43 5385.80   957 1.01 #> tau               0.13    0.00 0.12    0.00    0.05    0.10    0.18    0.44   853 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:36:19 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(diet_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(diet_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Dietary fat","text":"Model fit can checked using dic() function: models appear fit data well, residual deviance close number data points. DIC similar models, FE model may preferred parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(dic_FE <- dic(diet_fit_FE)) #> Residual deviance: 22.3 (on 21 data points) #>                pD: 11.1 #>               DIC: 33.4 (dic_RE <- dic(diet_fit_RE)) #> Residual deviance: 21.5 (on 21 data points) #>                pD: 13.6 #>               DIC: 35.1 plot(dic_FE) plot(dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Dietary fat","text":"Dias et al. (2011) produce absolute predictions mortality rates reduced fat control diets, assuming Normal distribution baseline log rate mortality mean \\(-3\\) precision \\(1.77\\). can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted rates (type = \"link\" produce predicted log rates).   baseline argument omitted, predicted rates produced every study network based estimated baseline log rate \\(\\mu_j\\):","code":"pred_FE <- predict(diet_fit_FE,                     baseline = distr(qnorm, mean = -3, sd = 1.77^-0.5),                     type = \"response\") pred_FE #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]     0.07 0.06 0.01 0.03 0.05 0.08  0.23     4145     3859    1 #> pred[Reduced Fat] 0.07 0.06 0.01 0.03 0.05 0.08  0.23     4122     3859    1 plot(pred_FE) pred_RE <- predict(diet_fit_RE,                     baseline = distr(qnorm, mean = -3, sd = 1.77^-0.5),                     type = \"response\") pred_RE #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]     0.07 0.06 0.01 0.03 0.05 0.08  0.22     4066     3678    1 #> pred[Reduced Fat] 0.07 0.06 0.01 0.03 0.05 0.08  0.22     4070     3998    1 plot(pred_RE) pred_FE_studies <- predict(diet_fit_FE, type = \"response\") pred_FE_studies #> ------------------------------------------------------------------- Study: DART ----  #>  #>                         mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[DART: Control]     0.06  0 0.05 0.06 0.06 0.06  0.07     5912     3276    1 #> pred[DART: Reduced Fat] 0.06  0 0.05 0.06 0.06 0.06  0.07     6410     3423    1 #>  #> ------------------------------------------------------ Study: London Corn/Olive ----  #>  #>                                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[London Corn/Olive: Control]     0.07 0.02 0.04 0.06 0.07 0.09  0.13     6977     3122 #> pred[London Corn/Olive: Reduced Fat] 0.07 0.02 0.04 0.06 0.07 0.09  0.13     6871     3286 #>                                      Rhat #> pred[London Corn/Olive: Control]        1 #> pred[London Corn/Olive: Reduced Fat]    1 #>  #> --------------------------------------------------------- Study: London Low Fat ----  #>  #>                                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[London Low Fat: Control]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     6472     2956    1 #> pred[London Low Fat: Reduced Fat] 0.06 0.01 0.04 0.05 0.06 0.06  0.08     7369     2993    1 #>  #> ----------------------------------------------------- Study: Minnesota Coronary ----  #>  #>                                       mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Minnesota Coronary: Control]     0.05  0 0.05 0.05 0.05 0.06  0.06     4365     3240    1 #> pred[Minnesota Coronary: Reduced Fat] 0.05  0 0.05 0.05 0.05 0.06  0.06     6108     3476    1 #>  #> --------------------------------------------------------------- Study: MRC Soya ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[MRC Soya: Control]     0.04 0.01 0.03 0.04 0.04 0.04  0.05     5828     2996    1 #> pred[MRC Soya: Reduced Fat] 0.04 0.01 0.03 0.04 0.04 0.04  0.05     6272     2813    1 #>  #> -------------------------------------------------------- Study: Oslo Diet-Heart ----  #>  #>                                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Oslo Diet-Heart: Control]     0.06 0.01 0.05 0.06 0.06 0.07  0.08     5832     3129    1 #> pred[Oslo Diet-Heart: Reduced Fat] 0.06 0.01 0.05 0.06 0.06 0.07  0.08     6413     3160    1 #>  #> ------------------------------------------------------------------ Study: STARS ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[STARS: Control]     0.02 0.01 0.01 0.01 0.02 0.03  0.05     7074     2749    1 #> pred[STARS: Reduced Fat] 0.02 0.01 0.01 0.01 0.02 0.03  0.05     7192     2807    1 #>  #> ------------------------------------------------------ Study: Sydney Diet-Heart ----  #>  #>                                      mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Sydney Diet-Heart: Control]     0.03  0 0.03 0.03 0.03 0.04  0.04     7061     3053    1 #> pred[Sydney Diet-Heart: Reduced Fat] 0.03  0 0.03 0.03 0.03 0.04  0.04     7398     3014    1 #>  #> ------------------------------------------------ Study: Veterans Administration ----  #>  #>                                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Veterans Administration: Control]     0.11 0.01  0.1 0.11 0.11 0.12  0.13     4995 #> pred[Veterans Administration: Reduced Fat] 0.11 0.01  0.1 0.11 0.11 0.12  0.12     6424 #>                                            Tail_ESS Rhat #> pred[Veterans Administration: Control]         3087    1 #> pred[Veterans Administration: Reduced Fat]     3221    1 #>  #> ------------------------------------------------ Study: Veterans Diet & Skin CA ----  #>  #>                                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Veterans Diet & Skin CA: Control]     0.01 0.01    0 0.01 0.01 0.02  0.03     7067 #> pred[Veterans Diet & Skin CA: Reduced Fat] 0.01 0.01    0 0.01 0.01 0.02  0.03     7048 #>                                            Tail_ESS Rhat #> pred[Veterans Diet & Skin CA: Control]         2205    1 #> pred[Veterans Diet & Skin CA: Reduced Fat]     2151    1 plot(pred_FE_studies) + ggplot2::facet_grid(Study~., labeller = ggplot2::label_wrap_gen(width = 10))"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Plaque psoriasis HTA report","text":"begin setting network. arm-level ordered multinomial count data, use function set_agd_arm(). function multi() helps us specify ordered outcomes correctly. Plot network structure.","code":"pso_net <- set_agd_arm(hta_psoriasis,                         study = paste(studyc, year),                         trt = trtc,                         r = multi(r0 = sample_size - rowSums(cbind(PASI50, PASI75, PASI90), na.rm = TRUE),                                   PASI50, PASI75, PASI90,                                  inclusive = FALSE,                                   type = \"ordered\")) pso_net #> A network with 16 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                           #>  ACD2058g 2004 2: Supportive care | Efalizumab                          #>  ACD2600g 2004 2: Supportive care | Efalizumab                          #>  Altmeyer 1994 2: Supportive care | Fumaderm                            #>  Chaudari 2001 2: Supportive care | Infliximab                          #>  Elewski 2004  3: Supportive care | Etanercept 25 mg | Etanercept 50 mg #>  Ellis 1991    3: Supportive care | Ciclosporin | Ciclosporin           #>  Gordon 2003   2: Supportive care | Efalizumab                          #>  Gottlieb 2003 2: Supportive care | Etanercept 25 mg                    #>  Gottlieb 2004 3: Supportive care | Infliximab | Infliximab             #>  Guenther 1991 2: Supportive care | Ciclosporin                         #>  ... plus 6 more studies #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 8 #> Total number of studies: 16 #> Reference treatment is: Supportive care #> Network is connected plot(pso_net, weight_edges = TRUE, weight_nodes = TRUE) +    # Nudge the legend over   ggplot2::theme(legend.box.spacing = ggplot2::unit(0.75, \"in\"),                  plot.margin = ggplot2::margin(0.1, 0, 0.1, 0.75, \"in\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Plaque psoriasis HTA report","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Plaque psoriasis HTA report","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\", using probit link function link = \"probit\". use \\(\\mathrm{N}(0, 10^2)\\) prior distributions treatment effects \\(d_k\\), \\(\\mathrm{N}(0, 100^2)\\) prior distributions study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: also need specify prior distributions latent cutpoints \\(c_\\textrm{PASI75}\\) \\(c_\\textrm{PASI90}\\) underlying scale - PASI standardised mean difference due probit link (cutpoint \\(c_\\textrm{PASI50}=0\\)). make easier reason , actually specify priors differences adjacent cutpoints, e.g. \\(c_\\textrm{PASI90} - c_\\textrm{PASI75}\\) \\(c_\\textrm{PASI75} - c_\\textrm{PASI50}\\). can given positive-valued prior distribution, Stan automatically impose necessary ordering constraints behind scenes. choose give implicit flat priors flat(). model fitted using nma() function. Basic parameter summaries given print() method: Note: treatment effects opposite sign TSD 2 (Dias et al. 2011). parameterise linear predictor \\(\\mu_j + d_k + c_m\\), rather \\(\\mu_j + d_k - c_m\\). interpretation thus follows standard binomial probit (logit) regression; SMDs (log ORs) greater zero mean treatment increases probability event compared comparator (less zero mean reduction probability). higher outcomes positive, active treatments estimated increase response (.e. greater reduction) PASI scale compared network reference (supportive care). default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Focusing specifically cutpoints see highly identified data, implicit flat priors work parameters.","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10),                   prior_aux = flat()) #> Note: Setting \"Supportive care\" as the network reference treatment. pso_fit_FE #> A fixed effects NMA with a ordered likelihood (probit link). #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff #> d[Ciclosporin]          1.92    0.01 0.33     1.31     1.69     1.90     2.13     2.61  1475 #> d[Efalizumab]           1.19    0.00 0.06     1.08     1.15     1.19     1.23     1.30  2233 #> d[Etanercept 25 mg]     1.51    0.00 0.10     1.32     1.45     1.51     1.58     1.71  2458 #> d[Etanercept 50 mg]     1.92    0.00 0.10     1.72     1.85     1.92     1.99     2.13  2516 #> d[Fumaderm]             1.48    0.01 0.49     0.63     1.14     1.45     1.78     2.54  2909 #> d[Infliximab]           2.33    0.01 0.27     1.81     2.14     2.33     2.51     2.88  2822 #> d[Methotrexate]         1.61    0.01 0.43     0.80     1.31     1.60     1.89     2.47  1721 #> lp__                -3405.15    0.09 3.59 -3412.96 -3407.28 -3404.76 -3402.59 -3399.11  1465 #> cc[PASI50]              0.00     NaN 0.00     0.00     0.00     0.00     0.00     0.00   NaN #> cc[PASI75]              0.76    0.00 0.03     0.70     0.74     0.76     0.78     0.82  5551 #> cc[PASI90]              1.57    0.00 0.05     1.46     1.53     1.56     1.60     1.67  5899 #>                     Rhat #> d[Ciclosporin]         1 #> d[Efalizumab]          1 #> d[Etanercept 25 mg]    1 #> d[Etanercept 50 mg]    1 #> d[Fumaderm]            1 #> d[Infliximab]          1 #> d[Methotrexate]        1 #> lp__                   1 #> cc[PASI50]           NaN #> cc[PASI75]             1 #> cc[PASI90]             1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:36:37 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_FE, pars = c(\"d\", \"mu\", \"cc\")) plot_prior_posterior(pso_fit_FE) plot_prior_posterior(pso_fit_FE, prior = \"aux\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Plaque psoriasis HTA report","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 10^2)\\) prior distributions treatment effects \\(d_k\\), \\(\\mathrm{N}(0, 100^2)\\) prior distributions study-specific intercepts \\(\\mu_j\\), implicit flat prior distributions latent cutpoints, additionally use \\(\\textrm{half-N}(2.5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 2.5)) #> A half-Normal prior distribution: location = 0, scale = 2.5. #> 50% of the prior density lies between 0 and 1.69. #> 95% of the prior density lies between 0 and 4.9. pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10),                   prior_aux = flat(),                   prior_het = half_normal(scale = 2.5),                   adapt_delta = 0.99) #> Note: Setting \"Supportive care\" as the network reference treatment. pso_fit_RE #> A random effects NMA with a ordered likelihood (probit link). #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=5000; warmup=2500; thin=1;  #> post-warmup draws per chain=2500, total post-warmup draws=10000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff #> d[Ciclosporin]          2.01    0.01 0.42     1.29     1.72     1.98     2.26     2.94  2577 #> d[Efalizumab]           1.19    0.00 0.17     0.83     1.11     1.19     1.27     1.54  3136 #> d[Etanercept 25 mg]     1.53    0.00 0.23     1.07     1.41     1.53     1.64     2.01  5049 #> d[Etanercept 50 mg]     1.93    0.00 0.27     1.40     1.79     1.93     2.05     2.46  4205 #> d[Fumaderm]             1.49    0.01 0.62     0.35     1.08     1.45     1.87     2.82  6850 #> d[Infliximab]           2.31    0.00 0.37     1.56     2.08     2.31     2.55     3.04  6869 #> d[Methotrexate]         1.70    0.01 0.62     0.58     1.30     1.67     2.05     3.03  3097 #> lp__                -3410.91    0.19 6.77 -3424.62 -3415.45 -3410.69 -3406.27 -3398.33  1217 #> tau                     0.30    0.01 0.22     0.02     0.14     0.25     0.40     0.86   864 #> cc[PASI50]              0.00     NaN 0.00     0.00     0.00     0.00     0.00     0.00   NaN #> cc[PASI75]              0.76    0.00 0.03     0.70     0.74     0.76     0.78     0.82 15056 #> cc[PASI90]              1.56    0.00 0.05     1.47     1.53     1.56     1.60     1.66 16398 #>                     Rhat #> d[Ciclosporin]      1.00 #> d[Efalizumab]       1.00 #> d[Etanercept 25 mg] 1.00 #> d[Etanercept 50 mg] 1.00 #> d[Fumaderm]         1.00 #> d[Infliximab]       1.00 #> d[Methotrexate]     1.00 #> lp__                1.01 #> tau                 1.01 #> cc[PASI50]           NaN #> cc[PASI75]          1.00 #> cc[PASI90]          1.00 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:37:32 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_RE, pars = c(\"d\", \"cc\", \"mu\", \"delta\")) plot_prior_posterior(pso_fit_RE, prior = c(\"trt\", \"aux\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Plaque psoriasis HTA report","text":"Model fit can checked using dic() function: random effects model lower DIC residual deviance closer number data points, preferred case. can also examine residual deviance contributions corresponding plot() method.   data points fit well, posterior mean residual deviances close degrees freedom. Meffert 1997 study substantially higher residual deviance contribution, investigated see study appears outlier.","code":"(dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 74.9 (on 58 data points) #>                pD: 25.4 #>               DIC: 100.3 (dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 63.3 (on 58 data points) #>                pD: 33.2 #>               DIC: 96.5 plot(dic_FE) plot(dic_RE)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"predicted-probabilities-of-response","dir":"Articles","previous_headings":"Further results","what":"Predicted probabilities of response","title":"Example: Plaque psoriasis HTA report","text":"Dias et al. (2011) produce absolute predictions probability achieving responses PASI cutoff, assuming Normal distribution baseline probit probability PASI50 response supportive care mean \\(-1.097\\) precision \\(123\\). can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted probabilities (type = \"link\" produce predicted probit probabilities).   instead information baseline PASI 50 response probit probability PASI 50 event counts, can use construct Beta distribution baseline probability PASI 50 response. example, 56 408 individuals achieved PASI 50 response supportive care target population interest, appropriate Beta distribution response probability \\(\\textrm{Beta}(56, 408-56)\\). can specify Beta distribution baseline response using baseline_type = \"reponse\" argument (default \"link\", used baseline probit probability).  (Notice results equivalent calculated using Normal distribution baseline probit probability, since event counts correspond probit probability.) can modify plots using standard ggplot2 functions. example, plot cutpoints together colour coding (instead split facets):  baseline argument omitted, predicted probabilities produced every study network based estimated baseline probit probability \\(\\mu_j\\).","code":"pred_FE <- predict(pso_fit_FE,                     baseline = distr(qnorm, mean = -1.097, sd = 123^-0.5),                     type = \"response\") pred_FE #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.18     3631     3432    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05     3958     3843    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01     4199     3591    1 #> pred[Ciclosporin, PASI50]      0.78 0.10 0.57 0.72 0.79 0.85  0.94     1552     2299    1 #> pred[Ciclosporin, PASI75]      0.52 0.13 0.28 0.43 0.52 0.61  0.78     1550     2285    1 #> pred[Ciclosporin, PASI90]      0.24 0.11 0.08 0.16 0.22 0.30  0.49     1589     2270    1 #> pred[Efalizumab, PASI50]       0.54 0.04 0.45 0.51 0.54 0.57  0.62     3093     3522    1 #> pred[Efalizumab, PASI75]       0.25 0.04 0.19 0.23 0.25 0.28  0.33     3304     3618    1 #> pred[Efalizumab, PASI90]       0.07 0.02 0.04 0.06 0.07 0.08  0.11     3455     3664    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.05 0.56 0.63 0.66 0.69  0.75     2877     2993    1 #> pred[Etanercept 25 mg, PASI75] 0.37 0.05 0.27 0.33 0.37 0.40  0.47     2988     2969    1 #> pred[Etanercept 25 mg, PASI90] 0.13 0.03 0.08 0.11 0.13 0.15  0.19     3185     3283    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.04 0.71 0.77 0.79 0.82  0.86     2871     3208    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.06 0.42 0.49 0.53 0.56  0.63     2958     3221    1 #> pred[Etanercept 50 mg, PASI90] 0.23 0.04 0.15 0.20 0.23 0.26  0.32     3171     3137    1 #> pred[Fumaderm, PASI50]         0.63 0.16 0.30 0.52 0.64 0.75  0.93     3206     2459    1 #> pred[Fumaderm, PASI75]         0.37 0.17 0.10 0.24 0.34 0.47  0.76     3225     2325    1 #> pred[Fumaderm, PASI90]         0.15 0.12 0.02 0.06 0.11 0.19  0.45     3251     2368    1 #> pred[Infliximab, PASI50]       0.88 0.05 0.75 0.85 0.89 0.92  0.96     2900     3003    1 #> pred[Infliximab, PASI75]       0.68 0.10 0.47 0.61 0.68 0.75  0.85     2924     2979    1 #> pred[Infliximab, PASI90]       0.38 0.11 0.19 0.30 0.37 0.45  0.60     2909     2846    1 #> pred[Methotrexate, PASI50]     0.68 0.14 0.38 0.58 0.70 0.79  0.92     1769     2308    1 #> pred[Methotrexate, PASI75]     0.41 0.16 0.14 0.29 0.40 0.52  0.74     1765     2321    1 #> pred[Methotrexate, PASI90]     0.17 0.11 0.03 0.09 0.15 0.22  0.44     1790     2074    1 plot(pred_FE) pred_RE <- predict(pso_fit_RE,                     baseline = distr(qnorm, mean = -1.097, sd = 123^-0.5),                     type = \"response\") pred_RE #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.18     9886     9993    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05    10318    10128    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01    11047     9957    1 #> pred[Ciclosporin, PASI50]      0.80 0.11 0.57 0.73 0.81 0.88  0.97     3241     2851    1 #> pred[Ciclosporin, PASI75]      0.56 0.15 0.28 0.44 0.55 0.66  0.87     3259     2835    1 #> pred[Ciclosporin, PASI90]      0.27 0.14 0.08 0.17 0.25 0.35  0.62     3276     2988    1 #> pred[Efalizumab, PASI50]       0.54 0.07 0.38 0.49 0.54 0.58  0.69     4652     3945    1 #> pred[Efalizumab, PASI75]       0.26 0.06 0.15 0.22 0.25 0.29  0.40     4750     4088    1 #> pred[Efalizumab, PASI90]       0.07 0.03 0.03 0.06 0.07 0.09  0.14     4863     4179    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.09 0.48 0.62 0.67 0.71  0.83     5547     4187    1 #> pred[Etanercept 25 mg, PASI75] 0.38 0.09 0.21 0.32 0.37 0.42  0.57     5573     4280    1 #> pred[Etanercept 25 mg, PASI90] 0.14 0.06 0.05 0.10 0.13 0.16  0.27     5678     4290    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.08 0.61 0.75 0.80 0.84  0.92     5324     3820    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.10 0.32 0.47 0.53 0.59  0.74     5277     3817    1 #> pred[Etanercept 50 mg, PASI90] 0.24 0.09 0.10 0.19 0.23 0.28  0.44     5342     4025    1 #> pred[Fumaderm, PASI50]         0.63 0.20 0.22 0.49 0.64 0.78  0.96     7380     4557    1 #> pred[Fumaderm, PASI75]         0.38 0.20 0.06 0.22 0.34 0.51  0.84     7411     4659    1 #> pred[Fumaderm, PASI90]         0.16 0.15 0.01 0.06 0.11 0.22  0.57     7503     4482    1 #> pred[Infliximab, PASI50]       0.87 0.08 0.68 0.84 0.89 0.93  0.98     7164     4708    1 #> pred[Infliximab, PASI75]       0.67 0.13 0.38 0.59 0.68 0.76  0.89     7093     4679    1 #> pred[Infliximab, PASI90]       0.37 0.13 0.13 0.28 0.36 0.46  0.66     7186     4759    1 #> pred[Methotrexate, PASI50]     0.69 0.18 0.30 0.58 0.72 0.83  0.97     3775     2836    1 #> pred[Methotrexate, PASI75]     0.44 0.21 0.10 0.29 0.43 0.58  0.88     3783     2912    1 #> pred[Methotrexate, PASI90]     0.20 0.16 0.02 0.09 0.16 0.27  0.66     3809     2883    1 plot(pred_RE) pred_FE_beta <- predict(pso_fit_FE,                          baseline = distr(qbeta, 56, 408-56),                         baseline_type = \"response\",                         type = \"response\") pred_FE_beta #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.17     3940     4002    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05     4137     3934    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01     4644     3739    1 #> pred[Ciclosporin, PASI50]      0.78 0.09 0.57 0.72 0.79 0.85  0.94     1600     2189    1 #> pred[Ciclosporin, PASI75]      0.52 0.13 0.28 0.43 0.52 0.61  0.78     1598     2222    1 #> pred[Ciclosporin, PASI90]      0.24 0.11 0.08 0.16 0.22 0.30  0.50     1635     2184    1 #> pred[Efalizumab, PASI50]       0.54 0.04 0.46 0.51 0.54 0.56  0.61     3251     3328    1 #> pred[Efalizumab, PASI75]       0.25 0.03 0.19 0.23 0.25 0.28  0.32     3414     3820    1 #> pred[Efalizumab, PASI90]       0.07 0.02 0.05 0.06 0.07 0.08  0.11     3593     3193    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.05 0.57 0.63 0.66 0.69  0.75     2969     3422    1 #> pred[Etanercept 25 mg, PASI75] 0.37 0.05 0.28 0.33 0.37 0.40  0.47     3055     3784    1 #> pred[Etanercept 25 mg, PASI90] 0.13 0.03 0.08 0.11 0.13 0.14  0.19     3299     3421    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.04 0.71 0.77 0.79 0.82  0.86     3018     3454    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.05 0.42 0.49 0.53 0.56  0.63     3070     3620    1 #> pred[Etanercept 50 mg, PASI90] 0.23 0.04 0.16 0.20 0.23 0.26  0.32     3338     3415    1 #> pred[Fumaderm, PASI50]         0.63 0.16 0.32 0.52 0.64 0.76  0.93     3217     2324    1 #> pred[Fumaderm, PASI75]         0.37 0.17 0.11 0.24 0.34 0.47  0.76     3230     2337    1 #> pred[Fumaderm, PASI90]         0.15 0.12 0.02 0.06 0.11 0.19  0.46     3265     2296    1 #> pred[Infliximab, PASI50]       0.88 0.05 0.76 0.85 0.89 0.92  0.96     2937     2923    1 #> pred[Infliximab, PASI75]       0.68 0.10 0.48 0.61 0.68 0.75  0.85     2966     2932    1 #> pred[Infliximab, PASI90]       0.38 0.11 0.19 0.30 0.37 0.44  0.59     2960     3025    1 #> pred[Methotrexate, PASI50]     0.68 0.14 0.38 0.59 0.69 0.79  0.92     1824     1869    1 #> pred[Methotrexate, PASI75]     0.41 0.16 0.14 0.29 0.40 0.52  0.74     1817     1973    1 #> pred[Methotrexate, PASI90]     0.17 0.11 0.03 0.09 0.14 0.22  0.43     1846     1873    1 plot(pred_FE_beta) pred_RE_beta <- predict(pso_fit_RE,                          baseline = distr(qbeta, 56, 408-56),                         baseline_type = \"response\",                         type = \"response\") pred_RE_beta #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.11 0.13 0.14 0.15  0.17     9843     9606    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05    10562     9723    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01    11624     9544    1 #> pred[Ciclosporin, PASI50]      0.80 0.10 0.57 0.73 0.81 0.88  0.97     3189     2739    1 #> pred[Ciclosporin, PASI75]      0.55 0.15 0.28 0.44 0.55 0.66  0.87     3208     2896    1 #> pred[Ciclosporin, PASI90]      0.27 0.14 0.08 0.17 0.25 0.35  0.62     3224     2751    1 #> pred[Efalizumab, PASI50]       0.54 0.07 0.39 0.50 0.54 0.58  0.68     4649     3782    1 #> pred[Efalizumab, PASI75]       0.26 0.06 0.15 0.22 0.25 0.29  0.39     4767     3780    1 #> pred[Efalizumab, PASI90]       0.07 0.03 0.03 0.06 0.07 0.09  0.14     4871     3891    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.08 0.48 0.62 0.67 0.71  0.82     5487     3960    1 #> pred[Etanercept 25 mg, PASI75] 0.38 0.09 0.21 0.32 0.37 0.42  0.57     5508     3932    1 #> pred[Etanercept 25 mg, PASI90] 0.14 0.06 0.05 0.10 0.13 0.16  0.27     5613     3976    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.08 0.61 0.75 0.80 0.83  0.92     5306     3563    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.10 0.32 0.47 0.53 0.58  0.74     5260     3645    1 #> pred[Etanercept 50 mg, PASI90] 0.24 0.08 0.10 0.19 0.23 0.28  0.44     5302     3640    1 #> pred[Fumaderm, PASI50]         0.63 0.20 0.22 0.49 0.64 0.78  0.96     7364     4214    1 #> pred[Fumaderm, PASI75]         0.38 0.20 0.06 0.22 0.34 0.51  0.83     7395     4299    1 #> pred[Fumaderm, PASI90]         0.16 0.15 0.01 0.06 0.11 0.22  0.56     7456     4232    1 #> pred[Infliximab, PASI50]       0.87 0.08 0.68 0.84 0.89 0.93  0.97     6991     4556    1 #> pred[Infliximab, PASI75]       0.67 0.13 0.39 0.59 0.68 0.76  0.89     6932     4235    1 #> pred[Infliximab, PASI90]       0.37 0.13 0.13 0.28 0.36 0.46  0.66     7024     4629    1 #> pred[Methotrexate, PASI50]     0.69 0.18 0.30 0.58 0.72 0.83  0.97     3689     3065    1 #> pred[Methotrexate, PASI75]     0.44 0.21 0.10 0.29 0.42 0.58  0.88     3708     3009    1 #> pred[Methotrexate, PASI90]     0.20 0.16 0.02 0.09 0.16 0.27  0.64     3745     2881    1 plot(pred_RE_beta) library(ggplot2) plot(pred_RE, position = position_dodge(width = 0.75)) +   facet_null() +   aes(colour = Category) +   scale_colour_brewer(palette = \"Blues\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"ranks-and-rank-probabilities","dir":"Articles","previous_headings":"Further results","what":"Ranks and rank probabilities","title":"Example: Plaque psoriasis HTA report","text":"Treatment rankings, rank probabilities, cumulative rank probabilities can also produced. set lower_better = FALSE since higher outcome categories better (outcomes positive).","code":"(pso_ranks <- posterior_ranks(pso_fit_RE, lower_better = FALSE)) #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[Supportive care]  7.99 0.10    8   8   8   8     8     6011       NA    1 #> rank[Ciclosporin]      2.79 1.27    1   2   3   4     5     6484     6981    1 #> rank[Efalizumab]       6.35 0.79    4   6   7   7     7     4253       NA    1 #> rank[Etanercept 25 mg] 4.90 1.07    3   4   5   6     7     6126     4791    1 #> rank[Etanercept 50 mg] 3.02 1.18    1   2   3   4     5     4881     4733    1 #> rank[Fumaderm]         4.89 1.97    1   3   5   7     7     7335     5606    1 #> rank[Infliximab]       1.77 1.16    1   1   1   2     5     2924     3998    1 #> rank[Methotrexate]     4.29 1.87    1   3   4   6     7     4574     5439    1 plot(pso_ranks) (pso_rankprobs <- posterior_rank_probs(pso_fit_RE, lower_better = FALSE)) #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] #> d[Supportive care]       0.00      0.00      0.00      0.00      0.00      0.00      0.01 #> d[Ciclosporin]           0.16      0.29      0.27      0.17      0.08      0.02      0.00 #> d[Efalizumab]            0.00      0.00      0.00      0.02      0.10      0.36      0.51 #> d[Etanercept 25 mg]      0.00      0.01      0.09      0.22      0.38      0.26      0.04 #> d[Etanercept 50 mg]      0.07      0.30      0.28      0.24      0.09      0.01      0.00 #> d[Fumaderm]              0.08      0.08      0.09      0.11      0.16      0.19      0.28 #> d[Infliximab]            0.59      0.19      0.12      0.06      0.02      0.01      0.00 #> d[Methotrexate]          0.09      0.12      0.15      0.18      0.17      0.15      0.15 #>                     p_rank[8] #> d[Supportive care]       0.99 #> d[Ciclosporin]           0.00 #> d[Efalizumab]            0.00 #> d[Etanercept 25 mg]      0.00 #> d[Etanercept 50 mg]      0.00 #> d[Fumaderm]              0.01 #> d[Infliximab]            0.00 #> d[Methotrexate]          0.00 plot(pso_rankprobs) (pso_cumrankprobs <- posterior_rank_probs(pso_fit_RE, lower_better = FALSE, cumulative = TRUE)) #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] #> d[Supportive care]       0.00      0.00      0.00      0.00      0.00      0.00      0.01 #> d[Ciclosporin]           0.16      0.45      0.73      0.90      0.98      1.00      1.00 #> d[Efalizumab]            0.00      0.00      0.01      0.03      0.13      0.49      1.00 #> d[Etanercept 25 mg]      0.00      0.02      0.10      0.32      0.70      0.96      1.00 #> d[Etanercept 50 mg]      0.07      0.38      0.66      0.89      0.98      1.00      1.00 #> d[Fumaderm]              0.08      0.16      0.26      0.37      0.53      0.72      0.99 #> d[Infliximab]            0.59      0.78      0.90      0.96      0.99      1.00      1.00 #> d[Methotrexate]          0.09      0.20      0.35      0.53      0.70      0.84      1.00 #>                     p_rank[8] #> d[Supportive care]          1 #> d[Ciclosporin]              1 #> d[Efalizumab]               1 #> d[Etanercept 25 mg]         1 #> d[Etanercept 50 mg]         1 #> d[Fumaderm]                 1 #> d[Infliximab]               1 #> d[Methotrexate]             1 plot(pso_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"study-data","dir":"Articles","previous_headings":"","what":"Study data","title":"Example: Newly diagnosed multiple myeloma","text":"consider adjustment following covariates: Age Sex ISS stage, -II vs. III Response post-ASCT, complete good partial response vs. lesser response summary distributions characteristics study follows:","code":"bind_rows(   summarise(ndmm_ipd,             N = n(),             age_mean = mean(age), age_sd = sd(age),             iss_stage3 = mean(iss_stage3),             response_cr_vgpr = mean(response_cr_vgpr),             male = mean(male),             .by = c(studyf, trtf)),   transmute(ndmm_agd_covs,             studyf, trtf,             N = sample_size,             age_mean, age_sd, iss_stage3, response_cr_vgpr, male) ) %>%   mutate(across(where(is.double), ~round(., digits = 2))) #>          studyf trtf    N age_mean age_sd iss_stage3 response_cr_vgpr male #> 1  McCarthy2012  Pbo  229    57.39   5.56       0.18             0.71 0.55 #> 2  McCarthy2012  Len  231    57.93   6.33       0.27             0.62 0.52 #> 3     Attal2012  Pbo  307    54.22   5.24       0.16             0.54 0.58 #> 4     Attal2012  Len  307    54.35   6.06       0.24             0.55 0.55 #> 5   Palumbo2014  Pbo  125    54.44   8.98       0.12             0.38 0.63 #> 6   Palumbo2014  Len  126    53.90   9.69       0.10             0.42 0.46 #> 7   Jackson2019  Len 1137    65.17   8.94       0.25             0.83 0.62 #> 8   Jackson2019  Pbo  864    64.63   9.40       0.19             0.83 0.62 #> 9    Morgan2012  Pbo  410    63.92   9.01       0.36             0.72 0.62 #> 10   Morgan2012 Thal  408    65.59   8.38       0.32             0.75 0.62"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"preparing-treatment-classes","dir":"Articles","previous_headings":"Setup","what":"Preparing treatment classes","title":"Example: Newly diagnosed multiple myeloma","text":"start setting network analysis. Since IPD placebo vs. lenalidomide comparison, one AgD study placebo vs. thalidomide comparison, make shared effect modifier assumption two active treatments order estimate effect modifying treatment-covariate interactions thalidomide Phillippo et al. (2020). Since lenalidomide thalidomide class treatments, assumption may reasonable. impose assumption, create treatment class variable active treatments vs. placebo.","code":"ndmm_ipd$trtclass <- case_match(ndmm_ipd$trtf,                                 \"Pbo\" ~ \"Placebo\",                                 c(\"Len\", \"Thal\") ~ \"Active\")  ndmm_agd$trtclass <- case_match(ndmm_agd$trtf,                                 \"Pbo\" ~ \"Placebo\",                                 c(\"Len\", \"Thal\") ~ \"Active\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"Setup","what":"Setting up the network","title":"Example: Newly diagnosed multiple myeloma","text":"set network using set_ipd(), set_agd_surv(), combine_network() functions. Since survival data form event/censoring times censoring indicators, use Surv argument set_*() functions set outcome data using usual survival::Surv() function. AgD set similar fashion IPD, except summary covariate information (data frame ndmm_agd_covs) included using covariates argument. data frame passed covariates must matching study treatment columns outcome data set (ndmm_agd), case studyf trtf respectively, one row per arm, covariate information can matched corresponding arms outcome data. IPD AgD combined single network using combine_network().","code":"ndmm_net <- combine_network(   set_ipd(ndmm_ipd,           study = studyf,           trt = trtf,           trt_class = trtclass,           Surv = Surv(eventtime, status)),   set_agd_surv(ndmm_agd,                study = studyf,                trt = trtf,                trt_class = trtclass,                Surv = Surv(eventtime, status),                covariates = ndmm_agd_covs) )"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"adding-numerical-integration-for-ml-nmr","dir":"Articles","previous_headings":"Setup","what":"Adding numerical integration for ML-NMR","title":"Example: Newly diagnosed multiple myeloma","text":"perform ML-NMR, need create numerical integration points joint covariate distributions AgD study. used integrate (.e. average) individual-level model joint covariate distribution form aggregate-level model. done using add_integration() function, covariate specify marginal distribution using distr() function. Since age skewed, use gamma distribution covariate; remaining covariates binary given Bernoulli distributions. procedure also requires information correlations covariates. known, can specified using cor argument. However, default weighted average correlations IPD studies used.","code":"ndmm_net <- add_integration(ndmm_net,                             age = distr(qgamma, mean = age_mean, sd = age_sd),                             iss_stage3 = distr(qbern, iss_stage3),                             response_cr_vgpr = distr(qbern, response_cr_vgpr),                             male = distr(qbern, male)) #> Using weighted average correlation matrix computed from IPD studies.  ndmm_net #> A network with 3 IPD studies, and 2 AgD studies (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study        Treatment arms #>  Attal2012    2: Pbo | Len   #>  McCarthy2012 2: Pbo | Len   #>  Palumbo2014  2: Pbo | Len   #>  #>  Outcome type: survival #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study       Treatment arms #>  Jackson2019 2: Pbo | Len   #>  Morgan2012  2: Pbo | Thal  #>  #>  Outcome type: survival #> ------------------------------------------------------------------------------------ #> Total number of treatments: 3, in 2 classes #> Total number of studies: 5 #> Reference treatment is: Pbo #> Network is connected #>  #> --------------------------------------------------------- Numerical integration ----  #> Numerical integration points available for 4 covariates:  #>   age iss_stage3 response_cr_vgpr male #> Number of numerical integration points: 64"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"network-plot","dir":"Articles","previous_headings":"Setup","what":"Network plot","title":"Example: Newly diagnosed multiple myeloma","text":"can plot network diagram using plot() method.","code":"plot(ndmm_net,      weight_nodes = TRUE,      weight_edges = TRUE,      # Nudge treatment labels away from nodes      nudge = 0.1,      # Manual layout      layout = data.frame(x = c(0, -1, 1),                          y = c(-0.5, 0, 0))) +   guides(edge_colour = guide_legend(override.aes = list(edge_width = 2))) +   theme(legend.position = \"bottom\", legend.direction = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"kaplan-meier-plots","dir":"Articles","previous_headings":"Setup","what":"Kaplan-Meier plots","title":"Example: Newly diagnosed multiple myeloma","text":"can produce Kaplan-Meier plots data study, aid geom_km() function.  transform argument geom_km() can used transform Kaplan-Meier curves prior plotting, example transform = \"cloglog\" assess proportional hazards log-log plot.","code":"ggplot() +   geom_km(ndmm_net) +   facet_wrap(~.study) +   labs(y = \"Survival probability\", x = \"Time\") +   coord_cartesian(ylim = c(0, 1)) +   theme_multinma() +   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"ml-nmr-models-with-m-spline-baseline-hazards","dir":"Articles","previous_headings":"","what":"ML-NMR models with M-spline baseline hazards","title":"Example: Newly diagnosed multiple myeloma","text":"fit proportional hazards survival model cubic M-splines baseline hazard Phillippo et al. (n.d.). allows baseline hazard flexibly follow shape baseline hazard may take. ML-NMR models fit using nma() function, specify M-spline baseline hazard used likelihood = \"mspline\". Fitting spline models requires user specify number location knots. default, seven internal knots used (n_knots = 7) placed evenly spaced quantiles observed event times within study. Overfitting avoided use random walk prior distribution (inverse softmax transformed) spline coefficients penalises complexity shrinks towards constant baseline hazard (Phillippo et al., n.d.); practice means number knots can set sufficiently large number left shrink suitable level complexity controlled standard deviation random walk. number knots can changed using n_knots argument, custom knot locations can specified using knots argument. nma() function always place boundary knots earliest entry time study (0 delayed entry) maximum event/censoring time. default, nma() function fit cubic M-spline (mspline_degree = 3). Piecewise-constant hazards (.e. piecewise exponential hazards) special case degree 0 splines, specified using likelihood = \"pexp\" (equivalent mspline_degree = 0). specify regression model using regression argument includes main effects covariates (prognostic effects) treatment-covariate interactions (effect modifier interactions) covariate. place vague \\(\\operatorname{N}(0, 100^2)\\) priors parameters linear predictor. give standard deviation random walk prior spline coefficients \\(\\operatorname{half-N}(0, 1^2)\\) prior distribution. also set QR = TRUE, using QR decomposition can greatly increase sampling efficiency regression models. details spline coefficients printed default, can shown print() summary() using pars option:","code":"ndmm_fit <- nma(ndmm_net,                 regression = ~(age + iss_stage3 + response_cr_vgpr + male)*.trt,                 likelihood = \"mspline\",                 prior_intercept = normal(0, 100),                 prior_trt = normal(0, 100),                 prior_reg = normal(0, 100),                 prior_aux = half_normal(1),                 QR = TRUE) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Cubic M-spline baseline hazard with 7 internal knots. #> Regression model: ~(age + iss_stage3 + response_cr_vgpr + male) * .trt. #> Centred covariates at the following overall mean values: #>              age       iss_stage3 response_cr_vgpr             male  #>       61.6558571        0.2297184        0.7314265        0.6020451  #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd      2.5%       25%       50% #> beta[age]                                   0.08    0.00 0.01      0.06      0.07      0.08 #> beta[iss_stage3]                            0.35    0.00 0.13      0.10      0.26      0.35 #> beta[response_cr_vgpr]                     -0.13    0.00 0.10     -0.34     -0.20     -0.13 #> beta[male]                                  0.00    0.00 0.10     -0.20     -0.07      0.00 #> beta[age:.trtclassActive]                  -0.02    0.00 0.01     -0.03     -0.02     -0.02 #> beta[iss_stage3:.trtclassActive]            0.20    0.00 0.17     -0.14      0.09      0.20 #> beta[response_cr_vgpr:.trtclassActive]      0.20    0.00 0.14     -0.09      0.10      0.20 #> beta[male:.trtclassActive]                  0.14    0.00 0.15     -0.17      0.03      0.14 #> d[Len]                                     -0.66    0.00 0.05     -0.77     -0.70     -0.66 #> d[Thal]                                    -0.20    0.00 0.11     -0.40     -0.27     -0.20 #> lp__                                   -12499.11    0.23 7.32 -12514.14 -12504.05 -12498.73 #> sigma[Attal2012]                            0.88    0.01 0.39      0.29      0.60      0.82 #> sigma[McCarthy2012]                         1.75    0.01 0.56      0.83      1.34      1.68 #> sigma[Palumbo2014]                          0.59    0.01 0.52      0.02      0.20      0.45 #> sigma[Jackson2019]                          0.81    0.01 0.33      0.33      0.57      0.75 #> sigma[Morgan2012]                           0.77    0.02 0.50      0.04      0.41      0.70 #>                                              75%     97.5% n_eff Rhat #> beta[age]                                   0.08      0.09  4376 1.00 #> beta[iss_stage3]                            0.43      0.59  4972 1.00 #> beta[response_cr_vgpr]                     -0.06      0.07  5101 1.00 #> beta[male]                                  0.07      0.20  5881 1.00 #> beta[age:.trtclassActive]                  -0.01      0.00  3695 1.00 #> beta[iss_stage3:.trtclassActive]            0.32      0.54  4979 1.00 #> beta[response_cr_vgpr:.trtclassActive]      0.29      0.48  4627 1.00 #> beta[male:.trtclassActive]                  0.24      0.44  5149 1.00 #> d[Len]                                     -0.63     -0.56  4987 1.00 #> d[Thal]                                    -0.12      0.01  3918 1.01 #> lp__                                   -12493.85 -12485.92  1052 1.01 #> sigma[Attal2012]                            1.09      1.82  1936 1.00 #> sigma[McCarthy2012]                         2.11      2.98  2491 1.00 #> sigma[Palumbo2014]                          0.85      1.93  1445 1.00 #> sigma[Jackson2019]                          0.98      1.59  1734 1.01 #> sigma[Morgan2012]                           1.06      1.95   969 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Thu Oct 12 19:58:13 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). summary(ndmm_fit, pars = \"scoef\") #>                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> scoef[Attal2012, 1]     0.02 0.00 0.01 0.01 0.02 0.02  0.03     2468     1624 1.00 #> scoef[McCarthy2012, 1]  0.01 0.00 0.00 0.00 0.01 0.01  0.01     3523     3205 1.00 #> scoef[Palumbo2014, 1]   0.01 0.00 0.01 0.01 0.02 0.02  0.02     2116     3388 1.00 #> scoef[Jackson2019, 1]   0.01 0.00 0.01 0.01 0.01 0.01  0.02     2495     3269 1.01 #> scoef[Morgan2012, 1]    0.01 0.00 0.01 0.01 0.01 0.01  0.02     1165     2636 1.01 #> scoef[Attal2012, 2]     0.03 0.01 0.02 0.02 0.03 0.03  0.04     2661     1995 1.00 #> scoef[McCarthy2012, 2]  0.01 0.01 0.00 0.01 0.01 0.02  0.03     3293     3334 1.00 #> scoef[Palumbo2014, 2]   0.03 0.01 0.02 0.03 0.03 0.03  0.04     2465     3270 1.00 #> scoef[Jackson2019, 2]   0.02 0.00 0.02 0.02 0.02 0.03  0.03     2222     3147 1.01 #> scoef[Morgan2012, 2]    0.02 0.00 0.01 0.02 0.02 0.03  0.03     1342     2926 1.01 #> scoef[Attal2012, 3]     0.05 0.01 0.04 0.05 0.05 0.06  0.07     3837     3615 1.00 #> scoef[McCarthy2012, 3]  0.05 0.01 0.03 0.04 0.05 0.06  0.09     3373     3301 1.00 #> scoef[Palumbo2014, 3]   0.05 0.01 0.04 0.05 0.05 0.06  0.07     4695     3591 1.00 #> scoef[Jackson2019, 3]   0.04 0.00 0.04 0.04 0.04 0.05  0.05     3312     3224 1.00 #> scoef[Morgan2012, 3]    0.04 0.01 0.03 0.04 0.04 0.05  0.06     3584     3326 1.00 #> scoef[Attal2012, 4]     0.09 0.01 0.06 0.08 0.08 0.09  0.11     4699     2958 1.00 #> scoef[McCarthy2012, 4]  0.09 0.02 0.06 0.08 0.09 0.10  0.13     4182     3236 1.00 #> scoef[Palumbo2014, 4]   0.07 0.01 0.05 0.06 0.07 0.07  0.09     4427     3725 1.00 #> scoef[Jackson2019, 4]   0.06 0.01 0.05 0.06 0.06 0.07  0.08     3811     3104 1.00 #> scoef[Morgan2012, 4]    0.07 0.01 0.05 0.06 0.07 0.07  0.08     3657     3469 1.00 #> scoef[Attal2012, 5]     0.10 0.01 0.07 0.09 0.10 0.11  0.13     4416     3747 1.00 #> scoef[McCarthy2012, 5]  0.07 0.02 0.04 0.06 0.07 0.09  0.11     3400     3357 1.00 #> scoef[Palumbo2014, 5]   0.09 0.01 0.07 0.08 0.08 0.09  0.12     3100     3537 1.00 #> scoef[Jackson2019, 5]   0.08 0.01 0.07 0.08 0.08 0.09  0.10     3484     3268 1.00 #> scoef[Morgan2012, 5]    0.08 0.01 0.07 0.08 0.08 0.09  0.11     1542     2765 1.00 #> scoef[Attal2012, 6]     0.11 0.02 0.08 0.10 0.11 0.12  0.15     4130     3521 1.00 #> scoef[McCarthy2012, 6]  0.08 0.02 0.05 0.07 0.08 0.09  0.12     3733     3526 1.00 #> scoef[Palumbo2014, 6]   0.09 0.01 0.06 0.08 0.09 0.09  0.12     4718     3260 1.00 #> scoef[Jackson2019, 6]   0.11 0.01 0.09 0.10 0.11 0.11  0.13     3673     3629 1.00 #> scoef[Morgan2012, 6]    0.10 0.01 0.08 0.09 0.10 0.11  0.13     3914     3569 1.00 #> scoef[Attal2012, 7]     0.14 0.02 0.11 0.13 0.14 0.15  0.19     3454     3624 1.00 #> scoef[McCarthy2012, 7]  0.13 0.03 0.08 0.11 0.12 0.14  0.18     3538     3333 1.00 #> scoef[Palumbo2014, 7]   0.13 0.02 0.10 0.12 0.12 0.14  0.18     3550     3357 1.00 #> scoef[Jackson2019, 7]   0.13 0.01 0.10 0.12 0.13 0.13  0.15     3705     3604 1.00 #> scoef[Morgan2012, 7]    0.13 0.02 0.10 0.12 0.13 0.14  0.16     4651     3552 1.00 #> scoef[Attal2012, 8]     0.17 0.02 0.12 0.15 0.17 0.18  0.22     4415     3648 1.00 #> scoef[McCarthy2012, 8]  0.19 0.04 0.12 0.16 0.18 0.21  0.27     3589     3194 1.00 #> scoef[Palumbo2014, 8]   0.18 0.03 0.13 0.17 0.18 0.19  0.24     4096     3493 1.00 #> scoef[Jackson2019, 8]   0.19 0.02 0.15 0.18 0.19 0.20  0.23     3722     3896 1.00 #> scoef[Morgan2012, 8]    0.20 0.02 0.15 0.18 0.19 0.21  0.25     3894     3098 1.00 #> scoef[Attal2012, 9]     0.12 0.02 0.07 0.10 0.12 0.13  0.16     4005     3200 1.00 #> scoef[McCarthy2012, 9]  0.12 0.04 0.05 0.10 0.12 0.15  0.20     2951     3267 1.00 #> scoef[Palumbo2014, 9]   0.14 0.03 0.08 0.13 0.15 0.16  0.18     3351     3011 1.00 #> scoef[Jackson2019, 9]   0.15 0.02 0.11 0.13 0.15 0.16  0.19     3277     3337 1.00 #> scoef[Morgan2012, 9]    0.16 0.03 0.11 0.15 0.16 0.17  0.22     3822     3196 1.00 #> scoef[Attal2012, 10]    0.10 0.02 0.07 0.09 0.10 0.11  0.14     4864     3366 1.00 #> scoef[McCarthy2012, 10] 0.16 0.04 0.09 0.13 0.15 0.18  0.24     4056     3424 1.00 #> scoef[Palumbo2014, 10]  0.13 0.02 0.08 0.12 0.13 0.14  0.18     5155     3406 1.00 #> scoef[Jackson2019, 10]  0.12 0.02 0.09 0.11 0.12 0.13  0.16     3572     3232 1.00 #> scoef[Morgan2012, 10]   0.12 0.02 0.08 0.11 0.12 0.13  0.17     4044     3655 1.00 #> scoef[Attal2012, 11]    0.07 0.02 0.05 0.06 0.07 0.08  0.11     6035     3940 1.00 #> scoef[McCarthy2012, 11] 0.09 0.03 0.04 0.06 0.08 0.10  0.15     4969     3157 1.00 #> scoef[Palumbo2014, 11]  0.08 0.02 0.05 0.07 0.08 0.09  0.13     4934     3655 1.00 #> scoef[Jackson2019, 11]  0.08 0.01 0.06 0.07 0.08 0.09  0.12     4599     3791 1.00 #> scoef[Morgan2012, 11]   0.06 0.02 0.03 0.05 0.07 0.08  0.09     2666     3835 1.00"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"ploting-hazards","dir":"Articles","previous_headings":"ML-NMR models with M-spline baseline hazards","what":"Ploting hazards","title":"Example: Newly diagnosed multiple myeloma","text":"Let us look estimated hazard functions model. default, predict() function type = \"hazard\" produce plots population-average marginal hazards (level = \"aggregate\", default). can plotted using plot() function.  can also look individual-level baseline hazards. possible using predict() function, time level = \"individual\". Since want show baseline hazard reference level covariates, ’ll create data frame pass predict() newdata. Since providing new data frame prediction, also need provide times predict distributions baseline (intercept) auxiliary (spline coefficient) parameters. predict evenly spaced times time 0 last event/censoring time study. specify named list study names baseline aux, use posterior distributions study parameters. produce predictions plot:","code":"plot(predict(ndmm_fit, type = \"hazard\", level = \"aggregate\")) refdat <- tibble(study = ndmm_net$studies,                  age = ndmm_fit$xbar[\"age\"],                  iss_stage3 = 0,                  response_cr_vgpr = 0,                  male = 0) # At evenly spaced times between the boundary knots tdat <- purrr::imap_dfr(ndmm_fit$basis,                         ~tibble(study = factor(.y, levels = ndmm_net$studies),                                 lower = attr(.x, \"Boundary.knots\")[1],                                 upper = attr(.x, \"Boundary.knots\")[2],                                 times = seq(lower, upper, length = 50)))  refdat <- left_join(refdat, tdat, by = \"study\")  studies <- as.list(setNames(nm = levels(ndmm_net$studies))) plot(predict(ndmm_fit, type = \"hazard\", level = \"individual\",              newdata = refdat, study = study, times = times,              baseline = studies, aux = studies))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"assessing-the-proportional-hazards-assumption","dir":"Articles","previous_headings":"","what":"Assessing the proportional hazards assumption","title":"Example: Newly diagnosed multiple myeloma","text":"can relax assess proportional hazards (PH) assumption allowing spline coefficients vary treatment arms within study. may achieved using aux_by argument, aux_by = c(.study, .trt). Technically, aux_by = .study always assumed order respect randomisation (analogous stratifying intercept terms NMA study), simply write aux_by = .trt; choose make stratification study explicit instance. compare model fit models without PH using LOOIC. overall fit proportional hazards model better. check single study better fit non-PH model, case improved fit one study masked increased complexity others. LOOIC similar lower proportional hazards model compared non-proportional hazards model studies. Based LOOIC alone, evidence suggest proportional hazards assumption invalid . Later, visual inspection estimated survival curves also suggests model good fit data. Stratifying baseline hazards treatment arm (well study) results model produce absolute predictions treatments populations already observed; e.g. estimated survival curve thalidomide can produced Morgan2012 study population (study thalidomide arm), survival curve lenalidomide produced population. Instead, proportional hazards assumption deemed inappropriate, might consider instead modelling departures proportional hazards using aux_regression argument nma() places model (inverse softmax transformed) spline coefficients, shape parameters parametric model. example, can allow baseline hazard vary smoothly treatment arm (aux_regression = ~.trt) /covariates (e.g. aux_regression = ~.trt + iss_stage3). relaxes proportional hazards assumption (already relaxed inclusion patient-level covariates), whilst still allowing predictions produced every treatment population interest.","code":"ndmm_fit_nph <- nma(ndmm_net,                     regression = ~(age + iss_stage3 + response_cr_vgpr + male)*.trt,                     likelihood = \"mspline\",                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_reg = normal(0, 100),                     prior_aux = half_normal(1),                     aux_by = c(.study, .trt),                     QR = TRUE) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nph #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Cubic M-spline baseline hazard with 7 internal knots. #> Regression model: ~(age + iss_stage3 + response_cr_vgpr + male) * .trt. #> Centred covariates at the following overall mean values: #>              age       iss_stage3 response_cr_vgpr             male  #>       61.6558571        0.2297184        0.7314265        0.6020451  #> Stratified baseline hazards by .study and .trt. #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd      2.5%       25%       50% #> beta[age]                                   0.07    0.00 0.01      0.06      0.07      0.07 #> beta[iss_stage3]                            0.33    0.00 0.13      0.08      0.24      0.33 #> beta[response_cr_vgpr]                     -0.11    0.00 0.10     -0.30     -0.18     -0.11 #> beta[male]                                 -0.01    0.00 0.10     -0.21     -0.08     -0.01 #> beta[age:.trtclassActive]                  -0.01    0.00 0.01     -0.03     -0.02     -0.01 #> beta[iss_stage3:.trtclassActive]            0.24    0.00 0.17     -0.11      0.11      0.24 #> beta[response_cr_vgpr:.trtclassActive]      0.16    0.00 0.14     -0.12      0.06      0.16 #> beta[male:.trtclassActive]                  0.15    0.00 0.15     -0.14      0.05      0.15 #> d[Len]                                     -0.62    0.00 0.07     -0.75     -0.66     -0.62 #> d[Thal]                                    -0.26    0.00 0.12     -0.49     -0.33     -0.25 #> lp__                                   -12534.68    0.27 9.19 -12553.34 -12540.75 -12534.38 #> sigma[Attal2012: Pbo]                       0.93    0.01 0.42      0.17      0.64      0.89 #> sigma[Attal2012: Len]                       0.63    0.01 0.40      0.06      0.34      0.55 #> sigma[McCarthy2012: Pbo]                    1.38    0.01 0.53      0.56      0.98      1.31 #> sigma[McCarthy2012: Len]                    1.20    0.01 0.46      0.50      0.86      1.14 #> sigma[Palumbo2014: Pbo]                     0.60    0.01 0.49      0.02      0.24      0.49 #> sigma[Palumbo2014: Len]                     0.77    0.01 0.54      0.03      0.35      0.68 #> sigma[Jackson2019: Pbo]                     0.63    0.01 0.33      0.16      0.40      0.58 #> sigma[Jackson2019: Len]                     0.99    0.01 0.41      0.35      0.69      0.93 #> sigma[Morgan2012: Pbo]                      0.33    0.01 0.32      0.01      0.10      0.23 #> sigma[Morgan2012: Thal]                     1.02    0.01 0.49      0.19      0.67      0.97 #>                                              75%     97.5% n_eff Rhat #> beta[age]                                   0.08      0.09  3031    1 #> beta[iss_stage3]                            0.42      0.58  5960    1 #> beta[response_cr_vgpr]                     -0.04      0.08  6219    1 #> beta[male]                                  0.05      0.19  5980    1 #> beta[age:.trtclassActive]                  -0.01      0.01  3006    1 #> beta[iss_stage3:.trtclassActive]            0.36      0.58  5580    1 #> beta[response_cr_vgpr:.trtclassActive]      0.25      0.43  4989    1 #> beta[male:.trtclassActive]                  0.25      0.46  4670    1 #> d[Len]                                     -0.57     -0.49  2884    1 #> d[Thal]                                    -0.17     -0.03  5412    1 #> lp__                                   -12528.20 -12517.61  1138    1 #> sigma[Attal2012: Pbo]                       1.18      1.86  1319    1 #> sigma[Attal2012: Len]                       0.84      1.59  1986    1 #> sigma[McCarthy2012: Pbo]                    1.70      2.59  2816    1 #> sigma[McCarthy2012: Len]                    1.47      2.27  2672    1 #> sigma[Palumbo2014: Pbo]                     0.84      1.85  2023    1 #> sigma[Palumbo2014: Len]                     1.09      2.06  2084    1 #> sigma[Jackson2019: Pbo]                     0.80      1.42  1811    1 #> sigma[Jackson2019: Len]                     1.24      1.94  1921    1 #> sigma[Morgan2012: Pbo]                      0.45      1.22  2206    1 #> sigma[Morgan2012: Thal]                     1.31      2.12  1601    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Oct 12 22:47:57 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). (ndmm_fit_loo <- loo(ndmm_fit)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12398.8 116.0 #> p_loo        35.1   0.7 #> looic     24797.7 232.1 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details. (ndmm_fit_nph_loo <- loo(ndmm_fit_nph)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12405.4 116.1 #> p_loo        44.2   0.8 #> looic     24810.9 232.2 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  # Compare to PH model loo_compare(ndmm_fit_loo, ndmm_fit_nph_loo) #>        elpd_diff se_diff #> model1  0.0       0.0    #> model2 -6.6       3.5 studies_all <- c(ndmm_ipd$study, ndmm_agd$study) cbind(   PH = by(ndmm_fit_loo$pointwise[, \"looic\"], studies_all, sum),   `non-PH` = by(ndmm_fit_nph_loo$pointwise[, \"looic\"], studies_all, sum) ) #>                     PH    non-PH #> Attal2012     3345.132  3346.962 #> Jackson2019  12398.245 12400.166 #> McCarthy2012  2726.430  2737.793 #> Morgan2012    4991.066  4989.484 #> Palumbo2014   1336.786  1336.462"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"comparison-to-unadjusted-nma","dir":"Articles","previous_headings":"","what":"Comparison to unadjusted NMA","title":"Example: Newly diagnosed multiple myeloma","text":"comparison, also fit NMA models without covariate adjustment, without proportional hazards assumption. , compare model fit using LOOIC, overall within study. Whilst little difference overall model fit, non-PH model preferred Jackson2019 study substantially lower LOOIC. Including covariates ML-NMR model sufficient remove PH violation, even though covariates fixed time-varying, ML-NMR model much better fit overall. Note: test likely low power, substitute usual inspection proportional hazards prior analysis. Using transform = \"cloglog\" geom_km() produce log-log plots one option assess proportionality.","code":"ndmm_fit_nma <- nma(ndmm_net,                     likelihood = \"mspline\",                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_aux = half_normal(1)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nma #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Cubic M-spline baseline hazard with 7 internal knots. #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                          mean se_mean   sd      2.5%       25%       50%       75%     97.5% n_eff #> d[Len]                  -0.52    0.00 0.05     -0.61     -0.55     -0.52     -0.49     -0.43  3117 #> d[Thal]                 -0.11    0.00 0.09     -0.28     -0.17     -0.11     -0.05      0.07  4059 #> lp__                -12533.05    0.21 6.85 -12547.59 -12537.46 -12532.59 -12528.12 -12521.11  1032 #> sigma[Attal2012]         0.82    0.01 0.39      0.19      0.55      0.77      1.04      1.74  1573 #> sigma[McCarthy2012]      1.71    0.01 0.56      0.76      1.29      1.66      2.06      2.95  2142 #> sigma[Palumbo2014]       0.66    0.01 0.50      0.04      0.29      0.55      0.91      1.89  1794 #> sigma[Jackson2019]       0.85    0.01 0.31      0.41      0.62      0.80      1.01      1.59  1960 #> sigma[Morgan2012]        0.90    0.01 0.46      0.29      0.57      0.80      1.14      2.02  1424 #>                     Rhat #> d[Len]                 1 #> d[Thal]                1 #> lp__                   1 #> sigma[Attal2012]       1 #> sigma[McCarthy2012]    1 #> sigma[Palumbo2014]     1 #> sigma[Jackson2019]     1 #> sigma[Morgan2012]      1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Oct 12 23:00:43 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1).  ndmm_fit_nma_nph <- nma(ndmm_net,                         likelihood = \"mspline\",                         prior_intercept = normal(0, 100),                         prior_trt = normal(0, 100),                         prior_aux = half_normal(1),                         aux_by = c(.study, .trt)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nma_nph #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Cubic M-spline baseline hazard with 7 internal knots. #> Stratified baseline hazards by .study and .trt. #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[Len]                       -0.47    0.00 0.05     -0.57     -0.50     -0.47     -0.43     -0.37 #> d[Thal]                      -0.14    0.00 0.10     -0.34     -0.21     -0.14     -0.08      0.05 #> lp__                     -12563.41    0.25 8.85 -12581.68 -12569.30 -12563.15 -12557.29 -12547.02 #> sigma[Attal2012: Pbo]         0.95    0.01 0.43      0.22      0.65      0.91      1.20      1.94 #> sigma[Attal2012: Len]         0.51    0.01 0.38      0.03      0.23      0.43      0.70      1.44 #> sigma[McCarthy2012: Pbo]      1.26    0.01 0.55      0.40      0.86      1.19      1.60      2.57 #> sigma[McCarthy2012: Len]      1.13    0.01 0.47      0.42      0.78      1.06      1.39      2.22 #> sigma[Palumbo2014: Pbo]       0.87    0.01 0.50      0.13      0.51      0.78      1.14      2.07 #> sigma[Palumbo2014: Len]       0.72    0.01 0.56      0.03      0.28      0.59      1.05      2.06 #> sigma[Jackson2019: Pbo]       0.88    0.01 0.32      0.43      0.65      0.83      1.05      1.68 #> sigma[Jackson2019: Len]       1.06    0.01 0.43      0.45      0.75      0.98      1.30      2.09 #> sigma[Morgan2012: Pbo]        0.51    0.01 0.35      0.05      0.26      0.43      0.68      1.40 #> sigma[Morgan2012: Thal]       1.07    0.01 0.45      0.36      0.74      1.01      1.33      2.12 #>                          n_eff Rhat #> d[Len]                    2546    1 #> d[Thal]                   3304    1 #> lp__                      1252    1 #> sigma[Attal2012: Pbo]     1825    1 #> sigma[Attal2012: Len]     1854    1 #> sigma[McCarthy2012: Pbo]  2327    1 #> sigma[McCarthy2012: Len]  2396    1 #> sigma[Palumbo2014: Pbo]   2391    1 #> sigma[Palumbo2014: Len]   2302    1 #> sigma[Jackson2019: Pbo]   2060    1 #> sigma[Jackson2019: Len]   1774    1 #> sigma[Morgan2012: Pbo]    2150    1 #> sigma[Morgan2012: Thal]   2407    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Oct 12 23:07:04 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Compare overall model fit (ndmm_fit_nma_loo <- loo(ndmm_fit_nma)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12473.4 115.2 #> p_loo        27.1   0.4 #> looic     24946.7 230.5 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  (ndmm_fit_nma_nph_loo <- loo(ndmm_fit_nma_nph)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate    SE #> elpd_loo -12475.9 115.3 #> p_loo        37.6   0.6 #> looic     24951.8 230.6 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  loo_compare(ndmm_fit_nma_loo, ndmm_fit_nma_nph_loo) #>        elpd_diff se_diff #> model1  0.0       0.0    #> model2 -2.5       4.4  # Compare model fit by study cbind(   PH = by(ndmm_fit_nma_loo$pointwise[, \"looic\"], studies_all, sum),   `non-PH` = by(ndmm_fit_nma_nph_loo$pointwise[, \"looic\"], studies_all, sum) ) #>                     PH    non-PH #> Attal2012     3410.058  3410.280 #> Jackson2019  12404.314 12398.934 #> McCarthy2012  2770.382  2781.407 #> Morgan2012    4989.289  4990.538 #> Palumbo2014   1372.698  1370.594"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"producing-population-average-estimates","dir":"Articles","previous_headings":"","what":"Producing population-average estimates","title":"Example: Newly diagnosed multiple myeloma","text":"now produce population-average estimates several different quantities interest. usual array posterior summary functions available, including relative_effects(), predict(), posterior_ranks() posterior_rank_probs(). predict() function particular numerous options working survival models, selected using type argument: \"survival\" survival probabilities \"hazard\" hazards \"cumhaz\" cumulative hazards \"rmst\" restricted mean survival times \"mean\" mean survival times (equivalent type = \"rmst\" time = Inf) \"quantile\" quantiles survival time distribution \"median\" median survival times (equivalent type = \"quantile\" quantiles = 0.5) \"link\" linear predictor producing population-average predictions (default level = \"aggregate\"), quantities corresponds population-average marginal survival function; see ?predict.stan_nma details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-survival-probabilities","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average survival probabilities","title":"Example: Newly diagnosed multiple myeloma","text":"produce population-average survival curves use predict() function type = \"survival\". marginal standardised survival curves. also overlay unadjusted Kaplan-Meier curves data using geom_km() helper function.  Whilst adjusted unadjusted curves exactly comparable (although marginal survival estimates, adjusted curves account differences covariate distributions arms relevant overall population study), estimated survival curves good fit data. baseline imbalance sex Palumbo2014 study accounted model, explains slight differences Kaplan-Meier curves .","code":"plot(predict(ndmm_fit, type = \"survival\")) +    geom_km(ndmm_net) +   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-median-survival-times","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average median survival times","title":"Example: Newly diagnosed multiple myeloma","text":"predict() function can produce range absolute effect summaries, example population-average median survival times:","code":"(medsurv <- predict(ndmm_fit, type = \"median\")) #> Warning: Evaluating M-spline at times beyond the boundary knots. #> Evaluating M-spline at times beyond the boundary knots. #> Evaluating M-spline at times beyond the boundary knots. #> Evaluating M-spline at times beyond the boundary knots. #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Attal2012: Pbo]  28.95 1.47 26.13 27.93 28.93 29.90 31.91     5299     3136 1.00 #> pred[Attal2012: Len]  46.74 2.33 42.20 45.14 46.78 48.29 51.41     7287     3045 1.00 #> pred[Attal2012: Thal] 32.35 3.42 26.30 29.99 32.11 34.43 39.96     2487     3264 1.01 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                           mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[McCarthy2012: Pbo]  33.79 2.11 29.63 32.37 33.74 35.16 38.05     4417     3185 1.00 #> pred[McCarthy2012: Len]  55.66 3.31 49.21 53.37 55.69 57.81 62.25     5297     3292 1.00 #> pred[McCarthy2012: Thal] 38.52 4.02 31.17 35.83 38.32 41.02 46.74     3925     3168 1.01 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Palumbo2014: Pbo]  22.29 2.21 18.29 20.75 22.14 23.76 26.91     4908     3445 1.00 #> pred[Palumbo2014: Len]  44.53 4.65 36.18 41.24 44.34 47.42 54.18     7050     2970 1.00 #> pred[Palumbo2014: Thal] 27.56 4.21 20.07 24.61 27.28 30.17 36.60     4591     3615 1.01 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Jackson2019: Pbo]  24.45 1.34 22.02 23.50 24.43 25.33 27.15     2035     3398 1.01 #> pred[Jackson2019: Len]  50.47 2.48 45.75 48.76 50.38 52.05 55.47      118     2795 1.03 #> pred[Jackson2019: Thal] 31.27 3.76 24.60 28.64 31.03 33.65 39.21     5212     3108 1.00 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                         mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Morgan2012: Pbo]  21.22 1.90 17.67 19.91 21.13 22.45 25.26     1157     3295 1.01 #> pred[Morgan2012: Len]  48.88 6.57 38.03 44.37 48.25 52.45 63.32      873     3187 1.01 #> pred[Morgan2012: Thal] 27.59 2.50 23.22 25.81 27.40 29.25 32.85     4950     3698 1.00  plot(medsurv)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-conditional-log-hazard-ratios","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average conditional log hazard ratios","title":"Example: Newly diagnosed multiple myeloma","text":"Relative effects produced using relative_effects() function. ML-NMR model (IPD meta-regression), population-average conditional log hazard ratios (log survival time ratios AFT models).","code":"(loghr <- relative_effects(ndmm_fit, all_contrasts = TRUE)) #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  54.29        0.2             0.54 0.57 #>  #>                             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Attal2012: Len vs. Pbo]  -0.60 0.07 -0.74 -0.64 -0.59 -0.54 -0.45     7342     3387 1.00 #> d[Attal2012: Thal vs. Pbo] -0.13 0.13 -0.39 -0.22 -0.13 -0.04  0.12     4188     3416 1.01 #> d[Attal2012: Thal vs. Len]  0.46 0.12  0.24  0.38  0.46  0.54  0.69     3631     3276 1.01 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  57.66       0.23             0.67 0.54 #>  #>                                mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[McCarthy2012: Len vs. Pbo]  -0.62 0.06 -0.74 -0.66 -0.62 -0.58 -0.51     7421     3243 1.00 #> d[McCarthy2012: Thal vs. Pbo] -0.16 0.12 -0.39 -0.24 -0.16 -0.08  0.07     4194     2877 1.01 #> d[McCarthy2012: Thal vs. Len]  0.46 0.12  0.24  0.38  0.46  0.54  0.69     3631     3276 1.01 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  54.17       0.11              0.4 0.55 #>  #>                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Palumbo2014: Len vs. Pbo]  -0.64 0.08 -0.80 -0.70 -0.64 -0.58 -0.48     7666     3354 1.00 #> d[Palumbo2014: Thal vs. Pbo] -0.18 0.14 -0.44 -0.27 -0.18 -0.08  0.09     4182     3321 1.01 #> d[Palumbo2014: Thal vs. Len]  0.46 0.12  0.24  0.38  0.46  0.54  0.69     3631     3276 1.01 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  64.63       0.21             0.84 0.62 #>  #>                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Jackson2019: Len vs. Pbo]  -0.69 0.06 -0.81 -0.72 -0.69 -0.64 -0.57     4040     3447 1.00 #> d[Jackson2019: Thal vs. Pbo] -0.22 0.11 -0.44 -0.29 -0.22 -0.15 -0.01     4339     2883 1.01 #> d[Jackson2019: Thal vs. Len]  0.46 0.12  0.24  0.38  0.46  0.54  0.69     3631     3276 1.01 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  64.46       0.33             0.73 0.62 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Morgan2012: Len vs. Pbo]  -0.68 0.06 -0.80 -0.72 -0.68 -0.64 -0.56     4134     3288 1.00 #> d[Morgan2012: Thal vs. Pbo] -0.22 0.10 -0.42 -0.28 -0.22 -0.15 -0.02     4430     2726 1.01 #> d[Morgan2012: Thal vs. Len]  0.46 0.12  0.24  0.38  0.46  0.54  0.69     3631     3276 1.01  plot(loghr)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-arm-based-data","dir":"Articles","previous_headings":"","what":"Analysis of arm-based data","title":"Example: Parkinson's disease","text":"begin analysis arm-based data - means standard errors.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"arm-level continuous data giving mean -time reduction (y) standard error (se) arm. use function set_agd_arm() set network. let treatment 4 set default network reference treatment, since results considerably improved sampling efficiency choosing treatment 1 network reference. sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"arm_net <- set_agd_arm(parkinsons,                        study = studyn,                       trt = trtn,                       y = y,                        se = se,                       sample_size = n) arm_net #> A network with 7 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(arm_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. arm_fit_FE <- nma(arm_net,                    trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10)) #> Note: Setting \"4\" as the network reference treatment. arm_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>       mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat #> d[1]  0.54    0.01 0.48  -0.40  0.21  0.54  0.86  1.50  1400    1 #> d[2] -1.28    0.01 0.53  -2.28 -1.65 -1.27 -0.92 -0.25  1525    1 #> d[3]  0.05    0.01 0.33  -0.61 -0.17  0.05  0.28  0.69  1930    1 #> d[5] -0.30    0.00 0.21  -0.73 -0.44 -0.30 -0.16  0.09  2683    1 #> lp__ -6.73    0.06 2.43 -12.38 -8.12 -6.36 -4.98 -3.12  1570    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:38:15 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(arm_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(arm_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. arm_fit_RE <- nma(arm_net,                    seed = 379394727,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = half_normal(scale = 5),                   adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. #> Warning: There were 3 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems pairs(arm_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\")) arm_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75% 97.5% n_eff Rhat #> d[1]   0.51    0.02 0.63  -0.67   0.11   0.52   0.91  1.70  1684    1 #> d[2]  -1.33    0.02 0.69  -2.72  -1.75  -1.30  -0.89 -0.07  1690    1 #> d[3]   0.02    0.01 0.45  -0.89  -0.25   0.03   0.28  0.88  2148    1 #> d[5]  -0.30    0.01 0.44  -1.21  -0.50  -0.29  -0.09  0.56  1346    1 #> lp__ -12.81    0.10 3.59 -20.80 -15.10 -12.52 -10.20 -6.61  1234    1 #> tau    0.38    0.01 0.37   0.01   0.13   0.27   0.51  1.41   877    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:38:23 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(arm_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(arm_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(arm_dic_FE <- dic(arm_fit_FE)) #> Residual deviance: 13.4 (on 15 data points) #>                pD: 11.1 #>               DIC: 24.6 (arm_dic_RE <- dic(arm_fit_RE)) #> Residual deviance: 13.6 (on 15 data points) #>                pD: 12.4 #>               DIC: 26.1 plot(arm_dic_FE) plot(arm_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean \\(-0.73\\) precision \\(21\\). use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify trt_ref = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted, predictions mean -time reduction produced every study network based estimated baseline response \\(\\mu_j\\):  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(arm_releff_FE <- relative_effects(arm_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.54 0.48 -1.50 -0.86 -0.54 -0.21  0.40     1416     1936    1 #> d[2] -1.82 0.33 -2.48 -2.04 -1.82 -1.60 -1.15     5879     2894    1 #> d[3] -0.49 0.49 -1.44 -0.81 -0.49 -0.17  0.47     2074     2425    1 #> d[5] -0.84 0.53 -1.85 -1.20 -0.85 -0.49  0.18     1574     2462    1 plot(arm_releff_FE, ref_line = 0) (arm_releff_RE <- relative_effects(arm_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.51 0.63 -1.70 -0.91 -0.52 -0.11  0.67     1804     1484    1 #> d[2] -1.84 0.51 -2.86 -2.12 -1.83 -1.54 -0.86     3748     2408    1 #> d[3] -0.49 0.66 -1.80 -0.90 -0.48 -0.08  0.74     2657     1956    1 #> d[5] -0.81 0.78 -2.36 -1.25 -0.82 -0.36  0.66     1737     1588    1 plot(arm_releff_RE, ref_line = 0) arm_pred_FE <- predict(arm_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) arm_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.27 0.53 -2.33 -1.62 -1.27 -0.91 -0.21     1636     2297    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.58 -0.29     3910     3936    1 #> pred[2] -2.55 0.40 -3.32 -2.82 -2.54 -2.28 -1.79     5087     3341    1 #> pred[3] -1.22 0.54 -2.27 -1.57 -1.22 -0.85 -0.18     2382     2516    1 #> pred[5] -1.57 0.57 -2.67 -1.95 -1.57 -1.18 -0.44     1741     2657    1 plot(arm_pred_FE) arm_pred_RE <- predict(arm_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) arm_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.24 0.67 -2.51 -1.66 -1.25 -0.81  0.04     1938     1999    1 #> pred[1] -0.73 0.22 -1.16 -0.87 -0.73 -0.58 -0.30     3976     3867    1 #> pred[2] -2.56 0.56 -3.69 -2.90 -2.56 -2.23 -1.50     3593     2853    1 #> pred[3] -1.22 0.70 -2.63 -1.66 -1.22 -0.78  0.09     2838     2008    1 #> pred[5] -1.54 0.82 -3.11 -2.03 -1.55 -1.05 -0.02     1807     1581    1 plot(arm_pred_RE) arm_pred_FE_studies <- predict(arm_fit_FE, type = \"response\") arm_pred_FE_studies #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[1: 4] -1.65 0.46 -2.57 -1.97 -1.65 -1.34 -0.76     1967     2359    1 #> pred[1: 1] -1.12 0.43 -1.96 -1.41 -1.12 -0.82 -0.29     3358     3179    1 #> pred[1: 2] -2.93 0.52 -3.98 -3.28 -2.93 -2.58 -1.94     3558     3007    1 #> pred[1: 3] -1.60 0.39 -2.36 -1.87 -1.60 -1.35 -0.85     3563     3476    1 #> pred[1: 5] -1.95 0.50 -2.95 -2.30 -1.95 -1.61 -0.97     2112     2518    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[2: 4] -1.18 0.52 -2.19 -1.51 -1.18 -0.83 -0.19     1403     2042    1 #> pred[2: 1] -0.64 0.26 -1.16 -0.82 -0.64 -0.46 -0.11     5099     3542    1 #> pred[2: 2] -2.45 0.24 -2.93 -2.62 -2.45 -2.29 -1.99     4938     3308    1 #> pred[2: 3] -1.13 0.53 -2.19 -1.48 -1.13 -0.76 -0.10     2020     2243    1 #> pred[2: 5] -1.48 0.56 -2.56 -1.85 -1.48 -1.10 -0.38     1549     2294    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[3: 4] -1.12 0.43 -1.96 -1.40 -1.13 -0.84 -0.30     1896     2287    1 #> pred[3: 1] -0.59 0.36 -1.30 -0.83 -0.58 -0.34  0.10     4295     2625    1 #> pred[3: 2] -2.40 0.39 -3.18 -2.66 -2.41 -2.14 -1.66     4336     2898    1 #> pred[3: 3] -1.07 0.48 -2.00 -1.39 -1.08 -0.75 -0.14     2678     2607    1 #> pred[3: 5] -1.42 0.48 -2.36 -1.74 -1.42 -1.12 -0.49     2069     2750    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4: 4] -0.40 0.30 -0.97 -0.61 -0.40 -0.20  0.18     2383     2650    1 #> pred[4: 1]  0.14 0.51 -0.84 -0.20  0.13  0.48  1.12     1909     2492    1 #> pred[4: 2] -1.68 0.56 -2.78 -2.05 -1.68 -1.31 -0.59     2009     2493    1 #> pred[4: 3] -0.35 0.24 -0.83 -0.51 -0.35 -0.18  0.11     5241     3305    1 #> pred[4: 5] -0.70 0.37 -1.43 -0.94 -0.71 -0.45  0.01     2615     2737    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[5: 4] -0.57 0.35 -1.25 -0.80 -0.56 -0.33  0.12     2455     2826    1 #> pred[5: 1] -0.03 0.53 -1.05 -0.38 -0.04  0.33  1.04     2141     2659    1 #> pred[5: 2] -1.84 0.58 -2.95 -2.24 -1.85 -1.45 -0.70     2219     2457    1 #> pred[5: 3] -0.52 0.30 -1.11 -0.71 -0.52 -0.32  0.09     5196     3264    1 #> pred[5: 5] -0.87 0.41 -1.68 -1.14 -0.86 -0.59 -0.09     2708     3075    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[6: 4] -2.20 0.18 -2.54 -2.32 -2.20 -2.08 -1.85     2978     3062    1 #> pred[6: 1] -1.66 0.52 -2.66 -2.01 -1.66 -1.31 -0.66     1536     2365    1 #> pred[6: 2] -3.48 0.56 -4.55 -3.86 -3.47 -3.09 -2.43     1652     2716    1 #> pred[6: 3] -2.15 0.37 -2.89 -2.40 -2.15 -1.90 -1.43     2192     2486    1 #> pred[6: 5] -2.50 0.17 -2.84 -2.62 -2.50 -2.38 -2.17     5107     2797    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[7: 4] -1.80 0.18 -2.15 -1.92 -1.80 -1.68 -1.46     3338     2985    1 #> pred[7: 1] -1.26 0.51 -2.25 -1.60 -1.26 -0.92 -0.25     1542     2379    1 #> pred[7: 2] -3.08 0.55 -4.14 -3.46 -3.07 -2.69 -2.03     1657     2473    1 #> pred[7: 3] -1.75 0.37 -2.47 -2.00 -1.75 -1.49 -1.02     2156     2604    1 #> pred[7: 5] -2.10 0.20 -2.49 -2.23 -2.10 -1.96 -1.71     4689     3469    1 plot(arm_pred_FE_studies) (arm_ranks <- posterior_ranks(arm_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.49 0.70    2   3   3   4     5     2073       NA    1 #> rank[1] 4.65 0.76    2   5   5   5     5     2172       NA    1 #> rank[2] 1.05 0.28    1   1   1   1     2     2948     3006    1 #> rank[3] 3.53 0.92    2   3   4   4     5     2867       NA    1 #> rank[5] 2.27 0.66    1   2   2   2     4     2558     2626    1 plot(arm_ranks) (arm_rankprobs <- posterior_rank_probs(arm_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.51      0.37      0.08 #> d[1]      0.00      0.04      0.06      0.12      0.79 #> d[2]      0.96      0.04      0.01      0.00      0.00 #> d[3]      0.00      0.16      0.25      0.46      0.12 #> d[5]      0.04      0.72      0.18      0.05      0.01 plot(arm_rankprobs) (arm_cumrankprobs <- posterior_rank_probs(arm_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.55      0.92         1 #> d[1]      0.00      0.04      0.10      0.21         1 #> d[2]      0.96      0.99      1.00      1.00         1 #> d[3]      0.00      0.17      0.42      0.88         1 #> d[5]      0.04      0.76      0.94      0.99         1 plot(arm_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-contrast-based-data","dir":"Articles","previous_headings":"","what":"Analysis of contrast-based data","title":"Example: Parkinson's disease","text":"now perform analysis using contrast-based data (mean differences standard errors).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"contrast-level data giving mean difference -time reduction (diff) standard error (se_diff), use function set_agd_contrast() set network. sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"contr_net <- set_agd_contrast(parkinsons,                                study = studyn,                               trt = trtn,                               y = diff,                                se = se_diff,                               sample_size = n) contr_net #> A network with 7 AgD studies (contrast-based). #>  #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(contr_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. contr_fit_FE <- nma(contr_net,                      trt_effects = \"fixed\",                     prior_trt = normal(scale = 100)) #> Note: Setting \"4\" as the network reference treatment. contr_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>       mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat #> d[1]  0.54    0.01 0.48 -0.40  0.21  0.54  0.85  1.48  2216    1 #> d[2] -1.27    0.01 0.52 -2.30 -1.61 -1.27 -0.93 -0.25  2325    1 #> d[3]  0.07    0.01 0.33 -0.58 -0.16  0.06  0.29  0.74  3070    1 #> d[5] -0.30    0.00 0.21 -0.71 -0.44 -0.30 -0.16  0.12  3359    1 #> lp__ -3.16    0.03 1.46 -6.87 -3.86 -2.82 -2.09 -1.38  1762    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:38:41 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). plot_prior_posterior(contr_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. contr_fit_RE <- nma(contr_net,                      seed = 1150676438,                     trt_effects = \"random\",                     prior_trt = normal(scale = 100),                     prior_het = half_normal(scale = 5),                     adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. #> Warning: There were 1 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems pairs(contr_fit_RE, pars = c(\"d[3]\", \"delta[4: 4 vs. 3]\", \"tau\")) contr_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>       mean se_mean   sd   2.5%    25%   50%   75% 97.5% n_eff Rhat #> d[1]  0.51    0.01 0.61  -0.69   0.13  0.50  0.89  1.71  2022    1 #> d[2] -1.33    0.01 0.68  -2.74  -1.74 -1.34 -0.90 -0.04  2369    1 #> d[3]  0.04    0.01 0.45  -0.86  -0.24  0.04  0.31  0.90  2730    1 #> d[5] -0.31    0.01 0.39  -1.09  -0.51 -0.31 -0.10  0.51  1861    1 #> lp__ -8.38    0.08 2.83 -14.87 -10.07 -8.13 -6.32 -3.71  1338    1 #> tau   0.37    0.01 0.38   0.01   0.12  0.27  0.50  1.29   982    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:38:46 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(contr_fit_RE, pars = c(\"d\", \"delta\")) plot_prior_posterior(contr_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(contr_dic_FE <- dic(contr_fit_FE)) #> Residual deviance: 6.3 (on 8 data points) #>                pD: 4 #>               DIC: 10.4 (contr_dic_RE <- dic(contr_fit_RE)) #> Residual deviance: 6.7 (on 8 data points) #>                pD: 5.5 #>               DIC: 12.1 plot(contr_dic_FE) plot(contr_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean \\(-0.73\\) precision \\(21\\). use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify trt_ref = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted error raised, study baselines estimated network. can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(contr_releff_FE <- relative_effects(contr_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.54 0.48 -1.48 -0.85 -0.54 -0.21  0.40     2233     2368    1 #> d[2] -1.80 0.33 -2.45 -2.03 -1.80 -1.59 -1.16     5522     3140    1 #> d[3] -0.47 0.47 -1.42 -0.78 -0.47 -0.16  0.45     3080     3086    1 #> d[5] -0.84 0.52 -1.88 -1.18 -0.84 -0.49  0.17     2381     2347    1 plot(contr_releff_FE, ref_line = 0) (contr_releff_RE <- relative_effects(contr_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.51 0.61 -1.71 -0.89 -0.50 -0.13  0.69     2200     1943    1 #> d[2] -1.84 0.49 -2.81 -2.12 -1.83 -1.55 -0.90     3668     2552    1 #> d[3] -0.47 0.64 -1.73 -0.86 -0.48 -0.08  0.80     3062     2332    1 #> d[5] -0.82 0.74 -2.25 -1.27 -0.82 -0.38  0.63     1967     1595    1 plot(contr_releff_RE, ref_line = 0) contr_pred_FE <- predict(contr_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) contr_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.27 0.52 -2.31 -1.61 -1.27 -0.92 -0.24     2393     2512    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.58 -0.30     3988     3629    1 #> pred[2] -2.53 0.39 -3.33 -2.80 -2.53 -2.27 -1.77     4851     3791    1 #> pred[3] -1.20 0.52 -2.23 -1.56 -1.20 -0.84 -0.18     3333     3328    1 #> pred[5] -1.57 0.56 -2.69 -1.94 -1.57 -1.19 -0.51     2506     2533    1 plot(contr_pred_FE) contr_pred_RE <- predict(contr_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) contr_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.24 0.65 -2.49 -1.65 -1.23 -0.85  0.06     2175     1866    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.59 -0.31     3715     3592    1 #> pred[2] -2.57 0.54 -3.67 -2.89 -2.57 -2.24 -1.52     3848     2953    1 #> pred[3] -1.21 0.68 -2.48 -1.63 -1.21 -0.79  0.10     2974     2324    1 #> pred[5] -1.55 0.77 -3.00 -2.03 -1.55 -1.08 -0.05     1929     1677    1 plot(contr_pred_RE) # Not run predict(contr_fit_FE, type = \"response\") (contr_ranks <- posterior_ranks(contr_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.47 0.72    2   3   3   4     5     2606       NA    1 #> rank[1] 4.65 0.75    2   5   5   5     5     2701       NA    1 #> rank[2] 1.06 0.30    1   1   1   1     2     2204     2244    1 #> rank[3] 3.55 0.91    2   3   4   4     5     3781       NA    1 #> rank[5] 2.27 0.66    1   2   2   2     4     2718     2809    1 plot(contr_ranks) (contr_rankprobs <- posterior_rank_probs(contr_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.05      0.51      0.36      0.08 #> d[1]      0.00      0.04      0.06      0.12      0.79 #> d[2]      0.96      0.03      0.01      0.00      0.00 #> d[3]      0.00      0.16      0.25      0.47      0.12 #> d[5]      0.04      0.72      0.17      0.06      0.01 plot(contr_rankprobs) (contr_cumrankprobs <- posterior_rank_probs(contr_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.05      0.56      0.92         1 #> d[1]      0.00      0.04      0.10      0.21         1 #> d[2]      0.96      0.99      1.00      1.00         1 #> d[3]      0.00      0.16      0.41      0.88         1 #> d[5]      0.04      0.76      0.94      0.99         1 plot(contr_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-mixed-arm-based-and-contrast-based-data","dir":"Articles","previous_headings":"","what":"Analysis of mixed arm-based and contrast-based data","title":"Example: Parkinson's disease","text":"now perform analysis studies contribute arm-based data, contribute contrast-based data. Replicating Dias et al. (2011), consider arm-based data studies 1-3, contrast-based data studies 4-7.","code":"studies <- parkinsons$studyn (parkinsons_arm <- parkinsons[studies %in% 1:3, ]) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718 #> 7      3    4 -1.20 0.478  81 -0.90   0.695 (parkinsons_contr <- parkinsons[studies %in% 4:7, ]) #>    studyn trtn     y    se   n  diff se_diff #> 8       4    3 -0.24 0.265 128    NA   0.265 #> 9       4    4 -0.59 0.354  72 -0.35   0.442 #> 10      5    3 -0.73 0.335  80    NA   0.335 #> 11      5    4 -0.18 0.442  46  0.55   0.555 #> 12      6    4 -2.20 0.197 137    NA   0.197 #> 13      6    5 -2.50 0.190 131 -0.30   0.274 #> 14      7    4 -1.80 0.200 154    NA   0.200 #> 15      7    5 -2.10 0.250 143 -0.30   0.320"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"use functions set_agd_arm() set_agd_contrast() set respective data sources within network, combine together combine_network(). sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"mix_arm_net <- set_agd_arm(parkinsons_arm,                             study = studyn,                            trt = trtn,                            y = y,                             se = se,                            sample_size = n)  mix_contr_net <- set_agd_contrast(parkinsons_contr,                                    study = studyn,                                   trt = trtn,                                   y = diff,                                    se = se_diff,                                   sample_size = n)  mix_net <- combine_network(mix_arm_net, mix_contr_net) mix_net #> A network with 3 AgD studies (arm-based), and 4 AgD studies (contrast-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  #>  Outcome type: continuous #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(mix_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. mix_fit_FE <- nma(mix_net,                    trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100)) #> Note: Setting \"4\" as the network reference treatment. mix_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>       mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat #> d[1]  0.52    0.01 0.47 -0.40  0.20  0.52  0.84  1.43  1517    1 #> d[2] -1.29    0.01 0.51 -2.32 -1.62 -1.29 -0.96 -0.29  1641    1 #> d[3]  0.05    0.01 0.32 -0.58 -0.16  0.04  0.26  0.67  2753    1 #> d[5] -0.30    0.00 0.20 -0.71 -0.44 -0.30 -0.16  0.10  2836    1 #> lp__ -4.61    0.04 1.87 -9.22 -5.57 -4.28 -3.26 -2.00  1833    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:38:57 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(mix_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(mix_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), additionally use \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. mix_fit_RE <- nma(mix_net,                    seed = 437219664,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = half_normal(scale = 5),                   adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. #> Warning: There were 2 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: There were 3 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See #> https://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded #> Warning: Examine the pairs() plot to diagnose sampling problems pairs(mix_fit_RE, pars = c(\"d[3]\", \"delta[4: 4 vs. 3]\", \"tau\")) mix_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%   75% 97.5% n_eff Rhat #> d[1]   0.51    0.02 0.66  -0.86   0.15   0.52  0.89  1.74  1629 1.00 #> d[2]  -1.34    0.02 0.75  -2.90  -1.75  -1.32 -0.91  0.04  1537 1.00 #> d[3]   0.02    0.01 0.54  -1.05  -0.26   0.02  0.32  0.99  2249 1.00 #> d[5]  -0.30    0.01 0.43  -1.21  -0.51  -0.30 -0.09  0.61  2295 1.00 #> lp__ -10.72    0.08 3.23 -17.78 -12.71 -10.44 -8.45 -5.15  1444 1.00 #> tau    0.42    0.02 0.46   0.01   0.13   0.28  0.54  1.67   533 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:39:06 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(mix_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(mix_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(mix_dic_FE <- dic(mix_fit_FE)) #> Residual deviance: 9.2 (on 11 data points) #>                pD: 6.9 #>               DIC: 16.2 (mix_dic_RE <- dic(mix_fit_RE)) #> Residual deviance: 9.6 (on 11 data points) #>                pD: 8.5 #>               DIC: 18.1 plot(mix_dic_FE) plot(mix_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean \\(-0.73\\) precision \\(21\\). use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify trt_ref = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted, predictions mean -time reduction produced every arm-based study network based estimated baseline response \\(\\mu_j\\):  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(mix_releff_FE <- relative_effects(mix_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.52 0.47 -1.43 -0.84 -0.52 -0.20  0.40     1542     2165    1 #> d[2] -1.81 0.33 -2.47 -2.03 -1.81 -1.59 -1.17     6740     3205    1 #> d[3] -0.47 0.49 -1.41 -0.81 -0.48 -0.14  0.48     2302     2692    1 #> d[5] -0.82 0.52 -1.81 -1.17 -0.82 -0.48  0.19     1755     2427    1 plot(mix_releff_FE, ref_line = 0) (mix_releff_RE <- relative_effects(mix_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.51 0.66 -1.74 -0.89 -0.52 -0.15  0.86     1814     1594    1 #> d[2] -1.85 0.58 -2.96 -2.13 -1.85 -1.56 -0.84     4001     2109    1 #> d[3] -0.50 0.69 -1.82 -0.89 -0.50 -0.12  0.89     2965     2206    1 #> d[5] -0.81 0.79 -2.32 -1.27 -0.82 -0.38  0.82     1866     1679    1 plot(mix_releff_RE, ref_line = 0) mix_pred_FE <- predict(mix_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) mix_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.24 0.52 -2.24 -1.61 -1.25 -0.89 -0.22     1674     2447    1 #> pred[1] -0.72 0.22 -1.14 -0.87 -0.72 -0.58 -0.29     3556     3638    1 #> pred[2] -2.53 0.39 -3.31 -2.80 -2.53 -2.27 -1.73     4609     3417    1 #> pred[3] -1.19 0.53 -2.21 -1.57 -1.20 -0.83 -0.15     2345     2871    1 #> pred[5] -1.54 0.56 -2.65 -1.92 -1.57 -1.15 -0.46     1866     2434    1 plot(mix_pred_FE) mix_pred_RE <- predict(mix_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        trt_ref = 1) mix_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.24 0.69 -2.54 -1.66 -1.25 -0.85  0.17     1920     1707    1 #> pred[1] -0.73 0.22 -1.17 -0.88 -0.73 -0.58 -0.31     4051     3817    1 #> pred[2] -2.58 0.62 -3.75 -2.91 -2.57 -2.24 -1.52     3816     2164    1 #> pred[3] -1.22 0.73 -2.60 -1.65 -1.22 -0.82  0.18     3082     2578    1 #> pred[5] -1.54 0.82 -3.08 -2.03 -1.56 -1.07  0.09     1963     1709    1 plot(mix_pred_RE) mix_pred_FE_studies <- predict(mix_fit_FE, type = \"response\") mix_pred_FE_studies #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[1: 4] -1.64 0.45 -2.53 -1.95 -1.64 -1.34 -0.75     2293     2590    1 #> pred[1: 1] -1.12 0.43 -1.98 -1.41 -1.12 -0.84 -0.27     3653     3131    1 #> pred[1: 2] -2.93 0.52 -3.94 -3.29 -2.93 -2.58 -1.91     3566     2944    1 #> pred[1: 3] -1.60 0.40 -2.38 -1.87 -1.59 -1.34 -0.81     3534     2565    1 #> pred[1: 5] -1.94 0.49 -2.91 -2.27 -1.95 -1.61 -0.96     2424     2445    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[2: 4] -1.16 0.50 -2.13 -1.50 -1.17 -0.83 -0.15     1495     2084    1 #> pred[2: 1] -0.64 0.26 -1.14 -0.82 -0.64 -0.47 -0.11     5710     3476    1 #> pred[2: 2] -2.45 0.24 -2.91 -2.61 -2.45 -2.29 -1.97     5095     3528    1 #> pred[2: 3] -1.11 0.53 -2.13 -1.47 -1.12 -0.76 -0.08     2107     2349    1 #> pred[2: 5] -1.46 0.54 -2.53 -1.83 -1.46 -1.09 -0.39     1693     2292    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[3: 4] -1.11 0.41 -1.89 -1.38 -1.12 -0.85 -0.27     1920     2608    1 #> pred[3: 1] -0.59 0.37 -1.32 -0.84 -0.58 -0.34  0.11     4354     3105    1 #> pred[3: 2] -2.40 0.38 -3.16 -2.65 -2.41 -2.15 -1.63     4350     3240    1 #> pred[3: 3] -1.07 0.47 -1.98 -1.38 -1.07 -0.75 -0.15     2796     2796    1 #> pred[3: 5] -1.41 0.46 -2.29 -1.72 -1.42 -1.11 -0.50     2130     2646    1 plot(mix_pred_FE_studies) (mix_ranks <- posterior_ranks(mix_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.50 0.71    2   3   3   4     5     2062       NA    1 #> rank[1] 4.63 0.78    2   5   5   5     5     1963       NA    1 #> rank[2] 1.05 0.26    1   1   1   1     2     2608     2767    1 #> rank[3] 3.54 0.92    2   3   4   4     5     3151       NA    1 #> rank[5] 2.28 0.66    1   2   2   2     4     2615     2603    1 plot(mix_ranks) (mix_rankprobs <- posterior_rank_probs(mix_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.49      0.38      0.08 #> d[1]      0.00      0.04      0.06      0.12      0.78 #> d[2]      0.96      0.03      0.01      0.00      0.00 #> d[3]      0.00      0.16      0.25      0.45      0.13 #> d[5]      0.04      0.72      0.19      0.05      0.01 plot(mix_rankprobs) (mix_cumrankprobs <- posterior_rank_probs(mix_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.54      0.92         1 #> d[1]      0.00      0.04      0.10      0.22         1 #> d[2]      0.96      0.99      1.00      1.00         1 #> d[3]      0.00      0.17      0.42      0.87         1 #> d[5]      0.04      0.75      0.94      0.99         1 plot(mix_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"initial_analysis","dir":"Articles","previous_headings":"","what":"Initial analysis","title":"Example: Plaque psoriasis ML-NMR","text":"start recreating analysis presented Phillippo et al. (2020). analyse IPD three studies, UNCOVER-1, UNCOVER-2, UNCOVER-3 (Griffiths et al. 2015; Gordon et al. 2016), AgD one study, FIXTURE (Langley et al. 2014). consider running ML-NMR adjusting five potential effect-modifying covariates: duration psoriasis durnpso, weight weight, previous systemic treatment prevsys, body surface area bsa, psoriatic arthritis psa.","code":"pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0  male bsa #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2  TRUE  18 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4  TRUE  33 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8  TRUE  33 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 FALSE  50 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 FALSE  35 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2  TRUE  29 #>   weight durnpso prevsys   psa #> 1   98.1     6.7    TRUE  TRUE #> 2  129.6    14.5   FALSE  TRUE #> 3   78.0    26.5    TRUE FALSE #> 4  139.9    25.0    TRUE  TRUE #> 5   54.2    11.9    TRUE FALSE #> 6   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n pasi100_r #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323        14 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324         0 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327        47 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323        78 #>   pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd pasi_w0_mean pasi_w0_sd male #> 1       323            326     43.8   13.0     28.7    5.9         23.2        9.8 71.2 #> 2       324            326     44.1   12.6     27.9    6.1         24.1       10.5 72.7 #> 3       327            327     45.4   12.9     28.4    5.9         23.7       10.5 72.2 #> 4       323            327     44.5   13.2     28.4    6.4         23.9        9.9 68.5 #>   bsa_mean bsa_sd weight_mean weight_sd durnpso_mean durnpso_sd prevsys  psa #> 1     33.6   18.0        84.6      20.5         16.4       12.0    65.6 13.5 #> 2     35.2   19.1        82.0      20.4         16.6       11.6    62.6 15.0 #> 3     34.5   19.4        83.6      20.8         17.3       12.2    64.8 15.0 #> 4     34.3   19.2        83.0      21.6         15.8       12.3    63.0 15.3"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"preparing-the-data","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Preparing the data","title":"Example: Plaque psoriasis ML-NMR","text":"need prepare data acceptable format run ML-NMR model. Firstly, need handle binary covariates prevsys psa. IPD, coded TRUE FALSE, AgD coded percentages (100). need transform sets variables numeric lie interval \\([0,1]\\), variables compatible across data sources. Whilst , also transform body surface area bsa (percentage) lie \\([0,1]\\), since make specifying appropriate marginal distribution easier later, rescale weight duration aid interpretation regression coefficients (terms 10 kilos 10 years respectively). also add trtclass variable, indicating treatments belong classes. Finally, check missing values IPD. small number individuals missing covariates: Since proportion missing data small, simply exclude individuals analysis.","code":"pso_ipd <- pso_ipd %>%    mutate(# Variable transformations          bsa = bsa / 100,          prevsys = as.numeric(prevsys),          psa = as.numeric(psa),          weight = weight / 10,          durnpso = durnpso / 10,          # Treatment classes          trtclass = case_when(trtn == 1 ~ \"Placebo\",                               trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                               trtn == 4 ~ \"TNFa blocker\"),          # Check complete cases for covariates of interest          complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%    mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                               trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                               trtn == 4 ~ \"TNFa blocker\")   ) sum(!pso_ipd$complete) #> [1] 4 mean(!pso_ipd$complete) #> [1] 0.001036807 pso_ipd <- filter(pso_ipd, complete)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"creating-the-network","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Creating the network","title":"Example: Plaque psoriasis ML-NMR","text":"Set network, setting IPD set_ipd(), AgD (arm-based) set_agd_arm(), combining together using combine_network(). specify binary pasi75 outcome r IPD, count outcome pasi75_r denominator pasi75_n r n AgD. specify treatment classes trt_class = trtclass. can produce network plot plot() method:","code":"pso_net <- combine_network(   set_ipd(pso_ipd,            study = studyc,            trt = trtc,            r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,                study = studyc,                trt = trtc,                r = pasi75_r,                n = pasi75_n,               trt_class = trtclass) )  pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE) +    ggplot2::theme(legend.position = \"bottom\", legend.box = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"numerical-integration-for-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Numerical integration for ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"ML-NMR models define meta-regression model individual level, exactly manner full-IPD meta-regression. ML-NMR incorporates AgD model integrating individual-level model covariate distribution AgD study (Phillippo et al. 2020; Phillippo 2019). Using integration, instead simply “plugging-” mean covariate values AgD studies, avoids aggregation bias link function identity function. package utilises numerical integration incorporate aggregate data - specifically, quasi-Monte Carlo (QMC) integration Gaussian copula (Phillippo et al. 2020; Phillippo 2019). QMC integration general flexible integration approach, typically requires far fewer integration points standard (pseudo-random) Monte-Carlo integration achieve numerical accuracy.1 Gaussian copula allows us account correlations covariates, may specified marginal distributions. now set numerical integration network. five covariates consider adjusting body surface area bsa, duration psoriasis durnpso, previous systemic treatment prevsys, psoriatic arthritis psa, weight weight. need choose suitable marginal distributions covariates draw integration points . prevsys psa binary covariates, given Bernoulli distribution. bsa percentage, choose logit-Normal distribution (note, requires logitnorm package installed). choose Gamma distributions durnpso weight account skewness. choices seem match well marginal distributions observed IPD:  add integration points AgD studies network using add_integration() function. Marginal distributions covariate specified using distr() function, takes cumulative distribution function corresponding chosen marginal distribution, arguments distribution column names aggregate data. Since know correlations covariates AgD studies, impute weighted mean correlations IPD studies (default option). Note: package provides several convenience functions specifying distributions, including qgamma() allows parameterisation Gamma distribution terms mean standard deviation, qbern() provides Bernoulli distribution, qlogitnorm() provides logit-Normal distribution allowing parameterisation terms mean standard deviation (requires logitnorm package installed).","code":"# Get mean and sd of covariates in each study ipd_summary <- pso_ipd %>%    group_by(studyc) %>%    summarise_at(vars(weight, durnpso, bsa), list(mean = mean, sd = sd, min = min, max = max)) %>%    pivot_longer(weight_mean:bsa_max, names_sep = \"_\", names_to = c(\"covariate\", \".value\")) %>%    # Assign distributions   mutate(dist = recode(covariate,                        bsa = \"dlogitnorm\",                        durnpso = \"dgamma\",                        weight = \"dgamma\")) %>%    # Compute density curves   group_by(studyc, covariate) %>%    mutate(value = if_else(dist == \"dlogitnorm\",                          list(seq(0, 1, length.out = 101)),                          list(seq(min*0.8, max*1.2, length.out = 101)))) %>%    unnest(cols = value) %>%    mutate(dens = eval(call(first(dist), x = value, mean = first(mean), sd = first(sd))))  # Plot histograms and assumed densities pso_ipd %>%    pivot_longer(c(weight, durnpso, bsa), names_to = \"covariate\", values_to = \"value\") %>%  ggplot(aes(x = value)) +   geom_histogram(aes(y = after_stat(density)),                   binwidth = function(x) diff(range(x)) / nclass.Sturges(x),                  boundary = 0,                  fill = \"grey50\") +   geom_line(aes(y = dens), data = ipd_summary,             colour = \"darkred\", linewidth = 0.5) +   facet_wrap(~studyc + covariate, scales = \"free\", ncol = 3) +   theme_multinma() pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64 ) #> Using weighted average correlation matrix computed from IPD studies."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"ml-nmr-models","dir":"Articles","previous_headings":"Initial analysis","what":"ML-NMR models","title":"Example: Plaque psoriasis ML-NMR","text":"fit fixed effect (FE) random effects (RE) ML-NMR models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"fixed-effect-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > ML-NMR models","what":"Fixed effect ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"First, fit FE ML-NMR model using function nma(). Following (Phillippo et al. 2020) specify weakly-informative \\(N(0, 10^2)\\) priors parameter. range parameter values implied prior distributions can checked using summary() method: regression model specified regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt, include main (prognostic) effects covariate well interactions treatment. use probit link function (link = \"probit\"), specify two-parameter Binomial approximation aggregate-level likelihood used (likelihood = \"bernoulli2\", “bernoulli” refers individual-level likelihood, “2” denotes two-parameter adjustment aggregate-level likelihood) (Phillippo et al. 2020). utilise shared effect modifier assumption help identify model, setting treatment-covariate interactions equal within class (class_interactions = \"common\"). narrow possible range random initial values init_r = 0.1 (default init_r = 2), since probit models particular often hard initialise. Using QR decomposition (QR = TRUE) greatly improves sampling efficiency , often case regression models. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  now recommend assessing sufficient accuracy numerical integration running half chains n_int / 2 integration points half full n_int. Rhat n_eff diagnostic warnings can either attributed insufficient MCMC iterations (argument iter nma()) insufficient integration points (n_int add_integration()), depending whether occur within two groups chains chains combined. feature enabled default (int_check = TRUE). case, warnings content number iterations number integration points. (Phillippo et al. (2020) used alternative approach based saving cumulative integration points plotting empirical integration error, can achieved setting int_thin nma() using plot_integration_error() function.)","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                    likelihood = \"bernoulli2\",                   regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   init_r = 0.1,                   QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. print(pso_fit_FE) #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                           0.04    0.00 0.06    -0.08     0.00     0.05     0.09 #> beta[prevsys]                          -0.14    0.00 0.15    -0.44    -0.24    -0.14    -0.03 #> beta[bsa]                              -0.06    0.01 0.43    -0.93    -0.35    -0.06     0.24 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02     0.04     0.06 #> beta[psa]                              -0.08    0.00 0.17    -0.42    -0.19    -0.08     0.04 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08    -0.03     0.02 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.14    -0.06    -0.01     0.03 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.18    -0.17     0.07     0.19     0.31 #> beta[prevsys:.trtclassIL blocker]       0.07    0.00 0.17    -0.27    -0.05     0.07     0.18 #> beta[bsa:.trtclassTNFa blocker]         0.05    0.01 0.51    -0.93    -0.31     0.04     0.40 #> beta[bsa:.trtclassIL blocker]           0.28    0.01 0.48    -0.66    -0.04     0.28     0.60 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.19    -0.17    -0.15 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12    -0.10    -0.08 #> beta[psa:.trtclassTNFa blocker]        -0.06    0.00 0.21    -0.49    -0.20    -0.06     0.09 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.19    -0.36    -0.12     0.01     0.13 #> d[ETN]                                  1.55    0.00 0.08     1.39     1.50     1.55     1.60 #> d[IXE_Q2W]                              2.95    0.00 0.09     2.79     2.90     2.95     3.01 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.38     2.49     2.54     2.59 #> d[SEC_150]                              2.14    0.00 0.12     1.92     2.06     2.14     2.22 #> d[SEC_300]                              2.45    0.00 0.12     2.22     2.37     2.45     2.53 #> lp__                                -1576.45    0.09 3.59 -1584.66 -1578.53 -1576.11 -1573.87 #>                                        97.5% n_eff Rhat #> beta[durnpso]                           0.17  6733    1 #> beta[prevsys]                           0.17  5563    1 #> beta[bsa]                               0.79  6380    1 #> beta[weight]                            0.10  6061    1 #> beta[psa]                               0.26  6489    1 #> beta[durnpso:.trtclassTNFa blocker]     0.12  6565    1 #> beta[durnpso:.trtclassIL blocker]       0.12  8225    1 #> beta[prevsys:.trtclassTNFa blocker]     0.54  6270    1 #> beta[prevsys:.trtclassIL blocker]       0.39  6703    1 #> beta[bsa:.trtclassTNFa blocker]         1.06  5716    1 #> beta[bsa:.trtclassIL blocker]           1.20  8072    1 #> beta[weight:.trtclassTNFa blocker]     -0.10  6818    1 #> beta[weight:.trtclassIL blocker]       -0.04  6912    1 #> beta[psa:.trtclassTNFa blocker]         0.35  6459    1 #> beta[psa:.trtclassIL blocker]           0.38  7563    1 #> d[ETN]                                  1.71  4756    1 #> d[IXE_Q2W]                              3.12  6255    1 #> d[IXE_Q4W]                              2.71  5567    1 #> d[SEC_150]                              2.37  5458    1 #> d[SEC_300]                              2.68  5765    1 #> lp__                                -1570.47  1450    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:39:52 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_FE, pars = c(\"d\", \"beta\", \"mu\")) plot_prior_posterior(pso_fit_FE, prior = c(\"intercept\", \"trt\", \"reg\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"random-effects-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > ML-NMR models","what":"Random effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"now fit RE model. , specify weakly-informative \\(N(0, 10^2)\\) priors parameter, now specify \\(\\textrm{half-N}(0, 2.5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). range parameter values implied prior distributions can checked using summary() method: Fitting model uses call nma() , except now trt_effects = \"random\". Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: number divergent transitions, can investigate using pairs() method:  divergent transition errors (red crosses) seem concentrated upper tail heterogeneity standard deviation parameter. suggests information identify heterogeneity parameter weak - four studies network - informative prior distribution might aid estimation. prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(half_normal(scale = 2.5)) #> A half-Normal prior distribution: location = 0, scale = 2.5. #> 50% of the prior density lies between 0 and 1.69. #> 95% of the prior density lies between 0 and 4.9. pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                    likelihood = \"bernoulli2\",                   regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_het = half_normal(scale = 2.5),                   init_r = 0.1,                   QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. #> Warning: There were 8 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems print(pso_fit_RE) #> A random effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                           0.05    0.00 0.06    -0.07     0.01     0.05     0.09 #> beta[prevsys]                          -0.13    0.00 0.16    -0.45    -0.24    -0.13    -0.02 #> beta[bsa]                              -0.09    0.01 0.45    -0.99    -0.39    -0.09     0.21 #> beta[weight]                            0.04    0.00 0.03    -0.01     0.02     0.04     0.06 #> beta[psa]                              -0.07    0.00 0.17    -0.40    -0.18    -0.07     0.05 #> beta[durnpso:.trtclassTNFa blocker]    -0.04    0.00 0.07    -0.18    -0.08    -0.04     0.01 #> beta[durnpso:.trtclassIL blocker]      -0.02    0.00 0.07    -0.15    -0.06    -0.02     0.03 #> beta[prevsys:.trtclassTNFa blocker]     0.18    0.00 0.19    -0.20     0.05     0.18     0.31 #> beta[prevsys:.trtclassIL blocker]       0.05    0.00 0.18    -0.30    -0.07     0.05     0.18 #> beta[bsa:.trtclassTNFa blocker]         0.08    0.01 0.53    -0.91    -0.28     0.07     0.43 #> beta[bsa:.trtclassIL blocker]           0.33    0.01 0.49    -0.62     0.00     0.32     0.66 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.19    -0.17    -0.15 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12    -0.10    -0.08 #> beta[psa:.trtclassTNFa blocker]        -0.06    0.00 0.20    -0.45    -0.20    -0.07     0.07 #> beta[psa:.trtclassIL blocker]          -0.01    0.00 0.19    -0.36    -0.14    -0.01     0.12 #> d[ETN]                                  1.56    0.00 0.14     1.28     1.47     1.55     1.64 #> d[IXE_Q2W]                              2.97    0.00 0.15     2.68     2.88     2.96     3.05 #> d[IXE_Q4W]                              2.56    0.00 0.15     2.27     2.47     2.56     2.64 #> d[SEC_150]                              2.13    0.01 0.22     1.66     2.00     2.13     2.25 #> d[SEC_300]                              2.43    0.01 0.23     1.95     2.31     2.44     2.56 #> lp__                                -1580.51    0.16 4.79 -1590.77 -1583.49 -1580.23 -1577.14 #> tau                                     0.18    0.00 0.11     0.01     0.10     0.16     0.24 #>                                        97.5% n_eff Rhat #> beta[durnpso]                           0.17  5544 1.00 #> beta[prevsys]                           0.20  5481 1.00 #> beta[bsa]                               0.78  4656 1.00 #> beta[weight]                            0.10  5160 1.00 #> beta[psa]                               0.26  5344 1.00 #> beta[durnpso:.trtclassTNFa blocker]     0.11  6233 1.00 #> beta[durnpso:.trtclassIL blocker]       0.12  6248 1.00 #> beta[prevsys:.trtclassTNFa blocker]     0.56  6261 1.00 #> beta[prevsys:.trtclassIL blocker]       0.40  6652 1.00 #> beta[bsa:.trtclassTNFa blocker]         1.15  4819 1.00 #> beta[bsa:.trtclassIL blocker]           1.30  5645 1.00 #> beta[weight:.trtclassTNFa blocker]     -0.10  5447 1.00 #> beta[weight:.trtclassIL blocker]       -0.04  6180 1.00 #> beta[psa:.trtclassTNFa blocker]         0.35  5675 1.00 #> beta[psa:.trtclassIL blocker]           0.37  6634 1.00 #> d[ETN]                                  1.86  1804 1.00 #> d[IXE_Q2W]                              3.26  2076 1.00 #> d[IXE_Q4W]                              2.87  1645 1.00 #> d[SEC_150]                              2.58  1640 1.00 #> d[SEC_300]                              2.92  2123 1.00 #> lp__                                -1571.98   885 1.01 #> tau                                     0.46   631 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:43:16 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_RE, pars = c(\"d\", \"beta\", \"tau\", \"mu\", \"delta\")) pairs(pso_fit_RE, pars = c(\"delta[UNCOVER-2: ETN]\", \"d[ETN]\", \"tau\", \"lp__\")) plot_prior_posterior(pso_fit_RE, prior = c(\"intercept\", \"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"model-comparison","dir":"Articles","previous_headings":"Initial analysis","what":"Model comparison","title":"Example: Plaque psoriasis ML-NMR","text":"model fit FE RE models can checked using dic() function. DIC similar FE RE models, suggesting little evidence residual heterogeneity.","code":"(pso_dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 3129.7 (on 3858 data points) #>                pD: 24.3 #>               DIC: 3154 (pso_dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 3123.8 (on 3858 data points) #>                pD: 28.1 #>               DIC: 3151.9"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"producing-relative-effects-and-event-probabilities","dir":"Articles","previous_headings":"Initial analysis","what":"Producing relative effects and event probabilities","title":"Example: Plaque psoriasis ML-NMR","text":"Parameter estimates can plotted using plot() method, example examine estimated regression coefficients:  Plots posterior summaries based ggdist package, allows great degree flexibility, can customised using ggplot2 commands. command specify \"halfeye\" plot, shows posterior density along posterior medians (points) 95% Credible Intervals (thin line) 66% inner bands (thicker line) default. details plotting options see ?plot.nma_summary. can produce population-adjusted relative effects study population network using relative_effects() function.  Predicted probabilities achieving PASI 75 study population treatment produced using predict() method. argument type = \"reponse\" specifies want predicted probabilities, rather probit probabilities.  can produce population-adjusted ranks, rank probabilities, cumulative rank probabilities study population using posterior_ranks() posterior_rank_probs() functions (although ranks unchanged populations, distributions effect modifiers similar). specify lower_better = FALSE, since higher outcome better (higher chance achieving PASI 75).    estimates (relative effects, predictions, rankings) can also produced specific target population populations providing suitable newdata argument function (baseline distribution predict()). produce population-adjusted relative effects (corresponding rankings) chosen target population, require mean covariate values population. example, newdata provide following mean covariate values: Population-adjusted relative effects target population calculated using relative_effects() function, can plotted corresponding plot() method:  absolute predictions, require information full covariate distribution target population, just mean values. IPD available target population, newdata simply data frame IPD. AgD available target population, newdata must data frame added integration points created using add_integration() function. example, suppose aggregate target population introduced following covariate means standard deviations (continuous covariates) proportions (discrete covariates): add integration points data frame similar manner . , need supply correlation matrix joint covariate distribution; use weighted mean correlation matrix computed earlier IPD network, stored network object int_cor. Predicted probabilities achieving PASI 75 target population, given \\(N(-1.75, 0.08^2)\\) distribution baseline probit-probability response Placebo (reference levels covariates), produced using predict() method:","code":"plot(pso_fit_FE,      pars = \"beta\",      stat = \"halfeye\",      ref_line = 0) (pso_releff_FE <- relative_effects(pso_fit_FE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[FIXTURE: ETN]     1.66 0.09 1.48 1.60 1.66 1.72  1.84     4771     3258    1 #> d[FIXTURE: IXE_Q2W] 3.03 0.10 2.83 2.96 3.03 3.09  3.22     6557     3642    1 #> d[FIXTURE: IXE_Q4W] 2.62 0.09 2.43 2.55 2.62 2.68  2.81     5695     2983    1 #> d[FIXTURE: SEC_150] 2.22 0.12 1.98 2.14 2.22 2.30  2.45     5163     3224    1 #> d[FIXTURE: SEC_300] 2.52 0.12 2.29 2.44 2.52 2.60  2.76     5563     3401    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-1: ETN]     1.51 0.08 1.34 1.45 1.51 1.56  1.68     4824     3453    1 #> d[UNCOVER-1: IXE_Q2W] 2.92 0.09 2.75 2.87 2.92 2.98  3.09     5808     3261    1 #> d[UNCOVER-1: IXE_Q4W] 2.51 0.08 2.35 2.46 2.51 2.57  2.68     5403     3094    1 #> d[UNCOVER-1: SEC_150] 2.11 0.12 1.88 2.03 2.11 2.20  2.35     5659     3298    1 #> d[UNCOVER-1: SEC_300] 2.42 0.12 2.18 2.33 2.42 2.50  2.66     5925     3435    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-2: ETN]     1.51 0.08 1.35 1.46 1.51 1.56  1.66     4843     3517    1 #> d[UNCOVER-2: IXE_Q2W] 2.92 0.08 2.76 2.87 2.92 2.98  3.09     6087     3349    1 #> d[UNCOVER-2: IXE_Q4W] 2.51 0.08 2.35 2.46 2.51 2.56  2.67     5619     3157    1 #> d[UNCOVER-2: SEC_150] 2.11 0.12 1.88 2.03 2.11 2.20  2.35     5691     3189    1 #> d[UNCOVER-2: SEC_300] 2.42 0.12 2.18 2.33 2.42 2.50  2.65     6009     3520    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-3: ETN]     1.53 0.08 1.37 1.48 1.53 1.58  1.68     4894     3650    1 #> d[UNCOVER-3: IXE_Q2W] 2.94 0.09 2.77 2.88 2.94 3.00  3.11     6385     3425    1 #> d[UNCOVER-3: IXE_Q4W] 2.53 0.08 2.37 2.47 2.53 2.58  2.69     5850     3167    1 #> d[UNCOVER-3: SEC_150] 2.13 0.12 1.90 2.05 2.13 2.21  2.36     5648     3232    1 #> d[UNCOVER-3: SEC_300] 2.44 0.12 2.21 2.35 2.44 2.52  2.66     5986     3315    1 plot(pso_releff_FE, ref_line = 0) (pso_pred_FE <- predict(pso_fit_FE, type = \"response\")) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[FIXTURE: PBO]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     4140     3412    1 #> pred[FIXTURE: ETN]     0.46 0.03 0.41 0.44 0.46 0.47  0.51     7947     3102    1 #> pred[FIXTURE: IXE_Q2W] 0.89 0.02 0.85 0.88 0.89 0.90  0.92     8018     3421    1 #> pred[FIXTURE: IXE_Q4W] 0.80 0.03 0.74 0.78 0.80 0.81  0.84     6392     2975    1 #> pred[FIXTURE: SEC_150] 0.67 0.03 0.62 0.65 0.67 0.69  0.72    10511     2856    1 #> pred[FIXTURE: SEC_300] 0.77 0.02 0.72 0.75 0.77 0.79  0.82    10105     2992    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-1: PBO]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     6211     3313    1 #> pred[UNCOVER-1: ETN]     0.46 0.03 0.41 0.44 0.46 0.48  0.52     8058     2986    1 #> pred[UNCOVER-1: IXE_Q2W] 0.90 0.01 0.88 0.89 0.90 0.91  0.92     8486     2960    1 #> pred[UNCOVER-1: IXE_Q4W] 0.81 0.02 0.78 0.80 0.81 0.82  0.84    10615     3056    1 #> pred[UNCOVER-1: SEC_150] 0.69 0.04 0.60 0.66 0.69 0.72  0.77     7383     3352    1 #> pred[UNCOVER-1: SEC_300] 0.78 0.04 0.71 0.76 0.79 0.81  0.85     8246     3417    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-2: PBO]     0.05 0.01 0.03 0.04 0.05 0.05  0.06     5586     3274    1 #> pred[UNCOVER-2: ETN]     0.42 0.02 0.38 0.40 0.42 0.43  0.46     9392     3108    1 #> pred[UNCOVER-2: IXE_Q2W] 0.88 0.01 0.86 0.87 0.88 0.89  0.90     7488     3484    1 #> pred[UNCOVER-2: IXE_Q4W] 0.78 0.02 0.75 0.77 0.78 0.79  0.81     8891     3021    1 #> pred[UNCOVER-2: SEC_150] 0.65 0.04 0.56 0.62 0.65 0.68  0.73     8459     3387    1 #> pred[UNCOVER-2: SEC_300] 0.75 0.04 0.67 0.73 0.75 0.78  0.82     9884     3147    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-3: PBO]     0.08 0.01 0.06 0.07 0.08 0.08  0.10     5734     3368    1 #> pred[UNCOVER-3: ETN]     0.53 0.02 0.49 0.52 0.53 0.54  0.57    10140     2869    1 #> pred[UNCOVER-3: IXE_Q2W] 0.93 0.01 0.91 0.92 0.93 0.93  0.94     8202     3253    1 #> pred[UNCOVER-3: IXE_Q4W] 0.85 0.01 0.83 0.85 0.85 0.86  0.88     8441     2936    1 #> pred[UNCOVER-3: SEC_150] 0.75 0.04 0.67 0.72 0.75 0.77  0.81     8207     3070    1 #> pred[UNCOVER-3: SEC_300] 0.83 0.03 0.77 0.81 0.83 0.85  0.88     9447     3340    1 plot(pso_pred_FE, ref_line = c(0, 1)) (pso_ranks_FE <- posterior_ranks(pso_fit_FE, lower_better = FALSE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[FIXTURE: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[FIXTURE: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[FIXTURE: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[FIXTURE: IXE_Q4W] 2.23 0.42    2   2   2   2     3     4451     4016    1 #> rank[FIXTURE: SEC_150] 4.00 0.05    4   4   4   4     4     4034       NA    1 #> rank[FIXTURE: SEC_300] 2.78 0.42    2   3   3   3     3     4445     4031    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-1: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-1: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-1: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[UNCOVER-1: IXE_Q4W] 2.23 0.42    2   2   2   2     3     4451     4016    1 #> rank[UNCOVER-1: SEC_150] 4.00 0.05    4   4   4   4     4     4034       NA    1 #> rank[UNCOVER-1: SEC_300] 2.78 0.42    2   3   3   3     3     4445     4031    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-2: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-2: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-2: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[UNCOVER-2: IXE_Q4W] 2.23 0.42    2   2   2   2     3     4451     4016    1 #> rank[UNCOVER-2: SEC_150] 4.00 0.05    4   4   4   4     4     4034       NA    1 #> rank[UNCOVER-2: SEC_300] 2.78 0.42    2   3   3   3     3     4445     4031    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-3: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-3: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-3: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[UNCOVER-3: IXE_Q4W] 2.23 0.42    2   2   2   2     3     4451     4016    1 #> rank[UNCOVER-3: SEC_150] 4.00 0.05    4   4   4   4     4     4034       NA    1 #> rank[UNCOVER-3: SEC_300] 2.78 0.42    2   3   3   3     3     4445     4031    1 plot(pso_ranks_FE) (pso_rankprobs_FE <- posterior_rank_probs(pso_fit_FE, lower_better = FALSE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             0      0.00      0.00         0         0         1 #> d[FIXTURE: ETN]             0      0.00      0.00         0         1         0 #> d[FIXTURE: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[FIXTURE: IXE_Q4W]         0      0.77      0.22         0         0         0 #> d[FIXTURE: SEC_150]         0      0.00      0.00         1         0         0 #> d[FIXTURE: SEC_300]         0      0.23      0.77         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-1: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-1: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-1: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-1: IXE_Q4W]         0      0.77      0.22         0         0         0 #> d[UNCOVER-1: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-1: SEC_300]         0      0.23      0.77         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-2: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-2: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-2: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-2: IXE_Q4W]         0      0.77      0.22         0         0         0 #> d[UNCOVER-2: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-2: SEC_300]         0      0.23      0.77         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-3: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-3: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-3: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-3: IXE_Q4W]         0      0.77      0.22         0         0         0 #> d[UNCOVER-3: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-3: SEC_300]         0      0.23      0.77         0         0         0 plot(pso_rankprobs_FE) (pso_cumrankprobs_FE <- posterior_rank_probs(pso_fit_FE, lower_better = FALSE, cumulative = TRUE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             0      0.00         0         0         0         1 #> d[FIXTURE: ETN]             0      0.00         0         0         1         1 #> d[FIXTURE: IXE_Q2W]         1      1.00         1         1         1         1 #> d[FIXTURE: IXE_Q4W]         0      0.77         1         1         1         1 #> d[FIXTURE: SEC_150]         0      0.00         0         1         1         1 #> d[FIXTURE: SEC_300]         0      0.23         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-1: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-1: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-1: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-1: IXE_Q4W]         0      0.77         1         1         1         1 #> d[UNCOVER-1: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-1: SEC_300]         0      0.23         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-2: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-2: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-2: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-2: IXE_Q4W]         0      0.77         1         1         1         1 #> d[UNCOVER-2: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-2: SEC_300]         0      0.23         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-3: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-3: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-3: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-3: IXE_Q4W]         0      0.77         1         1         1         1 #> d[UNCOVER-3: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-3: SEC_300]         0      0.23         1         1         1         1 plot(pso_cumrankprobs_FE) new_agd_means <- tibble(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3) (pso_releff_FE_new <- relative_effects(pso_fit_FE, newdata = new_agd_means)) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[New 1: ETN]     1.25 0.23 0.81 1.10 1.25 1.40  1.70     7827     3293    1 #> d[New 1: IXE_Q2W] 2.88 0.22 2.46 2.74 2.88 3.03  3.31     8752     2984    1 #> d[New 1: IXE_Q4W] 2.47 0.22 2.05 2.32 2.47 2.62  2.88     8743     2859    1 #> d[New 1: SEC_150] 2.07 0.22 1.64 1.92 2.08 2.22  2.50     7737     3292    1 #> d[New 1: SEC_300] 2.38 0.22 1.95 2.23 2.37 2.53  2.81     8371     3185    1 plot(pso_releff_FE_new, ref_line = 0) new_agd_int <- tibble(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1 ) new_agd_int <- add_integration(new_agd_int,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   cor = pso_net$int_cor,   n_int = 64) (pso_pred_FE_new <- predict(pso_fit_FE,                              type = \"response\",                             newdata = new_agd_int,                             baseline = distr(qnorm, -1.75, 0.08))) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: PBO]     0.06 0.02 0.03 0.04 0.06 0.07  0.12     6392     3385    1 #> pred[New 1: ETN]     0.37 0.06 0.26 0.33 0.37 0.41  0.49     6356     3748    1 #> pred[New 1: IXE_Q2W] 0.90 0.03 0.84 0.88 0.90 0.92  0.94     5380     3458    1 #> pred[New 1: IXE_Q4W] 0.81 0.04 0.72 0.78 0.81 0.83  0.87     5273     3910    1 #> pred[New 1: SEC_150] 0.68 0.06 0.56 0.64 0.68 0.72  0.78     5333     3781    1 #> pred[New 1: SEC_300] 0.78 0.05 0.68 0.75 0.78 0.81  0.86     5400     3725    1 plot(pso_pred_FE_new, ref_line = c(0, 1))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"extended_analysis","dir":"Articles","previous_headings":"","what":"Extended analysis","title":"Example: Plaque psoriasis ML-NMR","text":"now extend network include five studies (four AgD one IPD), recreating analysis Phillippo et al. (2022). larger network allows us assess key assumptions underlying population adjustment.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"preparing-the-data-1","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Preparing the data","title":"Example: Plaque psoriasis ML-NMR","text":"begin, , data transformations covariates set treatment class variable trtclass. small number individuals missing values IPD, simply exclude analysis.","code":"# IPD studies pso_ipd <- plaque_psoriasis_ipd %>%    mutate(     # Variable transformations     bsa = bsa / 100,     weight = weight / 10,     durnpso = durnpso / 10,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL-17 blocker\",                          trtn == 4 ~ \"TNFa blocker\",                          trtn == 7 ~ \"IL-12/23 blocker\"),     # Check complete cases for covariates of interest     is_complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   ) %>%    arrange(studyc, trtn)  # AgD studies pso_agd <- plaque_psoriasis_agd %>%    mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,      bsa_sd = bsa_sd / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     prevsys = prevsys / 100,     psa = psa / 100,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL-17 blocker\",                          trtn == 4 ~ \"TNFa blocker\",                          trtn == 7 ~ \"IL-12/23 blocker\")     ) %>%    arrange(studyc, trtn) pso_ipd %>%    group_by(studyc) %>%    summarise(n_total = n(),             n_missing = sum(!is_complete),              pct_missing = mean(!is_complete) * 100) #> # A tibble: 4 × 4 #>   studyc    n_total n_missing pct_missing #>   <chr>       <int>     <int>       <dbl> #> 1 IXORA-S       260         0       0     #> 2 UNCOVER-1    1296         0       0     #> 3 UNCOVER-2    1221         2       0.164 #> 4 UNCOVER-3    1341         2       0.149  pso_ipd <- filter(pso_ipd, is_complete)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"creating-the-network-1","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Creating the network","title":"Example: Plaque psoriasis ML-NMR","text":"Next set network. set IPD set_ipd() AgD (arm-based) set_agd_arm(), combine together using combine_network(). specify ordered categorical (multinomial) outcome using multi() helper function. outcome data “inclusive” format, .e. lowest category sample size (1 IPD), second category counts achieving PASI 75 greater (\\(\\ge 75\\%\\) reduction symptoms), third counts achieving PASI 90 greater (\\(\\ge 90\\%\\) reduction), final category counts achieving PASI 100 (\\(100\\%\\) reduction).2 specify treatment classes trt_class = trtclass. create network plot using plot() function applied pso_net network object, choosing scale edges nodes number studies/sample size (weight_edges weight_nodes = TRUE), colour treatment nodes class (show_trt_class = TRUE), nudge treatment names away nodes (nudge = 0.1). customise plot using ggplot syntax alter colour scheme.","code":"pso_net <- combine_network(   set_ipd(pso_ipd,     study = studyc,     trt = trtc,     r = multi(r0 = 1,                PASI75 = pasi75,               PASI90 = pasi90,               PASI100 = pasi100,               type = \"ordered\", inclusive = TRUE),     trt_class = trtclass),   set_agd_arm(pso_agd,     study = studyc,     trt = trtc,     r = multi(r0 = pasi75_n,                PASI75 = pasi75_r,               PASI90 = pasi90_r,               PASI100 = pasi100_r,               type = \"ordered\", inclusive = TRUE),     trt_class = trtclass) )  pso_net #> A network with 4 IPD studies, and 5 AgD studies (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: PBO | IXE_Q2W | IXE_Q4W       #>  UNCOVER-2 4: PBO | IXE_Q2W | IXE_Q4W | ETN #>  UNCOVER-3 4: PBO | IXE_Q2W | IXE_Q4W | ETN #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study    Treatment arms                   #>  CLEAR    2: SEC_300 | UST                 #>  ERASURE  3: PBO | SEC_150 | SEC_300       #>  FEATURE  3: PBO | SEC_150 | SEC_300       #>  FIXTURE  4: PBO | ETN | SEC_150 | SEC_300 #>  JUNCTURE 3: PBO | SEC_150 | SEC_300       #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 7, in 4 classes #> Total number of studies: 9 #> Reference treatment is: PBO #> Network is connected class_pal <- c(\"#D95F02\", \"#7570B3\", \"#E7298A\", \"#E6AB02\")  plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE, nudge = 0.1) +   ggraph::scale_edge_colour_manual(\"Data\",                                     values = c(AgD = \"#113259\", IPD = \"#55A480\"),                                    guide = guide_legend(override.aes = list(edge_width = 2))) +   scale_fill_manual(\"Treatment class\",                      values = class_pal,                     aesthetics = c(\"fill\", \"colour\"),                     guide = guide_legend(override.aes = list(size = 2))) #> Scale for edge_colour is already present. #> Adding another scale for edge_colour, which will replace the existing scale. #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale. #> Warning: Duplicated `override.aes` is ignored."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"numerical-integration-for-ml-nmr-models","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Numerical integration for ML-NMR models","title":"Example: Plaque psoriasis ML-NMR","text":"add integration points AgD studies network using add_integration() function, specifying chosen marginal distribution covariate using distr() function. , specify Gamma distributions weight duration psoriasis, logit-Normal distribution body surface area, Bernoulli distributions previous systemic treatment psoriatic arthritis binary covariates. Since know correlations covariates AgD studies, impute weighted mean correlations IPD studies (default option).","code":"pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"ml-nmr-model","dir":"Articles","previous_headings":"Extended analysis","what":"ML-NMR model","title":"Example: Plaque psoriasis ML-NMR","text":"Using nma() function, fit (fixed effect) ML-NMR model includes main effects (prognostic terms) covariate-treatment interactions (effect-modifying terms) five covariates. Ideally, fit independent interaction terms treatment; however, requires either IPD several AgD studies range covariate values treatment. data insufficient fit independent interaction terms treatment, make shared effect modifier assumption within class treatments (Phillippo et al. 2016) specify common interaction terms within treatment class (class_interactions = \"common\"). , specify \\(\\mathrm{N}(0, 10^2)\\) prior distributions study-specific intercepts, treatment effects, regression parameters. However, since now ordered multinomial likelihood also need specify priors differences latent cutoffs outcome category; choose improper flat prior \\(\\mathrm{U}(-\\infty,\\infty)\\) automatically truncated meet ordering constraints (prior_aux = flat()).","code":"pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                    regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_aux = flat(),                   QR = TRUE,                   init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit_FE #> A fixed effects ML-NMR with a ordered likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.7947485 0.6504375 0.2973544 8.9165934 0.2074278  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.03    0.00 0.06    -0.09    -0.01     0.03     0.08 #> beta[prevsys]                              -0.17    0.00 0.15    -0.46    -0.28    -0.18    -0.07 #> beta[bsa]                                  -0.12    0.01 0.44    -1.02    -0.40    -0.11     0.18 #> beta[weight]                                0.04    0.00 0.03    -0.01     0.03     0.04     0.06 #> beta[psa]                                  -0.07    0.00 0.17    -0.43    -0.20    -0.07     0.04 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.16    -0.07    -0.02     0.03 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.06    0.00 0.10    -0.26    -0.13    -0.07     0.01 #> beta[durnpso:.trtclassIL-17 blocker]       -0.02    0.00 0.06    -0.15    -0.07    -0.02     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.20    0.00 0.18    -0.16     0.08     0.20     0.32 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.45    0.00 0.32    -0.20     0.24     0.46     0.68 #> beta[prevsys:.trtclassIL-17 blocker]        0.17    0.00 0.16    -0.15     0.06     0.17     0.28 #> beta[bsa:.trtclassTNFa blocker]             0.26    0.01 0.51    -0.71    -0.08     0.25     0.59 #> beta[bsa:.trtclassIL-12/23 blocker]         0.61    0.01 0.66    -0.65     0.17     0.61     1.06 #> beta[bsa:.trtclassIL-17 blocker]            0.29    0.01 0.46    -0.60    -0.02     0.28     0.58 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.18    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.18    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.06    0.00 0.20    -0.46    -0.19    -0.05     0.08 #> beta[psa:.trtclassIL-12/23 blocker]         0.13    0.01 0.34    -0.53    -0.10     0.12     0.35 #> beta[psa:.trtclassIL-17 blocker]            0.09    0.00 0.18    -0.26    -0.03     0.09     0.22 #> d[ETN]                                      1.58    0.00 0.07     1.44     1.53     1.58     1.63 #> d[IXE_Q2W]                                  2.91    0.00 0.07     2.77     2.86     2.91     2.96 #> d[IXE_Q4W]                                  2.69    0.00 0.08     2.55     2.64     2.69     2.74 #> d[SEC_150]                                  2.19    0.00 0.08     2.03     2.13     2.19     2.25 #> d[SEC_300]                                  2.60    0.00 0.08     2.44     2.54     2.60     2.65 #> d[UST]                                      2.13    0.00 0.11     1.91     2.06     2.13     2.21 #> lp__                                    -7752.94    0.10 4.30 -7762.02 -7755.80 -7752.63 -7749.89 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.65     0.68     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.49     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.15  3278    1 #> beta[prevsys]                               0.13  3239    1 #> beta[bsa]                                   0.73  2993    1 #> beta[weight]                                0.10  2717    1 #> beta[psa]                                   0.25  3200    1 #> beta[durnpso:.trtclassTNFa blocker]         0.12  3645    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.14  3762    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.11  3711    1 #> beta[prevsys:.trtclassTNFa blocker]         0.55  3330    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.05  4366    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.47  3593    1 #> beta[bsa:.trtclassTNFa blocker]             1.30  3147    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.89  3386    1 #> beta[bsa:.trtclassIL-17 blocker]            1.22  3490    1 #> beta[weight:.trtclassTNFa blocker]         -0.10  3342    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.00  4100    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  3080    1 #> beta[psa:.trtclassTNFa blocker]             0.34  3511    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.80  3769    1 #> beta[psa:.trtclassIL-17 blocker]            0.46  3732    1 #> d[ETN]                                      1.72  2114    1 #> d[IXE_Q2W]                                  3.06  2708    1 #> d[IXE_Q4W]                                  2.84  2949    1 #> d[SEC_150]                                  2.36  2357    1 #> d[SEC_300]                                  2.76  2456    1 #> d[UST]                                      2.36  3349    1 #> lp__                                    -7745.56  1701    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  4016    1 #> cc[PASI100]                                 1.58  3777    1 #>  #> Samples were drawn using NUTS(diag_e) at Tue Jan  9 11:53:40 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1)."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-assumptions","dir":"Articles","previous_headings":"Extended analysis","what":"Assessing assumptions","title":"Example: Plaque psoriasis ML-NMR","text":"first analysis, small network made assessing assumptions difficult. larger network (although still nine studies) greater opportunity assess key assumptions. key assumption made ML-NMR (indeed population adjustment methods connected networks) conditional constancy relative effects assumption (Phillippo et al. 2016). means unobserved effect modifiers, relative effects constant given included effect-modifying covariates. assumption implies residual heterogeneity inconsistency, can assessed using standard network meta-analysis techniques. assess residual heterogeneity using random effects model, residual inconsistency using unrelated mean effects (UME) model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-residual-heterogeneity-with-a-random-effects-ml-nmr","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Assessing residual heterogeneity with a random effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"First, fit random effects model assess residual heterogeneity. call nma() function identical fixed effect model , except now specify trt_effects = \"random\" need provide prior -study heterogeneity (choose \\(\\textrm{half-N}(0, 2.5^2)\\) prior prior_het = half_normal(scale = 2.5). estimated -study heterogeneity standard deviation tau small compared relative treatment effects. compare model fit using DIC: DIC lower RE model, indicating may residual heterogeneity network conditional constancy relative effects assumption may invalid—may additional effect modifiers accounted . result different actual analysis reported Phillippo et al. (2022), since using synthetic IPD simulated closely resemble original IPD. actual analysis DIC similar FE RE models, might choose parsimonious FE model based DIC alone, evidence residual heterogeneity network.","code":"pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                    regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_aux = flat(),                   prior_het = half_normal(scale = 2.5),                   QR = TRUE,                   init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. #> Warning: There were 1 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems pso_fit_RE #> A random effects ML-NMR with a ordered likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.7947485 0.6504375 0.2973544 8.9165934 0.2074278  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.04    0.00 0.06    -0.09     0.00     0.04     0.08 #> beta[prevsys]                              -0.16    0.00 0.16    -0.47    -0.27    -0.16    -0.05 #> beta[bsa]                                  -0.13    0.01 0.47    -1.09    -0.43    -0.11     0.20 #> beta[weight]                                0.05    0.00 0.03    -0.01     0.03     0.05     0.07 #> beta[psa]                                  -0.07    0.00 0.18    -0.41    -0.19    -0.07     0.05 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.17    -0.07    -0.03     0.03 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.07    0.00 0.10    -0.26    -0.14    -0.07     0.00 #> beta[durnpso:.trtclassIL-17 blocker]       -0.03    0.00 0.07    -0.16    -0.07    -0.03     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.19    0.00 0.18    -0.16     0.07     0.19     0.31 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.44    0.00 0.33    -0.22     0.22     0.44     0.67 #> beta[prevsys:.trtclassIL-17 blocker]        0.16    0.00 0.17    -0.17     0.05     0.16     0.27 #> beta[bsa:.trtclassTNFa blocker]             0.25    0.01 0.53    -0.75    -0.12     0.24     0.59 #> beta[bsa:.trtclassIL-12/23 blocker]         0.63    0.01 0.66    -0.65     0.18     0.62     1.07 #> beta[bsa:.trtclassIL-17 blocker]            0.30    0.01 0.48    -0.60    -0.04     0.30     0.62 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.19    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.19    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.06    0.00 0.21    -0.47    -0.20    -0.06     0.08 #> beta[psa:.trtclassIL-12/23 blocker]         0.11    0.00 0.34    -0.55    -0.12     0.11     0.34 #> beta[psa:.trtclassIL-17 blocker]            0.08    0.00 0.19    -0.29    -0.04     0.08     0.21 #> d[ETN]                                      1.59    0.00 0.11     1.38     1.52     1.59     1.65 #> d[IXE_Q2W]                                  2.93    0.00 0.11     2.72     2.86     2.93     3.00 #> d[IXE_Q4W]                                  2.71    0.00 0.11     2.48     2.64     2.71     2.78 #> d[SEC_150]                                  2.22    0.00 0.12     2.00     2.14     2.21     2.29 #> d[SEC_300]                                  2.64    0.00 0.12     2.42     2.56     2.63     2.71 #> d[UST]                                      2.17    0.00 0.17     1.85     2.06     2.16     2.27 #> lp__                                    -7761.18    0.20 6.16 -7774.24 -7765.11 -7760.94 -7756.88 #> tau                                         0.14    0.00 0.07     0.03     0.09     0.13     0.17 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.65     0.68     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.49     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.16  4028    1 #> beta[prevsys]                               0.15  3931    1 #> beta[bsa]                                   0.75  3963    1 #> beta[weight]                                0.10  4005    1 #> beta[psa]                                   0.28  3835    1 #> beta[durnpso:.trtclassTNFa blocker]         0.12  4080    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.13  4244    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.10  4440    1 #> beta[prevsys:.trtclassTNFa blocker]         0.54  4143    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.07  4555    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.48  4517    1 #> beta[bsa:.trtclassTNFa blocker]             1.33  4333    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.96  4933    1 #> beta[bsa:.trtclassIL-17 blocker]            1.30  4329    1 #> beta[weight:.trtclassTNFa blocker]         -0.10  4309    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.00  4940    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  4681    1 #> beta[psa:.trtclassTNFa blocker]             0.35  3883    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.78  4810    1 #> beta[psa:.trtclassIL-17 blocker]            0.44  4230    1 #> d[ETN]                                      1.81  2539    1 #> d[IXE_Q2W]                                  3.16  2657    1 #> d[IXE_Q4W]                                  2.93  2394    1 #> d[SEC_150]                                  2.47  2433    1 #> d[SEC_300]                                  2.90  2193    1 #> d[UST]                                      2.50  3305    1 #> lp__                                    -7750.02   985    1 #> tau                                         0.30   622    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  5611    1 #> cc[PASI100]                                 1.58  5856    1 #>  #> Samples were drawn using NUTS(diag_e) at Tue Jan  9 12:36:43 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). (pso_dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 8811.2 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.3 (pso_dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 8799.8 (on 12387 data points) #>                pD: 42.3 #>               DIC: 8842.1"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-residual-inconsistency-with-an-unrelated-mean-effects-ml-nmr","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Assessing residual inconsistency with an unrelated mean effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"assess residual inconsistency using unrelated mean effects model (Dias et al. 2011). , call nma() function identical, except time specify consistency = \"ume\". Node-splitting also possibility (consistency = \"nodesplit\"), takes substantially longer since model re-run node-split comparison. proceed analysis Phillippo et al. (2022) fit fixed effect UME model (since evidence heterogeneity actual analysis); however, recreated analysis using synthetic IPD evidence heterogeneity really fit random effects UME model instead. compare model fit FE ML-NMR model using DIC. DIC values similar FE model (assuming consistency) UME (inconsistency) model, suggests evidence inconsistency overall. also important compare residual deviance contributions model see whether points fit better UME model, can also indicate inconsistency. Using plot() function produces “dev-dev” plot residual deviance contributions either model.  points lie line equality, evidence inconsistency. random effects models fitted heterogeneity estimates also compared drop tau UME model can also indicate inconsistency.","code":"pso_fit_UME <- nma(pso_net,                     trt_effects = \"fixed\",                    consistency = \"ume\",                    link = \"probit\",                     regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                    class_interactions = \"common\",                    prior_intercept = normal(scale = 10),                    prior_trt = normal(scale = 10),                    prior_reg = normal(scale = 10),                    prior_aux = flat(),                    QR = TRUE,                    init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit_UME #> A fixed effects ML-NMR with a ordered likelihood (probit link). #> An inconsistency model ('ume') was fitted. #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.7947485 0.6504375 0.2973544 8.9165934 0.2074278  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.04    0.00 0.06    -0.08     0.00     0.04     0.08 #> beta[prevsys]                              -0.18    0.00 0.16    -0.48    -0.28    -0.18    -0.07 #> beta[bsa]                                  -0.10    0.01 0.44    -0.99    -0.38    -0.09     0.20 #> beta[weight]                                0.04    0.00 0.03    -0.01     0.03     0.04     0.06 #> beta[psa]                                  -0.08    0.00 0.16    -0.40    -0.19    -0.08     0.03 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.16    -0.07    -0.02     0.02 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.06    0.00 0.10    -0.26    -0.13    -0.07     0.00 #> beta[durnpso:.trtclassIL-17 blocker]       -0.02    0.00 0.06    -0.14    -0.07    -0.02     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.20    0.00 0.18    -0.15     0.09     0.20     0.33 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.45    0.01 0.35    -0.28     0.23     0.47     0.70 #> beta[prevsys:.trtclassIL-17 blocker]        0.17    0.00 0.16    -0.15     0.06     0.18     0.29 #> beta[bsa:.trtclassTNFa blocker]             0.24    0.01 0.50    -0.74    -0.10     0.23     0.58 #> beta[bsa:.trtclassIL-12/23 blocker]         0.60    0.01 0.66    -0.71     0.17     0.60     1.04 #> beta[bsa:.trtclassIL-17 blocker]            0.27    0.01 0.46    -0.61    -0.05     0.26     0.57 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.19    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.18    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.05    0.00 0.19    -0.44    -0.18    -0.05     0.08 #> beta[psa:.trtclassIL-12/23 blocker]         0.12    0.00 0.34    -0.53    -0.11     0.13     0.36 #> beta[psa:.trtclassIL-17 blocker]            0.10    0.00 0.17    -0.24    -0.02     0.10     0.21 #> d[ETN vs. PBO]                              1.58    0.00 0.07     1.44     1.53     1.58     1.63 #> d[IXE_Q2W vs. PBO]                          2.91    0.00 0.07     2.77     2.86     2.91     2.96 #> d[IXE_Q4W vs. PBO]                          2.69    0.00 0.07     2.55     2.64     2.69     2.74 #> d[SEC_150 vs. PBO]                          2.19    0.00 0.08     2.03     2.14     2.19     2.25 #> d[SEC_300 vs. PBO]                          2.60    0.00 0.08     2.43     2.54     2.60     2.66 #> d[UST vs. IXE_Q2W]                         -0.79    0.00 0.16    -1.10    -0.90    -0.79    -0.68 #> d[UST vs. SEC_300]                         -0.47    0.00 0.09    -0.65    -0.53    -0.47    -0.40 #> lp__                                    -7756.43    0.11 4.32 -7765.88 -7759.08 -7756.13 -7753.33 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.65     0.67     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.48     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.15  3284    1 #> beta[prevsys]                               0.12  3119    1 #> beta[bsa]                                   0.74  3357    1 #> beta[weight]                                0.10  3195    1 #> beta[psa]                                   0.25  3296    1 #> beta[durnpso:.trtclassTNFa blocker]         0.11  3451    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.14  4341    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.10  3853    1 #> beta[prevsys:.trtclassTNFa blocker]         0.55  3201    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.08  4743    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.48  3578    1 #> beta[bsa:.trtclassTNFa blocker]             1.23  3593    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.85  4364    1 #> beta[bsa:.trtclassIL-17 blocker]            1.20  3941    1 #> beta[weight:.trtclassTNFa blocker]         -0.09  3555    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.00  4746    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  3758    1 #> beta[psa:.trtclassTNFa blocker]             0.32  3727    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.77  4746    1 #> beta[psa:.trtclassIL-17 blocker]            0.45  3793    1 #> d[ETN vs. PBO]                              1.73  2605    1 #> d[IXE_Q2W vs. PBO]                          3.05  2642    1 #> d[IXE_Q4W vs. PBO]                          2.84  2998    1 #> d[SEC_150 vs. PBO]                          2.36  2650    1 #> d[SEC_300 vs. PBO]                          2.77  2861    1 #> d[UST vs. IXE_Q2W]                         -0.47  5596    1 #> d[UST vs. SEC_300]                         -0.29  6888    1 #> lp__                                    -7749.04  1498    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  3023    1 #> cc[PASI100]                                 1.58  3164    1 #>  #> Samples were drawn using NUTS(diag_e) at Tue Jan  9 12:47:42 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). pso_dic_FE #> Residual deviance: 8811.2 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.3 (pso_dic_UME <- dic(pso_fit_UME)) #> Residual deviance: 8811.8 (on 12387 data points) #>                pD: 36.5 #>               DIC: 8848.4 plot(pso_dic_FE, pso_dic_UME, show_uncertainty = FALSE) +   xlab(\"Residual deviance - consistency model\") +   ylab(\"Residual deviance - inconsistency (UME) model\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"relaxing-the-shared-effect-modifier-assumption","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Relaxing the shared effect modifier assumption","title":"Example: Plaque psoriasis ML-NMR","text":"treatment classes network follows: fitted common interaction terms within treatment class, shared effect modifier assumption, order make model estimable available data. Note interleukin-17 blocker class one treatment; etanercept ustekinumab classes unaffected specifying class_interactions = \"common\". assess assumption simply fit independent interaction terms treatments effect modifiers sufficient data. Instead, relax assumption one covariate time, estimating independent interactions one covariate whilst keeping shared effect modifier assumption (common interactions within treatment class) covariates. specify relaxed models, need somehow mix class_interactions = \"common\" class_interactions = \"independent\" different covariates. way .trt .trtclass specials specifying regression model. see works, first note model making shared effect modifiers assumption can written equivalently using .trtclass special .trtclass special essentially factor variable containing treatment classes, available time treatment classes specified network; regression formula therefore single interaction term covariate within treatment class (result specifying class_interactions = \"common\" ). Finally, fit independent interactions single covariate, say durnpso, split using .trt special class_interactions = \"independent\" (.e. telling model combine interactions .trt within classes): Since fitting several models, let us set list model specifications iterate . Comparing model fit using DIC models similar higher DIC original model making shared effect modifier assumption covariates, exception model independent interactions weight slightly lower DIC. also visually examine differences estimated interaction terms original model (shared effect modifier assumption covariates) relaxed models (independent interactions, one covariate time).  independent interaction estimates similar common interaction estimates, much uncertainty—particularly secukinumab regimens estimated aggregate data. exception weight, suggestion covariate may interact differently secukinumab treatment regimens ixekizumab regimens. However, credible intervals secukinumab interactions wide overlap ixekizumab regimens common interaction. Overall, weak evidence shared effect modifier assumption (class interleukin-17 blockers) may invalid weight. Since fitting multiple models mindful multiple testing possibility differences occurred chance. hand, approach likely low power detect violations shared effect modifier assumption, particularly data lacking. case, results model relaxing shared effect modifier assumption weight similar original model (see Phillippo et al. 2022).","code":"data.frame(classes = pso_net$classes, treatments = pso_net$treatments) #>            classes treatments #> 1          Placebo        PBO #> 2     TNFa blocker        ETN #> 3    IL-17 blocker    IXE_Q2W #> 4    IL-17 blocker    IXE_Q4W #> 5    IL-17 blocker    SEC_150 #> 6    IL-17 blocker    SEC_300 #> 7 IL-12/23 blocker        UST regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt, class_interactions = \"common\" regression = ~(durnpso + prevsys + bsa + weight + psa)*.trtclass regression = ~(prevsys + bsa + weight + psa)*.trtclass + durnpso*.trt, class_interactions = \"independent\" noSEM_mods <- list(   durnpso = ~(prevsys + bsa + weight + psa)*.trtclass + durnpso*.trt,   prevsys = ~(durnpso + bsa + weight + psa)*.trtclass + prevsys*.trt,   bsa = ~(durnpso + prevsys + weight + psa)*.trtclass + bsa*.trt,   weight = ~(durnpso + prevsys + bsa + psa)*.trtclass + weight*.trt,   psa = ~(durnpso + prevsys + bsa + weight)*.trtclass + psa*.trt   )  noSEM_fits <- noSEM_mods  for (m in 1:length(noSEM_mods)) {   cat(\"Fitting model with independent interactions for\", names(noSEM_mods)[m], \"\\n\")      noSEM_fits[[m]] <-      nma(pso_net,          trt_effects = \"fixed\",         link = \"probit\",          regression = noSEM_mods[[m]],         class_interactions = \"independent\",         prior_intercept = normal(scale = 10),         prior_trt = normal(scale = 10),         prior_reg = normal(scale = 10),         prior_aux = flat(),         QR = TRUE,         init_r = 0.5,         # Using save_warmup = FALSE reduces memory footprint when          # fitting many models in one session         save_warmup = FALSE) } #> Fitting model with independent interactions for durnpso #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for prevsys #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for bsa #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for weight #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for psa #> Note: Setting \"PBO\" as the network reference treatment. pso_dic_FE #> Residual deviance: 8811.2 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.3 lapply(noSEM_fits, dic) #> $durnpso #> Residual deviance: 8812.4 (on 12387 data points) #>                pD: 37.7 #>               DIC: 8850.1 #>  #> $prevsys #> Residual deviance: 8813 (on 12387 data points) #>                pD: 37.6 #>               DIC: 8850.6 #>  #> $bsa #> Residual deviance: 8812.8 (on 12387 data points) #>                pD: 37.7 #>               DIC: 8850.6 #>  #> $weight #> Residual deviance: 8807.3 (on 12387 data points) #>                pD: 38 #>               DIC: 8845.3 #>  #> $psa #> Residual deviance: 8812 (on 12387 data points) #>                pD: 38.5 #>               DIC: 8850.5 library(purrr) library(stringr) library(forcats)  # Extract draws from relaxed models imap_dfr(noSEM_fits,         ~as_tibble(as.matrix(.x, pars = \"beta\")) %>%             pivot_longer(cols = everything(), names_to = \"parameter\", values_to = \"value\") %>%             filter(str_detect(parameter, paste0(\"(IXE|SEC).+:\", .y))) %>%             mutate(model = .y)) %>%       # Add in draws from the original model   bind_rows(     as_tibble(as.matrix(pso_fit_FE, pars = \"beta\")) %>%      pivot_longer(cols = everything(), names_to = \"parameter\", values_to = \"value\") %>%      filter(str_detect(parameter, \":.+IL\\\\-17 blocker\")) %>%      mutate(model = \"all\")   ) %>%       mutate(     # Rescale BSA to per 10%      value = if_else(str_detect(parameter, \"bsa\"), value / 10, value),     # Create labels     covariate = str_extract(parameter, \"durnpso|prevsys|bsa|weight|psa\"),     covariatef = recode_factor(covariate,                                durnpso = \"Duration of psoriasis, per 10 years\",                                prevsys = \"Previous systemic use\",                                bsa = \"Body surface area, per 10%\",                                weight = \"Weight, per 10 kg\",                                psa = \"Psoriatic arthritis\"),     treatment = str_remove(str_extract(parameter, \"\\\\.trt(class)?.+?(?=[\\\\]:])\"),                            \"\\\\.trt(class)?\"),     Interactions = fct_collapse(factor(model),                                  Common = \"all\",                                  other_level = \"Independent\")) %>%     # Plot ggplot(aes(x = value, y = fct_rev(treatment), colour = Interactions, fill = Interactions)) +   geom_vline(xintercept = 0, colour = \"grey70\") +   ggdist::stat_halfeye(normalize = \"panels\", slab_alpha = 0.3, .width = c(0, 0.95)) +   facet_wrap(\"covariatef\", scales = \"free\") +   xlab(\"Interaction effect (SMD)\") +    ylab(\"Treatment / Class\") +   scale_colour_manual(values = c(Common = \"#7B3294\", Independent = \"#91D388\"),                       aesthetics = c(\"colour\", \"fill\")) +   theme_multinma() +   theme(legend.position = c(0.85, 0.2))"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"study-populations-included-in-the-network","dir":"Articles","previous_headings":"Extended analysis > Producing relative effects and event probabilities","what":"Study populations included in the network","title":"Example: Plaque psoriasis ML-NMR","text":"Population-average treatment effects can produced study populations represented network using relative_effects() function. relative effects can plotted using plot() function.  Similarly, average response probabilities treatment, study population, PASI cutoff can produced using predict() function. specify type = \"response\" produce predicted probabilities (rather probit-probabilities). , can plotted using plot() function.","code":"(pso_releff_FE <- relative_effects(pso_fit_FE)) #> ------------------------------------------------------------------ Study: CLEAR ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.73    0.66 0.32   8.74 0.16 #>  #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[CLEAR: ETN]     1.62 0.08 1.47 1.57 1.62 1.67  1.77     2191     2895    1 #> d[CLEAR: IXE_Q2W] 2.94 0.08 2.78 2.89 2.94 2.99  3.10     2745     2706    1 #> d[CLEAR: IXE_Q4W] 2.72 0.08 2.57 2.67 2.72 2.78  2.88     2975     2682    1 #> d[CLEAR: SEC_150] 2.22 0.09 2.05 2.16 2.22 2.28  2.39     2365     2528    1 #> d[CLEAR: SEC_300] 2.63 0.08 2.46 2.57 2.63 2.68  2.80     2411     2959    1 #> d[CLEAR: UST]     2.17 0.11 1.95 2.09 2.16 2.24  2.38     3207     2921    1 #>  #> ---------------------------------------------------------------- Study: ERASURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.69    0.61 0.32   8.86 0.23 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[ERASURE: ETN]     1.59 0.07 1.44 1.54 1.59 1.64  1.73     2244     2968    1 #> d[ERASURE: IXE_Q2W] 2.92 0.08 2.77 2.87 2.92 2.97  3.08     2777     2821    1 #> d[ERASURE: IXE_Q4W] 2.70 0.08 2.56 2.65 2.70 2.75  2.86     3019     2884    1 #> d[ERASURE: SEC_150] 2.20 0.08 2.04 2.14 2.20 2.26  2.37     2411     2749    1 #> d[ERASURE: SEC_300] 2.61 0.08 2.45 2.55 2.61 2.66  2.77     2508     2891    1 #> d[ERASURE: UST]     2.14 0.12 1.91 2.06 2.14 2.22  2.37     3493     3081    1 #>  #> ---------------------------------------------------------------- Study: FEATURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.9    0.67 0.32   9.17 0.15 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[FEATURE: ETN]     1.55 0.07 1.41 1.50 1.55 1.60  1.70     2253     3017    1 #> d[FEATURE: IXE_Q2W] 2.88 0.08 2.73 2.83 2.88 2.93  3.04     2881     2641    1 #> d[FEATURE: IXE_Q4W] 2.66 0.08 2.51 2.61 2.66 2.71  2.82     3121     3016    1 #> d[FEATURE: SEC_150] 2.16 0.08 2.00 2.10 2.16 2.22  2.33     2421     2566    1 #> d[FEATURE: SEC_300] 2.57 0.08 2.41 2.51 2.57 2.62  2.73     2530     2830    1 #> d[FEATURE: UST]     2.12 0.11 1.90 2.05 2.12 2.19  2.34     3432     3215    1 #>  #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[FIXTURE: ETN]     1.69 0.08 1.53 1.63 1.68 1.74  1.85     2382     2730    1 #> d[FIXTURE: IXE_Q2W] 2.99 0.09 2.82 2.93 2.99 3.05  3.17     2834     2794    1 #> d[FIXTURE: IXE_Q4W] 2.77 0.09 2.61 2.72 2.77 2.83  2.95     3045     2875    1 #> d[FIXTURE: SEC_150] 2.27 0.09 2.10 2.21 2.27 2.33  2.45     2406     2615    1 #> d[FIXTURE: SEC_300] 2.68 0.09 2.51 2.62 2.68 2.74  2.86     2408     2992    1 #> d[FIXTURE: UST]     2.20 0.12 1.97 2.12 2.20 2.28  2.43     3246     3097    1 #>  #> ---------------------------------------------------------------- Study: IXORA-S ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.67    0.92 0.32   8.78 0.13 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[IXORA-S: ETN]     1.67 0.10 1.48 1.60 1.67 1.73  1.86     2140     2711    1 #> d[IXORA-S: IXE_Q2W] 2.98 0.10 2.79 2.91 2.97 3.04  3.17     2546     2835    1 #> d[IXORA-S: IXE_Q4W] 2.76 0.10 2.57 2.69 2.76 2.82  2.96     2763     2864    1 #> d[IXORA-S: SEC_150] 2.25 0.10 2.05 2.18 2.25 2.33  2.46     2373     3009    1 #> d[IXORA-S: SEC_300] 2.66 0.10 2.47 2.59 2.66 2.73  2.87     2418     3124    1 #> d[IXORA-S: UST]     2.28 0.13 2.04 2.19 2.27 2.36  2.53     2946     2530    1 #>  #> --------------------------------------------------------------- Study: JUNCTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.99    0.55 0.27   9.17 0.23 #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[JUNCTURE: ETN]     1.51 0.07 1.37 1.46 1.51 1.56  1.65     2419     3021    1 #> d[JUNCTURE: IXE_Q2W] 2.85 0.07 2.71 2.80 2.85 2.90  3.00     3004     2766    1 #> d[JUNCTURE: IXE_Q4W] 2.63 0.07 2.49 2.59 2.63 2.68  2.78     3295     3225    1 #> d[JUNCTURE: SEC_150] 2.13 0.08 1.97 2.07 2.13 2.18  2.30     2559     2584    1 #> d[JUNCTURE: SEC_300] 2.54 0.08 2.38 2.48 2.54 2.59  2.70     2737     2431    1 #> d[JUNCTURE: UST]     2.04 0.13 1.78 1.94 2.03 2.12  2.31     3874     3205    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-1: ETN]     1.53 0.08 1.38 1.48 1.53 1.58  1.68     2019     2694    1 #> d[UNCOVER-1: IXE_Q2W] 2.88 0.08 2.74 2.83 2.88 2.93  3.03     2590     2963    1 #> d[UNCOVER-1: IXE_Q4W] 2.66 0.08 2.51 2.61 2.66 2.71  2.81     2771     2664    1 #> d[UNCOVER-1: SEC_150] 2.16 0.09 1.99 2.10 2.16 2.22  2.33     2325     2735    1 #> d[UNCOVER-1: SEC_300] 2.57 0.09 2.40 2.51 2.57 2.63  2.74     2452     2753    1 #> d[UNCOVER-1: UST]     2.12 0.12 1.88 2.04 2.12 2.20  2.36     3351     3318    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-2: ETN]     1.53 0.07 1.39 1.48 1.53 1.58  1.67     2151     2749    1 #> d[UNCOVER-2: IXE_Q2W] 2.87 0.07 2.73 2.82 2.87 2.92  3.01     2708     2688    1 #> d[UNCOVER-2: IXE_Q4W] 2.65 0.07 2.51 2.60 2.65 2.70  2.79     2977     2739    1 #> d[UNCOVER-2: SEC_150] 2.15 0.08 1.99 2.09 2.15 2.20  2.31     2451     2480    1 #> d[UNCOVER-2: SEC_300] 2.56 0.08 2.40 2.50 2.56 2.61  2.72     2566     2563    1 #> d[UNCOVER-2: UST]     2.08 0.12 1.85 2.00 2.08 2.17  2.33     3490     3316    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-3: ETN]     1.55 0.07 1.41 1.50 1.55 1.60  1.69     2315     2954    1 #> d[UNCOVER-3: IXE_Q2W] 2.88 0.07 2.74 2.83 2.88 2.93  3.03     2846     2790    1 #> d[UNCOVER-3: IXE_Q4W] 2.67 0.07 2.52 2.62 2.67 2.72  2.81     3132     2866    1 #> d[UNCOVER-3: SEC_150] 2.16 0.08 2.01 2.11 2.16 2.22  2.32     2481     2445    1 #> d[UNCOVER-3: SEC_300] 2.57 0.08 2.41 2.52 2.57 2.62  2.73     2603     2581    1 #> d[UNCOVER-3: UST]     2.08 0.12 1.85 2.00 2.08 2.16  2.33     3588     3148    1 plot(pso_releff_FE, ref_line = 0) (pso_pred_FE <- predict(pso_fit_FE, type = \"response\")) #> ------------------------------------------------------------------ Study: CLEAR ----  #>  #>                               mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[CLEAR: PBO, PASI75]      0.09 0.02 0.07 0.08 0.09 0.10  0.13     3226     2898    1 #> pred[CLEAR: PBO, PASI90]      0.02 0.01 0.01 0.02 0.02 0.03  0.04     3516     3005    1 #> pred[CLEAR: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3935     2940    1 #> pred[CLEAR: ETN, PASI75]      0.61 0.03 0.54 0.58 0.61 0.63  0.67     6487     2944    1 #> pred[CLEAR: ETN, PASI90]      0.35 0.03 0.29 0.32 0.35 0.37  0.41     6826     2581    1 #> pred[CLEAR: ETN, PASI100]     0.11 0.02 0.08 0.10 0.11 0.12  0.15     7281     2823    1 #> pred[CLEAR: IXE_Q2W, PASI75]  0.94 0.01 0.92 0.93 0.94 0.95  0.96     5425     3102    1 #> pred[CLEAR: IXE_Q2W, PASI90]  0.81 0.02 0.76 0.80 0.81 0.83  0.86     5686     3102    1 #> pred[CLEAR: IXE_Q2W, PASI100] 0.52 0.04 0.45 0.50 0.52 0.55  0.60     6050     3334    1 #> pred[CLEAR: IXE_Q4W, PASI75]  0.91 0.02 0.88 0.90 0.91 0.92  0.94     5650     3038    1 #> pred[CLEAR: IXE_Q4W, PASI90]  0.75 0.03 0.69 0.73 0.75 0.77  0.81     5883     2991    1 #> pred[CLEAR: IXE_Q4W, PASI100] 0.44 0.04 0.37 0.41 0.44 0.46  0.51     6236     2898    1 #> pred[CLEAR: SEC_150, PASI75]  0.80 0.02 0.76 0.79 0.80 0.82  0.85     6974     3030    1 #> pred[CLEAR: SEC_150, PASI90]  0.57 0.03 0.51 0.55 0.57 0.59  0.63     7522     2931    1 #> pred[CLEAR: SEC_150, PASI100] 0.26 0.03 0.21 0.24 0.26 0.28  0.31     7795     3102    1 #> pred[CLEAR: SEC_300, PASI75]  0.90 0.01 0.87 0.89 0.90 0.90  0.92     7070     3340    1 #> pred[CLEAR: SEC_300, PASI90]  0.72 0.02 0.68 0.71 0.72 0.73  0.76     8084     3407    1 #> pred[CLEAR: SEC_300, PASI100] 0.40 0.02 0.36 0.39 0.40 0.42  0.45     9002     3557    1 #> pred[CLEAR: UST, PASI75]      0.78 0.02 0.75 0.77 0.78 0.80  0.82     6525     3460    1 #> pred[CLEAR: UST, PASI90]      0.55 0.02 0.51 0.54 0.55 0.57  0.59     7217     2959    1 #> pred[CLEAR: UST, PASI100]     0.25 0.02 0.21 0.23 0.25 0.26  0.28     6991     3323    1 #>  #> ---------------------------------------------------------------- Study: ERASURE ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ERASURE: PBO, PASI75]      0.05 0.01 0.03 0.04 0.05 0.05  0.06     2649     2638    1 #> pred[ERASURE: PBO, PASI90]      0.01 0.00 0.01 0.01 0.01 0.01  0.01     2816     2731    1 #> pred[ERASURE: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3172     2552    1 #> pred[ERASURE: ETN, PASI75]      0.45 0.03 0.40 0.43 0.45 0.47  0.51     5025     2755    1 #> pred[ERASURE: ETN, PASI90]      0.22 0.02 0.18 0.20 0.22 0.23  0.27     4758     3003    1 #> pred[ERASURE: ETN, PASI100]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     5151     3063    1 #> pred[ERASURE: IXE_Q2W, PASI75]  0.88 0.02 0.85 0.87 0.88 0.89  0.91     4393     3184    1 #> pred[ERASURE: IXE_Q2W, PASI90]  0.70 0.03 0.64 0.68 0.70 0.72  0.75     4403     3212    1 #> pred[ERASURE: IXE_Q2W, PASI100] 0.38 0.03 0.32 0.36 0.38 0.40  0.44     4520     3034    1 #> pred[ERASURE: IXE_Q4W, PASI75]  0.83 0.02 0.79 0.82 0.84 0.85  0.87     4583     3113    1 #> pred[ERASURE: IXE_Q4W, PASI90]  0.62 0.03 0.55 0.60 0.62 0.64  0.68     4622     3175    1 #> pred[ERASURE: IXE_Q4W, PASI100] 0.30 0.03 0.24 0.28 0.30 0.32  0.36     4734     3180    1 #> pred[ERASURE: SEC_150, PASI75]  0.68 0.02 0.65 0.67 0.69 0.70  0.72     6563     2962    1 #> pred[ERASURE: SEC_150, PASI90]  0.42 0.02 0.38 0.41 0.42 0.44  0.47     7123     3203    1 #> pred[ERASURE: SEC_150, PASI100] 0.15 0.01 0.13 0.14 0.15 0.16  0.18     6746     3046    1 #> pred[ERASURE: SEC_300, PASI75]  0.81 0.02 0.78 0.80 0.81 0.82  0.84     5243     2986    1 #> pred[ERASURE: SEC_300, PASI90]  0.58 0.02 0.54 0.57 0.58 0.60  0.62     5377     2999    1 #> pred[ERASURE: SEC_300, PASI100] 0.27 0.02 0.23 0.25 0.27 0.28  0.31     5602     2968    1 #> pred[ERASURE: UST, PASI75]      0.66 0.04 0.58 0.63 0.66 0.68  0.73     7153     2959    1 #> pred[ERASURE: UST, PASI90]      0.40 0.04 0.33 0.38 0.40 0.43  0.48     6931     3035    1 #> pred[ERASURE: UST, PASI100]     0.15 0.02 0.11 0.13 0.15 0.16  0.20     6275     3460    1 #>  #> ---------------------------------------------------------------- Study: FEATURE ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[FEATURE: PBO, PASI75]      0.05 0.01 0.03 0.04 0.05 0.06  0.08     3528     3111    1 #> pred[FEATURE: PBO, PASI90]      0.01 0.00 0.01 0.01 0.01 0.01  0.02     3573     2996    1 #> pred[FEATURE: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3744     3288    1 #> pred[FEATURE: ETN, PASI75]      0.45 0.04 0.37 0.42 0.45 0.48  0.54     4758     2641    1 #> pred[FEATURE: ETN, PASI90]      0.22 0.03 0.16 0.20 0.22 0.24  0.29     4716     2394    1 #> pred[FEATURE: ETN, PASI100]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     4908     2778    1 #> pred[FEATURE: IXE_Q2W, PASI75]  0.88 0.02 0.83 0.86 0.88 0.90  0.92     4349     2947    1 #> pred[FEATURE: IXE_Q2W, PASI90]  0.69 0.04 0.61 0.67 0.69 0.72  0.77     4378     2871    1 #> pred[FEATURE: IXE_Q2W, PASI100] 0.38 0.04 0.29 0.34 0.37 0.41  0.47     4556     2931    1 #> pred[FEATURE: IXE_Q4W, PASI75]  0.83 0.03 0.77 0.81 0.83 0.85  0.89     4688     3086    1 #> pred[FEATURE: IXE_Q4W, PASI90]  0.62 0.05 0.53 0.59 0.62 0.65  0.70     4720     3044    1 #> pred[FEATURE: IXE_Q4W, PASI100] 0.30 0.04 0.22 0.27 0.30 0.33  0.38     4944     3268    1 #> pred[FEATURE: SEC_150, PASI75]  0.68 0.03 0.61 0.66 0.68 0.71  0.75     5407     3219    1 #> pred[FEATURE: SEC_150, PASI90]  0.42 0.04 0.35 0.40 0.42 0.45  0.50     5530     3094    1 #> pred[FEATURE: SEC_150, PASI100] 0.15 0.02 0.11 0.14 0.15 0.17  0.20     5714     3379    1 #> pred[FEATURE: SEC_300, PASI75]  0.81 0.03 0.75 0.79 0.81 0.83  0.86     5144     2976    1 #> pred[FEATURE: SEC_300, PASI90]  0.58 0.04 0.51 0.55 0.58 0.61  0.65     5230     2987    1 #> pred[FEATURE: SEC_300, PASI100] 0.27 0.03 0.21 0.24 0.27 0.29  0.33     5420     3102    1 #> pred[FEATURE: UST, PASI75]      0.66 0.04 0.58 0.63 0.66 0.70  0.75     6147     3316    1 #> pred[FEATURE: UST, PASI90]      0.41 0.05 0.32 0.38 0.41 0.44  0.50     5953     3395    1 #> pred[FEATURE: UST, PASI100]     0.15 0.03 0.10 0.13 0.15 0.17  0.21     5912     3341    1 #>  #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[FIXTURE: PBO, PASI75]      0.04 0.01 0.03 0.03 0.04 0.04  0.05     2405     2526    1 #> pred[FIXTURE: PBO, PASI90]      0.01 0.00 0.00 0.01 0.01 0.01  0.01     2573     2779    1 #> pred[FIXTURE: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     2939     2784    1 #> pred[FIXTURE: ETN, PASI75]      0.44 0.02 0.40 0.43 0.44 0.46  0.49     5779     2950    1 #> pred[FIXTURE: ETN, PASI90]      0.21 0.02 0.18 0.20 0.21 0.22  0.24     5838     3063    1 #> pred[FIXTURE: ETN, PASI100]     0.05 0.01 0.04 0.05 0.05 0.06  0.07     6526     3466    1 #> pred[FIXTURE: IXE_Q2W, PASI75]  0.87 0.02 0.84 0.86 0.87 0.88  0.90     4706     3270    1 #> pred[FIXTURE: IXE_Q2W, PASI90]  0.68 0.03 0.63 0.66 0.68 0.70  0.73     4756     3306    1 #> pred[FIXTURE: IXE_Q2W, PASI100] 0.36 0.03 0.31 0.34 0.36 0.37  0.41     5019     3429    1 #> pred[FIXTURE: IXE_Q4W, PASI75]  0.82 0.02 0.78 0.81 0.82 0.84  0.86     4960     3445    1 #> pred[FIXTURE: IXE_Q4W, PASI90]  0.60 0.03 0.54 0.58 0.60 0.62  0.65     5125     3367    1 #> pred[FIXTURE: IXE_Q4W, PASI100] 0.28 0.03 0.23 0.26 0.28 0.30  0.33     5495     3586    1 #> pred[FIXTURE: SEC_150, PASI75]  0.67 0.02 0.63 0.65 0.67 0.68  0.70     6709     2896    1 #> pred[FIXTURE: SEC_150, PASI90]  0.40 0.02 0.36 0.39 0.40 0.42  0.44     7792     2801    1 #> pred[FIXTURE: SEC_150, PASI100] 0.14 0.01 0.12 0.13 0.14 0.15  0.16     7645     2984    1 #> pred[FIXTURE: SEC_300, PASI75]  0.80 0.01 0.77 0.79 0.80 0.81  0.82     7048     3072    1 #> pred[FIXTURE: SEC_300, PASI90]  0.56 0.02 0.52 0.55 0.56 0.58  0.60     8080     2971    1 #> pred[FIXTURE: SEC_300, PASI100] 0.25 0.02 0.22 0.24 0.25 0.26  0.28     8438     2901    1 #> pred[FIXTURE: UST, PASI75]      0.64 0.03 0.57 0.61 0.64 0.66  0.70     8702     3157    1 #> pred[FIXTURE: UST, PASI90]      0.38 0.03 0.31 0.36 0.38 0.40  0.45     8574     3069    1 #> pred[FIXTURE: UST, PASI100]     0.13 0.02 0.10 0.12 0.13 0.14  0.17     7713     3267    1 #>  #> ---------------------------------------------------------------- Study: IXORA-S ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[IXORA-S: PBO, PASI75]      0.05 0.01 0.03 0.04 0.05 0.05  0.07     3061     3007    1 #> pred[IXORA-S: PBO, PASI90]      0.01 0.00 0.00 0.01 0.01 0.01  0.02     3191     2842    1 #> pred[IXORA-S: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3332     3061    1 #> pred[IXORA-S: ETN, PASI75]      0.48 0.04 0.41 0.46 0.48 0.51  0.56     5617     3325    1 #> pred[IXORA-S: ETN, PASI90]      0.24 0.03 0.19 0.22 0.24 0.26  0.30     5603     3080    1 #> pred[IXORA-S: ETN, PASI100]     0.06 0.01 0.04 0.06 0.06 0.07  0.09     5527     3041    1 #> pred[IXORA-S: IXE_Q2W, PASI75]  0.89 0.02 0.86 0.88 0.89 0.90  0.92     5451     3254    1 #> pred[IXORA-S: IXE_Q2W, PASI90]  0.71 0.03 0.65 0.69 0.71 0.73  0.77     5597     3197    1 #> pred[IXORA-S: IXE_Q2W, PASI100] 0.40 0.03 0.33 0.37 0.40 0.42  0.46     5615     3013    1 #> pred[IXORA-S: IXE_Q4W, PASI75]  0.85 0.02 0.80 0.83 0.85 0.86  0.89     5613     2964    1 #> pred[IXORA-S: IXE_Q4W, PASI90]  0.64 0.04 0.57 0.61 0.64 0.66  0.70     5772     2967    1 #> pred[IXORA-S: IXE_Q4W, PASI100] 0.32 0.03 0.25 0.29 0.32 0.34  0.39     5831     2973    1 #> pred[IXORA-S: SEC_150, PASI75]  0.70 0.04 0.63 0.68 0.70 0.73  0.77     4994     3394    1 #> pred[IXORA-S: SEC_150, PASI90]  0.44 0.04 0.36 0.42 0.44 0.47  0.53     5162     3501    1 #> pred[IXORA-S: SEC_150, PASI100] 0.17 0.03 0.12 0.15 0.16 0.18  0.22     5044     3639    1 #> pred[IXORA-S: SEC_300, PASI75]  0.82 0.03 0.77 0.81 0.82 0.84  0.87     5587     3690    1 #> pred[IXORA-S: SEC_300, PASI90]  0.60 0.04 0.53 0.58 0.60 0.63  0.67     5773     3365    1 #> pred[IXORA-S: SEC_300, PASI100] 0.28 0.03 0.22 0.26 0.28 0.31  0.35     5646     3690    1 #> pred[IXORA-S: UST, PASI75]      0.71 0.03 0.65 0.69 0.71 0.73  0.76     5639     2992    1 #> pred[IXORA-S: UST, PASI90]      0.45 0.03 0.39 0.43 0.45 0.47  0.51     5732     2939    1 #> pred[IXORA-S: UST, PASI100]     0.17 0.02 0.13 0.16 0.17 0.19  0.22     5739     3114    1 #>  #> --------------------------------------------------------------- Study: JUNCTURE ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[JUNCTURE: PBO, PASI75]      0.06 0.01 0.03 0.05 0.05 0.06  0.08     4273     3268    1 #> pred[JUNCTURE: PBO, PASI90]      0.01 0.00 0.01 0.01 0.01 0.01  0.02     4356     3124    1 #> pred[JUNCTURE: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     4530     3119    1 #> pred[JUNCTURE: ETN, PASI75]      0.45 0.04 0.37 0.42 0.45 0.48  0.54     5721     3097    1 #> pred[JUNCTURE: ETN, PASI90]      0.22 0.03 0.16 0.20 0.22 0.24  0.29     5719     3291    1 #> pred[JUNCTURE: ETN, PASI100]     0.06 0.01 0.03 0.05 0.06 0.06  0.09     5795     3200    1 #> pred[JUNCTURE: IXE_Q2W, PASI75]  0.88 0.02 0.83 0.87 0.88 0.90  0.92     5095     3287    1 #> pred[JUNCTURE: IXE_Q2W, PASI90]  0.70 0.04 0.61 0.67 0.70 0.72  0.77     5150     3371    1 #> pred[JUNCTURE: IXE_Q2W, PASI100] 0.38 0.04 0.29 0.35 0.38 0.41  0.47     5350     3448    1 #> pred[JUNCTURE: IXE_Q4W, PASI75]  0.83 0.03 0.77 0.81 0.84 0.85  0.88     5341     3326    1 #> pred[JUNCTURE: IXE_Q4W, PASI90]  0.62 0.04 0.53 0.59 0.62 0.65  0.70     5399     3365    1 #> pred[JUNCTURE: IXE_Q4W, PASI100] 0.30 0.04 0.22 0.27 0.30 0.33  0.39     5618     3134    1 #> pred[JUNCTURE: SEC_150, PASI75]  0.68 0.03 0.61 0.66 0.68 0.71  0.75     5890     3193    1 #> pred[JUNCTURE: SEC_150, PASI90]  0.42 0.04 0.35 0.40 0.42 0.45  0.50     6104     3324    1 #> pred[JUNCTURE: SEC_150, PASI100] 0.16 0.02 0.11 0.14 0.15 0.17  0.20     6257     3386    1 #> pred[JUNCTURE: SEC_300, PASI75]  0.81 0.03 0.75 0.79 0.81 0.83  0.86     6201     3114    1 #> pred[JUNCTURE: SEC_300, PASI90]  0.58 0.04 0.51 0.56 0.58 0.61  0.65     6395     3145    1 #> pred[JUNCTURE: SEC_300, PASI100] 0.27 0.03 0.21 0.25 0.27 0.29  0.33     6578     2844    1 #> pred[JUNCTURE: UST, PASI75]      0.65 0.05 0.54 0.61 0.65 0.68  0.75     6638     3078    1 #> pred[JUNCTURE: UST, PASI90]      0.39 0.05 0.29 0.36 0.39 0.43  0.50     6572     3031    1 #> pred[JUNCTURE: UST, PASI100]     0.14 0.03 0.09 0.12 0.14 0.16  0.21     6285     3384    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #>                                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-1: PBO, PASI75]      0.06 0.01 0.04 0.05 0.06 0.06  0.07     2932     2882    1 #> pred[UNCOVER-1: PBO, PASI90]      0.01 0.00 0.01 0.01 0.01 0.01  0.02     3181     2654    1 #> pred[UNCOVER-1: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3470     2886    1 #> pred[UNCOVER-1: ETN, PASI75]      0.47 0.02 0.42 0.45 0.47 0.48  0.51     4589     2900    1 #> pred[UNCOVER-1: ETN, PASI90]      0.23 0.02 0.20 0.22 0.23 0.24  0.26     4645     3166    1 #> pred[UNCOVER-1: ETN, PASI100]     0.06 0.01 0.05 0.06 0.06 0.06  0.08     4571     2859    1 #> pred[UNCOVER-1: IXE_Q2W, PASI75]  0.89 0.01 0.87 0.88 0.89 0.90  0.91     6322     3068    1 #> pred[UNCOVER-1: IXE_Q2W, PASI90]  0.71 0.01 0.68 0.70 0.71 0.72  0.74     7204     3180    1 #> pred[UNCOVER-1: IXE_Q2W, PASI100] 0.39 0.02 0.36 0.38 0.39 0.40  0.43     7586     3358    1 #> pred[UNCOVER-1: IXE_Q4W, PASI75]  0.84 0.01 0.82 0.84 0.84 0.85  0.86     6326     3169    1 #> pred[UNCOVER-1: IXE_Q4W, PASI90]  0.63 0.02 0.60 0.62 0.63 0.65  0.66     7231     3067    1 #> pred[UNCOVER-1: IXE_Q4W, PASI100] 0.31 0.02 0.28 0.30 0.31 0.33  0.35     7674     3322    1 #> pred[UNCOVER-1: SEC_150, PASI75]  0.70 0.03 0.64 0.68 0.70 0.72  0.75     4573     2962    1 #> pred[UNCOVER-1: SEC_150, PASI90]  0.44 0.03 0.37 0.42 0.44 0.46  0.51     4631     3137    1 #> pred[UNCOVER-1: SEC_150, PASI100] 0.17 0.02 0.13 0.15 0.16 0.18  0.21     4574     2811    1 #> pred[UNCOVER-1: SEC_300, PASI75]  0.82 0.02 0.78 0.81 0.82 0.84  0.86     4833     3200    1 #> pred[UNCOVER-1: SEC_300, PASI90]  0.60 0.03 0.54 0.58 0.60 0.62  0.66     4991     3389    1 #> pred[UNCOVER-1: SEC_300, PASI100] 0.28 0.03 0.23 0.26 0.28 0.30  0.34     4873     3424    1 #> pred[UNCOVER-1: UST, PASI75]      0.68 0.04 0.60 0.66 0.68 0.71  0.76     5260     3088    1 #> pred[UNCOVER-1: UST, PASI90]      0.43 0.04 0.35 0.40 0.43 0.46  0.51     5378     3504    1 #> pred[UNCOVER-1: UST, PASI100]     0.16 0.03 0.12 0.14 0.16 0.18  0.22     5219     3385    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #>                                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-2: PBO, PASI75]      0.05 0.01 0.04 0.05 0.05 0.06  0.06     3122     2522    1 #> pred[UNCOVER-2: PBO, PASI90]      0.01 0.00 0.01 0.01 0.01 0.01  0.01     3356     2912    1 #> pred[UNCOVER-2: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3626     3266    1 #> pred[UNCOVER-2: ETN, PASI75]      0.44 0.02 0.40 0.43 0.44 0.45  0.48     4685     3191    1 #> pred[UNCOVER-2: ETN, PASI90]      0.21 0.01 0.18 0.20 0.21 0.22  0.24     5049     3053    1 #> pred[UNCOVER-2: ETN, PASI100]     0.05 0.01 0.04 0.05 0.05 0.06  0.06     5048     3316    1 #> pred[UNCOVER-2: IXE_Q2W, PASI75]  0.88 0.01 0.86 0.87 0.88 0.88  0.90     5035     2716    1 #> pred[UNCOVER-2: IXE_Q2W, PASI90]  0.69 0.02 0.66 0.68 0.69 0.70  0.72     5739     2934    1 #> pred[UNCOVER-2: IXE_Q2W, PASI100] 0.37 0.02 0.34 0.36 0.37 0.38  0.40     6147     3060    1 #> pred[UNCOVER-2: IXE_Q4W, PASI75]  0.83 0.01 0.81 0.82 0.83 0.84  0.85     5474     2962    1 #> pred[UNCOVER-2: IXE_Q4W, PASI90]  0.61 0.02 0.58 0.60 0.61 0.62  0.64     6371     3437    1 #> pred[UNCOVER-2: IXE_Q4W, PASI100] 0.29 0.02 0.26 0.28 0.29 0.30  0.32     6973     3554    1 #> pred[UNCOVER-2: SEC_150, PASI75]  0.68 0.03 0.61 0.66 0.68 0.70  0.73     5016     3385    1 #> pred[UNCOVER-2: SEC_150, PASI90]  0.41 0.03 0.35 0.39 0.41 0.44  0.48     5125     3421    1 #> pred[UNCOVER-2: SEC_150, PASI100] 0.15 0.02 0.11 0.13 0.15 0.16  0.19     5019     3539    1 #> pred[UNCOVER-2: SEC_300, PASI75]  0.80 0.02 0.76 0.79 0.81 0.82  0.84     5077     3048    1 #> pred[UNCOVER-2: SEC_300, PASI90]  0.57 0.03 0.51 0.55 0.57 0.60  0.63     5322     2906    1 #> pred[UNCOVER-2: SEC_300, PASI100] 0.26 0.03 0.21 0.24 0.26 0.28  0.31     5359     3285    1 #> pred[UNCOVER-2: UST, PASI75]      0.65 0.04 0.56 0.62 0.65 0.68  0.73     5584     3209    1 #> pred[UNCOVER-2: UST, PASI90]      0.39 0.04 0.31 0.36 0.39 0.42  0.48     5564     3136    1 #> pred[UNCOVER-2: UST, PASI100]     0.14 0.02 0.10 0.12 0.14 0.16  0.19     5238     3227    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #>                                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-3: PBO, PASI75]      0.07 0.01 0.05 0.06 0.07 0.07  0.09     3408     2896    1 #> pred[UNCOVER-3: PBO, PASI90]      0.02 0.00 0.01 0.01 0.01 0.02  0.02     3699     2795    1 #> pred[UNCOVER-3: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     4199     3282    1 #> pred[UNCOVER-3: ETN, PASI75]      0.51 0.02 0.47 0.49 0.51 0.52  0.54     5141     3015    1 #> pred[UNCOVER-3: ETN, PASI90]      0.26 0.01 0.23 0.25 0.26 0.27  0.29     5478     3035    1 #> pred[UNCOVER-3: ETN, PASI100]     0.07 0.01 0.06 0.07 0.07 0.08  0.09     5733     3307    1 #> pred[UNCOVER-3: IXE_Q2W, PASI75]  0.91 0.01 0.89 0.90 0.91 0.91  0.92     4495     3217    1 #> pred[UNCOVER-3: IXE_Q2W, PASI90]  0.74 0.01 0.71 0.73 0.74 0.75  0.77     5272     2943    1 #> pred[UNCOVER-3: IXE_Q2W, PASI100] 0.43 0.02 0.40 0.42 0.43 0.44  0.46     5853     2938    1 #> pred[UNCOVER-3: IXE_Q4W, PASI75]  0.87 0.01 0.85 0.86 0.87 0.87  0.88     5666     3558    1 #> pred[UNCOVER-3: IXE_Q4W, PASI90]  0.67 0.02 0.64 0.66 0.67 0.68  0.70     6671     3608    1 #> pred[UNCOVER-3: IXE_Q4W, PASI100] 0.35 0.02 0.32 0.34 0.35 0.36  0.38     8120     3670    1 #> pred[UNCOVER-3: SEC_150, PASI75]  0.73 0.03 0.67 0.71 0.73 0.75  0.78     5136     3029    1 #> pred[UNCOVER-3: SEC_150, PASI90]  0.48 0.03 0.41 0.46 0.48 0.50  0.54     5367     2968    1 #> pred[UNCOVER-3: SEC_150, PASI100] 0.19 0.02 0.15 0.17 0.19 0.20  0.23     5276     2947    1 #> pred[UNCOVER-3: SEC_300, PASI75]  0.84 0.02 0.80 0.83 0.84 0.86  0.88     5481     3182    1 #> pred[UNCOVER-3: SEC_300, PASI90]  0.63 0.03 0.57 0.61 0.63 0.65  0.69     5782     2938    1 #> pred[UNCOVER-3: SEC_300, PASI100] 0.31 0.03 0.26 0.29 0.31 0.33  0.37     5694     3154    1 #> pred[UNCOVER-3: UST, PASI75]      0.70 0.04 0.62 0.67 0.70 0.73  0.77     5694     3534    1 #> pred[UNCOVER-3: UST, PASI90]      0.45 0.04 0.37 0.42 0.45 0.48  0.53     5692     3345    1 #> pred[UNCOVER-3: UST, PASI100]     0.17 0.03 0.13 0.16 0.17 0.19  0.23     5399     3632    1 plot(pso_pred_FE, ref_line = c(0, 1))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"external-target-populations","dir":"Articles","previous_headings":"Extended analysis > Producing relative effects and event probabilities","what":"External target populations","title":"Example: Plaque psoriasis ML-NMR","text":"purposes decision-making crucial population-average estimates produced decision target population interest. decision target population may represented study populations network, indeed likely best represented external registry cohort study, perhaps expert knowledge (Phillippo et al. 2016). example, Phillippo et al. (2022) produce estimates three external target populations represented PsoBest registry (Reich et al. 2015; Augustin et al. 2014), PROSPECT (Thaçi et al. 2019) Chiricozzi 2019 (Chiricozzi et al. 2019) cohort studies. First , need covariate means standard deviations populations: produce estimates population-average treatment effects, use relative_effects() function data frame covariate means target populations newdata argument. need covariate means, variable names matching regression. estimates plotted using plot() function.  Estimates average event probabilities produced integrating predictions joint covariate distribution population. Since marginal summary statistics available, rather full IPD, create integration points using add_integration() function specifying forms marginal distributions correlation matrix. choose use forms marginal distributions used specifying integration points AgD studies network, weighted correlation matrix IPD studies. use predict() function produce average event probabilities (type = \"response\", level = \"aggregate\" default) target populations. , also need specify distribution baseline event probabilities (.e. probability achieving PASI 75 response) target populations. PASI 75 event counts individuals receiving secukinumab 300 mg treatment available PROSPECT (1156 achieved PASI 75 1509) Chiricozzi 2019 (243 330), use construct beta distributions baseline average response probabilities (specify baseline_level = \"aggregate\" population averages, rather specific reference individual, baseline_type = \"response\" probabilities rather transformed probit probabilities). information baseline response available PsoBest, predictions absolute response rates made. , plot estimates using plot() function, customisation using ggplot syntax.","code":"new_agd_means <- tibble::tribble(              ~study, ~covariate,  ~mean,   ~sd,           \"PsoBest\",      \"bsa\",     24,  20.5,           \"PsoBest\",  \"durnpso\",   18.2,  14.1,           \"PsoBest\",  \"prevsys\",   0.54,    NA,           \"PsoBest\",      \"psa\",  0.207,    NA,           \"PsoBest\",   \"weight\",     85,  19.1,          \"PROSPECT\",      \"bsa\",   18.7,  18.4,          \"PROSPECT\",  \"durnpso\",   19.6,  13.5,          \"PROSPECT\",  \"prevsys\", 0.9095,    NA,          \"PROSPECT\",      \"psa\",  0.202,    NA,          \"PROSPECT\",   \"weight\",   87.5,  20.3,   \"Chiricozzi 2019\",      \"bsa\",     23, 16.79,   \"Chiricozzi 2019\",  \"durnpso\",  16.93, 10.82,   \"Chiricozzi 2019\",  \"prevsys\", 0.9061,    NA,   \"Chiricozzi 2019\",      \"psa\", 0.2152,    NA,   \"Chiricozzi 2019\",   \"weight\",   78.3, 15.87   ) %>%   # Tidy up   pivot_wider(id_cols = study,                names_from = covariate,                values_from = c(mean, sd),               names_glue = \"{covariate}_{.value}\") %>%    # Rescale as per analysis   transmute(study,             bsa_mean = bsa_mean / 100,              bsa_sd = bsa_sd / 100,             weight_mean = weight_mean / 10,             weight_sd = weight_sd / 10,             durnpso_mean = durnpso_mean / 10,             durnpso_sd = durnpso_sd / 10,             prevsys = prevsys_mean,             psa = psa_mean) (pso_releff_FE_new <- relative_effects(pso_fit_FE,                                         newdata = transmute(new_agd_means,                                                            study,                                                            bsa = bsa_mean,                                                            weight = weight_mean,                                                            durnpso = durnpso_mean,                                                            prevsys,                                                            psa),                                        study = study)) #> -------------------------------------------------------- Study: Chiricozzi 2019 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.69    0.91 0.23   7.83 0.22 #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Chiricozzi 2019: ETN]     1.79 0.11 1.59 1.72 1.79 1.86  2.01     2269     2766    1 #> d[Chiricozzi 2019: IXE_Q2W] 3.08 0.10 2.88 3.01 3.08 3.15  3.28     2520     2614    1 #> d[Chiricozzi 2019: IXE_Q4W] 2.86 0.10 2.65 2.79 2.86 2.93  3.07     2693     2604    1 #> d[Chiricozzi 2019: SEC_150] 2.36 0.11 2.14 2.28 2.36 2.43  2.58     2435     2679    1 #> d[Chiricozzi 2019: SEC_300] 2.77 0.11 2.55 2.69 2.77 2.84  2.99     2479     2858    1 #> d[Chiricozzi 2019: UST]     2.31 0.15 2.02 2.21 2.31 2.41  2.60     3003     2920    1 #>  #> --------------------------------------------------------------- Study: PROSPECT ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.96    0.91 0.19   8.75 0.2 #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[PROSPECT: ETN]     1.63 0.11 1.42 1.56 1.63 1.70  1.84     2256     2690    1 #> d[PROSPECT: IXE_Q2W] 2.94 0.10 2.74 2.87 2.94 3.01  3.14     2650     2950    1 #> d[PROSPECT: IXE_Q4W] 2.72 0.10 2.53 2.66 2.72 2.79  2.92     2829     2750    1 #> d[PROSPECT: SEC_150] 2.22 0.11 2.00 2.14 2.22 2.29  2.44     2590     3014    1 #> d[PROSPECT: SEC_300] 2.63 0.11 2.41 2.55 2.63 2.70  2.85     2679     2654    1 #> d[PROSPECT: UST]     2.18 0.15 1.90 2.08 2.18 2.29  2.48     3181     3182    1 #>  #> ---------------------------------------------------------------- Study: PsoBest ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.82    0.54 0.24    8.5 0.21 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[PsoBest: ETN]     1.61 0.08 1.46 1.56 1.61 1.66  1.77     2455     2879    1 #> d[PsoBest: IXE_Q2W] 2.93 0.08 2.78 2.88 2.93 2.98  3.09     2824     2943    1 #> d[PsoBest: IXE_Q4W] 2.71 0.08 2.56 2.66 2.71 2.77  2.87     3100     2982    1 #> d[PsoBest: SEC_150] 2.21 0.09 2.04 2.15 2.21 2.27  2.38     2533     2357    1 #> d[PsoBest: SEC_300] 2.62 0.09 2.45 2.56 2.62 2.67  2.79     2647     2672    1 #> d[PsoBest: UST]     2.08 0.14 1.82 1.99 2.08 2.17  2.35     3616     3150    1 plot(pso_releff_FE_new, ref_line = 0) + facet_wrap(\"Study\") new_agd_int <- add_integration(filter(new_agd_means, study != \"PsoBest\"),                                durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),                                prevsys = distr(qbern, prob = prevsys),                                bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),                                weight = distr(qgamma, mean = weight_mean, sd = weight_sd),                                psa = distr(qbern, prob = psa),                                n_int = 64,                                cor = pso_net$int_cor) (pso_pred_FE_new <- predict(pso_fit_FE,          type = \"response\",          newdata = new_agd_int,         study = study,         baseline = list(PROSPECT = distr(qbeta, 1156, 1509-1156),                         \"Chiricozzi 2019\" = distr(qbeta, 243, 330-243)),         baseline_type = \"response\",         baseline_level = \"aggregate\",         trt_ref = \"SEC_300\")) #> -------------------------------------------------------- Study: Chiricozzi 2019 ----  #>  #>                                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Chiricozzi 2019: PBO, PASI75]      0.02 0.01 0.01 0.01 0.02 0.02  0.03     2774     2898    1 #> pred[Chiricozzi 2019: PBO, PASI90]      0.00 0.00 0.00 0.00 0.00 0.00  0.01     2838     3324    1 #> pred[Chiricozzi 2019: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     2893     3086    1 #> pred[Chiricozzi 2019: ETN, PASI75]      0.37 0.04 0.29 0.35 0.37 0.40  0.46     4735     3515    1 #> pred[Chiricozzi 2019: ETN, PASI90]      0.16 0.03 0.11 0.14 0.16 0.18  0.22     4671     3820    1 #> pred[Chiricozzi 2019: ETN, PASI100]     0.03 0.01 0.02 0.03 0.03 0.04  0.05     4874     3910    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI75]  0.83 0.03 0.77 0.81 0.83 0.85  0.88     3937     4088    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI90]  0.60 0.04 0.52 0.57 0.60 0.63  0.69     3975     3974    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI100] 0.28 0.04 0.21 0.26 0.28 0.31  0.36     4029     3977    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI75]  0.77 0.03 0.69 0.74 0.77 0.79  0.83     4139     3729    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI90]  0.52 0.05 0.43 0.49 0.52 0.55  0.61     4171     4113    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI100] 0.22 0.03 0.16 0.19 0.22 0.24  0.29     4273     4046    1 #> pred[Chiricozzi 2019: SEC_150, PASI75]  0.59 0.04 0.51 0.57 0.59 0.62  0.66     4475     4038    1 #> pred[Chiricozzi 2019: SEC_150, PASI90]  0.33 0.04 0.26 0.30 0.33 0.35  0.40     4604     4025    1 #> pred[Chiricozzi 2019: SEC_150, PASI100] 0.10 0.02 0.07 0.09 0.10 0.11  0.14     4509     3701    1 #> pred[Chiricozzi 2019: SEC_300, PASI75]  0.74 0.02 0.68 0.72 0.74 0.75  0.78     3565     3798    1 #> pred[Chiricozzi 2019: SEC_300, PASI90]  0.48 0.03 0.42 0.46 0.48 0.50  0.54     3838     3636    1 #> pred[Chiricozzi 2019: SEC_300, PASI100] 0.19 0.02 0.15 0.17 0.19 0.20  0.23     3745     3395    1 #> pred[Chiricozzi 2019: UST, PASI75]      0.57 0.05 0.47 0.54 0.57 0.61  0.68     4619     3313    1 #> pred[Chiricozzi 2019: UST, PASI90]      0.32 0.05 0.23 0.28 0.32 0.35  0.42     4616     3415    1 #> pred[Chiricozzi 2019: UST, PASI100]     0.10 0.02 0.06 0.08 0.10 0.11  0.15     4635     3362    1 #>  #> --------------------------------------------------------------- Study: PROSPECT ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[PROSPECT: PBO, PASI75]      0.03 0.01 0.02 0.03 0.03 0.04  0.05     2934     2914    1 #> pred[PROSPECT: PBO, PASI90]      0.01 0.00 0.00 0.00 0.01 0.01  0.01     2952     2943    1 #> pred[PROSPECT: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3041     3053    1 #> pred[PROSPECT: ETN, PASI75]      0.40 0.04 0.33 0.38 0.40 0.43  0.47     5801     3330    1 #> pred[PROSPECT: ETN, PASI90]      0.18 0.02 0.14 0.16 0.18 0.20  0.23     5572     3383    1 #> pred[PROSPECT: ETN, PASI100]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     5504     3323    1 #> pred[PROSPECT: IXE_Q2W, PASI75]  0.85 0.02 0.81 0.84 0.85 0.86  0.89     5040     3313    1 #> pred[PROSPECT: IXE_Q2W, PASI90]  0.64 0.03 0.57 0.62 0.64 0.66  0.70     5008     3529    1 #> pred[PROSPECT: IXE_Q2W, PASI100] 0.32 0.03 0.26 0.30 0.32 0.34  0.38     5095     3461    1 #> pred[PROSPECT: IXE_Q4W, PASI75]  0.79 0.03 0.74 0.78 0.79 0.81  0.84     5273     3203    1 #> pred[PROSPECT: IXE_Q4W, PASI90]  0.56 0.04 0.49 0.53 0.56 0.58  0.63     5255     3293    1 #> pred[PROSPECT: IXE_Q4W, PASI100] 0.25 0.03 0.19 0.23 0.24 0.27  0.31     5121     3195    1 #> pred[PROSPECT: SEC_150, PASI75]  0.63 0.03 0.57 0.61 0.63 0.64  0.68     6002     3692    1 #> pred[PROSPECT: SEC_150, PASI90]  0.36 0.03 0.31 0.34 0.36 0.38  0.42     5902     3841    1 #> pred[PROSPECT: SEC_150, PASI100] 0.12 0.01 0.09 0.11 0.12 0.13  0.15     5461     3642    1 #> pred[PROSPECT: SEC_300, PASI75]  0.77 0.01 0.74 0.76 0.77 0.77  0.79     3985     3918    1 #> pred[PROSPECT: SEC_300, PASI90]  0.52 0.02 0.49 0.51 0.52 0.53  0.55     4033     3889    1 #> pred[PROSPECT: SEC_300, PASI100] 0.22 0.01 0.19 0.21 0.22 0.22  0.24     3920     3878    1 #> pred[PROSPECT: UST, PASI75]      0.61 0.05 0.52 0.58 0.62 0.65  0.70     5757     3516    1 #> pred[PROSPECT: UST, PASI90]      0.36 0.05 0.27 0.32 0.35 0.39  0.45     5644     3496    1 #> pred[PROSPECT: UST, PASI100]     0.12 0.02 0.07 0.10 0.12 0.13  0.17     5586     3549    1 plot(pso_pred_FE_new, ref_line = c(0, 1)) +    facet_grid(rows = \"Study\") +    aes(colour = Category) +   scale_colour_brewer(palette = \"Blues\")"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Smoking cessation","text":"begin setting network. arm-level count data giving number quitting smoking (r) total (n) arm, use function set_agd_arm(). Treatment “intervention” set network reference treatment. Plot network structure.","code":"smknet <- set_agd_arm(smoking,                        study = studyn,                       trt = trtc,                       r = r,                        n = n,                       trt_ref = \"No intervention\") smknet #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected plot(smknet, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"random-effects-nma","dir":"Articles","previous_headings":"","what":"Random effects NMA","title":"Example: Smoking cessation","text":"Following TSD 4, fit random effects NMA model, using nma() function trt_effects = \"random\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), \\(\\textrm{half-N}(5^2)\\) prior distribution -study heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  default, displays model parameters given prior distributions (case \\(d_k\\), \\(\\mu_j\\), \\(\\tau\\)), may changed using prior argument:  Model fit can checked using dic() function residual deviance contributions examined corresponding plot() method  Overall model fit seems adequate, almost points showing good fit (mean residual deviance contribution 1). two points higher residual deviance (.e. worse fit) correspond two zero counts data:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. smkfit <- nma(smknet,                trt_effects = \"random\",               prior_intercept = normal(scale = 100),               prior_trt = normal(scale = 100),               prior_het = normal(scale = 5)) smkfit #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50%      75%    97.5% #> d[Group counselling]          1.10    0.01 0.45     0.25     0.81     1.09     1.40     2.03 #> d[Individual counselling]     0.84    0.01 0.24     0.38     0.69     0.83     1.00     1.34 #> d[Self-help]                  0.49    0.01 0.41    -0.30     0.22     0.48     0.75     1.32 #> lp__                      -5768.02    0.20 6.53 -5781.73 -5772.34 -5767.76 -5763.32 -5756.36 #> tau                           0.84    0.01 0.19     0.54     0.70     0.81     0.94     1.28 #>                           n_eff Rhat #> d[Group counselling]       1849 1.00 #> d[Individual counselling]  1070 1.00 #> d[Self-help]               1588 1.00 #> lp__                       1062 1.01 #> tau                        1201 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:45:09 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(smkfit, pars = c(\"d\", \"tau\", \"mu\", \"delta\")) plot_prior_posterior(smkfit) plot_prior_posterior(smkfit, prior = \"het\") (dic_consistency <- dic(smkfit)) #> Residual deviance: 53.8 (on 50 data points) #>                pD: 43.6 #>               DIC: 97.4 plot(dic_consistency) smoking[smoking$r == 0, ] #>    studyn trtn            trtc r  n #> 13      6    1 No intervention 0 33 #> 31     15    1 No intervention 0 20"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"checking-for-inconsistency","dir":"Articles","previous_headings":"","what":"Checking for inconsistency","title":"Example: Smoking cessation","text":"Note: results inconsistency models slightly different Dias et al. (2010, 2011), although overall conclusions . due presence multi-arm trials different ordering treatments, meaning inconsistency parameterised differently within multi-arm trials. results Dias et al. obtained network instead set trtn treatment variable.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"unrelated-mean-effects","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Unrelated mean effects","title":"Example: Smoking cessation","text":"first fit unrelated mean effects (UME) model (Dias et al. 2011) assess consistency assumption. , use function nma(), now argument consistency = \"ume\". Comparing model fit statistics see little choose two models. However, also important examine individual contributions model fit data point two models (-called “dev-dev” plot). Passing two nma_dic objects produced dic() function plot() method produces dev-dev plot:  points lie roughly line equality, evidence inconsistency .","code":"smkfit_ume <- nma(smknet,                    consistency = \"ume\",                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = normal(scale = 5)) smkfit_ume #> A random effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                     mean se_mean   sd     2.5%      25% #> d[Group counselling vs. No intervention]            1.15    0.02 0.81    -0.34     0.61 #> d[Individual counselling vs. No intervention]       0.91    0.01 0.29     0.36     0.73 #> d[Self-help vs. No intervention]                    0.33    0.01 0.59    -0.84    -0.05 #> d[Individual counselling vs. Group counselling]    -0.30    0.01 0.61    -1.48    -0.69 #> d[Self-help vs. Group counselling]                 -0.62    0.02 0.71    -2.04    -1.08 #> d[Self-help vs. Individual counselling]             0.19    0.02 1.02    -1.85    -0.46 #> lp__                                            -5765.34    0.19 6.25 -5778.16 -5769.49 #> tau                                                 0.94    0.01 0.23     0.60     0.78 #>                                                      50%      75%    97.5% n_eff Rhat #> d[Group counselling vs. No intervention]            1.12     1.64     2.88  2208 1.00 #> d[Individual counselling vs. No intervention]       0.90     1.08     1.49   832 1.00 #> d[Self-help vs. No intervention]                    0.33     0.70     1.49  1610 1.00 #> d[Individual counselling vs. Group counselling]    -0.30     0.09     0.92  2291 1.00 #> d[Self-help vs. Group counselling]                 -0.61    -0.17     0.78  2143 1.00 #> d[Self-help vs. Individual counselling]             0.17     0.85     2.20  3331 1.00 #> lp__                                            -5765.12 -5761.02 -5753.68  1058 1.01 #> tau                                                 0.90     1.06     1.48   941 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:45:21 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). dic_consistency #> Residual deviance: 53.8 (on 50 data points) #>                pD: 43.6 #>               DIC: 97.4 (dic_ume <- dic(smkfit_ume)) #> Residual deviance: 53.9 (on 50 data points) #>                pD: 45.3 #>               DIC: 99.2 plot(dic_consistency, dic_ume, point_alpha = 0.5, interval_alpha = 0.2)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"node-splitting","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Node-splitting","title":"Example: Smoking cessation","text":"Another method assessing inconsistency node-splitting (Dias et al. 2011, 2010). Whereas UME model assesses inconsistency globally, node-splitting assesses inconsistency locally potentially inconsistent comparison (direct indirect evidence) turn. Node-splitting can performed using nma() function argument consistency = \"nodesplit\". default, possible comparisons split (determined get_nodesplits() function). Alternatively, specific comparison comparisons split can provided nodesplit argument. summary() method summarises node-splitting results, displaying direct indirect estimates \\(d_\\mathrm{dir}\\) \\(d_\\mathrm{ind}\\) node-split model, network estimate \\(d_\\mathrm{net}\\) consistency model, inconsistency factor \\(\\omega = d_\\mathrm{dir} - d_\\mathrm{ind}\\), Bayesian \\(p\\)-value inconsistency comparison. Since random effects models fitted, heterogeneity standard deviation \\(\\tau\\) node-split model consistency model also displayed. DIC model fit statistics also provided. DIC inconsistency model unchanged consistency model, node-splits result reduced heterogeneity standard deviation \\(\\tau\\) compared consistency model, Bayesian \\(p\\)-values large. evidence inconsistency. can visually compare posterior distributions direct, indirect, network estimates using plot() method. agreement; posterior densities direct indirect estimates overlap. Notice much indirect information Individual counselling vs. intervention comparison, network (consistency) estimate similar direct estimate comparison.","code":"smk_nodesplit <- nma(smknet,                       consistency = \"nodesplit\",                      trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = normal(scale = 5)) #> Fitting model 1 of 7, node-split: Group counselling vs. No intervention #> Fitting model 2 of 7, node-split: Individual counselling vs. No intervention #> Fitting model 3 of 7, node-split: Self-help vs. No intervention #> Fitting model 4 of 7, node-split: Individual counselling vs. Group counselling #> Fitting model 5 of 7, node-split: Self-help vs. Group counselling #> Fitting model 6 of 7, node-split: Self-help vs. Individual counselling #> Fitting model 7 of 7, consistency model summary(smk_nodesplit) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.12 0.43  0.31  0.82  1.11 1.40  1.99     1817     2223    1 #> d_dir            1.05 0.76 -0.40  0.55  1.03 1.53  2.59     3037     2732    1 #> d_ind            1.14 0.55  0.06  0.77  1.14 1.52  2.22     1605     2456    1 #> omega           -0.09 0.90 -1.84 -0.67 -0.10 0.48  1.69     2239     2505    1 #> tau              0.87 0.20  0.55  0.73  0.84 0.98  1.31     1200     1825    1 #> tau_consistency  0.83 0.18  0.54  0.70  0.81 0.94  1.25     1194     2075    1 #>  #> Residual deviance: 54.3 (on 50 data points) #>                pD: 44.5 #>               DIC: 98.9 #>  #> Bayesian p-value: 0.91 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.85 0.24  0.41  0.69 0.84 1.00  1.34     1290     1875    1 #> d_dir           0.88 0.25  0.40  0.71 0.88 1.05  1.42     1715     2700    1 #> d_ind           0.58 0.69 -0.74  0.12 0.56 1.02  2.00     1686     2346    1 #> omega           0.30 0.72 -1.11 -0.17 0.30 0.77  1.71     1573     2265    1 #> tau             0.86 0.19  0.56  0.72 0.84 0.97  1.29     1167     2121    1 #> tau_consistency 0.83 0.18  0.54  0.70 0.81 0.94  1.25     1194     2075    1 #>  #> Residual deviance: 54.3 (on 50 data points) #>                pD: 44.2 #>               DIC: 98.5 #>  #> Bayesian p-value: 0.67 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.50 0.39 -0.24  0.24  0.50 0.76  1.27     1836     2291    1 #> d_dir            0.35 0.55 -0.73  0.00  0.35 0.70  1.45     2620     2373    1 #> d_ind            0.72 0.64 -0.47  0.30  0.70 1.12  2.04     1523     2162    1 #> omega           -0.37 0.84 -2.01 -0.91 -0.36 0.18  1.29     1891     2589    1 #> tau              0.88 0.19  0.57  0.74  0.85 0.99  1.31     1120     2009    1 #> tau_consistency  0.83 0.18  0.54  0.70  0.81 0.94  1.25     1194     2075    1 #>  #> Residual deviance: 53.8 (on 50 data points) #>                pD: 44.2 #>               DIC: 98.1 #>  #> Bayesian p-value: 0.65 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.27 0.41 -1.08 -0.54 -0.27  0.00  0.54     2150     2168    1 #> d_dir           -0.12 0.48 -1.10 -0.43 -0.12  0.19  0.85     3938     3227    1 #> d_ind           -0.55 0.61 -1.78 -0.94 -0.55 -0.16  0.71     1413     1780    1 #> omega            0.43 0.68 -0.92  0.00  0.43  0.88  1.76     1595     2088    1 #> tau              0.87 0.19  0.56  0.73  0.84  0.98  1.31     1111     1947    1 #> tau_consistency  0.83 0.18  0.54  0.70  0.81  0.94  1.25     1194     2075    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44.1 #>               DIC: 97.7 #>  #> Bayesian p-value: 0.5 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.62 0.48 -1.56 -0.93 -0.61 -0.30  0.32     2771     3003    1 #> d_dir           -0.60 0.68 -1.95 -1.03 -0.58 -0.15  0.71     3748     3157    1 #> d_ind           -0.63 0.66 -1.92 -1.05 -0.63 -0.19  0.68     1715     2490    1 #> omega            0.03 0.89 -1.69 -0.56  0.02  0.61  1.87     2103     2576    1 #> tau              0.88 0.20  0.56  0.73  0.85  0.99  1.32      953     1945    1 #> tau_consistency  0.83 0.18  0.54  0.70  0.81  0.94  1.25     1194     2075    1 #>  #> Residual deviance: 53.7 (on 50 data points) #>                pD: 44.1 #>               DIC: 97.7 #>  #> Bayesian p-value: 0.98 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.35 0.40 -1.15 -0.61 -0.35 -0.08  0.46     2236     2245 1.00 #> d_dir            0.06 0.66 -1.19 -0.37  0.06  0.49  1.38     3127     2762 1.00 #> d_ind           -0.62 0.53 -1.69 -0.97 -0.61 -0.28  0.47     1602     2031 1.00 #> omega            0.68 0.83 -0.97  0.16  0.68  1.23  2.29     1940     2175 1.00 #> tau              0.87 0.20  0.55  0.73  0.84  0.97  1.34      940     1924 1.01 #> tau_consistency  0.83 0.18  0.54  0.70  0.81  0.94  1.25     1194     2075 1.00 #>  #> Residual deviance: 53.9 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.2 #>  #> Bayesian p-value: 0.39 plot(smk_nodesplit) +   ggplot2::theme(legend.position = \"bottom\", legend.direct = \"horizontal\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Smoking cessation","text":"Pairwise relative effects, pairwise contrasts all_contrasts = TRUE.  Treatment rankings, rank probabilities, cumulative rank probabilities. set lower_better = FALSE since higher log odds cessation better (outcome positive).","code":"(smk_releff <- relative_effects(smkfit, all_contrasts = TRUE)) #>                                                  mean   sd  2.5%   25%   50%   75% 97.5% #> d[Group counselling vs. No intervention]         1.10 0.45  0.25  0.81  1.09  1.40  2.03 #> d[Individual counselling vs. No intervention]    0.84 0.24  0.38  0.69  0.83  1.00  1.34 #> d[Self-help vs. No intervention]                 0.49 0.41 -0.30  0.22  0.48  0.75  1.32 #> d[Individual counselling vs. Group counselling] -0.26 0.42 -1.10 -0.54 -0.25  0.01  0.58 #> d[Self-help vs. Group counselling]              -0.61 0.49 -1.58 -0.93 -0.61 -0.29  0.33 #> d[Self-help vs. Individual counselling]         -0.36 0.41 -1.15 -0.62 -0.37 -0.09  0.46 #>                                                 Bulk_ESS Tail_ESS Rhat #> d[Group counselling vs. No intervention]            1894     2362    1 #> d[Individual counselling vs. No intervention]       1059     1714    1 #> d[Self-help vs. No intervention]                    1604     1956    1 #> d[Individual counselling vs. Group counselling]     2468     2412    1 #> d[Self-help vs. Group counselling]                  2562     2111    1 #> d[Self-help vs. Individual counselling]             1940     2167    1 plot(smk_releff, ref_line = 0) (smk_ranks <- posterior_ranks(smkfit, lower_better = FALSE)) #>                              mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[No intervention]        3.89 0.33    3   4   4   4     4     2146       NA    1 #> rank[Group counselling]      1.37 0.62    1   1   1   2     3     3053     2870    1 #> rank[Individual counselling] 1.92 0.63    1   2   2   2     3     2387       NA    1 #> rank[Self-help]              2.83 0.67    1   3   3   3     4     2232       NA    1 plot(smk_ranks) (smk_rankprobs <- posterior_rank_probs(smkfit, lower_better = FALSE)) #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.11      0.89 #> d[Group counselling]           0.70      0.23      0.06      0.01 #> d[Individual counselling]      0.24      0.59      0.16      0.00 #> d[Self-help]                   0.05      0.18      0.67      0.10 plot(smk_rankprobs) (smk_cumrankprobs <- posterior_rank_probs(smkfit, lower_better = FALSE, cumulative = TRUE)) #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.11         1 #> d[Group counselling]           0.70      0.93      0.99         1 #> d[Individual counselling]      0.24      0.84      1.00         1 #> d[Self-help]                   0.05      0.23      0.90         1 plot(smk_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Statins for cholesterol lowering","text":"data giving number deaths (r) total (n) arm, use function set_agd_arm() set network. set placebo network reference treatment. prevention variable statins data frame automatically available use meta-regression model.","code":"statin_net <- set_agd_arm(statins,                            study = studyc,                           trt = trtc,                           r = r,                            n = n,                           trt_ref = \"Placebo\") statin_net #> A network with 19 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study     Treatment arms      #>  4S        2: Placebo | Statin #>  Bestehorn 2: Placebo | Statin #>  Brown     2: Placebo | Statin #>  CCAIT     2: Placebo | Statin #>  Downs     2: Placebo | Statin #>  EXCEL     2: Placebo | Statin #>  Furberg   2: Placebo | Statin #>  Haskell   2: Placebo | Statin #>  Jones     2: Placebo | Statin #>  KAPS      2: Placebo | Statin #>  ... plus 9 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 19 #> Reference treatment is: Placebo #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Statins for cholesterol lowering","text":"fit fixed effect (FE) random effects (RE) models, meta-regression binary covariate prevention.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"fixed-effect-meta-regression","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-regression","title":"Example: Statins for cholesterol lowering","text":"start fitting FE model. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Statin}\\), study-specific intercepts \\(\\mu_j\\), regression coefficient \\(\\beta\\). can examine range parameter values implied prior distributions summary() method: model fitted nma() function, fixed effect model specified trt_effects = \"fixed\". regression formula ~ .trt:prevention means interaction primary/secondary prevention treatment included; .trt special variable indicates treatment, prevention original data set. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. statin_fit_FE <- nma(statin_net,                       trt_effects = \"fixed\",                      regression = ~.trt:prevention,                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_reg = normal(scale = 100)) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. statin_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:prevention. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                          mean se_mean   sd     2.5%      25%      50%      75% #> beta[.trtStatin:preventionSecondary]    -0.21    0.00 0.11    -0.42    -0.28    -0.21    -0.13 #> d[Statin]                               -0.10    0.00 0.10    -0.29    -0.17    -0.10    -0.04 #> lp__                                 -7246.68    0.09 3.36 -7254.23 -7248.77 -7246.37 -7244.25 #>                                         97.5% n_eff Rhat #> beta[.trtStatin:preventionSecondary]     0.02  2104    1 #> d[Statin]                                0.09  1976    1 #> lp__                                 -7241.16  1298    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:46:27 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(statin_fit_FE, pars = c(\"d\", \"beta\", \"mu\")) plot_prior_posterior(statin_fit_FE, prior = c(\"trt\", \"reg\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"random-effects-meta-regression","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-regression","title":"Example: Statins for cholesterol lowering","text":"now fit RE model. use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effect \\(d_\\mathrm{Statin}\\), study-specific intercepts \\(\\mu_j\\), regression coefficient \\(\\beta\\). use \\(\\textrm{half-N}(0, 5^2)\\) prior distribution heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: , model fitted nma() function, now trt_effects = \"random\". increase adapt_delta 0.99 remove small number divergent transition errors (default RE models set 0.95). Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. statin_fit_RE <- nma(statin_net,                       trt_effects = \"random\",                      regression = ~.trt:prevention,                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_reg = normal(scale = 100),                      prior_het = half_normal(scale = 5),                      adapt_delta = 0.99) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. statin_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:prevention. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                          mean se_mean   sd     2.5%      25%      50%      75% #> beta[.trtStatin:preventionSecondary]    -0.27    0.01 0.27    -0.83    -0.41    -0.27    -0.13 #> d[Statin]                               -0.09    0.01 0.23    -0.59    -0.19    -0.08     0.03 #> lp__                                 -7255.79    0.17 5.42 -7267.39 -7259.34 -7255.51 -7251.98 #> tau                                      0.25    0.01 0.22     0.01     0.09     0.19     0.34 #>                                         97.5% n_eff Rhat #> beta[.trtStatin:preventionSecondary]     0.27  1146 1.00 #> d[Statin]                                0.33  1049 1.00 #> lp__                                 -7246.00   998 1.00 #> tau                                      0.79   671 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:46:35 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(statin_fit_RE, pars = c(\"d\", \"beta\", \"mu\", \"delta\")) plot_prior_posterior(statin_fit_RE, prior = c(\"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: Statins for cholesterol lowering","text":"Model fit can checked using dic() function: DIC similar FE RE models, might choose FE model based parsimony. residual deviance statistics larger number data points, suggesting data points fit well. can also examine residual deviance contributions corresponding plot() method.   number studies fit well either model, posterior mean residual deviance contributions greater 1, investigated see substantive differences studies.","code":"(statin_dic_FE <- dic(statin_fit_FE)) #> Residual deviance: 46 (on 38 data points) #>                pD: 21.7 #>               DIC: 67.7 (statin_dic_RE <- dic(statin_fit_RE)) #> Residual deviance: 42.5 (on 38 data points) #>                pD: 25.1 #>               DIC: 67.6 plot(statin_dic_FE) plot(statin_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Statins for cholesterol lowering","text":"can produce estimates relative effect statins vs. placebo either primary secondary prevention, using relative_effects() function. newdata argument specifies data frame containing levels covariate prevention interested , study argument used specify column newdata informative label. plot() method may used visually compare estimates:  Model parameters may plotted corresponding plot() method:  Whilst 95% Credible Interval includes zero, suggestion statins effective secondary prevention.","code":"statin_releff_FE <- relative_effects(statin_fit_FE,                                      newdata = data.frame(prevention = c(\"Primary\", \"Secondary\")),                                      study = prevention)  statin_releff_FE #> ---------------------------------------------------------------- Study: Primary ----  #>  #> Covariate values: #>  prevention #>     Primary #>  #>                    mean  sd  2.5%   25%  50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Primary: Statin] -0.1 0.1 -0.29 -0.17 -0.1 -0.04  0.09     2018     2707    1 #>  #> -------------------------------------------------------------- Study: Secondary ----  #>  #> Covariate values: #>  prevention #>   Secondary #>  #>                       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Secondary: Statin] -0.31 0.05 -0.41 -0.35 -0.31 -0.28 -0.21     4284     3413    1 plot(statin_releff_FE,       ref_line = 0) plot(statin_fit_FE,       pars = \"beta\",       ref_line = 0,      stat = \"halfeye\")"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Thrombolytic treatments","text":"begin setting network. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). default, SK set network reference treatment. Plot network structure.","code":"thrombo_net <- set_agd_arm(thrombolytics,                             study = studyn,                            trt = trtc,                            r = r,                             n = n) thrombo_net #> A network with 50 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms               #>  1     3: SK | Acc t-PA | SK + t-PA #>  2     2: SK | t-PA                 #>  3     2: SK | t-PA                 #>  4     2: SK | t-PA                 #>  5     2: SK | t-PA                 #>  6     3: SK | ASPAC | t-PA         #>  7     2: SK | t-PA                 #>  8     2: SK | t-PA                 #>  9     2: SK | t-PA                 #>  10    2: SK | SK + t-PA            #>  ... plus 40 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 9 #> Total number of studies: 50 #> Reference treatment is: SK #> Network is connected plot(thrombo_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"fixed-effects-nma","dir":"Articles","previous_headings":"","what":"Fixed effects NMA","title":"Example: Thrombolytic treatments","text":"Following TSD 4 (Dias et al. 2011), fit fixed effects NMA model, using nma() function trt_effects = \"fixed\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\). can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Model fit can checked using dic() function residual deviance contributions examined corresponding plot() method.  number points well fit model, posterior mean residual deviance contributions greater 1.","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. thrombo_fit <- nma(thrombo_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) #> Note: Setting \"SK\" as the network reference treatment. thrombo_fit #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd      2.5%       25%       50%       75%     97.5% n_eff #> d[Acc t-PA]      -0.18    0.00 0.04     -0.26     -0.21     -0.18     -0.15     -0.09  2695 #> d[ASPAC]          0.02    0.00 0.04     -0.06     -0.01      0.01      0.04      0.09  5508 #> d[PTCA]          -0.47    0.00 0.10     -0.66     -0.54     -0.48     -0.41     -0.28  3964 #> d[r-PA]          -0.12    0.00 0.06     -0.24     -0.16     -0.12     -0.08     -0.01  3775 #> d[SK + t-PA]     -0.05    0.00 0.05     -0.14     -0.08     -0.05     -0.02      0.04  5197 #> d[t-PA]           0.00    0.00 0.03     -0.06     -0.02      0.00      0.02      0.06  5025 #> d[TNK]           -0.17    0.00 0.08     -0.32     -0.23     -0.17     -0.12     -0.01  4096 #> d[UK]            -0.20    0.00 0.22     -0.63     -0.35     -0.20     -0.06      0.23  4649 #> lp__         -43042.91    0.15 5.47 -43054.47 -43046.36 -43042.64 -43038.96 -43033.21  1415 #>              Rhat #> d[Acc t-PA]     1 #> d[ASPAC]        1 #> d[PTCA]         1 #> d[r-PA]         1 #> d[SK + t-PA]    1 #> d[t-PA]         1 #> d[TNK]          1 #> d[UK]           1 #> lp__            1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:46:50 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(thrombo_fit, pars = c(\"d\", \"mu\")) plot_prior_posterior(thrombo_fit, prior = \"trt\") (dic_consistency <- dic(thrombo_fit)) #> Residual deviance: 106 (on 102 data points) #>                pD: 58.8 #>               DIC: 164.8 plot(dic_consistency)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"checking-for-inconsistency","dir":"Articles","previous_headings":"","what":"Checking for inconsistency","title":"Example: Thrombolytic treatments","text":"Note: results inconsistency models slightly different Dias et al. (2010, 2011), although overall conclusions . due presence multi-arm trials different ordering treatments, meaning inconsistency parameterised differently within multi-arm trials. results Dias et al. obtained network instead set trtn treatment variable.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"unrelated-mean-effects-model","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Unrelated mean effects model","title":"Example: Thrombolytic treatments","text":"first fit unrelated mean effects (UME) model (Dias et al. 2011) assess consistency assumption. , use function nma(), now argument consistency = \"ume\". Comparing model fit statistics Whilst UME model fits data better, lower residual deviance, additional parameters UME model mean DIC similar models. However, also important examine individual contributions model fit data point two models (-called “dev-dev” plot). Passing two nma_dic objects produced dic() function plot() method produces dev-dev plot:  four points lying lower right corner plot much lower posterior mean residual deviance UME model, indicating data potentially inconsistent. points correspond trials 44 45, two trials comparing Acc t-PA ASPAC. ASPAC vs. Acc t-PA estimates different consistency model inconsistency (UME) model, suggesting two trials may systematically different others network.","code":"thrombo_fit_ume <- nma(thrombo_net,                         consistency = \"ume\",                        trt_effects = \"fixed\",                        prior_intercept = normal(scale = 100),                        prior_trt = normal(scale = 100)) #> Note: Setting \"SK\" as the network reference treatment. thrombo_fit_ume #> A fixed effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                            mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[Acc t-PA vs. SK]        -0.16    0.00 0.05     -0.25     -0.19     -0.16     -0.12     -0.06 #> d[ASPAC vs. SK]            0.00    0.00 0.04     -0.07     -0.02      0.00      0.03      0.08 #> d[PTCA vs. SK]            -0.66    0.00 0.18     -1.02     -0.78     -0.66     -0.54     -0.31 #> d[r-PA vs. SK]            -0.06    0.00 0.09     -0.24     -0.12     -0.06      0.00      0.11 #> d[SK + t-PA vs. SK]       -0.04    0.00 0.05     -0.14     -0.08     -0.04     -0.01      0.05 #> d[t-PA vs. SK]             0.00    0.00 0.03     -0.06     -0.02      0.00      0.02      0.06 #> d[UK vs. SK]              -0.38    0.01 0.52     -1.44     -0.72     -0.37     -0.03      0.63 #> d[ASPAC vs. Acc t-PA]      1.41    0.01 0.42      0.61      1.12      1.39      1.68      2.28 #> d[PTCA vs. Acc t-PA]      -0.22    0.00 0.12     -0.46     -0.30     -0.22     -0.13      0.02 #> d[r-PA vs. Acc t-PA]       0.02    0.00 0.07     -0.11     -0.02      0.02      0.06      0.15 #> d[TNK vs. Acc t-PA]        0.01    0.00 0.06     -0.12     -0.04      0.01      0.05      0.13 #> d[UK vs. Acc t-PA]         0.14    0.01 0.36     -0.56     -0.10      0.13      0.39      0.86 #> d[t-PA vs. ASPAC]          0.29    0.01 0.36     -0.39      0.04      0.28      0.53      0.99 #> d[t-PA vs. PTCA]           0.54    0.01 0.41     -0.26      0.26      0.54      0.80      1.37 #> d[UK vs. t-PA]            -0.30    0.00 0.34     -0.97     -0.52     -0.30     -0.06      0.35 #> lp__                  -43039.93    0.14 5.87 -43052.55 -43043.72 -43039.54 -43035.81 -43029.53 #>                       n_eff Rhat #> d[Acc t-PA vs. SK]     5077    1 #> d[ASPAC vs. SK]        5368    1 #> d[PTCA vs. SK]         5189    1 #> d[r-PA vs. SK]         5481    1 #> d[SK + t-PA vs. SK]    5665    1 #> d[t-PA vs. SK]         4675    1 #> d[UK vs. SK]           6376    1 #> d[ASPAC vs. Acc t-PA]  3473    1 #> d[PTCA vs. Acc t-PA]   4794    1 #> d[r-PA vs. Acc t-PA]   5178    1 #> d[TNK vs. Acc t-PA]    5889    1 #> d[UK vs. Acc t-PA]     4520    1 #> d[t-PA vs. ASPAC]      4623    1 #> d[t-PA vs. PTCA]       4104    1 #> d[UK vs. t-PA]         5918    1 #> lp__                   1740    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:47:00 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). dic_consistency #> Residual deviance: 106 (on 102 data points) #>                pD: 58.8 #>               DIC: 164.8 (dic_ume <- dic(thrombo_fit_ume)) #> Residual deviance: 100 (on 102 data points) #>                pD: 66.3 #>               DIC: 166.3 plot(dic_consistency, dic_ume, show_uncertainty = FALSE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"node-splitting","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Node-splitting","title":"Example: Thrombolytic treatments","text":"Another method assessing inconsistency node-splitting (Dias et al. 2011, 2010). Whereas UME model assesses inconsistency globally, node-splitting assesses inconsistency locally potentially inconsistent comparison (direct indirect evidence) turn. Node-splitting can performed using nma() function argument consistency = \"nodesplit\". default, possible comparisons split (determined get_nodesplits() function). Alternatively, specific comparison comparisons split can provided nodesplit argument. summary() method summarises node-splitting results, displaying direct indirect estimates \\(d_\\mathrm{dir}\\) \\(d_\\mathrm{ind}\\) node-split model, network estimate \\(d_\\mathrm{net}\\) consistency model, inconsistency factor \\(\\omega = d_\\mathrm{dir} - d_\\mathrm{ind}\\), Bayesian \\(p\\)-value inconsistency comparison. DIC model fit statistics also provided. (random effects model fitted, heterogeneity standard deviation \\(\\tau\\) node-split model consistency model also displayed.) Node-splitting ASPAC vs. Acc t-PA comparison results lowest DIC, lower consistency model. posterior distribution inconsistency factor \\(\\omega\\) comparison lies far 0 Bayesian \\(p\\)-value inconsistency small (< 0.01), meaning substantial disagreement direct indirect evidence comparison. can visually compare direct, indirect, network estimates using plot() method.  can also plot posterior distributions inconsistency factors \\(\\omega\\), using plot() method. , specify “halfeye” plot posterior density median credible intervals, customise plot layout standard ggplot2 functions.  Notice posterior distribution inconsistency factor ASPAC vs. Acc t-PA comparison lies far 0, indicating substantial inconsistency direct indirect evidence comparison.","code":"thrombo_nodesplit <- nma(thrombo_net,                           consistency = \"nodesplit\",                          trt_effects = \"fixed\",                          prior_intercept = normal(scale = 100),                          prior_trt = normal(scale = 100)) #> Fitting model 1 of 15, node-split: Acc t-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 2 of 15, node-split: ASPAC vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 3 of 15, node-split: PTCA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 4 of 15, node-split: r-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 5 of 15, node-split: t-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 6 of 15, node-split: UK vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 7 of 15, node-split: ASPAC vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 8 of 15, node-split: PTCA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 9 of 15, node-split: r-PA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 10 of 15, node-split: SK + t-PA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 11 of 15, node-split: UK vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 12 of 15, node-split: t-PA vs. ASPAC #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 13 of 15, node-split: t-PA vs. PTCA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 14 of 15, node-split: UK vs. t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 15 of 15, consistency model #> Note: Setting \"SK\" as the network reference treatment. summary(thrombo_nodesplit) #> Node-splitting models fitted for 14 comparisons. #>  #> ---------------------------------------------------- Node-split Acc t-PA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.18 0.04 -0.26 -0.21 -0.18 -0.15 -0.10     2640     3059 1.00 #> d_dir -0.16 0.05 -0.25 -0.19 -0.16 -0.13 -0.06     4306     3693 1.00 #> d_ind -0.25 0.09 -0.45 -0.32 -0.25 -0.19 -0.08      608      921 1.01 #> omega  0.10 0.10 -0.10  0.02  0.09  0.17  0.30      704     1086 1.01 #>  #> Residual deviance: 106.8 (on 102 data points) #>                pD: 60.3 #>               DIC: 167.2 #>  #> Bayesian p-value: 0.35 #>  #> ------------------------------------------------------- Node-split ASPAC vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.02 0.04 -0.06 -0.01  0.02  0.04  0.09     5133     3493    1 #> d_dir  0.01 0.04 -0.07 -0.02  0.01  0.03  0.08     4928     3412    1 #> d_ind  0.42 0.25 -0.05  0.25  0.42  0.59  0.95     2370     2551    1 #> omega -0.42 0.25 -0.94 -0.58 -0.41 -0.24  0.06     2412     2485    1 #>  #> Residual deviance: 104.2 (on 102 data points) #>                pD: 59.6 #>               DIC: 163.8 #>  #> Bayesian p-value: 0.093 #>  #> -------------------------------------------------------- Node-split PTCA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.48 0.10 -0.67 -0.55 -0.48 -0.41 -0.28     4206     3699    1 #> d_dir -0.66 0.18 -1.02 -0.79 -0.66 -0.54 -0.31     5211     3413    1 #> d_ind -0.39 0.12 -0.62 -0.47 -0.39 -0.31 -0.16     3251     3242    1 #> omega -0.27 0.21 -0.70 -0.42 -0.27 -0.12  0.15     4172     3451    1 #>  #> Residual deviance: 105.2 (on 102 data points) #>                pD: 59.5 #>               DIC: 164.7 #>  #> Bayesian p-value: 0.2 #>  #> -------------------------------------------------------- Node-split r-PA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.12 0.06 -0.24 -0.16 -0.12 -0.08 -0.01     3637     3150    1 #> d_dir -0.06 0.09 -0.23 -0.12 -0.06  0.00  0.12     5536     2910    1 #> d_ind -0.17 0.08 -0.33 -0.23 -0.17 -0.12 -0.02     2313     3212    1 #> omega  0.12 0.12 -0.12  0.04  0.12  0.19  0.35     3238     3107    1 #>  #> Residual deviance: 106 (on 102 data points) #>                pD: 59.7 #>               DIC: 165.7 #>  #> Bayesian p-value: 0.33 #>  #> -------------------------------------------------------- Node-split t-PA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.00 0.03 -0.06 -0.02  0.00  0.02  0.06     4885     3557    1 #> d_dir  0.00 0.03 -0.06 -0.02  0.00  0.02  0.06     4463     3101    1 #> d_ind  0.18 0.24 -0.28  0.03  0.18  0.34  0.65     1609     2274    1 #> omega -0.18 0.24 -0.66 -0.34 -0.18 -0.03  0.29     1624     2329    1 #>  #> Residual deviance: 106.1 (on 102 data points) #>                pD: 59.6 #>               DIC: 165.7 #>  #> Bayesian p-value: 0.43 #>  #> ---------------------------------------------------------- Node-split UK vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.20 0.23 -0.64 -0.35 -0.20 -0.05  0.25     4426     2886    1 #> d_dir -0.37 0.52 -1.41 -0.70 -0.37 -0.01  0.62     5662     2778    1 #> d_ind -0.17 0.24 -0.64 -0.33 -0.17  0.00  0.30     4239     3407    1 #> omega -0.20 0.58 -1.34 -0.58 -0.19  0.20  0.90     5356     3077    1 #>  #> Residual deviance: 106.6 (on 102 data points) #>                pD: 59.5 #>               DIC: 166.1 #>  #> Bayesian p-value: 0.75 #>  #> ------------------------------------------------- Node-split ASPAC vs. Acc t-PA ----  #>  #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net 0.19 0.06 0.09 0.15 0.19 0.23  0.30     3546     3132    1 #> d_dir 1.40 0.42 0.63 1.11 1.38 1.67  2.29     3794     2697    1 #> d_ind 0.16 0.06 0.05 0.13 0.16 0.20  0.27     3040     3104    1 #> omega 1.24 0.42 0.47 0.94 1.22 1.50  2.14     3788     2623    1 #>  #> Residual deviance: 96.6 (on 102 data points) #>                pD: 59.5 #>               DIC: 156.1 #>  #> Bayesian p-value: <0.01 #>  #> -------------------------------------------------- Node-split PTCA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.30 0.10 -0.49 -0.37 -0.30 -0.23 -0.11     6001     3563    1 #> d_dir -0.22 0.12 -0.45 -0.29 -0.21 -0.13  0.00     4482     3634    1 #> d_ind -0.47 0.17 -0.82 -0.58 -0.47 -0.36 -0.14     3226     3328    1 #> omega  0.26 0.21 -0.15  0.11  0.26  0.40  0.66     3138     3213    1 #>  #> Residual deviance: 105.5 (on 102 data points) #>                pD: 59.9 #>               DIC: 165.4 #>  #> Bayesian p-value: 0.22 #>  #> -------------------------------------------------- Node-split r-PA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.05 0.05 -0.06  0.02  0.05  0.09  0.16     6314     2884    1 #> d_dir  0.02 0.07 -0.11 -0.03  0.02  0.07  0.15     4905     3938    1 #> d_ind  0.13 0.10 -0.06  0.06  0.13  0.21  0.33     2049     2562    1 #> omega -0.11 0.12 -0.35 -0.20 -0.11 -0.03  0.12     1986     2316    1 #>  #> Residual deviance: 106.4 (on 102 data points) #>                pD: 60.1 #>               DIC: 166.5 #>  #> Bayesian p-value: 0.35 #>  #> --------------------------------------------- Node-split SK + t-PA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.13 0.05  0.03  0.09  0.13  0.16  0.23     5252     3371    1 #> d_dir  0.13 0.05  0.02  0.09  0.13  0.16  0.23     3396     3167    1 #> d_ind  0.63 0.70 -0.72  0.18  0.61  1.08  2.12     3152     2204    1 #> omega -0.51 0.70 -1.99 -0.94 -0.49 -0.05  0.86     3179     2178    1 #>  #> Residual deviance: 106.7 (on 102 data points) #>                pD: 60.1 #>               DIC: 166.8 #>  #> Bayesian p-value: 0.45 #>  #> ---------------------------------------------------- Node-split UK vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.02 0.23 -0.46 -0.18 -0.03 0.13  0.43     4658     3053    1 #> d_dir  0.15 0.35 -0.51 -0.09  0.13 0.38  0.86     5803     3008    1 #> d_ind -0.14 0.29 -0.70 -0.33 -0.13 0.06  0.40     4829     3498    1 #> omega  0.28 0.45 -0.59 -0.02  0.27 0.58  1.19     4386     3418    1 #>  #> Residual deviance: 106.4 (on 102 data points) #>                pD: 59.6 #>               DIC: 166 #>  #> Bayesian p-value: 0.53 #>  #> ----------------------------------------------------- Node-split t-PA vs. ASPAC ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.01 0.04 -0.09 -0.04 -0.01  0.01  0.06     6674     3435    1 #> d_dir -0.02 0.04 -0.10 -0.05 -0.02  0.00  0.05     4653     3440    1 #> d_ind  0.02 0.06 -0.09 -0.02  0.03  0.07  0.15     3318     3221    1 #> omega -0.05 0.06 -0.17 -0.09 -0.05 -0.01  0.07     3271     3313    1 #>  #> Residual deviance: 106.4 (on 102 data points) #>                pD: 59.8 #>               DIC: 166.2 #>  #> Bayesian p-value: 0.43 #>  #> ------------------------------------------------------ Node-split t-PA vs. PTCA ----  #>  #>       mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net 0.48 0.10  0.28  0.41 0.48 0.55  0.68     4386     3494    1 #> d_dir 0.54 0.42 -0.24  0.27 0.54 0.81  1.38     4107     2711    1 #> d_ind 0.47 0.11  0.25  0.40 0.48 0.55  0.68     3761     3541    1 #> omega 0.07 0.43 -0.75 -0.21 0.06 0.34  0.93     3807     2616    1 #>  #> Residual deviance: 107.4 (on 102 data points) #>                pD: 60.3 #>               DIC: 167.7 #>  #> Bayesian p-value: 0.89 #>  #> -------------------------------------------------------- Node-split UK vs. t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.20 0.23 -0.65 -0.36 -0.20 -0.05  0.25     4547     2638    1 #> d_dir -0.29 0.35 -1.00 -0.52 -0.29 -0.06  0.40     5444     3113    1 #> d_ind -0.15 0.29 -0.71 -0.34 -0.15  0.05  0.42     4351     3034    1 #> omega -0.15 0.45 -1.01 -0.46 -0.14  0.17  0.74     4666     3421    1 #>  #> Residual deviance: 107 (on 102 data points) #>                pD: 60 #>               DIC: 167 #>  #> Bayesian p-value: 0.76 plot(thrombo_nodesplit) plot(thrombo_nodesplit, pars = \"omega\", stat = \"halfeye\", ref_line = 0) +   ggplot2::aes(y = comparison) +   ggplot2::facet_null()"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Thrombolytic treatments","text":"Relative effects pairwise contrasts treatments can produced using relative_effects() function, all_contrasts = TRUE.  Treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(thrombo_releff <- relative_effects(thrombo_fit, all_contrasts = TRUE)) #>                            mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Acc t-PA vs. SK]        -0.18 0.04 -0.26 -0.21 -0.18 -0.15 -0.09     2738     2956    1 #> d[ASPAC vs. SK]            0.02 0.04 -0.06 -0.01  0.01  0.04  0.09     5594     3133    1 #> d[PTCA vs. SK]            -0.47 0.10 -0.66 -0.54 -0.48 -0.41 -0.28     3997     3488    1 #> d[r-PA vs. SK]            -0.12 0.06 -0.24 -0.16 -0.12 -0.08 -0.01     3742     3401    1 #> d[SK + t-PA vs. SK]       -0.05 0.05 -0.14 -0.08 -0.05 -0.02  0.04     5285     3144    1 #> d[t-PA vs. SK]             0.00 0.03 -0.06 -0.02  0.00  0.02  0.06     5065     3655    1 #> d[TNK vs. SK]             -0.17 0.08 -0.32 -0.23 -0.17 -0.12 -0.01     4068     3196    1 #> d[UK vs. SK]              -0.20 0.22 -0.63 -0.35 -0.20 -0.06  0.23     4649     3199    1 #> d[ASPAC vs. Acc t-PA]      0.19 0.06  0.08  0.16  0.19  0.23  0.31     3787     3087    1 #> d[PTCA vs. Acc t-PA]      -0.30 0.09 -0.48 -0.36 -0.30 -0.24 -0.11     5367     3542    1 #> d[r-PA vs. Acc t-PA]       0.05 0.06 -0.06  0.02  0.06  0.09  0.16     5901     3678    1 #> d[SK + t-PA vs. Acc t-PA]  0.13 0.05  0.02  0.09  0.13  0.16  0.23     5731     3694    1 #> d[t-PA vs. Acc t-PA]       0.18 0.05  0.08  0.14  0.18  0.21  0.28     3474     3231    1 #> d[TNK vs. Acc t-PA]        0.01 0.06 -0.12 -0.04  0.01  0.05  0.13     6009     3591    1 #> d[UK vs. Acc t-PA]        -0.03 0.22 -0.45 -0.17 -0.03  0.12  0.41     4629     3101    1 #> d[PTCA vs. ASPAC]         -0.49 0.11 -0.70 -0.56 -0.49 -0.42 -0.28     4587     3691    1 #> d[r-PA vs. ASPAC]         -0.14 0.07 -0.28 -0.18 -0.14 -0.09  0.00     4170     2798    1 #> d[SK + t-PA vs. ASPAC]    -0.07 0.06 -0.18 -0.11 -0.07 -0.03  0.05     5643     3608    1 #> d[t-PA vs. ASPAC]         -0.01 0.04 -0.09 -0.04 -0.01  0.01  0.06     6993     3163    1 #> d[TNK vs. ASPAC]          -0.19 0.09 -0.36 -0.25 -0.19 -0.13 -0.02     4586     3548    1 #> d[UK vs. ASPAC]           -0.22 0.22 -0.65 -0.36 -0.22 -0.07  0.22     4814     2976    1 #> d[r-PA vs. PTCA]           0.35 0.11  0.14  0.28  0.35  0.42  0.57     4752     3217    1 #> d[SK + t-PA vs. PTCA]      0.42 0.10  0.22  0.35  0.43  0.50  0.63     4897     3213    1 #> d[t-PA vs. PTCA]           0.48 0.10  0.28  0.41  0.48  0.54  0.68     4332     3423    1 #> d[TNK vs. PTCA]            0.30 0.11  0.08  0.23  0.30  0.38  0.53     5810     3545    1 #> d[UK vs. PTCA]             0.27 0.23 -0.19  0.12  0.27  0.42  0.75     4717     3264    1 #> d[SK + t-PA vs. r-PA]      0.07 0.07 -0.07  0.03  0.07  0.12  0.21     5826     3325    1 #> d[t-PA vs. r-PA]           0.13 0.07 -0.01  0.08  0.13  0.17  0.26     4078     3485    1 #> d[TNK vs. r-PA]           -0.05 0.09 -0.22 -0.11 -0.05  0.01  0.12     7820     3075    1 #> d[UK vs. r-PA]            -0.08 0.22 -0.52 -0.23 -0.08  0.07  0.37     4771     3000    1 #> d[t-PA vs. SK + t-PA]      0.05 0.06 -0.05  0.01  0.05  0.09  0.16     5483     3209    1 #> d[TNK vs. SK + t-PA]      -0.12 0.09 -0.29 -0.18 -0.12 -0.07  0.05     5828     2968    1 #> d[UK vs. SK + t-PA]       -0.15 0.22 -0.59 -0.30 -0.15 -0.01  0.29     4748     3261    1 #> d[TNK vs. t-PA]           -0.17 0.08 -0.34 -0.23 -0.17 -0.12 -0.01     4314     3305    1 #> d[UK vs. t-PA]            -0.20 0.22 -0.64 -0.35 -0.20 -0.06  0.23     4712     3459    1 #> d[UK vs. TNK]             -0.03 0.23 -0.47 -0.18 -0.03  0.12  0.42     4722     3083    1 plot(thrombo_releff, ref_line = 0) (thrombo_ranks <- posterior_ranks(thrombo_fit)) #>                 mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[SK]        7.46 0.96    6   7   7   8     9     3802       NA    1 #> rank[Acc t-PA]  3.19 0.81    2   3   3   4     5     3975     3533    1 #> rank[ASPAC]     7.99 1.12    6   7   8   9     9     4892       NA    1 #> rank[PTCA]      1.12 0.33    1   1   1   1     2     3308     3311    1 #> rank[r-PA]      4.42 1.17    2   4   5   5     7     4959     3164    1 #> rank[SK + t-PA] 5.99 1.25    4   5   6   6     9     4944       NA    1 #> rank[t-PA]      7.48 1.11    5   7   8   8     9     4631       NA    1 #> rank[TNK]       3.48 1.27    2   3   3   4     6     4999     3358    1 #> rank[UK]        3.87 2.64    1   2   3   5     9     4438       NA    1 plot(thrombo_ranks) (thrombo_rankprobs <- posterior_rank_probs(thrombo_fit)) #>              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] p_rank[8] #> d[SK]             0.00      0.00      0.00      0.00      0.02      0.12      0.39      0.32 #> d[Acc t-PA]       0.00      0.20      0.45      0.30      0.05      0.00      0.00      0.00 #> d[ASPAC]          0.00      0.00      0.00      0.00      0.02      0.10      0.19      0.25 #> d[PTCA]           0.88      0.12      0.00      0.00      0.00      0.00      0.00      0.00 #> d[r-PA]           0.00      0.05      0.14      0.30      0.39      0.08      0.01      0.01 #> d[SK + t-PA]      0.00      0.00      0.01      0.06      0.24      0.45      0.10      0.07 #> d[t-PA]           0.00      0.00      0.00      0.01      0.04      0.15      0.28      0.32 #> d[TNK]            0.00      0.24      0.32      0.24      0.14      0.03      0.01      0.01 #> d[UK]             0.12      0.38      0.07      0.09      0.10      0.06      0.02      0.02 #>              p_rank[9] #> d[SK]             0.15 #> d[Acc t-PA]       0.00 #> d[ASPAC]          0.44 #> d[PTCA]           0.00 #> d[r-PA]           0.00 #> d[SK + t-PA]      0.06 #> d[t-PA]           0.20 #> d[TNK]            0.00 #> d[UK]             0.14 plot(thrombo_rankprobs) (thrombo_cumrankprobs <- posterior_rank_probs(thrombo_fit, cumulative = TRUE)) #>              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] p_rank[8] #> d[SK]             0.00      0.00      0.00      0.00      0.02      0.14      0.53      0.85 #> d[Acc t-PA]       0.00      0.20      0.65      0.95      1.00      1.00      1.00      1.00 #> d[ASPAC]          0.00      0.00      0.00      0.00      0.02      0.12      0.31      0.56 #> d[PTCA]           0.88      1.00      1.00      1.00      1.00      1.00      1.00      1.00 #> d[r-PA]           0.00      0.05      0.20      0.49      0.89      0.97      0.98      1.00 #> d[SK + t-PA]      0.00      0.00      0.02      0.08      0.32      0.78      0.87      0.94 #> d[t-PA]           0.00      0.00      0.00      0.01      0.04      0.19      0.48      0.80 #> d[TNK]            0.00      0.24      0.56      0.80      0.94      0.98      0.99      1.00 #> d[UK]             0.12      0.50      0.57      0.66      0.76      0.82      0.84      0.86 #>              p_rank[9] #> d[SK]                1 #> d[Acc t-PA]          1 #> d[ASPAC]             1 #> d[PTCA]              1 #> d[r-PA]              1 #> d[SK + t-PA]         1 #> d[t-PA]              1 #> d[TNK]               1 #> d[UK]                1 plot(thrombo_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: White blood cell transfusion","text":"begin setting network - just pairwise meta-analysis. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). set “Control” reference treatment.","code":"tr_net <- set_agd_arm(transfusion,                             study = studyc,                            trt = trtc,                            r = r,                             n = n,                            trt_ref = \"Control\") tr_net #> A network with 6 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms           #>  Bow 1984      2: Control | Transfusion #>  Herzig 1977   2: Control | Transfusion #>  Higby 1975    2: Control | Transfusion #>  Scali 1978    2: Control | Transfusion #>  Vogler 1977   2: Control | Transfusion #>  Winston 1982a 2: Control | Transfusion #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 6 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: White blood cell transfusion","text":"fit two random effects models, first non-informative prior heterogeneity, using informative prior described Turner et al. (2012).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"random-effects-meta-analysis-with-non-informative-heterogeneity-prior","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis with non-informative heterogeneity prior","title":"Example: White blood cell transfusion","text":"fit random effects model using nma() function trt_effects = \"random\". use \\(\\mathrm{N}(0, 100^2)\\) prior distributions treatment effects \\(d_k\\) study-specific intercepts \\(\\mu_j\\), non-informative \\(\\textrm{half-N}(5^2)\\) prior heterogeneity standard deviation \\(\\tau\\). can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  posterior distribution heterogeneity variance \\(\\tau^2\\) summarised ","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. tr_fit_RE_noninf <- nma(tr_net,                          trt_effects = \"random\",                         prior_intercept = normal(scale = 100),                         prior_trt = normal(scale = 100),                         prior_het = half_normal(scale = 5)) tr_fit_RE_noninf #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Transfusion]   -1.15    0.03 0.99   -3.35   -1.66   -1.10   -0.58    0.69  1160    1 #> lp__           -134.40    0.09 3.11 -141.40 -136.27 -134.00 -132.23 -129.26  1125    1 #> tau               1.85    0.03 1.04    0.52    1.15    1.59    2.27    4.66  1384    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:48:47 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(tr_fit_RE_noninf, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(tr_fit_RE_noninf, prior = \"het\") noninf_tau <- as.array(tr_fit_RE_noninf, pars = \"tau\") noninf_tausq <- noninf_tau^2 names(noninf_tausq) <- \"tausq\" summary(noninf_tausq) #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq 4.51 6.03 0.27 1.32 2.54 5.17 21.74     1216     1541    1"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"random-effects-meta-analysis-with-informative-heterogeneity-prior","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis with informative heterogeneity prior","title":"Example: White blood cell transfusion","text":"Keeping rest model setup , now use informative \\(\\textrm{log-N}(-3.93, 1.51^2)\\) prior heterogeneity variance \\(\\tau^2\\). can examine range parameter values implied prior distribution summary() method: Fitting RE model, specify log_normal prior distribution prior_het argument, set prior_het_type = \"var\" indicate prior distribution variance scale (instead standard deviation, default). Basic parameter summaries given print() method: default, summaries study-specific intercepts \\(\\mu_j\\) study-specific relative effects \\(\\delta_{jk}\\) hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Note: heterogeneity variance \\(\\tau^2\\) plotted since prior specified \\(\\tau^2\\). posterior distribution heterogeneity variance \\(\\tau^2\\) summarised ","code":"summary(log_normal(-3.93, 1.51)) #> A log-Normal prior distribution: location = -3.93, scale = 1.51. #> 50% of the prior density lies between 0.01 and 0.05. #> 95% of the prior density lies between 0 and 0.38. tr_fit_RE_inf <- nma(tr_net,                       trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = log_normal(-3.93, 1.51),                      prior_het_type = \"var\") #> Warning: There were 1 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems tr_fit_RE_inf #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Transfusion]   -0.77    0.01 0.44   -1.73   -1.04   -0.75   -0.48    0.00  1826    1 #> lp__           -141.27    0.08 2.91 -147.68 -142.96 -140.94 -139.19 -136.52  1463    1 #> tau               0.48    0.01 0.36    0.05    0.19    0.41    0.68    1.34  1513    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:48:50 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(tr_fit_RE_inf, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(tr_fit_RE_inf, prior = \"het\") inf_tau <- as.array(tr_fit_RE_inf, pars = \"tau\") inf_tausq <- inf_tau^2 names(inf_tausq) <- \"tausq\" summary(inf_tausq) #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq 0.36 0.63    0 0.04 0.17 0.47  1.79     1432     2849    1"},{"path":[]},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David M. Phillippo. Author, maintainer.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Phillippo DM (2023). multinma: Bayesian Network Meta-Analysis Individual Aggregate Data. doi:10.5281/zenodo.3904454, R package version 0.5.1.9007, https://dmphillippo.github.io/multinma/. Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189-1210. doi:10.1111/rssa.12579.","code":"@Manual{,   title = {multinma: Bayesian Network Meta-Analysis of Individual and Aggregate Data},   author = {David M. Phillippo},   year = {2023},   note = {R package version 0.5.1.9007},   url = {https://dmphillippo.github.io/multinma/},   doi = {10.5281/zenodo.3904454}, } @Article{,   title = {Multilevel Network Meta-Regression for population-adjusted treatment comparisons},   author = {David M. Phillippo and Sofia Dias and A. E. Ades and Mark Belger and Alan Brnabic and Alexander Schacht and Daniel Saure and Zbigniew Kadziola and Nicky J. Welton},   year = {2020},   doi = {10.1111/rssa.12579},   journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},   volume = {183},   number = {3},   pages = {1189-1210}, }"},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"multinma-network-meta-analysis-of-individual-and-aggregate-data-in-stan-","dir":"","previous_headings":"","what":"Bayesian network meta-analysis of individual and aggregate data","title":"Bayesian network meta-analysis of individual and aggregate data","text":"multinma package implements network meta-analysis, network meta-regression, multilevel network meta-regression models combine evidence network studies treatments using either aggregate data individual patient data study (Phillippo et al. 2020; Phillippo 2019). Models estimated Bayesian framework using Stan (Carpenter et al. 2017).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian network meta-analysis of individual and aggregate data","text":"can install released version multinma CRAN : development version can installed R-universe : source GitHub : Installing source requires rstan package installed configured. See installation guide .","code":"install.packages(\"multinma\") install.packages(\"multinma\", repos = c(\"https://dmphillippo.r-universe.dev\", getOption(\"repos\"))) # install.packages(\"devtools\") devtools::install_github(\"dmphillippo/multinma\")"},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting started","title":"Bayesian network meta-analysis of individual and aggregate data","text":"good place start package vignettes walk example analyses, see vignette(\"vignette_overview\") overview. series NICE Technical Support Documents evidence synthesis gives detailed introduction network meta-analysis: Dias, S. et al. (2011). “NICE DSU Technical Support Documents 1-7: Evidence Synthesis Decision Making.” National Institute Health Care Excellence. Available https://www.sheffield.ac.uk/nice-dsu/tsds. Multilevel network meta-regression set following methods paper: Phillippo, D. M. et al. (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3):1189-1210. doi: 10.1111/rssa.12579.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"citing-multinma","dir":"","previous_headings":"","what":"Citing multinma","title":"Bayesian network meta-analysis of individual and aggregate data","text":"multinma package can cited follows: Phillippo, D. M. (2023). multinma: Bayesian Network Meta-Analysis Individual Aggregate Data. R package version 0.5.1.9000, doi: 10.5281/zenodo.3904454. fitting ML-NMR models, please cite methods paper: Phillippo, D. M. et al. (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3):1189-1210. doi: 10.1111/rssa.12579.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":null,"dir":"Reference","previous_headings":"","what":"The Bernoulli Distribution — qbern","title":"The Bernoulli Distribution — qbern","text":"quantile function qbern Bernoulli distribution, success probability prob. equivalent qbinom(p, 1, prob).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Bernoulli Distribution — qbern","text":"","code":"qbern(p, prob, lower.tail = TRUE, log.p = FALSE)  pbern(q, prob, lower.tail = TRUE, log.p = FALSE)  dbern(x, prob, log = FALSE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Bernoulli Distribution — qbern","text":"p vector probabilities prob probability success lower.tail, log.p, log see stats::Binomial x, q vector quantiles","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":null,"dir":"Reference","previous_headings":"","what":"The Gamma distribution — qgamma","title":"The Gamma distribution — qgamma","text":"provide convenient extensions [dpq]gamma functions, allow distribution specified terms mean standard deviation, instead shape rate/scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Gamma distribution — qgamma","text":"","code":"qgamma(   p,   shape,   rate = 1,   scale = 1/rate,   lower.tail = TRUE,   log.p = FALSE,   mean,   sd )  dgamma(x, shape, rate = 1, scale = 1/rate, log = FALSE, mean, sd)  pgamma(   q,   shape,   rate = 1,   scale = 1/rate,   lower.tail = TRUE,   log.p = FALSE,   mean,   sd )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Gamma distribution — qgamma","text":"p vector probabilities shape, rate, scale, log, lower.tail, log.p see stats::GammaDist mean, sd mean standard deviation, overriding shape rate scale specified x, q vector quantiles","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_ndmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Example newly-diagnosed multiple myeloma — example_ndmm","title":"Example newly-diagnosed multiple myeloma — example_ndmm","text":"Calling example(\"example_ndmm\") run proportional hazards Weibull NMA model newly-diagnosed multiple myeloma data, using code Examples section . resulting stan_nma object ndmm_fit available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_ndmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example newly-diagnosed multiple myeloma — example_ndmm","text":"","code":"# Set up newly-diagnosed multiple myeloma network  head(ndmm_ipd) #>          study trt       studyf trtf      age iss_stage3 response_cr_vgpr male #> 1 McCarthy2012 Pbo McCarthy2012  Pbo 50.81625          0                1    0 #> 2 McCarthy2012 Pbo McCarthy2012  Pbo 62.18165          0                0    0 #> 3 McCarthy2012 Pbo McCarthy2012  Pbo 51.53762          1                1    1 #> 4 McCarthy2012 Pbo McCarthy2012  Pbo 46.74128          0                1    1 #> 5 McCarthy2012 Pbo McCarthy2012  Pbo 62.62561          0                1    1 #> 6 McCarthy2012 Pbo McCarthy2012  Pbo 49.24520          1                1    0 #>   eventtime status #> 1 31.106516      1 #> 2  3.299623      0 #> 3 57.400000      0 #> 4 57.400000      0 #> 5 57.400000      0 #> 6 30.714460      0 head(ndmm_agd) #>        study     studyf trt trtf eventtime status #> 1 Morgan2012 Morgan2012 Pbo  Pbo  18.72575      1 #> 2 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 3 Morgan2012 Morgan2012 Pbo  Pbo  34.35726      1 #> 4 Morgan2012 Morgan2012 Pbo  Pbo  10.77826      1 #> 5 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 6 Morgan2012 Morgan2012 Pbo  Pbo  14.52966      1  ndmm_net <- combine_network(   set_ipd(ndmm_ipd,           study, trt,           Surv = Surv(eventtime / 12, status)),   set_agd_surv(ndmm_agd,                study, trt,                Surv = Surv(eventtime / 12, status),                covariates = ndmm_agd_covs)) # \\donttest{ # Fit Weibull (PH) model ndmm_fit <- nma(ndmm_net, refresh = if (interactive()) 200 else 0,                 likelihood = \"weibull\",                 prior_intercept = normal(scale = 100),                 prior_trt = normal(scale = 10),                 prior_aux = half_normal(scale = 10)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit #> A fixed effects NMA with a weibull likelihood (log link). #> Inference for Stan model: survival_param. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75% #> d[Len]                 -0.54    0.00 0.05    -0.62    -0.57    -0.54    -0.51 #> d[Thal]                -0.11    0.00 0.09    -0.28    -0.17    -0.11    -0.06 #> lp__                -6229.88    0.06 2.40 -6235.28 -6231.31 -6229.58 -6228.13 #> shape[Attal2012]        1.30    0.00 0.06     1.18     1.26     1.30     1.34 #> shape[Jackson2019]      0.93    0.00 0.02     0.89     0.92     0.93     0.95 #> shape[McCarthy2012]     1.29    0.00 0.07     1.17     1.25     1.29     1.34 #> shape[Morgan2012]       0.88    0.00 0.03     0.82     0.86     0.88     0.90 #> shape[Palumbo2014]      1.02    0.00 0.07     0.88     0.97     1.01     1.06 #>                        97.5% n_eff Rhat #> d[Len]                 -0.45  5032    1 #> d[Thal]                 0.06  5954    1 #> lp__                -6226.07  1602    1 #> shape[Attal2012]        1.42  5073    1 #> shape[Jackson2019]      0.98  5326    1 #> shape[McCarthy2012]     1.43  4660    1 #> shape[Morgan2012]       0.94  5085    1 #> shape[Palumbo2014]      1.16  4929    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:20:51 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # } # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"ndmm_net\", ndmm_net, .GlobalEnv)   assign(\"ndmm_fit\", ndmm_fit, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_pso_mlnmr.html","id":null,"dir":"Reference","previous_headings":"","what":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","title":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","text":"Calling example(\"example_pso_mlnmr\") run ML-NMR model plaque psoriasis IPD AgD, using code Examples section . resulting stan_nma object pso_fit available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_pso_mlnmr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","text":"Plaque psoriasis ML-NMR use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_pso_mlnmr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","text":"","code":"# Set up plaque psoriasis network combining IPD and AgD library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.  # \\donttest{ # Fitting a ML-NMR model. # Specify a regression model to include effect modifier interactions for five # covariates, along with main (prognostic) effects. We use a probit link and # specify that the two-parameter Binomial approximation for the aggregate-level # likelihood should be used. We set treatment-covariate interactions to be equal # within each class. We narrow the possible range for random initial values with # init_r = 0.1, since probit models in particular are often hard to initialise. # Using the QR decomposition greatly improves sampling efficiency here, as is # often the case for regression models. pso_fit <- nma(pso_net, refresh = if (interactive()) 200 else 0,                trt_effects = \"fixed\",                link = \"probit\",                likelihood = \"bernoulli2\",                regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                class_interactions = \"common\",                prior_intercept = normal(scale = 10),                prior_trt = normal(scale = 10),                prior_reg = normal(scale = 10),                init_r = 0.1,                QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25% #> beta[durnpso]                           0.04    0.00 0.06    -0.07     0.00 #> beta[prevsys]                          -0.14    0.00 0.17    -0.46    -0.26 #> beta[bsa]                              -0.07    0.01 0.43    -0.91    -0.36 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02 #> beta[psa]                              -0.08    0.00 0.17    -0.43    -0.20 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.14    -0.06 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.19    -0.18     0.07 #> beta[prevsys:.trtclassIL blocker]       0.07    0.00 0.18    -0.29    -0.05 #> beta[bsa:.trtclassTNFa blocker]         0.06    0.01 0.51    -0.92    -0.29 #> beta[bsa:.trtclassIL blocker]           0.30    0.01 0.48    -0.61    -0.02 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.03    -0.23    -0.19 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12 #> beta[psa:.trtclassTNFa blocker]        -0.05    0.00 0.21    -0.46    -0.19 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.19    -0.35    -0.12 #> d[ETN]                                  1.55    0.00 0.08     1.40     1.50 #> d[IXE_Q2W]                              2.96    0.00 0.08     2.80     2.90 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.39     2.49 #> d[SEC_150]                              2.15    0.00 0.12     1.92     2.07 #> d[SEC_300]                              2.45    0.00 0.12     2.22     2.37 #> lp__                                -1576.27    0.08 3.35 -1583.82 -1578.29 #>                                          50%      75%    97.5% n_eff Rhat #> beta[durnpso]                           0.04     0.08     0.16  6061    1 #> beta[prevsys]                          -0.14    -0.03     0.18  5351    1 #> beta[bsa]                              -0.06     0.23     0.74  5533    1 #> beta[weight]                            0.04     0.06     0.10  6666    1 #> beta[psa]                              -0.08     0.03     0.24  5705    1 #> beta[durnpso:.trtclassTNFa blocker]    -0.03     0.02     0.11  5886    1 #> beta[durnpso:.trtclassIL blocker]      -0.01     0.03     0.12  6479    1 #> beta[prevsys:.trtclassTNFa blocker]     0.20     0.33     0.57  5820    1 #> beta[prevsys:.trtclassIL blocker]       0.07     0.19     0.41  6225    1 #> beta[bsa:.trtclassTNFa blocker]         0.05     0.40     1.08  5674    1 #> beta[bsa:.trtclassIL blocker]           0.29     0.62     1.23  6427    1 #> beta[weight:.trtclassTNFa blocker]     -0.17    -0.14    -0.10  6974    1 #> beta[weight:.trtclassIL blocker]       -0.10    -0.08    -0.03  7472    1 #> beta[psa:.trtclassTNFa blocker]        -0.05     0.10     0.37  6414    1 #> beta[psa:.trtclassIL blocker]           0.01     0.14     0.38  6481    1 #> d[ETN]                                  1.55     1.61     1.71  4379    1 #> d[IXE_Q2W]                              2.96     3.01     3.12  5454    1 #> d[IXE_Q4W]                              2.54     2.60     2.70  4950    1 #> d[SEC_150]                              2.15     2.22     2.37  5154    1 #> d[SEC_300]                              2.45     2.53     2.69  5201    1 #> lp__                                -1575.95 -1573.89 -1570.53  1650    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:22:07 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"pso_net\", pso_net, .GlobalEnv)   assign(\"pso_fit\", pso_fit, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_fe.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking FE NMA — example_smk_fe","title":"Example smoking FE NMA — example_smk_fe","text":"Calling example(\"example_smk_fe\") run fixed effects NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_FE available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_fe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking FE NMA — example_smk_fe","text":"Smoking FE NMA use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_fe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking FE NMA — example_smk_fe","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting a fixed effect model smk_fit_FE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100))  smk_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          0.84    0.00 0.18     0.49     0.72     0.84 #> d[Individual counselling]     0.76    0.00 0.06     0.65     0.72     0.76 #> d[Self-help]                  0.22    0.00 0.12    -0.01     0.14     0.22 #> lp__                      -5859.22    0.09 3.67 -5867.30 -5861.45 -5858.96 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          0.96     1.19  1693    1 #> d[Individual counselling]     0.80     0.88  1452    1 #> d[Self-help]                  0.31     0.47  2215    1 #> lp__                      -5856.57 -5853.04  1706    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:23:10 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_FE\", smk_fit_FE, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_nodesplit.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking node-splitting — example_smk_nodesplit","title":"Example smoking node-splitting — example_smk_nodesplit","text":"Calling example(\"example_smk_nodesplit\") run node-splitting models smoking cessation data, using code Examples section . resulting nma_nodesplit_df object smk_fit_RE_nodesplit available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_nodesplit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking node-splitting — example_smk_nodesplit","text":"Smoking node-splitting use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_nodesplit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking node-splitting — example_smk_nodesplit","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting all possible node-splitting models smk_fit_RE_nodesplit <- nma(smk_net, refresh = if (interactive()) 200 else 0,                             consistency = \"nodesplit\",                             trt_effects = \"random\",                             prior_intercept = normal(scale = 100),                             prior_trt = normal(scale = 100),                             prior_het = normal(scale = 5)) #> Fitting model 1 of 7, node-split: Group counselling vs. No intervention #> Fitting model 2 of 7, node-split: Individual counselling vs. No intervention #> Fitting model 3 of 7, node-split: Self-help vs. No intervention #> Fitting model 4 of 7, node-split: Individual counselling vs. Group counselling #> Fitting model 5 of 7, node-split: Self-help vs. Group counselling #> Fitting model 6 of 7, node-split: Self-help vs. Individual counselling #> Fitting model 7 of 7, consistency model # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_RE_nodesplit\", smk_fit_RE_nodesplit, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_re.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking RE NMA — example_smk_re","title":"Example smoking RE NMA — example_smk_re","text":"Calling example(\"example_smk_re\") run random effects NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_RE available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_re.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking RE NMA — example_smk_re","text":"Smoking RE NMA use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_re.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking RE NMA — example_smk_re","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting a random effects model smk_fit_RE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = normal(scale = 5))  smk_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          1.11    0.01 0.43     0.28     0.83     1.09 #> d[Individual counselling]     0.85    0.01 0.24     0.38     0.69     0.85 #> d[Self-help]                  0.50    0.01 0.40    -0.30     0.25     0.50 #> lp__                      -5768.48    0.21 6.52 -5782.33 -5772.47 -5768.01 #> tau                           0.83    0.01 0.18     0.54     0.70     0.81 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          1.38     1.96  2229    1 #> d[Individual counselling]     1.00     1.34  1164    1 #> d[Self-help]                  0.76     1.28  1892    1 #> lp__                      -5764.09 -5756.80   988    1 #> tau                           0.93     1.23  1260    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:24:08 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_RE\", smk_fit_RE, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_ume.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking UME NMA — example_smk_ume","title":"Example smoking UME NMA — example_smk_ume","text":"Calling example(\"example_smk_ume\") run unrelated mean effects (inconsistency) NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_RE_UME available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_ume.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking UME NMA — example_smk_ume","text":"Smoking UME NMA use examples.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_ume.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example smoking UME NMA — example_smk_ume","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting an unrelated mean effects (inconsistency) model smk_fit_RE_UME <- nma(smk_net, refresh = if (interactive()) 200 else 0,                       consistency = \"ume\",                       trt_effects = \"random\",                       prior_intercept = normal(scale = 100),                       prior_trt = normal(scale = 100),                       prior_het = normal(scale = 5))  smk_fit_RE_UME #> A random effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                     mean se_mean   sd     2.5% #> d[Group counselling vs. No intervention]            1.13    0.02 0.78    -0.35 #> d[Individual counselling vs. No intervention]       0.90    0.01 0.27     0.40 #> d[Self-help vs. No intervention]                    0.33    0.01 0.58    -0.85 #> d[Individual counselling vs. Group counselling]    -0.30    0.01 0.63    -1.53 #> d[Self-help vs. Group counselling]                 -0.61    0.01 0.68    -1.97 #> d[Self-help vs. Individual counselling]             0.17    0.02 1.08    -1.90 #> lp__                                            -5765.42    0.19 6.27 -5778.23 #> tau                                                 0.93    0.01 0.22     0.58 #>                                                      25%      50%      75% #> d[Group counselling vs. No intervention]            0.62     1.09     1.64 #> d[Individual counselling vs. No intervention]       0.72     0.90     1.07 #> d[Self-help vs. No intervention]                   -0.05     0.33     0.71 #> d[Individual counselling vs. Group counselling]    -0.70    -0.30     0.09 #> d[Self-help vs. Group counselling]                 -1.04    -0.59    -0.18 #> d[Self-help vs. Individual counselling]            -0.52     0.15     0.87 #> lp__                                            -5769.53 -5765.44 -5761.08 #> tau                                                 0.77     0.90     1.05 #>                                                    97.5% n_eff Rhat #> d[Group counselling vs. No intervention]            2.73  2256 1.00 #> d[Individual counselling vs. No intervention]       1.47  1130 1.00 #> d[Self-help vs. No intervention]                    1.46  1946 1.00 #> d[Individual counselling vs. Group counselling]     0.96  2221 1.00 #> d[Self-help vs. Group counselling]                  0.73  2494 1.00 #> d[Self-help vs. Individual counselling]             2.35  3461 1.00 #> lp__                                            -5753.65  1104 1.00 #> tau                                                 1.46  1096 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:24:14 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\dontshow{ if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) {   assign(\"smk_net\", smk_net, .GlobalEnv)   assign(\"smk_fit_RE_UME\", smk_fit_RE_UME, .GlobalEnv) } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/adapt_delta.html","id":null,"dir":"Reference","previous_headings":"","what":"Target average acceptance probability — adapt_delta","title":"Target average acceptance probability — adapt_delta","text":"Stan control argument adapt_delta sets target average acceptance probability -U-Turn Sampler (NUTS) used Stan.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/adapt_delta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Target average acceptance probability — adapt_delta","text":"default value adapt_delta used nma() 0.8 fixed effect models, 0.95 random effects models. need change adapt_delta unless see warning message divergent transitions. Increasing adapt_delta default value closer 1 means Stan use smaller step size, making sampling slower robust, resulting fewer divergent transitions. details see Stan documentation available https://mc-stan.org/users/documentation/.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":null,"dir":"Reference","previous_headings":"","what":"Add numerical integration points to aggregate data — add_integration","title":"Add numerical integration points to aggregate data — add_integration","text":"add_integration() generic creates Quasi-Monte Carlo numerical integration points using Gaussian copula Sobol' sequences, described Phillippo et al. (2020) . Methods available networks stored nma_data objects, data frames. function unnest_integration() unnests integration points stored data frame, aid plotting exploration.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add numerical integration points to aggregate data — add_integration","text":"","code":"add_integration(x, ...)  # S3 method for default add_integration(x, ...)  # S3 method for data.frame add_integration(   x,   ...,   cor = NULL,   cor_adjust = NULL,   n_int = 64L,   int_args = list() )  # S3 method for nma_data add_integration(   x,   ...,   cor = NULL,   cor_adjust = NULL,   n_int = 64L,   int_args = list() )  unnest_integration(data)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add numerical integration points to aggregate data — add_integration","text":"x nma_data object, created set_*() functions combine_network(), data frame ... Distributions covariates, see \"Details\" cor Correlation matrix use generating integration points. default, takes weighted correlation matrix IPD studies. Rows columns match order covariates specified .... cor_adjust Adjustment apply correlation matrix given cor (computed IPD cor = NULL) obtain Gaussian copula correlations, either \"spearman\", \"pearson\", \"none\", see \"Details\". default cor = NULL \"spearman\", otherwise default \"pearson\". n_int Number integration points generate, default 64. Powers 2 recommended, expected particularly efficient QMC integration. int_args named list arguments pass sobol() data Data frame nested integration points, stored list columns .int_<variable name>","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add numerical integration points to aggregate data — add_integration","text":"nma_data method, object class nma_data. data.frame method, input data frame returned (tibble) added column covariate (prefixed \".int_\"), containing numerical integration points nested length-n_int vectors within row. unnest_integration(), data frame integration points unnested.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add numerical integration points to aggregate data — add_integration","text":"arguments passed ... specify distributions covariates. Argument names specify name covariate, match covariate name IPD (IPD present). required marginal distribution specified using function distr(). argument cor_adjust specifies correlation matrix given cor (computed IPD cor = NULL) adjusted obtain correlation matrix Gaussian copula, using formulae Xiao Zhou (2018) . cor_adjust = \"spearman\" used correlations cor computed using Spearman's rank correlation. Correlations continuous covariates reproduced exactly integration points. Correlations discrete covariates reproduced approximately. default cor = NULL correlations calculated IPD studies. cor_adjust = \"pearson\" used correlations cor computed using Pearson's product-moment correlation. Correlations Normal covariates reproduced exactly integration points, others reproduced approximately. Correlations discrete covariates reproduced approximately (identically cor_adjust   = \"spearman\"). default cor provided user, since cor() defaults method = \"pearson\" Pearson correlations likely reported published data. However, recommend providing Spearman correlations (e.g. cor(., method = \"spearman\")) using cor_adjust = \"spearman\" possible. cor_adjust = \"none\" allows user specify correlation matrix Gaussian copula directly; adjustment applied. cor_adjust = \"legacy\" also available, reproduces exactly behaviour version 0.3.0 earlier. similar cor_adjust =   \"none\", unadjusted Spearman correlations used cor = NULL. adding integration points network object correlation matrix used stored $int_cor, copula correlation matrix adjustment used stored attributes $int_cor. correlation matrix passed add_integration() (e.g. reuse correlations external target population) detected, correct setting cor_adjust automatically applied.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Add numerical integration points to aggregate data — add_integration","text":"Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 . Xiao Q, Zhou S (2018). “Matching correlation coefficient Gaussian copula.” Communications Statistics - Theory Methods, 48(7), 1728--1747. doi:10.1080/03610926.2018.1439962 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add numerical integration points to aggregate data — add_integration","text":"","code":"## Plaque psoriasis ML-NMR - network setup and adding integration points # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.   ## Adding integration points to a data frame, e.g. for prediction # Define a data frame of covariate summaries new_agd_int <- data.frame(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1)  # Adding integration points, using the weighted average correlation matrix # computed for the plaque psoriasis network new_agd_int <- add_integration(new_agd_int,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   cor = pso_net$int_cor,   n_int = 64)  # Here, since we reused the correlation matrix pso_net$int_cor from the # network, the correct setting of cor_adjust = \"spearman\" is automatically # applied  new_agd_int #> # A tibble: 1 × 13 #>   bsa_mean bsa_sd prevsys   psa weight_mean weight_sd durnpso_mean durnpso_sd #>      <dbl>  <dbl>   <dbl> <dbl>       <dbl>     <dbl>        <dbl>      <dbl> #> 1      0.6    0.3     0.1   0.2          10         1            3          1 #> # ℹ 5 more variables: .int_durnpso <list>, .int_prevsys <list>, #> #   .int_bsa <list>, .int_weight <list>, .int_psa <list>"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"Samples (post warm-) stan_nma model object can coerced array, matrix, data frame.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"","code":"# S3 method for stan_nma as.array(x, ..., pars, include = TRUE)  # S3 method for stan_nma as.data.frame(x, ..., pars, include = TRUE)  # S3 method for stan_nma as_tibble(x, ..., pars, include = TRUE)  # S3 method for stan_nma as.tibble(x, ..., pars, include = TRUE)  # S3 method for stan_nma as.matrix(x, ..., pars, include = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"x stan_nma object ... Additional arguments passed .array.stanfit() pars Optional character vector parameter names include output. specified, parameters used. include Logical, parameters pars included (TRUE, default) excluded (FALSE)?","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":".array() method produces 3D array [Iteration, Chain, Parameter] containing posterior samples parameter (class mcmc_array). side effect enabling bayesplot functions seamlessly work stan_nma objects. .data.frame() method produces data frame containing posterior samples parameter, combined chains. .matrix() method produces matrix containing posterior samples parameter, combined chains.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":null,"dir":"Reference","previous_headings":"","what":"as.stanfit — as.stanfit","title":"as.stanfit — as.stanfit","text":"Attempt turn object stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"as.stanfit — as.stanfit","text":"","code":"as.stanfit(x, ...)  # S3 method for stan_nma as.stanfit(x, ...)  # S3 method for default as.stanfit(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"as.stanfit — as.stanfit","text":"x object ... additional arguments","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"as.stanfit — as.stanfit","text":"stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":null,"dir":"Reference","previous_headings":"","what":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"Data frame containing results 26 trials comparing 17 treatments 4 classes prevention stroke patients atrial fibrillation (Cooper et al. 2009) . data corrected versions given van Valkenhoef Kuiper (2016) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"","code":"atrial_fibrillation"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"data frame 63 rows 11 variables: studyc study name studyn numeric study ID trtc treatment name trtn numeric treatment code trt_class treatment class r number events n sample size E person-years risk stroke proportion individuals prior stroke year year study publication followup mean length follow-(years)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"Cooper NJ, Sutton AJ, Morris D, Ades AE, Welton NJ (2009). “Addressing -study heterogeneity inconsistency mixed treatment comparisons: Application stroke prevention treatments individuals non-rheumatic atrial fibrillation.” Statistics Medicine, 28(14), 1861--1881. doi:10.1002/sim.3594 . van Valkenhoef G, Kuiper J (2016). gemtc: Network Meta-Analysis Using Bayesian Methods. R package version 0.8-2, https://CRAN.R-project.org/package=gemtc.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":null,"dir":"Reference","previous_headings":"","what":"BCG vaccination — bcg_vaccine","title":"BCG vaccination — bcg_vaccine","text":"Data frame containing results 13 trials comparing BCG vaccination vaccination preventing tuberculosis (TB) (Dias et al. 2011; Berkey et al. 1995) . numbers individuals diagnosed TB arm study follow-period recorded. absolute degrees latitude study conducted also recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BCG vaccination — bcg_vaccine","text":"","code":"bcg_vaccine"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"BCG vaccination — bcg_vaccine","text":"data frame 26 rows 6 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name latitude absolute degrees latitude r number diagnosed TB n sample size","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"BCG vaccination — bcg_vaccine","text":"Berkey CS, Hoaglin DC, Mosteller F, Colditz GA (1995). “random-effects regression model meta-analysis.” Statistics Medicine, 14(4), 395--411. doi:10.1002/sim.4780140406 . Dias S, Sutton AJ, Welton NJ, Ades AE (2011). “NICE DSU Technical Support Document 3: Heterogeneity: subgroups, meta-regression, bias bias-adjustment.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":null,"dir":"Reference","previous_headings":"","what":"Beta blockers to prevent mortality after MI — blocker","title":"Beta blockers to prevent mortality after MI — blocker","text":"Data frame containing number deaths 22 trials comparing beta blockers vs. control preventing mortality myocardial infarction (Carlin 1992; Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Beta blockers to prevent mortality after MI — blocker","text":"","code":"blocker"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Beta blockers to prevent mortality after MI — blocker","text":"data frame 44 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Beta blockers to prevent mortality after MI — blocker","text":"Carlin JB (1992). “Meta-analysis 2 x 2 tables: bayesian approach.” Statistics Medicine, 11(2), 141--158. doi:10.1002/sim.4780110202 . Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine multiple data sources into one network — combine_network","title":"Combine multiple data sources into one network — combine_network","text":"Multiple data sources created using set_ipd(), set_agd_arm(), set_agd_contrast() can combined single network analysis.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine multiple data sources into one network — combine_network","text":"","code":"combine_network(..., trt_ref)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine multiple data sources into one network — combine_network","text":"... multiple data sources, defined using set_* functions trt_ref reference treatment entire network, string (coerced ) referring levels treatment factor variable","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine multiple data sources into one network — combine_network","text":"object class nma_data","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine multiple data sources into one network — combine_network","text":"","code":"## Parkinson's - combining contrast- and arm-based data studies <- parkinsons$studyn (parkinsons_arm <- parkinsons[studies %in% 1:3, ]) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718 #> 7      3    4 -1.20 0.478  81 -0.90   0.695 (parkinsons_contr <- parkinsons[studies %in% 4:7, ]) #>    studyn trtn     y    se   n  diff se_diff #> 8       4    3 -0.24 0.265 128    NA   0.265 #> 9       4    4 -0.59 0.354  72 -0.35   0.442 #> 10      5    3 -0.73 0.335  80    NA   0.335 #> 11      5    4 -0.18 0.442  46  0.55   0.555 #> 12      6    4 -2.20 0.197 137    NA   0.197 #> 13      6    5 -2.50 0.190 131 -0.30   0.274 #> 14      7    4 -1.80 0.200 154    NA   0.200 #> 15      7    5 -2.10 0.250 143 -0.30   0.320  park_arm_net <- set_agd_arm(parkinsons_arm,                             study = studyn,                             trt = trtn,                             y = y,                             se = se,                             sample_size = n)  park_contr_net <- set_agd_contrast(parkinsons_contr,                                    study = studyn,                                    trt = trtn,                                    y = diff,                                    se = se_diff,                                    sample_size = n)  park_net <- combine_network(park_arm_net, park_contr_net)  # Print network details park_net #> A network with 3 AgD studies (arm-based), and 4 AgD studies (contrast-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  #>  Outcome type: continuous #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected  # Plot network plot(park_net, weight_edges = TRUE, weight_nodes = TRUE)   ## Plaque Psoriasis - combining IPD and AgD in a network # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected   # Plot network plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Set default values — .default","title":"Set default values — .default","text":".default() function used internally mark certain values default, user may notified default values used. example, choosing default reference treatment network, using default prior distributions. function .is_default() checks whether argument/object set default value. Neither functions intended called user.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set default values — .default","text":"","code":".default(x = list())  .is_default(x)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set default values — .default","text":"x object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set default values — .default","text":".default(), identical object additional attribute .default. .is_default(), logical value (TRUE FALSE).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":null,"dir":"Reference","previous_headings":"","what":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"Data frame containing number new cases diabetes 22 trials 6 antihypertensive drugs (Elliott Meyer 2007; Dias et al. 2011) . trial duration (years) also recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"","code":"diabetes"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"data frame 48 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name r total number events n total number individuals time trial follow-(years)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Elliott WJ, Meyer PM (2007). “Incident diabetes clinical trials antihypertensive drugs: network meta-analysis.” Lancet, 369(9557), 201--207. doi:10.1016/s0140-6736(07)60108-1 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Deviance Information Criterion (DIC) — dic","title":"Deviance Information Criterion (DIC) — dic","text":"Calculate DIC model fitted using nma() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deviance Information Criterion (DIC) — dic","text":"","code":"dic(x, penalty = c(\"pD\", \"pV\"), ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deviance Information Criterion (DIC) — dic","text":"x fitted model object, inheriting class stan_nma penalty method estimating effective number parameters, used penalise model fit DIC. Either \"pD\" (default), \"pV\". survival likelihoods \"pV\" currently available. ... arguments (used)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deviance Information Criterion (DIC) — dic","text":"nma_dic object.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deviance Information Criterion (DIC) — dic","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking FE NMA example if not already available if (!exists(\"smk_fit_FE\")) example(\"example_smk_fe\", run.donttest = TRUE) # } # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC of FE and RE models (smk_dic_FE <- dic(smk_fit_FE)) #> Residual deviance: 266.9 (on 50 data points) #>                pD: 26.7 #>               DIC: 293.6 (smk_dic_RE <- dic(smk_fit_RE))   # substantially better fit #> Residual deviance: 54.5 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.8  # Plot residual deviance contributions under RE model plot(smk_dic_RE)   # Check for inconsistency using UME model # } # \\donttest{ # Run smoking UME NMA example if not already available if (!exists(\"smk_fit_RE_UME\")) example(\"example_smk_ume\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC smk_dic_RE #> Residual deviance: 54.5 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.8 (smk_dic_RE_UME <- dic(smk_fit_RE_UME))  # no difference in fit #> Residual deviance: 54 (on 50 data points) #>                pD: 45 #>               DIC: 99  # Compare residual deviance contributions plot(smk_dic_RE, smk_dic_RE_UME, show_uncertainty = FALSE)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduced dietary fat to prevent mortality — dietary_fat","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"Data frame containing number deaths person-years risk 10 trials comparing reduced fat diets vs. control (non-reduced fat diet) preventing mortality (Hooper et al. 2000; Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"","code":"dietary_fat"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"data frame 21 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name r number events n number randomised E person-years risk","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Hooper L, Summerbell CD, Higgins JPT, Thompson RL, Clements G, Capps N, Davey Smith G, Riemersma R, Ebrahim S (2000). “Reduced modified dietary fat preventing cardiovascular disease.” Cochrane Database Systematic Reviews. ISSN 1465-1858, doi:10.1002/14651858.CD002137 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":null,"dir":"Reference","previous_headings":"","what":"Specify a general marginal distribution — distr","title":"Specify a general marginal distribution — distr","text":"distr() used within function add_integration() specify marginal distributions covariates, via corresponding inverse CDF. also used predict.stan_nma() specify distribution baseline response (intercept) predicting absolute outcomes.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specify a general marginal distribution — distr","text":"","code":"distr(qfun, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specify a general marginal distribution — distr","text":"qfun inverse CDF, either function name string ... parameters distribution arguments qfun, quoted evaluated later context aggregate data sources","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specify a general marginal distribution — distr","text":"object class distr.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Specify a general marginal distribution — distr","text":"function qfun formal argument called p. restriction serves crude check inverse CDFs (e.g. error given dnorm used instead qnorm). user-written CDF supplied, must argument p takes vector probabilities.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Specify a general marginal distribution — distr","text":"","code":"## Specifying marginal distributions for integration  df <- data.frame(x1_mean = 2, x1_sd = 0.5, x2 = 0.8)  # Distribution parameters are evaluated in the context of the data frame add_integration(df,                 x1 = distr(qnorm, mean = x1_mean, sd = x1_sd),                 x2 = distr(qbern, prob = x2),                 cor = diag(2)) #> # A tibble: 1 × 5 #>   x1_mean x1_sd    x2 .int_x1    .int_x2    #>     <dbl> <dbl> <dbl> <list>     <list>     #> 1       2   0.5   0.8 <dbl [64]> <dbl [64]>"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalised Student's t distribution (with location and scale) — dgent","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"Density, distribution, quantile function generalised t distribution degrees freedom df, shifted location scaled scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"","code":"dgent(x, df, location = 0, scale = 1)  pgent(q, df, location = 0, scale = 1)  qgent(p, df, location = 0, scale = 1)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"x, q Vector quantiles df Degrees freedom, greater zero location Location parameter scale Scale parameter, greater zero p Vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"dgent() gives density, pgent() gives distribution function, qgent() gives quantile function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":null,"dir":"Reference","previous_headings":"","what":"Kaplan-Meier curves of survival data — geom_km","title":"Kaplan-Meier curves of survival data — geom_km","text":"helper function constructs ggplot2 geom plot Kaplan-Meier curves network containing survival time--event outcomes. useful overlaying \"raw\" survival data estimated survival functions created plotted plot.surv_nma_summary(), can also used standalone plot Kaplan-Meier curves fitting model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kaplan-Meier curves of survival data — geom_km","text":"","code":"geom_km(   network,   ...,   transform = c(\"identity\", \"cloglog\", \"log\", \"cumhaz\"),   curve_args = list(),   cens_args = list() )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kaplan-Meier curves of survival data — geom_km","text":"network nma_data network object containing survival outcomes ... Additional arguments passed survival::survfit() transform Character string giving transformation apply KM curves plotting. default \"identity\" transformation; options \"cloglog\" \\(\\log(-\\log(S))\\), \"log\" \\(\\log(S)\\), \"cumhaz\" cumulative hazard \\(-\\log(S)\\). curve_args Optional list arguments customise curves plotted ggplot2::geom_step() cens_args Optional list arguments customise censoring marks plotted ggplot2::geom_point()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kaplan-Meier curves of survival data — geom_km","text":"ggplot2 geom list can added ggplot2 plot object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kaplan-Meier curves of survival data — geom_km","text":"","code":"# Set up newly-diagnosed multiple myeloma network  head(ndmm_ipd) #>          study trt       studyf trtf      age iss_stage3 response_cr_vgpr male #> 1 McCarthy2012 Pbo McCarthy2012  Pbo 50.81625          0                1    0 #> 2 McCarthy2012 Pbo McCarthy2012  Pbo 62.18165          0                0    0 #> 3 McCarthy2012 Pbo McCarthy2012  Pbo 51.53762          1                1    1 #> 4 McCarthy2012 Pbo McCarthy2012  Pbo 46.74128          0                1    1 #> 5 McCarthy2012 Pbo McCarthy2012  Pbo 62.62561          0                1    1 #> 6 McCarthy2012 Pbo McCarthy2012  Pbo 49.24520          1                1    0 #>   eventtime status #> 1 31.106516      1 #> 2  3.299623      0 #> 3 57.400000      0 #> 4 57.400000      0 #> 5 57.400000      0 #> 6 30.714460      0 head(ndmm_agd) #>        study     studyf trt trtf eventtime status #> 1 Morgan2012 Morgan2012 Pbo  Pbo  18.72575      1 #> 2 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 3 Morgan2012 Morgan2012 Pbo  Pbo  34.35726      1 #> 4 Morgan2012 Morgan2012 Pbo  Pbo  10.77826      1 #> 5 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 6 Morgan2012 Morgan2012 Pbo  Pbo  14.52966      1  ndmm_net <- combine_network(   set_ipd(ndmm_ipd,           study, trt,           Surv = Surv(eventtime / 12, status)),   set_agd_surv(ndmm_agd,                study, trt,                Surv = Surv(eventtime / 12, status),                covariates = ndmm_agd_covs)) # Plot KM curves using ggplot2 library(ggplot2)  # We need to create an empty ggplot object to add the curves to ggplot() + geom_km(ndmm_net)   # Adding plotting options, facets, axis labels, and a plot theme ggplot() +   geom_km(ndmm_net,           curve_args = list(linewidth = 0.5),           cens_args = list(size = 3, shape = 124)) +   facet_wrap(vars(Study)) +   labs(xlab = \"Time\", ylab = \"Survival Probability\") +   theme_multinma()   # Using the transform argument to produce log-log plots (e.g. to assess the # proportional hazards assumption) ggplot() +   geom_km(ndmm_net, transform = \"cloglog\") +   facet_wrap(vars(Study)) +   theme_multinma()   # Using the transform argument to produce cumulative hazard plots ggplot() +   geom_km(ndmm_net, transform = \"cumhaz\") +   facet_wrap(vars(Study)) +   theme_multinma()   # This function can also be used to add KM data to plots of estimated survival # curves from a fitted model, in a similar manner # \\donttest{ # Run newly-diagnosed multiple myeloma example if not already available if (!exists(\"ndmm_fit\")) example(\"example_ndmm\", run.donttest = TRUE) # } # Plot estimated survival curves, and overlay the KM data # \\donttest{ plot(predict(ndmm_fit, type = \"survival\")) + geom_km(ndmm_net)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":null,"dir":"Reference","previous_headings":"","what":"Direct and indirect evidence — get_nodesplits","title":"Direct and indirect evidence — get_nodesplits","text":"Determine whether two treatments network connected direct /indirect evidence, generate list comparisons direct indirect evidence (.e. potential inconsistency) node-splitting.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Direct and indirect evidence — get_nodesplits","text":"","code":"get_nodesplits(network, include_consistency = FALSE)  has_direct(network, trt1, trt2)  has_indirect(network, trt1, trt2)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Direct and indirect evidence — get_nodesplits","text":"network nma_data object, created functions set_*() combine_network(). include_consistency Logical, whether include row NAs indicate consistency model (.e. model node-splitting) also fitted nma() function. Default FALSE calling get_nodesplits() hand, nma() sets TRUE default. trt1, trt2 Treatments, single integer, string, factor","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Direct and indirect evidence — get_nodesplits","text":"has_direct() has_indirect(), single logical value. get_nodesplits(), data frame two columns giving comparisons node-splitting.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Direct and indirect evidence — get_nodesplits","text":"list comparisons node-splitting generated following algorithm van Valkenhoef et al. (2016) . comparison two treatments potential inconsistency, thus considered node-splitting, comparison direct evidence independent indirect evidence. notion independent indirect evidence necessary multi-arm trials present, since design trials internally consistent. comparison two treatments independent indirect evidence , removing studies comparing two treatments network, two treatments still connected path evidence. criterion considered has_indirect() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Direct and indirect evidence — get_nodesplits","text":"van Valkenhoef G, Dias S, Ades AE, Welton NJ (2016). “Automated generation node-splitting models assessment inconsistency network meta-analysis.” Research Synthesis Methods, 7(1), 80--93. doi:10.1002/jrsm.1167 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Direct and indirect evidence — get_nodesplits","text":"","code":"# Parkinsons example park_net <- set_agd_arm(parkinsons,                         study = studyn,                         trt = trtn,                         y = y,                         se = se,                         trt_ref = 1) #> Note: Optional argument `sample_size` not provided, some features may not be available (see ?set_agd_arm).  # View the network plot plot(park_net)   # The 4 vs. 5 comparison is a spur on the network has_direct(park_net, 4, 5) #> [1] TRUE has_indirect(park_net, 4, 5) #> [1] FALSE  # 1 and 5 are not directly connected has_direct(park_net, 1, 5) #> [1] FALSE has_indirect(park_net, 1, 5) #> [1] TRUE  # The 1 vs. 2 comparison does not have independent indirect evidence, since # the 1-2-4 loop is a multi-arm study has_indirect(park_net, 1, 2) #> [1] FALSE  # Get a list of comparisons with potential inconsistency for node-splitting get_nodesplits(park_net) #> # A tibble: 4 × 2 #>   trt1  trt2  #>   <fct> <fct> #> 1 1     3     #> 2 1     4     #> 3 2     4     #> 4 3     4      # See van Valkenhoef (2016) for a discussion of this example"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert networks to graph objects — as.igraph.nma_data","title":"Convert networks to graph objects — as.igraph.nma_data","text":"method .igraph() converts nma_data objects form used igraph package. method as_tbl_graph() converts nma_data objects form used ggraph tidygraph packages.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert networks to graph objects — as.igraph.nma_data","text":"","code":"# S3 method for nma_data as.igraph(x, ..., collapse = TRUE)  # S3 method for nma_data as_tbl_graph(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert networks to graph objects — as.igraph.nma_data","text":"x nma_data object convert ... Additional arguments collapse Logical, collapse edges studies? Default TRUE, one edge produced comparison (IPD AgD study type) .nstudy attribute giving number studies making comparison. FALSE, repeated edges added study making comparison.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert networks to graph objects — as.igraph.nma_data","text":"igraph object .igraph(), tbl_graph object as_tbl_graph().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert networks to graph objects — as.igraph.nma_data","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # Convert to igraph object igraph::as.igraph(smk_net)  # Edges combined by default #> IGRAPH 4a8d0c2 UN-- 4 6 --  #> + attr: name (v/c), .sample_size (v/n), .nstudy (e/n), .type (e/c) #> + edges from 4a8d0c2 (vertex names): #> [1] No intervention       --Group counselling      #> [2] No intervention       --Individual counselling #> [3] Group counselling     --Individual counselling #> [4] No intervention       --Self-help              #> [5] Group counselling     --Self-help              #> [6] Individual counselling--Self-help              igraph::as.igraph(smk_net, collapse = FALSE)  # Without combining edges #> IGRAPH 6741d7c UN-- 4 28 --  #> + attr: name (v/c), .sample_size (v/n), .study (e/c), .type (e/c) #> + edges from 6741d7c (vertex names): #>  [1] No intervention       --Group counselling      #>  [2] No intervention       --Individual counselling #>  [3] Group counselling     --Individual counselling #>  [4] Group counselling     --Individual counselling #>  [5] Group counselling     --Self-help              #>  [6] Individual counselling--Self-help              #>  [7] No intervention       --Individual counselling #>  [8] No intervention       --Individual counselling #> + ... omitted several edges  # Convert to tbl_graph object tidygraph::as_tbl_graph(smk_net)  # Edges combined by default #> # A tbl_graph: 4 nodes and 6 edges #> # #> # An undirected simple graph with 1 component #> # #> # Node Data: 4 × 2 (active) #>   name                   .sample_size #>   <chr>                         <dbl> #> 1 No intervention                7231 #> 2 Group counselling               555 #> 3 Individual counselling         7383 #> 4 Self-help                      1571 #> # #> # Edge Data: 6 × 4 #>    from    to .nstudy .type #>   <int> <int>   <int> <chr> #> 1     1     2       2 AgD   #> 2     1     3      15 AgD   #> 3     2     3       4 AgD   #> # ℹ 3 more rows tidygraph::as_tbl_graph(smk_net, collapse = FALSE)  # Without combining edges #> # A tbl_graph: 4 nodes and 28 edges #> # #> # An undirected multigraph with 1 component #> # #> # Node Data: 4 × 2 (active) #>   name                   .sample_size #>   <chr>                         <dbl> #> 1 No intervention                7231 #> 2 Group counselling               555 #> 3 Individual counselling         7383 #> 4 Self-help                      1571 #> # #> # Edge Data: 28 × 4 #>    from    to .study .type #>   <int> <int> <chr>  <chr> #> 1     1     2 1      AgD   #> 2     1     3 1      AgD   #> 3     2     3 1      AgD   #> # ℹ 25 more rows"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":null,"dir":"Reference","previous_headings":"","what":"HTA Plaque Psoriasis — hta_psoriasis","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"Data frame containing results 16 trials comparing 8 treatments moderate--severe plaque psoriasis HTA report (Woolacott et al. 2006) , analysed TSD2 (Dias et al. 2011) . Outcomes success/failure achieve 50%, 75%, 90% reduction symptoms Psoriasis Area Severity Index (PASI) scale. studies report three ordered outcomes, others one two. latter coded missing values (see details).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"","code":"hta_psoriasis"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"data frame 36 rows 9 variables: studyn numeric study ID studyc study name year year publication trtn numeric treatment code trtc treatment name sample_size sample size arm PASI50, PASI75, PASI90 ordered multinomial outcome counts (exclusive, see details)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"Outcome counts \"exclusive\"; , study reporting outcomes, counts represent categories 50 < PASI < 75, 75 < PASI < 90, 90 < PASI < 100, named lower end interval. (opposed \"inclusive\" counts, represent overlapping categories PASI > 50, PASI > 70, PASI > 90.) count fourth category (lowest), 0 < PASI < 50, equal sample_size - PASI50 - PASI75 - PASI90. Missing values used studies report subset outcomes. study reporting two outcomes, say 50 75, counts represent 50 < PASI < 75 75 < PASI < 100. study reporting one outcome, say PASI 75, count represents 75 < PASI < 100.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Woolacott N, Hawkins N, Mason , Kainth , Khadjesari Z, Bravo Vergel Y, Misso K, Light K, Chalmers R, Sculpher M, Riemsma R (2006). “Etanercept efalizumab treatment psoriasis: systematic review.” Health Technology Assessment, 10(46). doi:10.3310/hta10460 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":null,"dir":"Reference","previous_headings":"","what":"Check network connectedness — is_network_connected","title":"Check network connectedness — is_network_connected","text":"Check whether network connected - whether path study evidence linking every pair treatments network.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check network connectedness — is_network_connected","text":"","code":"is_network_connected(network)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check network connectedness — is_network_connected","text":"network nma_data object, created functions set_*() combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check network connectedness — is_network_connected","text":"Logical TRUE FALSE","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check network connectedness — is_network_connected","text":"Models still run disconnected networks. However, estimated relative effects treatments across disconnected parts network entirely based prior distribution (typically uncertain), information update prior distribution. Relative effects within connected sub-network estimated sub-network analysed separately.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check network connectedness — is_network_connected","text":"","code":"## Smoking cessation # Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  is_network_connected(smk_net)  # TRUE, network is connected #> [1] TRUE ## A disconnected network disc_net <- set_agd_arm(smoking[smoking$studyn %in% c(15, 21), ],                         study = studyn,                         trt = trtc,                         r = r,                         n = n) is_network_connected(disc_net)  # FALSE, network is disconnected #> [1] FALSE disc_net #> A network with 2 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                         #>  15    2: Group counselling | No intervention #>  21    2: Individual counselling | Self-help  #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 2 #> Reference treatment is: Group counselling #> Network is disconnected plot(disc_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Student's t distribution — dlogt","title":"Log Student's t distribution — dlogt","text":"Density, distribution, quantile function log t distribution, whose logarithm degrees freedom df, mean location, standard deviation scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Student's t distribution — dlogt","text":"","code":"dlogt(x, df, location = 0, scale = 1)  plogt(q, df, location = 0, scale = 1)  qlogt(p, df, location = 0, scale = 1)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Student's t distribution — dlogt","text":"x, q Vector quantiles df Degrees freedom, greater zero location Location parameter scale Scale parameter, greater zero p Vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Student's t distribution — dlogt","text":"dlogt() gives density, plogt() gives distribution function, qlogt() gives quantile function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log Student's t distribution — dlogt","text":"\\(\\log(Y) \\sim t_\\nu(\\mu, \\sigma^2)\\), \\(Y\\) log t distribution location \\(\\mu\\), scale \\(\\sigma\\), df \\(\\nu\\). mean higher moments log t distribution undefined infinite. df = 1 distribution log Cauchy distribution. df tends infinity, approaches log Normal distribution.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":null,"dir":"Reference","previous_headings":"","what":"The logit Normal distribution — qlogitnorm","title":"The logit Normal distribution — qlogitnorm","text":"provide convenient extensions [dpq]logitnorm functions package logitnorm, allow distribution specified terms mean standard deviation, instead logit-mean logit-sd.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The logit Normal distribution — qlogitnorm","text":"","code":"qlogitnorm(p, mu = 0, sigma = 1, ..., mean, sd)  dlogitnorm(x, mu = 0, sigma = 1, ..., mean, sd)  plogitnorm(q, mu = 0, sigma = 1, ..., mean, sd)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The logit Normal distribution — qlogitnorm","text":"p, x vector quantiles mu, sigma, ... see logitnorm mean, sd mean standard deviation, overriding mu sigma specified q vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":null,"dir":"Reference","previous_headings":"","what":"Model comparison using the loo package — loo.stan_nma","title":"Model comparison using the loo package — loo.stan_nma","text":"loo() waic() functions loo package may called directly stan_nma stan_mlnmr objects.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model comparison using the loo package — loo.stan_nma","text":"","code":"# S3 method for stan_nma loo(x, ...)  # S3 method for stan_nma waic(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model comparison using the loo package — loo.stan_nma","text":"x object class stan_nma stan_mlnmr ... arguments loo() waic()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/make_knots.html","id":null,"dir":"Reference","previous_headings":"","what":"Knot locations for M-spline baseline hazard models — make_knots","title":"Knot locations for M-spline baseline hazard models — make_knots","text":"Several different algorithms provided calculate knot locations M-spline baseline hazard models. function called internally within nma() function, may called directly user control.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/make_knots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Knot locations for M-spline baseline hazard models — make_knots","text":"","code":"make_knots(   network,   n_knots = 7,   type = c(\"quantile\", \"quantile_common\", \"quantile_lumped\", \"quantile_longest\", \"equal\",     \"equal_common\") )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/make_knots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Knot locations for M-spline baseline hazard models — make_knots","text":"network network object, containing survival outcomes n_knots Non-negative integer giving number internal knots (default 7) type String specifying knot location algorithm use (see details). default used nma() \"quantile\", except regression model specified (using aux_regression) case default \"quantile_common\".","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/make_knots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Knot locations for M-spline baseline hazard models — make_knots","text":"named list vectors giving knot locations study.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/make_knots.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Knot locations for M-spline baseline hazard models — make_knots","text":"type argument can used choose different algorithms placing knots: \"quantile\" Creates separate knot locations study, internal knots placed evenly-spaced quantiles observed event times within study. \"quantile_lumped\" Creates common set knots studies, calculated evenly-spaced quantiles observed event times studies lumped together. \"quantile_common\" Creates common set knots studies, taking quantiles quantiles observed event times within study. often seems result even knot spacing \"quantile_lumped\", particularly follow-uneven across studies, may handle differing behaviour baseline hazard across studies better \"quantile_longest\". \"quantile_longest\" Creates common set knots studies, using evenly-spaced quantiles observed event times longest study. \"equal\" Creates separate knot locations study, evenly-spaced times boundary knots study. \"equal_common\" Creates common set knots studies, evenly-spaced times earliest entry time last event/censoring time network. Boundary knots calculated follows: separate knot locations study, boundary knots placed earliest entry time last event/censoring time study. common set knots across studies, boundary knots placed earliest entry time last event/censoring time across studies. Models regression spline coefficients (.e. aux_regression specified) require common set knots across studies. Provided sufficient number knots used, model fit largely unaffected knot locations. However, sampling difficulties can sometimes occur knot placement poor, example knot placed just last follow-time study.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/make_knots.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Knot locations for M-spline baseline hazard models — make_knots","text":"","code":"# Set up newly-diagnosed multiple myeloma network  head(ndmm_ipd) #>          study trt       studyf trtf      age iss_stage3 response_cr_vgpr male #> 1 McCarthy2012 Pbo McCarthy2012  Pbo 50.81625          0                1    0 #> 2 McCarthy2012 Pbo McCarthy2012  Pbo 62.18165          0                0    0 #> 3 McCarthy2012 Pbo McCarthy2012  Pbo 51.53762          1                1    1 #> 4 McCarthy2012 Pbo McCarthy2012  Pbo 46.74128          0                1    1 #> 5 McCarthy2012 Pbo McCarthy2012  Pbo 62.62561          0                1    1 #> 6 McCarthy2012 Pbo McCarthy2012  Pbo 49.24520          1                1    0 #>   eventtime status #> 1 31.106516      1 #> 2  3.299623      0 #> 3 57.400000      0 #> 4 57.400000      0 #> 5 57.400000      0 #> 6 30.714460      0 head(ndmm_agd) #>        study     studyf trt trtf eventtime status #> 1 Morgan2012 Morgan2012 Pbo  Pbo  18.72575      1 #> 2 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 3 Morgan2012 Morgan2012 Pbo  Pbo  34.35726      1 #> 4 Morgan2012 Morgan2012 Pbo  Pbo  10.77826      1 #> 5 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 6 Morgan2012 Morgan2012 Pbo  Pbo  14.52966      1  ndmm_net <- combine_network(   set_ipd(ndmm_ipd,           study, trt,           Surv = Surv(eventtime / 12, status)),   set_agd_surv(ndmm_agd,                study, trt,                Surv = Surv(eventtime / 12, status),                covariates = ndmm_agd_covs))  # The default knot locations make_knots(ndmm_net, type = \"quantile\") #> $Attal2012 #>               12.5%       25%     37.5%       50%     62.5%       75%     87.5%  #> 0.0000000 0.5934115 0.9482775 1.3534460 1.7149769 2.1791543 2.6156006 3.3067856  #>            #> 4.0144924  #>  #> $Jackson2019 #>               12.5%       25%     37.5%       50%     62.5%       75%     87.5%  #> 0.0000000 0.3764953 0.7013167 1.1208075 1.6061797 2.1894017 3.0797028 4.3685050  #>            #> 6.3743523  #>  #> $McCarthy2012 #>             12.5%      25%    37.5%      50%    62.5%      75%    87.5%  #> 0.000000 0.706951 1.051770 1.519605 2.067261 2.791005 3.383530 4.231690  #>           #> 5.833333  #>  #> $Morgan2012 #>               12.5%       25%     37.5%       50%     62.5%       75%     87.5%  #> 0.0000000 0.2730038 0.5063235 0.7761775 1.0551856 1.5629825 2.2663204 3.2201496  #>            #> 5.4000000  #>  #> $Palumbo2014 #>               12.5%       25%     37.5%       50%     62.5%       75%     87.5%  #> 0.0000000 0.3154367 0.5906098 0.9345159 1.1814523 1.7505439 2.1409332 3.1120086  #>            #> 4.5438931  #>   # Increasing the number of knots make_knots(ndmm_net, n_knots = 10) #> $Attal2012 #>           9.090909% 18.18182% 27.27273% 36.36364% 45.45455% 54.54545% 63.63636%  #> 0.0000000 0.4855970 0.7296991 1.0274442 1.3229218 1.5913659 1.9091936 2.2146202  #> 72.72727% 81.81818% 90.90909%            #> 2.4965883 2.9410168 3.5442040 4.0144924  #>  #> $Jackson2019 #>           9.090909% 18.18182% 27.27273% 36.36364% 45.45455% 54.54545% 63.63636%  #> 0.0000000 0.2850731 0.5160902 0.7852926 1.0889435 1.3955587 1.7796685 2.2724055  #> 72.72727% 81.81818% 90.90909%            #> 2.9445333 3.7260169 4.8115468 6.3743523  #>  #> $McCarthy2012 #>           9.090909% 18.18182% 27.27273% 36.36364% 45.45455% 54.54545% 63.63636%  #> 0.0000000 0.6217270 0.8054827 1.0820339 1.4854471 1.9165108 2.3385167 2.8373237  #> 72.72727% 81.81818% 90.90909%            #> 3.2475317 3.7700213 4.6931830 5.8333333  #>  #> $Morgan2012 #>           9.090909% 18.18182% 27.27273% 36.36364% 45.45455% 54.54545% 63.63636%  #> 0.0000000 0.2299352 0.3643555 0.5569621 0.7645674 0.9472899 1.1902067 1.6232784  #> 72.72727% 81.81818% 90.90909%            #> 2.0964056 2.7050749 3.8072636 5.4000000  #>  #> $Palumbo2014 #>           9.090909% 18.18182% 27.27273% 36.36364% 45.45455% 54.54545% 63.63636%  #> 0.0000000 0.2956157 0.4023159 0.6263514 0.9276731 1.0267498 1.2797050 1.7917861  #> 72.72727% 81.81818% 90.90909%            #> 2.0366305 2.5784913 3.4007800 4.5438931  #>   # Comparing alternative knot positioning algorithms # Visualise these with a quick function plot_knots <- function(network, knots) {   ggplot2::ggplot() +     geom_km(network) +     ggplot2::geom_vline(ggplot2::aes(xintercept = .data$knot),                         data = tidyr::pivot_longer(as.data.frame(knots), cols = dplyr::everything(),                                                    names_to = \"Study\", values_to = \"knot\"),                         linetype = 2, colour = \"grey60\") +     ggplot2::facet_wrap(~Study) +     theme_multinma() }  plot_knots(ndmm_net, make_knots(ndmm_net, type = \"quantile\"))  plot_knots(ndmm_net, make_knots(ndmm_net, type = \"quantile_common\"))  plot_knots(ndmm_net, make_knots(ndmm_net, type = \"quantile_lumped\"))  plot_knots(ndmm_net, make_knots(ndmm_net, type = \"quantile_longest\"))  plot_knots(ndmm_net, make_knots(ndmm_net, type = \"equal\"))  plot_knots(ndmm_net, make_knots(ndmm_net, type = \"equal_common\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Working with 3D MCMC arrays — mcmc_array-class","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"3D MCMC arrays (Iterations, Chains, Parameters) produced .array() methods applied stan_nma nma_summary objects.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"","code":"# S3 method for mcmc_array summary(object, ..., probs = c(0.025, 0.25, 0.5, 0.75, 0.975))  # S3 method for mcmc_array print(x, ...)  # S3 method for mcmc_array plot(x, ...)  # S3 method for mcmc_array names(x)  # S3 method for mcmc_array names(x) <- value"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"... arguments passed methods probs Numeric vector quantiles interest x, object 3D MCMC array class mcmc_array value Character vector replacement parameter names","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"summary() method returns nma_summary object, print() method returns x invisibly. names() method returns character vector parameter names, names()<- returns object updated parameter names. plot() method shortcut plot(summary(x), ...), passing arguments plot.nma_summary().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Working with arrays of posterior draws (as mcmc_array objects) is # convenient when transforming parameters  # Transforming log odds ratios to odds ratios LOR_array <- as.array(relative_effects(smk_fit_RE)) OR_array <- exp(LOR_array)  # mcmc_array objects can be summarised to produce a nma_summary object smk_OR_RE <- summary(OR_array)  # This can then be printed or plotted smk_OR_RE #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling]      3.32 1.54 1.32 2.28 2.97 3.99  7.10     2243     2523 #> d[Individual counselling] 2.41 0.60 1.47 2.00 2.33 2.73  3.83     1190     2147 #> d[Self-help]              1.78 0.74 0.74 1.28 1.64 2.13  3.59     1897     2560 #>                           Rhat #> d[Group counselling]         1 #> d[Individual counselling]    1 #> d[Self-help]                 1 plot(smk_OR_RE, ref_line = 1)   # Transforming heterogeneity SD to variance tau_array <- as.array(smk_fit_RE, pars = \"tau\") tausq_array <- tau_array^2  # Correct parameter names names(tausq_array) <- \"tausq\"  # Summarise summary(tausq_array) #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq 0.72 0.33 0.29 0.49 0.65 0.87  1.52     1286     1830    1 # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":null,"dir":"Reference","previous_headings":"","what":"Distribution functions for M-spline baseline hazards — dmspline","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"Density, distribution, quantile, hazard, cumulative hazard, restricted mean survival time functions M-spline baseline hazards model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"","code":"dmspline(x, basis, scoef, rate, log = FALSE)  pmspline(q, basis, scoef, rate, lower.tail = TRUE, log.p = FALSE)  qmspline(p, basis, scoef, rate, lower.tail = TRUE, log.p = FALSE)  hmspline(x, basis, scoef, rate, log = FALSE)  Hmspline(x, basis, scoef, rate, log = FALSE)  rmst_mspline(t, basis, scoef, rate, start = 0)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"x, q Vector quantiles basis M-spline basis produced splines2::mSpline() scoef Vector (matrix) spline coefficients length (number columns) equal dimension basis rate Vector rate parameters log, log.p Logical; TRUE, probabilities p given \\(\\log(p)\\) lower.tail Logical; TRUE (default), probabilities \\(P(X \\le x)\\), otherwise \\(P(X > x)\\) p Vector probabilities t Vector times restricted mean survival time calculated start Optional left-truncation time times. returned restricted mean survival conditioned survival time","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"dmspline() gives density, pmspline() gives distribution function (CDF), qmspline() gives quantile function (inverse-CDF), hmspline() gives hazard function, Hmspline() gives cumulative hazard function, rmst_mspline() gives restricted mean survival times.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"Survival models flexible M-spline baseline hazard described Brilleman et al. (2020) . Piecewise-exponential baseline hazards special case degree M-spline polynomial 0. d/p/h/H functions calculated definitions. qmspline() uses numerical inversion via flexsurv::qgeneric(). rmst_mspline()uses numerical integration via flexsurv::rmst_generic(), except special case piecewise-exponential hazard (.e. degree 0 M-splines) uses explicit formula Royston Parmar (2013) . Beyond boundary knots, hazard assumed constant. (differs approach splines2::mSpline() extrapolates polynomial basis functions, numerically unstable highly dependent data just boundary knots.) extrapolation, care taken evaluating splines times beyond boundary knots (either directly d/p/h/H/rmst functions, indirectly requesting quantiles qmspline() correspond times beyond boundary knots). reason evaluating (unrestricted) mean survival time generally recommended requires integrating infinite time horizon (.e. rmst_mspline() t = Inf).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"Brilleman SL, Elci EM, Novik JB, Wolfe R (2020). “Bayesian Survival Analysis Using rstanarm R Package.” arXiv. doi:10.48550/arXiv.2002.09633 , 2002.09633. Royston P, Parmar MKB (2013). “Restricted mean survival time: alternative hazard ratio design analysis randomized trials time--event outcome.” BMC Medical Research Methodology, 13(1). doi:10.1186/1471-2288-13-152 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial outcome data — multi","title":"Multinomial outcome data — multi","text":"function aids specification multinomial outcome data setting network set_agd_arm() set_ipd(). takes set columns (, generally, numeric vectors length) outcome counts category, binds together produce matrix.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multinomial outcome data — multi","text":"","code":"multi(..., inclusive = FALSE, type = c(\"ordered\", \"competing\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multinomial outcome data — multi","text":"... Two numeric columns (vectors) category counts. Argument names (optional) used label categories. inclusive Logical, ordered category counts inclusive (TRUE) exclusive (FALSE)? Default FALSE. used type = \"ordered\". See details. type String, indicating whether categories \"ordered\" \"competing\". Currently ordered categorical outcomes supported modelling functions package.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multinomial outcome data — multi","text":"matrix (exclusive) category counts","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multinomial outcome data — multi","text":"specifying ordered categorical counts, can either given exclusive counts (inclusive = FALSE, default) individuals counted highest category achieve, inclusive counts (inclusive = TRUE) individuals counted every category including highest category achieved. (Competing outcomes, nature, always specified exclusive counts.) NA values can used indicate categories/cutpoints measured.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multinomial outcome data — multi","text":"","code":"# These two data sets specify the same ordered categorical data for outcomes # r0 < r1 < r2, but the first uses the \"inclusive\" format and the second the # \"exclusive\" format. df_inclusive <- tibble::tribble(~r0, ~r1, ~r2,                                 1, 1, 1,                                 5, 4, 1,                                 5, 2, 2,                                 10, 5, 0,                                 5, 5, 0,                                 7, NA, 6,   # Achieved r2 or not (no r1)                                 10, 4, NA)  # Achieved r1 or not (no r2)  df_exclusive <- tibble::tribble(~r0, ~r1, ~r2,                                 0, 0, 1,                                 1, 3, 1,                                 3, 0, 2,                                 5, 5, 0,                                 0, 5, 0,                                 1, NA, 6,   # Achieved r2 or not (no r1)                                 6, 4, NA)   # Achieved r1 or not (no r2)  (r_inclusive <- with(df_inclusive, multi(r0, r1, r2, inclusive = TRUE))) #>      r0 r1 r2 #> [1,]  0  0  1 #> [2,]  1  3  1 #> [3,]  3  0  2 #> [4,]  5  5  0 #> [5,]  0  5  0 #> [6,]  1 NA  6 #> [7,]  6  4 NA #> attr(,\"class\") #> [1] \"multi_ordered\" \"matrix\"        \"array\"         (r_exclusive <- with(df_exclusive, multi(r0, r1, r2, inclusive = FALSE))) #>      r0 r1 r2 #> [1,]  0  0  1 #> [2,]  1  3  1 #> [3,]  3  0  2 #> [4,]  5  5  0 #> [5,]  0  5  0 #> [6,]  1 NA  6 #> [7,]  6  4 NA #> attr(,\"class\") #> [1] \"multi_ordered\" \"matrix\"        \"array\"          # Counts are always stored in exclusive format stopifnot(isTRUE(all.equal(r_inclusive, r_exclusive)))   ## HTA Plaque Psoriasis library(dplyr)  # Ordered outcomes here are given as \"exclusive\" counts head(hta_psoriasis) #>   studyn   studyc year trtn             trtc sample_size PASI50 PASI75 PASI90 #> 1      1  Elewski 2004    1  Supportive care         193     12      5      1 #> 2      1  Elewski 2004    2 Etanercept 25 mg         196     59     46     21 #> 3      1  Elewski 2004    3 Etanercept 50 mg         194     54     56     40 #> 4      2 Gottlieb 2003    1  Supportive care          55      5      1      0 #> 5      2 Gottlieb 2003    2 Etanercept 25 mg          57     23     11      6 #> 6      3  Lebwohl 2003    1  Supportive care         122     13      5      1  # Calculate lowest category count (failure to achieve PASI 50) pso_dat <- hta_psoriasis %>%   mutate(`PASI<50` = sample_size - rowSums(cbind(PASI50, PASI75, PASI90), na.rm = TRUE))  # Set up network pso_net <- set_agd_arm(pso_dat,                        study = paste(studyc, year),                        trt = trtc,                        r = multi(`PASI<50`, PASI50, PASI75, PASI90,                                  inclusive = FALSE,                                  type = \"ordered\"))  pso_net #> A network with 16 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                           #>  ACD2058g 2004 2: Supportive care | Efalizumab                          #>  ACD2600g 2004 2: Supportive care | Efalizumab                          #>  Altmeyer 1994 2: Supportive care | Fumaderm                            #>  Chaudari 2001 2: Supportive care | Infliximab                          #>  Elewski 2004  3: Supportive care | Etanercept 25 mg | Etanercept 50 mg #>  Ellis 1991    3: Supportive care | Ciclosporin | Ciclosporin           #>  Gordon 2003   2: Supportive care | Efalizumab                          #>  Gottlieb 2003 2: Supportive care | Etanercept 25 mg                    #>  Gottlieb 2004 3: Supportive care | Infliximab | Infliximab             #>  Guenther 1991 2: Supportive care | Ciclosporin                         #>  ... plus 6 more studies #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 8 #> Total number of studies: 16 #> Reference treatment is: Supportive care #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":null,"dir":"Reference","previous_headings":"","what":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"R package performing network meta-analysis network meta-regression aggregate data, individual patient data, mixtures .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"Network meta-analysis (NMA) combines (aggregate) data multiple studies multiple treatments order produce consistent estimates relative treatment effects pair treatments network (Dias et al. 2011) . Network meta-regression (NMR) extends NMA include covariates, allowing adjustment differences effect-modifying variables studies (Dias et al. 2011) . NMR typically performed using aggregate data (AgD), lacks power prone ecological bias. NMR individual patient data (IPD) gold standard, data available. Multilevel network meta-regression (ML-NMR) allows IPD AgD incorporated together network meta-regression (Phillippo et al. 2020; Phillippo 2019) . IPD NMR, individual-level regression model defined. AgD studies fitted integrating individual-level model respective covariate distributions. correctly links two levels model (instead \"plugging \" mean covariate values), avoiding aggregation bias. Population-adjusted treatment effects (Phillippo et al. 2016)  can produced study population network, external target population. Models estimated Bayesian framework using Stan (Carpenter et al. 2017) . Quasi-Monte Carlo numerical integration based Sobol' sequences used integration ML-NMR models, Gaussian copula account correlations covariates (Phillippo et al. 2020; Phillippo 2019) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"getting-started","dir":"Reference","previous_headings":"","what":"Getting Started","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"good place start package vignettes walk example analyses, see vignette(\"vignette_overview\") overview. series NICE Technical Support Documents evidence synthesis gives detailed introduction network meta-analysis: Dias S, Welton NJ, Sutton AJ, Caldwell DM, Lu G, Reken S, Ades AE (2011). “NICE DSU Technical Support Documents 1-7: Evidence Synthesis Decision Making.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Multilevel network meta-regression set following methods paper: Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate\nData in Stan — multinma-package","text":"Carpenter B, Gelman , Hoffman MD, Lee D, Goodrich B, Betancourt M, Brubaker M, Guo J, Li P, Riddell (2017). “Stan: Probabilistic Programming Language.” Journal Statistical Software, 76(1). doi:10.18637/jss.v076.i01 . Dias S, Sutton AJ, Welton NJ, Ades AE (2011). “NICE DSU Technical Support Document 3: Heterogeneity: subgroups, meta-regression, bias bias-adjustment.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Phillippo DM (2019). Calibration Treatment Effects Network Meta-Analysis using Individual Patient Data. Ph.D. thesis, University Bristol. Available https://research-information.bris.ac.uk/. Phillippo DM, Ades AE, Dias S, Palmer S, Abrams KR, Welton NJ (2016). “NICE DSU Technical Support Document 18: Methods population-adjusted indirect comparisons submission NICE.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Newly diagnosed multiple myeloma — ndmm_ipd","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"Three data frames, ndmm_ipd, ndmm_agd, ndmm_agd_covs containing (simulated) individual patient data (IPD) three studies aggregate data (AgD) two studies newly diagnosed multiple myeloma. outcome interest progression-free survival autologous stem cell transplant. IPD studies ndmm_ipd provide event/censoring times covariate values individual. AgD studies provide reconstructed event/censoring times digitized Kaplan-Meier curves ndmm_agd covariate summaries ndmm_agd_covs, obtained published trial reports. data constructed resemble used Leahy Walsh (2019) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"","code":"ndmm_ipd  ndmm_agd  ndmm_agd_covs"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"individual patient data contained data frame ndmm_ipd 1325 rows, one per individual, 10 variables: study, studyf study name trt, trtf treatment name eventtime event/censoring time status censoring indicator (0 = censored, 1 = event) age age (years) iss_stage3 ISS stage 3 (0 = , 1 = yes) response_cr_vgpr complete good partial response (0 = , 1 = yes) male male sex (0 = , 1 = yes) reconstructed Kaplan-Meier data aggregate studies contained data frame ndmm_agd 2819 rows 6 variables: study, studyf study name trt, trtf treatment name eventtime event/censoring time status censoring indicator (0 = censored, 1 = event) covariate summaries extracted published reportes aggregate studies contained data frame ndmm_agd_covs 4 rows, one per study arm, 15 columns: study, studyf study name trt, trtf treatment name sample_size sample size arm age_min, age_iqr_l, age_median, age_iqr_h, age_max, age_mean, age_sd summary statistics age (years) iss_stage3 proportion participants ISS stage 3 response_cr_vgpr proportion participants complete good partial response male proportion male participants","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"Leahy J, Walsh C (2019). “Assessing impact matching-adjusted indirect comparison Bayesian network meta-analysis.” Research Synthesis Methods, 10(4), 546--568. doi:10.1002/jrsm.1372 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Network meta-analysis models — nma","title":"Network meta-analysis models — nma","text":"nma function fits network meta-analysis (multilevel) network meta-regression models Stan.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Network meta-analysis models — nma","text":"","code":"nma(   network,   consistency = c(\"consistency\", \"ume\", \"nodesplit\"),   trt_effects = c(\"fixed\", \"random\"),   regression = NULL,   class_interactions = c(\"common\", \"exchangeable\", \"independent\"),   likelihood = NULL,   link = NULL,   ...,   nodesplit = get_nodesplits(network, include_consistency = TRUE),   prior_intercept = .default(normal(scale = 100)),   prior_trt = .default(normal(scale = 10)),   prior_het = .default(half_normal(scale = 5)),   prior_het_type = c(\"sd\", \"var\", \"prec\"),   prior_reg = .default(normal(scale = 10)),   prior_aux = .default(),   prior_aux_reg = .default(),   aux_by = NULL,   aux_regression = NULL,   QR = FALSE,   center = TRUE,   adapt_delta = NULL,   int_thin = 0,   int_check = TRUE,   mspline_degree = 3,   n_knots = 7,   knots = NULL,   mspline_basis = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Network meta-analysis models — nma","text":"network nma_data object, created functions set_*(), combine_network(), add_integration() consistency Character string specifying type ()consistency model fit, either \"consistency\", \"ume\", \"nodesplit\" trt_effects Character string specifying either \"fixed\" \"random\" effects regression one-sided model formula, specifying prognostic effect-modifying terms regression model. references treatment use .trt special variable, example specifying effect modifier interactions variable:.trt (see details). class_interactions Character string specifying whether effect modifier interactions specified \"common\", \"exchangeable\", \"independent\". likelihood Character string specifying likelihood, unspecified inferred data (see details) link Character string specifying link function, unspecified default canonical link (see details) ... arguments passed sampling(), iter, chains, cores, etc. nodesplit consistency = \"nodesplit\", comparison(s) split node-splitting model(s). Either length 2 vector giving treatments single comparison, 2 column data frame listing multiple treatment comparisons split turn. default, possible comparisons chosen (see get_nodesplits()). prior_intercept Specification prior distribution intercept prior_trt Specification prior distribution treatment effects prior_het Specification prior distribution heterogeneity (trt_effects = \"random\") prior_het_type Character string specifying whether prior distribution prior_het placed heterogeneity standard deviation \\(\\tau\\) (\"sd\", default), variance \\(\\tau^2\\) (\"var\"), precision \\(1/\\tau^2\\) (\"prec\"). prior_reg Specification prior distribution regression coefficients (regression formula specified) prior_aux Specification prior distribution auxiliary parameter, applicable (see details). likelihood = \"gengamma\" list prior distributions elements sigma k. prior_aux_reg Specification prior distribution auxiliary regression parameters, aux_regression specified (see details). aux_by Vector variable names listing variables stratify auxiliary parameters . Currently used survival models, see details. used aux_regression. aux_regression one-sided model formula giving regression model auxiliary parameters. Currently used survival models, see details. used aux_by. QR Logical scalar (default FALSE), whether apply QR decomposition model design matrix center Logical scalar (default TRUE), whether center (numeric) regression terms overall means adapt_delta See adapt_delta details int_thin single integer value, thinning factor returning cumulative estimates integration error. Saving cumulative estimates disabled int_thin = 0, default. int_check Logical, check sufficient accuracy numerical integration fitting half chains n_int/2? TRUE, Rhat n_eff diagnostic warnings given numerical integration sufficiently converged (suggesting increasing n_int add_integration()). Default TRUE, disabled (FALSE) int_thin > 0. mspline_degree Non-negative integer giving degree M-spline polynomial likelihood = \"mspline\". Piecewise exponential hazards (likelihood = \"pexp\") special case mspline_degree = 0. n_knots mspline pexp likelihoods, non-negative integer giving number internal knots partitioning baseline hazard intervals. knot locations within study determined corresponding quantiles observed event times, plus boundary knots earliest entry time (0 delayed entry) maximum event/censoring time. example, n_knots = 3, internal knot locations 25%, 50%, 75% quantiles observed event times. default n_knots = 7; overfitting avoided shrinking towards constant hazard random walk prior (see details). aux_regression specified single set knot locations calculated across studies network. See make_knots() details knot positioning algorithms. Ignored knots specified. knots mspline pexp likelihoods, named list numeric vectors knot locations (including boundary knots) studies network. Currently, vector must length (.e. study must use number knots). Alternatively, single numeric vector knot locations can provided shared across studies network. unspecified (default), knots chosen based n_knots described . aux_regression specified knots single numeric vector knot locations shared across studies network. make_knots() can used help specify knots directly, investigate knot placement prior model fitting. mspline_basis Instead specifying mspline_degree n_knots knots, named list M-spline bases (one study) can provided mspline_basis used directly. case, M-spline options ignored.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Network meta-analysis models — nma","text":"nma() returns stan_nma object, except consistency = \"nodesplit\" nma_nodesplit nma_nodesplit_df object returned. nma.fit() returns stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Network meta-analysis models — nma","text":"specifying model formula regression argument, usual formula syntax available (interpreted model.matrix()). additional requirement special variable .trt used refer treatment. example, effect modifier interactions specified variable:.trt. Prognostic (main) effects interactions can included together compactly variable*.trt, expands variable + variable:.trt (plus .trt, already NMA model). advanced user, additional specials .study .trtclass also available, refer studies (specified) treatment classes respectively. node-splitting models fitted (consistency = \"nodesplit\") special .omega available, indicating arms node-splitting inconsistency factor added. See ?priors details prior specification. Default prior distributions available, may appropriate particular setting raise warning used. attempt made tailor defaults data provided. Please consider appropriate prior distributions particular setting, accounting scales outcomes covariates, etc. function plot_prior_posterior() may useful examining influence chosen prior distributions posterior distributions, summary() method nma_prior objects prints prior intervals.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"likelihoods-and-link-functions","dir":"Reference","previous_headings":"","what":"Likelihoods and link functions","title":"Network meta-analysis models — nma","text":"Currently, following likelihoods link functions supported data type: bernoulli2 binomial2 likelihoods correspond two-parameter Binomial likelihood arm-based AgD, closely matches underlying Poisson Binomial distribution summarised aggregate outcomes ML-NMR model typical (one parameter) Binomial distribution (see Phillippo et al. 2020) . cloglog link used, including offset log follow-time (.e. regression = ~offset(log(time))) results model log hazard (see Dias et al. 2011) . survival data, accelerated failure time models (exponential-aft, weibull-aft, lognormal, loglogistic, gamma, gengamma) parameterised treatment effects regression parameters log Survival Time Ratios (.e. coefficient \\(\\log(2)\\) means treatment covariate associated doubling expected survival time). can converted log Acceleration Factors using relation \\(\\log(\\mathrm{AF}) = -\\log(\\mathrm{STR})\\) (equivalently \\(\\mathrm{AF} = 1/\\mathrm{STR}\\)). details likelihood link function given Dias et al. (2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"auxiliary-parameters","dir":"Reference","previous_headings":"","what":"Auxiliary parameters","title":"Network meta-analysis models — nma","text":"Auxiliary parameters present following models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"normal-likelihood-with-ipd","dir":"Reference","previous_headings":"","what":"Normal likelihood with IPD","title":"Network meta-analysis models — nma","text":"Normal likelihood fitted IPD, auxiliary parameters arm-level standard deviations \\(\\sigma_{jk}\\) treatment \\(k\\) study \\(j\\).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"ordered-multinomial-likelihood","dir":"Reference","previous_headings":"","what":"Ordered multinomial likelihood","title":"Network meta-analysis models — nma","text":"fitting model \\(M\\) ordered outcomes, auxiliary parameters latent cutoffs category, \\(c_0 < c_1 < \\dots <   c_M\\). \\(c_2\\) \\(c_{M-1}\\) estimated; fix \\(c_0 =   -\\infty\\), \\(c_1 = 0\\), \\(c_M = \\infty\\). specifying priors latent cutoffs, choose specify priors differences \\(c_{m+1} - c_m\\). Stan automatically truncates priors ordering constraints satisfied.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"survival-time-to-event-likelihoods","dir":"Reference","previous_headings":"","what":"Survival (time-to-event) likelihoods","title":"Network meta-analysis models — nma","text":"survival likelihoods except exponential exponential-aft likelihoods auxiliary parameters. typically study-specific shape parameters \\(\\gamma_j>0\\), except lognormal likelihood auxiliary parameters study-specific standard deviations log scale \\(\\sigma_j>0\\). gengamma likelihood two sets auxiliary parameters, study-specific scale parameters \\(\\sigma_j>0\\) shape parameters \\(k_j\\), following parameterisation Lawless (1980) , permits range behaviours baseline hazard including increasing, decreasing, bathtub arc-shaped hazards. parameterisation related discussed Cox et al. (2007)  implemented flexsurv package \\(Q = k^{-0.5}\\). parameterisation used effectively bounds shape parameter \\(k\\) away numerical instabilities \\(k \\rightarrow \\infty\\) (.e. away \\(Q   \\rightarrow 0\\), log-Normal distribution) via prior distribution. Implicitly, parameterisation restricted \\(Q > 0\\) certain survival distributions like inverse-Gamma inverse-Weibull part parameter space; however, \\(Q > 0\\) still encompasses survival distributions implemented package. mspline pexp likelihoods, auxiliary parameters spline coefficients study. form unit simplex (.e. lie 0 1, sum 1), given random walk prior distribution. prior_aux specifies hyperprior random walk standard deviation \\(\\sigma\\) controls level smoothing baseline hazard, \\(\\sigma = 0\\) corresponding constant baseline hazard. auxiliary parameters can stratified additional factors aux_by argument. example, allow shape baseline hazard vary treatment arms well studies, use aux_by = c(\".study\", \".trt\"). (Technically, .study always included stratification even omitted aux_by, choose make stratification explicit.) common way relaxing proportional hazards assumption. default equivalent aux_by = \".study\" stratifies auxiliary parameters study, described . regression model may specified auxiliary parameters using aux_regression. useful wish model departures non-proportionality, rather allowing baseline hazards completely independent using aux_by. necessary absolute predictions (e.g. survival curves) required population unobserved combinations covariates; example, aux_by = .trt absolute predictions may produced observed treatment arms study population, whereas aux_regression = ~.trt absolute predictions can produced treatments population. mspline pexp likelihoods, regression coefficients smoothed time using random walk prior avoid overfitting: prior_aux_reg specifies hyperprior random walk standard deviation. parametric likelihoods, prior_aux_reg specifies prior auxiliary regression coefficients.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Network meta-analysis models — nma","text":"Cox C, Chu H, Schneider MF, Muñoz (2007). “Parametric survival analysis taxonomy hazard functions generalized gamma distribution.” Statistics Medicine, 26(23), 4352--4374. doi:10.1002/sim.2836 . Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Lawless JF (1980). “Inference Generalized Gamma Log Gamma Distributions.” Technometrics, 22(3), 409--419. doi:10.1080/00401706.1980.10486173 . Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189--1210. doi:10.1111/rssa.12579 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Network meta-analysis models — nma","text":"","code":"## Smoking cessation NMA # Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # \\donttest{ # Fitting a fixed effect model smk_fit_FE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100))  smk_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          0.84    0.00 0.17     0.50     0.72     0.84 #> d[Individual counselling]     0.76    0.00 0.06     0.65     0.73     0.76 #> d[Self-help]                  0.22    0.00 0.13    -0.02     0.14     0.22 #> lp__                      -5859.47    0.09 3.61 -5867.34 -5861.73 -5859.17 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          0.96     1.18  2604    1 #> d[Individual counselling]     0.80     0.88  2272    1 #> d[Self-help]                  0.31     0.47  2799    1 #> lp__                      -5856.87 -5853.25  1771    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:25:16 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\donttest{ # Fitting a random effects model smk_fit_RE <- nma(smk_net, refresh = if (interactive()) 200 else 0,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = normal(scale = 5))  smk_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          1.10    0.01 0.45     0.24     0.80     1.10 #> d[Individual counselling]     0.85    0.01 0.24     0.39     0.68     0.84 #> d[Self-help]                  0.49    0.01 0.41    -0.31     0.22     0.47 #> lp__                      -5768.03    0.21 6.57 -5781.57 -5772.26 -5767.82 #> tau                           0.85    0.01 0.19     0.54     0.72     0.82 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          1.39     1.99  2395    1 #> d[Individual counselling]     1.00     1.34  1416    1 #> d[Self-help]                  0.74     1.32  1898    1 #> lp__                      -5763.39 -5756.05   973    1 #> tau                           0.95     1.28  1177    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:25:23 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\donttest{ # Fitting an unrelated mean effects (inconsistency) model smk_fit_RE_UME <- nma(smk_net, refresh = if (interactive()) 200 else 0,                       consistency = \"ume\",                       trt_effects = \"random\",                       prior_intercept = normal(scale = 100),                       prior_trt = normal(scale = 100),                       prior_het = normal(scale = 5))  smk_fit_RE_UME #> A random effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                     mean se_mean   sd     2.5% #> d[Group counselling vs. No intervention]            1.10    0.02 0.81    -0.41 #> d[Individual counselling vs. No intervention]       0.90    0.01 0.27     0.39 #> d[Self-help vs. No intervention]                    0.37    0.01 0.57    -0.75 #> d[Individual counselling vs. Group counselling]    -0.30    0.01 0.61    -1.55 #> d[Self-help vs. Group counselling]                 -0.64    0.01 0.70    -2.04 #> d[Self-help vs. Individual counselling]             0.16    0.02 1.01    -1.91 #> lp__                                            -5765.51    0.20 6.43 -5779.08 #> tau                                                 0.92    0.01 0.22     0.58 #>                                                      25%      50%      75% #> d[Group counselling vs. No intervention]            0.57     1.05     1.61 #> d[Individual counselling vs. No intervention]       0.72     0.89     1.07 #> d[Self-help vs. No intervention]                    0.00     0.37     0.75 #> d[Individual counselling vs. Group counselling]    -0.68    -0.31     0.08 #> d[Self-help vs. Group counselling]                 -1.09    -0.65    -0.21 #> d[Self-help vs. Individual counselling]            -0.50     0.17     0.82 #> lp__                                            -5769.60 -5765.14 -5761.01 #> tau                                                 0.77     0.90     1.05 #>                                                    97.5% n_eff Rhat #> d[Group counselling vs. No intervention]            2.84  1873    1 #> d[Individual counselling vs. No intervention]       1.44  1110    1 #> d[Self-help vs. No intervention]                    1.50  1555    1 #> d[Individual counselling vs. Group counselling]     0.89  2370    1 #> d[Self-help vs. Group counselling]                  0.78  2368    1 #> d[Self-help vs. Individual counselling]             2.15  3500    1 #> lp__                                            -5753.93  1074    1 #> tau                                                 1.41  1167    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:25:31 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  # \\donttest{ # Fitting all possible node-splitting models smk_fit_RE_nodesplit <- nma(smk_net, refresh = if (interactive()) 200 else 0,                             consistency = \"nodesplit\",                             trt_effects = \"random\",                             prior_intercept = normal(scale = 100),                             prior_trt = normal(scale = 100),                             prior_het = normal(scale = 5)) #> Fitting model 1 of 7, node-split: Group counselling vs. No intervention #> Fitting model 2 of 7, node-split: Individual counselling vs. No intervention #> Fitting model 3 of 7, node-split: Self-help vs. No intervention #> Fitting model 4 of 7, node-split: Individual counselling vs. Group counselling #> Fitting model 5 of 7, node-split: Self-help vs. Group counselling #> Fitting model 6 of 7, node-split: Self-help vs. Individual counselling #> Fitting model 7 of 7, consistency model # }  # \\donttest{ # Summarise the node-splitting results summary(smk_fit_RE_nodesplit) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.11 0.43  0.29  0.81  1.10 1.39  1.95     1869     2494 1.00 #> d_dir            1.07 0.73 -0.30  0.59  1.06 1.53  2.59     3330     3240 1.00 #> d_ind            1.16 0.56  0.09  0.79  1.15 1.52  2.27     1599     2132 1.00 #> omega           -0.09 0.88 -1.75 -0.66 -0.11 0.49  1.71     2508     2577 1.00 #> tau              0.87 0.20  0.56  0.73  0.85 0.98  1.33     1156     1958 1.00 #> tau_consistency  0.84 0.18  0.55  0.71  0.82 0.94  1.28     1159     1955 1.01 #>  #> Residual deviance: 53.8 (on 50 data points) #>                pD: 44.1 #>               DIC: 97.8 #>  #> Bayesian p-value: 0.9 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.85 0.25  0.39  0.68 0.84 1.00  1.34     1232     1964 1.00 #> d_dir           0.89 0.26  0.40  0.71 0.88 1.06  1.42     2083     2044 1.00 #> d_ind           0.58 0.66 -0.65  0.14 0.56 0.99  1.94     1619     2289 1.00 #> omega           0.31 0.69 -1.10 -0.14 0.32 0.76  1.62     1683     2239 1.00 #> tau             0.86 0.20  0.56  0.72 0.83 0.97  1.31     1391     1942 1.00 #> tau_consistency 0.84 0.18  0.55  0.71 0.82 0.94  1.28     1159     1955 1.01 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.1 #>               DIC: 98.2 #>  #> Bayesian p-value: 0.64 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.48 0.40 -0.28  0.22  0.48 0.74  1.31     2118     2377 1.00 #> d_dir            0.35 0.56 -0.76  0.00  0.35 0.70  1.44     3917     2780 1.00 #> d_ind            0.68 0.63 -0.56  0.26  0.68 1.09  1.90     2888     2881 1.00 #> omega           -0.34 0.84 -2.01 -0.89 -0.32 0.21  1.30     2880     2896 1.00 #> tau              0.87 0.20  0.57  0.73  0.84 0.98  1.34     1191     2218 1.00 #> tau_consistency  0.84 0.18  0.55  0.71  0.82 0.94  1.28     1159     1955 1.01 #>  #> Residual deviance: 53.8 (on 50 data points) #>                pD: 44.2 #>               DIC: 98 #>  #> Bayesian p-value: 0.7 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.26 0.41 -1.10 -0.52 -0.26  0.00  0.55     2507     2811 1.00 #> d_dir           -0.12 0.49 -1.09 -0.44 -0.12  0.19  0.84     3391     2838 1.00 #> d_ind           -0.54 0.62 -1.78 -0.92 -0.53 -0.13  0.67     1771     2303 1.00 #> omega            0.42 0.69 -0.93 -0.03  0.41  0.85  1.85     1829     2064 1.00 #> tau              0.86 0.20  0.55  0.72  0.83  0.97  1.30     1145     1844 1.00 #> tau_consistency  0.84 0.18  0.55  0.71  0.82  0.94  1.28     1159     1955 1.01 #>  #> Residual deviance: 53.9 (on 50 data points) #>                pD: 44 #>               DIC: 97.9 #>  #> Bayesian p-value: 0.53 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.62 0.49 -1.61 -0.94 -0.62 -0.31  0.35     2351     2381 1.00 #> d_dir           -0.62 0.66 -1.93 -1.04 -0.62 -0.19  0.66     3933     2287 1.00 #> d_ind           -0.62 0.68 -1.99 -1.06 -0.62 -0.16  0.64     1940     2101 1.00 #> omega            0.00 0.89 -1.78 -0.57  0.00  0.59  1.81     2134     2003 1.00 #> tau              0.87 0.19  0.57  0.73  0.84  0.98  1.34     1176     2005 1.00 #> tau_consistency  0.84 0.18  0.55  0.71  0.82  0.94  1.28     1159     1955 1.01 #>  #> Residual deviance: 54.2 (on 50 data points) #>                pD: 44.5 #>               DIC: 98.7 #>  #> Bayesian p-value: 1 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.36 0.43 -1.24 -0.63 -0.35 -0.09  0.47     2261     2362 1.00 #> d_dir            0.10 0.65 -1.16 -0.32  0.10  0.50  1.43     3247     3022 1.00 #> d_ind           -0.61 0.54 -1.68 -0.95 -0.60 -0.27  0.44     1950     1969 1.00 #> omega            0.71 0.83 -0.90  0.16  0.71  1.26  2.43     2301     2314 1.00 #> tau              0.86 0.19  0.55  0.72  0.84  0.97  1.30     1048     1878 1.00 #> tau_consistency  0.84 0.18  0.55  0.71  0.82  0.94  1.28     1159     1955 1.01 #>  #> Residual deviance: 53.9 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.2 #>  #> Bayesian p-value: 0.38 # }  ## Plaque psoriasis ML-NMR # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.  # \\donttest{ # Fitting a ML-NMR model. # Specify a regression model to include effect modifier interactions for five # covariates, along with main (prognostic) effects. We use a probit link and # specify that the two-parameter Binomial approximation for the aggregate-level # likelihood should be used. We set treatment-covariate interactions to be equal # within each class. We narrow the possible range for random initial values with # init_r = 0.1, since probit models in particular are often hard to initialise. # Using the QR decomposition greatly improves sampling efficiency here, as is # often the case for regression models. pso_fit <- nma(pso_net, refresh = if (interactive()) 200 else 0,                trt_effects = \"fixed\",                link = \"probit\",                likelihood = \"bernoulli2\",                regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                class_interactions = \"common\",                prior_intercept = normal(scale = 10),                prior_trt = normal(scale = 10),                prior_reg = normal(scale = 10),                init_r = 0.1,                QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25% #> beta[durnpso]                           0.04    0.00 0.06    -0.07     0.00 #> beta[prevsys]                          -0.14    0.00 0.16    -0.45    -0.25 #> beta[bsa]                              -0.06    0.01 0.44    -0.95    -0.36 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02 #> beta[psa]                              -0.08    0.00 0.17    -0.41    -0.19 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.14    -0.06 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.19    -0.19     0.07 #> beta[prevsys:.trtclassIL blocker]       0.07    0.00 0.18    -0.27    -0.05 #> beta[bsa:.trtclassTNFa blocker]         0.05    0.01 0.51    -0.94    -0.31 #> beta[bsa:.trtclassIL blocker]           0.29    0.00 0.48    -0.63    -0.05 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.03    -0.23    -0.19 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12 #> beta[psa:.trtclassTNFa blocker]        -0.06    0.00 0.20    -0.45    -0.20 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.18    -0.34    -0.12 #> d[ETN]                                  1.55    0.00 0.08     1.40     1.50 #> d[IXE_Q2W]                              2.95    0.00 0.08     2.79     2.90 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.38     2.49 #> d[SEC_150]                              2.14    0.00 0.11     1.93     2.07 #> d[SEC_300]                              2.45    0.00 0.12     2.21     2.37 #> lp__                                -1576.28    0.09 3.47 -1583.98 -1578.41 #>                                          50%      75%    97.5% n_eff Rhat #> beta[durnpso]                           0.04     0.08     0.16  8765    1 #> beta[prevsys]                          -0.14    -0.04     0.17  6520    1 #> beta[bsa]                              -0.06     0.24     0.78  7127    1 #> beta[weight]                            0.04     0.06     0.10  7278    1 #> beta[psa]                              -0.07     0.04     0.24  5124    1 #> beta[durnpso:.trtclassTNFa blocker]    -0.03     0.02     0.11 10319    1 #> beta[durnpso:.trtclassIL blocker]      -0.01     0.03     0.12 10020    1 #> beta[prevsys:.trtclassTNFa blocker]     0.19     0.32     0.56  7743    1 #> beta[prevsys:.trtclassIL blocker]       0.07     0.18     0.42  7742    1 #> beta[bsa:.trtclassTNFa blocker]         0.05     0.39     1.05  7543    1 #> beta[bsa:.trtclassIL blocker]           0.28     0.60     1.22  9271    1 #> beta[weight:.trtclassTNFa blocker]     -0.17    -0.14    -0.10  7178    1 #> beta[weight:.trtclassIL blocker]       -0.10    -0.08    -0.04  8459    1 #> beta[psa:.trtclassTNFa blocker]        -0.06     0.08     0.35  5681    1 #> beta[psa:.trtclassIL blocker]           0.01     0.13     0.36  5556    1 #> d[ETN]                                  1.55     1.60     1.71  4831    1 #> d[IXE_Q2W]                              2.95     3.01     3.12  6236    1 #> d[IXE_Q4W]                              2.54     2.60     2.70  6409    1 #> d[SEC_150]                              2.14     2.22     2.36  5172    1 #> d[SEC_300]                              2.45     2.53     2.68  6593    1 #> lp__                                -1575.96 -1573.85 -1570.42  1649    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:26:53 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }  ## Newly-diagnosed multiple myeloma NMA # Set up newly-diagnosed multiple myeloma network  head(ndmm_ipd) #>          study trt       studyf trtf      age iss_stage3 response_cr_vgpr male #> 1 McCarthy2012 Pbo McCarthy2012  Pbo 50.81625          0                1    0 #> 2 McCarthy2012 Pbo McCarthy2012  Pbo 62.18165          0                0    0 #> 3 McCarthy2012 Pbo McCarthy2012  Pbo 51.53762          1                1    1 #> 4 McCarthy2012 Pbo McCarthy2012  Pbo 46.74128          0                1    1 #> 5 McCarthy2012 Pbo McCarthy2012  Pbo 62.62561          0                1    1 #> 6 McCarthy2012 Pbo McCarthy2012  Pbo 49.24520          1                1    0 #>   eventtime status #> 1 31.106516      1 #> 2  3.299623      0 #> 3 57.400000      0 #> 4 57.400000      0 #> 5 57.400000      0 #> 6 30.714460      0 head(ndmm_agd) #>        study     studyf trt trtf eventtime status #> 1 Morgan2012 Morgan2012 Pbo  Pbo  18.72575      1 #> 2 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 3 Morgan2012 Morgan2012 Pbo  Pbo  34.35726      1 #> 4 Morgan2012 Morgan2012 Pbo  Pbo  10.77826      1 #> 5 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 6 Morgan2012 Morgan2012 Pbo  Pbo  14.52966      1  ndmm_net <- combine_network(   set_ipd(ndmm_ipd,           study, trt,           Surv = Surv(eventtime / 12, status)),   set_agd_surv(ndmm_agd,                study, trt,                Surv = Surv(eventtime / 12, status),                covariates = ndmm_agd_covs)) # \\donttest{ # Fit Weibull (PH) model ndmm_fit <- nma(ndmm_net, refresh = if (interactive()) 200 else 0,                 likelihood = \"weibull\",                 prior_intercept = normal(scale = 100),                 prior_trt = normal(scale = 10),                 prior_aux = half_normal(scale = 10)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit #> A fixed effects NMA with a weibull likelihood (log link). #> Inference for Stan model: survival_param. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75% #> d[Len]                 -0.54    0.00 0.04    -0.63    -0.57    -0.54    -0.51 #> d[Thal]                -0.11    0.00 0.09    -0.28    -0.17    -0.11    -0.06 #> lp__                -6229.83    0.06 2.42 -6235.51 -6231.22 -6229.49 -6228.08 #> shape[Attal2012]        1.30    0.00 0.06     1.18     1.26     1.30     1.34 #> shape[Jackson2019]      0.93    0.00 0.02     0.89     0.92     0.93     0.95 #> shape[McCarthy2012]     1.29    0.00 0.07     1.17     1.25     1.29     1.34 #> shape[Morgan2012]       0.88    0.00 0.03     0.82     0.86     0.88     0.90 #> shape[Palumbo2014]      1.02    0.00 0.07     0.88     0.97     1.01     1.06 #>                        97.5% n_eff Rhat #> d[Len]                 -0.45  5572    1 #> d[Thal]                 0.06  4970    1 #> lp__                -6226.12  1586    1 #> shape[Attal2012]        1.42  4820    1 #> shape[Jackson2019]      0.98  5142    1 #> shape[McCarthy2012]     1.42  4382    1 #> shape[Morgan2012]       0.94  5560    1 #> shape[Palumbo2014]      1.16  4465    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:28:47 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_data-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_data class — nma_data-class","title":"The nma_data class — nma_data-class","text":"nma_data class contains data NMA standard format, created using functions set_ipd(), set_agd_arm(), set_agd_contrast(), set_agd_surv(), combine_network(). sub-class mlnmr_data created function add_integration(), contains numerical integration points aggregate data.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_data-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_data class — nma_data-class","text":"Objects class nma_data following components: agd_arm data studies aggregate data (arm format) agd_contrast data studies aggregate data (contrast format) ipd data studies individual patient data treatments treatment coding factor entire network classes treatment class coding factor (length treatments entire network) studies study coding factor entire network outcome outcome type data source, named list agd_arm, agd_contrast, ipd components tibbles following columns: .study study (factor) .trt treatment (factor) .trtclass treatment class (factor), specified .y continuous outcome .se standard error (continuous) .r event count (discrete) .n event count denominator (discrete, agd_arm ) .E time risk (discrete) .Surv survival outcome type Surv (time--event), nested study arm .sample_size sample size (agd_* ) ... columns (typically covariates) original data frame Objects class mlnmr_data additionally components: n_int number numerical integration points int_names names covariates numerical integration points int_cor correlation matrix covariates used generate numerical integration points agd_arm agd_contrast tibbles additional list columns prefix .int_, one covariate, contain numerical integration points nested length-n_int vectors within row.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_dic-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_dic class — nma_dic-class","title":"The nma_dic class — nma_dic-class","text":"nma_dic class contains details Deviance Information Criterion (DIC), produced using dic() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_dic-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_dic class — nma_dic-class","text":"Objects class nma_dic following components: dic DIC value pd, pv effective number parameters resdev total residual deviance pointwise list data frames containing pointwise contributions IPD AgD. resdev_array 3D MCMC array [Iterations, Chains, Parameters] posterior residual deviance samples.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_nodesplit-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_nodesplit class — nma_nodesplit-class","title":"The nma_nodesplit class — nma_nodesplit-class","text":"nma_nodesplit nma_nodesplit_df classes contains results running node-splitting model function nma().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_nodesplit-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_nodesplit class — nma_nodesplit-class","text":"Objects class nma_nodesplit inherit stan_nma class, contain results fitting single node-split model. one additional component, nodesplit, gives comparison node-split length 2 vector. Objects class nma_nodesplit_df tibble data frames one row node-split comparison columns: trt1, trt2 Treatments forming comparison model list column containing results model nma_nodesplit object Optionally, additional row consistency model fitted (e.g. get_nodesplits(., include_consistency = TRUE)) trt1 trt2 NA.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_prior-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_prior class — nma_prior-class","title":"The nma_prior class — nma_prior-class","text":"nma_prior class used specify prior distributions.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_prior-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_prior class — nma_prior-class","text":"Objects class nma_prior following components: dist Distribution name fun Name constructor function, string (e.g. \"normal\") ... Parameters distribution distribution parameters, specified named components ..., match constructor functions (see priors).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_summary class — nma_summary-class","title":"The nma_summary class — nma_summary-class","text":"nma_summary class contains posterior summary statistics model parameters quantities interest, draws used obtain statistics.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_summary class — nma_summary-class","text":"Objects class nma_summary following components: summary data frame containing computed summary statistics. Column .trt indicates corresponding treatment, columns .trta .trtb indicate corresponding contrast (.trtb vs. .trta). regression model fitted effect modifier interactions treatment, summaries study-specific. case, corresponding study population indicated .study column. multinomial model fitted, .category column indicates corresponding category. sims 3D array [Iteration, Chain, Parameter] MCMC simulations studies (Optional) data frame containing study information, printed along corresponding summary statistics summary contains .study column. matching .study column. following attributes may also set: xlab Label x axis plots, usually either \"Treatment\" \"Contrast\". ylab Label y axis plots, usually used scale e.g. \"log Odds Ratio\". subclass nma_rank_probs used function posterior_rank_probs(), contains posterior rank probabilities. subclass sims component, rank probabilities posterior summaries ranks (.e. posterior distribution). posterior ranks rank probabilities calculated may obtained posterior_ranks().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for nma_summary objects — print.nma_summary","title":"Methods for nma_summary objects — print.nma_summary","text":".data.frame(), as_tibble(), .tibble() methods return posterior summary statistics data frame tibble. .matrix() method returns matrix posterior draws. .array() method returns 3D array [Iteration, Chain, Parameter] posterior draws (class mcmc_array).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for nma_summary objects — print.nma_summary","text":"","code":"# S3 method for nma_summary print(x, ..., digits = 2, pars, include = TRUE)  # S3 method for nma_summary as.data.frame(x, ...)  # S3 method for nma_summary as.tibble(x, ...)  # S3 method for nma_summary as_tibble(x, ...)  # S3 method for nma_summary as.array(x, ...)  # S3 method for nma_summary as.matrix(x, ...)  # S3 method for nma_rank_probs as.array(x, ...)  # S3 method for nma_rank_probs as.matrix(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for nma_summary objects — print.nma_summary","text":"x nma_summary object ... Additional arguments passed methods digits Integer number digits display pars Character vector parameters display printed summary include Logical, parameters named pars included (TRUE) excluded (FALSE)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for nma_summary objects — print.nma_summary","text":"data.frame .data.frame(), tbl_df .tibble() as_tibble(), matrix .matrix(), mcmc_array .array(). print() method returns x invisibly.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nodesplit_summary class — nodesplit_summary-class","title":"The nodesplit_summary class — nodesplit_summary-class","text":"nodesplit_summary class contains posterior summary statistics node-splitting models, result calling summary() nma_nodesplit nma_nodesplit_df object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nodesplit_summary class — nodesplit_summary-class","text":"Objects class nodesplit_summary tibble data frames, one row node-split comparison columns: trt1, trt2 Treatments forming comparison summary list column containing nma_summary objects posterior summaries draws node-splitting parameters p_value Bayesian p-value inconsistency dic list column containing nma_dic objects, giving model fit statistics parameters included summary : d_net Network estimate corresponding consistency model, available d_dir Direct estimate node-splitting model d_ind Indirect estimate node-splitting model omega Inconsistency factor \\(\\omega = d_\\mathrm{dir} -   d_\\mathrm{ind}\\) tau Heterogeneity standard deviation node-splitting model, random effects model fitted tau_consistency Heterogeneity standard deviation corresponding consistency model, available random effects model fitted","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for nodesplit_summary objects — print.nodesplit_summary","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":".data.frame(), as_tibble(), .tibble() methods return node-splitting summaries data frame tibble.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"","code":"# S3 method for nodesplit_summary print(x, ..., digits = 2)  # S3 method for nodesplit_summary as_tibble(x, ..., nest = FALSE)  as.tibble.nodesplit_summary(x, ..., nest = FALSE)  # S3 method for nodesplit_summary as.data.frame(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"x nodesplit_summary object ... Additional arguments passed methods digits Integer number digits display nest Whether return nested tibble, full nma_summary nma_dic objects, unnest summaries, default FALSE","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"data.frame .data.frame(), tbl_df .tibble() as_tibble(). print() method returns x invisibly.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix of plots for a stan_nma object — pairs.stan_nma","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"pairs() method stan_nma objects, calls bayesplot::mcmc_pairs() underlying stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"","code":"# S3 method for stan_nma pairs(x, ..., pars, include = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"x object class stan_nma ... arguments passed bayesplot::mcmc_pairs() pars Optional character vector parameter names include output. specified, parameters used. include Logical, parameters pars included (TRUE, default) excluded (FALSE)?","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"grid ggplot objects produced bayesplot::mcmc_pairs().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"","code":"if (FALSE) { ## Parkinson's mean off time reduction park_net <- set_agd_arm(parkinsons,                         study = studyn,                         trt = trtn,                         y = y,                         se = se,                         sample_size = n)  # Fitting a RE model park_fit_RE <- nma(park_net,                    trt_effects = \"random\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_het = half_normal(scale = 5))  # We see a small number of divergent transition errors # These do not go away entirely when adapt_delta is increased  # Try to diagnose with a pairs plot pairs(park_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\"))  # Transforming tau onto log scale pairs(park_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\"),       transformations = list(tau = \"log\"))  # The divergent transitions occur in the upper tail of the heterogeneity # standard deviation. In this case, with only a small number of studies, there # is not very much information to estimate the heterogeneity standard deviation # and the prior distribution may be too heavy-tailed. We could consider a more # informative prior distribution for the heterogeneity variance to aid # estimation. }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean off-time reduction in Parkison's disease — parkinsons","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"Data frame containing mean -time reduction patients given dopamine agonists adjunct therapy Parkinson's disease, 7 trials comparing four active drugs placebo (Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"","code":"parkinsons"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"data frame 15 rows 7 variables: studyn numeric study ID trtn numeric treatment code (placebo = 1) y mean -time reduction se standard error n sample size diff mean difference vs. treatment reference arm se_diff standard error mean difference, see details","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"dataset may analysed using either arm-based likelihood using y se, contrast-based likelihood using diff se_diff (combination two across different studies). contrast-based data formatted described set_agd_contrast(). , chosen reference arm study, mean difference diff set NA, se_diff set standard error se outcome reference arm.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":null,"dir":"Reference","previous_headings":"","what":"Plaque psoriasis data — plaque_psoriasis_ipd","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"Two data frames, plaque_psoriasis_ipd plaque_psoriasis_agd, containing (simulated) individual patient data four studies aggregate data five studies (Phillippo 2019) . Outcomes binary success/failure achieve 75%, 90%, 100% reduction symptoms Psoriasis Area Severity Index (PASI) scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"","code":"plaque_psoriasis_ipd  plaque_psoriasis_agd"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"individual patient data contained data frame plaque_psoriasis_ipd 4118 rows, one per individual, 16 variables: studyc study name trtc_long treatment name (long format) trtc treatment name trtn numeric treatment code pasi75 binary PASI 75 outcome pasi90 binary PASI 90 outcome pasi100 binary PASI 100 outcome age age (years) bmi body mass index (BMI) pasi_w0 PASI score week 0 male male sex (TRUE FALSE) bsa body surface area (percent) weight weight (kilograms) durnpso duration psoriasis (years) prevsys previous systemic treatment (TRUE FALSE) psa psoriatic arthritis (TRUE FALSE) aggregate data contained data frame plaque_psoriasis_agd 15 rows, one per study arm, 26 variables: studyc study name trtc_long treatment name (long format) trtc treatment name trtn numeric treatment code pasi75_r, pasi75_n PASI 75 outcome count denominator pasi90_r, pasi90_n PASI 75 outcome count denominator pasi100_r, pasi100_n PASI 75 outcome count denominator sample_size_w0 sample size week zero age_mean, age_sd mean standard deviation age (years) bmi_mean, bmi_sd mean standard deviation BMI pasi_w0_mean, pasi_w0_sd mean standard deviation PASI score week 0 male percentage males bsa_mean, bsa_sd mean standard deviation body surface area (percent) weight_mean, weight_sd mean standard deviation weight (kilograms) durnpso_mean, durnpso_sd mean standard deviation duration psoriasis (years) prevsys percentage individuals previous systemic treatment psa percentage individuals psoriatic arthritis object class data.frame 15 rows 26 columns.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"Phillippo DM (2019). Calibration Treatment Effects Network Meta-Analysis using Individual Patient Data. Ph.D. thesis, University Bristol. Available https://research-information.bris.ac.uk/.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Network plots — plot.nma_data","title":"Network plots — plot.nma_data","text":"Create network plot nma_data network object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Network plots — plot.nma_data","text":"","code":"# S3 method for nma_data plot(   x,   ...,   layout,   circular,   weight_edges = TRUE,   weight_nodes = FALSE,   show_trt_class = FALSE,   nudge = 0 )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Network plots — plot.nma_data","text":"x nma_data object plot ... Additional arguments passed ggraph() layout function layout type layout create. layout accepted ggraph() may used, including layout functions provided igraph. circular Whether use circular representation. See ggraph(). weight_edges Weight edges number studies? Default TRUE. weight_nodes Weight nodes total sample size? Default FALSE. show_trt_class Colour treatment nodes class, trt_class set? Default FALSE. nudge Numeric value nudge treatment labels away nodes weight_nodes = TRUE. Default 0 (adjustment label position). small value like 0.1 usually sufficient.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Network plots — plot.nma_data","text":"ggplot object, produced ggraph().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Network plots — plot.nma_data","text":"default equivalent layout = \"linear\" circular = TRUE, places treatment nodes circle order defined treatment factor variable. alternative layout may give good results simple networks \"sugiyama\", attempts minimise number edge crossings. weight_nodes = TRUE requires sample sizes specified aggregate data network, using sample_size option set_agd_*().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Network plots — plot.nma_data","text":"","code":"## Stroke prevention in atrial fibrillation # Setting up the network af_net <- set_agd_arm(atrial_fibrillation,                       study = studyc,                       trt = abbreviate(trtc, minlength = 3),                       r = r,                       n = n,                       trt_class = trt_class) af_net #> A network with 26 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                #>  ACTIVE-W      2: Sada | Lda+c               #>  AFASAK 1      3: Sada | Lda | P/c           #>  AFASAK 2      4: Sada | Fdw | Fdw+mda | Mda #>  BAATAF        2: Lada | P/c                 #>  BAFTA         2: Sada | Lda                 #>  CAFA          2: Sada | P/c                 #>  Chinese ATAFS 2: Sada | Lda                 #>  EAFT          3: Sada | Mda | P/c           #>  ESPS 2        4: Dpy | Lda | Lda+d | P/c    #>  JAST          2: Lda | P/c                  #>  ... plus 16 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 17, in 4 classes #> Total number of studies: 26 #> Reference treatment is: Sada #> Network is connected  # Basic plot plot(af_net)   # Turn off weighting edges by number of studies plot(af_net, weight_edges = FALSE)   # Turn on weighting nodes by sample size plot(af_net, weight_nodes = TRUE)   # Colour treatment nodes by class plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE)   # Nudge the treatment labels away from the nodes plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE, nudge = 0.1)   # Output may be customised using standard ggplot commands # For example, to display the legends below the plot: plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE) +   ggplot2::theme(legend.position = \"bottom\",                  legend.box = \"vertical\",                  legend.margin = ggplot2::margin(0, 0, 0, 0),                  legend.spacing = ggplot2::unit(0.5, \"lines\"))   # Choosing a different ggraph layout, hiding some legends plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE,      layout = \"star\") +   ggplot2::guides(edge_width = \"none\", size = \"none\")"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of model fit diagnostics — plot.nma_dic","title":"Plots of model fit diagnostics — plot.nma_dic","text":"plot() method nma_dic objects produced dic() produces several useful diagnostic plots checking model fit model comparison. detail plots interpretation given Dias et al. (2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of model fit diagnostics — plot.nma_dic","text":"","code":"# S3 method for nma_dic plot(   x,   y,   ...,   show_uncertainty = TRUE,   stat = \"pointinterval\",   orientation = c(\"vertical\", \"horizontal\", \"x\", \"y\") )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of model fit diagnostics — plot.nma_dic","text":"x nma_dic object y (Optional) second nma_dic object, produce \"dev-dev\" plots model comparison. ... Additional arguments passed methods show_uncertainty Logical, show uncertainty ggdist plot stat? Default TRUE. stat Character string specifying ggdist plot stat use show_uncertainty = TRUE, default \"pointinterval\". y provided, currently \"pointinterval\" supported. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"). used residual deviance plots, default \"vertical\".","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of model fit diagnostics — plot.nma_dic","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of model fit diagnostics — plot.nma_dic","text":"single nma_dic object given, plot residual deviance contribution data point produced. good fitting model, data point expected residual deviance 1; larger values indicate data points fit poorly model. two nma_dic objects given, \"dev-dev\" plot comparing residual deviance contributions model produced. Data points residual deviance contributions lying line equality fit equally well either model. Data points lying line equality indicate better fit second model (y); conversely, data points lying line equality indicate better fit first model (x). common use case compare standard consistency model (fitted using nma() consistency = \"consistency\") unrelated mean effects (UME) inconsistency model (fitted using nma() consistency = \"ume\"), check potential inconsistency. See Dias et al. (2011)  details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plots of model fit diagnostics — plot.nma_dic","text":"Dias S, Welton NJ, Sutton AJ, Ades AE (2011). “NICE DSU Technical Support Document 2: generalised linear modelling framework pair-wise network meta-analysis randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of model fit diagnostics — plot.nma_dic","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking FE NMA example if not already available if (!exists(\"smk_fit_FE\")) example(\"example_smk_fe\", run.donttest = TRUE) # } # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC of FE and RE models (smk_dic_FE <- dic(smk_fit_FE)) #> Residual deviance: 266.9 (on 50 data points) #>                pD: 26.7 #>               DIC: 293.6 (smk_dic_RE <- dic(smk_fit_RE))   # substantially better fit #> Residual deviance: 54.5 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.8  # Plot residual deviance contributions under RE model plot(smk_dic_RE)   # Further customisation is possible using ggplot commands # For example, highlighting data points with residual deviance above a certain threshold plot(smk_dic_RE) +   ggplot2::aes(colour = ggplot2::after_stat(ifelse(y > 1.5, \"darkorange\", \"black\"))) +   ggplot2::scale_colour_identity()   # Or by posterior probability, for example here a central probability of 0.6 # corresponds to a lower tail probability of (1 - 0.6)/2 = 0.2 plot(smk_dic_RE, .width = c(0.6, 0.95)) +   ggplot2::aes(colour = ggplot2::after_stat(ifelse(ymin > 1, \"darkorange\", \"black\"))) +   ggplot2::scale_colour_identity()   # Check for inconsistency using UME model # } # \\donttest{ # Run smoking UME NMA example if not already available if (!exists(\"smk_fit_RE_UME\")) example(\"example_smk_ume\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC smk_dic_RE #> Residual deviance: 54.5 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.8 (smk_dic_RE_UME <- dic(smk_fit_RE_UME))  # no difference in fit #> Residual deviance: 54 (on 50 data points) #>                pD: 45 #>               DIC: 99  # Compare residual deviance contributions with a \"dev-dev\" plot plot(smk_dic_RE, smk_dic_RE_UME)   # By default the dev-dev plot can be a little cluttered # Hiding the credible intervals plot(smk_dic_RE, smk_dic_RE_UME, show_uncertainty = FALSE)   # Changing transparency plot(smk_dic_RE, smk_dic_RE_UME, point_alpha = 0.5, interval_alpha = 0.1)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of summary results — plot.nma_summary","title":"Plots of summary results — plot.nma_summary","text":"plot method nma_summary objects used produce plots parameter estimates (called stan_nma object summary), relative effects (called output relative_effects()), absolute predictions (called output predict.stan_nma()), posterior ranks rank probabilities (called output posterior_ranks() posterior_rank_probs()).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of summary results — plot.nma_summary","text":"","code":"# S3 method for nma_summary plot(   x,   ...,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )  # S3 method for nma_parameter_summary plot(   x,   ...,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )  # S3 method for nma_rank_probs plot(x, ...)  # S3 method for surv_nma_summary plot(x, ..., stat = \"lineribbon\")"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of summary results — plot.nma_summary","text":"x nma_summary object ... Additional arguments passed underlying ggdist plot stat, see Details stat Character string specifying ggdist plot stat use, default \"pointinterval\", except plotting estimated survival/hazard/cumulative hazard curves survival models default \"lineribbon\" orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\" ref_line Numeric vector positions reference lines, default reference lines drawn","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of summary results — plot.nma_summary","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of summary results — plot.nma_summary","text":"Plotting handled ggplot2 stats geoms provided ggdist package. result, output flexible. plotting stats provided ggdist may used, via argument stat. default uses ggdist::stat_pointinterval(), produce medians 95% Credible Intervals 66% inner bands. Additional arguments ... passed ggdist stat, customise output. example, produce means Credible Intervals, specify point_interval = \"mean_qi\". produce 80% Credible Interval inner band, specify .width = c(0, 0.8). Alternative stats can specified produce different summaries. example, specify stat = \"[half]eye\" produce (half) eye plots, stat = \"histinterval\" produce histograms intervals. full list options examples found ggdist vignette vignette(\"slabinterval\", package = \"ggdist\"). survival/hazard/cumulative hazard curves estimated survival models, default uses ggdist::stat_lineribbon() produces curves posterior medians 50%, 80%, 95% Credible Interval bands. , additional arguments ... passed ggdist stat. example, produce posterior means 95% Credible bands, specify point_interval = \"mean_qi\" .width = 0.95. ggplot object returned can modified usual ggplot2 functions add aesthetics, geoms, themes, etc.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of summary results — plot.nma_summary","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce relative effects smk_releff_RE <- relative_effects(smk_fit_RE) plot(smk_releff_RE, ref_line = 0)   # Customise plot options plot(smk_releff_RE, ref_line = 0, stat = \"halfeye\")   # Further customisation is possible with ggplot commands plot(smk_releff_RE, ref_line = 0, stat = \"halfeye\", slab_alpha = 0.6) +   ggplot2::aes(slab_fill = ggplot2::after_stat(ifelse(x < 0, \"darkred\", \"grey60\")))   # Produce posterior ranks smk_rank_RE <- posterior_ranks(smk_fit_RE, lower_better = FALSE) plot(smk_rank_RE)   # Produce rank probabilities smk_rankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE) plot(smk_rankprob_RE)   # Produce cumulative rank probabilities smk_cumrankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE,                                            cumulative = TRUE) plot(smk_cumrankprob_RE)   # Further customisation is possible with ggplot commands plot(smk_cumrankprob_RE) +   ggplot2::facet_null() +   ggplot2::aes(colour = Treatment)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of node-splitting models — plot.nodesplit_summary","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"Produce summary plots node-splitting models","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"","code":"# S3 method for nodesplit_summary plot(   x,   ...,   pars = \"d\",   stat = \"dens_overlay\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"x nodesplit_summary object. ... Additional arguments passed underlying ggdist plot stat, see Details. pars Character vector specifying parameters include plot, choices include \"d\" direct, indirect, network estimates relative effects, \"omega\" inconsistency factor, \"tau\" heterogeneity standard deviation random effects models. Default \"d\". stat Character string specifying ggdist plot stat use. default \"dens_overlay\" special case, producing overlaid density plot. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\". ref_line Numeric vector positions reference lines, default reference lines drawn.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"Plotting handled ggplot2 stats geoms provided ggdist package. result, output flexible. plotting stats provided ggdist may used, via argument stat. default \"dens_overlay\" special exception, uses ggplot2::geom_density(), plot overlaid densities. Additional arguments ... passed ggdist stat, customise output. Alternative stats can specified produce different summaries. example, specify stat = \"[half]eye\" produce (half) eye plots, stat = \"pointinterval\" produce point estimates credible intervals. full list options examples found ggdist vignette vignette(\"slabinterval\", package = \"ggdist\"). ggplot object returned can modified usual ggplot2 functions add aesthetics, geoms, themes, etc.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"","code":"# \\donttest{ # Run smoking node-splitting example if not already available if (!exists(\"smk_fit_RE_nodesplit\")) example(\"example_smk_nodesplit\", run.donttest = TRUE) # } # \\donttest{ # Summarise the node-splitting results (smk_nodesplit_summary <- summary(smk_fit_RE_nodesplit)) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.10 0.43  0.28  0.81  1.09 1.38  2.01     1792     2159    1 #> d_dir            1.06 0.75 -0.33  0.57  1.02 1.52  2.64     3212     2561    1 #> d_ind            1.16 0.54  0.14  0.80  1.16 1.50  2.26     1698     2097    1 #> omega           -0.10 0.89 -1.79 -0.70 -0.13 0.47  1.76     2328     2516    1 #> tau              0.86 0.20  0.55  0.72  0.84 0.97  1.33     1181     1600    1 #> tau_consistency  0.83 0.18  0.55  0.71  0.81 0.94  1.26     1549     1758    1 #>  #> Residual deviance: 54.2 (on 50 data points) #>                pD: 44.2 #>               DIC: 98.4 #>  #> Bayesian p-value: 0.87 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.86 0.24  0.41  0.70 0.85 1.00  1.34     1277     1723 1.00 #> d_dir           0.89 0.25  0.42  0.72 0.88 1.05  1.41     1351     1977 1.00 #> d_ind           0.58 0.66 -0.70  0.13 0.57 1.01  1.96     1288     1730 1.00 #> omega           0.31 0.69 -1.09 -0.13 0.32 0.78  1.67     1288     1658 1.01 #> tau             0.85 0.19  0.55  0.72 0.83 0.96  1.28     1145     1894 1.00 #> tau_consistency 0.83 0.18  0.55  0.71 0.81 0.94  1.26     1549     1758 1.00 #>  #> Residual deviance: 54.5 (on 50 data points) #>                pD: 44.5 #>               DIC: 99 #>  #> Bayesian p-value: 0.63 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.50 0.39 -0.25  0.24  0.49 0.75  1.30     2036     2569    1 #> d_dir            0.33 0.54 -0.72 -0.02  0.33 0.67  1.40     3221     2757    1 #> d_ind            0.70 0.62 -0.53  0.30  0.69 1.10  1.92     2129     2391    1 #> omega           -0.37 0.81 -2.01 -0.90 -0.35 0.15  1.24     2201     2688    1 #> tau              0.86 0.19  0.55  0.73  0.84 0.98  1.28     1370     2384    1 #> tau_consistency  0.83 0.18  0.55  0.71  0.81 0.94  1.26     1549     1758    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.4 #>               DIC: 98.5 #>  #> Bayesian p-value: 0.62 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.24 0.41 -1.09 -0.51 -0.23  0.02  0.56     2722     2753    1 #> d_dir           -0.13 0.49 -1.09 -0.45 -0.13  0.19  0.84     3952     3114    1 #> d_ind           -0.54 0.65 -1.84 -0.96 -0.53 -0.12  0.68     1270     1487    1 #> omega            0.41 0.72 -1.00 -0.04  0.43  0.87  1.79     1384     1605    1 #> tau              0.87 0.20  0.56  0.73  0.85  0.99  1.33     1311     2157    1 #> tau_consistency  0.83 0.18  0.55  0.71  0.81  0.94  1.26     1549     1758    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.5 #>               DIC: 98.6 #>  #> Bayesian p-value: 0.54 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.60 0.49 -1.59 -0.91 -0.59 -0.28  0.36     2352     2587    1 #> d_dir           -0.60 0.64 -1.93 -1.01 -0.60 -0.17  0.62     3918     3021    1 #> d_ind           -0.59 0.68 -1.96 -1.01 -0.59 -0.17  0.73     2047     2302    1 #> omega           -0.01 0.87 -1.71 -0.57  0.01  0.54  1.75     2267     2502    1 #> tau              0.87 0.19  0.56  0.73  0.85  0.97  1.30     1306     2065    1 #> tau_consistency  0.83 0.18  0.55  0.71  0.81  0.94  1.26     1549     1758    1 #>  #> Residual deviance: 54 (on 50 data points) #>                pD: 44.2 #>               DIC: 98.2 #>  #> Bayesian p-value: 0.99 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.36 0.41 -1.14 -0.62 -0.36 -0.09  0.46     2328     2818    1 #> d_dir            0.07 0.64 -1.15 -0.34  0.06  0.48  1.31     3377     2830    1 #> d_ind           -0.60 0.53 -1.64 -0.93 -0.58 -0.26  0.46     1842     2061    1 #> omega            0.66 0.81 -0.97  0.14  0.67  1.19  2.21     2242     2155    1 #> tau              0.85 0.19  0.54  0.72  0.83  0.97  1.29     1029     1995    1 #> tau_consistency  0.83 0.18  0.55  0.71  0.81  0.94  1.26     1549     1758    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44 #>               DIC: 97.6 #>  #> Bayesian p-value: 0.4  # Plot the node-splitting results plot(smk_nodesplit_summary)   # Plot the inconsistency factors instead, change the plot stat to half-eye, # and add a reference line at 0 plot(smk_nodesplit_summary, pars = \"omega\", stat = \"halfeye\", ref_line = 0)   # Plot a comparison of the heterogeneity under the node-split models vs. # the consistency model plot(smk_nodesplit_summary, pars = \"tau\")  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot numerical integration error — plot_integration_error","title":"Plot numerical integration error — plot_integration_error","text":"ML-NMR models, plot estimated numerical integration error entire posterior distribution, number integration points increases. See (Phillippo et al. 2020; Phillippo 2019)  details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot numerical integration error — plot_integration_error","text":"","code":"plot_integration_error(   x,   ...,   stat = \"violin\",   orientation = c(\"vertical\", \"horizontal\", \"x\", \"y\"),   show_expected_rate = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot numerical integration error — plot_integration_error","text":"x object type stan_mlnmr ... Additional arguments passed ggdist plot stat. stat Character string specifying ggdist plot stat used summarise integration error posterior. Default \"violin\", equivalent \"eye\" cosmetic tweaks. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"vertical\" show_expected_rate Logical, show typical convergence rate \\(1/N\\)? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot numerical integration error — plot_integration_error","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot numerical integration error — plot_integration_error","text":"total number integration points set n_int argument add_integration(), intervals integration error estimated set int_thin argument nma(). typical convergence rate Quasi-Monte Carlo integration (used ) \\(1/N\\), default displayed plot output. integration error thinning interval \\(N_\\mathrm{thin}\\) estimated point posterior distribution subtracting final estimate (using n_int points) estimate using first \\(N_\\mathrm{thin}\\) points.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"note-for-survival-models","dir":"Reference","previous_headings":"","what":"Note for survival models","title":"Plot numerical integration error — plot_integration_error","text":"function supported survival/time--event models. save cumulative integration points efficiency reasons (time memory).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot numerical integration error — plot_integration_error","text":"","code":"## Plaque psoriasis ML-NMR # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.  # \\donttest{ # Fit the ML-NMR model pso_fit <- nma(pso_net, refresh = if (interactive()) 200 else 0,                trt_effects = \"fixed\",                link = \"probit\",                likelihood = \"bernoulli2\",                regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                class_interactions = \"common\",                prior_intercept = normal(scale = 10),                prior_trt = normal(scale = 10),                prior_reg = normal(scale = 10),                init_r = 0.1,                QR = TRUE,                # Set the thinning factor for saving the cumulative results                # (This also sets int_check = FALSE)                int_thin = 8) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25% #> beta[durnpso]                           0.04    0.00 0.06    -0.08     0.00 #> beta[prevsys]                          -0.13    0.00 0.16    -0.45    -0.24 #> beta[bsa]                              -0.06    0.01 0.45    -0.98    -0.36 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02 #> beta[psa]                              -0.08    0.00 0.17    -0.44    -0.20 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.14    -0.06 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.19    -0.18     0.05 #> beta[prevsys:.trtclassIL blocker]       0.06    0.00 0.18    -0.28    -0.06 #> beta[bsa:.trtclassTNFa blocker]         0.06    0.01 0.52    -0.91    -0.31 #> beta[bsa:.trtclassIL blocker]           0.29    0.01 0.49    -0.63    -0.05 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.03    -0.23    -0.19 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12 #> beta[psa:.trtclassTNFa blocker]        -0.05    0.00 0.21    -0.47    -0.19 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.19    -0.34    -0.12 #> d[ETN]                                  1.55    0.00 0.08     1.40     1.50 #> d[IXE_Q2W]                              2.96    0.00 0.09     2.79     2.90 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.39     2.49 #> d[SEC_150]                              2.14    0.00 0.12     1.92     2.06 #> d[SEC_300]                              2.45    0.00 0.12     2.22     2.37 #> lp__                                -1576.36    0.09 3.51 -1583.88 -1578.58 #>                                          50%      75%    97.5% n_eff Rhat #> beta[durnpso]                           0.05     0.09     0.16  5202    1 #> beta[prevsys]                          -0.13    -0.03     0.19  5740    1 #> beta[bsa]                              -0.04     0.24     0.77  4615    1 #> beta[weight]                            0.04     0.06     0.09  4581    1 #> beta[psa]                              -0.08     0.04     0.25  5289    1 #> beta[durnpso:.trtclassTNFa blocker]    -0.03     0.02     0.12  5217    1 #> beta[durnpso:.trtclassIL blocker]      -0.01     0.03     0.12  6190    1 #> beta[prevsys:.trtclassTNFa blocker]     0.18     0.31     0.55  5477    1 #> beta[prevsys:.trtclassIL blocker]       0.06     0.18     0.41  7564    1 #> beta[bsa:.trtclassTNFa blocker]         0.05     0.40     1.11  4472    1 #> beta[bsa:.trtclassIL blocker]           0.28     0.62     1.25  5378    1 #> beta[weight:.trtclassTNFa blocker]     -0.17    -0.14    -0.10  4626    1 #> beta[weight:.trtclassIL blocker]       -0.10    -0.08    -0.04  5191    1 #> beta[psa:.trtclassTNFa blocker]        -0.05     0.09     0.37  5409    1 #> beta[psa:.trtclassIL blocker]           0.01     0.14     0.40  6259    1 #> d[ETN]                                  1.55     1.61     1.71  3795    1 #> d[IXE_Q2W]                              2.96     3.01     3.13  4389    1 #> d[IXE_Q4W]                              2.54     2.60     2.70  5413    1 #> d[SEC_150]                              2.14     2.23     2.37  4505    1 #> d[SEC_300]                              2.45     2.53     2.68  5583    1 #> lp__                                -1575.98 -1573.84 -1570.47  1656    1 #>  #> Samples were drawn using NUTS(diag_e) at Wed Jan 17 14:30:24 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1).  # Plot numerical integration error plot_integration_error(pso_fit)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot prior vs posterior distribution — plot_prior_posterior","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"Produce plots comparing prior posterior distributions model parameters.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"","code":"plot_prior_posterior(   x,   ...,   prior = NULL,   post_args = list(),   prior_args = list(),   overlay = c(\"prior\", \"posterior\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"x stan_nma object ... Additional arguments passed methods prior Character vector selecting prior posterior distribution(s) plot. May include \"intercept\", \"trt\", \"het\", \"reg\", \"aux\", appropriate. post_args List arguments passed ggplot2::geom_histogram control plot output posterior distribution prior_args List arguments passed ggplot2::geom_path control plot output prior distribution. Additionally, n controls number points density curve evaluated (default 500), p_limits controls endpoints curve quantiles (default c(.001, .999)). overlay String, prior posterior shown top? Default \"prior\". ref_line Numeric vector positions reference lines, default reference lines drawn","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"Prior distributions displayed lines, posterior distributions displayed histograms.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"","code":"## Smoking cessation NMA # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Plot prior vs. posterior, by default all parameters are plotted plot_prior_posterior(smk_fit_RE)   # Plot prior vs. posterior for heterogeneity SD only plot_prior_posterior(smk_fit_RE, prior = \"het\")   # Customise plot plot_prior_posterior(smk_fit_RE, prior = \"het\",                      prior_args = list(colour = \"darkred\", size = 2),                      post_args = list(alpha = 0.6))  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":null,"dir":"Reference","previous_headings":"","what":"Treatment rankings and rank probabilities — posterior_ranks","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"Produce posterior treatment rankings rank probabilities fitted NMA model. meta-regression fitted effect modifier interactions treatment, differ study population.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"","code":"posterior_ranks(   x,   newdata = NULL,   study = NULL,   lower_better = TRUE,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   sucra = FALSE,   summary = TRUE )  posterior_rank_probs(   x,   newdata = NULL,   study = NULL,   lower_better = TRUE,   cumulative = FALSE,   sucra = FALSE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"x stan_nma object created nma() newdata used regression model fitted. data frame study details, one row per study, giving covariate values produce relative effects. Column names must match variables regression model. NULL, relative effects produced studies network. study Column newdata specifies study names, otherwise studies labelled row number. lower_better Logical, lower treatment effects better (TRUE; default) higher better (FALSE)? See details. probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) sucra Logical, calculate surface cumulative ranking curve (SUCRA) treatment? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE. cumulative Logical, return cumulative rank probabilities? Default FALSE, return posterior probabilities treatment given rank. TRUE, cumulative posterior rank probabilities returned treatment given rank better.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"function posterior_ranks() produces posterior rankings, distribution (e.g. mean/median rank 95% Credible Interval). function posterior_rank_probs() produces rank probabilities, give posterior probabilities ranked first, second, etc. treatments. argument lower_better specifies whether lower treatment effects higher treatment effects preferred. example, negative binary outcome lower (negative) log odds ratios preferred, lower_better = TRUE. Conversely, example, treatments aim increase rate positive outcome lower_better = FALSE.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce posterior ranks smk_rank_RE <- posterior_ranks(smk_fit_RE, lower_better = FALSE) smk_rank_RE #>                              mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[No intervention]        3.89 0.32    3   4   4   4     4     2357       NA #> rank[Group counselling]      1.36 0.62    1   1   1   2     3     3355     3388 #> rank[Individual counselling] 1.93 0.62    1   2   2   2     3     2955       NA #> rank[Self-help]              2.82 0.68    1   3   3   3     4     2656       NA #>                              Rhat #> rank[No intervention]           1 #> rank[Group counselling]         1 #> rank[Individual counselling]    1 #> rank[Self-help]                 1 plot(smk_rank_RE)   # Produce rank probabilities smk_rankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE) smk_rankprob_RE #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.10       0.9 #> d[Group counselling]           0.71      0.22      0.06       0.0 #> d[Individual counselling]      0.23      0.61      0.16       0.0 #> d[Self-help]                   0.06      0.17      0.68       0.1 plot(smk_rankprob_RE)   # Produce cumulative rank probabilities smk_cumrankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE,                                            cumulative = TRUE) smk_cumrankprob_RE #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00       0.1         1 #> d[Group counselling]           0.71      0.93       1.0         1 #> d[Individual counselling]      0.23      0.84       1.0         1 #> d[Self-help]                   0.06      0.22       0.9         1 plot(smk_cumrankprob_RE)   # Further customisation is possible with ggplot commands plot(smk_cumrankprob_RE) +   ggplot2::facet_null() +   ggplot2::aes(colour = Treatment)  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Produce population-adjusted rankings for all study populations in # the network  # Ranks pso_rank <- posterior_ranks(pso_fit) pso_rank #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[FIXTURE: PBO]     1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[FIXTURE: ETN]     2.00 0.00    2   2   2   2     2       NA       NA   NA #> rank[FIXTURE: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[FIXTURE: IXE_Q4W] 4.77 0.42    4   5   5   5     5     4082       NA    1 #> rank[FIXTURE: SEC_150] 3.00 0.04    3   3   3   3     3     4026     4026    1 #> rank[FIXTURE: SEC_300] 4.22 0.42    4   4   4   4     5     3990       NA    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-1: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-1: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-1: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA #> rank[UNCOVER-1: IXE_Q4W] 4.77 0.42    4   5   5   5     5     4082       NA #> rank[UNCOVER-1: SEC_150] 3.00 0.04    3   3   3   3     3     4026     4026 #> rank[UNCOVER-1: SEC_300] 4.22 0.42    4   4   4   4     5     3990       NA #>                          Rhat #> rank[UNCOVER-1: PBO]       NA #> rank[UNCOVER-1: ETN]       NA #> rank[UNCOVER-1: IXE_Q2W]   NA #> rank[UNCOVER-1: IXE_Q4W]    1 #> rank[UNCOVER-1: SEC_150]    1 #> rank[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-2: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-2: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-2: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA #> rank[UNCOVER-2: IXE_Q4W] 4.77 0.42    4   5   5   5     5     4082       NA #> rank[UNCOVER-2: SEC_150] 3.00 0.04    3   3   3   3     3     4026     4026 #> rank[UNCOVER-2: SEC_300] 4.22 0.42    4   4   4   4     5     3990       NA #>                          Rhat #> rank[UNCOVER-2: PBO]       NA #> rank[UNCOVER-2: ETN]       NA #> rank[UNCOVER-2: IXE_Q2W]   NA #> rank[UNCOVER-2: IXE_Q4W]    1 #> rank[UNCOVER-2: SEC_150]    1 #> rank[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-3: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-3: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-3: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA #> rank[UNCOVER-3: IXE_Q4W] 4.77 0.42    4   5   5   5     5     4082       NA #> rank[UNCOVER-3: SEC_150] 3.00 0.04    3   3   3   3     3     4026     4026 #> rank[UNCOVER-3: SEC_300] 4.22 0.42    4   4   4   4     5     3990       NA #>                          Rhat #> rank[UNCOVER-3: PBO]       NA #> rank[UNCOVER-3: ETN]       NA #> rank[UNCOVER-3: IXE_Q2W]   NA #> rank[UNCOVER-3: IXE_Q4W]    1 #> rank[UNCOVER-3: SEC_150]    1 #> rank[UNCOVER-3: SEC_300]    1 #>  plot(pso_rank)   # Rank probabilities pso_rankprobs <- posterior_rank_probs(pso_fit) pso_rankprobs #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             1         0         0      0.00      0.00         0 #> d[FIXTURE: ETN]             0         1         0      0.00      0.00         0 #> d[FIXTURE: IXE_Q2W]         0         0         0      0.00      0.00         1 #> d[FIXTURE: IXE_Q4W]         0         0         0      0.22      0.78         0 #> d[FIXTURE: SEC_150]         0         0         1      0.00      0.00         0 #> d[FIXTURE: SEC_300]         0         0         0      0.77      0.22         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-1: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-1: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-1: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-1: IXE_Q4W]         0         0         0      0.22      0.78 #> d[UNCOVER-1: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-1: SEC_300]         0         0         0      0.77      0.22 #>                       p_rank[6] #> d[UNCOVER-1: PBO]             0 #> d[UNCOVER-1: ETN]             0 #> d[UNCOVER-1: IXE_Q2W]         1 #> d[UNCOVER-1: IXE_Q4W]         0 #> d[UNCOVER-1: SEC_150]         0 #> d[UNCOVER-1: SEC_300]         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-2: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-2: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-2: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-2: IXE_Q4W]         0         0         0      0.22      0.78 #> d[UNCOVER-2: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-2: SEC_300]         0         0         0      0.77      0.22 #>                       p_rank[6] #> d[UNCOVER-2: PBO]             0 #> d[UNCOVER-2: ETN]             0 #> d[UNCOVER-2: IXE_Q2W]         1 #> d[UNCOVER-2: IXE_Q4W]         0 #> d[UNCOVER-2: SEC_150]         0 #> d[UNCOVER-2: SEC_300]         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-3: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-3: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-3: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-3: IXE_Q4W]         0         0         0      0.22      0.78 #> d[UNCOVER-3: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-3: SEC_300]         0         0         0      0.77      0.22 #>                       p_rank[6] #> d[UNCOVER-3: PBO]             0 #> d[UNCOVER-3: ETN]             0 #> d[UNCOVER-3: IXE_Q2W]         1 #> d[UNCOVER-3: IXE_Q4W]         0 #> d[UNCOVER-3: SEC_150]         0 #> d[UNCOVER-3: SEC_300]         0 #>  plot(pso_rankprobs)   # Cumulative rank probabilities pso_cumrankprobs <- posterior_rank_probs(pso_fit, cumulative = TRUE) pso_cumrankprobs #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             1         1         1      1.00         1         1 #> d[FIXTURE: ETN]             0         1         1      1.00         1         1 #> d[FIXTURE: IXE_Q2W]         0         0         0      0.00         0         1 #> d[FIXTURE: IXE_Q4W]         0         0         0      0.22         1         1 #> d[FIXTURE: SEC_150]         0         0         1      1.00         1         1 #> d[FIXTURE: SEC_300]         0         0         0      0.78         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-1: PBO]             1         1         1      1.00         1 #> d[UNCOVER-1: ETN]             0         1         1      1.00         1 #> d[UNCOVER-1: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-1: IXE_Q4W]         0         0         0      0.22         1 #> d[UNCOVER-1: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-1: SEC_300]         0         0         0      0.78         1 #>                       p_rank[6] #> d[UNCOVER-1: PBO]             1 #> d[UNCOVER-1: ETN]             1 #> d[UNCOVER-1: IXE_Q2W]         1 #> d[UNCOVER-1: IXE_Q4W]         1 #> d[UNCOVER-1: SEC_150]         1 #> d[UNCOVER-1: SEC_300]         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-2: PBO]             1         1         1      1.00         1 #> d[UNCOVER-2: ETN]             0         1         1      1.00         1 #> d[UNCOVER-2: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-2: IXE_Q4W]         0         0         0      0.22         1 #> d[UNCOVER-2: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-2: SEC_300]         0         0         0      0.78         1 #>                       p_rank[6] #> d[UNCOVER-2: PBO]             1 #> d[UNCOVER-2: ETN]             1 #> d[UNCOVER-2: IXE_Q2W]         1 #> d[UNCOVER-2: IXE_Q4W]         1 #> d[UNCOVER-2: SEC_150]         1 #> d[UNCOVER-2: SEC_300]         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-3: PBO]             1         1         1      1.00         1 #> d[UNCOVER-3: ETN]             0         1         1      1.00         1 #> d[UNCOVER-3: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-3: IXE_Q4W]         0         0         0      0.22         1 #> d[UNCOVER-3: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-3: SEC_300]         0         0         0      0.78         1 #>                       p_rank[6] #> d[UNCOVER-3: PBO]             1 #> d[UNCOVER-3: ETN]             1 #> d[UNCOVER-3: IXE_Q2W]         1 #> d[UNCOVER-3: IXE_Q4W]         1 #> d[UNCOVER-3: SEC_150]         1 #> d[UNCOVER-3: SEC_300]         1 #>  plot(pso_cumrankprobs)   # Produce population-adjusted rankings for a different target # population new_agd_means <- data.frame(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3)  # Ranks posterior_ranks(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                      mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[New 1: PBO]     1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[New 1: ETN]     2.00 0.00    2   2   2   2     2       NA       NA   NA #> rank[New 1: IXE_Q2W] 6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[New 1: IXE_Q4W] 4.77 0.42    4   5   5   5     5     4082       NA    1 #> rank[New 1: SEC_150] 3.00 0.04    3   3   3   3     3     4026     4026    1 #> rank[New 1: SEC_300] 4.22 0.42    4   4   4   4     5     3990       NA    1 #>   # Rank probabilities posterior_rank_probs(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[New 1: PBO]             1         0         0      0.00      0.00         0 #> d[New 1: ETN]             0         1         0      0.00      0.00         0 #> d[New 1: IXE_Q2W]         0         0         0      0.00      0.00         1 #> d[New 1: IXE_Q4W]         0         0         0      0.22      0.78         0 #> d[New 1: SEC_150]         0         0         1      0.00      0.00         0 #> d[New 1: SEC_300]         0         0         0      0.77      0.22         0 #>   # Cumulative rank probabilities posterior_rank_probs(pso_fit, newdata = new_agd_means,                      cumulative = TRUE) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[New 1: PBO]             1         1         1      1.00         1         1 #> d[New 1: ETN]             0         1         1      1.00         1         1 #> d[New 1: IXE_Q2W]         0         0         0      0.00         0         1 #> d[New 1: IXE_Q4W]         0         0         0      0.22         1         1 #> d[New 1: SEC_150]         0         0         1      1.00         1         1 #> d[New 1: SEC_300]         0         0         0      0.78         1         1 #>  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions of absolute effects from NMA models — predict.stan_nma","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Obtain predictions absolute effects NMA models fitted nma(). example, model fitted binary data logit link, predicted outcome probabilities log odds can produced. survival models, predictions can made survival probabilities, (cumulative) hazards, (restricted) mean survival times, quantiles including median survival times. IPD NMA ML-NMR model fitted, predictions can produced either individual level aggregate level. Aggregate-level predictions population-average absolute effects; marginalised standardised population. example, average event probabilities logistic regression, marginal (standardised) survival probabilities survival model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"","code":"# S3 method for stan_nma predict(   object,   ...,   baseline = NULL,   newdata = NULL,   study = NULL,   trt_ref = NULL,   type = c(\"link\", \"response\"),   level = c(\"aggregate\", \"individual\"),   baseline_type = c(\"link\", \"response\"),   baseline_level = c(\"individual\", \"aggregate\"),   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE )  # S3 method for stan_nma_surv predict(   object,   times = NULL,   ...,   baseline = NULL,   aux = NULL,   newdata = NULL,   study = NULL,   trt_ref = NULL,   type = c(\"survival\", \"hazard\", \"cumhaz\", \"mean\", \"median\", \"quantile\", \"rmst\", \"link\"),   quantiles = c(0.25, 0.5, 0.75),   level = c(\"aggregate\", \"individual\"),   times_seq = NULL,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"object stan_nma object created nma(). ... Additional arguments, passed uniroot() regression models baseline_level = \"aggregate\". baseline optional distr() distribution baseline response (.e. intercept), produce absolute effects. Can also character string naming study network take estimated baseline response distribution . NULL, predictions produced using baseline response study network IPD arm-based AgD. regression models, may list distr() distributions (study names network use baseline distributions ) length number studies newdata, possibly named studies newdata otherwise order appearance newdata. Use baseline_type baseline_level arguments specify whether distribution response linear predictor scale, (ML-NMR models including IPD) whether applies individual reference level covariates entire newdata population, respectively. example, model logit link baseline_type = \"link\", distribution baseline log odds event. survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_type always \"link\", baseline_level \"individual\" IPD NMA ML-NMR, \"aggregate\" AgD NMA). Use trt_ref argument specify treatment distribution applies . newdata required regression model fitted baseline specified. data frame covariate details, produce predictions. Column names must match variables regression model. level = \"aggregate\" either data frame integration points produced add_integration() (one row per study), data frame individual covariate values (one row per individual) summarised . level = \"individual\" data frame individual covariate values, one row per individual. NULL, predictions produced studies IPD /arm-based AgD network, depending value level. study Column newdata specifies study names IDs. specified: newdata contains integration points produced add_integration(), studies labelled sequentially row; otherwise data assumed come single study. trt_ref Treatment baseline response distribution refers, baseline specified. default, baseline response distribution refer network reference treatment. Coerced character string. type Whether produce predictions \"link\" scale (default, e.g. log odds) \"response\" scale (e.g. probabilities). survival models, options \"survival\" survival probabilities (default), \"hazard\" hazards, \"cumhaz\" cumulative hazards, \"mean\" mean survival times, \"quantile\" quantiles survival time distribution, \"median\" median survival times (equivalent type = \"quantile\" quantiles = 0.5), \"rmst\" restricted mean survival times, \"link\" linear predictor. type = \"survival\", \"hazard\" \"cumhaz\", predictions given times specified times event/censoring times network times = NULL. type = \"rmst\", restricted time horizon specified times, times = NULL earliest last follow-time amongst studies network used. level = \"aggregate\", correspond standardised survival function (see details). level level predictions produced, either \"aggregate\" (default), \"individual\". baseline specified, predictions produced IPD studies network level \"individual\" \"aggregate\", arm-based AgD studies network level \"aggregate\". baseline_type baseline distribution given, specifies whether corresponds \"link\" scale (default, e.g. log odds) \"response\" scale (e.g. probabilities). survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_type always \"link\"). baseline_level baseline distribution given, specifies whether corresponds individual reference level covariates (\"individual\", default), (unadjusted) average outcome reference treatment newdata population (\"aggregate\"). Ignored AgD NMA, since option \"aggregate\" instance. survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_level \"individual\" IPD NMA ML-NMR, \"aggregate\" AgD NMA). probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) predictive_distribution Logical, random effects model fitted, predictive distribution absolute effects new study returned? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE. times numeric vector times evaluate predictions . Alternatively, newdata specified, times can name column newdata contains times. NULL (default) predictions made event/censoring times studies included network (according times_seq). used type \"survival\", \"hazard\", \"cumhaz\" \"rmst\". aux optional distr() distribution auxiliary parameter(s) baseline hazard (e.g. shapes). Can also character string naming study network take estimated auxiliary parameter distribution . NULL, predictions produced using parameter estimates study network IPD arm-based AgD. regression models, may list distr() distributions (study names network use auxiliary parameters ) length number studies newdata, possibly named study names otherwise order appearance newdata. quantiles numeric vector quantiles survival time distribution produce estimates type = \"quantile\". times_seq positive integer, specified evaluate predictions many evenly-spaced event times 0 latest follow-time study, instead every observed event/censoring time. used newdata = NULL type \"survival\", \"hazard\" \"cumhaz\". can useful plotting survival (cumulative) hazard curves, prediction every observed even/censoring time unnecessary can slow. call within plot() detected, e.g. like plot(predict(fit, type = \"survival\")), times_seq default 50.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"aggregate-level-predictions-from-ipd-nma-and-ml-nmr-models","dir":"Reference","previous_headings":"","what":"Aggregate-level predictions from IPD NMA and ML-NMR models","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Population-average absolute effects can produced IPD NMA ML-NMR models level = \"aggregate\". Predictions averaged target population (.e. standardised/marginalised), either (numerical) integration joint covariate distribution (AgD studies network ML-NMR, AgD newdata integration points created add_integration()), averaging predictions sample individuals (IPD studies network IPD NMA/ML-NMR, IPD newdata). example, binary outcome, population-average event probabilities treatment \\(k\\) study/population \\(j\\) $$\\bar{p}_{jk} = \\int_\\mathfrak{X} p_{jk}(\\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x}$$ joint covariate distribution \\(f_{jk}(\\mathbf{x})\\) support \\(\\mathfrak{X}\\) $$\\bar{p}_{jk} = \\sum_i p_{jk}(\\mathbf{x}_i)$$ sample individuals covariates \\(\\mathbf{x}_i\\). Population-average absolute predictions follow similarly types outcomes, however survival outcomes specific considerations.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"standardised-survival-predictions","dir":"Reference","previous_headings":"","what":"Standardised survival predictions","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Different types population-average survival predictions, often called standardised survival predictions, follow standardised survival function created integrating (equivalently averaging) individual-level survival functions time \\(t\\): $$\\bar{S}_{jk}(t) = \\int_\\mathfrak{X} S_{jk}(t | \\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x}$$ produced using type = \"survival\". standardised hazard function corresponding standardised survival function weighted average individual-level hazard functions $$\\bar{h}_{jk}(t) = \\frac{\\int_\\mathfrak{X} S_{jk}(t | \\mathbf{x}) h_{jk}(t | \\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x} }{\\bar{S}_{jk}(t)}$$ weighted probability surviving time \\(t\\). produced using type = \"hazard\". corresponding standardised cumulative hazard function $$\\bar{H}_{jk}(t) = -\\log(\\bar{S}_{jk}(t))$$ produced using type = \"cumhaz\". Quantiles medians standardised survival times found solving $$\\bar{S}_{jk}(t) = 1-\\alpha$$ \\(\\alpha\\%\\) quantile, using numerical root finding. produced using type = \"quantile\" \"median\". (Restricted) means standardised survival times found integrating $$\\mathrm{RMST}_{jk}(t^*) = \\int_0^{t^*} \\bar{S}_{jk}(t) dt$$ restricted time horizon \\(t^*\\), \\(t^*=\\infty\\) mean standardised survival time. produced using type = \"rmst\" \"mean\".","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Predicted log odds of success in each study in the network predict(smk_fit_RE) #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[1: No intervention]        -2.79 0.33 -3.46 -3.00 -2.78 -2.56 -2.16 #> pred[1: Group counselling]      -1.68 0.50 -2.67 -2.01 -1.70 -1.34 -0.68 #> pred[1: Individual counselling] -1.94 0.39 -2.71 -2.20 -1.94 -1.68 -1.17 #> pred[1: Self-help]              -2.29 0.51 -3.29 -2.62 -2.29 -1.95 -1.30 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[1: No intervention]            5721     3121    1 #> pred[1: Group counselling]          2749     2677    1 #> pred[1: Individual counselling]     2577     2884    1 #> pred[1: Self-help]                  2743     2773    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[2: No intervention]        -2.58 0.77 -4.19 -3.06 -2.57 -2.08 -1.12 #> pred[2: Group counselling]      -1.47 0.77 -3.03 -1.97 -1.47 -0.98  0.02 #> pred[2: Individual counselling] -1.73 0.76 -3.26 -2.21 -1.74 -1.25 -0.23 #> pred[2: Self-help]              -2.08 0.76 -3.60 -2.56 -2.07 -1.60 -0.57 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[2: No intervention]            2739     2354    1 #> pred[2: Group counselling]          3287     2592    1 #> pred[2: Individual counselling]     3076     2524    1 #> pred[2: Self-help]                  3811     2812    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[3: No intervention]        -2.14 0.12 -2.39 -2.22 -2.14 -2.06 -1.92 #> pred[3: Group counselling]      -1.04 0.45 -1.91 -1.32 -1.05 -0.75 -0.14 #> pred[3: Individual counselling] -1.29 0.26 -1.81 -1.47 -1.29 -1.13 -0.77 #> pred[3: Self-help]              -1.64 0.41 -2.51 -1.91 -1.64 -1.38 -0.85 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[3: No intervention]            7281     3087    1 #> pred[3: Group counselling]          2442     2702    1 #> pred[3: Individual counselling]     1490     2630    1 #> pred[3: Self-help]                  2045     2636    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[4: No intervention]        -4.05 0.56 -5.22 -4.41 -4.03 -3.66 -3.03 #> pred[4: Group counselling]      -2.94 0.69 -4.36 -3.39 -2.94 -2.49 -1.63 #> pred[4: Individual counselling] -3.20 0.57 -4.39 -3.56 -3.18 -2.81 -2.13 #> pred[4: Self-help]              -3.55 0.68 -4.91 -3.99 -3.52 -3.08 -2.25 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[4: No intervention]            4649     2750    1 #> pred[4: Group counselling]          4284     3136    1 #> pred[4: Individual counselling]     4909     3179    1 #> pred[4: Self-help]                  3718     3062    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[5: No intervention]        -2.15 0.14 -2.43 -2.25 -2.15 -2.06 -1.89 #> pred[5: Group counselling]      -1.05 0.45 -1.94 -1.34 -1.06 -0.75 -0.15 #> pred[5: Individual counselling] -1.30 0.28 -1.83 -1.48 -1.32 -1.12 -0.75 #> pred[5: Self-help]              -1.66 0.42 -2.49 -1.92 -1.65 -1.38 -0.84 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[5: No intervention]            6408     2986    1 #> pred[5: Group counselling]          2379     2672    1 #> pred[5: Individual counselling]     1431     2558    1 #> pred[5: Self-help]                  2006     2566    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[6: No intervention]        -3.42 0.73 -5.07 -3.85 -3.36 -2.92 -2.16 #> pred[6: Group counselling]      -2.31 0.80 -4.06 -2.81 -2.26 -1.77 -0.95 #> pred[6: Individual counselling] -2.57 0.71 -4.13 -3.00 -2.53 -2.08 -1.33 #> pred[6: Self-help]              -2.92 0.80 -4.69 -3.41 -2.86 -2.37 -1.53 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[6: No intervention]            3052     2287    1 #> pred[6: Group counselling]          3643     2614    1 #> pred[6: Individual counselling]     3270     2354    1 #> pred[6: Self-help]                  3136     2632    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[7: No intervention]        -3.02 0.44 -3.96 -3.29 -2.99 -2.71 -2.25 #> pred[7: Group counselling]      -1.91 0.58 -3.14 -2.28 -1.88 -1.51 -0.81 #> pred[7: Individual counselling] -2.17 0.46 -3.16 -2.46 -2.14 -1.85 -1.34 #> pred[7: Self-help]              -2.52 0.57 -3.68 -2.88 -2.50 -2.12 -1.45 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[7: No intervention]            4486     2888    1 #> pred[7: Group counselling]          3504     2610    1 #> pred[7: Individual counselling]     3496     2560    1 #> pred[7: Self-help]                  3301     2516    1 #>  #> ---------------------------------------------------------------------- Study: 8 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[8: No intervention]        -2.72 0.62 -4.06 -3.11 -2.68 -2.29 -1.63 #> pred[8: Group counselling]      -1.61 0.71 -3.11 -2.05 -1.57 -1.14 -0.32 #> pred[8: Individual counselling] -1.87 0.61 -3.17 -2.26 -1.83 -1.45 -0.77 #> pred[8: Self-help]              -2.22 0.71 -3.79 -2.67 -2.16 -1.74 -0.92 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[8: No intervention]            4104     2933    1 #> pred[8: Group counselling]          4601     2860    1 #> pred[8: Individual counselling]     4107     2633    1 #> pred[8: Self-help]                  3857     2827    1 #>  #> ---------------------------------------------------------------------- Study: 9 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[9: No intervention]        -1.85 0.43 -2.72 -2.11 -1.84 -1.55 -1.06 #> pred[9: Group counselling]      -0.74 0.60 -1.95 -1.13 -0.74 -0.35  0.46 #> pred[9: Individual counselling] -1.00 0.47 -1.93 -1.30 -0.99 -0.68 -0.09 #> pred[9: Self-help]              -1.35 0.58 -2.49 -1.73 -1.34 -0.97 -0.23 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[9: No intervention]            5637     2874    1 #> pred[9: Group counselling]          3310     2857    1 #> pred[9: Individual counselling]     3531     2899    1 #> pred[9: Self-help]                  3260     2722    1 #>  #> --------------------------------------------------------------------- Study: 10 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[10: No intervention]        -2.08 0.12 -2.32 -2.16 -2.08 -2.00 -1.85 #> pred[10: Group counselling]      -0.97 0.44 -1.81 -1.27 -0.98 -0.69 -0.09 #> pred[10: Individual counselling] -1.23 0.27 -1.75 -1.41 -1.24 -1.07 -0.69 #> pred[10: Self-help]              -1.58 0.41 -2.38 -1.83 -1.58 -1.31 -0.79 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[10: No intervention]            7633     3017    1 #> pred[10: Group counselling]          2401     2716    1 #> pred[10: Individual counselling]     1523     2494    1 #> pred[10: Self-help]                  2049     2573    1 #>  #> --------------------------------------------------------------------- Study: 11 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[11: No intervention]        -3.62 0.23 -4.10 -3.77 -3.61 -3.46 -3.20 #> pred[11: Group counselling]      -2.52 0.48 -3.46 -2.84 -2.52 -2.20 -1.56 #> pred[11: Individual counselling] -2.77 0.33 -3.43 -2.98 -2.77 -2.56 -2.13 #> pred[11: Self-help]              -3.12 0.44 -4.00 -3.41 -3.13 -2.83 -2.26 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[11: No intervention]            6723     2840    1 #> pred[11: Group counselling]          2569     3080    1 #> pred[11: Individual counselling]     2086     2936    1 #> pred[11: Self-help]                  2082     2650    1 #>  #> --------------------------------------------------------------------- Study: 12 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[12: No intervention]        -2.22 0.13 -2.48 -2.30 -2.22 -2.13 -1.97 #> pred[12: Group counselling]      -1.11 0.45 -1.96 -1.40 -1.13 -0.82 -0.22 #> pred[12: Individual counselling] -1.37 0.27 -1.90 -1.55 -1.38 -1.19 -0.84 #> pred[12: Self-help]              -1.72 0.41 -2.55 -1.99 -1.72 -1.44 -0.88 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[12: No intervention]            7081     3186    1 #> pred[12: Group counselling]          2369     2614    1 #> pred[12: Individual counselling]     1398     2413    1 #> pred[12: Self-help]                  2040     2510    1 #>  #> --------------------------------------------------------------------- Study: 13 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[13: No intervention]        -2.69 0.44 -3.58 -2.98 -2.67 -2.39 -1.87 #> pred[13: Group counselling]      -1.58 0.61 -2.78 -1.99 -1.59 -1.18 -0.39 #> pred[13: Individual counselling] -1.84 0.48 -2.80 -2.15 -1.82 -1.52 -0.92 #> pred[13: Self-help]              -2.19 0.58 -3.34 -2.57 -2.19 -1.80 -1.05 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[13: No intervention]            4599     2805    1 #> pred[13: Group counselling]          3220     3058    1 #> pred[13: Individual counselling]     3122     2644    1 #> pred[13: Self-help]                  2870     3021    1 #>  #> --------------------------------------------------------------------- Study: 14 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[14: No intervention]        -2.41 0.23 -2.88 -2.57 -2.40 -2.26 -1.97 #> pred[14: Group counselling]      -1.30 0.48 -2.23 -1.63 -1.32 -0.99 -0.34 #> pred[14: Individual counselling] -1.56 0.32 -2.17 -1.78 -1.56 -1.36 -0.92 #> pred[14: Self-help]              -1.91 0.46 -2.80 -2.21 -1.92 -1.61 -1.01 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[14: No intervention]            4830     2956    1 #> pred[14: Group counselling]          2729     2728    1 #> pred[14: Individual counselling]     2042     2834    1 #> pred[14: Self-help]                  2349     2967    1 #>  #> --------------------------------------------------------------------- Study: 15 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[15: No intervention]        -2.69 0.73 -4.30 -3.12 -2.63 -2.18 -1.43 #> pred[15: Group counselling]      -1.58 0.72 -3.13 -2.02 -1.54 -1.10 -0.28 #> pred[15: Individual counselling] -1.84 0.73 -3.46 -2.27 -1.78 -1.34 -0.56 #> pred[15: Self-help]              -2.19 0.79 -3.92 -2.67 -2.15 -1.65 -0.78 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[15: No intervention]            3275     2521    1 #> pred[15: Group counselling]          4021     2667    1 #> pred[15: Individual counselling]     3536     2343    1 #> pred[15: Self-help]                  3217     2426    1 #>  #> --------------------------------------------------------------------- Study: 16 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[16: No intervention]        -2.61 0.34 -3.33 -2.84 -2.60 -2.38 -1.99 #> pred[16: Group counselling]      -1.51 0.54 -2.56 -1.87 -1.50 -1.16 -0.46 #> pred[16: Individual counselling] -1.77 0.41 -2.60 -2.04 -1.77 -1.48 -0.98 #> pred[16: Self-help]              -2.12 0.48 -3.07 -2.43 -2.11 -1.80 -1.20 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[16: No intervention]            5542     2995    1 #> pred[16: Group counselling]          3204     3154    1 #> pred[16: Individual counselling]     2537     2777    1 #> pred[16: Self-help]                  2637     3039    1 #>  #> --------------------------------------------------------------------- Study: 17 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[17: No intervention]        -2.38 0.11 -2.60 -2.45 -2.37 -2.30 -2.17 #> pred[17: Group counselling]      -1.27 0.44 -2.11 -1.56 -1.28 -0.98 -0.39 #> pred[17: Individual counselling] -1.53 0.26 -2.02 -1.70 -1.53 -1.36 -1.00 #> pred[17: Self-help]              -1.88 0.41 -2.70 -2.14 -1.87 -1.61 -1.08 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[17: No intervention]            7637     2637    1 #> pred[17: Group counselling]          2289     2719    1 #> pred[17: Individual counselling]     1272     2140    1 #> pred[17: Self-help]                  1964     2331    1 #>  #> --------------------------------------------------------------------- Study: 18 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[18: No intervention]        -2.57 0.28 -3.14 -2.74 -2.56 -2.38 -2.06 #> pred[18: Group counselling]      -1.46 0.51 -2.45 -1.80 -1.48 -1.13 -0.44 #> pred[18: Individual counselling] -1.72 0.36 -2.40 -1.96 -1.72 -1.48 -1.03 #> pred[18: Self-help]              -2.07 0.48 -3.04 -2.37 -2.07 -1.75 -1.14 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[18: No intervention]            5825     2592    1 #> pred[18: Group counselling]          2591     2595    1 #> pred[18: Individual counselling]     2069     2669    1 #> pred[18: Self-help]                  2356     3009    1 #>  #> --------------------------------------------------------------------- Study: 19 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[19: No intervention]        -1.90 0.12 -2.14 -1.99 -1.90 -1.82 -1.68 #> pred[19: Group counselling]      -0.80 0.45 -1.64 -1.09 -0.81 -0.51  0.11 #> pred[19: Individual counselling] -1.05 0.27 -1.57 -1.23 -1.06 -0.87 -0.51 #> pred[19: Self-help]              -1.40 0.42 -2.23 -1.67 -1.41 -1.13 -0.58 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[19: No intervention]            8801     2983    1 #> pred[19: Group counselling]          2301     2514    1 #> pred[19: Individual counselling]     1406     2127    1 #> pred[19: Self-help]                  2012     2554    1 #>  #> --------------------------------------------------------------------- Study: 20 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[20: No intervention]        -2.80 0.12 -3.05 -2.88 -2.80 -2.72 -2.57 #> pred[20: Group counselling]      -1.69 0.45 -2.54 -1.99 -1.71 -1.40 -0.78 #> pred[20: Individual counselling] -1.95 0.26 -2.46 -2.13 -1.96 -1.78 -1.40 #> pred[20: Self-help]              -2.30 0.42 -3.14 -2.58 -2.30 -2.02 -1.50 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[20: No intervention]            7216     3235    1 #> pred[20: Group counselling]          2271     2444    1 #> pred[20: Individual counselling]     1417     2249    1 #> pred[20: Self-help]                  1961     2522    1 #>  #> --------------------------------------------------------------------- Study: 21 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[21: No intervention]        -1.11 0.80 -2.69 -1.62 -1.10 -0.60  0.47 #> pred[21: Group counselling]       0.00 0.86 -1.67 -0.55  0.00  0.54  1.68 #> pred[21: Individual counselling] -0.26 0.79 -1.81 -0.78 -0.27  0.23  1.30 #> pred[21: Self-help]              -0.61 0.80 -2.15 -1.13 -0.61 -0.10  0.97 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[21: No intervention]            3000     2832    1 #> pred[21: Group counselling]          3273     2809    1 #> pred[21: Individual counselling]     3348     3010    1 #> pred[21: Self-help]                  3816     3013    1 #>  #> --------------------------------------------------------------------- Study: 22 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[22: No intervention]        -2.41 0.85 -4.09 -2.96 -2.39 -1.86 -0.80 #> pred[22: Group counselling]      -1.30 0.80 -2.87 -1.82 -1.29 -0.78  0.26 #> pred[22: Individual counselling] -1.56 0.84 -3.22 -2.09 -1.55 -1.02  0.07 #> pred[22: Self-help]              -1.91 0.83 -3.55 -2.47 -1.89 -1.36 -0.33 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[22: No intervention]            2838     2694    1 #> pred[22: Group counselling]          3471     3018    1 #> pred[22: Individual counselling]     3073     2748    1 #> pred[22: Self-help]                  3569     2597    1 #>  #> --------------------------------------------------------------------- Study: 23 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[23: No intervention]        -2.32 0.80 -3.87 -2.85 -2.31 -1.79 -0.74 #> pred[23: Group counselling]      -1.21 0.78 -2.71 -1.72 -1.21 -0.72  0.38 #> pred[23: Individual counselling] -1.47 0.77 -2.97 -1.97 -1.47 -0.96  0.04 #> pred[23: Self-help]              -1.82 0.84 -3.47 -2.38 -1.82 -1.27 -0.14 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[23: No intervention]            3095     2901    1 #> pred[23: Group counselling]          3906     2858    1 #> pred[23: Individual counselling]     3850     2854    1 #> pred[23: Self-help]                  3508     2639    1 #>  #> --------------------------------------------------------------------- Study: 24 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[24: No intervention]        -2.82 0.84 -4.55 -3.36 -2.81 -2.29 -1.14 #> pred[24: Group counselling]      -1.72 0.83 -3.36 -2.26 -1.72 -1.16 -0.09 #> pred[24: Individual counselling] -1.97 0.81 -3.57 -2.49 -1.97 -1.44 -0.36 #> pred[24: Self-help]              -2.32 0.88 -4.08 -2.90 -2.33 -1.74 -0.59 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[24: No intervention]            3352     2569    1 #> pred[24: Group counselling]          4027     2956    1 #> pred[24: Individual counselling]     3922     3219    1 #> pred[24: Self-help]                  3522     2926    1 #>   # Predicted probabilities of success in each study in the network predict(smk_fit_RE, type = \"response\") #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[1: No intervention]        0.06 0.02 0.03 0.05 0.06 0.07  0.10     5721 #> pred[1: Group counselling]      0.17 0.07 0.06 0.12 0.16 0.21  0.34     2749 #> pred[1: Individual counselling] 0.13 0.04 0.06 0.10 0.13 0.16  0.24     2577 #> pred[1: Self-help]              0.10 0.05 0.04 0.07 0.09 0.12  0.21     2743 #>                                 Tail_ESS Rhat #> pred[1: No intervention]            3121    1 #> pred[1: Group counselling]          2677    1 #> pred[1: Individual counselling]     2884    1 #> pred[1: Self-help]                  2773    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[2: No intervention]        0.09 0.06 0.01 0.04 0.07 0.11  0.25     2739 #> pred[2: Group counselling]      0.21 0.12 0.05 0.12 0.19 0.27  0.51     3287 #> pred[2: Individual counselling] 0.17 0.10 0.04 0.10 0.15 0.22  0.44     3076 #> pred[2: Self-help]              0.13 0.09 0.03 0.07 0.11 0.17  0.36     3811 #>                                 Tail_ESS Rhat #> pred[2: No intervention]            2354    1 #> pred[2: Group counselling]          2592    1 #> pred[2: Individual counselling]     2524    1 #> pred[2: Self-help]                  2812    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[3: No intervention]        0.11 0.01 0.08 0.10 0.11 0.11  0.13     7281 #> pred[3: Group counselling]      0.27 0.09 0.13 0.21 0.26 0.32  0.47     2442 #> pred[3: Individual counselling] 0.22 0.04 0.14 0.19 0.22 0.24  0.32     1490 #> pred[3: Self-help]              0.17 0.06 0.08 0.13 0.16 0.20  0.30     2045 #>                                 Tail_ESS Rhat #> pred[3: No intervention]            3087    1 #> pred[3: Group counselling]          2702    1 #> pred[3: Individual counselling]     2630    1 #> pred[3: Self-help]                  2636    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[4: No intervention]        0.02 0.01 0.01 0.01 0.02 0.03  0.05     4649 #> pred[4: Group counselling]      0.06 0.04 0.01 0.03 0.05 0.08  0.16     4284 #> pred[4: Individual counselling] 0.04 0.02 0.01 0.03 0.04 0.06  0.11     4909 #> pred[4: Self-help]              0.03 0.02 0.01 0.02 0.03 0.04  0.09     3718 #>                                 Tail_ESS Rhat #> pred[4: No intervention]            2750    1 #> pred[4: Group counselling]          3136    1 #> pred[4: Individual counselling]     3179    1 #> pred[4: Self-help]                  3062    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[5: No intervention]        0.10 0.01 0.08 0.10 0.10 0.11  0.13     6408 #> pred[5: Group counselling]      0.27 0.09 0.13 0.21 0.26 0.32  0.46     2379 #> pred[5: Individual counselling] 0.22 0.05 0.14 0.18 0.21 0.25  0.32     1431 #> pred[5: Self-help]              0.17 0.06 0.08 0.13 0.16 0.20  0.30     2006 #>                                 Tail_ESS Rhat #> pred[5: No intervention]            2986    1 #> pred[5: Group counselling]          2672    1 #> pred[5: Individual counselling]     2558    1 #> pred[5: Self-help]                  2566    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[6: No intervention]        0.04 0.03 0.01 0.02 0.03 0.05  0.10     3052 #> pred[6: Group counselling]      0.11 0.07 0.02 0.06 0.09 0.15  0.28     3643 #> pred[6: Individual counselling] 0.08 0.05 0.02 0.05 0.07 0.11  0.21     3270 #> pred[6: Self-help]              0.06 0.04 0.01 0.03 0.05 0.09  0.18     3136 #>                                 Tail_ESS Rhat #> pred[6: No intervention]            2287    1 #> pred[6: Group counselling]          2614    1 #> pred[6: Individual counselling]     2354    1 #> pred[6: Self-help]                  2632    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[7: No intervention]        0.05 0.02 0.02 0.04 0.05 0.06  0.10     4486 #> pred[7: Group counselling]      0.14 0.07 0.04 0.09 0.13 0.18  0.31     3504 #> pred[7: Individual counselling] 0.11 0.04 0.04 0.08 0.11 0.14  0.21     3496 #> pred[7: Self-help]              0.08 0.04 0.02 0.05 0.08 0.11  0.19     3301 #>                                 Tail_ESS Rhat #> pred[7: No intervention]            2888    1 #> pred[7: Group counselling]          2610    1 #> pred[7: Individual counselling]     2560    1 #> pred[7: Self-help]                  2516    1 #>  #> ---------------------------------------------------------------------- Study: 8 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[8: No intervention]        0.07 0.04 0.02 0.04 0.06 0.09  0.16     4104 #> pred[8: Group counselling]      0.19 0.10 0.04 0.11 0.17 0.24  0.42     4601 #> pred[8: Individual counselling] 0.15 0.07 0.04 0.09 0.14 0.19  0.32     4107 #> pred[8: Self-help]              0.11 0.07 0.02 0.06 0.10 0.15  0.28     3857 #>                                 Tail_ESS Rhat #> pred[8: No intervention]            2933    1 #> pred[8: Group counselling]          2860    1 #> pred[8: Individual counselling]     2633    1 #> pred[8: Self-help]                  2827    1 #>  #> ---------------------------------------------------------------------- Study: 9 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[9: No intervention]        0.14 0.05 0.06 0.11 0.14 0.17  0.26     5637 #> pred[9: Group counselling]      0.34 0.13 0.12 0.24 0.32 0.41  0.61     3310 #> pred[9: Individual counselling] 0.28 0.09 0.13 0.21 0.27 0.34  0.48     3531 #> pred[9: Self-help]              0.22 0.10 0.08 0.15 0.21 0.28  0.44     3260 #>                                 Tail_ESS Rhat #> pred[9: No intervention]            2874    1 #> pred[9: Group counselling]          2857    1 #> pred[9: Individual counselling]     2899    1 #> pred[9: Self-help]                  2722    1 #>  #> --------------------------------------------------------------------- Study: 10 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[10: No intervention]        0.11 0.01 0.09 0.10 0.11 0.12  0.14     7633 #> pred[10: Group counselling]      0.28 0.09 0.14 0.22 0.27 0.33  0.48     2401 #> pred[10: Individual counselling] 0.23 0.05 0.15 0.20 0.23 0.26  0.33     1523 #> pred[10: Self-help]              0.18 0.06 0.08 0.14 0.17 0.21  0.31     2049 #>                                  Tail_ESS Rhat #> pred[10: No intervention]            3017    1 #> pred[10: Group counselling]          2716    1 #> pred[10: Individual counselling]     2494    1 #> pred[10: Self-help]                  2573    1 #>  #> --------------------------------------------------------------------- Study: 11 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[11: No intervention]        0.03 0.01 0.02 0.02 0.03 0.03  0.04     6723 #> pred[11: Group counselling]      0.08 0.04 0.03 0.06 0.07 0.10  0.17     2569 #> pred[11: Individual counselling] 0.06 0.02 0.03 0.05 0.06 0.07  0.11     2086 #> pred[11: Self-help]              0.05 0.02 0.02 0.03 0.04 0.06  0.09     2082 #>                                  Tail_ESS Rhat #> pred[11: No intervention]            2840    1 #> pred[11: Group counselling]          3080    1 #> pred[11: Individual counselling]     2936    1 #> pred[11: Self-help]                  2650    1 #>  #> --------------------------------------------------------------------- Study: 12 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[12: No intervention]        0.10 0.01 0.08 0.09 0.10 0.11  0.12     7081 #> pred[12: Group counselling]      0.26 0.08 0.12 0.20 0.24 0.31  0.45     2369 #> pred[12: Individual counselling] 0.21 0.04 0.13 0.18 0.20 0.23  0.30     1398 #> pred[12: Self-help]              0.16 0.06 0.07 0.12 0.15 0.19  0.29     2040 #>                                  Tail_ESS Rhat #> pred[12: No intervention]            3186    1 #> pred[12: Group counselling]          2614    1 #> pred[12: Individual counselling]     2413    1 #> pred[12: Self-help]                  2510    1 #>  #> --------------------------------------------------------------------- Study: 13 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[13: No intervention]        0.07 0.03 0.03 0.05 0.06 0.08  0.13     4599 #> pred[13: Group counselling]      0.19 0.09 0.06 0.12 0.17 0.24  0.40     3220 #> pred[13: Individual counselling] 0.15 0.06 0.06 0.10 0.14 0.18  0.29     3122 #> pred[13: Self-help]              0.11 0.06 0.03 0.07 0.10 0.14  0.26     2870 #>                                  Tail_ESS Rhat #> pred[13: No intervention]            2805    1 #> pred[13: Group counselling]          3058    1 #> pred[13: Individual counselling]     2644    1 #> pred[13: Self-help]                  3021    1 #>  #> --------------------------------------------------------------------- Study: 14 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[14: No intervention]        0.08 0.02 0.05 0.07 0.08 0.09  0.12     4830 #> pred[14: Group counselling]      0.22 0.08 0.10 0.16 0.21 0.27  0.42     2729 #> pred[14: Individual counselling] 0.18 0.05 0.10 0.14 0.17 0.20  0.29     2042 #> pred[14: Self-help]              0.14 0.05 0.06 0.10 0.13 0.17  0.27     2349 #>                                  Tail_ESS Rhat #> pred[14: No intervention]            2956    1 #> pred[14: Group counselling]          2728    1 #> pred[14: Individual counselling]     2834    1 #> pred[14: Self-help]                  2967    1 #>  #> --------------------------------------------------------------------- Study: 15 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[15: No intervention]        0.08 0.05 0.01 0.04 0.07 0.10  0.19     3275 #> pred[15: Group counselling]      0.19 0.10 0.04 0.12 0.18 0.25  0.43     4021 #> pred[15: Individual counselling] 0.16 0.09 0.03 0.09 0.14 0.21  0.36     3536 #> pred[15: Self-help]              0.12 0.08 0.02 0.06 0.10 0.16  0.31     3217 #>                                  Tail_ESS Rhat #> pred[15: No intervention]            2521    1 #> pred[15: Group counselling]          2667    1 #> pred[15: Individual counselling]     2343    1 #> pred[15: Self-help]                  2426    1 #>  #> --------------------------------------------------------------------- Study: 16 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[16: No intervention]        0.07 0.02 0.03 0.06 0.07 0.08  0.12     5542 #> pred[16: Group counselling]      0.19 0.08 0.07 0.13 0.18 0.24  0.39     3204 #> pred[16: Individual counselling] 0.15 0.05 0.07 0.12 0.15 0.19  0.27     2537 #> pred[16: Self-help]              0.12 0.05 0.04 0.08 0.11 0.14  0.23     2637 #>                                  Tail_ESS Rhat #> pred[16: No intervention]            2995    1 #> pred[16: Group counselling]          3154    1 #> pred[16: Individual counselling]     2777    1 #> pred[16: Self-help]                  3039    1 #>  #> --------------------------------------------------------------------- Study: 17 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[17: No intervention]        0.09 0.01 0.07 0.08 0.09 0.09  0.10     7637 #> pred[17: Group counselling]      0.23 0.08 0.11 0.17 0.22 0.27  0.40     2289 #> pred[17: Individual counselling] 0.18 0.04 0.12 0.16 0.18 0.20  0.27     1272 #> pred[17: Self-help]              0.14 0.05 0.06 0.11 0.13 0.17  0.25     1964 #>                                  Tail_ESS Rhat #> pred[17: No intervention]            2637    1 #> pred[17: Group counselling]          2719    1 #> pred[17: Individual counselling]     2140    1 #> pred[17: Self-help]                  2331    1 #>  #> --------------------------------------------------------------------- Study: 18 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[18: No intervention]        0.07 0.02 0.04 0.06 0.07 0.08  0.11     5825 #> pred[18: Group counselling]      0.20 0.08 0.08 0.14 0.19 0.24  0.39     2591 #> pred[18: Individual counselling] 0.16 0.05 0.08 0.12 0.15 0.19  0.26     2069 #> pred[18: Self-help]              0.12 0.05 0.05 0.09 0.11 0.15  0.24     2356 #>                                  Tail_ESS Rhat #> pred[18: No intervention]            2592    1 #> pred[18: Group counselling]          2595    1 #> pred[18: Individual counselling]     2669    1 #> pred[18: Self-help]                  3009    1 #>  #> --------------------------------------------------------------------- Study: 19 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[19: No intervention]        0.13 0.01 0.11 0.12 0.13 0.14  0.16     8801 #> pred[19: Group counselling]      0.32 0.09 0.16 0.25 0.31 0.38  0.53     2301 #> pred[19: Individual counselling] 0.26 0.05 0.17 0.23 0.26 0.29  0.37     1406 #> pred[19: Self-help]              0.21 0.07 0.10 0.16 0.20 0.24  0.36     2012 #>                                  Tail_ESS Rhat #> pred[19: No intervention]            2983    1 #> pred[19: Group counselling]          2514    1 #> pred[19: Individual counselling]     2127    1 #> pred[19: Self-help]                  2554    1 #>  #> --------------------------------------------------------------------- Study: 20 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[20: No intervention]        0.06 0.01 0.05 0.05 0.06 0.06  0.07     7216 #> pred[20: Group counselling]      0.16 0.06 0.07 0.12 0.15 0.20  0.31     2271 #> pred[20: Individual counselling] 0.13 0.03 0.08 0.11 0.12 0.14  0.20     1417 #> pred[20: Self-help]              0.10 0.04 0.04 0.07 0.09 0.12  0.18     1961 #>                                  Tail_ESS Rhat #> pred[20: No intervention]            3235    1 #> pred[20: Group counselling]          2444    1 #> pred[20: Individual counselling]     2249    1 #> pred[20: Self-help]                  2522    1 #>  #> --------------------------------------------------------------------- Study: 21 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[21: No intervention]        0.27 0.14 0.06 0.16 0.25 0.35  0.62     3000 #> pred[21: Group counselling]      0.50 0.18 0.16 0.37 0.50 0.63  0.84     3273 #> pred[21: Individual counselling] 0.44 0.17 0.14 0.31 0.43 0.56  0.79     3348 #> pred[21: Self-help]              0.37 0.16 0.10 0.24 0.35 0.48  0.73     3816 #>                                  Tail_ESS Rhat #> pred[21: No intervention]            2832    1 #> pred[21: Group counselling]          2809    1 #> pred[21: Individual counselling]     3010    1 #> pred[21: Self-help]                  3013    1 #>  #> --------------------------------------------------------------------- Study: 22 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[22: No intervention]        0.10 0.08 0.02 0.05 0.08 0.13  0.31     2838 #> pred[22: Group counselling]      0.24 0.13 0.05 0.14 0.22 0.31  0.56     3471 #> pred[22: Individual counselling] 0.20 0.13 0.04 0.11 0.18 0.27  0.52     3073 #> pred[22: Self-help]              0.16 0.11 0.03 0.08 0.13 0.20  0.42     3569 #>                                  Tail_ESS Rhat #> pred[22: No intervention]            2694    1 #> pred[22: Group counselling]          3018    1 #> pred[22: Individual counselling]     2748    1 #> pred[22: Self-help]                  2597    1 #>  #> --------------------------------------------------------------------- Study: 23 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[23: No intervention]        0.11 0.08 0.02 0.05 0.09 0.14  0.32     3095 #> pred[23: Group counselling]      0.25 0.14 0.06 0.15 0.23 0.33  0.59     3906 #> pred[23: Individual counselling] 0.21 0.12 0.05 0.12 0.19 0.28  0.51     3850 #> pred[23: Self-help]              0.17 0.11 0.03 0.08 0.14 0.22  0.47     3508 #>                                  Tail_ESS Rhat #> pred[23: No intervention]            2901    1 #> pred[23: Group counselling]          2858    1 #> pred[23: Individual counselling]     2854    1 #> pred[23: Self-help]                  2639    1 #>  #> --------------------------------------------------------------------- Study: 24 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[24: No intervention]        0.07 0.06 0.01 0.03 0.06 0.09  0.24     3352 #> pred[24: Group counselling]      0.18 0.12 0.03 0.09 0.15 0.24  0.48     4027 #> pred[24: Individual counselling] 0.15 0.10 0.03 0.08 0.12 0.19  0.41     3922 #> pred[24: Self-help]              0.11 0.09 0.02 0.05 0.09 0.15  0.36     3522 #>                                  Tail_ESS Rhat #> pred[24: No intervention]            2569    1 #> pred[24: Group counselling]          2956    1 #> pred[24: Individual counselling]     3219    1 #> pred[24: Self-help]                  2926    1 #>   # Predicted probabilities in a population with 67 observed events out of 566 # individuals on No Intervention, corresponding to a Beta(67, 566 - 67) # distribution on the baseline probability of response, using # `baseline_type = \"response\"` (smk_pred_RE <- predict(smk_fit_RE,                         baseline = distr(qbeta, 67, 566 - 67),                         baseline_type = \"response\",                         type = \"response\")) #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[No intervention]        0.12 0.01 0.09 0.11 0.12 0.13  0.15     4317 #> pred[Group counselling]      0.30 0.09 0.15 0.23 0.29 0.35  0.50     2359 #> pred[Individual counselling] 0.24 0.05 0.16 0.21 0.24 0.27  0.35     1480 #> pred[Self-help]              0.19 0.06 0.09 0.14 0.18 0.22  0.34     1976 #>                              Tail_ESS Rhat #> pred[No intervention]            3618    1 #> pred[Group counselling]          2649    1 #> pred[Individual counselling]     2547    1 #> pred[Self-help]                  2673    1 plot(smk_pred_RE, ref_line = c(0, 1))   # Predicted probabilities in a population with a baseline log odds of # response on No Intervention given a Normal distribution with mean -2 # and SD 0.13, using `baseline_type = \"link\"` (the default) # Note: this is approximately equivalent to the above Beta distribution on # the baseline probability (smk_pred_RE2 <- predict(smk_fit_RE,                          baseline = distr(qnorm, mean = -2, sd = 0.13),                          type = \"response\")) #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[No intervention]        0.12 0.01 0.09 0.11 0.12 0.13  0.15     3656 #> pred[Group counselling]      0.30 0.09 0.15 0.23 0.29 0.35  0.50     2453 #> pred[Individual counselling] 0.24 0.05 0.16 0.21 0.24 0.27  0.36     1486 #> pred[Self-help]              0.19 0.06 0.09 0.15 0.18 0.23  0.33     2118 #>                              Tail_ESS Rhat #> pred[No intervention]            3884    1 #> pred[Group counselling]          2696    1 #> pred[Individual counselling]     2774    1 #> pred[Self-help]                  2849    1 plot(smk_pred_RE2, ref_line = c(0, 1))  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Predicted probabilities of response in each study in the network (pso_pred <- predict(pso_fit, type = \"response\")) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[FIXTURE: PBO]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     4385     2960 #> pred[FIXTURE: ETN]     0.46 0.02 0.41 0.44 0.46 0.47  0.50     9667     3298 #> pred[FIXTURE: IXE_Q2W] 0.89 0.02 0.85 0.88 0.89 0.90  0.92     7054     2995 #> pred[FIXTURE: IXE_Q4W] 0.80 0.03 0.74 0.78 0.80 0.81  0.84     7475     3318 #> pred[FIXTURE: SEC_150] 0.67 0.03 0.62 0.65 0.67 0.69  0.72    10173     3205 #> pred[FIXTURE: SEC_300] 0.77 0.02 0.72 0.75 0.77 0.79  0.81     7775     2999 #>                        Rhat #> pred[FIXTURE: PBO]        1 #> pred[FIXTURE: ETN]        1 #> pred[FIXTURE: IXE_Q2W]    1 #> pred[FIXTURE: IXE_Q4W]    1 #> pred[FIXTURE: SEC_150]    1 #> pred[FIXTURE: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-1: PBO]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     5466     3333 #> pred[UNCOVER-1: ETN]     0.46 0.03 0.41 0.44 0.46 0.48  0.52     6276     3144 #> pred[UNCOVER-1: IXE_Q2W] 0.90 0.01 0.88 0.89 0.90 0.91  0.92     7327     2947 #> pred[UNCOVER-1: IXE_Q4W] 0.81 0.02 0.78 0.80 0.81 0.82  0.84     8712     2821 #> pred[UNCOVER-1: SEC_150] 0.69 0.04 0.60 0.66 0.69 0.72  0.77     7518     3199 #> pred[UNCOVER-1: SEC_300] 0.78 0.04 0.71 0.76 0.79 0.81  0.85     8014     3035 #>                          Rhat #> pred[UNCOVER-1: PBO]        1 #> pred[UNCOVER-1: ETN]        1 #> pred[UNCOVER-1: IXE_Q2W]    1 #> pred[UNCOVER-1: IXE_Q4W]    1 #> pred[UNCOVER-1: SEC_150]    1 #> pred[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-2: PBO]     0.05 0.01 0.03 0.04 0.05 0.05  0.06     5285     2863 #> pred[UNCOVER-2: ETN]     0.42 0.02 0.38 0.41 0.42 0.43  0.46     8939     3411 #> pred[UNCOVER-2: IXE_Q2W] 0.88 0.01 0.86 0.87 0.88 0.89  0.90     6533     2677 #> pred[UNCOVER-2: IXE_Q4W] 0.78 0.02 0.75 0.77 0.78 0.79  0.81     7788     3129 #> pred[UNCOVER-2: SEC_150] 0.65 0.04 0.57 0.62 0.65 0.68  0.73     8670     3374 #> pred[UNCOVER-2: SEC_300] 0.75 0.04 0.68 0.73 0.75 0.78  0.82     8848     3293 #>                          Rhat #> pred[UNCOVER-2: PBO]        1 #> pred[UNCOVER-2: ETN]        1 #> pred[UNCOVER-2: IXE_Q2W]    1 #> pred[UNCOVER-2: IXE_Q4W]    1 #> pred[UNCOVER-2: SEC_150]    1 #> pred[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-3: PBO]     0.08 0.01 0.06 0.07 0.08 0.08  0.10     5484     3139 #> pred[UNCOVER-3: ETN]     0.53 0.02 0.49 0.52 0.53 0.54  0.57     9508     3312 #> pred[UNCOVER-3: IXE_Q2W] 0.93 0.01 0.91 0.92 0.93 0.93  0.94     6475     2629 #> pred[UNCOVER-3: IXE_Q4W] 0.85 0.01 0.83 0.85 0.85 0.86  0.88     7914     3029 #> pred[UNCOVER-3: SEC_150] 0.75 0.03 0.67 0.72 0.75 0.77  0.81     9523     3183 #> pred[UNCOVER-3: SEC_300] 0.83 0.03 0.77 0.81 0.83 0.85  0.88     9357     3320 #>                          Rhat #> pred[UNCOVER-3: PBO]        1 #> pred[UNCOVER-3: ETN]        1 #> pred[UNCOVER-3: IXE_Q2W]    1 #> pred[UNCOVER-3: IXE_Q4W]    1 #> pred[UNCOVER-3: SEC_150]    1 #> pred[UNCOVER-3: SEC_300]    1 #>  plot(pso_pred, ref_line = c(0, 1))   # Predicted probabilites of response in a new target population, with means # and SDs or proportions given by new_agd_int <- data.frame(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1 )  # We need to add integration points to this data frame of new data # We use the weighted mean correlation matrix computed from the IPD studies new_agd_int <- add_integration(new_agd_int,                                durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),                                prevsys = distr(qbern, prob = prevsys),                                bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),                                weight = distr(qgamma, mean = weight_mean, sd = weight_sd),                                psa = distr(qbern, prob = psa),                                cor = pso_net$int_cor,                                n_int = 64)  # Predicted probabilities of achieving PASI 75 in this target population, given # a Normal(-1.75, 0.08^2) distribution on the baseline probit-probability of # response on Placebo (at the reference levels of the covariates), are given by (pso_pred_new <- predict(pso_fit,                          type = \"response\",                          newdata = new_agd_int,                          baseline = distr(qnorm, -1.75, 0.08))) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: PBO]     0.06 0.02 0.03 0.04 0.06 0.07  0.12     5444     3551    1 #> pred[New 1: ETN]     0.37 0.06 0.26 0.33 0.37 0.41  0.48     6240     3318    1 #> pred[New 1: IXE_Q2W] 0.90 0.02 0.84 0.88 0.90 0.92  0.94     5504     3287    1 #> pred[New 1: IXE_Q4W] 0.81 0.04 0.73 0.78 0.81 0.83  0.87     5354     3747    1 #> pred[New 1: SEC_150] 0.68 0.05 0.57 0.65 0.68 0.72  0.78     5114     3742    1 #> pred[New 1: SEC_300] 0.78 0.05 0.68 0.75 0.78 0.81  0.86     5367     3883    1 #>  plot(pso_pred_new, ref_line = c(0, 1))  # }  ## Progression free survival with newly-diagnosed multiple myeloma # \\donttest{ # Run newly-diagnosed multiple myeloma example if not already available if (!exists(\"ndmm_fit\")) example(\"example_ndmm\", run.donttest = TRUE) # } # \\donttest{ # We can produce a range of predictions from models with survival outcomes, # chosen with the type argument to predict  # Predicted survival probabilities at 5 years predict(ndmm_fit, type = \"survival\", times = 5) #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                          .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Attal2012: Pbo, 1]      5 0.19 0.02 0.15 0.18 0.19 0.21  0.23     5320 #> pred[Attal2012: Len, 1]      5 0.38 0.02 0.33 0.36 0.38 0.40  0.43     4522 #> pred[Attal2012: Thal, 1]     5 0.23 0.04 0.16 0.20 0.23 0.25  0.30     5621 #>                          Tail_ESS Rhat #> pred[Attal2012: Pbo, 1]      3308    1 #> pred[Attal2012: Len, 1]      2989    1 #> pred[Attal2012: Thal, 1]     3517    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                            .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Jackson2019: Pbo, 1]      5 0.25 0.01 0.22 0.24 0.25 0.26  0.28     4767 #> pred[Jackson2019: Len, 1]      5 0.45 0.01 0.42 0.44 0.45 0.45  0.47     5015 #> pred[Jackson2019: Thal, 1]     5 0.29 0.03 0.22 0.27 0.29 0.31  0.36     5896 #>                            Tail_ESS Rhat #> pred[Jackson2019: Pbo, 1]      3559    1 #> pred[Jackson2019: Len, 1]      3552    1 #> pred[Jackson2019: Thal, 1]     3491    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                             .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[McCarthy2012: Pbo, 1]      5 0.27 0.02 0.22 0.25 0.27 0.28  0.31     5109 #> pred[McCarthy2012: Len, 1]      5 0.46 0.02 0.41 0.45 0.46 0.48  0.50     5060 #> pred[McCarthy2012: Thal, 1]     5 0.31 0.04 0.23 0.28 0.31 0.33  0.38     5912 #>                             Tail_ESS Rhat #> pred[McCarthy2012: Pbo, 1]      3589    1 #> pred[McCarthy2012: Len, 1]      3226    1 #> pred[McCarthy2012: Thal, 1]     3614    1 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                           .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Morgan2012: Pbo, 1]      5 0.24 0.02 0.20 0.22 0.24 0.25  0.28     5683 #> pred[Morgan2012: Len, 1]      5 0.43 0.03 0.38 0.41 0.43 0.45  0.49     6100 #> pred[Morgan2012: Thal, 1]     5 0.28 0.02 0.24 0.26 0.28 0.29  0.32     4862 #>                           Tail_ESS Rhat #> pred[Morgan2012: Pbo, 1]      3419    1 #> pred[Morgan2012: Len, 1]      3585    1 #> pred[Morgan2012: Thal, 1]     3105    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                            .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Palumbo2014: Pbo, 1]      5 0.20 0.03 0.14 0.17 0.20 0.22  0.26     5105 #> pred[Palumbo2014: Len, 1]      5 0.38 0.04 0.32 0.36 0.38 0.41  0.46     5240 #> pred[Palumbo2014: Thal, 1]     5 0.23 0.04 0.15 0.20 0.23 0.26  0.32     5521 #>                            Tail_ESS Rhat #> pred[Palumbo2014: Pbo, 1]      3071    1 #> pred[Palumbo2014: Len, 1]      2971    1 #> pred[Palumbo2014: Thal, 1]     3649    1 #>   # Survival curves plot(predict(ndmm_fit, type = \"survival\"))   # Hazard curves # Here we specify a vector of times to avoid attempting to plot infinite # hazards for some studies at t=0 plot(predict(ndmm_fit, type = \"hazard\", times = seq(0.001, 6, length.out = 50)))   # Cumulative hazard curves plot(predict(ndmm_fit, type = \"cumhaz\"))   # Survival time quantiles and median survival predict(ndmm_fit, type = \"quantile\", quantiles = c(0.2, 0.5, 0.8)) #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Attal2012: Pbo, 0.2]  1.07 0.07 0.93 1.02 1.07 1.11  1.21     5138 #> pred[Attal2012: Pbo, 0.5]  2.56 0.12 2.34 2.48 2.55 2.64  2.79     5225 #> pred[Attal2012: Pbo, 0.8]  4.90 0.25 4.46 4.73 4.89 5.06  5.42     5251 #> pred[Attal2012: Len, 0.2]  1.61 0.09 1.44 1.55 1.61 1.67  1.79     4869 #> pred[Attal2012: Len, 0.5]  3.87 0.19 3.54 3.74 3.86 3.99  4.27     4403 #> pred[Attal2012: Len, 0.8]  7.42 0.47 6.60 7.08 7.39 7.73  8.46     4663 #> pred[Attal2012: Thal, 0.2] 1.17 0.11 0.97 1.10 1.16 1.24  1.38     5513 #> pred[Attal2012: Thal, 0.5] 2.80 0.22 2.39 2.64 2.79 2.94  3.25     5761 #> pred[Attal2012: Thal, 0.8] 5.36 0.45 4.54 5.05 5.35 5.64  6.29     5616 #>                            Tail_ESS Rhat #> pred[Attal2012: Pbo, 0.2]      3208    1 #> pred[Attal2012: Pbo, 0.5]      3045    1 #> pred[Attal2012: Pbo, 0.8]      3265    1 #> pred[Attal2012: Len, 0.2]      3683    1 #> pred[Attal2012: Len, 0.5]      2876    1 #> pred[Attal2012: Len, 0.8]      3386    1 #> pred[Attal2012: Thal, 0.2]     2858    1 #> pred[Attal2012: Thal, 0.5]     3573    1 #> pred[Attal2012: Thal, 0.8]     3511    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                               mean   sd 2.5%   25%   50%   75% 97.5% Bulk_ESS #> pred[Jackson2019: Pbo, 0.2]   0.71 0.04 0.64  0.68  0.71  0.74  0.79     5405 #> pred[Jackson2019: Pbo, 0.5]   2.39 0.10 2.20  2.32  2.39  2.45  2.59     5137 #> pred[Jackson2019: Pbo, 0.8]   5.89 0.25 5.42  5.72  5.89  6.06  6.40     4738 #> pred[Jackson2019: Len, 0.2]   1.26 0.06 1.15  1.22  1.26  1.30  1.38     5761 #> pred[Jackson2019: Len, 0.5]   4.24 0.16 3.94  4.13  4.24  4.35  4.57     5098 #> pred[Jackson2019: Len, 0.8]  10.47 0.46 9.62 10.15 10.45 10.76 11.42     4524 #> pred[Jackson2019: Thal, 0.2]  0.80 0.09 0.64  0.75  0.80  0.86  0.98     5915 #> pred[Jackson2019: Thal, 0.5]  2.71 0.27 2.19  2.53  2.70  2.88  3.27     5845 #> pred[Jackson2019: Thal, 0.8]  6.68 0.68 5.41  6.21  6.65  7.10  8.11     5908 #>                              Tail_ESS Rhat #> pred[Jackson2019: Pbo, 0.2]      3221    1 #> pred[Jackson2019: Pbo, 0.5]      3292    1 #> pred[Jackson2019: Pbo, 0.8]      3583    1 #> pred[Jackson2019: Len, 0.2]      3482    1 #> pred[Jackson2019: Len, 0.5]      3381    1 #> pred[Jackson2019: Len, 0.8]      3651    1 #> pred[Jackson2019: Thal, 0.2]     3425    1 #> pred[Jackson2019: Thal, 0.5]     3613    1 #> pred[Jackson2019: Thal, 0.8]     3428    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                               mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[McCarthy2012: Pbo, 0.2]  1.26 0.10 1.08 1.19 1.26 1.33  1.46     4687 #> pred[McCarthy2012: Pbo, 0.5]  3.03 0.15 2.75 2.93 3.03 3.13  3.34     4960 #> pred[McCarthy2012: Pbo, 0.8]  5.82 0.30 5.28 5.62 5.81 6.02  6.46     5096 #> pred[McCarthy2012: Len, 0.2]  1.91 0.12 1.68 1.83 1.91 1.99  2.15     4963 #> pred[McCarthy2012: Len, 0.5]  4.59 0.23 4.17 4.44 4.59 4.74  5.05     5055 #> pred[McCarthy2012: Len, 0.8]  8.83 0.56 7.84 8.44 8.80 9.19 10.00     4903 #> pred[McCarthy2012: Thal, 0.2] 1.38 0.14 1.12 1.29 1.38 1.47  1.66     5118 #> pred[McCarthy2012: Thal, 0.5] 3.32 0.28 2.79 3.13 3.31 3.50  3.87     5709 #> pred[McCarthy2012: Thal, 0.8] 6.37 0.55 5.36 5.99 6.35 6.71  7.53     5921 #>                               Tail_ESS Rhat #> pred[McCarthy2012: Pbo, 0.2]      3097    1 #> pred[McCarthy2012: Pbo, 0.5]      3351    1 #> pred[McCarthy2012: Pbo, 0.8]      3719    1 #> pred[McCarthy2012: Len, 0.2]      3470    1 #> pred[McCarthy2012: Len, 0.5]      3253    1 #> pred[McCarthy2012: Len, 0.8]      3153    1 #> pred[McCarthy2012: Thal, 0.2]     2550    1 #> pred[McCarthy2012: Thal, 0.5]     3124    1 #> pred[McCarthy2012: Thal, 0.8]     3667    1 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                              mean   sd 2.5%  25%   50%   75% 97.5% Bulk_ESS #> pred[Morgan2012: Pbo, 0.2]   0.61 0.05 0.51 0.57  0.60  0.64  0.72     4711 #> pred[Morgan2012: Pbo, 0.5]   2.20 0.16 1.91 2.09  2.19  2.30  2.52     5149 #> pred[Morgan2012: Pbo, 0.8]   5.72 0.43 4.94 5.43  5.70  5.99  6.62     5771 #> pred[Morgan2012: Len, 0.2]   1.12 0.10 0.93 1.05  1.11  1.18  1.34     5213 #> pred[Morgan2012: Len, 0.5]   4.05 0.36 3.41 3.80  4.03  4.27  4.79     5968 #> pred[Morgan2012: Len, 0.8]  10.56 1.04 8.72 9.82 10.48 11.20 12.82     6369 #> pred[Morgan2012: Thal, 0.2]  0.69 0.06 0.58 0.65  0.69  0.73  0.82     5602 #> pred[Morgan2012: Thal, 0.5]  2.50 0.18 2.17 2.37  2.49  2.61  2.86     5126 #> pred[Morgan2012: Thal, 0.8]  6.51 0.49 5.63 6.16  6.47  6.82  7.55     4763 #>                             Tail_ESS Rhat #> pred[Morgan2012: Pbo, 0.2]      2815    1 #> pred[Morgan2012: Pbo, 0.5]      3094    1 #> pred[Morgan2012: Pbo, 0.8]      3405    1 #> pred[Morgan2012: Len, 0.2]      3146    1 #> pred[Morgan2012: Len, 0.5]      3650    1 #> pred[Morgan2012: Len, 0.8]      3681    1 #> pred[Morgan2012: Thal, 0.2]     3458    1 #> pred[Morgan2012: Thal, 0.5]     3216    1 #> pred[Morgan2012: Thal, 0.8]     2732    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Palumbo2014: Pbo, 0.2]  0.71 0.09 0.53 0.64 0.70 0.76  0.89     5406 #> pred[Palumbo2014: Pbo, 0.5]  2.16 0.19 1.81 2.02 2.15 2.28  2.54     5433 #> pred[Palumbo2014: Pbo, 0.8]  4.97 0.48 4.15 4.63 4.93 5.27  6.02     5008 #> pred[Palumbo2014: Len, 0.2]  1.20 0.13 0.95 1.11 1.19 1.28  1.46     5244 #> pred[Palumbo2014: Len, 0.5]  3.67 0.33 3.09 3.43 3.65 3.87  4.39     5309 #> pred[Palumbo2014: Len, 0.8]  8.47 1.01 6.79 7.77 8.36 9.07 10.72     5027 #> pred[Palumbo2014: Thal, 0.2] 0.79 0.12 0.58 0.71 0.79 0.87  1.04     5420 #> pred[Palumbo2014: Thal, 0.5] 2.42 0.30 1.89 2.21 2.41 2.60  3.08     5258 #> pred[Palumbo2014: Thal, 0.8] 5.58 0.75 4.33 5.05 5.51 6.02  7.22     5384 #>                              Tail_ESS Rhat #> pred[Palumbo2014: Pbo, 0.2]      3186    1 #> pred[Palumbo2014: Pbo, 0.5]      3569    1 #> pred[Palumbo2014: Pbo, 0.8]      2983    1 #> pred[Palumbo2014: Len, 0.2]      3189    1 #> pred[Palumbo2014: Len, 0.5]      2939    1 #> pred[Palumbo2014: Len, 0.8]      3048    1 #> pred[Palumbo2014: Thal, 0.2]     2730    1 #> pred[Palumbo2014: Thal, 0.5]     3117    1 #> pred[Palumbo2014: Thal, 0.8]     3758    1 #>  plot(predict(ndmm_fit, type = \"median\"))   # Mean survival time predict(ndmm_fit, type = \"mean\") #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[Attal2012: Pbo]  3.14 0.15 2.87 3.04 3.13 3.24  3.45     5227     3449 #> pred[Attal2012: Len]  4.75 0.28 4.27 4.55 4.73 4.93  5.36     4586     3126 #> pred[Attal2012: Thal] 3.43 0.28 2.92 3.24 3.42 3.61  4.01     5809     3681 #>                       Rhat #> pred[Attal2012: Pbo]     1 #> pred[Attal2012: Len]     1 #> pred[Attal2012: Thal]    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[Jackson2019: Pbo]  3.65 0.15 3.36 3.55 3.65 3.76  3.97     4740     3625 #> pred[Jackson2019: Len]  6.49 0.29 5.97 6.29 6.48 6.67  7.08     4520     3686 #> pred[Jackson2019: Thal] 4.14 0.42 3.35 3.85 4.12 4.40  5.03     5909     3428 #>                         Rhat #> pred[Jackson2019: Pbo]     1 #> pred[Jackson2019: Len]     1 #> pred[Jackson2019: Thal]    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[McCarthy2012: Pbo]  3.73 0.18 3.40 3.60 3.72 3.85  4.11     5097     3220 #> pred[McCarthy2012: Len]  5.65 0.33 5.06 5.42 5.63 5.87  6.34     4969     3141 #> pred[McCarthy2012: Thal] 4.08 0.34 3.44 3.84 4.06 4.29  4.80     5917     3550 #>                          Rhat #> pred[McCarthy2012: Pbo]     1 #> pred[McCarthy2012: Len]     1 #> pred[McCarthy2012: Thal]    1 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[Morgan2012: Pbo]  3.55 0.27 3.06 3.37 3.54 3.72  4.12     5782     3532 #> pred[Morgan2012: Len]  6.55 0.65 5.41 6.09 6.50 6.95  7.97     6371     3644 #> pred[Morgan2012: Thal] 4.04 0.31 3.49 3.82 4.02 4.24  4.69     4736     2733 #>                        Rhat #> pred[Morgan2012: Pbo]     1 #> pred[Morgan2012: Len]     1 #> pred[Morgan2012: Thal]    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[Palumbo2014: Pbo]  3.09 0.29 2.59 2.89 3.07 3.27  3.74     4922     2984 #> pred[Palumbo2014: Len]  5.27 0.62 4.27 4.84 5.20 5.64  6.65     4996     2977 #> pred[Palumbo2014: Thal] 3.47 0.46 2.70 3.15 3.43 3.74  4.48     5355     3685 #>                         Rhat #> pred[Palumbo2014: Pbo]     1 #> pred[Palumbo2014: Len]     1 #> pred[Palumbo2014: Thal]    1 #>   # Restricted mean survival time # By default, the time horizon is the shortest follow-up time in the network predict(ndmm_fit, type = \"rmst\") #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                       .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Attal2012: Pbo]   4.01 2.49 0.06 2.37 2.45 2.49 2.54  2.61     5184 #> pred[Attal2012: Len]   4.01 2.99 0.05 2.89 2.96 2.99 3.03  3.09     4614 #> pred[Attal2012: Thal]  4.01 2.61 0.10 2.40 2.54 2.61 2.67  2.80     5710 #>                       Tail_ESS Rhat #> pred[Attal2012: Pbo]      3096    1 #> pred[Attal2012: Len]      3665    1 #> pred[Attal2012: Thal]     3182    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                         .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Jackson2019: Pbo]   4.01 2.36 0.04 2.27 2.33 2.36 2.39  2.45     5189 #> pred[Jackson2019: Len]   4.01 2.91 0.03 2.84 2.88 2.91 2.93  2.97     5538 #> pred[Jackson2019: Thal]  4.01 2.48 0.10 2.27 2.42 2.49 2.55  2.68     5824 #>                         Tail_ESS Rhat #> pred[Jackson2019: Pbo]      3264    1 #> pred[Jackson2019: Len]      3579    1 #> pred[Jackson2019: Thal]     3579    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                          .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[McCarthy2012: Pbo]   4.01 2.71 0.07 2.58 2.66 2.71 2.76  2.84     4801 #> pred[McCarthy2012: Len]   4.01 3.16 0.05 3.05 3.12 3.16 3.19  3.26     5050 #> pred[McCarthy2012: Thal]  4.01 2.81 0.10 2.60 2.75 2.82 2.88  3.01     5482 #>                          Tail_ESS Rhat #> pred[McCarthy2012: Pbo]      3329    1 #> pred[McCarthy2012: Len]      3680    1 #> pred[McCarthy2012: Thal]     3204    1 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                        .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Morgan2012: Pbo]   4.01 2.26 0.07 2.12 2.21 2.26 2.31  2.41     5090 #> pred[Morgan2012: Len]   4.01 2.83 0.07 2.69 2.79 2.83 2.88  2.97     5576 #> pred[Morgan2012: Thal]  4.01 2.39 0.07 2.25 2.34 2.39 2.44  2.53     5281 #>                        Tail_ESS Rhat #> pred[Morgan2012: Pbo]      3049    1 #> pred[Morgan2012: Len]      3276    1 #> pred[Morgan2012: Thal]     3412    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                         .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Palumbo2014: Pbo]   4.01 2.25 0.10 2.05 2.18 2.25 2.32  2.45     5489 #> pred[Palumbo2014: Len]   4.01 2.81 0.08 2.64 2.76 2.81 2.87  2.97     5728 #> pred[Palumbo2014: Thal]  4.01 2.38 0.14 2.10 2.28 2.38 2.47  2.65     5480 #>                         Tail_ESS Rhat #> pred[Palumbo2014: Pbo]      3523    1 #> pred[Palumbo2014: Len]      3319    1 #> pred[Palumbo2014: Thal]     3142    1 #>   # An alternative restriction time can be set using the times argument predict(ndmm_fit, type = \"rmst\", times = 5)  # 5-year RMST #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                       .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Attal2012: Pbo]      5 2.73 0.08 2.57 2.67 2.73 2.78  2.88     5220 #> pred[Attal2012: Len]      5 3.41 0.07 3.28 3.37 3.41 3.46  3.55     4492 #> pred[Attal2012: Thal]     5 2.88 0.14 2.61 2.79 2.88 2.97  3.14     5718 #>                       Tail_ESS Rhat #> pred[Attal2012: Pbo]      3228    1 #> pred[Attal2012: Len]      3002    1 #> pred[Attal2012: Thal]     3506    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                         .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Jackson2019: Pbo]      5 2.64 0.06 2.53 2.60 2.64 2.68  2.75     5103 #> pred[Jackson2019: Len]      5 3.38 0.05 3.29 3.35 3.38 3.41  3.47     5430 #> pred[Jackson2019: Thal]     5 2.81 0.14 2.52 2.72 2.81 2.90  3.07     5842 #>                         Tail_ESS Rhat #> pred[Jackson2019: Pbo]      3306    1 #> pred[Jackson2019: Len]      3560    1 #> pred[Jackson2019: Thal]     3540    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                          .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[McCarthy2012: Pbo]      5 3.02 0.09 2.85 2.96 3.02 3.08  3.19     4902 #> pred[McCarthy2012: Len]      5 3.66 0.07 3.52 3.61 3.66 3.70  3.80     5122 #> pred[McCarthy2012: Thal]     5 3.16 0.14 2.88 3.07 3.17 3.26  3.43     5622 #>                          Tail_ESS Rhat #> pred[McCarthy2012: Pbo]      3440    1 #> pred[McCarthy2012: Len]      3581    1 #> pred[McCarthy2012: Thal]     3080    1 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                        .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Morgan2012: Pbo]      5 2.53 0.09 2.35 2.47 2.53 2.59  2.72     5197 #> pred[Morgan2012: Len]      5 3.29 0.10 3.10 3.23 3.29 3.36  3.48     5712 #> pred[Morgan2012: Thal]     5 2.70 0.09 2.52 2.64 2.70 2.76  2.88     5138 #>                        Tail_ESS Rhat #> pred[Morgan2012: Pbo]      3094    1 #> pred[Morgan2012: Len]      3455    1 #> pred[Morgan2012: Thal]     3320    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                         .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Palumbo2014: Pbo]      5 2.48 0.13 2.23 2.39 2.48 2.56  2.73     5513 #> pred[Palumbo2014: Len]      5 3.23 0.11 3.00 3.15 3.23 3.31  3.45     5674 #> pred[Palumbo2014: Thal]     5 2.64 0.18 2.29 2.52 2.65 2.76  3.00     5292 #>                         Tail_ESS Rhat #> pred[Palumbo2014: Pbo]      3566    1 #> pred[Palumbo2014: Len]      3202    1 #> pred[Palumbo2014: Thal]     3181    1 #>  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Print nma_data objects — print.nma_data","title":"Print nma_data objects — print.nma_data","text":"Print details networks stored nma_data objects, created set_ipd(), set_agd_arm(), set_agd_contrast(), set_agd_surv(), combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print nma_data objects — print.nma_data","text":"","code":"# S3 method for nma_data print(x, ..., n = 10)  # S3 method for mlnmr_data print(x, ..., n = 10)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print nma_data objects — print.nma_data","text":"x nma_data object ... options (used) n number studies type print","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Print DIC details — print.nma_dic","title":"Print DIC details — print.nma_dic","text":"Print details DIC model fit statistics, computed dic() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print DIC details — print.nma_dic","text":"","code":"# S3 method for nma_dic print(x, digits = 1, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print DIC details — print.nma_dic","text":"x object class nma_dic digits integer passed round() ... Ignored","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print DIC details — print.nma_dic","text":"x returned invisibly.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"Print nma_nodesplit_df objects","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"","code":"# S3 method for nma_nodesplit_df print(x, ...)  # S3 method for nma_nodesplit print(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"x nma_nodesplit_df object ... arguments passed print.stanfit()","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Print stan_nma objects — print.stan_nma","title":"Print stan_nma objects — print.stan_nma","text":"Print stan_nma objects","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print stan_nma objects — print.stan_nma","text":"","code":"# S3 method for stan_nma print(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print stan_nma objects — print.stan_nma","text":"x stan_nma object ... arguments passed print.stanfit()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":null,"dir":"Reference","previous_headings":"","what":"Prior distributions — priors","title":"Prior distributions — priors","text":"functions used specify prior distributions model parameters.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prior distributions — priors","text":"","code":"normal(location = 0, scale)  half_normal(scale)  log_normal(location, scale)  cauchy(location = 0, scale)  half_cauchy(scale)  student_t(location = 0, scale, df)  half_student_t(scale, df)  log_student_t(location, scale, df)  exponential(scale = 1/rate, rate = 1/scale)  flat()"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prior distributions — priors","text":"location Prior location. Typically prior mean (see details). scale Prior scale. Typically prior standard deviation (see details). df Prior degrees freedom. rate Prior rate.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prior distributions — priors","text":"Object class nma_prior.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prior distributions — priors","text":"location scale parameters typically prior mean standard deviation, following exceptions: Cauchy distribution location prior median scale prior scale. log-Normal distribution, location scale prior mean standard deviation logarithm.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"compatibility-with-model-parameters","dir":"Reference","previous_headings":"","what":"Compatibility with model parameters","title":"Prior distributions — priors","text":"following table summarises prior distributions may used model parameters. Essentially, priors take non-negative values (e.g. half-Normal) may used non-negative parameters (heterogeneity SD/variance/precision, auxiliary parameter). real-valued prior distribution specified non-negative parameter, truncated 0 non-negative. flat() prior special case prior information added model, resulting implicit flat uniform prior distribution entire support parameter. improper prior parameter unbounded, generally advised. See Stan user's guide details.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Random effects structure — RE_cor","title":"Random effects structure — RE_cor","text":"Use RE_cor generate random effects correlation matrix, assumption common heterogeneity variance (.e. within-study correlations 0.5). Use which_RE return vector IDs RE deltas (0 means RE delta arm).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random effects structure — RE_cor","text":"","code":"RE_cor(study, trt, contrast, type = c(\"reftrt\", \"blshift\"))  which_RE(study, trt, contrast, type = c(\"reftrt\", \"blshift\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random effects structure — RE_cor","text":"study vector study IDs (integer, character, factor) trt factor vector treatment codes (coercible ), first level indicating reference treatment contrast logical vector, length study trt, indicating whether corresponding data contrast rather arm format. type Character string, whether generate RE structure \"reference treatment\" parameterisation, \"baseline shift\" parameterisation.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random effects structure — RE_cor","text":"RE_cor(), correlation matrix dimension equal number random effects deltas (excluding set equal zero). which_RE(), integer vector IDs indexing rows columns correlation matrix returned RE_cor().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random effects structure — RE_cor","text":"","code":"RE_cor(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking))) #> Coerced `trt` to factor. #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #>  [1,]  1.0  0.5  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>  [2,]  0.5  1.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>  [3,]  0.0  0.0  1.0  0.5  0.5    0    0    0    0     0     0     0     0 #>  [4,]  0.0  0.0  0.5  1.0  0.5    0    0    0    0     0     0     0     0 #>  [5,]  0.0  0.0  0.5  0.5  1.0    0    0    0    0     0     0     0     0 #>  [6,]  0.0  0.0  0.0  0.0  0.0    1    0    0    0     0     0     0     0 #>  [7,]  0.0  0.0  0.0  0.0  0.0    0    1    0    0     0     0     0     0 #>  [8,]  0.0  0.0  0.0  0.0  0.0    0    0    1    0     0     0     0     0 #>  [9,]  0.0  0.0  0.0  0.0  0.0    0    0    0    1     0     0     0     0 #> [10,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     1     0     0     0 #> [11,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     1     0     0 #> [12,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     1     0 #> [13,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     1 #> [14,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [15,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [16,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [17,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [18,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [19,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [20,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [21,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [22,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [23,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [24,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [25,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [26,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [27,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [28,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [29,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [30,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [31,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] #>  [1,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [2,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [3,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [4,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [5,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [6,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [7,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [8,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [9,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [10,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [11,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [12,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [13,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [14,]     1     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [15,]     0     1     0     0     0     0     0     0     0     0   0.0   0.0 #> [16,]     0     0     1     0     0     0     0     0     0     0   0.0   0.0 #> [17,]     0     0     0     1     0     0     0     0     0     0   0.0   0.0 #> [18,]     0     0     0     0     1     0     0     0     0     0   0.0   0.0 #> [19,]     0     0     0     0     0     1     0     0     0     0   0.0   0.0 #> [20,]     0     0     0     0     0     0     1     0     0     0   0.0   0.0 #> [21,]     0     0     0     0     0     0     0     1     0     0   0.0   0.0 #> [22,]     0     0     0     0     0     0     0     0     1     0   0.0   0.0 #> [23,]     0     0     0     0     0     0     0     0     0     1   0.0   0.0 #> [24,]     0     0     0     0     0     0     0     0     0     0   1.0   0.5 #> [25,]     0     0     0     0     0     0     0     0     0     0   0.5   1.0 #> [26,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [27,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [28,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [29,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [30,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [31,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>       [,26] [,27] [,28] [,29] [,30] [,31] #>  [1,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [2,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [3,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [4,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [5,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [6,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [7,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [8,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [9,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [10,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [11,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [12,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [13,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [14,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [15,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [16,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [17,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [18,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [19,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [20,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [21,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [22,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [23,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [24,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [25,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [26,]   1.0   0.5   0.0   0.0   0.0   0.0 #> [27,]   0.5   1.0   0.0   0.0   0.0   0.0 #> [28,]   0.0   0.0   1.0   0.5   0.0   0.0 #> [29,]   0.0   0.0   0.5   1.0   0.0   0.0 #> [30,]   0.0   0.0   0.0   0.0   1.0   0.5 #> [31,]   0.0   0.0   0.0   0.0   0.5   1.0 RE_cor(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking)), type = \"blshift\") #> Coerced `trt` to factor. #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #>  [1,]  1.0  0.5  0.0  0.0    0    0    0    0    0     0     0     0     0 #>  [2,]  0.5  1.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #>  [3,]  0.0  0.0  1.0  0.5    0    0    0    0    0     0     0     0     0 #>  [4,]  0.0  0.0  0.5  1.0    0    0    0    0    0     0     0     0     0 #>  [5,]  0.0  0.0  0.0  0.0    1    0    0    0    0     0     0     0     0 #>  [6,]  0.0  0.0  0.0  0.0    0    1    0    0    0     0     0     0     0 #>  [7,]  0.0  0.0  0.0  0.0    0    0    1    0    0     0     0     0     0 #>  [8,]  0.0  0.0  0.0  0.0    0    0    0    1    0     0     0     0     0 #>  [9,]  0.0  0.0  0.0  0.0    0    0    0    0    1     0     0     0     0 #> [10,]  0.0  0.0  0.0  0.0    0    0    0    0    0     1     0     0     0 #> [11,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     1     0     0 #> [12,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     1     0 #> [13,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     1 #> [14,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [15,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [16,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [17,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [18,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [19,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [20,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [21,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [22,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [23,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [24,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [25,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [26,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #>       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] #>  [1,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [2,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [3,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [4,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [5,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [6,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [7,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [8,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [9,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [10,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [11,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [12,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [13,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [14,]     1     0     0     0     0     0     0     0     0     0     0     0 #> [15,]     0     1     0     0     0     0     0     0     0     0     0     0 #> [16,]     0     0     1     0     0     0     0     0     0     0     0     0 #> [17,]     0     0     0     1     0     0     0     0     0     0     0     0 #> [18,]     0     0     0     0     1     0     0     0     0     0     0     0 #> [19,]     0     0     0     0     0     1     0     0     0     0     0     0 #> [20,]     0     0     0     0     0     0     1     0     0     0     0     0 #> [21,]     0     0     0     0     0     0     0     1     0     0     0     0 #> [22,]     0     0     0     0     0     0     0     0     1     0     0     0 #> [23,]     0     0     0     0     0     0     0     0     0     1     0     0 #> [24,]     0     0     0     0     0     0     0     0     0     0     1     0 #> [25,]     0     0     0     0     0     0     0     0     0     0     0     1 #> [26,]     0     0     0     0     0     0     0     0     0     0     0     0 #>       [,26] #>  [1,]     0 #>  [2,]     0 #>  [3,]     0 #>  [4,]     0 #>  [5,]     0 #>  [6,]     0 #>  [7,]     0 #>  [8,]     0 #>  [9,]     0 #> [10,]     0 #> [11,]     0 #> [12,]     0 #> [13,]     0 #> [14,]     0 #> [15,]     0 #> [16,]     0 #> [17,]     0 #> [18,]     0 #> [19,]     0 #> [20,]     0 #> [21,]     0 #> [22,]     0 #> [23,]     0 #> [24,]     0 #> [25,]     0 #> [26,]     1 which_RE(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking))) #> Coerced `trt` to factor. #>  [1]  0  1  2  3  4  5  0  6  0  7  0  8  0  9  0 10  0 11  0 12  0 13  0 14  0 #> [26] 15  0 16  0 17  0 18  0 19  0 20  0 21  0 22  0 23 24 25 26 27 28 29 30 31 which_RE(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking)), type = \"blshift\") #> Coerced `trt` to factor. #>  [1]  0  1  2  0  3  4  0  5  0  6  0  7  0  8  0  9  0 10  0 11  0 12  0 13  0 #> [26] 14  0 15  0 16  0 17  0 18  0 19  0 20  0 21  0 22  0 23  0 24  0 25  0 26"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. survival Surv","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Relative treatment effects — relative_effects","title":"Relative treatment effects — relative_effects","text":"Generate (population-average) relative treatment effects. ML-NMR meta-regression model fitted, specific study population.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relative treatment effects — relative_effects","text":"","code":"relative_effects(   x,   newdata = NULL,   study = NULL,   all_contrasts = FALSE,   trt_ref = NULL,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relative treatment effects — relative_effects","text":"x stan_nma object created nma() newdata used regression model fitted. data frame study details, one row per study, giving covariate values produce relative effects. Column names must match variables regression model. NULL, relative effects produced studies network. study Column newdata specifies study names, otherwise studies labelled row number. all_contrasts Logical, generate estimates contrasts (TRUE), just \"basic\" contrasts network reference treatment (FALSE)? Default FALSE. trt_ref Reference treatment construct relative effects , all_contrasts = FALSE. default, relative effects network reference treatment. Coerced character string. probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) predictive_distribution Logical, random effects model fitted, predictive distribution relative effects new study returned? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relative treatment effects — relative_effects","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Relative treatment effects — relative_effects","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce relative effects smk_releff_RE <- relative_effects(smk_fit_RE) smk_releff_RE #>                           mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> d[Group counselling]      1.11 0.43  0.28 0.83 1.09 1.38  1.96     2243 #> d[Individual counselling] 0.85 0.24  0.38 0.69 0.85 1.00  1.34     1190 #> d[Self-help]              0.50 0.40 -0.30 0.25 0.50 0.76  1.28     1897 #>                           Tail_ESS Rhat #> d[Group counselling]          2523    1 #> d[Individual counselling]     2147    1 #> d[Self-help]                  2560    1 plot(smk_releff_RE, ref_line = 0)   # Relative effects for all pairwise comparisons relative_effects(smk_fit_RE, all_contrasts = TRUE) #>                                                  mean   sd  2.5%   25%   50% #> d[Group counselling vs. No intervention]         1.11 0.43  0.28  0.83  1.09 #> d[Individual counselling vs. No intervention]    0.85 0.24  0.38  0.69  0.85 #> d[Self-help vs. No intervention]                 0.50 0.40 -0.30  0.25  0.50 #> d[Individual counselling vs. Group counselling] -0.26 0.41 -1.07 -0.52 -0.25 #> d[Self-help vs. Group counselling]              -0.61 0.48 -1.60 -0.92 -0.60 #> d[Self-help vs. Individual counselling]         -0.35 0.41 -1.19 -0.61 -0.35 #>                                                   75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling vs. No intervention]         1.38  1.96     2243     2523 #> d[Individual counselling vs. No intervention]    1.00  1.34     1190     2147 #> d[Self-help vs. No intervention]                 0.76  1.28     1897     2560 #> d[Individual counselling vs. Group counselling]  0.00  0.53     3067     2803 #> d[Self-help vs. Group counselling]              -0.29  0.34     3251     2655 #> d[Self-help vs. Individual counselling]         -0.09  0.44     2409     2741 #>                                                 Rhat #> d[Group counselling vs. No intervention]           1 #> d[Individual counselling vs. No intervention]      1 #> d[Self-help vs. No intervention]                   1 #> d[Individual counselling vs. Group counselling]    1 #> d[Self-help vs. Group counselling]                 1 #> d[Self-help vs. Individual counselling]            1  # Relative effects against a different reference treatment relative_effects(smk_fit_RE, trt_ref = \"Self-help\") #>                            mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> d[No intervention]        -0.50 0.40 -1.28 -0.76 -0.50 -0.25  0.30     1897 #> d[Group counselling]       0.61 0.48 -0.34  0.29  0.60  0.92  1.60     3251 #> d[Individual counselling]  0.35 0.41 -0.44  0.09  0.35  0.61  1.19     2409 #>                           Tail_ESS Rhat #> d[No intervention]            2560    1 #> d[Group counselling]          2655    1 #> d[Individual counselling]     2741    1  # Transforming to odds ratios # We work with the array of relative effects samples LOR_array <- as.array(smk_releff_RE) OR_array <- exp(LOR_array)  # mcmc_array objects can be summarised to produce a nma_summary object smk_OR_RE <- summary(OR_array)  # This can then be printed or plotted smk_OR_RE #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling]      3.32 1.54 1.32 2.28 2.97 3.99  7.10     2243     2523 #> d[Individual counselling] 2.41 0.60 1.47 2.00 2.33 2.73  3.83     1190     2147 #> d[Self-help]              1.78 0.74 0.74 1.28 1.64 2.13  3.59     1897     2560 #>                           Rhat #> d[Group counselling]         1 #> d[Individual counselling]    1 #> d[Self-help]                 1 plot(smk_OR_RE, ref_line = 1)  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Produce population-adjusted relative effects for all study populations in # the network pso_releff <- relative_effects(pso_fit) pso_releff #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[FIXTURE: ETN]     1.66 0.09 1.48 1.60 1.66 1.72  1.84     4732     3251    1 #> d[FIXTURE: IXE_Q2W] 3.03 0.10 2.85 2.97 3.03 3.09  3.22     5619     3314    1 #> d[FIXTURE: IXE_Q4W] 2.62 0.09 2.44 2.55 2.61 2.68  2.80     5435     3154    1 #> d[FIXTURE: SEC_150] 2.22 0.12 1.99 2.14 2.22 2.30  2.46     4817     3132    1 #> d[FIXTURE: SEC_300] 2.52 0.12 2.29 2.44 2.52 2.60  2.77     5220     3451    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-1: ETN]     1.51 0.08 1.35 1.45 1.51 1.57  1.67     4392     3424 #> d[UNCOVER-1: IXE_Q2W] 2.93 0.08 2.76 2.87 2.93 2.98  3.09     5306     3450 #> d[UNCOVER-1: IXE_Q4W] 2.51 0.08 2.36 2.46 2.51 2.57  2.67     4871     3466 #> d[UNCOVER-1: SEC_150] 2.12 0.12 1.89 2.04 2.11 2.19  2.36     5277     2960 #> d[UNCOVER-1: SEC_300] 2.42 0.13 2.18 2.33 2.42 2.50  2.67     5379     3211 #>                       Rhat #> d[UNCOVER-1: ETN]        1 #> d[UNCOVER-1: IXE_Q2W]    1 #> d[UNCOVER-1: IXE_Q4W]    1 #> d[UNCOVER-1: SEC_150]    1 #> d[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-2: ETN]     1.51 0.08 1.35 1.45 1.51 1.56  1.66     4433     3170 #> d[UNCOVER-2: IXE_Q2W] 2.92 0.08 2.77 2.87 2.93 2.98  3.09     5616     3407 #> d[UNCOVER-2: IXE_Q4W] 2.51 0.08 2.36 2.46 2.51 2.56  2.66     5119     3448 #> d[UNCOVER-2: SEC_150] 2.11 0.12 1.89 2.03 2.11 2.19  2.35     5376     2991 #> d[UNCOVER-2: SEC_300] 2.42 0.12 2.19 2.33 2.42 2.50  2.66     5572     3362 #>                       Rhat #> d[UNCOVER-2: ETN]        1 #> d[UNCOVER-2: IXE_Q2W]    1 #> d[UNCOVER-2: IXE_Q4W]    1 #> d[UNCOVER-2: SEC_150]    1 #> d[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-3: ETN]     1.53 0.08 1.38 1.48 1.53 1.58  1.68     4522     3021 #> d[UNCOVER-3: IXE_Q2W] 2.94 0.08 2.78 2.89 2.94 3.00  3.10     5813     3311 #> d[UNCOVER-3: IXE_Q4W] 2.53 0.08 2.38 2.48 2.53 2.58  2.68     5327     3513 #> d[UNCOVER-3: SEC_150] 2.13 0.12 1.91 2.05 2.13 2.21  2.36     5307     2777 #> d[UNCOVER-3: SEC_300] 2.44 0.12 2.21 2.35 2.44 2.52  2.68     5641     3361 #>                       Rhat #> d[UNCOVER-3: ETN]        1 #> d[UNCOVER-3: IXE_Q2W]    1 #> d[UNCOVER-3: IXE_Q4W]    1 #> d[UNCOVER-3: SEC_150]    1 #> d[UNCOVER-3: SEC_300]    1 #>  plot(pso_releff, ref_line = 0)   # Produce population-adjusted relative effects for a different target # population new_agd_means <- data.frame(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3)  relative_effects(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[New 1: ETN]     1.25 0.23 0.80 1.09 1.25 1.41  1.73     6086     2887    1 #> d[New 1: IXE_Q2W] 2.89 0.22 2.47 2.74 2.89 3.04  3.35     7351     2690    1 #> d[New 1: IXE_Q4W] 2.48 0.22 2.07 2.33 2.47 2.62  2.92     6949     2857    1 #> d[New 1: SEC_150] 2.08 0.22 1.65 1.93 2.08 2.23  2.54     6597     2614    1 #> d[New 1: SEC_300] 2.38 0.23 1.95 2.23 2.38 2.53  2.86     6783     3315    1 #>  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up arm-based aggregate data — set_agd_arm","title":"Set up arm-based aggregate data — set_agd_arm","text":"Set network containing arm-based aggregate data (AgD), event counts mean outcomes arm. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up arm-based aggregate data — set_agd_arm","text":"","code":"set_agd_arm(   data,   study,   trt,   y = NULL,   se = NULL,   r = NULL,   n = NULL,   E = NULL,   sample_size = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up arm-based aggregate data — set_agd_arm","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome se column data specifying standard error continuous outcome r column data specifying binary Binomial outcome count n column data specifying Binomial outcome numerator E column data specifying total time risk Poisson outcomes sample_size column data giving sample size arm. Optional, see details. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up arm-based aggregate data — set_agd_arm","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up arm-based aggregate data — set_agd_arm","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). sample_size argument optional, specified: Enables automatic centering predictors (center = TRUE) nma() regression model given network combining IPD AgD Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Nodes plot.nma_data() may weighted sample size Binomial outcome specified sample_size omitted, n used sample size default. Multinomial outcome specified sample_size omitted, sample size determined automatically supplied counts default. arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up arm-based aggregate data — set_agd_arm","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected   # Plot network plot(smk_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up contrast-based aggregate data — set_agd_contrast","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"Set network containing contrast-based aggregate data (AgD), .e. summaries relative effects treatments log Odds Ratios. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"","code":"set_agd_contrast(   data,   study,   trt,   y = NULL,   se = NULL,   sample_size = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome se column data specifying standard error continuous outcome sample_size column data giving sample size arm. Optional, see details. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"study single reference/baseline treatment, relative effects arm(s) given. reference arm, include data row continuous outcome y equal NA. study three arms (two relative effects), set standard error se reference arm data row equal standard error mean outcome reference arm (determines covariance relative effects, expressed differences mean outcomes arms). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year) default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). sample_size argument optional, specified: Enables automatic centering predictors (center = TRUE) nma() regression model given network combining IPD AgD Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Nodes plot.nma_data() may weighted sample size","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"","code":"# Set up network of Parkinson's contrast data head(parkinsons) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718  park_net <- set_agd_contrast(parkinsons,                              study = studyn,                              trt = trtn,                              y = diff,                              se = se_diff,                              sample_size = n)  # Print details park_net #> A network with 7 AgD studies (contrast-based). #>  #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected  # Plot network plot(park_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up aggregate survival data — set_agd_surv","title":"Set up aggregate survival data — set_agd_surv","text":"Set network containing aggregate survival data (AgD) form event/censoring times (e.g. reconstructed digitized Kaplan-Meier curves) covariate summary statistics study. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up aggregate survival data — set_agd_surv","text":"","code":"set_agd_surv(   data,   study,   trt,   Surv,   covariates = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up aggregate survival data — set_agd_surv","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors Surv column data specifying survival time--event outcome, using Surv() function. Right/left/interval censoring left truncation (delayed entry) supported. covariates data frame covariate summary statistics study study arm, corresponding study trt columns match data trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up aggregate survival data — set_agd_surv","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up aggregate survival data — set_agd_surv","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up aggregate survival data — set_agd_surv","text":"","code":"## Newly diagnosed multiple myeloma  head(ndmm_agd)  # Reconstructed Kaplan-Meier data #>        study     studyf trt trtf eventtime status #> 1 Morgan2012 Morgan2012 Pbo  Pbo  18.72575      1 #> 2 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 3 Morgan2012 Morgan2012 Pbo  Pbo  34.35726      1 #> 4 Morgan2012 Morgan2012 Pbo  Pbo  10.77826      1 #> 5 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 6 Morgan2012 Morgan2012 Pbo  Pbo  14.52966      1 ndmm_agd_covs   # Summary covariate information on each arm #>         study      studyf  trt trtf sample_size  age_min age_iqr_l age_median #> 1 Jackson2019 Jackson2019  Len  Len        1137 17.28246  59.13164   65.76766 #> 2 Jackson2019 Jackson2019  Pbo  Pbo         864 21.18572  58.30991   65.47402 #> 3  Morgan2012  Morgan2012  Pbo  Pbo         410 33.88979  58.05696   64.15999 #> 4  Morgan2012  Morgan2012 Thal Thal         408 38.45127  59.30022   65.48736 #>   age_iqr_h  age_max age_mean   age_sd iss_stage3 response_cr_vgpr      male #> 1  72.00756 85.76095 65.16867 8.936962  0.2480211        0.8258575 0.6165347 #> 2  71.80261 86.23080 64.62894 9.399272  0.1921296        0.8310185 0.6215278 #> 3  70.44791 84.79372 63.92360 9.006311  0.3634146        0.7170732 0.6195122 #> 4  71.73597 84.69365 65.59387 8.384686  0.3186275        0.7450980 0.6151961  set_agd_surv(ndmm_agd,              study = studyf,              trt = trtf,              Surv = Surv(eventtime, status),              covariates = ndmm_agd_covs) #> A network with 2 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study       Treatment arms #>  Jackson2019 2: Pbo | Len   #>  Morgan2012  2: Pbo | Thal  #>  #>  Outcome type: survival #> ------------------------------------------------------------------------------------ #> Total number of treatments: 3 #> Total number of studies: 2 #> Reference treatment is: Pbo #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up individual patient data — set_ipd","title":"Set up individual patient data — set_ipd","text":"Set network containing individual patient data (IPD). Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up individual patient data — set_ipd","text":"","code":"set_ipd(   data,   study,   trt,   y = NULL,   r = NULL,   E = NULL,   Surv = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up individual patient data — set_ipd","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome r column data specifying binary outcome Poisson outcome count E column data specifying total time risk Poisson outcomes Surv column data specifying survival time--event outcome, using Surv() function. Right/left/interval censoring left truncation (delayed entry) supported. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up individual patient data — set_ipd","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up individual patient data — set_ipd","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up individual patient data — set_ipd","text":"","code":"# Set up network of plaque psoriasis IPD head(plaque_psoriasis_ipd) #>    studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  62 38.6    15.8 #> 2 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  38 23.2    28.2 #> 3 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  54 27.5    13.2 #> 4 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  44 24.6    41.0 #> 5 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  44 28.3    15.2 #> 6 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 23.6    30.4 #>    male bsa weight durnpso prevsys   psa #> 1 FALSE  13  111.2       8    TRUE  TRUE #> 2 FALSE  37   62.0       1    TRUE FALSE #> 3  TRUE  13   83.5      38    TRUE FALSE #> 4 FALSE  67   66.0       1    TRUE FALSE #> 5 FALSE  10   92.7      23    TRUE FALSE #> 6 FALSE  75   73.5      21    TRUE FALSE  pso_net <- set_ipd(plaque_psoriasis_ipd,                    study = studyc,                    trt = trtc,                    r = pasi75)  # Print network details pso_net #> A network with 4 IPD studies. #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 4 #> Reference treatment is: IXE_Q2W #> Network is connected  # Plot network plot(pso_net)   # Setting a different reference treatment set_ipd(plaque_psoriasis_ipd,         study = studyc,         trt = trtc,         r = pasi75,         trt_ref = \"PBO\") #> A network with 4 IPD studies. #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":null,"dir":"Reference","previous_headings":"","what":"Smoking cessation data — smoking","title":"Smoking cessation data — smoking","text":"Data frame containing results 24 trials 4 smoking cessation treatments (Hasselblad 1998; Dias et al. 2011) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smoking cessation data — smoking","text":"","code":"smoking"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Smoking cessation data — smoking","text":"data frame 50 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Smoking cessation data — smoking","text":"Dias S, Welton NJ, Sutton AJ, Caldwell DM, Lu G, Ades AE (2011). “NICE DSU Technical Support Document 4: Inconsistency networks evidence based randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Hasselblad V (1998). “Meta-analysis Multitreatment Studies.” Medical Decision Making, 18(1), 37--43. doi:10.1177/0272989x9801800110 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/stan_nma-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The stan_nma class — stan_nma-class","title":"The stan_nma class — stan_nma-class","text":"stan_nma stan_mlnmr classes contains results running model function nma().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/stan_nma-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The stan_nma class — stan_nma-class","text":"Objects class stan_nma stan_mlnmr following components: network network data model run (class nma_data stan_nma, class mlnmr_data stan_mlnmr) stanfit stanfit object returned calling sampling() model trt_effects Whether fixed random effects used (character string) consistency consistency/inconsistency model used (character string) regression regression model used (formula) class_interactions treatment classes regression model specified, model used interactions within class (common, exchangeable, independent) xbar named vector values used centering likelihood likelihood used (character string) link link function used (character string) priors list containing priors used (nma_prior objects) basis mspline pexp models, named list spline bases study stan_mlnmr sub-class inherits stan_nma, differs class network object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":null,"dir":"Reference","previous_headings":"","what":"Statins for cholesterol lowering — statins","title":"Statins for cholesterol lowering — statins","text":"Data frame containing results 19 trials comparing statins placebo usual care (Dias et al. 2011) . number deaths (-cause mortality) recorded. studies aim primary prevention (patients previous heart disease), others aim secondary prevention (patients previous heart disease).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statins for cholesterol lowering — statins","text":"","code":"statins"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Statins for cholesterol lowering — statins","text":"data frame 38 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name prevention primary secondary prevention study r number deaths n sample size","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Statins for cholesterol lowering — statins","text":"Dias S, Sutton AJ, Welton NJ, Ades AE (2011). “NICE DSU Technical Support Document 3: Heterogeneity: subgroups, meta-regression, bias bias-adjustment.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"Posterior summaries node-splitting models (nma_nodesplit nma_nodesplit_df objects) can produced using summary() method, plotted using plot() method.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"","code":"# S3 method for nma_nodesplit_df summary(   object,   consistency = NULL,   ...,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975) )  # S3 method for nma_nodesplit summary(   object,   consistency = NULL,   ...,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975) )  # S3 method for nma_nodesplit plot(x, consistency = NULL, ...)  # S3 method for nma_nodesplit_df plot(x, consistency = NULL, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"consistency Optional, stan_nma object corresponding fitted consistency model, display network estimates alongside direct indirect estimates. fitted consistency model present nma_nodesplit_df object used present (see get_nodesplits()). ... Additional arguments passed methods probs Numeric vector specifying quantiles interest, default c(0.025, 0.25, 0.5, 0.75, 0.975) x, object nma_nodesplit nma_nodesplit_df object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"nodesplit_summary object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"plot() method shortcut plot(summary(nma_nodesplit)). details plotting options, see plot.nodesplit_summary().","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"","code":"# \\donttest{ # Run smoking node-splitting example if not already available if (!exists(\"smk_fit_RE_nodesplit\")) example(\"example_smk_nodesplit\", run.donttest = TRUE) # } # \\donttest{ # Summarise the node-splitting results summary(smk_fit_RE_nodesplit) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.10 0.43  0.28  0.81  1.09 1.38  2.01     1792     2159    1 #> d_dir            1.06 0.75 -0.33  0.57  1.02 1.52  2.64     3212     2561    1 #> d_ind            1.16 0.54  0.14  0.80  1.16 1.50  2.26     1698     2097    1 #> omega           -0.10 0.89 -1.79 -0.70 -0.13 0.47  1.76     2328     2516    1 #> tau              0.86 0.20  0.55  0.72  0.84 0.97  1.33     1181     1600    1 #> tau_consistency  0.83 0.18  0.55  0.71  0.81 0.94  1.26     1549     1758    1 #>  #> Residual deviance: 54.2 (on 50 data points) #>                pD: 44.2 #>               DIC: 98.4 #>  #> Bayesian p-value: 0.87 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.86 0.24  0.41  0.70 0.85 1.00  1.34     1277     1723 1.00 #> d_dir           0.89 0.25  0.42  0.72 0.88 1.05  1.41     1351     1977 1.00 #> d_ind           0.58 0.66 -0.70  0.13 0.57 1.01  1.96     1288     1730 1.00 #> omega           0.31 0.69 -1.09 -0.13 0.32 0.78  1.67     1288     1658 1.01 #> tau             0.85 0.19  0.55  0.72 0.83 0.96  1.28     1145     1894 1.00 #> tau_consistency 0.83 0.18  0.55  0.71 0.81 0.94  1.26     1549     1758 1.00 #>  #> Residual deviance: 54.5 (on 50 data points) #>                pD: 44.5 #>               DIC: 99 #>  #> Bayesian p-value: 0.63 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.50 0.39 -0.25  0.24  0.49 0.75  1.30     2036     2569    1 #> d_dir            0.33 0.54 -0.72 -0.02  0.33 0.67  1.40     3221     2757    1 #> d_ind            0.70 0.62 -0.53  0.30  0.69 1.10  1.92     2129     2391    1 #> omega           -0.37 0.81 -2.01 -0.90 -0.35 0.15  1.24     2201     2688    1 #> tau              0.86 0.19  0.55  0.73  0.84 0.98  1.28     1370     2384    1 #> tau_consistency  0.83 0.18  0.55  0.71  0.81 0.94  1.26     1549     1758    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.4 #>               DIC: 98.5 #>  #> Bayesian p-value: 0.62 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.24 0.41 -1.09 -0.51 -0.23  0.02  0.56     2722     2753    1 #> d_dir           -0.13 0.49 -1.09 -0.45 -0.13  0.19  0.84     3952     3114    1 #> d_ind           -0.54 0.65 -1.84 -0.96 -0.53 -0.12  0.68     1270     1487    1 #> omega            0.41 0.72 -1.00 -0.04  0.43  0.87  1.79     1384     1605    1 #> tau              0.87 0.20  0.56  0.73  0.85  0.99  1.33     1311     2157    1 #> tau_consistency  0.83 0.18  0.55  0.71  0.81  0.94  1.26     1549     1758    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.5 #>               DIC: 98.6 #>  #> Bayesian p-value: 0.54 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.60 0.49 -1.59 -0.91 -0.59 -0.28  0.36     2352     2587    1 #> d_dir           -0.60 0.64 -1.93 -1.01 -0.60 -0.17  0.62     3918     3021    1 #> d_ind           -0.59 0.68 -1.96 -1.01 -0.59 -0.17  0.73     2047     2302    1 #> omega           -0.01 0.87 -1.71 -0.57  0.01  0.54  1.75     2267     2502    1 #> tau              0.87 0.19  0.56  0.73  0.85  0.97  1.30     1306     2065    1 #> tau_consistency  0.83 0.18  0.55  0.71  0.81  0.94  1.26     1549     1758    1 #>  #> Residual deviance: 54 (on 50 data points) #>                pD: 44.2 #>               DIC: 98.2 #>  #> Bayesian p-value: 0.99 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.36 0.41 -1.14 -0.62 -0.36 -0.09  0.46     2328     2818    1 #> d_dir            0.07 0.64 -1.15 -0.34  0.06  0.48  1.31     3377     2830    1 #> d_ind           -0.60 0.53 -1.64 -0.93 -0.58 -0.26  0.46     1842     2061    1 #> omega            0.66 0.81 -0.97  0.14  0.67  1.19  2.21     2242     2155    1 #> tau              0.85 0.19  0.54  0.72  0.83  0.97  1.29     1029     1995    1 #> tau_consistency  0.83 0.18  0.55  0.71  0.81  0.94  1.26     1549     1758    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44 #>               DIC: 97.6 #>  #> Bayesian p-value: 0.4  # Plot the node-splitting results plot(smk_fit_RE_nodesplit)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of prior distributions — summary.nma_prior","title":"Summary of prior distributions — summary.nma_prior","text":"Print summary prior distribution details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of prior distributions — summary.nma_prior","text":"","code":"# S3 method for nma_prior summary(object, ..., probs = c(0.5, 0.95), digits = 2, trunc = NULL)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of prior distributions — summary.nma_prior","text":"object Prior distribution nma_prior object ... Additional arguments, used probs Numeric vector probabilities calculate prior intervals digits Number digits display trunc Optional numeric vector length 2, giving truncation limits prior distribution. Useful real-valued prior assigned positive-valued parameter, trunc = c(0, Inf) give correct prior intervals. default, truncation used.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of prior distributions — summary.nma_prior","text":"data frame returned invisibly, giving prior intervals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of prior distributions — summary.nma_prior","text":"","code":"summary(normal(location = 0, scale = 1)) #> A Normal prior distribution: location = 0, scale = 1. #> 50% of the prior density lies between -0.67 and 0.67. #> 95% of the prior density lies between -1.96 and 1.96. summary(half_normal(scale = 1)) #> A half-Normal prior distribution: location = 0, scale = 1. #> 50% of the prior density lies between 0 and 0.67. #> 95% of the prior density lies between 0 and 1.96. summary(log_normal(location = -3.93, scale = 1.51)) #> A log-Normal prior distribution: location = -3.93, scale = 1.51. #> 50% of the prior density lies between 0.01 and 0.05. #> 95% of the prior density lies between 0 and 0.38.  # Truncation limits may be set, for example to restrict a prior to positive values summary(normal(location = 0.5, scale = 1), trunc = c(0, Inf)) #> A Normal prior distribution: location = 0.5, scale = 1. #> 50% of the prior density lies between 0.45 and 1.44. #> 95% of the prior density lies between 0.05 and 2.61."},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior summaries from stan_nma objects — summary.stan_nma","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"Posterior summaries model parameters stan_nma objects may produced using summary() method plotted plot() method. NOTE: produce relative effects, absolute predictions, posterior ranks, see relative_effects(), predict.stan_nma(), posterior_ranks(), posterior_rank_probs().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"","code":"# S3 method for stan_nma summary(object, ..., pars, include, probs = c(0.025, 0.25, 0.5, 0.75, 0.975))  # S3 method for stan_nma plot(   x,   ...,   pars,   include,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"... Additional arguments passed methods pars, include See rstan::extract() probs Numeric vector specifying quantiles interest, default c(0.025, 0.25, 0.5, 0.75, 0.975) x, object stan_nma object stat Character string specifying ggdist plot stat use, default \"pointinterval\" orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\" ref_line Numeric vector positions reference lines, default reference lines drawn summary Logical, calculate posterior summaries? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"nma_summary object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"plot() method shortcut plot(summary(stan_nma)). details plotting options, see plot.nma_summary().","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Summary and plot of all model parameters summary(smk_fit_RE) #>                                    mean   sd  2.5%   25%   50%   75% 97.5% #> mu[1]                             -2.79 0.33 -3.46 -3.00 -2.78 -2.56 -2.16 #> mu[2]                             -2.58 0.77 -4.19 -3.06 -2.57 -2.08 -1.12 #> mu[3]                             -2.14 0.12 -2.39 -2.22 -2.14 -2.06 -1.92 #> mu[4]                             -4.05 0.56 -5.22 -4.41 -4.03 -3.66 -3.03 #> mu[5]                             -2.15 0.14 -2.43 -2.25 -2.15 -2.06 -1.89 #> mu[6]                             -3.42 0.73 -5.07 -3.85 -3.36 -2.92 -2.16 #> mu[7]                             -3.02 0.44 -3.96 -3.29 -2.99 -2.71 -2.25 #> mu[8]                             -2.72 0.62 -4.06 -3.11 -2.68 -2.29 -1.63 #> mu[9]                             -1.85 0.43 -2.72 -2.11 -1.84 -1.55 -1.06 #> mu[10]                            -2.08 0.12 -2.32 -2.16 -2.08 -2.00 -1.85 #> mu[11]                            -3.62 0.23 -4.10 -3.77 -3.61 -3.46 -3.20 #> mu[12]                            -2.22 0.13 -2.48 -2.30 -2.22 -2.13 -1.97 #> mu[13]                            -2.69 0.44 -3.58 -2.98 -2.67 -2.39 -1.87 #> mu[14]                            -2.41 0.23 -2.88 -2.57 -2.40 -2.26 -1.97 #> mu[15]                            -2.69 0.73 -4.30 -3.12 -2.63 -2.18 -1.43 #> mu[16]                            -2.61 0.34 -3.33 -2.84 -2.60 -2.38 -1.99 #> mu[17]                            -2.38 0.11 -2.60 -2.45 -2.37 -2.30 -2.17 #> mu[18]                            -2.57 0.28 -3.14 -2.74 -2.56 -2.38 -2.06 #> mu[19]                            -1.90 0.12 -2.14 -1.99 -1.90 -1.82 -1.68 #> mu[20]                            -2.80 0.12 -3.05 -2.88 -2.80 -2.72 -2.57 #> mu[21]                            -1.11 0.80 -2.69 -1.62 -1.10 -0.60  0.47 #> mu[22]                            -2.41 0.85 -4.09 -2.96 -2.39 -1.86 -0.80 #> mu[23]                            -2.32 0.80 -3.87 -2.85 -2.31 -1.79 -0.74 #> mu[24]                            -2.82 0.84 -4.55 -3.36 -2.81 -2.29 -1.14 #> d[Group counselling]               1.11 0.43  0.28  0.83  1.09  1.38  1.96 #> d[Individual counselling]          0.85 0.24  0.38  0.69  0.85  1.00  1.34 #> d[Self-help]                       0.50 0.40 -0.30  0.25  0.50  0.76  1.28 #> tau                                0.83 0.18  0.54  0.70  0.81  0.93  1.23 #> delta[1: Individual counselling]   1.07 0.39  0.31  0.81  1.07  1.33  1.86 #> delta[1: Group counselling]        0.37 0.43 -0.50  0.09  0.37  0.65  1.23 #> delta[2: Self-help]                0.68 0.79 -0.82  0.17  0.66  1.16  2.27 #> delta[2: Individual counselling]   0.77 0.77 -0.72  0.27  0.76  1.25  2.35 #> delta[2: Group counselling]        1.00 0.78 -0.49  0.49  0.98  1.49  2.60 #> delta[3: Individual counselling]   2.17 0.14  1.89  2.07  2.17  2.26  2.44 #> delta[4: Individual counselling]   0.90 0.58 -0.21  0.52  0.89  1.27  2.06 #> delta[5: Individual counselling]   0.44 0.15  0.15  0.33  0.44  0.54  0.74 #> delta[6: Individual counselling]   1.71 0.72  0.50  1.20  1.65  2.14  3.35 #> delta[7: Individual counselling]   2.13 0.49  1.26  1.80  2.11  2.44  3.17 #> delta[8: Individual counselling]   1.66 0.63  0.51  1.23  1.63  2.06  3.01 #> delta[9: Individual counselling]   0.60 0.47 -0.31  0.27  0.60  0.90  1.53 #> delta[10: Self-help]               0.00 0.17 -0.32 -0.11  0.00  0.11  0.34 #> delta[11: Self-help]               0.41 0.31 -0.22  0.20  0.41  0.61  1.02 #> delta[12: Individual counselling]  0.41 0.17  0.09  0.30  0.41  0.53  0.74 #> delta[13: Individual counselling]  0.40 0.50 -0.55  0.07  0.40  0.72  1.43 #> delta[14: Individual counselling]  0.63 0.29  0.05  0.43  0.63  0.82  1.21 #> delta[15: Group counselling]       2.15 0.75  0.81  1.62  2.10  2.61  3.77 #> delta[16: Self-help]               0.65 0.40 -0.10  0.38  0.65  0.91  1.43 #> delta[17: Individual counselling]  0.55 0.14  0.28  0.45  0.55  0.65  0.84 #> delta[18: Individual counselling]  0.03 0.31 -0.58 -0.17  0.03  0.24  0.68 #> delta[19: Individual counselling] -0.19 0.17 -0.52 -0.31 -0.19 -0.07  0.14 #> delta[20: Individual counselling]  0.08 0.19 -0.30 -0.05  0.08  0.20  0.43 #> delta[21: Self-help]               0.68 0.80 -0.89  0.18  0.66  1.19  2.26 #> delta[21: Individual counselling]  0.63 0.78 -0.95  0.14  0.63  1.14  2.19 #> delta[22: Self-help]               0.32 0.84 -1.33 -0.23  0.32  0.86  2.02 #> delta[22: Group counselling]       1.28 0.85 -0.30  0.74  1.26  1.82  2.99 #> delta[23: Individual counselling]  0.67 0.78 -0.91  0.17  0.67  1.18  2.16 #> delta[23: Group counselling]       1.28 0.79 -0.28  0.75  1.28  1.80  2.84 #> delta[24: Individual counselling]  1.07 0.82 -0.53  0.54  1.05  1.57  2.80 #> delta[24: Group counselling]       0.91 0.84 -0.76  0.36  0.91  1.46  2.59 #>                                   Bulk_ESS Tail_ESS Rhat #> mu[1]                                 5721     3121    1 #> mu[2]                                 2739     2354    1 #> mu[3]                                 7281     3087    1 #> mu[4]                                 4649     2750    1 #> mu[5]                                 6408     2986    1 #> mu[6]                                 3052     2287    1 #> mu[7]                                 4486     2888    1 #> mu[8]                                 4104     2933    1 #> mu[9]                                 5637     2874    1 #> mu[10]                                7633     3017    1 #> mu[11]                                6723     2840    1 #> mu[12]                                7081     3186    1 #> mu[13]                                4599     2805    1 #> mu[14]                                4830     2956    1 #> mu[15]                                3275     2521    1 #> mu[16]                                5542     2995    1 #> mu[17]                                7637     2637    1 #> mu[18]                                5825     2592    1 #> mu[19]                                8801     2983    1 #> mu[20]                                7216     3235    1 #> mu[21]                                3000     2832    1 #> mu[22]                                2838     2694    1 #> mu[23]                                3095     2901    1 #> mu[24]                                3352     2569    1 #> d[Group counselling]                  2243     2523    1 #> d[Individual counselling]             1190     2147    1 #> d[Self-help]                          1897     2560    1 #> tau                                   1286     1830    1 #> delta[1: Individual counselling]      5647     3246    1 #> delta[1: Group counselling]           5616     3405    1 #> delta[2: Self-help]                   2819     2736    1 #> delta[2: Individual counselling]      2848     2718    1 #> delta[2: Group counselling]           2821     2614    1 #> delta[3: Individual counselling]      5896     3387    1 #> delta[4: Individual counselling]      4151     3089    1 #> delta[5: Individual counselling]      6226     2954    1 #> delta[6: Individual counselling]      2700     2108    1 #> delta[7: Individual counselling]      3947     2899    1 #> delta[8: Individual counselling]      3738     2840    1 #> delta[9: Individual counselling]      5164     3128    1 #> delta[10: Self-help]                  5594     3428    1 #> delta[11: Self-help]                  5464     3345    1 #> delta[12: Individual counselling]     5747     3160    1 #> delta[13: Individual counselling]     4835     3334    1 #> delta[14: Individual counselling]     4971     2971    1 #> delta[15: Group counselling]          2563     2175    1 #> delta[16: Self-help]                  4916     2763    1 #> delta[17: Individual counselling]     6046     2677    1 #> delta[18: Individual counselling]     5402     3004    1 #> delta[19: Individual counselling]     6111     3427    1 #> delta[20: Individual counselling]     6150     3577    1 #> delta[21: Self-help]                  2917     2812    1 #> delta[21: Individual counselling]     2961     2740    1 #> delta[22: Self-help]                  2938     2576    1 #> delta[22: Group counselling]          2739     2711    1 #> delta[23: Individual counselling]     3163     2744    1 #> delta[23: Group counselling]          3104     3138    1 #> delta[24: Individual counselling]     3559     2694    1 #> delta[24: Group counselling]          3664     2935    1 plot(smk_fit_RE)   # Summary and plot of heterogeneity tau only summary(smk_fit_RE, pars = \"tau\") #>     mean   sd 2.5% 25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau 0.83 0.18 0.54 0.7 0.81 0.93  1.23     1286     1830    1 plot(smk_fit_RE, pars = \"tau\")   # Customising plot output plot(smk_fit_RE,      pars = c(\"d\", \"tau\"),      stat = \"halfeye\",      ref_line = 0)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot theme for multinma plots — theme_multinma","title":"Plot theme for multinma plots — theme_multinma","text":"simple ggplot2 theme plots multinma package.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot theme for multinma plots — theme_multinma","text":"","code":"theme_multinma(...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot theme for multinma plots — theme_multinma","text":"... Arguments passed ggplot2::theme_light()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot theme for multinma plots — theme_multinma","text":"ggplot2 theme","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot theme for multinma plots — theme_multinma","text":"","code":"library(ggplot2) theme_set(theme_multinma())"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":null,"dir":"Reference","previous_headings":"","what":"Thrombolytic treatments data — thrombolytics","title":"Thrombolytic treatments data — thrombolytics","text":"Data frame containing results 50 trials 8 thrombolytic drugs (streptokinase, SK; alteplase, t-PA; accelerated alteplase, Acc t-PA; streptokinase plus alteplase, SK+tPA; reteplase, r-PA; tenocteplase, TNK; urokinase, UK; anistreptilase, ASPAC) plus per-cutaneous transluminal coronary angioplasty (PTCA) (Boland et al. 2003; Lu Ades 2006; Dias et al. 2011) . number deaths 30 35 days following acute myocardial infarction recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Thrombolytic treatments data — thrombolytics","text":"","code":"thrombolytics"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Thrombolytic treatments data — thrombolytics","text":"data frame 102 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Thrombolytic treatments data — thrombolytics","text":"Boland , Dundar Y, Bagust , Haycox , Hill R, Mota RM, Walley T, Dickson R (2003). “Early thrombolysis treatment acute myocardial infarction: systematic review economic evaluation.” Health Technology Assessment, 7(15). doi:10.3310/hta7150 . Dias S, Welton NJ, Sutton AJ, Caldwell DM, Lu G, Ades AE (2011). “NICE DSU Technical Support Document 4: Inconsistency networks evidence based randomised controlled trials.” National Institute Health Care Excellence. https://www.sheffield.ac.uk/nice-dsu. Lu GB, Ades AE (2006). “Assessing evidence inconsistency mixed treatment comparisons.” Journal American Statistical Association, 101(474), 447--459. doi:10.1198/016214505000001302 .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":null,"dir":"Reference","previous_headings":"","what":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"Data frame containing number deaths 6 trials comparing transfusion granulocytes (white blood cells) control (Stanworth et al. 2005) . Previously used demonstrate informative prior distributions heterogeneity variance Turner et al. (2012) .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"","code":"transfusion"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"data frame 12 rows 4 variables: studyc study name trtc treatment name r total number deaths n total number individuals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Granulocyte transfusion in patients with neutropenia or neutrophil\ndysfunction — transfusion","text":"Stanworth S, Massey E, Hyde C, Brunskill SJ, Navarette C, Lucas G, Marks D, Paulus U (2005). “Granulocyte transfusions treating infections patients neutropenia neutrophil dysfunction.” Cochrane Database Systematic Reviews. ISSN 1465-1858, doi:10.1002/14651858.CD005339 . Turner RM, Davey J, Clarke MJ, Thompson SG, Higgins JPT (2012). “Predicting extent heterogeneity meta-analysis, using empirical data Cochrane Database Systematic Reviews.” International Journal Epidemiology, 41(3), 818--827. doi:10.1093/ije/dys041 .","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"feature-survivaltime-to-event-models-are-now-supported-0-5-1-9000","dir":"Changelog","previous_headings":"","what":"Feature: Survival/time-to-event models are now supported","title":"multinma 0.5.1.9000","text":"set_ipd() now Surv argument specifying survival outcomes using survival::Surv(), new function set_agd_surv() sets aggregate data form event/censoring times (e.g. digitized Kaplan-Meier curves) overall covariate summaries. Left, right, interval censoring well left truncation (delayed entry) supported. available likelihoods Exponential (PH AFT forms), Weibull (PH AFT forms), Gompertz, log-Normal, log-Logistic, Gamma, Generalised Gamma, flexible M-splines baseline hazard, piecewise exponential hazards. Auxiliary parameters (e.g. shapes, spline coefficients) always stratified study respect randomisation, may stratified treatment (e.g. relax proportional hazards assumption) /additional factors using aux_by argument nma(). regression model may defined auxiliary parameters using aux_regression argument nma(), allowing non-proportionality modelled treatment /covariate effects shapes spline coefficients. predict() method produces estimates survival probabilities, hazards, cumulative hazards, mean survival times, restricted mean survival times, quantiles survival time distribution, median survival times. predictions can plotted using plot() method. geom_km() function assists plotting Kaplan-Meier curves network object, example overlay estimated survival curves. transform argument can used produce log-log plots assessing proportional hazards assumption, along cumulative hazards log survival curves. new vignette demonstrates ML-NMR survival analysis example progression-free survival autologous stem cell transplant newly diagnosed multiple myeloma, corresponding datasets ndmm_ipd, ndmm_agd, ndmm_agd_covs.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"feature-automatic-checking-of-numerical-integration-for-ml-nmr-models-0-5-1-9000","dir":"Changelog","previous_headings":"","what":"Feature: Automatic checking of numerical integration for ML-NMR models","title":"multinma 0.5.1.9000","text":"accuracy numerical integration ML-NMR models can now checked automatically, default. , half chains run n_int half n_int/2 integration points. Rhat effective sample size warnings can ascribed either: non-convergence MCMC chains, requiring increased number iterations iter nma(), ; insufficient accuracy numerical integration, requiring increased number integration points n_int add_integration(). Descriptive warning messages indicate case. feature controlled new int_check argument nma(), enabled (TRUE) default. Saving thinned cumulative integration points can now disabled int_thin = 0, now disabled default. previous default int_thin = max(n_int %/% 10, 1). can now check sufficient accuracy automatically, default number integration points n_int add_integration() lowered 64. still conservative choice, sufficient many cases; previous default 1000 excessive. result, ML-NMR models now much faster run default, due lower n_int disabling saving cumulative integration points.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"other-updates-0-5-1-9000","dir":"Changelog","previous_headings":"","what":"Other updates","title":"multinma 0.5.1.9000","text":"Feature: dic() now includes option use pV penalty instead pD. Feature: baseline aux arguments predict() can now specified name study network, use parameter estimates study prediction. Improvement: predict() now produce aggregate-level predictions sample individuals newdata ML-NMR models (previously newdata include integration points). Improvement: Compatibility future rstan versions (PR #25). Improvement: Added plot.mcmc_array() method, shortcut plot(summary(x), ...). Fix: plot.nma_data(), using custom layout string (e.g.  data frame layout coordinates) now works expected nudge > 0. Fix: Documentation corrections (PR #24). Fix: Added missing .tibble.stan_nma() as_tibble.stan_nma() methods, complement existing .data.frame.stan_nma(). Fix: Bug ordered multinomial models data studies missing categories assigned wrong category (#28).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-051","dir":"Changelog","previous_headings":"","what":"multinma 0.5.1","title":"multinma 0.5.1","text":"CRAN release: 2023-05-24 Fix: Now compatible latest StanHeaders v2.26.25 (fixes #23) Fix: Dealt various tidyverse deprecations Fix: Updated TSD URLs (thanks @ndunnewind)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-050","dir":"Changelog","previous_headings":"","what":"multinma 0.5.0","title":"multinma 0.5.0","text":"CRAN release: 2022-08-29 Feature: Treatment labels network plots can now nudged away nodes weight_nodes = TRUE, using new nudge argument plot.nma_data() (#15). Feature: data frame returned calling as_tibble() .data.frame() nma_summary object (relative effects predictions) now includes columns corresponding treatment (.trt) contrast (.trta .trtb), .category column may included multinomial models. Previously details present part parameter column Feature: Added log t prior distribution log_student_t(), can used positive-valued parameters (e.g. heterogeneity variance). Improvement: set_agd_contrast() now produces informative error message covariance matrix implied se column positive definite. Previously checked Stan calling nma() function. Improvement: Updated plaque psoriasis ML-NMR vignette include new analyses, including assessing assumptions population adjustment synthesising multinomial outcomes. Improvement: Improved behaviour .trtclass special regression formulas, now main effects .trtclass always removed since collinear .trt. allows expansion interactions * work properly, e.g. ~variable*.trtclass, whereas previously resulted -parametrised model. Fix: CRAN check note manual HTML5 compatibility. Fix: Residual deviance log likelihood parameters now named correctly contrast-based aggregate data present (PR #19).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-042","dir":"Changelog","previous_headings":"","what":"multinma 0.4.2","title":"multinma 0.4.2","text":"CRAN release: 2022-03-02 Fix: Error get_nodesplits() studies multiple arms treatment. Fix: print.nma_data() now prints repeated arms studies multiple arms treatment. Fix: CRAN warning regarding invalid img tag height attribute documentation.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-041","dir":"Changelog","previous_headings":"","what":"multinma 0.4.1","title":"multinma 0.4.1","text":"CRAN release: 2022-02-04 Fix: tidyr v1.2.0 breaks ordered multinomial models studies report categories (.e. multinomial category outcomes NA multi()) (PR #11)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-040","dir":"Changelog","previous_headings":"","what":"multinma 0.4.0","title":"multinma 0.4.0","text":"CRAN release: 2022-01-18 Feature: Node-splitting models assessing inconsistency now available consistency = \"nodesplit\" nma(). Comparisons split can chosen using nodesplit argument, default possibly inconsistent comparisons chosen using get_nodesplits(). Node-splitting results can summarised summary.nma_nodesplit() plotted plot.nodesplit_summary(). Feature: correlation matrix generating integration points add_integration() ML-NMR models now adjusted underlying Gaussian copula, output correlations integration points better match requested input correlations. new argument cor_adjust controls behaviour, options \"spearman\", \"pearson\", \"none\". Although correlations typically little impact results, strict reproducibility old behaviour version 0.3.0 available cor_adjust = \"legacy\". Feature: random effects models, predictive distribution relative/absolute effects new study can now obtained relative_effects() predict.stan_nma() respectively, using new argument predictive_distribution = TRUE. Feature: Added option calculate SUCRA values summarising posterior treatment ranks posterior_ranks() posterior_rank_probs(), argument sucra = TRUE. Improvement: Factor order now respected trt, study, trt_class factors, previously order levels reset natural sort order. Improvement: Update package website Bootstrap 5 release pkgdown 2.0.0 Fix: Model fitting now robust non-default settings options(\"contrasts\"). Fix: plot.nma_data() longer gives ggplot deprecation warning (PR #6). Fix: Bug predict.stan_nma() single covariate newdata data.frame (PR #7). Fix: Attempting call predict.stan_nma() regression model contrast data newdata baseline specified now throws descriptive error message.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-030","dir":"Changelog","previous_headings":"","what":"multinma 0.3.0","title":"multinma 0.3.0","text":"CRAN release: 2021-03-18 Feature: Added baseline_type baseline_level arguments predict.stan_nma(), allow baseline distributions specified response linear predictor scale, individual aggregate level. Feature: baseline argument predict.stan_nma() can now accept (named) list baseline distributions newdata contains multiple studies. Improvement: Misspecified newdata arguments functions like relative_effects() predict.stan_nma() now give informative error messages. Fix: Constructing models contrast-based data previously gave errors scenarios (ML-NMR models, UME models, cases AgD meta-regression models). Fix: Ensure CRAN additional checks --run-donttest run correctly.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-021","dir":"Changelog","previous_headings":"","what":"multinma 0.2.1","title":"multinma 0.2.1","text":"CRAN release: 2021-01-09 Fix: Producing relative effect estimates contrasts using relative_effects() all_contrasts = TRUE longer gives error regression models. Fix: Specifying covariate correlation matrix cor add_integration() required one covariate present. Improvement: Added detailed documentation likelihoods link functions available data type (likelihood link arguments nma()).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-020","dir":"Changelog","previous_headings":"","what":"multinma 0.2.0","title":"multinma 0.2.0","text":"CRAN release: 2020-12-04 Feature: set_*() functions now accept dplyr::mutate() style semantics, allowing inline variable transformations. Feature: Added ordered multinomial models, helper function multi() specifying outcomes. Accompanied new data set hta_psoriasis vignette. Feature: Implicit flat priors can now specified, parameter, using flat(). Improvement: .array.stan_nma() now much efficient, meaning many post-estimation functions also now much efficient. Improvement: plot.nma_dic() now efficient, particularly large numbers data points. Improvement: layering points producing “dev-dev” plots using plot.nma_dic() multiple data types reversed improved clarity (now AgD top IPD). Improvement: Aggregate-level predictions predict() ML-NMR / IPD regression models now calculated much memory-efficient manner. Improvement: Added overview examples given vignettes. Improvement: Network plots weight_edges = TRUE longer produce legends non-integer values number studies. Fix: plot.nma_dic() longer gives error attempting specify .width argument producing “dev-dev” plots.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-013","dir":"Changelog","previous_headings":"","what":"multinma 0.1.3","title":"multinma 0.1.3","text":"CRAN release: 2020-06-30 Format DESCRIPTION CRAN requirements","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-012","dir":"Changelog","previous_headings":"","what":"multinma 0.1.2","title":"multinma 0.1.2","text":"Wrapped long-running examples \\donttest{} instead \\dontrun{}","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-011","dir":"Changelog","previous_headings":"","what":"multinma 0.1.1","title":"multinma 0.1.1","text":"Reduced size vignettes Added methods paper reference DESCRIPTION Added zenodo DOI","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-010","dir":"Changelog","previous_headings":"","what":"multinma 0.1.0","title":"multinma 0.1.0","text":"Feature: Network plots, using plot() method nma_data objects. Feature: .igraph(), as_tbl_graph() methods nma_data objects. Feature: Produce relative effect estimates relative_effects(), posterior ranks posterior_ranks(), posterior rank probabilities posterior_rank_probs(). study-specific regression model given. Feature: Produce predictions absolute effects predict() method stan_nma objects. Feature: Plots relative effects, ranks, predictions, parameter estimates via plot.nma_summary(). Enables centering predictors (center = TRUE) nma() regression model given, replacing agd_sample_size argument nma() Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Allows nodes network plots weighted sample size Feature: Plots residual deviance contributions model “dev-dev” plots comparing residual deviance contributions two models, using plot() method nma_dic objects produced dic(). Feature: Complementary log-log (cloglog) link function link = \"cloglog\" binomial likelihoods. Feature: Option specify priors heterogeneity standard deviation, variance, precision, argument prior_het_type. Feature: Added log-Normal prior distribution. Feature: Plots prior distributions vs. posterior distributions plot_prior_posterior(). Feature: Pairs plot method pairs(). Feature: Added vignettes example analyses NICE TSDs . Fix: Random effects models even moderate numbers studies slow. now run much quickly, using sparse representation RE correlation matrix automatically enabled sparsity 90% (roughly equivalent 10 studies).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-001","dir":"Changelog","previous_headings":"","what":"multinma 0.0.1","title":"multinma 0.0.1","text":"Initial release.","code":""}]
