[{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Atrial fibrillation","text":"Whilst data patient-years risk study (E), ignore follow analysis Cooper et al. (2009), instead analysing number patients stroke (r) total (n) arm. use function set_agd_arm() set network, making sure specify treatment classes trt_class. remove WASPO study network arms zero events, study therefore contributes information. (better analysis, accounting differences patient-years risk studies, can performed specifying rate outcome r E set_agd_arm() . following code remains identical.) Plot network plot() method:","code":"af_net <- set_agd_arm(atrial_fibrillation[atrial_fibrillation$studyc != \"WASPO\", ],                        study = studyc,                       trt = trtc,                       r = r,                        n = n,                       trt_class = trt_class) af_net #> A network with 25 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                                                  #>  ACTIVE-W      2: Standard adjusted dose anti-coagulant | Low dose aspirin + copidogrel        #>  AFASAK 1      3: Standard adjusted dose anti-coagulant | Low dose aspirin | Placebo/Standa... #>  AFASAK 2      4: Standard adjusted dose anti-coagulant | Fixed dose warfarin | Fixed dose ... #>  BAATAF        2: Low adjusted dose anti-coagulant | Placebo/Standard care                     #>  BAFTA         2: Standard adjusted dose anti-coagulant | Low dose aspirin                     #>  CAFA          2: Standard adjusted dose anti-coagulant | Placebo/Standard care                #>  Chinese ATAFS 2: Standard adjusted dose anti-coagulant | Low dose aspirin                     #>  EAFT          3: Standard adjusted dose anti-coagulant | Medium dose aspirin | Placebo/Sta... #>  ESPS 2        4: Dipyridamole | Low dose aspirin | Low dose aspirin + dipyridamole | Place... #>  JAST          2: Low dose aspirin | Placebo/Standard care                                     #>  ... plus 15 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 17, in 4 classes #> Total number of studies: 25 #> Reference treatment is: Standard adjusted dose anti-coagulant #> Network is connected plot(af_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE) +    ggplot2::theme(legend.position = \"bottom\", legend.box = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Atrial fibrillation","text":"fit two (random effects) models: standard NMA model without covariates (model 1 Cooper et al. (2009)); meta-regression model adjusting proportion individuals study prior stroke, shared interaction coefficients treatment class (model 4b Cooper et al. (2009)).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"nma-with-no-covariates","dir":"Articles","previous_headings":"Meta-analysis models","what":"NMA with no covariates","title":"Example: Atrial fibrillation","text":"fit random effects model using nma() function trt_effects = \"random\". use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k study-specific intercepts μj\\mu_j, half-N(52)\\textrm{half-N}(5^2) prior heterogeneity standard deviation τ\\tau. can examine range parameter values implied prior distributions summary() method: Fitting model nma() function. increase target acceptance rate adapt_delta = 0.99 minimise divergent transition warnings. Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  can compute relative effects placebo/standard care relative_effects() function trt_ref argument: estimates can easily plotted plot() method:  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. af_fit_1 <- nma(af_net,                  trt_effects = \"random\",                 prior_intercept = normal(scale = 100),                 prior_trt = normal(scale = 100),                 prior_het = half_normal(scale = 5),                 adapt_delta = 0.99) #> Note: Setting \"Standard adjusted dose anti-coagulant\" as the network reference treatment. af_fit_1 #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=5000; warmup=2500; thin=1;  #> post-warmup draws per chain=2500, total post-warmup draws=10000. #>  #>                                                  mean se_mean   sd     2.5%      25%      50% #> d[Acenocoumarol]                                -0.80    0.01 0.83    -2.51    -1.33    -0.78 #> d[Alternate day aspirin]                        -1.01    0.01 1.37    -4.16    -1.80    -0.84 #> d[Dipyridamole]                                  0.60    0.01 0.45    -0.29     0.31     0.60 #> d[Fixed dose warfarin]                           0.92    0.00 0.41     0.12     0.65     0.92 #> d[Fixed dose warfarin + low dose aspirin]        0.47    0.01 0.44    -0.38     0.19     0.47 #> d[Fixed dose warfarin + medium dose aspirin]     0.89    0.00 0.32     0.24     0.69     0.89 #> d[High dose aspirin]                             0.51    0.01 0.77    -1.03     0.00     0.51 #> d[Indobufen]                                     0.25    0.00 0.45    -0.64    -0.04     0.24 #> d[Low adjusted dose anti-coagulant]             -0.29    0.00 0.39    -1.07    -0.55    -0.29 #> d[Low dose aspirin]                              0.62    0.00 0.22     0.18     0.48     0.62 #> d[Low dose aspirin + copidogrel]                 0.52    0.00 0.34    -0.18     0.32     0.52 #> d[Low dose aspirin + dipyridamole]               0.27    0.01 0.47    -0.67    -0.03     0.28 #> d[Medium dose aspirin]                           0.39    0.00 0.20    -0.01     0.26     0.39 #> d[Placebo/Standard care]                         0.76    0.00 0.20     0.36     0.63     0.76 #> d[Triflusal]                                     0.65    0.01 0.62    -0.55     0.23     0.63 #> d[Ximelagatran]                                 -0.08    0.00 0.26    -0.61    -0.24    -0.09 #> lp__                                         -4771.87    0.15 7.36 -4787.37 -4776.57 -4771.51 #> tau                                              0.28    0.00 0.14     0.03     0.18     0.27 #>                                                   75%    97.5% n_eff Rhat #> d[Acenocoumarol]                                -0.24     0.76  9712    1 #> d[Alternate day aspirin]                        -0.06     1.23  9231    1 #> d[Dipyridamole]                                  0.90     1.48  7697    1 #> d[Fixed dose warfarin]                           1.19     1.73  9935    1 #> d[Fixed dose warfarin + low dose aspirin]        0.75     1.36  6755    1 #> d[Fixed dose warfarin + medium dose aspirin]     1.09     1.50  8929    1 #> d[High dose aspirin]                             1.03     2.00 10861    1 #> d[Indobufen]                                     0.53     1.17 10530    1 #> d[Low adjusted dose anti-coagulant]             -0.03     0.45  6829    1 #> d[Low dose aspirin]                              0.76     1.05  4785    1 #> d[Low dose aspirin + copidogrel]                 0.72     1.22  9360    1 #> d[Low dose aspirin + dipyridamole]               0.58     1.18  7572    1 #> d[Medium dose aspirin]                           0.51     0.76  6297    1 #> d[Placebo/Standard care]                         0.89     1.16  3686    1 #> d[Triflusal]                                     1.03     1.93  9732    1 #> d[Ximelagatran]                                  0.08     0.44  8345    1 #> lp__                                         -4766.76 -4758.57  2386    1 #> tau                                              0.36     0.57  1635    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:34:03 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(af_fit_1, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(af_fit_1, prior = c(\"trt\", \"het\")) (af_1_releff <- relative_effects(af_fit_1, trt_ref = \"Placebo/Standard care\")) #>                                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> d[Standard adjusted dose anti-coagulant]     -0.76 0.20 -1.16 -0.89 -0.76 -0.63 -0.36     3734 #> d[Acenocoumarol]                             -1.56 0.85 -3.34 -2.11 -1.52 -0.98  0.05     8970 #> d[Alternate day aspirin]                     -1.77 1.36 -4.87 -2.55 -1.59 -0.83  0.43    12129 #> d[Dipyridamole]                              -0.16 0.42 -0.98 -0.43 -0.16  0.11  0.66    12931 #> d[Fixed dose warfarin]                        0.16 0.44 -0.72 -0.13  0.16  0.46  1.01     9337 #> d[Fixed dose warfarin + low dose aspirin]    -0.28 0.39 -1.04 -0.53 -0.29 -0.05  0.52    10845 #> d[Fixed dose warfarin + medium dose aspirin]  0.13 0.37 -0.61 -0.10  0.13  0.37  0.84     8027 #> d[High dose aspirin]                         -0.25 0.76 -1.77 -0.75 -0.23  0.26  1.21    13112 #> d[Indobufen]                                 -0.51 0.50 -1.49 -0.83 -0.51 -0.20  0.50     8713 #> d[Low adjusted dose anti-coagulant]          -1.05 0.36 -1.75 -1.29 -1.05 -0.81 -0.36    12008 #> d[Low dose aspirin]                          -0.14 0.21 -0.56 -0.28 -0.14  0.00  0.27    11427 #> d[Low dose aspirin + copidogrel]             -0.24 0.40 -1.02 -0.48 -0.24  0.01  0.56     7779 #> d[Low dose aspirin + dipyridamole]           -0.49 0.44 -1.37 -0.78 -0.48 -0.20  0.38    12769 #> d[Medium dose aspirin]                       -0.37 0.22 -0.83 -0.51 -0.37 -0.22  0.06     7332 #> d[Triflusal]                                 -0.11 0.65 -1.36 -0.53 -0.13  0.30  1.23     8877 #> d[Ximelagatran]                              -0.84 0.33 -1.51 -1.05 -0.84 -0.63 -0.17     5984 #>                                              Tail_ESS Rhat #> d[Standard adjusted dose anti-coagulant]         5157    1 #> d[Acenocoumarol]                                 7713    1 #> d[Alternate day aspirin]                         5983    1 #> d[Dipyridamole]                                  8392    1 #> d[Fixed dose warfarin]                           7488    1 #> d[Fixed dose warfarin + low dose aspirin]        6624    1 #> d[Fixed dose warfarin + medium dose aspirin]     7303    1 #> d[High dose aspirin]                             7638    1 #> d[Indobufen]                                     6308    1 #> d[Low adjusted dose anti-coagulant]              7892    1 #> d[Low dose aspirin]                              7842    1 #> d[Low dose aspirin + copidogrel]                 6117    1 #> d[Low dose aspirin + dipyridamole]               7664    1 #> d[Medium dose aspirin]                           6125    1 #> d[Triflusal]                                     7347    1 #> d[Ximelagatran]                                  6402    1 plot(af_1_releff, ref_line = 0) (af_1_ranks <- posterior_ranks(af_fit_1)) #>                                                  mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS #> rank[Standard adjusted dose anti-coagulant]      5.30 1.42    3   4   5   6     8     6202 #> rank[Acenocoumarol]                              3.00 3.07    1   1   2   3    13     8574 #> rank[Alternate day aspirin]                      3.68 4.23    1   1   2   4    16    13825 #> rank[Dipyridamole]                              11.35 3.78    4   9  12  15    17    10602 #> rank[Fixed dose warfarin]                       14.04 3.06    6  12  15  16    17     9949 #> rank[Fixed dose warfarin + low dose aspirin]    10.07 3.81    3   7  10  13    17     9910 #> rank[Fixed dose warfarin + medium dose aspirin] 14.08 2.66    8  13  15  16    17     7039 #> rank[High dose aspirin]                         10.26 5.29    2   5  11  16    17    12576 #> rank[Indobufen]                                  8.05 3.97    2   5   8  11    16     9911 #> rank[Low adjusted dose anti-coagulant]           3.78 2.23    1   2   3   5    10     8209 #> rank[Low dose aspirin]                          11.75 2.25    7  10  12  13    16    10118 #> rank[Low dose aspirin + copidogrel]             10.61 3.41    4   8  11  13    17     8718 #> rank[Low dose aspirin + dipyridamole]            8.21 3.89    2   5   8  11    16    11047 #> rank[Medium dose aspirin]                        9.14 2.13    5   8   9  11    13     9845 #> rank[Placebo/Standard care]                     13.43 1.82   10  12  14  15    17     8570 #> rank[Triflusal]                                 11.38 4.57    3   8  12  16    17     9654 #> rank[Ximelagatran]                               4.88 2.30    2   3   4   6    10     7255 #>                                                 Tail_ESS Rhat #> rank[Standard adjusted dose anti-coagulant]         6592    1 #> rank[Acenocoumarol]                                 7538    1 #> rank[Alternate day aspirin]                         9660    1 #> rank[Dipyridamole]                                    NA    1 #> rank[Fixed dose warfarin]                             NA    1 #> rank[Fixed dose warfarin + low dose aspirin]        7061    1 #> rank[Fixed dose warfarin + medium dose aspirin]       NA    1 #> rank[High dose aspirin]                               NA    1 #> rank[Indobufen]                                     6530    1 #> rank[Low adjusted dose anti-coagulant]              8350    1 #> rank[Low dose aspirin]                              8330    1 #> rank[Low dose aspirin + copidogrel]                 6730    1 #> rank[Low dose aspirin + dipyridamole]               8156    1 #> rank[Medium dose aspirin]                           9091    1 #> rank[Placebo/Standard care]                         7856    1 #> rank[Triflusal]                                       NA    1 #> rank[Ximelagatran]                                  6411    1 plot(af_1_ranks) (af_1_rankprobs <- posterior_rank_probs(af_fit_1)) #>                                              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[Standard adjusted dose anti-coagulant]          0.00      0.01      0.08      0.20      0.28 #> d[Acenocoumarol]                                  0.38      0.29      0.10      0.05      0.03 #> d[Alternate day aspirin]                          0.47      0.17      0.07      0.04      0.03 #> d[Dipyridamole]                                   0.00      0.01      0.02      0.02      0.03 #> d[Fixed dose warfarin]                            0.00      0.00      0.00      0.00      0.01 #> d[Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.03      0.04      0.05 #> d[Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00      0.00      0.00 #> d[High dose aspirin]                              0.02      0.06      0.06      0.06      0.04 #> d[Indobufen]                                      0.01      0.04      0.07      0.08      0.09 #> d[Low adjusted dose anti-coagulant]               0.08      0.23      0.26      0.15      0.09 #> d[Low dose aspirin]                               0.00      0.00      0.00      0.00      0.00 #> d[Low dose aspirin + copidogrel]                  0.00      0.01      0.01      0.02      0.03 #> d[Low dose aspirin + dipyridamole]                0.01      0.04      0.07      0.08      0.08 #> d[Medium dose aspirin]                            0.00      0.00      0.00      0.01      0.02 #> d[Placebo/Standard care]                          0.00      0.00      0.00      0.00      0.00 #> d[Triflusal]                                      0.00      0.02      0.04      0.04      0.04 #> d[Ximelagatran]                                   0.02      0.10      0.18      0.21      0.17 #>                                              p_rank[6] p_rank[7] p_rank[8] p_rank[9] #> d[Standard adjusted dose anti-coagulant]          0.23      0.12      0.05      0.01 #> d[Acenocoumarol]                                  0.03      0.02      0.02      0.02 #> d[Alternate day aspirin]                          0.03      0.03      0.02      0.02 #> d[Dipyridamole]                                   0.04      0.06      0.07      0.08 #> d[Fixed dose warfarin]                            0.01      0.02      0.03      0.04 #> d[Fixed dose warfarin + low dose aspirin]         0.06      0.08      0.10      0.09 #> d[Fixed dose warfarin + medium dose aspirin]      0.01      0.01      0.02      0.03 #> d[High dose aspirin]                              0.05      0.05      0.05      0.05 #> d[Indobufen]                                      0.10      0.10      0.10      0.08 #> d[Low adjusted dose anti-coagulant]               0.07      0.04      0.03      0.02 #> d[Low dose aspirin]                               0.01      0.02      0.04      0.09 #> d[Low dose aspirin + copidogrel]                  0.05      0.08      0.10      0.10 #> d[Low dose aspirin + dipyridamole]                0.09      0.10      0.09      0.08 #> d[Medium dose aspirin]                            0.06      0.12      0.17      0.19 #> d[Placebo/Standard care]                          0.00      0.00      0.01      0.01 #> d[Triflusal]                                      0.05      0.06      0.06      0.06 #> d[Ximelagatran]                                   0.12      0.09      0.05      0.03 #>                                              p_rank[10] p_rank[11] p_rank[12] p_rank[13] #> d[Standard adjusted dose anti-coagulant]           0.00       0.00       0.00       0.00 #> d[Acenocoumarol]                                   0.01       0.01       0.01       0.01 #> d[Alternate day aspirin]                           0.02       0.01       0.01       0.01 #> d[Dipyridamole]                                    0.08       0.08       0.08       0.08 #> d[Fixed dose warfarin]                             0.04       0.05       0.06       0.07 #> d[Fixed dose warfarin + low dose aspirin]          0.09       0.08       0.08       0.07 #> d[Fixed dose warfarin + medium dose aspirin]       0.04       0.06       0.07       0.09 #> d[High dose aspirin]                               0.05       0.04       0.05       0.04 #> d[Indobufen]                                       0.07       0.05       0.05       0.04 #> d[Low adjusted dose anti-coagulant]                0.01       0.01       0.00       0.00 #> d[Low dose aspirin]                                0.13       0.16       0.17       0.15 #> d[Low dose aspirin + copidogrel]                   0.10       0.10       0.09       0.08 #> d[Low dose aspirin + dipyridamole]                 0.08       0.07       0.05       0.04 #> d[Medium dose aspirin]                             0.16       0.12       0.07       0.04 #> d[Placebo/Standard care]                           0.04       0.08       0.14       0.20 #> d[Triflusal]                                       0.06       0.06       0.06       0.05 #> d[Ximelagatran]                                    0.02       0.01       0.01       0.00 #>                                              p_rank[14] p_rank[15] p_rank[16] p_rank[17] #> d[Standard adjusted dose anti-coagulant]           0.00       0.00       0.00       0.00 #> d[Acenocoumarol]                                   0.01       0.01       0.01       0.00 #> d[Alternate day aspirin]                           0.01       0.01       0.02       0.02 #> d[Dipyridamole]                                    0.09       0.09       0.09       0.08 #> d[Fixed dose warfarin]                             0.09       0.14       0.20       0.24 #> d[Fixed dose warfarin + low dose aspirin]          0.07       0.06       0.05       0.04 #> d[Fixed dose warfarin + medium dose aspirin]       0.12       0.17       0.22       0.17 #> d[High dose aspirin]                               0.05       0.07       0.08       0.17 #> d[Indobufen]                                       0.04       0.03       0.03       0.02 #> d[Low adjusted dose anti-coagulant]                0.00       0.00       0.00       0.00 #> d[Low dose aspirin]                                0.12       0.07       0.03       0.01 #> d[Low dose aspirin + copidogrel]                   0.08       0.07       0.05       0.03 #> d[Low dose aspirin + dipyridamole]                 0.04       0.03       0.03       0.02 #> d[Medium dose aspirin]                             0.02       0.01       0.00       0.00 #> d[Placebo/Standard care]                           0.22       0.17       0.10       0.03 #> d[Triflusal]                                       0.06       0.08       0.10       0.17 #> d[Ximelagatran]                                    0.00       0.00       0.00       0.00 plot(af_1_rankprobs) (af_1_cumrankprobs <- posterior_rank_probs(af_fit_1, cumulative = TRUE)) #>                                              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[Standard adjusted dose anti-coagulant]          0.00      0.01      0.09      0.29      0.58 #> d[Acenocoumarol]                                  0.38      0.67      0.77      0.82      0.85 #> d[Alternate day aspirin]                          0.47      0.64      0.71      0.75      0.79 #> d[Dipyridamole]                                   0.00      0.01      0.02      0.05      0.07 #> d[Fixed dose warfarin]                            0.00      0.00      0.00      0.01      0.01 #> d[Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.04      0.08      0.13 #> d[Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00      0.00      0.01 #> d[High dose aspirin]                              0.02      0.09      0.15      0.21      0.25 #> d[Indobufen]                                      0.01      0.06      0.13      0.21      0.30 #> d[Low adjusted dose anti-coagulant]               0.08      0.31      0.58      0.72      0.82 #> d[Low dose aspirin]                               0.00      0.00      0.00      0.00      0.00 #> d[Low dose aspirin + copidogrel]                  0.00      0.01      0.02      0.04      0.07 #> d[Low dose aspirin + dipyridamole]                0.01      0.05      0.12      0.20      0.28 #> d[Medium dose aspirin]                            0.00      0.00      0.00      0.01      0.04 #> d[Placebo/Standard care]                          0.00      0.00      0.00      0.00      0.00 #> d[Triflusal]                                      0.00      0.02      0.06      0.10      0.14 #> d[Ximelagatran]                                   0.02      0.12      0.30      0.51      0.67 #>                                              p_rank[6] p_rank[7] p_rank[8] p_rank[9] #> d[Standard adjusted dose anti-coagulant]          0.81      0.94      0.98      1.00 #> d[Acenocoumarol]                                  0.88      0.91      0.93      0.94 #> d[Alternate day aspirin]                          0.82      0.84      0.86      0.88 #> d[Dipyridamole]                                   0.12      0.18      0.25      0.33 #> d[Fixed dose warfarin]                            0.03      0.04      0.07      0.11 #> d[Fixed dose warfarin + low dose aspirin]         0.19      0.27      0.37      0.46 #> d[Fixed dose warfarin + medium dose aspirin]      0.01      0.02      0.04      0.07 #> d[High dose aspirin]                              0.30      0.35      0.40      0.45 #> d[Indobufen]                                      0.40      0.49      0.59      0.67 #> d[Low adjusted dose anti-coagulant]               0.88      0.93      0.96      0.97 #> d[Low dose aspirin]                               0.01      0.03      0.07      0.16 #> d[Low dose aspirin + copidogrel]                  0.12      0.19      0.29      0.39 #> d[Low dose aspirin + dipyridamole]                0.37      0.47      0.56      0.64 #> d[Medium dose aspirin]                            0.10      0.22      0.39      0.58 #> d[Placebo/Standard care]                          0.00      0.00      0.01      0.02 #> d[Triflusal]                                      0.18      0.24      0.30      0.36 #> d[Ximelagatran]                                   0.79      0.88      0.93      0.96 #>                                              p_rank[10] p_rank[11] p_rank[12] p_rank[13] #> d[Standard adjusted dose anti-coagulant]           1.00       1.00       1.00       1.00 #> d[Acenocoumarol]                                   0.95       0.96       0.97       0.98 #> d[Alternate day aspirin]                           0.90       0.91       0.92       0.94 #> d[Dipyridamole]                                    0.41       0.49       0.58       0.66 #> d[Fixed dose warfarin]                             0.15       0.20       0.26       0.33 #> d[Fixed dose warfarin + low dose aspirin]          0.55       0.63       0.71       0.78 #> d[Fixed dose warfarin + medium dose aspirin]       0.12       0.17       0.24       0.33 #> d[High dose aspirin]                               0.50       0.54       0.59       0.63 #> d[Indobufen]                                       0.73       0.79       0.84       0.88 #> d[Low adjusted dose anti-coagulant]                0.98       0.99       0.99       1.00 #> d[Low dose aspirin]                                0.29       0.45       0.62       0.77 #> d[Low dose aspirin + copidogrel]                   0.50       0.59       0.68       0.77 #> d[Low dose aspirin + dipyridamole]                 0.72       0.79       0.84       0.88 #> d[Medium dose aspirin]                             0.75       0.86       0.94       0.98 #> d[Placebo/Standard care]                           0.06       0.14       0.29       0.49 #> d[Triflusal]                                       0.42       0.48       0.54       0.59 #> d[Ximelagatran]                                    0.98       0.99       0.99       1.00 #>                                              p_rank[14] p_rank[15] p_rank[16] p_rank[17] #> d[Standard adjusted dose anti-coagulant]           1.00       1.00       1.00          1 #> d[Acenocoumarol]                                   0.98       0.99       1.00          1 #> d[Alternate day aspirin]                           0.95       0.96       0.98          1 #> d[Dipyridamole]                                    0.75       0.83       0.92          1 #> d[Fixed dose warfarin]                             0.42       0.56       0.76          1 #> d[Fixed dose warfarin + low dose aspirin]          0.85       0.91       0.96          1 #> d[Fixed dose warfarin + medium dose aspirin]       0.44       0.62       0.83          1 #> d[High dose aspirin]                               0.68       0.75       0.83          1 #> d[Indobufen]                                       0.92       0.95       0.98          1 #> d[Low adjusted dose anti-coagulant]                1.00       1.00       1.00          1 #> d[Low dose aspirin]                                0.89       0.96       0.99          1 #> d[Low dose aspirin + copidogrel]                   0.85       0.92       0.97          1 #> d[Low dose aspirin + dipyridamole]                 0.92       0.95       0.98          1 #> d[Medium dose aspirin]                             0.99       1.00       1.00          1 #> d[Placebo/Standard care]                           0.71       0.88       0.97          1 #> d[Triflusal]                                       0.65       0.73       0.83          1 #> d[Ximelagatran]                                    1.00       1.00       1.00          1 plot(af_1_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"network-meta-regression-adjusting-for-proportion-of-prior-stroke","dir":"Articles","previous_headings":"Meta-analysis models","what":"Network meta-regression adjusting for proportion of prior stroke","title":"Example: Atrial fibrillation","text":"now consider meta-regression model adjusting proportion individuals study prior stroke, shared interaction coefficients treatment class. regression model specified nma() function using formula regression argument. formula ~ .trt:stroke means interactions prior stroke treatment included; .trt special variable indicates treatment, stroke original data set. specify class_interactions = \"common\" denote interaction parameters common (.e. shared) treatments within class. (Setting class_interactions = \"independent\" fit model 2 Cooper et al. (2009) separate interactions treatment, data permitting.) use prior distributions , additionally require prior distribution regression coefficients prior_reg; use N(0,1002)\\mathrm{N}(0, 100^2) prior distribution. QR decomposition can greatly improve efficiency sampling regression models decorrelating sampling space; specify used QR = TRUE, increase target acceptance rate adapt_delta = 0.99 minimise divergent transition warnings. Basic parameter summaries given print() method: estimated treatment effects d[] shown correspond relative effects reference level covariate, proportion prior stroke centered network mean value 0.296. default, summaries study-specific intercepts μj\\mu_j study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  can compute relative effects placebo/standard care relative_effects() function trt_ref argument, default produces relative effects observed proportions prior stroke study: can produce estimated treatment effects particular covariate values using newdata argument. example, treatment effects individuals individuals prior stroke produced  estimated class interactions (reference “Mixed” class) uncertain.  interactions straightforward interpret transform interaction coefficients (using consistency equations) control class:  evidence effect anti-coagulants increases (compared control) prior stroke. little evidence effect anti-platelets reduces prior stroke, although point estimate represents substantial reduction effectiveness, 95% Credible Interval includes values correspond substantial increases treatment effect. interaction effect stroke mixed treatments uncertain, potentially indicates substantial reduction treatment effects prior stroke. can also produce treatment rankings, rank probabilities, cumulative rank probabilities. default (without newdata argument specified), produced value stroke study network turn. instead produce rankings individuals individuals prior stroke, specify newdata argument.","code":"af_fit_4b <- nma(af_net,                   trt_effects = \"random\",                  regression = ~ .trt:stroke,                  class_interactions = \"common\",                  QR = TRUE,                  prior_intercept = normal(scale = 100),                  prior_trt = normal(scale = 100),                  prior_reg = normal(scale = 100),                  prior_het = half_normal(scale = 5),                  adapt_delta = 0.99) #> Note: Setting \"Standard adjusted dose anti-coagulant\" as the network reference treatment. #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess af_fit_4b #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:stroke. #> Centred covariates at the following overall mean values: #>    stroke  #> 0.2957377  #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                  mean se_mean   sd     2.5%      25%      50% #> beta[.trtclassControl:stroke]                    0.70    0.01 0.45    -0.18     0.40     0.69 #> beta[.trtclassAnti-platelet:stroke]              0.94    0.01 0.43     0.11     0.67     0.93 #> beta[.trtclassMixed:stroke]                      3.96    0.03 2.12    -0.14     2.53     3.93 #> d[Acenocoumarol]                                 0.38    0.02 1.02    -1.67    -0.27     0.41 #> d[Alternate day aspirin]                        -0.93    0.03 1.46    -4.45    -1.71    -0.74 #> d[Dipyridamole]                                  0.57    0.01 0.41    -0.26     0.31     0.57 #> d[Fixed dose warfarin]                           0.64    0.01 0.38    -0.12     0.38     0.63 #> d[Fixed dose warfarin + low dose aspirin]        1.47    0.01 0.74     0.02     1.00     1.46 #> d[Fixed dose warfarin + medium dose aspirin]     1.00    0.00 0.30     0.42     0.81     1.00 #> d[High dose aspirin]                             0.42    0.01 0.74    -1.06    -0.06     0.43 #> d[Indobufen]                                    -0.42    0.01 0.49    -1.40    -0.73    -0.41 #> d[Low adjusted dose anti-coagulant]             -0.43    0.01 0.37    -1.17    -0.68    -0.42 #> d[Low dose aspirin]                              0.71    0.00 0.20     0.30     0.59     0.72 #> d[Low dose aspirin + copidogrel]                 0.65    0.01 0.30     0.06     0.48     0.66 #> d[Low dose aspirin + dipyridamole]               0.25    0.01 0.42    -0.60    -0.04     0.25 #> d[Medium dose aspirin]                           0.35    0.00 0.17     0.00     0.23     0.35 #> d[Placebo/Standard care]                         0.79    0.00 0.19     0.43     0.67     0.79 #> d[Triflusal]                                     0.92    0.01 0.60    -0.28     0.53     0.91 #> d[Ximelagatran]                                 -0.08    0.00 0.22    -0.51    -0.21    -0.08 #> lp__                                         -4771.33    0.21 7.21 -4785.67 -4776.02 -4771.02 #> tau                                              0.19    0.01 0.13     0.01     0.08     0.17 #>                                                   75%    97.5% n_eff Rhat #> beta[.trtclassControl:stroke]                    0.99     1.60  4544 1.00 #> beta[.trtclassAnti-platelet:stroke]              1.21     1.79  4066 1.00 #> beta[.trtclassMixed:stroke]                      5.38     8.24  4887 1.00 #> d[Acenocoumarol]                                 1.08     2.36  3927 1.00 #> d[Alternate day aspirin]                         0.06     1.38  1921 1.00 #> d[Dipyridamole]                                  0.84     1.36  5132 1.00 #> d[Fixed dose warfarin]                           0.89     1.42  4316 1.00 #> d[Fixed dose warfarin + low dose aspirin]        1.94     2.94  5436 1.00 #> d[Fixed dose warfarin + medium dose aspirin]     1.19     1.60  5160 1.00 #> d[High dose aspirin]                             0.93     1.82  5967 1.00 #> d[Indobufen]                                    -0.09     0.55  4083 1.00 #> d[Low adjusted dose anti-coagulant]             -0.18     0.29  4316 1.00 #> d[Low dose aspirin]                              0.84     1.11  4992 1.00 #> d[Low dose aspirin + copidogrel]                 0.83     1.23  3037 1.00 #> d[Low dose aspirin + dipyridamole]               0.53     1.06  5102 1.00 #> d[Medium dose aspirin]                           0.46     0.69  4904 1.00 #> d[Placebo/Standard care]                         0.91     1.16  5042 1.00 #> d[Triflusal]                                     1.31     2.10  4716 1.00 #> d[Ximelagatran]                                  0.05     0.38  2878 1.00 #> lp__                                         -4766.36 -4758.07  1138 1.00 #> tau                                              0.26     0.50   330 1.02 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:34:15 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(af_fit_4b, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(af_fit_4b, prior = c(\"reg\", \"het\")) # Not run (af_4b_releff <- relative_effects(af_fit_4b, trt_ref = \"Placebo/Standard care\")) plot(af_4b_releff, ref_line = 0) (af_4b_releff_01 <- relative_effects(af_fit_4b,                                       trt_ref = \"Placebo/Standard care\",                                      newdata = data.frame(stroke = c(0, 1),                                                            label = c(\"stroke = 0\", \"stroke = 1\")),                                      study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                           mean   sd  2.5%   25%   50%   75% #> d[stroke = 0: Standard adjusted dose anti-coagulant]     -0.58 0.24 -1.07 -0.74 -0.58 -0.42 #> d[stroke = 0: Acenocoumarol]                             -1.37 0.84 -3.14 -1.90 -1.34 -0.83 #> d[stroke = 0: Alternate day aspirin]                     -1.79 1.44 -5.28 -2.55 -1.58 -0.82 #> d[stroke = 0: Dipyridamole]                              -0.29 0.45 -1.18 -0.59 -0.29  0.00 #> d[stroke = 0: Fixed dose warfarin]                        0.05 0.44 -0.78 -0.24  0.04  0.35 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]    -0.29 0.34 -0.96 -0.50 -0.28 -0.07 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin] -0.75 0.64 -2.02 -1.17 -0.75 -0.33 #> d[stroke = 0: High dose aspirin]                         -0.44 0.78 -1.96 -0.94 -0.43  0.07 #> d[stroke = 0: Indobufen]                                 -1.28 0.58 -2.45 -1.63 -1.27 -0.91 #> d[stroke = 0: Low adjusted dose anti-coagulant]          -1.01 0.33 -1.68 -1.23 -1.00 -0.78 #> d[stroke = 0: Low dose aspirin]                          -0.15 0.23 -0.60 -0.29 -0.15  0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]             -0.21 0.36 -0.94 -0.42 -0.20  0.01 #> d[stroke = 0: Low dose aspirin + dipyridamole]           -0.61 0.46 -1.52 -0.92 -0.61 -0.31 #> d[stroke = 0: Medium dose aspirin]                       -0.51 0.27 -1.05 -0.69 -0.51 -0.34 #> d[stroke = 0: Triflusal]                                  0.06 0.63 -1.18 -0.35  0.05  0.47 #> d[stroke = 0: Ximelagatran]                              -0.66 0.32 -1.28 -0.86 -0.66 -0.46 #>                                                          97.5% Bulk_ESS Tail_ESS Rhat #> d[stroke = 0: Standard adjusted dose anti-coagulant]     -0.10     4961     2951    1 #> d[stroke = 0: Acenocoumarol]                              0.19     4136     2471    1 #> d[stroke = 0: Alternate day aspirin]                      0.49     2761     1489    1 #> d[stroke = 0: Dipyridamole]                               0.57     5029     2923    1 #> d[stroke = 0: Fixed dose warfarin]                        0.94     5014     3242    1 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]     0.35     5277     2501    1 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]  0.50     4419     2761    1 #> d[stroke = 0: High dose aspirin]                          1.05     5582     3104    1 #> d[stroke = 0: Indobufen]                                 -0.13     4243     2945    1 #> d[stroke = 0: Low adjusted dose anti-coagulant]          -0.37     4771     2960    1 #> d[stroke = 0: Low dose aspirin]                           0.30     4967     2971    1 #> d[stroke = 0: Low dose aspirin + copidogrel]              0.50     3991     1975    1 #> d[stroke = 0: Low dose aspirin + dipyridamole]            0.27     5123     2683    1 #> d[stroke = 0: Medium dose aspirin]                        0.01     4909     2949    1 #> d[stroke = 0: Triflusal]                                  1.32     5343     2752    1 #> d[stroke = 0: Ximelagatran]                               0.00     3474     2568    1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                           mean   sd  2.5%   25%   50%   75% #> d[stroke = 1: Standard adjusted dose anti-coagulant]     -1.28 0.36 -2.00 -1.52 -1.27 -1.05 #> d[stroke = 1: Acenocoumarol]                              1.89 2.30 -2.63  0.33  1.88  3.39 #> d[stroke = 1: Alternate day aspirin]                     -1.56 1.49 -5.06 -2.36 -1.36 -0.54 #> d[stroke = 1: Dipyridamole]                              -0.06 0.38 -0.82 -0.31 -0.05  0.20 #> d[stroke = 1: Fixed dose warfarin]                       -0.65 0.53 -1.70 -1.01 -0.65 -0.31 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]     2.97 2.17 -1.23  1.54  2.93  4.37 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]  2.51 1.64 -0.73  1.41  2.47  3.57 #> d[stroke = 1: High dose aspirin]                         -0.20 0.72 -1.64 -0.66 -0.21  0.28 #> d[stroke = 1: Indobufen]                                 -1.04 0.53 -2.09 -1.38 -1.04 -0.69 #> d[stroke = 1: Low adjusted dose anti-coagulant]          -1.71 0.52 -2.76 -2.07 -1.70 -1.36 #> d[stroke = 1: Low dose aspirin]                           0.09 0.29 -0.50 -0.09  0.10  0.28 #> d[stroke = 1: Low dose aspirin + copidogrel]              0.03 0.39 -0.76 -0.20  0.03  0.27 #> d[stroke = 1: Low dose aspirin + dipyridamole]           -0.38 0.41 -1.18 -0.65 -0.36 -0.10 #> d[stroke = 1: Medium dose aspirin]                       -0.28 0.25 -0.80 -0.42 -0.27 -0.12 #> d[stroke = 1: Triflusal]                                  0.30 0.66 -1.05 -0.12  0.29  0.73 #> d[stroke = 1: Ximelagatran]                              -1.36 0.42 -2.18 -1.62 -1.35 -1.09 #>                                                          97.5% Bulk_ESS Tail_ESS Rhat #> d[stroke = 1: Standard adjusted dose anti-coagulant]     -0.59     4678     2880 1.00 #> d[stroke = 1: Acenocoumarol]                              6.40     4773     2853 1.00 #> d[stroke = 1: Alternate day aspirin]                      0.84     2796     1507 1.00 #> d[stroke = 1: Dipyridamole]                               0.70     5281     2735 1.00 #> d[stroke = 1: Fixed dose warfarin]                        0.42     3967     3029 1.00 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]     7.38     5166     2866 1.00 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]  5.82     5201     3085 1.00 #> d[stroke = 1: High dose aspirin]                          1.22     5824     3250 1.00 #> d[stroke = 1: Indobufen]                                  0.00     4470     2866 1.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]          -0.70     4333     2847 1.00 #> d[stroke = 1: Low dose aspirin]                           0.65     4829     2338 1.00 #> d[stroke = 1: Low dose aspirin + copidogrel]              0.79     3764     2440 1.00 #> d[stroke = 1: Low dose aspirin + dipyridamole]            0.41     5452     3293 1.00 #> d[stroke = 1: Medium dose aspirin]                        0.21     4399     2268 1.01 #> d[stroke = 1: Triflusal]                                  1.58     4603     2921 1.00 #> d[stroke = 1: Ximelagatran]                              -0.55     4235     2734 1.00 plot(af_4b_releff_01, ref_line = 0) plot(af_fit_4b, pars = \"beta\", stat = \"halfeye\", ref_line = 0) af_4b_beta <- as.array(af_fit_4b, pars = \"beta\")  # Subtract beta[Control:stroke] from the other class interactions af_4b_beta[ , , 2:3] <- sweep(af_4b_beta[ , , 2:3], 1:2,                                af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"], FUN = \"-\")  # Set beta[Anti-coagulant:stroke] = -beta[Control:stroke] af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"] <- -af_4b_beta[ , , \"beta[.trtclassControl:stroke]\"] names(af_4b_beta)[1] <- \"beta[.trtclassAnti-coagulant:stroke]\"  # Summarise summary(af_4b_beta) #>                                       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> beta[.trtclassAnti-coagulant:stroke] -0.70 0.45 -1.60 -0.99 -0.69 -0.40  0.18     4527 #> beta[.trtclassAnti-platelet:stroke]   0.24 0.34 -0.44  0.02  0.24  0.46  0.92     4498 #> beta[.trtclassMixed:stroke]           3.26 2.14 -0.85  1.81  3.24  4.67  7.62     4973 #>                                      Tail_ESS Rhat #> beta[.trtclassAnti-coagulant:stroke]     2957 1.01 #> beta[.trtclassAnti-platelet:stroke]      2766 1.00 #> beta[.trtclassMixed:stroke]              2927 1.00 plot(summary(af_4b_beta), stat = \"halfeye\", ref_line = 0) (af_4b_ranks <- posterior_ranks(af_fit_4b,                                 newdata = data.frame(stroke = c(0, 1),                                                       label = c(\"stroke = 0\", \"stroke = 1\")),                                  study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                              mean   sd 2.5% 25% 50% 75% 97.5% #> rank[stroke = 0: Standard adjusted dose anti-coagulant]      7.74 1.89    4   6   8   9    12 #> rank[stroke = 0: Acenocoumarol]                              4.02 3.72    1   1   3   5    15 #> rank[stroke = 0: Alternate day aspirin]                      4.06 4.52    1   1   2   5    17 #> rank[stroke = 0: Dipyridamole]                              11.04 3.75    4   8  11  14    17 #> rank[stroke = 0: Fixed dose warfarin]                       14.07 2.89    7  12  15  16    17 #> rank[stroke = 0: Fixed dose warfarin + low dose aspirin]    11.06 3.66    4   8  11  14    17 #> rank[stroke = 0: Fixed dose warfarin + medium dose aspirin]  7.06 4.42    1   3   6  10    16 #> rank[stroke = 0: High dose aspirin]                          9.63 5.25    1   5  10  15    17 #> rank[stroke = 0: Indobufen]                                  3.65 2.81    1   2   3   4    12 #> rank[stroke = 0: Low adjusted dose anti-coagulant]           4.52 2.46    1   3   4   6    11 #> rank[stroke = 0: Low dose aspirin]                          12.88 1.97    9  12  13  14    16 #> rank[stroke = 0: Low dose aspirin + copidogrel]             12.08 2.92    5  10  12  14    17 #> rank[stroke = 0: Low dose aspirin + dipyridamole]            7.82 3.68    2   5   7  10    16 #> rank[stroke = 0: Medium dose aspirin]                        8.59 2.23    4   7   9  10    13 #> rank[stroke = 0: Placebo/Standard care]                     14.31 1.94   10  13  15  16    17 #> rank[stroke = 0: Triflusal]                                 13.46 3.97    4  11  15  17    17 #> rank[stroke = 0: Ximelagatran]                               7.01 2.64    3   5   7   9    13 #>                                                             Bulk_ESS Tail_ESS Rhat #> rank[stroke = 0: Standard adjusted dose anti-coagulant]         3854     2898    1 #> rank[stroke = 0: Acenocoumarol]                                 4346     3030    1 #> rank[stroke = 0: Alternate day aspirin]                         4678     3002    1 #> rank[stroke = 0: Dipyridamole]                                  4871       NA    1 #> rank[stroke = 0: Fixed dose warfarin]                           4637       NA    1 #> rank[stroke = 0: Fixed dose warfarin + low dose aspirin]        5615       NA    1 #> rank[stroke = 0: Fixed dose warfarin + medium dose aspirin]     4750     3276    1 #> rank[stroke = 0: High dose aspirin]                             5114       NA    1 #> rank[stroke = 0: Indobufen]                                     3557     3054    1 #> rank[stroke = 0: Low adjusted dose anti-coagulant]              3977     3293    1 #> rank[stroke = 0: Low dose aspirin]                              3921     3059    1 #> rank[stroke = 0: Low dose aspirin + copidogrel]                 3618     2192    1 #> rank[stroke = 0: Low dose aspirin + dipyridamole]               4833     2269    1 #> rank[stroke = 0: Medium dose aspirin]                           4854     3400    1 #> rank[stroke = 0: Placebo/Standard care]                         3626       NA    1 #> rank[stroke = 0: Triflusal]                                     4230       NA    1 #> rank[stroke = 0: Ximelagatran]                                  3215     2498    1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                              mean   sd 2.5% 25% 50% 75% 97.5% #> rank[stroke = 1: Standard adjusted dose anti-coagulant]      3.65 1.14    2   3   4   4     6 #> rank[stroke = 1: Acenocoumarol]                             13.28 4.35    1  14  15  16    17 #> rank[stroke = 1: Alternate day aspirin]                      4.53 4.08    1   1   3   7    14 #> rank[stroke = 1: Dipyridamole]                              10.49 2.72    5   8  11  13    15 #> rank[stroke = 1: Fixed dose warfarin]                        7.09 2.80    3   5   6   8    14 #> rank[stroke = 1: Fixed dose warfarin + low dose aspirin]    15.85 2.86    5  16  17  17    17 #> rank[stroke = 1: Fixed dose warfarin + medium dose aspirin] 15.42 1.96    8  15  16  16    17 #> rank[stroke = 1: High dose aspirin]                          9.44 3.93    2   6   9  13    16 #> rank[stroke = 1: Indobufen]                                  4.98 2.21    1   4   5   6    10 #> rank[stroke = 1: Low adjusted dose anti-coagulant]           2.02 1.33    1   1   2   2     6 #> rank[stroke = 1: Low dose aspirin]                          11.85 1.83    8  11  12  13    15 #> rank[stroke = 1: Low dose aspirin + copidogrel]             11.17 2.40    6  10  11  13    15 #> rank[stroke = 1: Low dose aspirin + dipyridamole]            8.19 2.63    3   6   8  10    14 #> rank[stroke = 1: Medium dose aspirin]                        8.60 1.70    6   7   8  10    12 #> rank[stroke = 1: Placebo/Standard care]                     11.11 1.93    7  10  11  12    15 #> rank[stroke = 1: Triflusal]                                 12.15 3.07    5  10  13  14    17 #> rank[stroke = 1: Ximelagatran]                               3.19 1.42    1   2   3   4     6 #>                                                             Bulk_ESS Tail_ESS Rhat #> rank[stroke = 1: Standard adjusted dose anti-coagulant]         3430     3123    1 #> rank[stroke = 1: Acenocoumarol]                                 4356       NA    1 #> rank[stroke = 1: Alternate day aspirin]                         4322     2597    1 #> rank[stroke = 1: Dipyridamole]                                  4788     3203    1 #> rank[stroke = 1: Fixed dose warfarin]                           3731     3121    1 #> rank[stroke = 1: Fixed dose warfarin + low dose aspirin]        3190       NA    1 #> rank[stroke = 1: Fixed dose warfarin + medium dose aspirin]     3130       NA    1 #> rank[stroke = 1: High dose aspirin]                             4899     3215    1 #> rank[stroke = 1: Indobufen]                                     4053     3112    1 #> rank[stroke = 1: Low adjusted dose anti-coagulant]              3010     2911    1 #> rank[stroke = 1: Low dose aspirin]                              4122     3328    1 #> rank[stroke = 1: Low dose aspirin + copidogrel]                 3662     2420    1 #> rank[stroke = 1: Low dose aspirin + dipyridamole]               4464     2955    1 #> rank[stroke = 1: Medium dose aspirin]                           4235     3679    1 #> rank[stroke = 1: Placebo/Standard care]                         4379     3372    1 #> rank[stroke = 1: Triflusal]                                     4014     3015    1 #> rank[stroke = 1: Ximelagatran]                                  2616     2661    1 plot(af_4b_ranks) (af_4b_rankprobs <- posterior_rank_probs(af_fit_4b,                                          newdata = data.frame(stroke = c(0, 1),                                                                label = c(\"stroke = 0\", \"stroke = 1\")),                                           study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.00      0.00      0.00 #> d[stroke = 0: Acenocoumarol]                                  0.25      0.24      0.14 #> d[stroke = 0: Alternate day aspirin]                          0.44      0.14      0.09 #> d[stroke = 0: Dipyridamole]                                   0.00      0.00      0.02 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.00      0.00 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.00      0.00      0.01 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.04      0.10      0.12 #> d[stroke = 0: High dose aspirin]                              0.03      0.06      0.07 #> d[stroke = 0: Indobufen]                                      0.17      0.26      0.20 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.05      0.14      0.21 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.00      0.00      0.01 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.01      0.03      0.07 #> d[stroke = 0: Medium dose aspirin]                            0.00      0.00      0.01 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.00      0.01      0.01 #> d[stroke = 0: Ximelagatran]                                   0.00      0.01      0.05 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.03      0.08      0.15 #> d[stroke = 0: Acenocoumarol]                                  0.10      0.05      0.03 #> d[stroke = 0: Alternate day aspirin]                          0.06      0.04      0.03 #> d[stroke = 0: Dipyridamole]                                   0.03      0.04      0.05 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.01      0.01 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.02      0.04      0.05 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.12      0.10      0.07 #> d[stroke = 0: High dose aspirin]                              0.08      0.06      0.05 #> d[stroke = 0: Indobufen]                                      0.12      0.07      0.04 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.19      0.14      0.09 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.01      0.01      0.02 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.09      0.12      0.11 #> d[stroke = 0: Medium dose aspirin]                            0.02      0.06      0.09 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.02      0.02      0.03 #> d[stroke = 0: Ximelagatran]                                   0.10      0.15      0.16 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.21      0.19      0.16 #> d[stroke = 0: Acenocoumarol]                                  0.03      0.03      0.02 #> d[stroke = 0: Alternate day aspirin]                          0.02      0.02      0.02 #> d[stroke = 0: Dipyridamole]                                   0.06      0.06      0.07 #> d[stroke = 0: Fixed dose warfarin]                            0.01      0.02      0.03 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.05      0.07      0.07 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.06      0.06      0.05 #> d[stroke = 0: High dose aspirin]                              0.05      0.04      0.05 #> d[stroke = 0: Indobufen]                                      0.03      0.03      0.02 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.05      0.04      0.03 #> d[stroke = 0: Low dose aspirin]                               0.00      0.01      0.03 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.02      0.04      0.06 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.08      0.08      0.08 #> d[stroke = 0: Medium dose aspirin]                            0.14      0.17      0.17 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.01 #> d[stroke = 0: Triflusal]                                      0.03      0.03      0.04 #> d[stroke = 0: Ximelagatran]                                   0.14      0.12      0.09 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.10       0.05       0.02 #> d[stroke = 0: Acenocoumarol]                                   0.02       0.02       0.01 #> d[stroke = 0: Alternate day aspirin]                           0.02       0.02       0.02 #> d[stroke = 0: Dipyridamole]                                    0.09       0.10       0.10 #> d[stroke = 0: Fixed dose warfarin]                             0.04       0.06       0.07 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.09       0.09       0.10 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.04       0.04       0.04 #> d[stroke = 0: High dose aspirin]                               0.05       0.05       0.05 #> d[stroke = 0: Indobufen]                                       0.02       0.01       0.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.02       0.01       0.01 #> d[stroke = 0: Low dose aspirin]                                0.06       0.12       0.18 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.10       0.12       0.13 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.08       0.07       0.05 #> d[stroke = 0: Medium dose aspirin]                             0.14       0.11       0.05 #> d[stroke = 0: Placebo/Standard care]                           0.02       0.05       0.08 #> d[stroke = 0: Triflusal]                                       0.04       0.05       0.06 #> d[stroke = 0: Ximelagatran]                                    0.07       0.04       0.03 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.01       0.00       0.00 #> d[stroke = 0: Acenocoumarol]                                   0.01       0.01       0.01 #> d[stroke = 0: Alternate day aspirin]                           0.02       0.02       0.01 #> d[stroke = 0: Dipyridamole]                                    0.09       0.07       0.09 #> d[stroke = 0: Fixed dose warfarin]                             0.09       0.11       0.12 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.10       0.09       0.09 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.03       0.04       0.04 #> d[stroke = 0: High dose aspirin]                               0.05       0.05       0.05 #> d[stroke = 0: Indobufen]                                       0.01       0.01       0.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.00       0.00       0.00 #> d[stroke = 0: Low dose aspirin]                                0.19       0.19       0.13 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.14       0.12       0.11 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.04       0.03       0.03 #> d[stroke = 0: Medium dose aspirin]                             0.03       0.01       0.00 #> d[stroke = 0: Placebo/Standard care]                           0.13       0.17       0.23 #> d[stroke = 0: Triflusal]                                       0.06       0.07       0.08 #> d[stroke = 0: Ximelagatran]                                    0.02       0.01       0.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.00       0.00 #> d[stroke = 0: Acenocoumarol]                                   0.02       0.00 #> d[stroke = 0: Alternate day aspirin]                           0.02       0.03 #> d[stroke = 0: Dipyridamole]                                    0.08       0.06 #> d[stroke = 0: Fixed dose warfarin]                             0.21       0.22 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.07       0.05 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.03       0.02 #> d[stroke = 0: High dose aspirin]                               0.08       0.13 #> d[stroke = 0: Indobufen]                                       0.00       0.00 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.00       0.00 #> d[stroke = 0: Low dose aspirin]                                0.06       0.02 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.08       0.04 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.02       0.01 #> d[stroke = 0: Medium dose aspirin]                             0.00       0.00 #> d[stroke = 0: Placebo/Standard care]                           0.19       0.11 #> d[stroke = 0: Triflusal]                                       0.15       0.31 #> d[stroke = 0: Ximelagatran]                                    0.00       0.00 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.12      0.34 #> d[stroke = 1: Acenocoumarol]                                  0.04      0.02      0.01 #> d[stroke = 1: Alternate day aspirin]                          0.37      0.10      0.05 #> d[stroke = 1: Dipyridamole]                                   0.00      0.00      0.00 #> d[stroke = 1: Fixed dose warfarin]                            0.00      0.01      0.02 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.02      0.02      0.03 #> d[stroke = 1: Indobufen]                                      0.04      0.08      0.11 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.43      0.35      0.10 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.00      0.01      0.01 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.00      0.00 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 1: Triflusal]                                      0.00      0.00      0.01 #> d[stroke = 1: Ximelagatran]                                   0.08      0.26      0.31 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.34      0.14      0.03 #> d[stroke = 1: Acenocoumarol]                                  0.01      0.01      0.02 #> d[stroke = 1: Alternate day aspirin]                          0.06      0.07      0.09 #> d[stroke = 1: Dipyridamole]                                   0.00      0.02      0.04 #> d[stroke = 1: Fixed dose warfarin]                            0.07      0.18      0.25 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.03      0.06      0.09 #> d[stroke = 1: Indobufen]                                      0.18      0.27      0.15 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.06      0.04      0.02 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.01      0.02 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.03      0.07      0.14 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.01      0.06 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.01 #> d[stroke = 1: Triflusal]                                      0.01      0.01      0.03 #> d[stroke = 1: Ximelagatran]                                   0.20      0.09      0.03 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.00      0.00 #> d[stroke = 1: Acenocoumarol]                                  0.02      0.02      0.02 #> d[stroke = 1: Alternate day aspirin]                          0.05      0.03      0.03 #> d[stroke = 1: Dipyridamole]                                   0.08      0.10      0.11 #> d[stroke = 1: Fixed dose warfarin]                            0.15      0.08      0.06 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.01      0.01      0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.01      0.01 #> d[stroke = 1: High dose aspirin]                              0.11      0.08      0.07 #> d[stroke = 1: Indobufen]                                      0.08      0.04      0.02 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.01      0.00      0.00 #> d[stroke = 1: Low dose aspirin]                               0.01      0.03      0.06 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.04      0.07      0.10 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.18      0.15      0.12 #> d[stroke = 1: Medium dose aspirin]                            0.18      0.26      0.22 #> d[stroke = 1: Placebo/Standard care]                          0.02      0.06      0.12 #> d[stroke = 1: Triflusal]                                      0.04      0.05      0.05 #> d[stroke = 1: Ximelagatran]                                   0.01      0.01      0.00 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.01       0.01       0.01 #> d[stroke = 1: Alternate day aspirin]                           0.02       0.02       0.02 #> d[stroke = 1: Dipyridamole]                                    0.12       0.13       0.12 #> d[stroke = 1: Fixed dose warfarin]                             0.04       0.04       0.03 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.01       0.01       0.01 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.01       0.00       0.01 #> d[stroke = 1: High dose aspirin]                               0.06       0.06       0.06 #> d[stroke = 1: Indobufen]                                       0.01       0.01       0.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.13       0.18       0.23 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.12       0.15       0.16 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.09       0.07       0.05 #> d[stroke = 1: Medium dose aspirin]                             0.14       0.07       0.03 #> d[stroke = 1: Placebo/Standard care]                           0.18       0.19       0.18 #> d[stroke = 1: Triflusal]                                       0.06       0.06       0.08 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00       0.00 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.02       0.04       0.44 #> d[stroke = 1: Alternate day aspirin]                           0.03       0.03       0.01 #> d[stroke = 1: Dipyridamole]                                    0.12       0.09       0.03 #> d[stroke = 1: Fixed dose warfarin]                             0.03       0.02       0.01 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.01       0.01       0.05 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.01       0.02       0.27 #> d[stroke = 1: High dose aspirin]                               0.09       0.13       0.04 #> d[stroke = 1: Indobufen]                                       0.01       0.00       0.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.21       0.11       0.03 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.17       0.10       0.03 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.04       0.02       0.01 #> d[stroke = 1: Medium dose aspirin]                             0.01       0.00       0.00 #> d[stroke = 1: Placebo/Standard care]                           0.13       0.07       0.02 #> d[stroke = 1: Triflusal]                                       0.12       0.34       0.06 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00       0.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           0.00       0.00 #> d[stroke = 1: Acenocoumarol]                                   0.21       0.07 #> d[stroke = 1: Alternate day aspirin]                           0.00       0.00 #> d[stroke = 1: Dipyridamole]                                    0.02       0.01 #> d[stroke = 1: Fixed dose warfarin]                             0.01       0.00 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.19       0.67 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.50       0.16 #> d[stroke = 1: High dose aspirin]                               0.01       0.02 #> d[stroke = 1: Indobufen]                                       0.00       0.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                0.00       0.00 #> d[stroke = 1: Low dose aspirin]                                0.02       0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.01       0.01 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.00       0.00 #> d[stroke = 1: Medium dose aspirin]                             0.00       0.00 #> d[stroke = 1: Placebo/Standard care]                           0.01       0.00 #> d[stroke = 1: Triflusal]                                       0.03       0.05 #> d[stroke = 1: Ximelagatran]                                    0.00       0.00  # Modify the default output with ggplot2 functionality library(ggplot2) plot(af_4b_rankprobs) +    facet_grid(Treatment~Study, labeller = label_wrap_gen(20)) +    theme(strip.text.y = element_text(angle = 0)) (af_4b_cumrankprobs <- posterior_rank_probs(af_fit_4b, cumulative = TRUE,                                             newdata = data.frame(stroke = c(0, 1),                                                                   label = c(\"stroke = 0\", \"stroke = 1\")),                                              study = label)) #> ------------------------------------------------------------- Study: stroke = 0 ----  #>  #> Covariate values: #>  stroke #>       0 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.00      0.00      0.01 #> d[stroke = 0: Acenocoumarol]                                  0.25      0.49      0.63 #> d[stroke = 0: Alternate day aspirin]                          0.44      0.58      0.66 #> d[stroke = 0: Dipyridamole]                                   0.00      0.00      0.02 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.00      0.00 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.04      0.14      0.26 #> d[stroke = 0: High dose aspirin]                              0.03      0.09      0.16 #> d[stroke = 0: Indobufen]                                      0.17      0.43      0.64 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.05      0.19      0.40 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.00      0.00      0.01 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.01      0.04      0.11 #> d[stroke = 0: Medium dose aspirin]                            0.00      0.00      0.01 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.00      0.01      0.02 #> d[stroke = 0: Ximelagatran]                                   0.00      0.01      0.06 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.03      0.11      0.26 #> d[stroke = 0: Acenocoumarol]                                  0.72      0.78      0.81 #> d[stroke = 0: Alternate day aspirin]                          0.73      0.77      0.80 #> d[stroke = 0: Dipyridamole]                                   0.05      0.09      0.14 #> d[stroke = 0: Fixed dose warfarin]                            0.00      0.01      0.02 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.04      0.09      0.14 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.37      0.48      0.55 #> d[stroke = 0: High dose aspirin]                              0.24      0.31      0.35 #> d[stroke = 0: Indobufen]                                      0.76      0.83      0.87 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.59      0.74      0.83 #> d[stroke = 0: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.02      0.03      0.05 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.21      0.32      0.43 #> d[stroke = 0: Medium dose aspirin]                            0.03      0.08      0.18 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 0: Triflusal]                                      0.04      0.06      0.09 #> d[stroke = 0: Ximelagatran]                                   0.16      0.31      0.48 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 0: Standard adjusted dose anti-coagulant]          0.48      0.66      0.82 #> d[stroke = 0: Acenocoumarol]                                  0.84      0.87      0.89 #> d[stroke = 0: Alternate day aspirin]                          0.82      0.84      0.86 #> d[stroke = 0: Dipyridamole]                                   0.20      0.26      0.33 #> d[stroke = 0: Fixed dose warfarin]                            0.03      0.05      0.09 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]         0.19      0.26      0.33 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]      0.61      0.67      0.72 #> d[stroke = 0: High dose aspirin]                              0.40      0.44      0.49 #> d[stroke = 0: Indobufen]                                      0.90      0.93      0.95 #> d[stroke = 0: Low adjusted dose anti-coagulant]               0.88      0.92      0.95 #> d[stroke = 0: Low dose aspirin]                               0.01      0.02      0.05 #> d[stroke = 0: Low dose aspirin + copidogrel]                  0.07      0.11      0.17 #> d[stroke = 0: Low dose aspirin + dipyridamole]                0.51      0.59      0.67 #> d[stroke = 0: Medium dose aspirin]                            0.32      0.49      0.66 #> d[stroke = 0: Placebo/Standard care]                          0.00      0.01      0.02 #> d[stroke = 0: Triflusal]                                      0.11      0.14      0.18 #> d[stroke = 0: Ximelagatran]                                   0.62      0.74      0.83 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           0.92       0.97       0.99 #> d[stroke = 0: Acenocoumarol]                                   0.91       0.93       0.94 #> d[stroke = 0: Alternate day aspirin]                           0.87       0.89       0.90 #> d[stroke = 0: Dipyridamole]                                    0.42       0.52       0.62 #> d[stroke = 0: Fixed dose warfarin]                             0.13       0.19       0.26 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.42       0.51       0.61 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.76       0.80       0.84 #> d[stroke = 0: High dose aspirin]                               0.54       0.59       0.64 #> d[stroke = 0: Indobufen]                                       0.96       0.97       0.98 #> d[stroke = 0: Low adjusted dose anti-coagulant]                0.97       0.98       0.99 #> d[stroke = 0: Low dose aspirin]                                0.11       0.23       0.41 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.27       0.39       0.52 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.75       0.82       0.87 #> d[stroke = 0: Medium dose aspirin]                             0.80       0.91       0.96 #> d[stroke = 0: Placebo/Standard care]                           0.04       0.09       0.17 #> d[stroke = 0: Triflusal]                                       0.22       0.27       0.33 #> d[stroke = 0: Ximelagatran]                                    0.90       0.94       0.96 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 0: Acenocoumarol]                                   0.96       0.97       0.98 #> d[stroke = 0: Alternate day aspirin]                           0.92       0.94       0.95 #> d[stroke = 0: Dipyridamole]                                    0.70       0.78       0.86 #> d[stroke = 0: Fixed dose warfarin]                             0.34       0.45       0.57 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.71       0.80       0.88 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.88       0.91       0.95 #> d[stroke = 0: High dose aspirin]                               0.69       0.74       0.79 #> d[stroke = 0: Indobufen]                                       0.98       0.99       0.99 #> d[stroke = 0: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 0: Low dose aspirin]                                0.60       0.79       0.92 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.66       0.78       0.89 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.92       0.95       0.97 #> d[stroke = 0: Medium dose aspirin]                             0.99       1.00       1.00 #> d[stroke = 0: Placebo/Standard care]                           0.30       0.47       0.70 #> d[stroke = 0: Triflusal]                                       0.38       0.46       0.54 #> d[stroke = 0: Ximelagatran]                                    0.98       0.99       1.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 0: Standard adjusted dose anti-coagulant]           1.00          1 #> d[stroke = 0: Acenocoumarol]                                   1.00          1 #> d[stroke = 0: Alternate day aspirin]                           0.97          1 #> d[stroke = 0: Dipyridamole]                                    0.94          1 #> d[stroke = 0: Fixed dose warfarin]                             0.78          1 #> d[stroke = 0: Fixed dose warfarin + low dose aspirin]          0.95          1 #> d[stroke = 0: Fixed dose warfarin + medium dose aspirin]       0.98          1 #> d[stroke = 0: High dose aspirin]                               0.87          1 #> d[stroke = 0: Indobufen]                                       1.00          1 #> d[stroke = 0: Low adjusted dose anti-coagulant]                1.00          1 #> d[stroke = 0: Low dose aspirin]                                0.98          1 #> d[stroke = 0: Low dose aspirin + copidogrel]                   0.96          1 #> d[stroke = 0: Low dose aspirin + dipyridamole]                 0.99          1 #> d[stroke = 0: Medium dose aspirin]                             1.00          1 #> d[stroke = 0: Placebo/Standard care]                           0.89          1 #> d[stroke = 0: Triflusal]                                       0.69          1 #> d[stroke = 0: Ximelagatran]                                    1.00          1 #>  #> ------------------------------------------------------------- Study: stroke = 1 ----  #>  #> Covariate values: #>  stroke #>       1 #>  #>                                                          p_rank[1] p_rank[2] p_rank[3] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.01      0.13      0.47 #> d[stroke = 1: Acenocoumarol]                                  0.04      0.06      0.08 #> d[stroke = 1: Alternate day aspirin]                          0.37      0.47      0.52 #> d[stroke = 1: Dipyridamole]                                   0.00      0.00      0.00 #> d[stroke = 1: Fixed dose warfarin]                            0.00      0.02      0.04 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.00      0.01      0.02 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.00      0.00      0.00 #> d[stroke = 1: High dose aspirin]                              0.02      0.04      0.07 #> d[stroke = 1: Indobufen]                                      0.04      0.12      0.23 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.43      0.78      0.88 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.00      0.00      0.00 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.00      0.01      0.03 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.00      0.00 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.00 #> d[stroke = 1: Triflusal]                                      0.00      0.01      0.01 #> d[stroke = 1: Ximelagatran]                                   0.08      0.34      0.65 #>                                                          p_rank[4] p_rank[5] p_rank[6] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          0.81      0.95      0.98 #> d[stroke = 1: Acenocoumarol]                                  0.09      0.10      0.12 #> d[stroke = 1: Alternate day aspirin]                          0.58      0.66      0.75 #> d[stroke = 1: Dipyridamole]                                   0.01      0.03      0.07 #> d[stroke = 1: Fixed dose warfarin]                            0.11      0.29      0.53 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.02      0.03      0.03 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.01      0.01      0.01 #> d[stroke = 1: High dose aspirin]                              0.10      0.17      0.26 #> d[stroke = 1: Indobufen]                                      0.40      0.67      0.82 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.94      0.97      0.99 #> d[stroke = 1: Low dose aspirin]                               0.00      0.00      0.01 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.01      0.02      0.04 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.05      0.12      0.27 #> d[stroke = 1: Medium dose aspirin]                            0.00      0.02      0.08 #> d[stroke = 1: Placebo/Standard care]                          0.00      0.00      0.01 #> d[stroke = 1: Triflusal]                                      0.02      0.03      0.06 #> d[stroke = 1: Ximelagatran]                                   0.85      0.94      0.98 #>                                                          p_rank[7] p_rank[8] p_rank[9] #> d[stroke = 1: Standard adjusted dose anti-coagulant]          1.00      1.00      1.00 #> d[stroke = 1: Acenocoumarol]                                  0.14      0.16      0.18 #> d[stroke = 1: Alternate day aspirin]                          0.80      0.83      0.86 #> d[stroke = 1: Dipyridamole]                                   0.15      0.26      0.37 #> d[stroke = 1: Fixed dose warfarin]                            0.69      0.77      0.83 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]         0.04      0.05      0.06 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]      0.02      0.03      0.04 #> d[stroke = 1: High dose aspirin]                              0.36      0.45      0.52 #> d[stroke = 1: Indobufen]                                      0.90      0.94      0.96 #> d[stroke = 1: Low adjusted dose anti-coagulant]               0.99      1.00      1.00 #> d[stroke = 1: Low dose aspirin]                               0.01      0.04      0.10 #> d[stroke = 1: Low dose aspirin + copidogrel]                  0.07      0.14      0.24 #> d[stroke = 1: Low dose aspirin + dipyridamole]                0.45      0.60      0.72 #> d[stroke = 1: Medium dose aspirin]                            0.26      0.52      0.73 #> d[stroke = 1: Placebo/Standard care]                          0.03      0.08      0.21 #> d[stroke = 1: Triflusal]                                      0.10      0.15      0.21 #> d[stroke = 1: Ximelagatran]                                   0.99      0.99      1.00 #>                                                          p_rank[10] p_rank[11] p_rank[12] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 1: Acenocoumarol]                                   0.19       0.20       0.21 #> d[stroke = 1: Alternate day aspirin]                           0.88       0.90       0.92 #> d[stroke = 1: Dipyridamole]                                    0.49       0.62       0.73 #> d[stroke = 1: Fixed dose warfarin]                             0.87       0.90       0.93 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.07       0.07       0.08 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.04       0.05       0.05 #> d[stroke = 1: High dose aspirin]                               0.58       0.64       0.70 #> d[stroke = 1: Indobufen]                                       0.98       0.98       0.99 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 1: Low dose aspirin]                                0.22       0.40       0.62 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.36       0.51       0.67 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.81       0.88       0.93 #> d[stroke = 1: Medium dose aspirin]                             0.87       0.95       0.98 #> d[stroke = 1: Placebo/Standard care]                           0.39       0.58       0.76 #> d[stroke = 1: Triflusal]                                       0.26       0.33       0.40 #> d[stroke = 1: Ximelagatran]                                    1.00       1.00       1.00 #>                                                          p_rank[13] p_rank[14] p_rank[15] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00       1.00       1.00 #> d[stroke = 1: Acenocoumarol]                                   0.24       0.28       0.72 #> d[stroke = 1: Alternate day aspirin]                           0.95       0.98       0.99 #> d[stroke = 1: Dipyridamole]                                    0.86       0.95       0.98 #> d[stroke = 1: Fixed dose warfarin]                             0.96       0.98       0.99 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.09       0.10       0.15 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.06       0.07       0.35 #> d[stroke = 1: High dose aspirin]                               0.79       0.92       0.96 #> d[stroke = 1: Indobufen]                                       0.99       1.00       1.00 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00       1.00       1.00 #> d[stroke = 1: Low dose aspirin]                                0.83       0.95       0.98 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.85       0.95       0.98 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 0.97       0.99       1.00 #> d[stroke = 1: Medium dose aspirin]                             0.99       1.00       1.00 #> d[stroke = 1: Placebo/Standard care]                           0.90       0.96       0.99 #> d[stroke = 1: Triflusal]                                       0.53       0.87       0.92 #> d[stroke = 1: Ximelagatran]                                    1.00       1.00       1.00 #>                                                          p_rank[16] p_rank[17] #> d[stroke = 1: Standard adjusted dose anti-coagulant]           1.00          1 #> d[stroke = 1: Acenocoumarol]                                   0.93          1 #> d[stroke = 1: Alternate day aspirin]                           1.00          1 #> d[stroke = 1: Dipyridamole]                                    0.99          1 #> d[stroke = 1: Fixed dose warfarin]                             1.00          1 #> d[stroke = 1: Fixed dose warfarin + low dose aspirin]          0.33          1 #> d[stroke = 1: Fixed dose warfarin + medium dose aspirin]       0.84          1 #> d[stroke = 1: High dose aspirin]                               0.98          1 #> d[stroke = 1: Indobufen]                                       1.00          1 #> d[stroke = 1: Low adjusted dose anti-coagulant]                1.00          1 #> d[stroke = 1: Low dose aspirin]                                1.00          1 #> d[stroke = 1: Low dose aspirin + copidogrel]                   0.99          1 #> d[stroke = 1: Low dose aspirin + dipyridamole]                 1.00          1 #> d[stroke = 1: Medium dose aspirin]                             1.00          1 #> d[stroke = 1: Placebo/Standard care]                           1.00          1 #> d[stroke = 1: Triflusal]                                       0.95          1 #> d[stroke = 1: Ximelagatran]                                    1.00          1  plot(af_4b_cumrankprobs) +    facet_grid(Treatment~Study, labeller = label_wrap_gen(20)) +    theme(strip.text.y = element_text(angle = 0))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_atrial_fibrillation.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: Atrial fibrillation","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC slightly lower meta-regression model, although couple points (substantial differences usually considered 3-5 points). estimated heterogeneity standard deviation much lower meta-regression model, suggesting adjusting proportion patients prior stroke explaining heterogeneity data. can also examine residual deviance contributions corresponding plot() method.","code":"(af_dic_1 <- dic(af_fit_1)) #> Residual deviance: 60.5 (on 61 data points) #>                pD: 48.7 #>               DIC: 109.2 (af_dic_4b <- dic(af_fit_4b)) #> Residual deviance: 58.3 (on 61 data points) #>                pD: 48.3 #>               DIC: 106.6 plot(af_dic_1) plot(af_dic_4b)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: BCG vaccine for tuberculosis","text":"data giving number diagnosed TB trial follow-(r) total (n) arm, use function set_agd_arm() set network. set “unvaccinated” network reference treatment. latitude variable bcg_vaccine data frame automatically available use meta-regression model.","code":"bcg_net <- set_agd_arm(bcg_vaccine,                         study = studyn,                        trt = trtc,                        r = r,                         n = n,                        trt_ref = \"Unvaccinated\") bcg_net #> A network with 13 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms               #>  1     2: Unvaccinated | Vaccinated #>  2     2: Unvaccinated | Vaccinated #>  3     2: Unvaccinated | Vaccinated #>  4     2: Unvaccinated | Vaccinated #>  5     2: Unvaccinated | Vaccinated #>  6     2: Unvaccinated | Vaccinated #>  7     2: Unvaccinated | Vaccinated #>  8     2: Unvaccinated | Vaccinated #>  9     2: Unvaccinated | Vaccinated #>  10    2: Unvaccinated | Vaccinated #>  ... plus 3 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 13 #> Reference treatment is: Unvaccinated #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: BCG vaccine for tuberculosis","text":"fit random effects (RE) models, firstly without covariates, meta-regression continuous covariate latitude.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"re-meta-analysis-no-covariate","dir":"Articles","previous_headings":"Meta-analysis models","what":"RE meta-analysis (no covariate)","title":"Example: BCG vaccine for tuberculosis","text":"start fitting standard RE model without covariates. use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effect dVaccined_\\mathrm{Vaccine} study-specific intercepts μj\\mu_j, half-N(0,52)\\textrm{half-N}(0, 5^2) prior distribution heterogeneity standard deviation τ\\tau. can examine range parameter values implied prior distributions summary() method: model fitted nma() function, random effects model specified trt_effects = \"random\". Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j random effects δj\\delta_j hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. bcg_fit_unadj <- nma(bcg_net,                       trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = half_normal(scale = 5)) #> rmup) #> Chain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup) #> Chain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup) #> Chain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup) #> Chain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup) #> Chain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup) #> Chain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling) #> Chain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling) #> Chain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling) #> Chain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling) #> Chain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling) #> Chain 3: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 1.477 seconds (Warm-up) #> Chain 3:                1.402 seconds (Sampling) #> Chain 3:                2.879 seconds (Total) #> Chain 3:  #> Chain 1: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 1.497 seconds (Warm-up) #> Chain 1:                1.406 seconds (Sampling) #> Chain 1:                2.903 seconds (Total) #> Chain 1:  #> Chain 2: Iteration: 10000 / 10000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 1.479 seconds (Warm-up) #> Chain 2:                1.571 seconds (Sampling) #> Chain 2:                3.05 seconds (Total) #> Chain 2: bcg_fit_unadj #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=10000; warmup=5000; thin=1;  #> post-warmup draws per chain=5000, total post-warmup draws=20000. #>  #>                    mean se_mean   sd      2.5%       25%       50%       75%     97.5% n_eff #> d[Vaccinated]     -0.76    0.00 0.22     -1.20     -0.90     -0.76     -0.62     -0.33  6566 #> lp__          -13453.89    0.06 4.49 -13463.54 -13456.77 -13453.55 -13450.72 -13446.06  5292 #> tau                0.68    0.00 0.20      0.39      0.54      0.65      0.78      1.16  6576 #>               Rhat #> d[Vaccinated]    1 #> lp__             1 #> tau              1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:34:38 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(bcg_fit_unadj, pars = c(\"d\", \"mu\", \"delta\", \"tau\")) plot_prior_posterior(bcg_fit_unadj, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"re-meta-regression-with-covariate-latitude","dir":"Articles","previous_headings":"Meta-analysis models","what":"RE meta-regression with covariate latitude","title":"Example: BCG vaccine for tuberculosis","text":"now fit RE meta-regression model, adjusting latitude. use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effect dVaccined_\\mathrm{Vaccine}, study-specific intercepts μj\\mu_j, regression coefficient β\\beta. use half-N(0,52)\\text{half-N}(0, 5^2) prior distribution heterogeneity standard deviation τ\\tau. can examine range parameter values implied prior distributions summary() method: , model fitted nma() function. regression formula ~ .trt:latitude means interaction latitude treatment included; .trt special variable indicates treatment, latitude original data set. increase adapt_delta 0.99 remove small number divergent transition errors (default RE models set 0.95). Basic parameter summaries given print() method: Note latitude automatically centered 33.46, mean value studies network. default, summaries study-specific intercepts μj\\mu_j study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. bcg_fit_lat <- nma(bcg_net,                     trt_effects = \"random\",                    regression = ~.trt:latitude,                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_reg = normal(scale = 100),                    prior_het = half_normal(scale = 5),                    adapt_delta = 0.99) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. bcg_fit_lat #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:latitude. #> Centred covariates at the following overall mean values: #> latitude  #> 33.46154  #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=5000; warmup=2500; thin=1;  #> post-warmup draws per chain=2500, total post-warmup draws=10000. #>  #>                                    mean se_mean   sd      2.5%       25%       50%       75% #> beta[.trtVaccinated:latitude]     -0.03    0.00 0.01     -0.05     -0.04     -0.03     -0.03 #> d[Vaccinated]                     -0.76    0.00 0.12     -1.03     -0.83     -0.76     -0.69 #> lp__                          -13457.21    0.12 5.07 -13468.16 -13460.40 -13456.94 -13453.61 #> tau                                0.30    0.00 0.18      0.03      0.16      0.27      0.40 #>                                   97.5% n_eff Rhat #> beta[.trtVaccinated:latitude]     -0.01  4569    1 #> d[Vaccinated]                     -0.54  4898    1 #> lp__                          -13448.27  1772    1 #> tau                                0.73  1905    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:34:46 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(bcg_fit_lat, pars = c(\"d\", \"beta\", \"mu\", \"delta\", \"tau\")) plot_prior_posterior(bcg_fit_lat, prior = c(\"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: BCG vaccine for tuberculosis","text":"Model fit can checked using dic() function: DIC similar two models, might first choose unadjusted model. posterior mean residual deviance larger model covariate, model also lower effective number parameters pDp_D allowing shrinkage random treatment effects. Moreover, model covariate much lower estimated heterogeneity standard deviation: Adjusting latitude explaining substantial amount heterogeneity data. 95% Credible Interval regression coefficient also excludes zero:  Altogether, might prefer model adjustment latitude. considering covariates random effects models important just look DIC (Dias et al. 2011). also consider reductions heterogeneity, estimated regression coefficients standard error. DIC sensitive changes heterogeneity, RE models flexible can fit data well whatever level heterogeneity.","code":"(bcg_dic_unadj <- dic(bcg_fit_unadj)) #> Residual deviance: 26 (on 26 data points) #>                pD: 23.5 #>               DIC: 49.5 (bcg_dic_lat <- dic(bcg_fit_lat)) #> Residual deviance: 30.7 (on 26 data points) #>                pD: 21.5 #>               DIC: 52.1 summary(bcg_fit_unadj, pars = \"tau\") #>     mean  sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau 0.68 0.2 0.39 0.54 0.65 0.78  1.16     6616    10707    1 summary(bcg_fit_lat, pars = \"tau\") #>     mean   sd 2.5%  25%  50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau  0.3 0.18 0.03 0.16 0.27 0.4  0.73     1678     2461    1 summary(bcg_fit_lat, pars = \"beta\") #>                                mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> beta[.trtVaccinated:latitude] -0.03 0.01 -0.05 -0.04 -0.03 -0.03 -0.01     4890     4242    1  plot(bcg_fit_lat,       pars = \"beta\",       ref_line = 0,      stat = \"halfeye\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_bcg_vaccine.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: BCG vaccine for tuberculosis","text":"can produce estimates relative effect vaccination latitude using relative_effects() function. newdata argument specifies data frame containing values covariate latitude interested , study argument used specify column newdata informative label. plot() method may used visually compare estimates:  sophisticated plot shows regression line confidence band effect latitude, overlaid observed log odds ratios study:  presence heterogeneity, argued decision makers consider predictive distribution relative effects new study, instead posterior distribution mean treatment effects, reflects uncertainty due heterogeneity may better represent uncertainty future roll-treatment (see Dias et al. 2011). can produce predictive distributions using predictive_distribution = TRUE argument relative_effects(). Dias et al. (2018, sec. 8.3.2) consider predictive distributions BCG vaccine analysis. unadjusted analysis, whilst substantial evidence vaccination effective average essentially zero probability harm based mean effect, predictive distribution effectiveness new study wide covers range harmful effects: predictive probability new trial showing harmful effect : analysis adjusting latitude, predictive distribution relative effects now depends latitude; calculate increments 10 degrees equator: predictive probabilities new trial carried given latitude showing harmful effect can calculated : predictive probability new trial carried equator shows harmful effect around 80%, whereas 50 degrees latitude predictive probability 0.7%.","code":"bcg_releff_lat <- relative_effects(bcg_fit_lat,                                    newdata = tibble::tibble(latitude = seq(10, 50, by = 10),                                                             label = paste0(latitude, \"\\u00B0 latitude\")),                                    study = label)  bcg_releff_lat #> ----------------------------------------------------------- Study: 10° latitude ----  #>  #> Covariate values: #>  latitude #>        10 #>  #>                              mean   sd  2.5%   25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[10° latitude: Vaccinated] -0.02 0.22 -0.52 -0.13   0 0.1  0.41     4584     4077    1 #>  #> ----------------------------------------------------------- Study: 20° latitude ----  #>  #> Covariate values: #>  latitude #>        20 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[20° latitude: Vaccinated] -0.34 0.16 -0.69 -0.42 -0.32 -0.25 -0.03     4587     4402    1 #>  #> ----------------------------------------------------------- Study: 30° latitude ----  #>  #> Covariate values: #>  latitude #>        30 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[30° latitude: Vaccinated] -0.65 0.12 -0.93 -0.72 -0.65 -0.58 -0.42     4890     4879    1 #>  #> ----------------------------------------------------------- Study: 40° latitude ----  #>  #> Covariate values: #>  latitude #>        40 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[40° latitude: Vaccinated] -0.97 0.14 -1.27 -1.05 -0.97 -0.89 -0.71     5451     5245    1 #>  #> ----------------------------------------------------------- Study: 50° latitude ----  #>  #> Covariate values: #>  latitude #>        50 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[50° latitude: Vaccinated] -1.29 0.19 -1.68 -1.39 -1.29 -1.18 -0.89     5398     4690    1 plot(bcg_releff_lat,       ref_line = 0) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2)  # Get data for regression line lat_range <- range(bcg_vaccine$latitude) lat_dat <- tibble(latitude = seq(lat_range[1], lat_range[2], by = 1))  bcg_lat_reg <- relative_effects(bcg_fit_lat,                                  newdata = lat_dat) %>%    as_tibble() %>%    bind_cols(lat_dat)  # Get study log odds ratios bcg_lor <- bcg_vaccine %>%    group_by(studyn) %>%    mutate(lor = log(r / (n - r)) - log(first(r) / (first(n) - first(r))),          sample_size = sum(n)) %>%    slice(-1)  # Plot ggplot(aes(x = latitude), data = bcg_lor) +   geom_hline(yintercept = 0, colour = \"grey60\") +   geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), data = bcg_lat_reg,               fill = \"darkred\", alpha = 0.3) +   geom_line(aes(y = mean), data = bcg_lat_reg,             colour = \"darkred\") +   geom_point(aes(y = lor, size = sample_size), alpha = 0.6) +   coord_cartesian(xlim = c(0, 60)) +   xlab(\"Degrees Latitude\") + ylab(\"log Odds Ratio\") +   scale_size(\"Sample Size\") +   theme_multinma() (bcg_predeff_unadj <- relative_effects(bcg_fit_unadj, predictive_distribution = TRUE)) #>                        mean   sd 2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> delta_new[Vaccinated] -0.77 0.75 -2.3 -1.22 -0.76 -0.31  0.73    16583    17208    1 mean(as.matrix(bcg_predeff_unadj) > 0) #> [1] 0.1316 bcg_predeff_lat <- relative_effects(bcg_fit_lat,                                    newdata = tibble::tibble(latitude = seq(0, 50, by = 10),                                                             label = paste0(latitude, \"\\u00B0 latitude\")),                                    study = label,                                    predictive_distribution = TRUE)  bcg_predeff_lat #> ------------------------------------------------------------ Study: 0° latitude ----  #>  #> Covariate values: #>  latitude #>         0 #>  #>                                    mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> delta_new[0° latitude: Vaccinated]  0.3 0.46 -0.71 0.08 0.32 0.52   1.2     6645     5618    1 #>  #> ----------------------------------------------------------- Study: 10° latitude ----  #>  #> Covariate values: #>  latitude #>        10 #>  #>                                      mean   sd  2.5%   25% 50%  75% 97.5% Bulk_ESS Tail_ESS #> delta_new[10° latitude: Vaccinated] -0.02 0.41 -0.93 -0.21   0 0.18   0.8     7313     6060 #>                                     Rhat #> delta_new[10° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 20° latitude ----  #>  #> Covariate values: #>  latitude #>        20 #>  #>                                      mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[20° latitude: Vaccinated] -0.34 0.38 -1.18 -0.51 -0.32 -0.16  0.45     8079     6925 #>                                     Rhat #> delta_new[20° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 30° latitude ----  #>  #> Covariate values: #>  latitude #>        30 #>  #>                                      mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[30° latitude: Vaccinated] -0.65 0.37 -1.44 -0.82 -0.64 -0.48  0.12     8646     7396 #>                                     Rhat #> delta_new[30° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 40° latitude ----  #>  #> Covariate values: #>  latitude #>        40 #>  #>                                      mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[40° latitude: Vaccinated] -0.97 0.38 -1.75 -1.15 -0.96 -0.79 -0.18     8573     7868 #>                                     Rhat #> delta_new[40° latitude: Vaccinated]    1 #>  #> ----------------------------------------------------------- Study: 50° latitude ----  #>  #> Covariate values: #>  latitude #>        50 #>  #>                                      mean  sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS #> delta_new[50° latitude: Vaccinated] -1.29 0.4 -2.12 -1.47 -1.29 -1.09 -0.45     7930     7734 #>                                     Rhat #> delta_new[50° latitude: Vaccinated]    1 colMeans(as.matrix(bcg_predeff_lat) > 0) #>  delta_new[0° latitude: Vaccinated] delta_new[10° latitude: Vaccinated]  #>                              0.8062                              0.5047  #> delta_new[20° latitude: Vaccinated] delta_new[30° latitude: Vaccinated]  #>                              0.1327                              0.0398  #> delta_new[40° latitude: Vaccinated] delta_new[50° latitude: Vaccinated]  #>                              0.0135                              0.0061"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Beta blockers","text":"begin setting network - just pairwise meta-analysis. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). set “Control” reference treatment.","code":"blocker_net <- set_agd_arm(blocker,                             study = studyn,                            trt = trtc,                            r = r,                             n = n,                            trt_ref = \"Control\") blocker_net #> A network with 22 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms            #>  1     2: Control | Beta Blocker #>  2     2: Control | Beta Blocker #>  3     2: Control | Beta Blocker #>  4     2: Control | Beta Blocker #>  5     2: Control | Beta Blocker #>  6     2: Control | Beta Blocker #>  7     2: Control | Beta Blocker #>  8     2: Control | Beta Blocker #>  9     2: Control | Beta Blocker #>  10    2: Control | Beta Blocker #>  ... plus 12 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 22 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Beta blockers","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Beta blockers","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k study-specific intercepts μj\\mu_j. can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. blocker_fit_FE <- nma(blocker_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) #> 20%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.059 seconds (Warm-up) #> Chain 1:                0.042 seconds (Sampling) #> Chain 1:                0.101 seconds (Total) #> Chain 1:  #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.055 seconds (Warm-up) #> Chain 2:                0.041 seconds (Sampling) #> Chain 2:                0.096 seconds (Total) #> Chain 2:  #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.054 seconds (Warm-up) #> Chain 3:                0.041 seconds (Sampling) #> Chain 3:                0.095 seconds (Total) #> Chain 3: blocker_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                     mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff Rhat #> d[Beta Blocker]    -0.26    0.00 0.05    -0.36    -0.30    -0.26    -0.23    -0.16  3693    1 #> lp__            -5960.39    0.09 3.48 -5968.17 -5962.42 -5960.09 -5957.94 -5954.57  1363    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:34:56 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(blocker_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(blocker_fit_FE, prior = \"trt\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Beta blockers","text":"now fit random effects model using nma() function trt_effects = \"random\". , use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k study-specific intercepts μj\\mu_j, additionally use half-N(52)\\textrm{half-N}(5^2) prior heterogeneity standard deviation τ\\tau. can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. blocker_fit_RE <- nma(blocker_net,                     trt_effects = \"random\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_het = half_normal(scale = 5)) #>  2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.277 seconds (Warm-up) #> Chain 2:                0.202 seconds (Sampling) #> Chain 2:                0.479 seconds (Total) #> Chain 2:  #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.291 seconds (Warm-up) #> Chain 1:                0.206 seconds (Sampling) #> Chain 1:                0.497 seconds (Total) #> Chain 1:  #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.286 seconds (Warm-up) #> Chain 3:                0.204 seconds (Sampling) #> Chain 3:                0.49 seconds (Total) #> Chain 3: blocker_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                     mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff Rhat #> d[Beta Blocker]    -0.25    0.00 0.06    -0.38    -0.29    -0.25    -0.21    -0.13  4174    1 #> lp__            -5970.70    0.17 5.66 -5982.57 -5974.43 -5970.52 -5966.81 -5960.34  1072    1 #> tau                 0.13    0.00 0.08     0.01     0.07     0.13     0.19     0.31   928    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:34:59 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(blocker_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(blocker_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Beta blockers","text":"Model fit can checked using dic() function: residual deviance lower RE model, expected model flexible. However, comes increased effective number parameters (note increase pDp_D). result, DIC models similar FE model may preferred parsimony. can also examine residual deviance contributions corresponding plot() method.   number points well fit FE model, posterior mean residual deviance contributions greater 1. Study 14 particularly poor fit FE model, residual deviance reduced (although still high) RE model. evidence given careful examination, consideration given issues potential effect-modifying covariates (Dias et al. 2011). Leverage plots can also produced plot() method, type = \"leverage\".   plot leverage data point (.e. contribution model complexity pDp_D) square root residual deviance. sign square root residual deviance given sign difference observed model-predicted values, indicating whether data point - -estimated model. Contours displayed indicate lines constant contribution DIC. Points contributing 3 DIC generally considered contributing poor fit; labelled points using ggplot2 function geom_text(). residual deviance plots , see arms study 14 fit poorly FE model, fit improved (still poor) RE model.","code":"(dic_FE <- dic(blocker_fit_FE)) #> Residual deviance: 46.8 (on 44 data points) #>                pD: 23.1 #>               DIC: 69.9 (dic_RE <- dic(blocker_fit_RE)) #> Residual deviance: 41.8 (on 44 data points) #>                pD: 28.1 #>               DIC: 69.9 plot(dic_FE) plot(dic_RE) plot(dic_FE, type = \"leverage\") +    # Add labels for points outside DIC=3   geom_text(aes(label = parameter), data = ~subset(., dic > 3), vjust = -0.5) plot(dic_RE, type = \"leverage\") +    # Add labels for points outside DIC=3   geom_text(aes(label = parameter), data = ~subset(., dic > 3), vjust = -0.5)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_blocker.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Beta blockers","text":"Dias et al. (2011) produce absolute predictions probability mortality beta blockers control, assuming Normal distribution baseline logit-probability mortality mean −2.2-2.2 precision 3.33.3. can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted probabilities (type = \"link\" produce predicted log odds).   instead information baseline logit-probability mortality event counts, can use construct Beta distribution baseline probability mortality. example, 4 36 individuals died control treatment target population interest, appropriate Beta distribution probability Beta(4,36−4)\\textrm{Beta}(4, 36-4). can specify Beta distribution baseline response using baseline_type = \"reponse\" argument (default \"link\", used baseline logit-probability).   Notice results nearly equivalent calculated using Normal distribution baseline logit-probability, since event counts correspond approximately distribution logit-probability.","code":"pred_FE <- predict(blocker_fit_FE,                     baseline = distr(qnorm, mean = -2.2, sd = 3.3^-0.5),                     type = \"response\") pred_FE #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.04 0.07 0.10 0.14  0.24     4073     3875    1 #> pred[Beta Blocker] 0.09 0.04 0.03 0.06 0.08 0.11  0.19     4086     3948    1 plot(pred_FE) pred_RE <- predict(blocker_fit_RE,                     baseline = distr(qnorm, mean = -2.2, sd = 3.3^-0.5),                     type = \"response\") pred_RE #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.04 0.07 0.10 0.14  0.25     4384     3718    1 #> pred[Beta Blocker] 0.09 0.05 0.03 0.06 0.08 0.11  0.20     4373     3486    1 plot(pred_RE) pred_FE_beta <- predict(blocker_fit_FE,                          baseline = distr(qbeta, 4, 36-4),                         baseline_type = \"response\",                         type = \"response\") pred_FE_beta #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.03 0.07 0.10 0.14  0.23     3493     3846    1 #> pred[Beta Blocker] 0.09 0.04 0.02 0.06 0.08 0.11  0.19     3523     3885    1 plot(pred_FE_beta) pred_RE_beta <- predict(blocker_fit_RE,                          baseline = distr(qbeta, 4, 36-4),                         baseline_type = \"response\",                         type = \"response\") pred_RE_beta #>                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]      0.11 0.05 0.03 0.07 0.10 0.14  0.23     3990     3890    1 #> pred[Beta Blocker] 0.09 0.04 0.03 0.06 0.08 0.11  0.19     4017     3918    1 plot(pred_RE_beta)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Diabetes","text":"begin setting network. arm-level count data giving number new cases diabetes (r) total (n) arm, use function set_agd_arm(). computational efficiency, let “Beta Blocker” set network reference treatment default. Elliott Meyer (2007) Dias et al. (2011) use “Diuretic” reference, simple matter transform results fitting NMA model.1 also details length follow-years trial (time), use offset cloglog link function model data rates. specify function set_agd_arm(): additional columns data (e.g. offsets covariates, column time) automatically made available network. Plot network structure.","code":"db_net <- set_agd_arm(diabetes,                        study = studyc,                       trt = trtc,                       r = r,                        n = n) db_net #> A network with 22 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study  Treatment arms                        #>  AASK   3: Beta Blocker | ACE Inhibitor | CCB #>  ALLHAT 3: ACE Inhibitor | CCB | Diuretic     #>  ALPINE 2: ARB | Diuretic                     #>  ANBP-2 2: ACE Inhibitor | Diuretic           #>  ASCOT  2: Beta Blocker | CCB                 #>  CAPPP  2: Beta Blocker | ACE Inhibitor       #>  CHARM  2: ARB | Placebo                      #>  DREAM  2: ACE Inhibitor | Placebo            #>  EWPH   2: Diuretic | Placebo                 #>  FEVER  2: CCB | Placebo                      #>  ... plus 12 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6 #> Total number of studies: 22 #> Reference treatment is: Beta Blocker #> Network is connected plot(db_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Diabetes","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Diabetes","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k study-specific intercepts μj\\mu_j. can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. specify cloglog link used link = \"cloglog\" (Binomial likelihood default data), specify log follow-time offset using regression formula regression = ~offset(log(time)). Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. db_fit_FE <- nma(db_net,                   trt_effects = \"fixed\",                  link = \"cloglog\",                  regression = ~offset(log(time)),                  prior_intercept = normal(scale = 100),                  prior_trt = normal(scale = 100)) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. #> Note: Setting \"Beta Blocker\" as the network reference treatment. db_fit_FE #> A fixed effects NMA with a binomial likelihood (cloglog link). #> Regression model: ~offset(log(time)). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                       mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[ACE Inhibitor]     -0.30    0.00 0.05     -0.39     -0.34     -0.30     -0.27     -0.21 #> d[ARB]               -0.40    0.00 0.05     -0.49     -0.43     -0.40     -0.37     -0.31 #> d[CCB]               -0.20    0.00 0.03     -0.26     -0.22     -0.20     -0.18     -0.14 #> d[Diuretic]           0.05    0.00 0.06     -0.05      0.02      0.06      0.09      0.16 #> d[Placebo]           -0.19    0.00 0.05     -0.29     -0.23     -0.19     -0.16     -0.09 #> lp__             -37970.30    0.09 3.64 -37978.50 -37972.56 -37970.06 -37967.69 -37963.89 #>                  n_eff Rhat #> d[ACE Inhibitor]  1657    1 #> d[ARB]            2483    1 #> d[CCB]            1915    1 #> d[Diuretic]       1868    1 #> d[Placebo]        1482    1 #> lp__              1824    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:35:09 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(db_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(db_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Diabetes","text":"now fit random effects model using nma() function trt_effects = \"random\". , use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k study-specific intercepts μj\\mu_j, additionally use half-N(52)\\textrm{half-N}(5^2) prior heterogeneity standard deviation τ\\tau. can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. db_fit_RE <- nma(db_net,                   trt_effects = \"random\",                  link = \"cloglog\",                  regression = ~offset(log(time)),                  prior_intercept = normal(scale = 10),                  prior_trt = normal(scale = 10),                  prior_het = half_normal(scale = 5),                  init_r = 0.5) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. #> Note: Setting \"Beta Blocker\" as the network reference treatment. db_fit_RE #> A random effects NMA with a binomial likelihood (cloglog link). #> Regression model: ~offset(log(time)). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                       mean se_mean   sd      2.5%       25%       50%       75%     97.5% #> d[ACE Inhibitor]     -0.33    0.00 0.08     -0.49     -0.38     -0.33     -0.28     -0.18 #> d[ARB]               -0.40    0.00 0.09     -0.60     -0.46     -0.40     -0.34     -0.22 #> d[CCB]               -0.17    0.00 0.06     -0.29     -0.21     -0.17     -0.13     -0.04 #> d[Diuretic]           0.07    0.00 0.09     -0.10      0.01      0.07      0.13      0.25 #> d[Placebo]           -0.22    0.00 0.09     -0.39     -0.27     -0.22     -0.16     -0.05 #> lp__             -37980.88    0.21 6.79 -37995.13 -37985.14 -37980.45 -37976.16 -37968.39 #> tau                   0.13    0.00 0.04      0.06      0.10      0.12      0.15      0.23 #>                  n_eff Rhat #> d[ACE Inhibitor]  2057    1 #> d[ARB]            2483    1 #> d[CCB]            2448    1 #> d[Diuretic]       2279    1 #> d[Placebo]        1870    1 #> lp__              1032    1 #> tau               1053    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:35:16 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(db_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(db_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Diabetes","text":"Model fit can checked using dic() function: FE model poor fit data, residual deviance much higher number data points. RE model fits data better, much lower DIC; prefer RE model. can also examine residual deviance contributions corresponding plot() method.","code":"(dic_FE <- dic(db_fit_FE)) #> Residual deviance: 78.2 (on 48 data points) #>                pD: 27 #>               DIC: 105.2 (dic_RE <- dic(db_fit_RE)) #> Residual deviance: 53.5 (on 48 data points) #>                pD: 38.2 #>               DIC: 91.7 plot(dic_FE) plot(dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_diabetes.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Diabetes","text":"comparison Elliott Meyer (2007) Dias et al. (2011), can produce relative effects “Diuretic” using relative_effects() function trt_ref = \"Diuretic\":   Dias et al. (2011) produce absolute predictions probability developing diabetes three years, assuming Normal distribution baseline cloglog probability developing diabetes diuretic treatment mean −4.2-4.2 precision 1.111.11. can replicate results using predict() method. specify data frame newdata, containing time offset(s) produce predictions (3 years). baseline argument takes distr() distribution object specify corresponding Normal distribution baseline cloglog probability, set baseline_trt = \"Diuretic\" indicate baseline distribution corresponds “Diuretic” rather network reference “Beta Blocker”. set type = \"response\" produce predicted event probabilities (type = \"link\" produce predicted cloglog probabilities).   baseline newdata arguments omitted, predicted probabilities produced every study network based follow-times estimated baseline cloglog probabilities μj\\mu_j:  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(db_releff_FE <- relative_effects(db_fit_FE, trt_ref = \"Diuretic\")) #>                   mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Beta Blocker]  -0.05 0.06 -0.16 -0.09 -0.06 -0.02  0.05     1895     2372    1 #> d[ACE Inhibitor] -0.36 0.05 -0.46 -0.39 -0.36 -0.32 -0.26     5041     3299    1 #> d[ARB]           -0.45 0.06 -0.58 -0.50 -0.45 -0.41 -0.33     4056     3578    1 #> d[CCB]           -0.25 0.05 -0.35 -0.29 -0.25 -0.22 -0.15     3358     3133    1 #> d[Placebo]       -0.25 0.06 -0.36 -0.28 -0.25 -0.21 -0.14     4578     3624    1 plot(db_releff_FE, ref_line = 0) (db_releff_RE <- relative_effects(db_fit_RE, trt_ref = \"Diuretic\")) #>                   mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Beta Blocker]  -0.07 0.09 -0.25 -0.13 -0.07 -0.01  0.10     2296     2559    1 #> d[ACE Inhibitor] -0.40 0.09 -0.58 -0.46 -0.40 -0.35 -0.24     4614     2802    1 #> d[ARB]           -0.47 0.11 -0.70 -0.54 -0.47 -0.40 -0.27     4229     2794    1 #> d[CCB]           -0.24 0.08 -0.41 -0.30 -0.24 -0.19 -0.08     4094     3073    1 #> d[Placebo]       -0.29 0.09 -0.48 -0.35 -0.29 -0.23 -0.12     4296     3191    1 plot(db_releff_RE, ref_line = 0) db_pred_FE <- predict(db_fit_FE,                        newdata = data.frame(time = 3),                       baseline = distr(qnorm, mean = -4.2, sd = 1.11^-0.5),                        baseline_trt = \"Diuretic\",                       type = \"response\") db_pred_FE #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: Beta Blocker]  0.06 0.06 0.01 0.02 0.04 0.08  0.22     4072     3918    1 #> pred[New 1: ACE Inhibitor] 0.05 0.05 0.01 0.02 0.03 0.06  0.17     4089     3919    1 #> pred[New 1: ARB]           0.04 0.04 0.00 0.02 0.03 0.05  0.16     4034     3878    1 #> pred[New 1: CCB]           0.05 0.05 0.01 0.02 0.03 0.06  0.19     4072     3919    1 #> pred[New 1: Diuretic]      0.06 0.06 0.01 0.02 0.04 0.08  0.23     4064     3878    1 #> pred[New 1: Placebo]       0.05 0.05 0.01 0.02 0.03 0.06  0.19     4065     3879    1 plot(db_pred_FE) db_pred_RE <- predict(db_fit_RE,                        newdata = data.frame(time = 3),                       baseline = distr(qnorm, mean = -4.2, sd = 1.11^-0.5),                        baseline_trt = \"Diuretic\",                       type = \"response\") db_pred_RE #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: Beta Blocker]  0.06 0.07 0.01 0.02 0.04 0.08  0.25     4344     4017    1 #> pred[New 1: ACE Inhibitor] 0.05 0.05 0.00 0.02 0.03 0.06  0.19     4355     3868    1 #> pred[New 1: ARB]           0.04 0.05 0.00 0.01 0.03 0.05  0.17     4349     3770    1 #> pred[New 1: CCB]           0.05 0.06 0.01 0.02 0.04 0.07  0.21     4358     3918    1 #> pred[New 1: Diuretic]      0.07 0.07 0.01 0.02 0.04 0.08  0.26     4365     3649    1 #> pred[New 1: Placebo]       0.05 0.06 0.01 0.02 0.03 0.06  0.20     4351     3892    1 plot(db_pred_RE) db_pred_RE_studies <- predict(db_fit_RE, type = \"response\") db_pred_RE_studies #> ------------------------------------------------------------------- Study: AASK ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[AASK: Beta Blocker]  0.17 0.02 0.14 0.16 0.17 0.18  0.20     5856     3012    1 #> pred[AASK: ACE Inhibitor] 0.12 0.01 0.10 0.12 0.12 0.13  0.15     4212     3415    1 #> pred[AASK: ARB]           0.12 0.01 0.09 0.11 0.12 0.13  0.15     4173     3318    1 #> pred[AASK: CCB]           0.15 0.01 0.12 0.14 0.14 0.15  0.18     5456     3418    1 #> pred[AASK: Diuretic]      0.18 0.02 0.14 0.17 0.18 0.19  0.22     3857     2770    1 #> pred[AASK: Placebo]       0.14 0.02 0.11 0.13 0.14 0.15  0.17     3806     3221    1 #>  #> ----------------------------------------------------------------- Study: ALLHAT ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ALLHAT: Beta Blocker]  0.04 0.01 0.03 0.04 0.04 0.05  0.05     2788     2474    1 #> pred[ALLHAT: ACE Inhibitor] 0.03 0.00 0.02 0.03 0.03 0.03  0.04     3825     2905    1 #> pred[ALLHAT: ARB]           0.03 0.00 0.02 0.03 0.03 0.03  0.04     3956     2890    1 #> pred[ALLHAT: CCB]           0.04 0.00 0.03 0.03 0.04 0.04  0.05     3700     2577    1 #> pred[ALLHAT: Diuretic]      0.05 0.01 0.04 0.04 0.05 0.05  0.06     4129     2922    1 #> pred[ALLHAT: Placebo]       0.03 0.00 0.03 0.03 0.03 0.04  0.04     4004     2975    1 #>  #> ----------------------------------------------------------------- Study: ALPINE ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ALPINE: Beta Blocker]  0.03 0.01 0.01 0.02 0.03 0.03  0.05     6620     2912    1 #> pred[ALPINE: ACE Inhibitor] 0.02 0.01 0.01 0.01 0.02 0.02  0.03     6889     3386    1 #> pred[ALPINE: ARB]           0.02 0.01 0.01 0.01 0.02 0.02  0.03     7425     3148    1 #> pred[ALPINE: CCB]           0.02 0.01 0.01 0.02 0.02 0.03  0.04     6995     3191    1 #> pred[ALPINE: Diuretic]      0.03 0.01 0.01 0.02 0.03 0.03  0.05     7301     2646    1 #> pred[ALPINE: Placebo]       0.02 0.01 0.01 0.02 0.02 0.03  0.04     7178     3340    1 #>  #> ----------------------------------------------------------------- Study: ANBP-2 ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ANBP-2: Beta Blocker]  0.07 0.01 0.05 0.06 0.07 0.07  0.09     3256     3085    1 #> pred[ANBP-2: ACE Inhibitor] 0.05 0.01 0.04 0.04 0.05 0.05  0.06     4712     2832    1 #> pred[ANBP-2: ARB]           0.05 0.01 0.03 0.04 0.05 0.05  0.06     4132     2487    1 #> pred[ANBP-2: CCB]           0.06 0.01 0.04 0.05 0.06 0.06  0.08     4179     2957    1 #> pred[ANBP-2: Diuretic]      0.07 0.01 0.06 0.07 0.07 0.08  0.09     4963     3098    1 #> pred[ANBP-2: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     4525     2928    1 #>  #> ------------------------------------------------------------------ Study: ASCOT ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ASCOT: Beta Blocker]  0.11 0.00 0.10 0.11 0.11 0.11  0.12     5333     2649    1 #> pred[ASCOT: ACE Inhibitor] 0.08 0.01 0.07 0.08 0.08 0.09  0.10     2443     2771    1 #> pred[ASCOT: ARB]           0.08 0.01 0.06 0.07 0.08 0.08  0.09     2712     2415    1 #> pred[ASCOT: CCB]           0.10 0.01 0.08 0.09 0.10 0.10  0.11     2756     3189    1 #> pred[ASCOT: Diuretic]      0.12 0.01 0.10 0.11 0.12 0.13  0.14     2466     2684    1 #> pred[ASCOT: Placebo]       0.09 0.01 0.08 0.09 0.09 0.10  0.11     2163     2352    1 #>  #> ------------------------------------------------------------------ Study: CAPPP ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[CAPPP: Beta Blocker]  0.07 0.00 0.07 0.07 0.07 0.08  0.08     4746     2697    1 #> pred[CAPPP: ACE Inhibitor] 0.05 0.00 0.05 0.05 0.05 0.06  0.06     2342     2517    1 #> pred[CAPPP: ARB]           0.05 0.01 0.04 0.05 0.05 0.05  0.06     2797     2515    1 #> pred[CAPPP: CCB]           0.06 0.00 0.05 0.06 0.06 0.07  0.07     3082     2980    1 #> pred[CAPPP: Diuretic]      0.08 0.01 0.07 0.08 0.08 0.08  0.10     2727     2647    1 #> pred[CAPPP: Placebo]       0.06 0.01 0.05 0.06 0.06 0.06  0.07     2199     2583    1 #>  #> ------------------------------------------------------------------ Study: CHARM ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[CHARM: Beta Blocker]  0.09 0.01 0.07 0.08 0.09 0.10  0.12     2847     2184    1 #> pred[CHARM: ACE Inhibitor] 0.07 0.01 0.05 0.06 0.07 0.07  0.09     4152     2493    1 #> pred[CHARM: ARB]           0.06 0.01 0.05 0.06 0.06 0.07  0.08     4657     2744    1 #> pred[CHARM: CCB]           0.08 0.01 0.06 0.07 0.08 0.08  0.10     3660     2636    1 #> pred[CHARM: Diuretic]      0.10 0.01 0.07 0.09 0.10 0.11  0.13     4246     2150    1 #> pred[CHARM: Placebo]       0.07 0.01 0.06 0.07 0.07 0.08  0.09     4524     2869    1 #>  #> ------------------------------------------------------------------ Study: DREAM ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[DREAM: Beta Blocker]  0.23 0.03 0.18 0.21 0.23 0.25  0.29     2903     2425    1 #> pred[DREAM: ACE Inhibitor] 0.17 0.02 0.13 0.16 0.17 0.18  0.21     4455     2468    1 #> pred[DREAM: ARB]           0.16 0.02 0.12 0.15 0.16 0.17  0.21     4566     1902    1 #> pred[DREAM: CCB]           0.20 0.03 0.15 0.18 0.19 0.21  0.26     4181     2786    1 #> pred[DREAM: Diuretic]      0.24 0.03 0.19 0.22 0.24 0.26  0.31     4122     2720    1 #> pred[DREAM: Placebo]       0.19 0.02 0.15 0.17 0.19 0.20  0.24     4520     2496    1 #>  #> ------------------------------------------------------------------- Study: EWPH ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[EWPH: Beta Blocker]  0.06 0.01 0.04 0.05 0.06 0.07  0.09     4138     2774    1 #> pred[EWPH: ACE Inhibitor] 0.05 0.01 0.03 0.04 0.04 0.05  0.06     5362     2974    1 #> pred[EWPH: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     5205     3233    1 #> pred[EWPH: CCB]           0.05 0.01 0.04 0.05 0.05 0.06  0.07     5099     3149    1 #> pred[EWPH: Diuretic]      0.07 0.01 0.04 0.06 0.07 0.07  0.09     5204     2824    1 #> pred[EWPH: Placebo]       0.05 0.01 0.03 0.04 0.05 0.06  0.07     5542     3284    1 #>  #> ------------------------------------------------------------------ Study: FEVER ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[FEVER: Beta Blocker]  0.04 0.01 0.03 0.04 0.04 0.04  0.05     3362     2938    1 #> pred[FEVER: ACE Inhibitor] 0.03 0.00 0.02 0.03 0.03 0.03  0.04     5056     2710    1 #> pred[FEVER: ARB]           0.03 0.00 0.02 0.03 0.03 0.03  0.04     4880     2731    1 #> pred[FEVER: CCB]           0.04 0.00 0.03 0.03 0.03 0.04  0.05     4887     2850    1 #> pred[FEVER: Diuretic]      0.04 0.01 0.03 0.04 0.04 0.05  0.06     4819     2987    1 #> pred[FEVER: Placebo]       0.03 0.00 0.02 0.03 0.03 0.04  0.04     5062     2595    1 #>  #> ----------------------------------------------------------------- Study: HAPPHY ----  #>  #>                             mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[HAPPHY: Beta Blocker]  0.02  0 0.02 0.02 0.02 0.03  0.03     5325     3139    1 #> pred[HAPPHY: ACE Inhibitor] 0.02  0 0.01 0.02 0.02 0.02  0.02     4392     3108    1 #> pred[HAPPHY: ARB]           0.02  0 0.01 0.02 0.02 0.02  0.02     4056     3239    1 #> pred[HAPPHY: CCB]           0.02  0 0.02 0.02 0.02 0.02  0.03     5196     3012    1 #> pred[HAPPHY: Diuretic]      0.03  0 0.02 0.02 0.03 0.03  0.03     3741     2871    1 #> pred[HAPPHY: Placebo]       0.02  0 0.02 0.02 0.02 0.02  0.02     3786     3426    1 #>  #> ------------------------------------------------------------------- Study: HOPE ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[HOPE: Beta Blocker]  0.06 0.01 0.04 0.05 0.06 0.06  0.08     2953     2322    1 #> pred[HOPE: ACE Inhibitor] 0.04 0.01 0.03 0.04 0.04 0.05  0.05     4718     2868    1 #> pred[HOPE: ARB]           0.04 0.01 0.03 0.04 0.04 0.04  0.05     4014     2932    1 #> pred[HOPE: CCB]           0.05 0.01 0.04 0.04 0.05 0.05  0.07     3985     2961    1 #> pred[HOPE: Diuretic]      0.06 0.01 0.05 0.06 0.06 0.07  0.08     4310     2846    1 #> pred[HOPE: Placebo]       0.05 0.01 0.04 0.04 0.05 0.05  0.06     5317     2758    1 #>  #> ---------------------------------------------------------------- Study: INSIGHT ----  #>  #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[INSIGHT: Beta Blocker]  0.07 0.01 0.05 0.06 0.06 0.07  0.09     3484     2451    1 #> pred[INSIGHT: ACE Inhibitor] 0.05 0.01 0.03 0.04 0.05 0.05  0.06     4837     2841    1 #> pred[INSIGHT: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     4916     2970    1 #> pred[INSIGHT: CCB]           0.06 0.01 0.04 0.05 0.05 0.06  0.07     4759     2671    1 #> pred[INSIGHT: Diuretic]      0.07 0.01 0.05 0.06 0.07 0.08  0.09     5373     2697    1 #> pred[INSIGHT: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     4770     2832    1 #>  #> ----------------------------------------------------------------- Study: INVEST ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[INVEST: Beta Blocker]  0.08 0.00 0.08 0.08 0.08 0.08  0.09     7397     3036    1 #> pred[INVEST: ACE Inhibitor] 0.06 0.00 0.05 0.06 0.06 0.06  0.07     2489     2730    1 #> pred[INVEST: ARB]           0.06 0.01 0.05 0.05 0.06 0.06  0.07     2806     2645    1 #> pred[INVEST: CCB]           0.07 0.00 0.06 0.07 0.07 0.07  0.08     3012     2530    1 #> pred[INVEST: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.09  0.11     2722     2775    1 #> pred[INVEST: Placebo]       0.07 0.01 0.06 0.06 0.07 0.07  0.08     2177     2229    1 #>  #> ------------------------------------------------------------------- Study: LIFE ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[LIFE: Beta Blocker]  0.08 0.00 0.07 0.08 0.08 0.08  0.09     6892     2730    1 #> pred[LIFE: ACE Inhibitor] 0.06 0.01 0.05 0.06 0.06 0.06  0.07     2738     2732    1 #> pred[LIFE: ARB]           0.06 0.01 0.05 0.05 0.06 0.06  0.07     2755     2209    1 #> pred[LIFE: CCB]           0.07 0.01 0.06 0.07 0.07 0.07  0.08     3356     2668    1 #> pred[LIFE: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.09  0.11     2815     2952    1 #> pred[LIFE: Placebo]       0.07 0.01 0.05 0.06 0.07 0.07  0.08     2434     2256    1 #>  #> ------------------------------------------------------------------ Study: MRC-E ----  #>  #>                            mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[MRC-E: Beta Blocker]  0.03  0 0.02 0.03 0.03 0.03  0.04     3892     2891    1 #> pred[MRC-E: ACE Inhibitor] 0.02  0 0.02 0.02 0.02 0.02  0.03     5151     3090    1 #> pred[MRC-E: ARB]           0.02  0 0.02 0.02 0.02 0.02  0.03     4746     3323    1 #> pred[MRC-E: CCB]           0.03  0 0.02 0.02 0.02 0.03  0.03     4712     2926    1 #> pred[MRC-E: Diuretic]      0.03  0 0.02 0.03 0.03 0.03  0.04     4156     3186    1 #> pred[MRC-E: Placebo]       0.02  0 0.02 0.02 0.02 0.03  0.03     4694     2919    1 #>  #> ----------------------------------------------------------------- Study: NORDIL ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[NORDIL: Beta Blocker]  0.05 0.00 0.04 0.05 0.05 0.05  0.06     6409     3060    1 #> pred[NORDIL: ACE Inhibitor] 0.04 0.00 0.03 0.03 0.04 0.04  0.04     3032     2857    1 #> pred[NORDIL: ARB]           0.03 0.00 0.03 0.03 0.03 0.04  0.04     3344     2688    1 #> pred[NORDIL: CCB]           0.04 0.00 0.04 0.04 0.04 0.04  0.05     3646     2922    1 #> pred[NORDIL: Diuretic]      0.05 0.01 0.04 0.05 0.05 0.06  0.06     2999     2891    1 #> pred[NORDIL: Placebo]       0.04 0.00 0.03 0.04 0.04 0.04  0.05     2516     2892    1 #>  #> ------------------------------------------------------------------ Study: PEACE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[PEACE: Beta Blocker]  0.14 0.02 0.10 0.13 0.14 0.15  0.18     3180     2612    1 #> pred[PEACE: ACE Inhibitor] 0.10 0.01 0.08 0.09 0.10 0.11  0.13     4810     2940    1 #> pred[PEACE: ARB]           0.09 0.01 0.07 0.09 0.09 0.10  0.13     4642     2739    1 #> pred[PEACE: CCB]           0.12 0.02 0.09 0.11 0.12 0.13  0.15     4228     2993    1 #> pred[PEACE: Diuretic]      0.15 0.02 0.11 0.13 0.15 0.16  0.19     4225     2777    1 #> pred[PEACE: Placebo]       0.11 0.01 0.09 0.10 0.11 0.12  0.14     5101     2912    1 #>  #> ------------------------------------------------------------------ Study: SCOPE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[SCOPE: Beta Blocker]  0.06 0.01 0.05 0.06 0.06 0.07  0.09     3469     2867    1 #> pred[SCOPE: ACE Inhibitor] 0.05 0.01 0.03 0.04 0.05 0.05  0.06     4796     3170    1 #> pred[SCOPE: ARB]           0.04 0.01 0.03 0.04 0.04 0.05  0.06     5110     2735    1 #> pred[SCOPE: CCB]           0.06 0.01 0.04 0.05 0.05 0.06  0.08     4690     2561    1 #> pred[SCOPE: Diuretic]      0.07 0.01 0.05 0.06 0.07 0.08  0.09     4700     2806    1 #> pred[SCOPE: Placebo]       0.05 0.01 0.04 0.05 0.05 0.06  0.07     5227     2991    1 #>  #> ------------------------------------------------------------------- Study: SHEP ----  #>  #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[SHEP: Beta Blocker]  0.09 0.01 0.06 0.08 0.09 0.09  0.11     3100     2510    1 #> pred[SHEP: ACE Inhibitor] 0.06 0.01 0.05 0.06 0.06 0.07  0.08     5233     2717    1 #> pred[SHEP: ARB]           0.06 0.01 0.04 0.05 0.06 0.06  0.08     4727     2877    1 #> pred[SHEP: CCB]           0.07 0.01 0.05 0.07 0.07 0.08  0.10     4437     3048    1 #> pred[SHEP: Diuretic]      0.09 0.01 0.07 0.08 0.09 0.10  0.12     4830     2836    1 #> pred[SHEP: Placebo]       0.07 0.01 0.05 0.06 0.07 0.08  0.09     5354     3210    1 #>  #> ----------------------------------------------------------------- Study: STOP-2 ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[STOP-2: Beta Blocker]  0.05 0.00 0.05 0.05 0.05 0.06  0.06     5026     2962    1 #> pred[STOP-2: ACE Inhibitor] 0.04 0.00 0.03 0.04 0.04 0.04  0.05     3322     3121    1 #> pred[STOP-2: ARB]           0.04 0.00 0.03 0.03 0.04 0.04  0.04     3328     3196    1 #> pred[STOP-2: CCB]           0.05 0.00 0.04 0.04 0.05 0.05  0.05     4536     3268    1 #> pred[STOP-2: Diuretic]      0.06 0.01 0.05 0.05 0.06 0.06  0.07     4019     3019    1 #> pred[STOP-2: Placebo]       0.04 0.00 0.03 0.04 0.04 0.05  0.05     3010     2734    1 #>  #> ------------------------------------------------------------------ Study: VALUE ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[VALUE: Beta Blocker]  0.20 0.02 0.15 0.18 0.19 0.21  0.25     3245     2085    1 #> pred[VALUE: ACE Inhibitor] 0.15 0.02 0.11 0.13 0.14 0.16  0.19     4617     2685    1 #> pred[VALUE: ARB]           0.14 0.02 0.10 0.13 0.13 0.15  0.17     4516     2850    1 #> pred[VALUE: CCB]           0.17 0.02 0.13 0.16 0.17 0.18  0.21     4583     2311    1 #> pred[VALUE: Diuretic]      0.21 0.03 0.16 0.19 0.21 0.22  0.27     4294     2406    1 #> pred[VALUE: Placebo]       0.16 0.02 0.12 0.15 0.16 0.17  0.21     4569     2700    1 plot(db_pred_RE_studies) (db_ranks <- posterior_ranks(db_fit_RE)) #>                     mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[Beta Blocker]  5.19 0.42    5   5   5   5     6     2951       NA    1 #> rank[ACE Inhibitor] 1.84 0.55    1   2   2   2     3     4176     3265    1 #> rank[ARB]           1.27 0.51    1   1   1   1     2     3740     3305    1 #> rank[CCB]           3.70 0.51    3   3   4   4     4     3664     3461    1 #> rank[Diuretic]      5.80 0.41    5   6   6   6     6     2907       NA    1 #> rank[Placebo]       3.20 0.59    2   3   3   4     4     3404     2810    1 plot(db_ranks) (db_rankprobs <- posterior_rank_probs(db_fit_RE)) #>                  p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[Beta Blocker]       0.00      0.00      0.00      0.01      0.79       0.2 #> d[ACE Inhibitor]      0.23      0.70      0.06      0.01      0.00       0.0 #> d[ARB]                0.76      0.22      0.02      0.00      0.00       0.0 #> d[CCB]                0.00      0.02      0.27      0.70      0.01       0.0 #> d[Diuretic]           0.00      0.00      0.00      0.00      0.19       0.8 #> d[Placebo]            0.00      0.07      0.65      0.27      0.00       0.0 plot(db_rankprobs) (db_cumrankprobs <- posterior_rank_probs(db_fit_RE, cumulative = TRUE)) #>                  p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[Beta Blocker]       0.00      0.00      0.00      0.01       0.8         1 #> d[ACE Inhibitor]      0.23      0.93      0.99      1.00       1.0         1 #> d[ARB]                0.76      0.98      1.00      1.00       1.0         1 #> d[CCB]                0.00      0.02      0.29      0.99       1.0         1 #> d[Diuretic]           0.00      0.00      0.00      0.00       0.2         1 #> d[Placebo]            0.00      0.08      0.72      1.00       1.0         1 plot(db_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Dietary fat","text":"begin setting network - just pairwise meta-analysis. arm-level rate data giving number deaths (r) person-years risk (E) arm, use function set_agd_arm(). set “Control” reference treatment. also specify optional sample_size argument, although strictly necessary . case sample_size required produce network plot nodes weighted sample size, network plot particularly informative meta-analysis two treatments. (sample_size argument important regression model specified, since also enables automatic centering predictors production predictions studies network, see ?set_agd_arm.)","code":"diet_net <- set_agd_arm(dietary_fat,                          study = studyc,                         trt = trtc,                         r = r,                          E = E,                         trt_ref = \"Control\",                         sample_size = n) diet_net #> A network with 10 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study                   Treatment arms                         #>  DART                    2: Control | Reduced Fat               #>  London Corn/Olive       3: Control | Reduced Fat | Reduced Fat #>  London Low Fat          2: Control | Reduced Fat               #>  Minnesota Coronary      2: Control | Reduced Fat               #>  MRC Soya                2: Control | Reduced Fat               #>  Oslo Diet-Heart         2: Control | Reduced Fat               #>  STARS                   2: Control | Reduced Fat               #>  Sydney Diet-Heart       2: Control | Reduced Fat               #>  Veterans Administration 2: Control | Reduced Fat               #>  Veterans Diet & Skin CA 2: Control | Reduced Fat               #>  #>  Outcome type: rate #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 10 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Dietary fat","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Dietary fat","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k study-specific intercepts μj\\mu_j. can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Poisson likelihood log link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. diet_fit_FE <- nma(diet_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) #> / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.04 seconds (Warm-up) #> Chain 1:                0.03 seconds (Sampling) #> Chain 1:                0.07 seconds (Total) #> Chain 1:  #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.04 seconds (Warm-up) #> Chain 2:                0.03 seconds (Sampling) #> Chain 2:                0.07 seconds (Total) #> Chain 2:  #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.041 seconds (Warm-up) #> Chain 3:                0.029 seconds (Sampling) #> Chain 3:                0.07 seconds (Total) #> Chain 3: diet_fit_FE #> A fixed effects NMA with a poisson likelihood (log link). #> Inference for Stan model: poisson. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Reduced Fat]   -0.01    0.00 0.05   -0.11   -0.04   -0.01    0.03    0.10  3568    1 #> lp__           5386.16    0.06 2.49 5380.38 5384.77 5386.50 5387.97 5389.91  1586    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:35:29 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(diet_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(diet_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Dietary fat","text":"now fit random effects model using nma() function trt_effects = \"random\". , use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k study-specific intercepts μj\\mu_j, additionally use half-N(52)\\textrm{half-N}(5^2) prior heterogeneity standard deviation τ\\tau. can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. diet_fit_RE <- nma(diet_net,                     trt_effects = \"random\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_het = half_normal(scale = 5)) #>  2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.187 seconds (Warm-up) #> Chain 1:                0.146 seconds (Sampling) #> Chain 1:                0.333 seconds (Total) #> Chain 1:  #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.187 seconds (Warm-up) #> Chain 2:                0.147 seconds (Sampling) #> Chain 2:                0.334 seconds (Total) #> Chain 2:  #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.194 seconds (Warm-up) #> Chain 3:                0.155 seconds (Sampling) #> Chain 3:                0.349 seconds (Total) #> Chain 3: diet_fit_RE #> A random effects NMA with a poisson likelihood (log link). #> Inference for Stan model: poisson. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Reduced Fat]   -0.02    0.00 0.09   -0.19   -0.06   -0.02    0.03    0.15  1581    1 #> lp__           5379.23    0.11 3.74 5371.41 5376.76 5379.38 5381.88 5385.92  1217    1 #> tau               0.13    0.00 0.12    0.01    0.05    0.10    0.18    0.45   819    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:35:33 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(diet_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(diet_fit_RE, prior = c(\"trt\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Dietary fat","text":"Model fit can checked using dic() function: models appear fit data well, residual deviance close number data points. DIC similar models, FE model may preferred parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(dic_FE <- dic(diet_fit_FE)) #> Residual deviance: 22.5 (on 21 data points) #>                pD: 11.3 #>               DIC: 33.8 (dic_RE <- dic(diet_fit_RE)) #> Residual deviance: 21.4 (on 21 data points) #>                pD: 13.5 #>               DIC: 34.9 plot(dic_FE) plot(dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_dietary_fat.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Dietary fat","text":"Dias et al. (2011) produce absolute predictions mortality rates reduced fat control diets, assuming Normal distribution baseline log rate mortality mean −3-3 precision 1.771.77. can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted rates (type = \"link\" produce predicted log rates).   baseline argument omitted, predicted rates produced every study network based estimated baseline log rate μj\\mu_j:","code":"pred_FE <- predict(diet_fit_FE,                     baseline = distr(qnorm, mean = -3, sd = 1.77^-0.5),                     type = \"response\") pred_FE #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]     0.06 0.05 0.01 0.03 0.05 0.08  0.21     4142     3904    1 #> pred[Reduced Fat] 0.06 0.05 0.01 0.03 0.05 0.08  0.21     4118     3909    1 plot(pred_FE) pred_RE <- predict(diet_fit_RE,                     baseline = distr(qnorm, mean = -3, sd = 1.77^-0.5),                     type = \"response\") pred_RE #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Control]     0.07 0.06 0.01 0.03 0.05 0.08  0.22     4379     3576    1 #> pred[Reduced Fat] 0.07 0.06 0.01 0.03 0.05 0.08  0.21     4394     3531    1 plot(pred_RE) pred_FE_studies <- predict(diet_fit_FE, type = \"response\") pred_FE_studies #> ------------------------------------------------------------------- Study: DART ----  #>  #>                         mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[DART: Control]     0.06  0 0.05 0.06 0.06 0.06  0.07     6187     3190    1 #> pred[DART: Reduced Fat] 0.06  0 0.05 0.06 0.06 0.06  0.07     7818     3376    1 #>  #> ------------------------------------------------------ Study: London Corn/Olive ----  #>  #>                                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[London Corn/Olive: Control]     0.07 0.03 0.03 0.06 0.07 0.09  0.13     8422     3035 #> pred[London Corn/Olive: Reduced Fat] 0.07 0.02 0.03 0.06 0.07 0.09  0.13     8512     3110 #>                                      Rhat #> pred[London Corn/Olive: Control]        1 #> pred[London Corn/Olive: Reduced Fat]    1 #>  #> --------------------------------------------------------- Study: London Low Fat ----  #>  #>                                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[London Low Fat: Control]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     7697     2749    1 #> pred[London Low Fat: Reduced Fat] 0.06 0.01 0.04 0.05 0.06 0.06  0.08     8588     2715    1 #>  #> ----------------------------------------------------- Study: Minnesota Coronary ----  #>  #>                                       mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Minnesota Coronary: Control]     0.05  0 0.05 0.05 0.05 0.06  0.06     5035     3586    1 #> pred[Minnesota Coronary: Reduced Fat] 0.05  0 0.05 0.05 0.05 0.06  0.06     6263     3698    1 #>  #> --------------------------------------------------------------- Study: MRC Soya ----  #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[MRC Soya: Control]     0.04 0.01 0.03 0.04 0.04 0.04  0.05     7530     2448    1 #> pred[MRC Soya: Reduced Fat] 0.04 0.01 0.03 0.04 0.04 0.04  0.05     8515     2983    1 #>  #> -------------------------------------------------------- Study: Oslo Diet-Heart ----  #>  #>                                    mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Oslo Diet-Heart: Control]     0.06 0.01 0.05 0.06 0.06 0.07  0.08     6664     3113    1 #> pred[Oslo Diet-Heart: Reduced Fat] 0.06 0.01 0.05 0.06 0.06 0.07  0.08     8209     3279    1 #>  #> ------------------------------------------------------------------ Study: STARS ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[STARS: Control]     0.02 0.01 0.01 0.01 0.02 0.03  0.05     6720     2887    1 #> pred[STARS: Reduced Fat] 0.02 0.01 0.01 0.01 0.02 0.03  0.05     6802     2867    1 #>  #> ------------------------------------------------------ Study: Sydney Diet-Heart ----  #>  #>                                      mean sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Sydney Diet-Heart: Control]     0.03  0 0.03 0.03 0.03 0.04  0.04     7106     2707    1 #> pred[Sydney Diet-Heart: Reduced Fat] 0.03  0 0.03 0.03 0.03 0.04  0.04     7635     2816    1 #>  #> ------------------------------------------------ Study: Veterans Administration ----  #>  #>                                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Veterans Administration: Control]     0.11 0.01  0.1 0.11 0.11 0.12  0.13     5091 #> pred[Veterans Administration: Reduced Fat] 0.11 0.01  0.1 0.11 0.11 0.12  0.12     6910 #>                                            Tail_ESS Rhat #> pred[Veterans Administration: Control]         3139    1 #> pred[Veterans Administration: Reduced Fat]     3250    1 #>  #> ------------------------------------------------ Study: Veterans Diet & Skin CA ----  #>  #>                                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Veterans Diet & Skin CA: Control]     0.01 0.01    0 0.01 0.01 0.02  0.03     5371 #> pred[Veterans Diet & Skin CA: Reduced Fat] 0.01 0.01    0 0.01 0.01 0.02  0.03     5342 #>                                            Tail_ESS Rhat #> pred[Veterans Diet & Skin CA: Control]         2466    1 #> pred[Veterans Diet & Skin CA: Reduced Fat]     2556    1 plot(pred_FE_studies) + ggplot2::facet_grid(Study~., labeller = ggplot2::label_wrap_gen(width = 10))"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Plaque psoriasis HTA report","text":"begin setting network. arm-level ordered multinomial count data, use function set_agd_arm(). function multi() helps us specify ordered outcomes correctly. Plot network structure.","code":"pso_net <- set_agd_arm(hta_psoriasis,                         study = paste(studyc, year),                         trt = trtc,                         r = multi(r0 = sample_size - rowSums(cbind(PASI50, PASI75, PASI90), na.rm = TRUE),                                   PASI50, PASI75, PASI90,                                  inclusive = FALSE,                                   type = \"ordered\")) pso_net #> A network with 16 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                           #>  ACD2058g 2004 2: Supportive care | Efalizumab                          #>  ACD2600g 2004 2: Supportive care | Efalizumab                          #>  Altmeyer 1994 2: Supportive care | Fumaderm                            #>  Chaudari 2001 2: Supportive care | Infliximab                          #>  Elewski 2004  3: Supportive care | Etanercept 25 mg | Etanercept 50 mg #>  Ellis 1991    3: Supportive care | Ciclosporin | Ciclosporin           #>  Gordon 2003   2: Supportive care | Efalizumab                          #>  Gottlieb 2003 2: Supportive care | Etanercept 25 mg                    #>  Gottlieb 2004 3: Supportive care | Infliximab | Infliximab             #>  Guenther 1991 2: Supportive care | Ciclosporin                         #>  ... plus 6 more studies #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 8 #> Total number of studies: 16 #> Reference treatment is: Supportive care #> Network is connected plot(pso_net, weight_edges = TRUE, weight_nodes = TRUE) +    # Nudge the legend over   ggplot2::theme(legend.box.spacing = ggplot2::unit(0.75, \"in\"),                  plot.margin = ggplot2::margin(0.1, 0, 0.1, 0.75, \"in\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Plaque psoriasis HTA report","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Plaque psoriasis HTA report","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\", using probit link function link = \"probit\". use N(0,102)\\mathrm{N}(0, 10^2) prior distributions treatment effects dkd_k, N(0,1002)\\mathrm{N}(0, 100^2) prior distributions study-specific intercepts μj\\mu_j. can examine range parameter values implied prior distributions summary() method: also need specify prior distributions latent cutpoints cPASI75c_\\textrm{PASI75} cPASI90c_\\textrm{PASI90} underlying scale - PASI standardised mean difference due probit link (cutpoint cPASI50=0c_\\textrm{PASI50}=0). make easier reason , actually specify priors differences adjacent cutpoints, e.g. cPASI90−cPASI75c_\\textrm{PASI90} - c_\\textrm{PASI75} cPASI75−cPASI50c_\\textrm{PASI75} - c_\\textrm{PASI50}. can given positive-valued prior distribution, Stan automatically impose necessary ordering constraints behind scenes. choose give implicit flat priors flat(). model fitted using nma() function. Basic parameter summaries given print() method: Note: treatment effects opposite sign TSD 2 (Dias et al. 2011). parameterise linear predictor μj+dk+cm\\mu_j + d_k + c_m, rather μj+dk−cm\\mu_j + d_k - c_m. interpretation thus follows standard binomial probit (logit) regression; SMDs (log ORs) greater zero mean treatment increases probability event compared comparator (less zero mean reduction probability). higher outcomes positive, active treatments estimated increase response (.e. greater reduction) PASI scale compared network reference (supportive care). default, summaries study-specific intercepts μj\\mu_j hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Focusing specifically cutpoints see highly identified data, implicit flat priors work parameters.","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10),                   prior_aux = flat()) #> Note: Setting \"Supportive care\" as the network reference treatment. pso_fit_FE #> A fixed effects NMA with a ordered likelihood (probit link). #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff #> d[Ciclosporin]          1.92    0.01 0.33     1.31     1.68     1.91     2.14     2.61  1525 #> d[Efalizumab]           1.19    0.00 0.06     1.07     1.15     1.19     1.23     1.30  1886 #> d[Etanercept 25 mg]     1.51    0.00 0.10     1.32     1.45     1.51     1.58     1.70  2002 #> d[Etanercept 50 mg]     1.92    0.00 0.10     1.72     1.85     1.92     1.99     2.11  2100 #> d[Fumaderm]             1.48    0.01 0.48     0.63     1.14     1.44     1.78     2.49  2793 #> d[Infliximab]           2.33    0.01 0.27     1.84     2.14     2.32     2.50     2.88  2568 #> d[Methotrexate]         1.62    0.01 0.44     0.77     1.33     1.61     1.91     2.49  1833 #> lp__                -3405.05    0.09 3.52 -3412.77 -3407.19 -3404.72 -3402.54 -3399.05  1610 #> cc[PASI50]              0.00     NaN 0.00     0.00     0.00     0.00     0.00     0.00   NaN #> cc[PASI75]              0.76    0.00 0.03     0.70     0.74     0.76     0.78     0.82  5083 #> cc[PASI90]              1.56    0.00 0.05     1.46     1.53     1.56     1.60     1.67  5920 #>                     Rhat #> d[Ciclosporin]         1 #> d[Efalizumab]          1 #> d[Etanercept 25 mg]    1 #> d[Etanercept 50 mg]    1 #> d[Fumaderm]            1 #> d[Infliximab]          1 #> d[Methotrexate]        1 #> lp__                   1 #> cc[PASI50]           NaN #> cc[PASI75]             1 #> cc[PASI90]             1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:35:44 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_FE, pars = c(\"d\", \"mu\", \"cc\")) plot_prior_posterior(pso_fit_FE) plot_prior_posterior(pso_fit_FE, prior = \"aux\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Plaque psoriasis HTA report","text":"now fit random effects model using nma() function trt_effects = \"random\". , use N(0,102)\\mathrm{N}(0, 10^2) prior distributions treatment effects dkd_k, N(0,1002)\\mathrm{N}(0, 100^2) prior distributions study-specific intercepts μj\\mu_j, implicit flat prior distributions latent cutpoints, additionally use half-N(2.52)\\textrm{half-N}(2.5^2) prior heterogeneity standard deviation τ\\tau. can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 2.5)) #> A half-Normal prior distribution: location = 0, scale = 2.5. #> 50% of the prior density lies between 0 and 1.69. #> 95% of the prior density lies between 0 and 4.9. pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10),                   prior_aux = flat(),                   prior_het = half_normal(scale = 2.5),                   adapt_delta = 0.99) #> Note: Setting \"Supportive care\" as the network reference treatment. pso_fit_RE #> A random effects NMA with a ordered likelihood (probit link). #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=5000; warmup=2500; thin=1;  #> post-warmup draws per chain=2500, total post-warmup draws=10000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff #> d[Ciclosporin]          2.02    0.01 0.42     1.30     1.73     1.99     2.27     2.95  3445 #> d[Efalizumab]           1.18    0.00 0.18     0.82     1.10     1.19     1.27     1.55  4612 #> d[Etanercept 25 mg]     1.53    0.00 0.25     1.02     1.40     1.52     1.65     2.05  4159 #> d[Etanercept 50 mg]     1.93    0.00 0.27     1.35     1.80     1.93     2.06     2.51  4818 #> d[Fumaderm]             1.48    0.01 0.63     0.27     1.08     1.45     1.88     2.77  7699 #> d[Infliximab]           2.31    0.00 0.38     1.55     2.08     2.31     2.55     3.07  8199 #> d[Methotrexate]         1.70    0.01 0.62     0.54     1.30     1.67     2.07     3.00  4511 #> lp__                -3410.46    0.18 6.82 -3424.39 -3414.96 -3410.32 -3405.69 -3397.77  1372 #> tau                     0.31    0.01 0.22     0.02     0.15     0.27     0.43     0.85   947 #> cc[PASI50]              0.00     NaN 0.00     0.00     0.00     0.00     0.00     0.00   NaN #> cc[PASI75]              0.76    0.00 0.03     0.70     0.73     0.76     0.78     0.82 14642 #> cc[PASI90]              1.56    0.00 0.05     1.46     1.53     1.56     1.60     1.66 16421 #>                     Rhat #> d[Ciclosporin]      1.00 #> d[Efalizumab]       1.00 #> d[Etanercept 25 mg] 1.00 #> d[Etanercept 50 mg] 1.00 #> d[Fumaderm]         1.00 #> d[Infliximab]       1.00 #> d[Methotrexate]     1.00 #> lp__                1.00 #> tau                 1.01 #> cc[PASI50]           NaN #> cc[PASI75]          1.00 #> cc[PASI90]          1.00 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:36:32 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_RE, pars = c(\"d\", \"cc\", \"mu\", \"delta\")) plot_prior_posterior(pso_fit_RE, prior = c(\"trt\", \"aux\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"model-comparison","dir":"Articles","previous_headings":"Meta-analysis models","what":"Model comparison","title":"Example: Plaque psoriasis HTA report","text":"Model fit can checked using dic() function: random effects model lower DIC residual deviance closer number data points, preferred case. can also examine residual deviance contributions corresponding plot() method.   data points fit well, posterior mean residual deviances close degrees freedom. Meffert 1997 study substantially higher residual deviance contribution, investigated see study appears outlier.","code":"(dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 74.7 (on 58 data points) #>                pD: 25.2 #>               DIC: 100 (dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 62.6 (on 58 data points) #>                pD: 33.3 #>               DIC: 95.9 plot(dic_FE) plot(dic_RE)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"predicted-probabilities-of-response","dir":"Articles","previous_headings":"Further results","what":"Predicted probabilities of response","title":"Example: Plaque psoriasis HTA report","text":"Dias et al. (2011) produce absolute predictions probability achieving responses PASI cutoff, assuming Normal distribution baseline probit probability PASI50 response supportive care mean −1.097-1.097 precision 123123. can replicate results using predict() method. baseline argument takes distr() distribution object, specify corresponding Normal distribution. set type = \"response\" produce predicted probabilities (type = \"link\" produce predicted probit probabilities).   instead information baseline PASI 50 response probit probability PASI 50 event counts, can use construct Beta distribution baseline probability PASI 50 response. example, 56 408 individuals achieved PASI 50 response supportive care target population interest, appropriate Beta distribution response probability Beta(56,408−56)\\textrm{Beta}(56, 408-56). can specify Beta distribution baseline response using baseline_type = \"reponse\" argument (default \"link\", used baseline probit probability).  (Notice results equivalent calculated using Normal distribution baseline probit probability, since event counts correspond probit probability.) can modify plots using standard ggplot2 functions. example, plot cutpoints together colour coding (instead split facets):  baseline argument omitted, predicted probabilities produced every study network based estimated baseline probit probability μj\\mu_j.","code":"pred_FE <- predict(pso_fit_FE,                     baseline = distr(qnorm, mean = -1.097, sd = 123^-0.5),                     type = \"response\") pred_FE #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.18     3631     3432    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05     3724     3434    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01     4040     3841    1 #> pred[Ciclosporin, PASI50]      0.78 0.10 0.57 0.72 0.79 0.85  0.94     1633     2194    1 #> pred[Ciclosporin, PASI75]      0.52 0.13 0.28 0.43 0.52 0.61  0.78     1616     2120    1 #> pred[Ciclosporin, PASI90]      0.24 0.11 0.08 0.16 0.23 0.30  0.49     1646     2169    1 #> pred[Efalizumab, PASI50]       0.54 0.04 0.45 0.51 0.54 0.57  0.62     2866     3591    1 #> pred[Efalizumab, PASI75]       0.25 0.03 0.19 0.23 0.25 0.28  0.33     2948     3178    1 #> pred[Efalizumab, PASI90]       0.07 0.02 0.05 0.06 0.07 0.08  0.11     3189     3694    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.05 0.56 0.63 0.66 0.69  0.75     2515     3271    1 #> pred[Etanercept 25 mg, PASI75] 0.37 0.05 0.27 0.33 0.37 0.40  0.47     2600     3535    1 #> pred[Etanercept 25 mg, PASI90] 0.13 0.03 0.08 0.11 0.12 0.14  0.19     2802     3523    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.04 0.71 0.77 0.79 0.82  0.86     2596     3315    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.05 0.42 0.49 0.53 0.56  0.63     2689     3381    1 #> pred[Etanercept 50 mg, PASI90] 0.23 0.04 0.16 0.20 0.23 0.26  0.32     2813     3509    1 #> pred[Fumaderm, PASI50]         0.63 0.16 0.32 0.51 0.63 0.76  0.92     3142     2210    1 #> pred[Fumaderm, PASI75]         0.37 0.17 0.11 0.23 0.34 0.47  0.75     3086     2160    1 #> pred[Fumaderm, PASI90]         0.14 0.11 0.02 0.06 0.11 0.19  0.44     3055     2146    1 #> pred[Infliximab, PASI50]       0.88 0.05 0.76 0.85 0.89 0.92  0.97     2858     2694    1 #> pred[Infliximab, PASI75]       0.68 0.10 0.47 0.61 0.68 0.74  0.86     2832     2656    1 #> pred[Infliximab, PASI90]       0.37 0.10 0.19 0.30 0.37 0.44  0.60     2893     2673    1 #> pred[Methotrexate, PASI50]     0.68 0.14 0.37 0.59 0.70 0.79  0.92     1917     2382    1 #> pred[Methotrexate, PASI75]     0.42 0.16 0.14 0.30 0.41 0.52  0.74     1893     2389    1 #> pred[Methotrexate, PASI90]     0.17 0.11 0.03 0.09 0.15 0.23  0.43     1923     2344    1 plot(pred_FE) pred_RE <- predict(pso_fit_RE,                     baseline = distr(qnorm, mean = -1.097, sd = 123^-0.5),                     type = \"response\") pred_RE #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.18     9886     9993    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05    10214     9804    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01    11067     9195    1 #> pred[Ciclosporin, PASI50]      0.80 0.11 0.57 0.74 0.81 0.88  0.97     3818     3904    1 #> pred[Ciclosporin, PASI75]      0.56 0.15 0.28 0.45 0.55 0.67  0.87     3797     3762    1 #> pred[Ciclosporin, PASI90]      0.28 0.14 0.08 0.17 0.25 0.35  0.62     3867     3836    1 #> pred[Efalizumab, PASI50]       0.53 0.08 0.37 0.49 0.53 0.58  0.69     5724     4943    1 #> pred[Efalizumab, PASI75]       0.26 0.06 0.14 0.22 0.25 0.29  0.40     5807     4872    1 #> pred[Efalizumab, PASI90]       0.07 0.03 0.03 0.06 0.07 0.09  0.14     5982     5094    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.09 0.46 0.61 0.66 0.72  0.84     5290     3843    1 #> pred[Etanercept 25 mg, PASI75] 0.38 0.10 0.20 0.32 0.37 0.43  0.59     5313     3915    1 #> pred[Etanercept 25 mg, PASI90] 0.14 0.06 0.05 0.10 0.13 0.16  0.28     5338     4164    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.08 0.59 0.75 0.80 0.84  0.92     5769     3818    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.11 0.30 0.47 0.53 0.59  0.75     5785     3895    1 #> pred[Etanercept 50 mg, PASI90] 0.24 0.09 0.09 0.19 0.23 0.28  0.45     5726     3792    1 #> pred[Fumaderm, PASI50]         0.63 0.20 0.20 0.49 0.64 0.78  0.96     7901     5277    1 #> pred[Fumaderm, PASI75]         0.37 0.20 0.05 0.22 0.34 0.51  0.83     7915     5162    1 #> pred[Fumaderm, PASI90]         0.16 0.15 0.01 0.06 0.11 0.22  0.56     7948     4788    1 #> pred[Infliximab, PASI50]       0.87 0.08 0.67 0.83 0.89 0.93  0.98     8322     5613    1 #> pred[Infliximab, PASI75]       0.67 0.13 0.37 0.58 0.67 0.76  0.89     8319     5479    1 #> pred[Infliximab, PASI90]       0.37 0.14 0.13 0.28 0.36 0.46  0.66     8370     5474    1 #> pred[Methotrexate, PASI50]     0.69 0.18 0.28 0.58 0.72 0.83  0.97     4706     4457    1 #> pred[Methotrexate, PASI75]     0.44 0.21 0.09 0.29 0.42 0.59  0.88     4700     4651    1 #> pred[Methotrexate, PASI90]     0.20 0.16 0.02 0.09 0.16 0.28  0.65     4746     4506    1 plot(pred_RE) pred_FE_beta <- predict(pso_fit_FE,                          baseline = distr(qbeta, 56, 408-56),                         baseline_type = \"response\",                         type = \"response\") pred_FE_beta #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.10 0.12 0.14 0.15  0.17     3940     4002    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05     4026     3931    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01     4614     4140    1 #> pred[Ciclosporin, PASI50]      0.78 0.09 0.58 0.72 0.79 0.85  0.94     1659     2017    1 #> pred[Ciclosporin, PASI75]      0.52 0.13 0.29 0.43 0.52 0.61  0.78     1636     1987    1 #> pred[Ciclosporin, PASI90]      0.24 0.11 0.08 0.16 0.23 0.30  0.49     1669     2093    1 #> pred[Efalizumab, PASI50]       0.54 0.04 0.46 0.51 0.54 0.56  0.61     3238     3759    1 #> pred[Efalizumab, PASI75]       0.25 0.03 0.19 0.23 0.25 0.28  0.32     3276     3480    1 #> pred[Efalizumab, PASI90]       0.07 0.02 0.05 0.06 0.07 0.08  0.10     3624     3838    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.05 0.56 0.63 0.66 0.69  0.74     2528     3368    1 #> pred[Etanercept 25 mg, PASI75] 0.37 0.05 0.28 0.34 0.37 0.40  0.46     2682     3458    1 #> pred[Etanercept 25 mg, PASI90] 0.13 0.03 0.08 0.11 0.13 0.14  0.19     3045     3396    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.04 0.71 0.77 0.79 0.82  0.86     2616     3614    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.05 0.42 0.49 0.53 0.56  0.62     2735     3551    1 #> pred[Etanercept 50 mg, PASI90] 0.23 0.04 0.16 0.20 0.23 0.26  0.32     2852     3278    1 #> pred[Fumaderm, PASI50]         0.63 0.16 0.32 0.51 0.63 0.75  0.92     3227     2153    1 #> pred[Fumaderm, PASI75]         0.36 0.17 0.11 0.23 0.34 0.47  0.75     3191     2153    1 #> pred[Fumaderm, PASI90]         0.14 0.11 0.02 0.06 0.11 0.19  0.44     3162     2112    1 #> pred[Infliximab, PASI50]       0.88 0.05 0.76 0.85 0.89 0.92  0.96     2662     2669    1 #> pred[Infliximab, PASI75]       0.68 0.10 0.48 0.61 0.68 0.74  0.85     2649     2702    1 #> pred[Infliximab, PASI90]       0.37 0.10 0.19 0.30 0.37 0.44  0.59     2721     2621    1 #> pred[Methotrexate, PASI50]     0.68 0.14 0.37 0.59 0.70 0.79  0.92     1918     2206    1 #> pred[Methotrexate, PASI75]     0.42 0.16 0.13 0.30 0.41 0.52  0.74     1896     2275    1 #> pred[Methotrexate, PASI90]     0.17 0.11 0.03 0.09 0.15 0.23  0.43     1924     2318    1 plot(pred_FE_beta) pred_RE_beta <- predict(pso_fit_RE,                          baseline = distr(qbeta, 56, 408-56),                         baseline_type = \"response\",                         type = \"response\") pred_RE_beta #>                                mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Supportive care, PASI50]  0.14 0.02 0.11 0.13 0.14 0.15  0.17     9843     9606    1 #> pred[Supportive care, PASI75]  0.03 0.01 0.02 0.03 0.03 0.04  0.05    10312    10142    1 #> pred[Supportive care, PASI90]  0.00 0.00 0.00 0.00 0.00 0.00  0.01    11248     9733    1 #> pred[Ciclosporin, PASI50]      0.80 0.11 0.57 0.74 0.81 0.88  0.97     3949     3809    1 #> pred[Ciclosporin, PASI75]      0.56 0.15 0.28 0.45 0.55 0.66  0.87     3930     3807    1 #> pred[Ciclosporin, PASI90]      0.28 0.14 0.08 0.18 0.25 0.35  0.62     3994     3711    1 #> pred[Efalizumab, PASI50]       0.53 0.07 0.38 0.49 0.54 0.58  0.68     5268     4467    1 #> pred[Efalizumab, PASI75]       0.26 0.06 0.14 0.22 0.25 0.29  0.39     5309     4845    1 #> pred[Efalizumab, PASI90]       0.07 0.03 0.03 0.06 0.07 0.09  0.14     5412     4570    1 #> pred[Etanercept 25 mg, PASI50] 0.66 0.09 0.47 0.61 0.66 0.71  0.83     4862     4111    1 #> pred[Etanercept 25 mg, PASI75] 0.38 0.09 0.20 0.32 0.37 0.43  0.58     4872     3898    1 #> pred[Etanercept 25 mg, PASI90] 0.14 0.06 0.05 0.10 0.13 0.16  0.28     4890     4331    1 #> pred[Etanercept 50 mg, PASI50] 0.79 0.08 0.60 0.75 0.80 0.84  0.92     5452     3614    1 #> pred[Etanercept 50 mg, PASI75] 0.53 0.11 0.30 0.47 0.53 0.59  0.75     5441     3711    1 #> pred[Etanercept 50 mg, PASI90] 0.24 0.08 0.09 0.19 0.23 0.28  0.45     5403     3761    1 #> pred[Fumaderm, PASI50]         0.63 0.20 0.20 0.49 0.64 0.78  0.95     7940     5012    1 #> pred[Fumaderm, PASI75]         0.37 0.20 0.06 0.22 0.34 0.51  0.82     7954     5047    1 #> pred[Fumaderm, PASI90]         0.16 0.14 0.01 0.06 0.11 0.22  0.55     7995     4970    1 #> pred[Infliximab, PASI50]       0.87 0.08 0.67 0.83 0.89 0.93  0.98     8400     5360    1 #> pred[Infliximab, PASI75]       0.67 0.13 0.37 0.59 0.68 0.76  0.89     8396     5573    1 #> pred[Infliximab, PASI90]       0.37 0.14 0.13 0.28 0.36 0.46  0.66     8454     5928    1 #> pred[Methotrexate, PASI50]     0.69 0.18 0.29 0.58 0.72 0.84  0.97     4852     4451    1 #> pred[Methotrexate, PASI75]     0.44 0.21 0.09 0.29 0.43 0.59  0.88     4847     4407    1 #> pred[Methotrexate, PASI90]     0.20 0.16 0.02 0.09 0.16 0.28  0.64     4893     4362    1 plot(pred_RE_beta) library(ggplot2) plot(pred_RE, position = position_dodge(width = 0.75)) +   facet_null() +   aes(colour = Category) +   scale_colour_brewer(palette = \"Blues\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_hta_psoriasis.html","id":"ranks-and-rank-probabilities","dir":"Articles","previous_headings":"Further results","what":"Ranks and rank probabilities","title":"Example: Plaque psoriasis HTA report","text":"Treatment rankings, rank probabilities, cumulative rank probabilities can also produced. set lower_better = FALSE since higher outcome categories better (outcomes positive).","code":"(pso_ranks <- posterior_ranks(pso_fit_RE, lower_better = FALSE)) #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[Supportive care]  7.99 0.12    8   8   8   8     8     5133       NA    1 #> rank[Ciclosporin]      2.76 1.26    1   2   3   4     5     6535     6914    1 #> rank[Efalizumab]       6.35 0.80    4   6   7   7     7     5853       NA    1 #> rank[Etanercept 25 mg] 4.91 1.08    3   4   5   6     7     6411     4916    1 #> rank[Etanercept 50 mg] 3.03 1.20    1   2   3   4     5     5547     5831    1 #> rank[Fumaderm]         4.90 1.96    1   3   5   7     7     7797     5347    1 #> rank[Infliximab]       1.80 1.18    1   1   1   2     5     4057     4624    1 #> rank[Methotrexate]     4.26 1.87    1   3   4   6     7     5791     6025    1 plot(pso_ranks) (pso_rankprobs <- posterior_rank_probs(pso_fit_RE, lower_better = FALSE)) #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] #> d[Supportive care]       0.00      0.00      0.00      0.00      0.00      0.00      0.01 #> d[Ciclosporin]           0.17      0.29      0.27      0.17      0.08      0.02      0.00 #> d[Efalizumab]            0.00      0.00      0.00      0.02      0.10      0.36      0.51 #> d[Etanercept 25 mg]      0.00      0.01      0.08      0.21      0.38      0.26      0.04 #> d[Etanercept 50 mg]      0.08      0.30      0.27      0.24      0.09      0.02      0.00 #> d[Fumaderm]              0.07      0.09      0.10      0.11      0.16      0.19      0.27 #> d[Infliximab]            0.58      0.19      0.13      0.06      0.03      0.01      0.00 #> d[Methotrexate]          0.09      0.12      0.14      0.18      0.17      0.14      0.15 #>                     p_rank[8] #> d[Supportive care]       0.99 #> d[Ciclosporin]           0.00 #> d[Efalizumab]            0.00 #> d[Etanercept 25 mg]      0.00 #> d[Etanercept 50 mg]      0.00 #> d[Fumaderm]              0.01 #> d[Infliximab]            0.00 #> d[Methotrexate]          0.00 plot(pso_rankprobs) (pso_cumrankprobs <- posterior_rank_probs(pso_fit_RE, lower_better = FALSE, cumulative = TRUE)) #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] #> d[Supportive care]       0.00      0.00      0.00      0.00      0.00      0.00      0.01 #> d[Ciclosporin]           0.17      0.46      0.73      0.90      0.98      1.00      1.00 #> d[Efalizumab]            0.00      0.00      0.01      0.03      0.13      0.49      1.00 #> d[Etanercept 25 mg]      0.00      0.02      0.10      0.32      0.69      0.95      1.00 #> d[Etanercept 50 mg]      0.08      0.38      0.65      0.89      0.98      1.00      1.00 #> d[Fumaderm]              0.07      0.16      0.26      0.37      0.53      0.71      0.99 #> d[Infliximab]            0.58      0.77      0.90      0.96      0.99      1.00      1.00 #> d[Methotrexate]          0.09      0.21      0.35      0.53      0.71      0.85      1.00 #>                     p_rank[8] #> d[Supportive care]          1 #> d[Ciclosporin]              1 #> d[Efalizumab]               1 #> d[Etanercept 25 mg]         1 #> d[Etanercept 50 mg]         1 #> d[Fumaderm]                 1 #> d[Infliximab]               1 #> d[Methotrexate]             1 plot(pso_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"study-data","dir":"Articles","previous_headings":"","what":"Study data","title":"Example: Newly diagnosed multiple myeloma","text":"consider adjustment following covariates: Age Sex ISS stage, -II vs. III Response post-ASCT, complete good partial response vs. lesser response summary distributions characteristics study follows:","code":"bind_rows(   summarise(ndmm_ipd,             N = n(),             age_mean = mean(age), age_sd = sd(age),             iss_stage3 = mean(iss_stage3),             response_cr_vgpr = mean(response_cr_vgpr),             male = mean(male),             .by = c(studyf, trtf)),   transmute(ndmm_agd_covs,             studyf, trtf,             N = sample_size,             age_mean, age_sd, iss_stage3, response_cr_vgpr, male) ) %>%   mutate(across(where(is.double), ~round(., digits = 2))) #>          studyf trtf    N age_mean age_sd iss_stage3 response_cr_vgpr male #> 1  McCarthy2012  Pbo  229    57.39   5.56       0.18             0.71 0.55 #> 2  McCarthy2012  Len  231    57.93   6.33       0.27             0.62 0.52 #> 3     Attal2012  Pbo  307    54.22   5.24       0.16             0.54 0.58 #> 4     Attal2012  Len  307    54.35   6.06       0.24             0.55 0.55 #> 5   Palumbo2014  Pbo  125    54.44   8.98       0.12             0.38 0.63 #> 6   Palumbo2014  Len  126    53.90   9.69       0.10             0.42 0.46 #> 7   Jackson2019  Len 1137    65.17   8.94       0.25             0.83 0.62 #> 8   Jackson2019  Pbo  864    64.63   9.40       0.19             0.83 0.62 #> 9    Morgan2012  Pbo  410    63.92   9.01       0.36             0.72 0.62 #> 10   Morgan2012 Thal  408    65.59   8.38       0.32             0.75 0.62"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"preparing-treatment-classes","dir":"Articles","previous_headings":"Setup","what":"Preparing treatment classes","title":"Example: Newly diagnosed multiple myeloma","text":"start setting network analysis. Since IPD placebo vs. lenalidomide comparison, one AgD study placebo vs. thalidomide comparison, make shared effect modifier assumption two active treatments order estimate effect modifying treatment-covariate interactions thalidomide (Phillippo et al. 2016, 2020). Since lenalidomide thalidomide class treatments, assumption may reasonable. impose assumption, create treatment class variable active treatments vs. placebo.","code":"ndmm_ipd$trtclass <- case_match(ndmm_ipd$trtf,                                 \"Pbo\" ~ \"Placebo\",                                 c(\"Len\", \"Thal\") ~ \"Active\")  ndmm_agd$trtclass <- case_match(ndmm_agd$trtf,                                 \"Pbo\" ~ \"Placebo\",                                 c(\"Len\", \"Thal\") ~ \"Active\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"Setup","what":"Setting up the network","title":"Example: Newly diagnosed multiple myeloma","text":"set network using set_ipd(), set_agd_surv(), combine_network() functions. Since survival data form event/censoring times censoring indicators, use Surv argument set_*() functions set outcome data using usual survival::Surv() function. AgD set similar fashion IPD, except summary covariate information (data frame ndmm_agd_covs) included using covariates argument. data frame passed covariates must matching study treatment columns outcome data set (ndmm_agd), case studyf trtf respectively, one row per arm, covariate information can matched corresponding arms outcome data. IPD AgD combined single network using combine_network().","code":"ndmm_net <- combine_network(   set_ipd(ndmm_ipd,           study = studyf,           trt = trtf,           trt_class = trtclass,           Surv = Surv(eventtime / 12, status)),   set_agd_surv(ndmm_agd,                study = studyf,                trt = trtf,                trt_class = trtclass,                Surv = Surv(eventtime / 12, status),                covariates = ndmm_agd_covs) )"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"adding-numerical-integration-for-ml-nmr","dir":"Articles","previous_headings":"Setup","what":"Adding numerical integration for ML-NMR","title":"Example: Newly diagnosed multiple myeloma","text":"perform ML-NMR, need create numerical integration points joint covariate distributions AgD study. used integrate (.e. average) individual-level model joint covariate distribution form aggregate-level model. done using add_integration() function, covariate specify marginal distribution using distr() function. Since age skewed, use gamma distribution covariate; remaining covariates binary given Bernoulli distributions. procedure also requires information correlations covariates. known, can specified using cor argument. However, default weighted average correlations IPD studies used.","code":"ndmm_net <- add_integration(ndmm_net,                             age = distr(qgamma, mean = age_mean, sd = age_sd),                             iss_stage3 = distr(qbern, iss_stage3),                             response_cr_vgpr = distr(qbern, response_cr_vgpr),                             male = distr(qbern, male)) #> Using weighted average correlation matrix computed from IPD studies.  ndmm_net #> A network with 3 IPD studies, and 2 AgD studies (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study        Treatment arms #>  Attal2012    2: Pbo | Len   #>  McCarthy2012 2: Pbo | Len   #>  Palumbo2014  2: Pbo | Len   #>  #>  Outcome type: survival #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study       Treatment arms #>  Jackson2019 2: Pbo | Len   #>  Morgan2012  2: Pbo | Thal  #>  #>  Outcome type: survival #> ------------------------------------------------------------------------------------ #> Total number of treatments: 3, in 2 classes #> Total number of studies: 5 #> Reference treatment is: Pbo #> Network is connected #>  #> --------------------------------------------------------- Numerical integration ----  #> Numerical integration points available for 4 covariates:  #>   age iss_stage3 response_cr_vgpr male #> Number of numerical integration points: 64"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"network-plot","dir":"Articles","previous_headings":"Setup","what":"Network plot","title":"Example: Newly diagnosed multiple myeloma","text":"can plot network diagram using plot() method.","code":"plot(ndmm_net,      weight_nodes = TRUE,      weight_edges = TRUE,      # Nudge treatment labels away from nodes      nudge = 0.1,      # Manual layout      layout = data.frame(x = c(0, -1, 1),                          y = c(-0.5, 0, 0))) +   guides(edge_colour = guide_legend(override.aes = list(edge_width = 2))) +   theme(legend.position = \"bottom\", legend.direction = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"kaplan-meier-plots","dir":"Articles","previous_headings":"Setup","what":"Kaplan-Meier plots","title":"Example: Newly diagnosed multiple myeloma","text":"can produce Kaplan-Meier plots data study, aid geom_km() function.  transform argument geom_km() can used transform Kaplan-Meier curves prior plotting, example transform = \"cloglog\" assess proportional hazards log-log plot.","code":"ggplot() +   geom_km(ndmm_net) +   facet_wrap(~.study) +   labs(y = \"Survival probability\", x = \"Time\") +   coord_cartesian(ylim = c(0, 1)) +   theme_multinma() +   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"ml-nmr-models-with-m-spline-baseline-hazards","dir":"Articles","previous_headings":"","what":"ML-NMR models with M-spline baseline hazards","title":"Example: Newly diagnosed multiple myeloma","text":"fit proportional hazards survival model cubic M-splines baseline hazard Phillippo et al. (2024). allows baseline hazard flexibly follow shape baseline hazard may take. ML-NMR models fit using nma() function, specify M-spline baseline hazard used likelihood = \"mspline\". Fitting spline models requires user specify number location knots. default, seven internal knots used (n_knots = 7) placed evenly spaced quantiles observed event times within study. Overfitting avoided use random walk prior distribution (inverse softmax transformed) spline coefficients penalises complexity shrinks towards constant baseline hazard (Phillippo et al. 2024); practice means number knots can set sufficiently large number left shrink suitable level complexity controlled standard deviation random walk. number knots can changed using n_knots argument, custom knot locations can specified using knots argument. nma() function always place boundary knots earliest entry time study (0 delayed entry) maximum event/censoring time. default, nma() function fit cubic M-spline (mspline_degree = 3). Piecewise-constant hazards (.e. piecewise exponential hazards) special case degree 0 splines, specified using likelihood = \"pexp\" (equivalent mspline_degree = 0). specify regression model using regression argument includes main effects covariates (prognostic effects) treatment-covariate interactions (effect modifier interactions) covariate. place vague N(0,1002)\\operatorname{N}(0, 100^2) priors parameters linear predictor. give standard deviation random walk prior spline coefficients half-N(0,12)\\operatorname{half-N}(0, 1^2) prior distribution. also set QR = TRUE, using QR decomposition can greatly increase sampling efficiency regression models. details spline coefficients printed default, can shown print() summary() using pars option:","code":"ndmm_fit <- nma(ndmm_net,                 regression = ~(age + iss_stage3 + response_cr_vgpr + male)*.trt,                 likelihood = \"mspline\",                 prior_intercept = normal(0, 100),                 prior_trt = normal(0, 100),                 prior_reg = normal(0, 100),                 prior_aux = half_normal(1),                 QR = TRUE) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Cubic M-spline baseline hazard with 7 internal knots. #> Regression model: ~(age + iss_stage3 + response_cr_vgpr + male) * .trt. #> Centred covariates at the following overall mean values: #>              age       iss_stage3 response_cr_vgpr             male  #>       61.6558571        0.2297184        0.7314265        0.6020451  #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                            mean se_mean   sd     2.5%      25%      50%      75% #> beta[age]                                  0.08    0.00 0.01     0.06     0.07     0.08     0.08 #> beta[iss_stage3]                           0.35    0.00 0.13     0.08     0.26     0.35     0.44 #> beta[response_cr_vgpr]                    -0.13    0.00 0.10    -0.33    -0.20    -0.13    -0.07 #> beta[male]                                 0.00    0.00 0.10    -0.20    -0.07     0.00     0.07 #> beta[age:.trtclassActive]                 -0.02    0.00 0.01    -0.03    -0.02    -0.02    -0.01 #> beta[iss_stage3:.trtclassActive]           0.21    0.00 0.18    -0.14     0.09     0.21     0.32 #> beta[response_cr_vgpr:.trtclassActive]     0.20    0.00 0.14    -0.09     0.11     0.20     0.29 #> beta[male:.trtclassActive]                 0.13    0.00 0.15    -0.16     0.04     0.13     0.23 #> d[Len]                                    -0.66    0.00 0.05    -0.77    -0.70    -0.66    -0.63 #> d[Thal]                                   -0.20    0.00 0.11    -0.41    -0.27    -0.19    -0.12 #> lp__                                   -6142.01    0.22 7.11 -6156.79 -6146.76 -6141.61 -6137.15 #> sigma[Attal2012]                           0.88    0.01 0.39     0.26     0.60     0.82     1.09 #> sigma[McCarthy2012]                        1.77    0.01 0.55     0.85     1.36     1.72     2.11 #> sigma[Palumbo2014]                         0.61    0.01 0.53     0.02     0.20     0.47     0.88 #> sigma[Jackson2019]                         0.80    0.01 0.33     0.30     0.55     0.74     0.98 #> sigma[Morgan2012]                          0.79    0.02 0.49     0.05     0.43     0.73     1.07 #>                                           97.5% n_eff Rhat #> beta[age]                                  0.09  4064    1 #> beta[iss_stage3]                           0.61  5131    1 #> beta[response_cr_vgpr]                     0.07  4804    1 #> beta[male]                                 0.21  6516    1 #> beta[age:.trtclassActive]                  0.00  3544    1 #> beta[iss_stage3:.trtclassActive]           0.56  4974    1 #> beta[response_cr_vgpr:.trtclassActive]     0.47  3194    1 #> beta[male:.trtclassActive]                 0.43  5312    1 #> d[Len]                                    -0.56  4723    1 #> d[Thal]                                    0.02  3842    1 #> lp__                                   -6128.88  1081    1 #> sigma[Attal2012]                           1.77  1817    1 #> sigma[McCarthy2012]                        2.94  2106    1 #> sigma[Palumbo2014]                         2.00  1506    1 #> sigma[Jackson2019]                         1.57  1511    1 #> sigma[Morgan2012]                          1.95  1004    1 #>  #> Samples were drawn using NUTS(diag_e) at Sat Apr 27 02:43:00 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). summary(ndmm_fit, pars = \"scoef\") #>                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> scoef[Attal2012, 1]     0.02 0.00 0.01 0.01 0.02 0.02  0.03     2587     2098 1.00 #> scoef[McCarthy2012, 1]  0.01 0.00 0.00 0.00 0.01 0.01  0.01     3120     3214 1.00 #> scoef[Palumbo2014, 1]   0.01 0.00 0.01 0.01 0.02 0.02  0.02     2055     3306 1.00 #> scoef[Jackson2019, 1]   0.01 0.00 0.01 0.01 0.01 0.01  0.01     2162     3013 1.01 #> scoef[Morgan2012, 1]    0.01 0.00 0.01 0.01 0.01 0.01  0.02     1195     2463 1.00 #> scoef[Attal2012, 2]     0.03 0.01 0.02 0.02 0.03 0.03  0.04     2857     2436 1.00 #> scoef[McCarthy2012, 2]  0.01 0.01 0.01 0.01 0.01 0.02  0.03     3252     2680 1.00 #> scoef[Palumbo2014, 2]   0.03 0.01 0.02 0.03 0.03 0.03  0.04     2563     3889 1.00 #> scoef[Jackson2019, 2]   0.02 0.00 0.02 0.02 0.02 0.03  0.03     2550     3571 1.01 #> scoef[Morgan2012, 2]    0.02 0.00 0.01 0.02 0.02 0.03  0.03     1548     2542 1.00 #> scoef[Attal2012, 3]     0.05 0.01 0.04 0.05 0.05 0.06  0.07     4196     3599 1.00 #> scoef[McCarthy2012, 3]  0.05 0.01 0.03 0.05 0.05 0.06  0.08     2954     3520 1.00 #> scoef[Palumbo2014, 3]   0.05 0.01 0.04 0.05 0.05 0.06  0.07     5008     3892 1.00 #> scoef[Jackson2019, 3]   0.04 0.00 0.04 0.04 0.04 0.05  0.05     3295     3299 1.00 #> scoef[Morgan2012, 3]    0.04 0.01 0.03 0.04 0.04 0.05  0.06     3051     3396 1.00 #> scoef[Attal2012, 4]     0.09 0.01 0.07 0.08 0.08 0.09  0.11     4662     3890 1.00 #> scoef[McCarthy2012, 4]  0.09 0.02 0.06 0.08 0.09 0.10  0.13     3948     3648 1.00 #> scoef[Palumbo2014, 4]   0.07 0.01 0.05 0.06 0.07 0.07  0.09     4576     3631 1.00 #> scoef[Jackson2019, 4]   0.06 0.01 0.05 0.06 0.06 0.07  0.08     3611     3096 1.00 #> scoef[Morgan2012, 4]    0.07 0.01 0.05 0.06 0.07 0.07  0.08     3457     3155 1.00 #> scoef[Attal2012, 5]     0.10 0.01 0.07 0.09 0.10 0.11  0.13     3837     3318 1.00 #> scoef[McCarthy2012, 5]  0.07 0.02 0.04 0.06 0.07 0.08  0.11     3598     3568 1.00 #> scoef[Palumbo2014, 5]   0.09 0.01 0.07 0.08 0.08 0.09  0.12     3510     3013 1.00 #> scoef[Jackson2019, 5]   0.08 0.01 0.07 0.08 0.08 0.09  0.10     3458     3456 1.00 #> scoef[Morgan2012, 5]    0.09 0.01 0.07 0.08 0.08 0.09  0.11     1584     3279 1.00 #> scoef[Attal2012, 6]     0.11 0.02 0.08 0.10 0.11 0.12  0.15     3436     3359 1.00 #> scoef[McCarthy2012, 6]  0.08 0.02 0.05 0.07 0.08 0.09  0.12     3315     2908 1.00 #> scoef[Palumbo2014, 6]   0.09 0.01 0.06 0.08 0.09 0.09  0.12     5062     3506 1.00 #> scoef[Jackson2019, 6]   0.11 0.01 0.09 0.10 0.10 0.11  0.13     3951     3407 1.00 #> scoef[Morgan2012, 6]    0.10 0.01 0.08 0.09 0.10 0.11  0.13     3735     3238 1.00 #> scoef[Attal2012, 7]     0.14 0.02 0.11 0.13 0.14 0.15  0.19     3401     3420 1.00 #> scoef[McCarthy2012, 7]  0.13 0.03 0.08 0.11 0.13 0.14  0.18     3191     3092 1.00 #> scoef[Palumbo2014, 7]   0.13 0.02 0.10 0.12 0.12 0.14  0.18     4028     3972 1.00 #> scoef[Jackson2019, 7]   0.13 0.01 0.10 0.12 0.13 0.13  0.15     3708     3016 1.00 #> scoef[Morgan2012, 7]    0.13 0.02 0.10 0.12 0.13 0.14  0.16     4266     3723 1.00 #> scoef[Attal2012, 8]     0.17 0.02 0.12 0.16 0.17 0.19  0.22     3805     3309 1.00 #> scoef[McCarthy2012, 8]  0.19 0.04 0.12 0.16 0.18 0.21  0.26     3395     3363 1.00 #> scoef[Palumbo2014, 8]   0.18 0.03 0.13 0.17 0.18 0.19  0.24     4403     3393 1.00 #> scoef[Jackson2019, 8]   0.19 0.02 0.15 0.18 0.19 0.20  0.23     3085     3193 1.00 #> scoef[Morgan2012, 8]    0.20 0.02 0.15 0.18 0.19 0.21  0.25     3857     3612 1.00 #> scoef[Attal2012, 9]     0.12 0.02 0.07 0.10 0.12 0.13  0.16     3185     3507 1.00 #> scoef[McCarthy2012, 9]  0.12 0.04 0.05 0.10 0.12 0.15  0.20     2975     3141 1.00 #> scoef[Palumbo2014, 9]   0.14 0.03 0.08 0.13 0.15 0.16  0.19     3241     2855 1.00 #> scoef[Jackson2019, 9]   0.15 0.02 0.11 0.14 0.15 0.16  0.19     3015     2984 1.00 #> scoef[Morgan2012, 9]    0.16 0.03 0.11 0.15 0.16 0.17  0.22     3478     3039 1.00 #> scoef[Attal2012, 10]    0.10 0.02 0.07 0.09 0.10 0.12  0.14     4591     3615 1.00 #> scoef[McCarthy2012, 10] 0.16 0.04 0.09 0.13 0.15 0.18  0.23     3741     3299 1.00 #> scoef[Palumbo2014, 10]  0.13 0.02 0.08 0.12 0.13 0.14  0.18     5639     3402 1.00 #> scoef[Jackson2019, 10]  0.12 0.02 0.09 0.11 0.12 0.13  0.16     3360     3424 1.00 #> scoef[Morgan2012, 10]   0.12 0.02 0.08 0.11 0.12 0.13  0.17     4206     3575 1.00 #> scoef[Attal2012, 11]    0.07 0.02 0.05 0.06 0.07 0.08  0.11     4771     2936 1.00 #> scoef[McCarthy2012, 11] 0.09 0.03 0.04 0.07 0.08 0.10  0.16     5087     3110 1.00 #> scoef[Palumbo2014, 11]  0.08 0.02 0.05 0.07 0.08 0.09  0.14     4560     3523 1.00 #> scoef[Jackson2019, 11]  0.08 0.01 0.06 0.07 0.08 0.09  0.12     5130     3486 1.00 #> scoef[Morgan2012, 11]   0.06 0.02 0.03 0.05 0.07 0.08  0.09     2543     3587 1.00"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"ploting-hazards","dir":"Articles","previous_headings":"ML-NMR models with M-spline baseline hazards","what":"Ploting hazards","title":"Example: Newly diagnosed multiple myeloma","text":"Let us look estimated hazard functions model. default, predict() function type = \"hazard\" produce plots population-average marginal hazards (level = \"aggregate\", default). can plotted using plot() function.  can also look individual-level baseline hazards. possible using predict() function, time level = \"individual\". Since want show baseline hazard reference level covariates, ’ll create data frame pass predict() newdata. Since providing new data frame prediction, also need provide times predict distributions baseline (intercept) auxiliary (spline coefficient) parameters. predict evenly spaced times time 0 last event/censoring time study. specify named list study names baseline aux, use posterior distributions study parameters. produce predictions plot:","code":"plot(predict(ndmm_fit, type = \"hazard\", level = \"aggregate\")) refdat <- tibble(study = ndmm_net$studies,                  age = ndmm_fit$xbar[\"age\"],                  iss_stage3 = 0,                  response_cr_vgpr = 0,                  male = 0) # At evenly spaced times between the boundary knots tdat <- purrr::imap_dfr(ndmm_fit$basis,                         ~tibble(study = factor(.y, levels = ndmm_net$studies),                                 lower = attr(.x, \"Boundary.knots\")[1],                                 upper = attr(.x, \"Boundary.knots\")[2],                                 times = seq(lower, upper, length = 50)))  refdat <- left_join(refdat, tdat, by = \"study\")  studies <- as.list(setNames(nm = levels(ndmm_net$studies))) plot(predict(ndmm_fit, type = \"hazard\", level = \"individual\",              newdata = refdat, study = study, times = times,              baseline = studies, aux = studies))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"assessing-the-proportional-hazards-assumption","dir":"Articles","previous_headings":"","what":"Assessing the proportional hazards assumption","title":"Example: Newly diagnosed multiple myeloma","text":"can relax assess proportional hazards (PH) assumption allowing spline coefficients vary treatment arms within study. may achieved using aux_by argument, aux_by = c(.study, .trt). Technically, aux_by = .study always assumed order respect randomisation (analogous stratifying intercept terms NMA study), simply write aux_by = .trt; choose make stratification study explicit instance. compare model fit models without PH using LOOIC. overall fit proportional hazards model better. check single study better fit non-PH model, case improved fit one study masked increased complexity others. LOOIC similar lower proportional hazards model compared non-proportional hazards model studies. Based LOOIC alone, evidence suggest proportional hazards assumption invalid . Later, visual inspection estimated survival curves also suggests model good fit data. Stratifying baseline hazards treatment arm (well study) results model produce absolute predictions treatments populations already observed; e.g. estimated survival curve thalidomide can produced Morgan2012 study population (study thalidomide arm), survival curve lenalidomide produced population. Instead, proportional hazards assumption deemed inappropriate, might consider instead modelling departures proportional hazards using aux_regression argument nma() places model (inverse softmax transformed) spline coefficients, shape parameters parametric model. example, can allow baseline hazard vary smoothly treatment arm (aux_regression = ~.trt) /covariates (e.g. aux_regression = ~.trt + iss_stage3). relaxes proportional hazards assumption (already relaxed inclusion patient-level covariates), whilst still allowing predictions produced every treatment population interest.","code":"ndmm_fit_nph <- nma(ndmm_net,                     regression = ~(age + iss_stage3 + response_cr_vgpr + male)*.trt,                     likelihood = \"mspline\",                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_reg = normal(0, 100),                     prior_aux = half_normal(1),                     aux_by = c(.study, .trt),                     QR = TRUE) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nph #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Cubic M-spline baseline hazard with 7 internal knots. #> Regression model: ~(age + iss_stage3 + response_cr_vgpr + male) * .trt. #> Centred covariates at the following overall mean values: #>              age       iss_stage3 response_cr_vgpr             male  #>       61.6558571        0.2297184        0.7314265        0.6020451  #> Stratified baseline hazards by .study and .trt. #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                            mean se_mean   sd     2.5%      25%      50%      75% #> beta[age]                                  0.07    0.00 0.01     0.06     0.07     0.07     0.08 #> beta[iss_stage3]                           0.34    0.00 0.12     0.09     0.25     0.34     0.42 #> beta[response_cr_vgpr]                    -0.11    0.00 0.10    -0.31    -0.18    -0.11    -0.04 #> beta[male]                                -0.01    0.00 0.10    -0.21    -0.08    -0.01     0.06 #> beta[age:.trtclassActive]                 -0.01    0.00 0.01    -0.03    -0.02    -0.01    -0.01 #> beta[iss_stage3:.trtclassActive]           0.23    0.00 0.18    -0.11     0.11     0.23     0.35 #> beta[response_cr_vgpr:.trtclassActive]     0.15    0.00 0.14    -0.12     0.06     0.15     0.26 #> beta[male:.trtclassActive]                 0.15    0.00 0.15    -0.13     0.05     0.15     0.25 #> d[Len]                                    -0.62    0.00 0.07    -0.75    -0.66    -0.62    -0.58 #> d[Thal]                                   -0.25    0.00 0.12    -0.49    -0.33    -0.25    -0.17 #> lp__                                   -6173.53    0.28 9.48 -6192.85 -6179.84 -6173.02 -6166.98 #> sigma[Attal2012: Pbo]                      0.95    0.01 0.43     0.20     0.65     0.90     1.21 #> sigma[Attal2012: Len]                      0.59    0.01 0.38     0.04     0.32     0.52     0.79 #> sigma[McCarthy2012: Pbo]                   1.38    0.01 0.53     0.54     0.99     1.31     1.73 #> sigma[McCarthy2012: Len]                   1.21    0.01 0.46     0.50     0.86     1.15     1.47 #> sigma[Palumbo2014: Pbo]                    0.60    0.01 0.49     0.02     0.23     0.48     0.85 #> sigma[Palumbo2014: Len]                    0.78    0.01 0.56     0.04     0.34     0.67     1.11 #> sigma[Jackson2019: Pbo]                    0.63    0.01 0.32     0.16     0.41     0.57     0.81 #> sigma[Jackson2019: Len]                    1.01    0.01 0.43     0.36     0.70     0.94     1.27 #> sigma[Morgan2012: Pbo]                     0.33    0.01 0.32     0.01     0.11     0.24     0.45 #> sigma[Morgan2012: Thal]                    1.01    0.02 0.50     0.13     0.65     0.97     1.31 #>                                           97.5% n_eff Rhat #> beta[age]                                  0.09  2193    1 #> beta[iss_stage3]                           0.58  5568    1 #> beta[response_cr_vgpr]                     0.08  5831    1 #> beta[male]                                 0.18  5236    1 #> beta[age:.trtclassActive]                  0.01  2637    1 #> beta[iss_stage3:.trtclassActive]           0.57  5536    1 #> beta[response_cr_vgpr:.trtclassActive]     0.43  4496    1 #> beta[male:.trtclassActive]                 0.45  4772    1 #> d[Len]                                    -0.49  2425    1 #> d[Thal]                                   -0.02  3444    1 #> lp__                                   -6155.82  1156    1 #> sigma[Attal2012: Pbo]                      1.93  1491    1 #> sigma[Attal2012: Len]                      1.55  1642    1 #> sigma[McCarthy2012: Pbo]                   2.56  2173    1 #> sigma[McCarthy2012: Len]                   2.28  2430    1 #> sigma[Palumbo2014: Pbo]                    1.85  1934    1 #> sigma[Palumbo2014: Len]                    2.11  1783    1 #> sigma[Jackson2019: Pbo]                    1.39  1487    1 #> sigma[Jackson2019: Len]                    2.02  1479    1 #> sigma[Morgan2012: Pbo]                     1.18  1869    1 #> sigma[Morgan2012: Thal]                    2.15  1048    1 #>  #> Samples were drawn using NUTS(diag_e) at Sat Apr 27 06:37:01 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). (ndmm_fit_loo <- loo(ndmm_fit)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate   SE #> elpd_loo  -6129.3 47.2 #> p_loo        35.2  0.7 #> looic     12258.5 94.5 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details. (ndmm_fit_nph_loo <- loo(ndmm_fit_nph)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate   SE #> elpd_loo  -6135.9 47.2 #> p_loo        44.0  0.8 #> looic     12271.9 94.3 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  # Compare to PH model loo_compare(ndmm_fit_loo, ndmm_fit_nph_loo) #>        elpd_diff se_diff #> model1  0.0       0.0    #> model2 -6.7       3.5 studies_all <- c(ndmm_ipd$study, ndmm_agd$study) cbind(   PH = by(ndmm_fit_loo$pointwise[, \"looic\"], studies_all, sum),   `non-PH` = by(ndmm_fit_nph_loo$pointwise[, \"looic\"], studies_all, sum) ) #>                     PH    non-PH #> Attal2012    1630.6453 1632.3042 #> Jackson2019  6270.7875 6272.2199 #> McCarthy2012 1378.9831 1390.9979 #> Morgan2012   2346.9508 2345.6749 #> Palumbo2014   631.1527  630.7023"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"comparison-to-unadjusted-nma","dir":"Articles","previous_headings":"","what":"Comparison to unadjusted NMA","title":"Example: Newly diagnosed multiple myeloma","text":"comparison, also fit NMA models without covariate adjustment, without proportional hazards assumption. , compare model fit using LOOIC, overall within study. Whilst little difference overall model fit, non-PH model preferred Jackson2019 study substantially lower LOOIC. Including covariates ML-NMR model sufficient remove PH violation, even though covariates fixed time-varying, ML-NMR model much better fit overall. Note: test likely low power, substitute usual inspection proportional hazards prior analysis. Using transform = \"cloglog\" geom_km() produce log-log plots one option assess proportionality.","code":"ndmm_fit_nma <- nma(ndmm_net,                     likelihood = \"mspline\",                     prior_intercept = normal(0, 100),                     prior_trt = normal(0, 100),                     prior_aux = half_normal(1)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nma #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Cubic M-spline baseline hazard with 7 internal knots. #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff Rhat #> d[Len]                 -0.52    0.00 0.05    -0.61    -0.55    -0.52    -0.49    -0.43  4055    1 #> d[Thal]                -0.11    0.00 0.09    -0.28    -0.16    -0.11    -0.04     0.07  4644    1 #> lp__                -6220.38    0.21 6.74 -6235.14 -6224.78 -6220.01 -6215.62 -6208.25  1064    1 #> sigma[Attal2012]        0.81    0.01 0.39     0.20     0.54     0.75     1.03     1.73  1985    1 #> sigma[McCarthy2012]     1.68    0.01 0.56     0.73     1.28     1.64     2.02     2.91  2117    1 #> sigma[Palumbo2014]      0.64    0.01 0.47     0.03     0.28     0.53     0.88     1.78  1775    1 #> sigma[Jackson2019]      0.87    0.01 0.32     0.41     0.64     0.82     1.05     1.65  2280    1 #> sigma[Morgan2012]       0.91    0.01 0.46     0.27     0.57     0.82     1.16     2.03  1490    1 #>  #> Samples were drawn using NUTS(diag_e) at Sat Apr 27 06:55:51 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1).  ndmm_fit_nma_nph <- nma(ndmm_net,                         likelihood = \"mspline\",                         prior_intercept = normal(0, 100),                         prior_trt = normal(0, 100),                         prior_aux = half_normal(1),                         aux_by = c(.study, .trt)) #> Note: Setting \"Pbo\" as the network reference treatment.  ndmm_fit_nma_nph #> A fixed effects ML-NMR with a mspline likelihood (log link). #> Cubic M-spline baseline hazard with 7 internal knots. #> Stratified baseline hazards by .study and .trt. #> Inference for Stan model: survival_mspline. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                              mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff #> d[Len]                      -0.47    0.00 0.05    -0.57    -0.50    -0.47    -0.43    -0.37  3041 #> d[Thal]                     -0.14    0.00 0.10    -0.33    -0.21    -0.14    -0.08     0.05  3173 #> lp__                     -6245.96    0.26 8.98 -6264.36 -6251.77 -6245.47 -6239.57 -6229.71  1230 #> sigma[Attal2012: Pbo]        0.93    0.01 0.42     0.21     0.64     0.89     1.18     1.86  1762 #> sigma[Attal2012: Len]        0.52    0.01 0.38     0.02     0.23     0.44     0.72     1.45  1861 #> sigma[McCarthy2012: Pbo]     1.27    0.01 0.54     0.41     0.86     1.20     1.59     2.50  2356 #> sigma[McCarthy2012: Len]     1.15    0.01 0.49     0.42     0.79     1.08     1.43     2.27  2842 #> sigma[Palumbo2014: Pbo]      0.88    0.01 0.50     0.13     0.52     0.80     1.15     2.10  2332 #> sigma[Palumbo2014: Len]      0.70    0.01 0.54     0.03     0.29     0.59     1.00     2.01  1938 #> sigma[Jackson2019: Pbo]      0.88    0.01 0.31     0.43     0.66     0.82     1.04     1.63  2452 #> sigma[Jackson2019: Len]      1.07    0.01 0.42     0.44     0.75     1.00     1.31     2.07  1859 #> sigma[Morgan2012: Pbo]       0.52    0.01 0.36     0.05     0.26     0.44     0.68     1.42  2233 #> sigma[Morgan2012: Thal]      1.07    0.01 0.45     0.36     0.74     1.02     1.33     2.12  2005 #>                          Rhat #> d[Len]                      1 #> d[Thal]                     1 #> lp__                        1 #> sigma[Attal2012: Pbo]       1 #> sigma[Attal2012: Len]       1 #> sigma[McCarthy2012: Pbo]    1 #> sigma[McCarthy2012: Len]    1 #> sigma[Palumbo2014: Pbo]     1 #> sigma[Palumbo2014: Len]     1 #> sigma[Jackson2019: Pbo]     1 #> sigma[Jackson2019: Len]     1 #> sigma[Morgan2012: Pbo]      1 #> sigma[Morgan2012: Thal]     1 #>  #> Samples were drawn using NUTS(diag_e) at Sat Apr 27 07:05:35 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Compare overall model fit (ndmm_fit_nma_loo <- loo(ndmm_fit_nma)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate   SE #> elpd_loo  -6203.9 45.5 #> p_loo        27.1  0.4 #> looic     12407.8 91.1 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  (ndmm_fit_nma_nph_loo <- loo(ndmm_fit_nma_nph)) #>  #> Computed from 4000 by 4144 log-likelihood matrix #>  #>          Estimate   SE #> elpd_loo  -6206.1 45.5 #> p_loo        37.4  0.6 #> looic     12412.3 91.0 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> All Pareto k estimates are good (k < 0.5). #> See help('pareto-k-diagnostic') for details.  loo_compare(ndmm_fit_nma_loo, ndmm_fit_nma_nph_loo) #>        elpd_diff se_diff #> model1  0.0       0.0    #> model2 -2.2       4.4  # Compare model fit by study cbind(   PH = by(ndmm_fit_nma_loo$pointwise[, \"looic\"], studies_all, sum),   `non-PH` = by(ndmm_fit_nma_nph_loo$pointwise[, \"looic\"], studies_all, sum) ) #>                     PH   non-PH #> Attal2012    1695.4881 1695.942 #> Jackson2019  6276.3877 6270.620 #> McCarthy2012 1423.6705 1434.468 #> Morgan2012   2345.1156 2346.434 #> Palumbo2014   667.1769  664.794"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"producing-population-average-estimates","dir":"Articles","previous_headings":"","what":"Producing population-average estimates","title":"Example: Newly diagnosed multiple myeloma","text":"now produce population-average estimates several different quantities interest. usual array posterior summary functions available, including relative_effects(), predict(), marginal_effects(), posterior_ranks() posterior_rank_probs(). predict() function particular numerous options working survival models, selected using type argument: \"survival\" survival probabilities \"hazard\" hazards \"cumhaz\" cumulative hazards \"rmst\" restricted mean survival times \"mean\" mean survival times (equivalent type = \"rmst\" time = Inf) \"quantile\" quantiles survival time distribution \"median\" median survival times (equivalent type = \"quantile\" quantiles = 0.5) \"link\" linear predictor producing population-average predictions (default level = \"aggregate\"), quantities corresponds population-average marginal survival function; see ?predict.stan_nma details. marginal_effects() function may used form population-average marginal treatment effects population-average predictions.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-survival-probabilities","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average survival probabilities","title":"Example: Newly diagnosed multiple myeloma","text":"produce population-average survival curves use predict() function type = \"survival\". marginal standardised survival curves. also overlay unadjusted Kaplan-Meier curves data using geom_km() helper function.  Whilst adjusted unadjusted curves exactly comparable (although marginal survival estimates, adjusted curves account differences covariate distributions arms relevant overall population study), estimated survival curves good fit data. baseline imbalance sex Palumbo2014 study accounted model, explains slight differences Kaplan-Meier curves .","code":"plot(predict(ndmm_fit, type = \"survival\")) +   geom_km(ndmm_net) +   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-median-survival-times","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average median survival times","title":"Example: Newly diagnosed multiple myeloma","text":"predict() function can produce range absolute effect summaries, example population-average median survival times:","code":"(medsurv <- predict(ndmm_fit, type = \"median\")) #> Warning: Evaluating M-spline at times beyond the boundary knots. #> Evaluating M-spline at times beyond the boundary knots. #> Evaluating M-spline at times beyond the boundary knots. #> Evaluating M-spline at times beyond the boundary knots. #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Attal2012: Pbo]  2.41 0.13 2.17 2.33 2.41 2.50  2.67     5533     3109    1 #> pred[Attal2012: Len]  3.89 0.20 3.50 3.76 3.90 4.02  4.29     6980     3079    1 #> pred[Attal2012: Thal] 2.69 0.30 2.17 2.49 2.67 2.87  3.34     3590     3103    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[McCarthy2012: Pbo]  2.81 0.16 2.51 2.70 2.81 2.92  3.14     4700     3412    1 #> pred[McCarthy2012: Len]  4.64 0.27 4.13 4.45 4.63 4.82  5.17     6116     3226    1 #> pred[McCarthy2012: Thal] 3.20 0.34 2.58 2.97 3.19 3.42  3.91     4287     3134    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Palumbo2014: Pbo]  1.86 0.18 1.52 1.73 1.85 1.98  2.25     5166     3450    1 #> pred[Palumbo2014: Len]  3.72 0.39 3.03 3.45 3.70 3.96  4.55     6734     3356    1 #> pred[Palumbo2014: Thal] 2.30 0.37 1.66 2.03 2.27 2.53  3.09     4463     3521    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Jackson2019: Pbo]  2.04 0.11 1.83 1.96 2.04 2.11  2.26      196     2566 1.02 #> pred[Jackson2019: Len]  4.21 0.20 3.83 4.06 4.20 4.35  4.62      125     2626 1.03 #> pred[Jackson2019: Thal] 2.60 0.32 2.04 2.37 2.58 2.81  3.29     4478     3345 1.00 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Morgan2012: Pbo]  1.77 0.16 1.47 1.66 1.76 1.88  2.12     1912     3489 1.01 #> pred[Morgan2012: Len]  4.09 0.57 3.17 3.69 4.03 4.41  5.37     3155     3106 1.01 #> pred[Morgan2012: Thal] 2.30 0.21 1.92 2.15 2.29 2.43  2.74     4889     3545 1.00  plot(medsurv)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-conditional-log-hazard-ratios","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average conditional log hazard ratios","title":"Example: Newly diagnosed multiple myeloma","text":"Relative effects produced using relative_effects() function. ML-NMR model (IPD meta-regression), population-average conditional log hazard ratios (log survival time ratios AFT models).","code":"(loghr <- relative_effects(ndmm_fit, all_contrasts = TRUE)) #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  54.29        0.2             0.54 0.57 #>  #>                             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Attal2012: Len vs. Pbo]  -0.60 0.07 -0.74 -0.65 -0.59 -0.55 -0.45     7521     3160    1 #> d[Attal2012: Thal vs. Pbo] -0.13 0.14 -0.40 -0.22 -0.13 -0.04  0.14     3707     3286    1 #> d[Attal2012: Thal vs. Len]  0.47 0.12  0.23  0.38  0.46  0.55  0.71     3904     2960    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  57.66       0.23             0.67 0.54 #>  #>                                mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[McCarthy2012: Len vs. Pbo]  -0.62 0.06 -0.74 -0.66 -0.62 -0.58 -0.51     6907     3318    1 #> d[McCarthy2012: Thal vs. Pbo] -0.15 0.12 -0.39 -0.24 -0.15 -0.07  0.09     3687     3176    1 #> d[McCarthy2012: Thal vs. Len]  0.47 0.12  0.23  0.38  0.46  0.55  0.71     3904     2960    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  54.17       0.11              0.4 0.55 #>  #>                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Palumbo2014: Len vs. Pbo]  -0.64 0.08 -0.80 -0.69 -0.64 -0.59 -0.48     7772     3098    1 #> d[Palumbo2014: Thal vs. Pbo] -0.18 0.14 -0.45 -0.27 -0.18 -0.08  0.10     3954     3073    1 #> d[Palumbo2014: Thal vs. Len]  0.47 0.12  0.23  0.38  0.46  0.55  0.71     3904     2960    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  64.63       0.21             0.84 0.62 #>  #>                               mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Jackson2019: Len vs. Pbo]  -0.69 0.06 -0.81 -0.73 -0.68 -0.64 -0.57     3658     2731    1 #> d[Jackson2019: Thal vs. Pbo] -0.22 0.11 -0.44 -0.30 -0.22 -0.14  0.00     4231     2708    1 #> d[Jackson2019: Thal vs. Len]  0.47 0.12  0.23  0.38  0.46  0.55  0.71     3904     2960    1 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #> Covariate values: #>    age iss_stage3 response_cr_vgpr male #>  64.46       0.33             0.73 0.62 #>  #>                              mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Morgan2012: Len vs. Pbo]  -0.68 0.06 -0.81 -0.72 -0.68 -0.64 -0.56     4429     3066    1 #> d[Morgan2012: Thal vs. Pbo] -0.22 0.11 -0.43 -0.29 -0.21 -0.14 -0.01     4490     3058    1 #> d[Morgan2012: Thal vs. Len]  0.47 0.12  0.23  0.38  0.46  0.55  0.71     3904     2960    1  plot(loghr)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_ndmm.html","id":"population-average-marginal-hazard-ratios","dir":"Articles","previous_headings":"Producing population-average estimates","what":"Population-average marginal hazard ratios","title":"Example: Newly diagnosed multiple myeloma","text":"marginal_effects() function produces population-average marginal relative effects, formed marginal absolute predictions produced predict(). example, can produce population-average marginal hazard ratios: time-varying non-proportional model includes covariate effects, even though covariates measured baseline time-varying.","code":"plot(marginal_effects(ndmm_fit, type = \"hazard\", mtype = \"ratio\")) +   theme(legend.position = \"top\", legend.box.spacing = unit(0, \"lines\"))"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-arm-based-data","dir":"Articles","previous_headings":"","what":"Analysis of arm-based data","title":"Example: Parkinson's disease","text":"begin analysis arm-based data - means standard errors.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"arm-level continuous data giving mean -time reduction (y) standard error (se) arm. use function set_agd_arm() set network. let treatment 4 set default network reference treatment, since results considerably improved sampling efficiency choosing treatment 1 network reference. sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"arm_net <- set_agd_arm(parkinsons,                        study = studyn,                       trt = trtn,                       y = y,                        se = se,                       sample_size = n) arm_net #> A network with 7 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(arm_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k study-specific intercepts μj\\mu_j. can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. arm_fit_FE <- nma(arm_net,                    trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 10)) #> Note: Setting \"4\" as the network reference treatment. arm_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>       mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat #> d[1]  0.54    0.01 0.47  -0.38  0.23  0.55  0.86  1.47  1503    1 #> d[2] -1.26    0.01 0.52  -2.29 -1.61 -1.26 -0.91 -0.26  1555    1 #> d[3]  0.05    0.01 0.33  -0.60 -0.18  0.04  0.27  0.68  1965    1 #> d[5] -0.30    0.00 0.22  -0.73 -0.45 -0.30 -0.15  0.12  3127    1 #> lp__ -6.76    0.06 2.41 -12.44 -8.12 -6.42 -5.02 -3.12  1724    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:37:07 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(arm_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(arm_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k study-specific intercepts μj\\mu_j, additionally use half-N(52)\\textrm{half-N}(5^2) prior heterogeneity standard deviation τ\\tau. can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. arm_fit_RE <- nma(arm_net,                    seed = 379394727,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = half_normal(scale = 5),                   adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. #> Warning: There were 3 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems pairs(arm_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\")) arm_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%    75% 97.5% n_eff Rhat #> d[1]   0.53    0.01 0.61  -0.65   0.15   0.55   0.91  1.69  1935    1 #> d[2]  -1.33    0.02 0.71  -2.72  -1.75  -1.31  -0.88 -0.05  1448    1 #> d[3]   0.02    0.01 0.47  -0.90  -0.25   0.03   0.31  0.91  1999    1 #> d[5]  -0.29    0.01 0.41  -1.09  -0.49  -0.29  -0.10  0.54  2340    1 #> lp__ -13.00    0.10 3.53 -20.90 -15.16 -12.71 -10.46 -7.04  1160    1 #> tau    0.37    0.02 0.39   0.01   0.11   0.26   0.49  1.46   516    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:37:12 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(arm_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(arm_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison","dir":"Articles","previous_headings":"Analysis of arm-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(arm_dic_FE <- dic(arm_fit_FE)) #> Residual deviance: 13.5 (on 15 data points) #>                pD: 11.2 #>               DIC: 24.7 (arm_dic_RE <- dic(arm_fit_RE)) #> Residual deviance: 13.7 (on 15 data points) #>                pD: 12.4 #>               DIC: 26.1 plot(arm_dic_FE) plot(arm_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results","dir":"Articles","previous_headings":"Analysis of arm-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean −0.73-0.73 precision 2121. use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify baseline_trt = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted, predictions mean -time reduction produced every study network based estimated baseline response μj\\mu_j:  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(arm_releff_FE <- relative_effects(arm_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.54 0.47 -1.47 -0.86 -0.55 -0.23  0.38     1520     2166    1 #> d[2] -1.81 0.34 -2.46 -2.05 -1.81 -1.57 -1.13     5565     3253    1 #> d[3] -0.50 0.49 -1.43 -0.82 -0.50 -0.17  0.46     2474     2878    1 #> d[5] -0.84 0.52 -1.85 -1.19 -0.85 -0.50  0.17     1747     2429    1 plot(arm_releff_FE, ref_line = 0) (arm_releff_RE <- relative_effects(arm_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.53 0.61 -1.69 -0.91 -0.55 -0.15  0.65     1998     1640    1 #> d[2] -1.86 0.54 -2.97 -2.14 -1.84 -1.55 -0.87     4450     1638    1 #> d[3] -0.50 0.64 -1.74 -0.88 -0.50 -0.12  0.72     3033     2509    1 #> d[5] -0.82 0.72 -2.19 -1.25 -0.84 -0.39  0.58     2075     1955    1 plot(arm_releff_RE, ref_line = 0) arm_pred_FE <- predict(arm_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        baseline_trt = 1) arm_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.27 0.53 -2.29 -1.62 -1.28 -0.91 -0.24     1701     2585    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.58 -0.29     3910     3936    1 #> pred[2] -2.53 0.41 -3.33 -2.81 -2.53 -2.26 -1.74     5361     3716    1 #> pred[3] -1.22 0.54 -2.27 -1.59 -1.22 -0.86 -0.17     2650     3202    1 #> pred[5] -1.57 0.57 -2.68 -1.96 -1.58 -1.18 -0.44     1935     2716    1 plot(arm_pred_FE) arm_pred_RE <- predict(arm_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        baseline_trt = 1) arm_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.25 0.64 -2.50 -1.68 -1.26 -0.85 -0.02     2148     1954    1 #> pred[1] -0.73 0.22 -1.16 -0.87 -0.73 -0.58 -0.30     3976     3867    1 #> pred[2] -2.58 0.58 -3.76 -2.90 -2.57 -2.25 -1.49     4216     1441    1 #> pred[3] -1.23 0.68 -2.57 -1.63 -1.22 -0.82  0.06     3151     2639    1 #> pred[5] -1.55 0.75 -3.02 -2.00 -1.55 -1.10 -0.08     2181     2142    1 plot(arm_pred_RE) arm_pred_FE_studies <- predict(arm_fit_FE, type = \"response\") arm_pred_FE_studies #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[1: 4] -1.66 0.46 -2.52 -1.98 -1.66 -1.35 -0.77     1884     2597    1 #> pred[1: 1] -1.12 0.43 -1.97 -1.40 -1.12 -0.83 -0.27     3777     3318    1 #> pred[1: 2] -2.92 0.52 -3.97 -3.28 -2.92 -2.58 -1.93     3554     3227    1 #> pred[1: 3] -1.61 0.39 -2.35 -1.88 -1.61 -1.35 -0.85     3393     3380    1 #> pred[1: 5] -1.96 0.50 -2.90 -2.32 -1.97 -1.62 -0.95     2052     2630    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[2: 4] -1.18 0.51 -2.16 -1.52 -1.18 -0.85 -0.17     1478     2006    1 #> pred[2: 1] -0.64 0.27 -1.16 -0.82 -0.64 -0.45 -0.12     4690     3456    1 #> pred[2: 2] -2.45 0.24 -2.91 -2.61 -2.45 -2.28 -1.99     5023     3477    1 #> pred[2: 3] -1.14 0.53 -2.17 -1.50 -1.14 -0.78 -0.10     2234     2653    1 #> pred[2: 5] -1.48 0.55 -2.55 -1.86 -1.49 -1.12 -0.38     1704     2387    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[3: 4] -1.12 0.41 -1.93 -1.40 -1.12 -0.85 -0.31     1834     2637    1 #> pred[3: 1] -0.58 0.36 -1.26 -0.82 -0.58 -0.34  0.11     3935     3596    1 #> pred[3: 2] -2.39 0.37 -3.12 -2.64 -2.38 -2.14 -1.66     3721     3110    1 #> pred[3: 3] -1.08 0.48 -2.04 -1.40 -1.08 -0.75 -0.12     2759     2766    1 #> pred[3: 5] -1.43 0.47 -2.34 -1.74 -1.43 -1.11 -0.53     2144     2574    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4: 4] -0.39 0.30 -0.98 -0.60 -0.40 -0.19  0.21     2218     2451    1 #> pred[4: 1]  0.15 0.50 -0.85 -0.19  0.16  0.49  1.11     2290     2536    1 #> pred[4: 2] -1.66 0.56 -2.79 -2.03 -1.64 -1.28 -0.57     2160     2387    1 #> pred[4: 3] -0.35 0.25 -0.83 -0.52 -0.35 -0.18  0.14     5423     3545    1 #> pred[4: 5] -0.70 0.37 -1.42 -0.94 -0.70 -0.45  0.05     2540     2624    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[5: 4] -0.56 0.34 -1.24 -0.79 -0.56 -0.33  0.10     2436     2809    1 #> pred[5: 1] -0.02 0.52 -1.03 -0.38 -0.01  0.33  0.99     2383     2706    1 #> pred[5: 2] -1.83 0.58 -2.94 -2.21 -1.84 -1.44 -0.71     2259     2744    1 #> pred[5: 3] -0.52 0.29 -1.08 -0.72 -0.53 -0.32  0.08     5745     3401    1 #> pred[5: 5] -0.87 0.41 -1.68 -1.14 -0.85 -0.58 -0.08     2827     2930    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[6: 4] -2.20 0.18 -2.56 -2.32 -2.19 -2.08 -1.84     3387     2923    1 #> pred[6: 1] -1.65 0.50 -2.64 -1.99 -1.65 -1.32 -0.65     1650     2421    1 #> pred[6: 2] -3.46 0.55 -4.55 -3.83 -3.46 -3.09 -2.38     1680     2233    1 #> pred[6: 3] -2.15 0.38 -2.90 -2.40 -2.15 -1.89 -1.42     2186     2773    1 #> pred[6: 5] -2.50 0.17 -2.83 -2.61 -2.50 -2.38 -2.16     4987     3117    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[7: 4] -1.80 0.18 -2.16 -1.92 -1.80 -1.68 -1.45     3551     2946    1 #> pred[7: 1] -1.26 0.50 -2.24 -1.59 -1.25 -0.91 -0.29     1679     2355    1 #> pred[7: 2] -3.06 0.55 -4.15 -3.43 -3.06 -2.70 -1.99     1742     2606    1 #> pred[7: 3] -1.75 0.38 -2.50 -2.01 -1.75 -1.50 -1.01     2214     2539    1 #> pred[7: 5] -2.10 0.21 -2.50 -2.24 -2.10 -1.96 -1.70     4914     3210    1 plot(arm_pred_FE_studies) (arm_ranks <- posterior_ranks(arm_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.49 0.70    2   3   3   4     5     1990       NA    1 #> rank[1] 4.66 0.75    2   5   5   5     5     2335       NA    1 #> rank[2] 1.06 0.30    1   1   1   1     2     2583     2595    1 #> rank[3] 3.51 0.93    2   3   4   4     5     2854       NA    1 #> rank[5] 2.28 0.69    1   2   2   2     4     2545     2543    1 plot(arm_ranks) (arm_rankprobs <- posterior_rank_probs(arm_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.49      0.39      0.07 #> d[1]      0.00      0.04      0.06      0.11      0.79 #> d[2]      0.95      0.04      0.01      0.00      0.00 #> d[3]      0.00      0.17      0.26      0.45      0.12 #> d[5]      0.04      0.71      0.18      0.05      0.01 plot(arm_rankprobs) (arm_cumrankprobs <- posterior_rank_probs(arm_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.05      0.54      0.93         1 #> d[1]      0.00      0.04      0.10      0.21         1 #> d[2]      0.95      0.99      1.00      1.00         1 #> d[3]      0.00      0.17      0.43      0.88         1 #> d[5]      0.04      0.75      0.94      0.99         1 plot(arm_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-contrast-based-data","dir":"Articles","previous_headings":"","what":"Analysis of contrast-based data","title":"Example: Parkinson's disease","text":"now perform analysis using contrast-based data (mean differences standard errors).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"contrast-level data giving mean difference -time reduction (diff) standard error (se_diff), use function set_agd_contrast() set network. sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"contr_net <- set_agd_contrast(parkinsons,                                study = studyn,                               trt = trtn,                               y = diff,                                se = se_diff,                               sample_size = n) contr_net #> A network with 7 AgD studies (contrast-based). #>  #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(contr_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k. can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. contr_fit_FE <- nma(contr_net,                      trt_effects = \"fixed\",                     prior_trt = normal(scale = 100)) #> Note: Setting \"4\" as the network reference treatment. contr_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>       mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat #> d[1]  0.54    0.01 0.46 -0.37  0.23  0.53  0.84  1.43  2175    1 #> d[2] -1.27    0.01 0.50 -2.26 -1.62 -1.27 -0.93 -0.29  2263    1 #> d[3]  0.05    0.01 0.33 -0.58 -0.18  0.05  0.27  0.71  3058    1 #> d[5] -0.30    0.00 0.21 -0.71 -0.44 -0.30 -0.16  0.08  3831    1 #> lp__ -3.12    0.03 1.36 -6.55 -3.77 -2.82 -2.12 -1.39  1841    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:37:23 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). plot_prior_posterior(contr_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k, additionally use half-N(52)\\textrm{half-N}(5^2) prior heterogeneity standard deviation τ\\tau. can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. contr_fit_RE <- nma(contr_net,                      seed = 1150676438,                     trt_effects = \"random\",                     prior_trt = normal(scale = 100),                     prior_het = half_normal(scale = 5),                     adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. pairs(contr_fit_RE, pars = c(\"d[3]\", \"delta[4: 4 vs. 3]\", \"tau\")) contr_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>       mean se_mean   sd   2.5%    25%   50%   75% 97.5% n_eff Rhat #> d[1]  0.51    0.01 0.60  -0.65   0.13  0.52  0.90  1.65  2435 1.00 #> d[2] -1.33    0.01 0.69  -2.70  -1.74 -1.31 -0.89 -0.01  2356 1.00 #> d[3]  0.03    0.01 0.47  -0.83  -0.24  0.03  0.30  0.95  1953 1.00 #> d[5] -0.31    0.01 0.41  -1.19  -0.52 -0.30 -0.10  0.48  2077 1.00 #> lp__ -8.27    0.09 2.92 -14.84 -10.03 -7.97 -6.20 -3.43  1172 1.00 #> tau   0.38    0.01 0.38   0.01   0.12  0.28  0.52  1.42   945 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:37:26 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(contr_fit_RE, pars = c(\"d\", \"delta\")) plot_prior_posterior(contr_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison-1","dir":"Articles","previous_headings":"Analysis of contrast-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(contr_dic_FE <- dic(contr_fit_FE)) #> Residual deviance: 6.2 (on 8 data points) #>                pD: 3.9 #>               DIC: 10.2 (contr_dic_RE <- dic(contr_fit_RE)) #> Residual deviance: 6.5 (on 8 data points) #>                pD: 5.3 #>               DIC: 11.8 plot(contr_dic_FE) plot(contr_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results-1","dir":"Articles","previous_headings":"Analysis of contrast-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean −0.73-0.73 precision 2121. use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify baseline_trt = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted error raised, study baselines estimated network. can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(contr_releff_FE <- relative_effects(contr_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.54 0.46 -1.43 -0.84 -0.53 -0.23  0.37     2193     2485    1 #> d[2] -1.81 0.33 -2.46 -2.03 -1.81 -1.58 -1.17     5584     3277    1 #> d[3] -0.49 0.48 -1.43 -0.81 -0.48 -0.15  0.46     3041     2924    1 #> d[5] -0.83 0.50 -1.83 -1.18 -0.83 -0.50  0.15     2444     2494    1 plot(contr_releff_FE, ref_line = 0) (contr_releff_RE <- relative_effects(contr_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.51 0.60 -1.65 -0.90 -0.52 -0.13  0.65     2505     2312    1 #> d[2] -1.84 0.51 -2.85 -2.12 -1.83 -1.55 -0.87     3437     2322    1 #> d[3] -0.48 0.63 -1.71 -0.86 -0.49 -0.11  0.75     3210     2479    1 #> d[5] -0.82 0.74 -2.29 -1.25 -0.82 -0.38  0.59     2325     1876    1 plot(contr_releff_RE, ref_line = 0) contr_pred_FE <- predict(contr_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        baseline_trt = 1) contr_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.26 0.51 -2.27 -1.61 -1.27 -0.91 -0.25     2343     3040    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.58 -0.30     3988     3629    1 #> pred[2] -2.54 0.39 -3.33 -2.80 -2.54 -2.28 -1.77     4860     3667    1 #> pred[3] -1.22 0.53 -2.24 -1.58 -1.22 -0.87 -0.18     3029     3222    1 #> pred[5] -1.56 0.55 -2.65 -1.94 -1.56 -1.19 -0.51     2499     2945    1 plot(contr_pred_FE) contr_pred_RE <- predict(contr_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        baseline_trt = 1) contr_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.25 0.63 -2.47 -1.65 -1.25 -0.84 -0.01     2628     2267    1 #> pred[1] -0.73 0.22 -1.16 -0.88 -0.73 -0.59 -0.31     3715     3592    1 #> pred[2] -2.58 0.55 -3.67 -2.91 -2.58 -2.24 -1.50     3516     2575    1 #> pred[3] -1.22 0.67 -2.51 -1.63 -1.22 -0.80  0.09     3217     2295    1 #> pred[5] -1.56 0.77 -3.09 -2.02 -1.55 -1.09 -0.04     2445     2093    1 plot(contr_pred_RE) # Not run predict(contr_fit_FE, type = \"response\") (contr_ranks <- posterior_ranks(contr_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.49 0.70    2   3   3   4     5     2741       NA    1 #> rank[1] 4.68 0.73    2   5   5   5     5     2532       NA    1 #> rank[2] 1.04 0.23    1   1   1   1     2     2825     2834    1 #> rank[3] 3.51 0.92    2   3   4   4     5     3397       NA    1 #> rank[5] 2.28 0.65    1   2   2   2     4     2845     2127    1 plot(contr_ranks) (contr_rankprobs <- posterior_rank_probs(contr_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.50      0.39      0.07 #> d[1]      0.00      0.03      0.06      0.11      0.80 #> d[2]      0.96      0.03      0.00      0.00      0.00 #> d[3]      0.00      0.17      0.25      0.45      0.12 #> d[5]      0.03      0.72      0.19      0.05      0.01 plot(contr_rankprobs) (contr_cumrankprobs <- posterior_rank_probs(contr_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.54      0.93         1 #> d[1]      0.00      0.03      0.09      0.20         1 #> d[2]      0.96      0.99      1.00      1.00         1 #> d[3]      0.00      0.18      0.43      0.88         1 #> d[5]      0.03      0.75      0.94      0.99         1 plot(contr_cumrankprobs)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"analysis-of-mixed-arm-based-and-contrast-based-data","dir":"Articles","previous_headings":"","what":"Analysis of mixed arm-based and contrast-based data","title":"Example: Parkinson's disease","text":"now perform analysis studies contribute arm-based data, contribute contrast-based data. Replicating Dias et al. (2011), consider arm-based data studies 1-3, contrast-based data studies 4-7.","code":"studies <- parkinsons$studyn (parkinsons_arm <- parkinsons[studies %in% 1:3, ]) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718 #> 7      3    4 -1.20 0.478  81 -0.90   0.695 (parkinsons_contr <- parkinsons[studies %in% 4:7, ]) #>    studyn trtn     y    se   n  diff se_diff #> 8       4    3 -0.24 0.265 128    NA   0.265 #> 9       4    4 -0.59 0.354  72 -0.35   0.442 #> 10      5    3 -0.73 0.335  80    NA   0.335 #> 11      5    4 -0.18 0.442  46  0.55   0.555 #> 12      6    4 -2.20 0.197 137    NA   0.197 #> 13      6    5 -2.50 0.190 131 -0.30   0.274 #> 14      7    4 -1.80 0.200 154    NA   0.200 #> 15      7    5 -2.10 0.250 143 -0.30   0.320"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"setting-up-the-network-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Setting up the network","title":"Example: Parkinson's disease","text":"use functions set_agd_arm() set_agd_contrast() set respective data sources within network, combine together combine_network(). sample_size argument optional, enables nodes weighted sample size network plot. Plot network structure.","code":"mix_arm_net <- set_agd_arm(parkinsons_arm,                             study = studyn,                            trt = trtn,                            y = y,                             se = se,                            sample_size = n)  mix_contr_net <- set_agd_contrast(parkinsons_contr,                                    study = studyn,                                   trt = trtn,                                   y = diff,                                    se = se_diff,                                   sample_size = n)  mix_net <- combine_network(mix_arm_net, mix_contr_net) mix_net #> A network with 3 AgD studies (arm-based), and 4 AgD studies (contrast-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  #>  Outcome type: continuous #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected plot(mix_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"meta-analysis-models-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Meta-analysis models","title":"Example: Parkinson's disease","text":"fit fixed effect (FE) random effects (RE) models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"fixed-effect-meta-analysis-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Fixed effect meta-analysis","title":"Example: Parkinson's disease","text":"First, fit fixed effect model using nma() function trt_effects = \"fixed\". use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k study-specific intercepts μj\\mu_j. can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. mix_fit_FE <- nma(mix_net,                    trt_effects = \"fixed\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100)) #> Note: Setting \"4\" as the network reference treatment. mix_fit_FE #> A fixed effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>       mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat #> d[1]  0.51    0.01 0.48 -0.43  0.18  0.50  0.83  1.46  1586    1 #> d[2] -1.31    0.01 0.53 -2.35 -1.66 -1.31 -0.94 -0.31  1626    1 #> d[3]  0.04    0.01 0.32 -0.62 -0.18  0.04  0.26  0.64  2553    1 #> d[5] -0.30    0.00 0.21 -0.72 -0.44 -0.29 -0.16  0.11  3050    1 #> lp__ -4.66    0.05 1.87 -9.12 -5.73 -4.34 -3.23 -2.01  1640    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:37:33 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(mix_fit_FE, pars = c(\"d\", \"mu\")) plot_prior_posterior(mix_fit_FE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"random-effects-meta-analysis-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Random effects meta-analysis","title":"Example: Parkinson's disease","text":"now fit random effects model using nma() function trt_effects = \"random\". , use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k study-specific intercepts μj\\mu_j, additionally use half-N(52)\\textrm{half-N}(5^2) prior heterogeneity standard deviation τ\\tau. can examine range parameter values implied prior distributions summary() method: Fitting RE model see small number divergent transition errors, simply removed increasing value adapt_delta argument (default set 0.95 RE models). diagnose, use pairs() method investigate posterior distribution divergences happening (indicated red crosses):  divergent transitions occur upper tail heterogeneity standard deviation. case, small number studies, much information estimate heterogeneity standard deviation prior distribution may heavy-tailed. consider informative prior distribution heterogeneity variance aid estimation. Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. mix_fit_RE <- nma(mix_net,                    seed = 437219664,                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = half_normal(scale = 5),                   adapt_delta = 0.99) #> Note: Setting \"4\" as the network reference treatment. pairs(mix_fit_RE, pars = c(\"d[3]\", \"delta[4: 4 vs. 3]\", \"tau\")) mix_fit_RE #> A random effects NMA with a normal likelihood (identity link). #> Inference for Stan model: normal. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>        mean se_mean   sd   2.5%    25%    50%   75% 97.5% n_eff Rhat #> d[1]   0.55    0.01 0.59  -0.61   0.15   0.54  0.91  1.73  1945    1 #> d[2]  -1.30    0.01 0.67  -2.61  -1.73  -1.29 -0.88  0.01  2026    1 #> d[3]   0.03    0.01 0.45  -0.86  -0.24   0.02  0.30  0.92  2923    1 #> d[5]  -0.31    0.01 0.40  -1.13  -0.51  -0.30 -0.09  0.47  2330    1 #> lp__ -10.88    0.09 3.26 -18.03 -12.90 -10.60 -8.59 -5.26  1465    1 #> tau    0.37    0.01 0.36   0.01   0.12   0.27  0.49  1.28  1080    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:37:38 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(mix_fit_RE, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(mix_fit_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"model-comparison-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data > Meta-analysis models","what":"Model comparison","title":"Example: Parkinson's disease","text":"Model fit can checked using dic() function: models fit data well, posterior mean residual deviance close number data points. DIC similar models, choose FE model based parsimony. can also examine residual deviance contributions corresponding plot() method.","code":"(mix_dic_FE <- dic(mix_fit_FE)) #> Residual deviance: 9.3 (on 11 data points) #>                pD: 7 #>               DIC: 16.3 (mix_dic_RE <- dic(mix_fit_RE)) #> Residual deviance: 9.6 (on 11 data points) #>                pD: 8.4 #>               DIC: 18 plot(mix_dic_FE) plot(mix_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_parkinsons.html","id":"further-results-2","dir":"Articles","previous_headings":"Analysis of mixed arm-based and contrast-based data","what":"Further results","title":"Example: Parkinson's disease","text":"comparison Dias et al. (2011), can produce relative effects placebo using relative_effects() function trt_ref = 1:   Following Dias et al. (2011), produce absolute predictions mean -time reduction treatment assuming Normal distribution outcomes treatment 1 (placebo) mean −0.73-0.73 precision 2121. use predict() method, baseline argument takes distr() distribution object specify corresponding Normal distribution, specify baseline_trt = 1 indicate baseline distribution corresponds treatment 1. (Strictly speaking, type = \"response\" unnecessary , since identity link function used.)   baseline argument omitted, predictions mean -time reduction produced every arm-based study network based estimated baseline response μj\\mu_j:  can also produce treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(mix_releff_FE <- relative_effects(mix_fit_FE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.51 0.48 -1.46 -0.83 -0.50 -0.18  0.43     1606     2262    1 #> d[2] -1.81 0.33 -2.47 -2.04 -1.81 -1.58 -1.16     5739     2842    1 #> d[3] -0.47 0.49 -1.43 -0.80 -0.47 -0.14  0.50     2409     3011    1 #> d[5] -0.80 0.53 -1.85 -1.16 -0.79 -0.45  0.27     1713     2275    1 plot(mix_releff_FE, ref_line = 0) (mix_releff_RE <- relative_effects(mix_fit_RE, trt_ref = 1)) #>       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[4] -0.55 0.59 -1.73 -0.91 -0.54 -0.15  0.61     1952     2171    1 #> d[2] -1.85 0.49 -2.89 -2.13 -1.85 -1.55 -0.96     4054     2813    1 #> d[3] -0.52 0.62 -1.74 -0.89 -0.51 -0.13  0.64     2989     2480    1 #> d[5] -0.85 0.71 -2.23 -1.28 -0.84 -0.40  0.51     2067     1959    1 plot(mix_releff_RE, ref_line = 0) mix_pred_FE <- predict(mix_fit_FE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        baseline_trt = 1) mix_pred_FE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.23 0.53 -2.27 -1.59 -1.22 -0.88 -0.17     1777     2613    1 #> pred[1] -0.72 0.22 -1.14 -0.87 -0.72 -0.58 -0.29     3556     3638    1 #> pred[2] -2.53 0.39 -3.31 -2.80 -2.53 -2.26 -1.78     5108     3551    1 #> pred[3] -1.19 0.54 -2.24 -1.55 -1.21 -0.82 -0.10     2525     3106    1 #> pred[5] -1.52 0.57 -2.66 -1.91 -1.52 -1.14 -0.37     1842     2382    1 plot(mix_pred_FE) mix_pred_RE <- predict(mix_fit_RE,                         baseline = distr(qnorm, mean = -0.73, sd = 21^-0.5),                        type = \"response\",                        baseline_trt = 1) mix_pred_RE #>          mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[4] -1.27 0.63 -2.52 -1.68 -1.27 -0.87 -0.06     2088     2415    1 #> pred[1] -0.73 0.22 -1.17 -0.88 -0.73 -0.58 -0.31     4051     3817    1 #> pred[2] -2.58 0.54 -3.68 -2.90 -2.57 -2.24 -1.57     4000     2896    1 #> pred[3] -1.25 0.65 -2.52 -1.66 -1.24 -0.84  0.01     3099     2869    1 #> pred[5] -1.58 0.74 -2.99 -2.04 -1.58 -1.14 -0.13     2124     2509    1 plot(mix_pred_RE) mix_pred_FE_studies <- predict(mix_fit_FE, type = \"response\") mix_pred_FE_studies #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[1: 4] -1.64 0.45 -2.50 -1.94 -1.65 -1.34 -0.70     2068     2403    1 #> pred[1: 1] -1.13 0.43 -1.95 -1.42 -1.14 -0.84 -0.29     3407     2920    1 #> pred[1: 2] -2.94 0.52 -3.93 -3.29 -2.94 -2.59 -1.96     3148     3019    1 #> pred[1: 3] -1.60 0.39 -2.35 -1.86 -1.61 -1.34 -0.84     3552     3294    1 #> pred[1: 5] -1.93 0.50 -2.88 -2.28 -1.93 -1.60 -0.94     2099     2516    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[2: 4] -1.14 0.52 -2.14 -1.50 -1.13 -0.79 -0.10     1589     2167    1 #> pred[2: 1] -0.64 0.26 -1.15 -0.81 -0.63 -0.46 -0.11     4656     3462    1 #> pred[2: 2] -2.45 0.24 -2.93 -2.61 -2.45 -2.28 -1.96     5173     3692    1 #> pred[2: 3] -1.11 0.53 -2.15 -1.46 -1.11 -0.74 -0.05     2303     2812    1 #> pred[2: 5] -1.44 0.56 -2.53 -1.83 -1.44 -1.05 -0.31     1690     2295    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>             mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[3: 4] -1.10 0.42 -1.94 -1.38 -1.10 -0.81 -0.28     2007     2612    1 #> pred[3: 1] -0.59 0.36 -1.30 -0.84 -0.60 -0.35  0.11     4337     2979    1 #> pred[3: 2] -2.41 0.39 -3.17 -2.66 -2.41 -2.14 -1.66     3882     3167    1 #> pred[3: 3] -1.06 0.47 -1.99 -1.39 -1.04 -0.75 -0.14     3112     2988    1 #> pred[3: 5] -1.40 0.48 -2.34 -1.71 -1.40 -1.06 -0.47     2072     2409    1 plot(mix_pred_FE_studies) (mix_ranks <- posterior_ranks(mix_fit_FE)) #>         mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[4] 3.51 0.71    2   3   3   4     5     2379       NA    1 #> rank[1] 4.63 0.79    2   5   5   5     5     2077       NA    1 #> rank[2] 1.05 0.26    1   1   1   1     2     2572     2682    1 #> rank[3] 3.52 0.92    2   3   4   4     5     3397       NA    1 #> rank[5] 2.29 0.68    1   2   2   3     4     2517     2745    1 plot(mix_ranks) (mix_rankprobs <- posterior_rank_probs(mix_fit_FE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.49      0.39      0.08 #> d[1]      0.00      0.04      0.07      0.11      0.78 #> d[2]      0.96      0.03      0.01      0.00      0.00 #> d[3]      0.00      0.17      0.25      0.45      0.13 #> d[5]      0.04      0.71      0.19      0.05      0.01 plot(mix_rankprobs) (mix_cumrankprobs <- posterior_rank_probs(mix_fit_FE, cumulative = TRUE)) #>      p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[4]      0.00      0.04      0.53      0.92         1 #> d[1]      0.00      0.04      0.11      0.22         1 #> d[2]      0.96      0.99      1.00      1.00         1 #> d[3]      0.00      0.17      0.43      0.87         1 #> d[5]      0.04      0.75      0.94      0.99         1 plot(mix_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"initial_analysis","dir":"Articles","previous_headings":"","what":"Initial analysis","title":"Example: Plaque psoriasis ML-NMR","text":"start recreating analysis presented Phillippo et al. (2020). analyse IPD three studies, UNCOVER-1, UNCOVER-2, UNCOVER-3 (Griffiths et al. 2015; Gordon et al. 2016), AgD one study, FIXTURE (Langley et al. 2014). consider running ML-NMR adjusting five potential effect-modifying covariates: duration psoriasis durnpso, weight weight, previous systemic treatment prevsys, body surface area bsa, psoriatic arthritis psa.","code":"pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0  male bsa #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2  TRUE  18 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4  TRUE  33 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8  TRUE  33 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 FALSE  50 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 FALSE  35 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2  TRUE  29 #>   weight durnpso prevsys   psa #> 1   98.1     6.7    TRUE  TRUE #> 2  129.6    14.5   FALSE  TRUE #> 3   78.0    26.5    TRUE FALSE #> 4  139.9    25.0    TRUE  TRUE #> 5   54.2    11.9    TRUE FALSE #> 6   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n pasi100_r #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323        14 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324         0 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327        47 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323        78 #>   pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd pasi_w0_mean pasi_w0_sd male #> 1       323            326     43.8   13.0     28.7    5.9         23.2        9.8 71.2 #> 2       324            326     44.1   12.6     27.9    6.1         24.1       10.5 72.7 #> 3       327            327     45.4   12.9     28.4    5.9         23.7       10.5 72.2 #> 4       323            327     44.5   13.2     28.4    6.4         23.9        9.9 68.5 #>   bsa_mean bsa_sd weight_mean weight_sd durnpso_mean durnpso_sd prevsys  psa #> 1     33.6   18.0        84.6      20.5         16.4       12.0    65.6 13.5 #> 2     35.2   19.1        82.0      20.4         16.6       11.6    62.6 15.0 #> 3     34.5   19.4        83.6      20.8         17.3       12.2    64.8 15.0 #> 4     34.3   19.2        83.0      21.6         15.8       12.3    63.0 15.3"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"preparing-the-data","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Preparing the data","title":"Example: Plaque psoriasis ML-NMR","text":"need prepare data acceptable format run ML-NMR model. Firstly, need handle binary covariates prevsys psa. IPD, coded TRUE FALSE, AgD coded percentages (100). need transform sets variables numeric lie interval [0,1][0,1], variables compatible across data sources. Whilst , also transform body surface area bsa (percentage) lie [0,1][0,1], since make specifying appropriate marginal distribution easier later, rescale weight duration aid interpretation regression coefficients (terms 10 kilos 10 years respectively). also add trtclass variable, indicating treatments belong classes. Finally, check missing values IPD. small number individuals missing covariates: Since proportion missing data small, simply exclude individuals analysis.","code":"pso_ipd <- pso_ipd %>%    mutate(# Variable transformations          bsa = bsa / 100,          prevsys = as.numeric(prevsys),          psa = as.numeric(psa),          weight = weight / 10,          durnpso = durnpso / 10,          # Treatment classes          trtclass = case_when(trtn == 1 ~ \"Placebo\",                               trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                               trtn == 4 ~ \"TNFa blocker\"),          # Check complete cases for covariates of interest          complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%    mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                               trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                               trtn == 4 ~ \"TNFa blocker\")   ) sum(!pso_ipd$complete) #> [1] 4 mean(!pso_ipd$complete) #> [1] 0.001036807 pso_ipd <- filter(pso_ipd, complete)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"creating-the-network","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Creating the network","title":"Example: Plaque psoriasis ML-NMR","text":"Set network, setting IPD set_ipd(), AgD (arm-based) set_agd_arm(), combining together using combine_network(). specify binary pasi75 outcome r IPD, count outcome pasi75_r denominator pasi75_n r n AgD. specify treatment classes trt_class = trtclass. can produce network plot plot() method:","code":"pso_net <- combine_network(   set_ipd(pso_ipd,            study = studyc,            trt = trtc,            r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,                study = studyc,                trt = trtc,                r = pasi75_r,                n = pasi75_n,               trt_class = trtclass) )  pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE) +    ggplot2::theme(legend.position = \"bottom\", legend.box = \"vertical\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"numerical-integration-for-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > Setup","what":"Numerical integration for ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"ML-NMR models define meta-regression model individual level, exactly manner full-IPD meta-regression. ML-NMR incorporates AgD model integrating individual-level model covariate distribution AgD study (Phillippo et al. 2020; Phillippo 2019). Using integration, instead simply “plugging-” mean covariate values AgD studies, avoids aggregation bias link function identity function. package utilises numerical integration incorporate aggregate data - specifically, quasi-Monte Carlo (QMC) integration Gaussian copula (Phillippo et al. 2020; Phillippo 2019). QMC integration general flexible integration approach, typically requires far fewer integration points standard (pseudo-random) Monte-Carlo integration achieve numerical accuracy.1 Gaussian copula allows us account correlations covariates, may specified marginal distributions. now set numerical integration network. five covariates consider adjusting body surface area bsa, duration psoriasis durnpso, previous systemic treatment prevsys, psoriatic arthritis psa, weight weight. need choose suitable marginal distributions covariates draw integration points . prevsys psa binary covariates, given Bernoulli distribution. bsa percentage, choose logit-Normal distribution (note, requires logitnorm package installed). choose Gamma distributions durnpso weight account skewness. choices seem match well marginal distributions observed IPD:  add integration points AgD studies network using add_integration() function. Marginal distributions covariate specified using distr() function, takes cumulative distribution function corresponding chosen marginal distribution, arguments distribution column names aggregate data. Since know correlations covariates AgD studies, impute weighted mean correlations IPD studies (default option). Note: package provides several convenience functions specifying distributions, including qgamma() allows parameterisation Gamma distribution terms mean standard deviation, qbern() provides Bernoulli distribution, qlogitnorm() provides logit-Normal distribution allowing parameterisation terms mean standard deviation (requires logitnorm package installed).","code":"# Get mean and sd of covariates in each study ipd_summary <- pso_ipd %>%    group_by(studyc) %>%    summarise_at(vars(weight, durnpso, bsa), list(mean = mean, sd = sd, min = min, max = max)) %>%    pivot_longer(weight_mean:bsa_max, names_sep = \"_\", names_to = c(\"covariate\", \".value\")) %>%    # Assign distributions   mutate(dist = recode(covariate,                        bsa = \"dlogitnorm\",                        durnpso = \"dgamma\",                        weight = \"dgamma\")) %>%    # Compute density curves   group_by(studyc, covariate) %>%    mutate(value = if_else(dist == \"dlogitnorm\",                          list(seq(0, 1, length.out = 101)),                          list(seq(min*0.8, max*1.2, length.out = 101)))) %>%    unnest(cols = value) %>%    mutate(dens = eval(call(first(dist), x = value, mean = first(mean), sd = first(sd))))  # Plot histograms and assumed densities pso_ipd %>%    pivot_longer(c(weight, durnpso, bsa), names_to = \"covariate\", values_to = \"value\") %>%  ggplot(aes(x = value)) +   geom_histogram(aes(y = after_stat(density)),                   binwidth = function(x) diff(range(x)) / nclass.Sturges(x),                  boundary = 0,                  fill = \"grey50\") +   geom_line(aes(y = dens), data = ipd_summary,             colour = \"darkred\", linewidth = 0.5) +   facet_wrap(~studyc + covariate, scales = \"free\", ncol = 3) +   theme_multinma() pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64 ) #> Using weighted average correlation matrix computed from IPD studies."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"ml-nmr-models","dir":"Articles","previous_headings":"Initial analysis","what":"ML-NMR models","title":"Example: Plaque psoriasis ML-NMR","text":"fit fixed effect (FE) random effects (RE) ML-NMR models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"fixed-effect-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > ML-NMR models","what":"Fixed effect ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"First, fit FE ML-NMR model using function nma(). Following (Phillippo et al. 2020) specify weakly-informative N(0,102)N(0, 10^2) priors parameter. range parameter values implied prior distributions can checked using summary() method: regression model specified regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt, include main (prognostic) effects covariate well interactions treatment. use probit link function (link = \"probit\"), specify two-parameter Binomial approximation aggregate-level likelihood used (likelihood = \"bernoulli2\", “bernoulli” refers individual-level likelihood, “2” denotes two-parameter adjustment aggregate-level likelihood) (Phillippo et al. 2020). utilise shared effect modifier assumption help identify model, setting treatment-covariate interactions equal within class (class_interactions = \"common\"). narrow possible range random initial values init_r = 0.1 (default init_r = 2), since probit models particular often hard initialise. Using QR decomposition (QR = TRUE) greatly improves sampling efficiency , often case regression models. Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  now recommend assessing sufficient accuracy numerical integration running half chains n_int / 2 integration points half full n_int. Rhat n_eff diagnostic warnings can either attributed insufficient MCMC iterations (argument iter nma()) insufficient integration points (n_int add_integration()), depending whether occur within two groups chains chains combined. feature enabled default (int_check = TRUE). case, warnings content number iterations number integration points. (Phillippo et al. (2020) used alternative approach based saving cumulative integration points plotting empirical integration error, can achieved setting int_thin nma() using plot_integration_error() function.)","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                    likelihood = \"bernoulli2\",                   regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   init_r = 0.1,                   QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. print(pso_fit_FE) #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                           0.04    0.00 0.06    -0.08     0.00     0.04     0.09 #> beta[prevsys]                          -0.14    0.00 0.16    -0.45    -0.25    -0.14    -0.03 #> beta[bsa]                              -0.06    0.01 0.45    -0.97    -0.36    -0.05     0.23 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02     0.04     0.06 #> beta[psa]                              -0.08    0.00 0.17    -0.41    -0.19    -0.08     0.04 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08    -0.03     0.02 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.14    -0.06    -0.01     0.03 #> beta[prevsys:.trtclassTNFa blocker]     0.19    0.00 0.19    -0.18     0.07     0.19     0.32 #> beta[prevsys:.trtclassIL blocker]       0.07    0.00 0.17    -0.27    -0.05     0.07     0.18 #> beta[bsa:.trtclassTNFa blocker]         0.05    0.01 0.51    -0.96    -0.30     0.04     0.39 #> beta[bsa:.trtclassIL blocker]           0.29    0.01 0.49    -0.65    -0.04     0.29     0.61 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.19    -0.17    -0.14 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12    -0.10    -0.08 #> beta[psa:.trtclassTNFa blocker]        -0.05    0.00 0.20    -0.43    -0.19    -0.06     0.08 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.19    -0.34    -0.12     0.01     0.13 #> d[ETN]                                  1.55    0.00 0.08     1.39     1.50     1.55     1.60 #> d[IXE_Q2W]                              2.95    0.00 0.09     2.78     2.89     2.95     3.01 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.38     2.49     2.54     2.60 #> d[SEC_150]                              2.14    0.00 0.12     1.91     2.06     2.14     2.22 #> d[SEC_300]                              2.45    0.00 0.12     2.21     2.37     2.45     2.53 #> lp__                                -1576.50    0.09 3.52 -1584.16 -1578.71 -1576.13 -1573.98 #>                                        97.5% n_eff Rhat #> beta[durnpso]                           0.16  6400    1 #> beta[prevsys]                           0.17  5679    1 #> beta[bsa]                               0.79  5506    1 #> beta[weight]                            0.09  5398    1 #> beta[psa]                               0.24  6419    1 #> beta[durnpso:.trtclassTNFa blocker]     0.12  6417    1 #> beta[durnpso:.trtclassIL blocker]       0.12  7724    1 #> beta[prevsys:.trtclassTNFa blocker]     0.57  6415    1 #> beta[prevsys:.trtclassIL blocker]       0.40  6735    1 #> beta[bsa:.trtclassTNFa blocker]         1.07  5564    1 #> beta[bsa:.trtclassIL blocker]           1.28  6352    1 #> beta[weight:.trtclassTNFa blocker]     -0.10  6082    1 #> beta[weight:.trtclassIL blocker]       -0.04  6876    1 #> beta[psa:.trtclassTNFa blocker]         0.35  6259    1 #> beta[psa:.trtclassIL blocker]           0.38  7634    1 #> d[ETN]                                  1.70  4251    1 #> d[IXE_Q2W]                              3.13  5683    1 #> d[IXE_Q4W]                              2.70  5379    1 #> d[SEC_150]                              2.37  5015    1 #> d[SEC_300]                              2.69  5369    1 #> lp__                                -1570.58  1627    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:38:37 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_FE, pars = c(\"d\", \"beta\", \"mu\")) plot_prior_posterior(pso_fit_FE, prior = c(\"intercept\", \"trt\", \"reg\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"random-effects-ml-nmr","dir":"Articles","previous_headings":"Initial analysis > ML-NMR models","what":"Random effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"now fit RE model. , specify weakly-informative N(0,102)N(0, 10^2) priors parameter, now specify half-N(0,2.52)\\textrm{half-N}(0, 2.5^2) prior heterogeneity standard deviation τ\\tau. range parameter values implied prior distributions can checked using summary() method: Fitting model uses call nma() , except now trt_effects = \"random\". Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: number divergent transitions, can investigate using pairs() method:  divergent transition errors (red crosses) seem concentrated upper tail heterogeneity standard deviation parameter. suggests information identify heterogeneity parameter weak - four studies network - informative prior distribution might aid estimation. prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 10)) #> A Normal prior distribution: location = 0, scale = 10. #> 50% of the prior density lies between -6.74 and 6.74. #> 95% of the prior density lies between -19.6 and 19.6. summary(half_normal(scale = 2.5)) #> A half-Normal prior distribution: location = 0, scale = 2.5. #> 50% of the prior density lies between 0 and 1.69. #> 95% of the prior density lies between 0 and 4.9. pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                    likelihood = \"bernoulli2\",                   regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_het = half_normal(scale = 2.5),                   init_r = 0.1,                   QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. #> Warning: There were 15 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems print(pso_fit_RE) #> A random effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                           0.05    0.00 0.06    -0.08     0.01     0.05     0.09 #> beta[prevsys]                          -0.13    0.00 0.16    -0.44    -0.23    -0.13    -0.02 #> beta[bsa]                              -0.09    0.01 0.43    -0.97    -0.37    -0.08     0.20 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02     0.04     0.06 #> beta[psa]                              -0.06    0.00 0.17    -0.41    -0.17    -0.06     0.06 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08    -0.03     0.02 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.14    -0.06    -0.02     0.03 #> beta[prevsys:.trtclassTNFa blocker]     0.18    0.00 0.19    -0.18     0.05     0.18     0.31 #> beta[prevsys:.trtclassIL blocker]       0.05    0.00 0.17    -0.29    -0.06     0.05     0.17 #> beta[bsa:.trtclassTNFa blocker]         0.07    0.01 0.50    -0.87    -0.27     0.06     0.41 #> beta[bsa:.trtclassIL blocker]           0.32    0.01 0.48    -0.60     0.00     0.32     0.64 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.19    -0.17    -0.15 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12    -0.10    -0.08 #> beta[psa:.trtclassTNFa blocker]        -0.07    0.00 0.21    -0.47    -0.21    -0.08     0.06 #> beta[psa:.trtclassIL blocker]          -0.01    0.00 0.19    -0.37    -0.14    -0.01     0.11 #> d[ETN]                                  1.56    0.00 0.15     1.27     1.47     1.55     1.64 #> d[IXE_Q2W]                              2.96    0.00 0.16     2.64     2.87     2.96     3.06 #> d[IXE_Q4W]                              2.55    0.00 0.15     2.27     2.47     2.55     2.64 #> d[SEC_150]                              2.12    0.01 0.24     1.61     2.00     2.13     2.26 #> d[SEC_300]                              2.43    0.01 0.23     1.97     2.30     2.43     2.56 #> lp__                                -1580.58    0.17 4.94 -1591.32 -1583.76 -1580.22 -1577.05 #> tau                                     0.18    0.01 0.12     0.01     0.10     0.16     0.24 #>                                        97.5% n_eff Rhat #> beta[durnpso]                           0.16  4397 1.00 #> beta[prevsys]                           0.20  3602 1.00 #> beta[bsa]                               0.74  3005 1.00 #> beta[weight]                            0.10  3669 1.00 #> beta[psa]                               0.27  3918 1.00 #> beta[durnpso:.trtclassTNFa blocker]     0.11  4833 1.00 #> beta[durnpso:.trtclassIL blocker]       0.12  5532 1.00 #> beta[prevsys:.trtclassTNFa blocker]     0.55  3510 1.00 #> beta[prevsys:.trtclassIL blocker]       0.39  4425 1.00 #> beta[bsa:.trtclassTNFa blocker]         1.08  3388 1.00 #> beta[bsa:.trtclassIL blocker]           1.27  3875 1.00 #> beta[weight:.trtclassTNFa blocker]     -0.10  4031 1.00 #> beta[weight:.trtclassIL blocker]       -0.04  4463 1.00 #> beta[psa:.trtclassTNFa blocker]         0.35  3841 1.00 #> beta[psa:.trtclassIL blocker]           0.37  4261 1.00 #> d[ETN]                                  1.85  1452 1.00 #> d[IXE_Q2W]                              3.28  1106 1.00 #> d[IXE_Q4W]                              2.87   972 1.00 #> d[SEC_150]                              2.60  1484 1.00 #> d[SEC_300]                              2.88  1663 1.00 #> lp__                                -1571.94   803 1.01 #> tau                                     0.48   580 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:41:14 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(pso_fit_RE, pars = c(\"d\", \"beta\", \"tau\", \"mu\", \"delta\")) pairs(pso_fit_RE, pars = c(\"delta[UNCOVER-2: ETN]\", \"d[ETN]\", \"tau\", \"lp__\")) plot_prior_posterior(pso_fit_RE, prior = c(\"intercept\", \"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"model-comparison","dir":"Articles","previous_headings":"Initial analysis","what":"Model comparison","title":"Example: Plaque psoriasis ML-NMR","text":"model fit FE RE models can checked using dic() function. DIC similar FE RE models, suggesting little evidence residual heterogeneity.","code":"(pso_dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 3129.8 (on 3858 data points) #>                pD: 24.5 #>               DIC: 3154.3 (pso_dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 3123.7 (on 3858 data points) #>                pD: 28.2 #>               DIC: 3151.9"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"producing-relative-effects-and-event-probabilities","dir":"Articles","previous_headings":"Initial analysis","what":"Producing relative effects and event probabilities","title":"Example: Plaque psoriasis ML-NMR","text":"Parameter estimates can plotted using plot() method, example examine estimated regression coefficients:  Plots posterior summaries based ggdist package, allows great degree flexibility, can customised using ggplot2 commands. command specify \"halfeye\" plot, shows posterior density along posterior medians (points) 95% Credible Intervals (thin line) 66% inner bands (thicker line) default. details plotting options see ?plot.nma_summary. can produce population-adjusted relative effects study population network using relative_effects() function.  Predicted probabilities achieving PASI 75 study population treatment produced using predict() method. argument type = \"reponse\" specifies want predicted probabilities, rather probit probabilities.  can produce population-adjusted ranks, rank probabilities, cumulative rank probabilities study population using posterior_ranks() posterior_rank_probs() functions (although ranks unchanged populations, distributions effect modifiers similar). specify lower_better = FALSE, since higher outcome better (higher chance achieving PASI 75).    estimates (relative effects, predictions, rankings) can also produced specific target population populations providing suitable newdata argument function (baseline distribution predict()). produce population-adjusted relative effects (corresponding rankings) chosen target population, require mean covariate values population. example, newdata provide following mean covariate values: Population-adjusted relative effects target population calculated using relative_effects() function, can plotted corresponding plot() method:  absolute predictions, require information full covariate distribution target population, just mean values. IPD available target population, newdata simply data frame IPD. AgD available target population, newdata must data frame added integration points created using add_integration() function. example, suppose aggregate target population introduced following covariate means standard deviations (continuous covariates) proportions (discrete covariates): add integration points data frame similar manner . , need supply correlation matrix joint covariate distribution; use weighted mean correlation matrix computed earlier IPD network, stored network object int_cor. Predicted probabilities achieving PASI 75 target population, given N(−1.75,0.082)N(-1.75, 0.08^2) distribution baseline probit-probability response Placebo (reference levels covariates), produced using predict() method:","code":"plot(pso_fit_FE,      pars = \"beta\",      stat = \"halfeye\",      ref_line = 0) (pso_releff_FE <- relative_effects(pso_fit_FE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[FIXTURE: ETN]     1.66 0.09 1.48 1.60 1.66 1.72  1.84     4249     3419    1 #> d[FIXTURE: IXE_Q2W] 3.03 0.10 2.83 2.96 3.03 3.10  3.23     5912     3080    1 #> d[FIXTURE: IXE_Q4W] 2.62 0.09 2.43 2.55 2.61 2.68  2.80     5451     3476    1 #> d[FIXTURE: SEC_150] 2.22 0.12 1.98 2.14 2.21 2.30  2.45     4532     3477    1 #> d[FIXTURE: SEC_300] 2.52 0.12 2.28 2.44 2.52 2.60  2.76     5000     2982    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-1: ETN]     1.51 0.08 1.34 1.45 1.51 1.57  1.67     4401     3120    1 #> d[UNCOVER-1: IXE_Q2W] 2.92 0.09 2.75 2.86 2.93 2.98  3.09     5674     2939    1 #> d[UNCOVER-1: IXE_Q4W] 2.51 0.08 2.35 2.45 2.51 2.57  2.67     5300     3430    1 #> d[UNCOVER-1: SEC_150] 2.11 0.12 1.88 2.03 2.11 2.20  2.35     5054     3308    1 #> d[UNCOVER-1: SEC_300] 2.42 0.13 2.17 2.33 2.42 2.50  2.67     5621     3349    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-2: ETN]     1.51 0.08 1.35 1.45 1.51 1.56  1.66     4371     3070    1 #> d[UNCOVER-2: IXE_Q2W] 2.92 0.09 2.75 2.86 2.92 2.98  3.09     5884     2906    1 #> d[UNCOVER-2: IXE_Q4W] 2.51 0.08 2.36 2.45 2.51 2.57  2.67     5455     3244    1 #> d[UNCOVER-2: SEC_150] 2.11 0.12 1.88 2.03 2.11 2.19  2.34     5109     3463    1 #> d[UNCOVER-2: SEC_300] 2.42 0.12 2.17 2.33 2.41 2.50  2.66     5621     3434    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-3: ETN]     1.53 0.08 1.37 1.48 1.53 1.58  1.68     4459     3194    1 #> d[UNCOVER-3: IXE_Q2W] 2.94 0.09 2.77 2.88 2.94 3.00  3.11     6068     2688    1 #> d[UNCOVER-3: IXE_Q4W] 2.53 0.08 2.37 2.47 2.53 2.58  2.69     5594     3388    1 #> d[UNCOVER-3: SEC_150] 2.13 0.12 1.90 2.05 2.13 2.21  2.36     5043     3039    1 #> d[UNCOVER-3: SEC_300] 2.43 0.12 2.20 2.35 2.43 2.51  2.67     5561     3172    1 plot(pso_releff_FE, ref_line = 0) (pso_pred_FE <- predict(pso_fit_FE, type = \"response\")) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[FIXTURE: PBO]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     4089     3108    1 #> pred[FIXTURE: ETN]     0.46 0.02 0.41 0.44 0.46 0.47  0.51     7490     3344    1 #> pred[FIXTURE: IXE_Q2W] 0.89 0.02 0.85 0.88 0.89 0.90  0.92     7809     3291    1 #> pred[FIXTURE: IXE_Q4W] 0.80 0.03 0.74 0.78 0.80 0.81  0.84     7254     3322    1 #> pred[FIXTURE: SEC_150] 0.67 0.03 0.62 0.65 0.67 0.69  0.72     8413     3217    1 #> pred[FIXTURE: SEC_300] 0.77 0.02 0.72 0.75 0.77 0.79  0.82     8937     2909    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-1: PBO]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     6089     3457    1 #> pred[UNCOVER-1: ETN]     0.46 0.03 0.41 0.44 0.46 0.48  0.52     7066     3075    1 #> pred[UNCOVER-1: IXE_Q2W] 0.90 0.01 0.88 0.89 0.90 0.91  0.92     8887     3178    1 #> pred[UNCOVER-1: IXE_Q4W] 0.81 0.02 0.78 0.80 0.81 0.82  0.84     8115     3014    1 #> pred[UNCOVER-1: SEC_150] 0.69 0.04 0.60 0.66 0.69 0.72  0.77     7581     3172    1 #> pred[UNCOVER-1: SEC_300] 0.78 0.04 0.71 0.76 0.79 0.81  0.85     7575     3118    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-2: PBO]     0.05 0.01 0.03 0.04 0.05 0.05  0.06     5765     3250    1 #> pred[UNCOVER-2: ETN]     0.42 0.02 0.38 0.41 0.42 0.43  0.46     9278     2919    1 #> pred[UNCOVER-2: IXE_Q2W] 0.88 0.01 0.86 0.87 0.88 0.89  0.91     6795     2830    1 #> pred[UNCOVER-2: IXE_Q4W] 0.78 0.02 0.75 0.77 0.78 0.79  0.81     9534     3177    1 #> pred[UNCOVER-2: SEC_150] 0.65 0.04 0.57 0.62 0.65 0.68  0.73     8984     2941    1 #> pred[UNCOVER-2: SEC_300] 0.75 0.04 0.67 0.73 0.75 0.78  0.82     8331     3163    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-3: PBO]     0.08 0.01 0.06 0.07 0.08 0.08  0.10     5624     3478    1 #> pred[UNCOVER-3: ETN]     0.53 0.02 0.49 0.52 0.53 0.54  0.57     8166     2777    1 #> pred[UNCOVER-3: IXE_Q2W] 0.93 0.01 0.91 0.92 0.93 0.93  0.94     6886     3220    1 #> pred[UNCOVER-3: IXE_Q4W] 0.85 0.01 0.83 0.85 0.85 0.86  0.88     8830     3269    1 #> pred[UNCOVER-3: SEC_150] 0.75 0.04 0.67 0.72 0.75 0.77  0.81     9620     3219    1 #> pred[UNCOVER-3: SEC_300] 0.83 0.03 0.77 0.81 0.83 0.85  0.88     8022     3217    1 plot(pso_pred_FE, ref_line = c(0, 1)) (pso_ranks_FE <- posterior_ranks(pso_fit_FE, lower_better = FALSE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[FIXTURE: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[FIXTURE: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[FIXTURE: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[FIXTURE: IXE_Q4W] 2.23 0.42    2   2   2   2     3     4388     4018    1 #> rank[FIXTURE: SEC_150] 4.00 0.05    4   4   4   4     4     4036       NA    1 #> rank[FIXTURE: SEC_300] 2.77 0.42    2   3   3   3     3     4493     4031    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-1: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-1: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-1: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[UNCOVER-1: IXE_Q4W] 2.23 0.42    2   2   2   2     3     4388     4018    1 #> rank[UNCOVER-1: SEC_150] 4.00 0.05    4   4   4   4     4     4036       NA    1 #> rank[UNCOVER-1: SEC_300] 2.77 0.42    2   3   3   3     3     4493     4031    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-2: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-2: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-2: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[UNCOVER-2: IXE_Q4W] 2.23 0.42    2   2   2   2     3     4388     4018    1 #> rank[UNCOVER-2: SEC_150] 4.00 0.05    4   4   4   4     4     4036       NA    1 #> rank[UNCOVER-2: SEC_300] 2.77 0.42    2   3   3   3     3     4493     4031    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[UNCOVER-3: PBO]     6.00 0.00    6   6   6   6     6       NA       NA   NA #> rank[UNCOVER-3: ETN]     5.00 0.00    5   5   5   5     5       NA       NA   NA #> rank[UNCOVER-3: IXE_Q2W] 1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[UNCOVER-3: IXE_Q4W] 2.23 0.42    2   2   2   2     3     4388     4018    1 #> rank[UNCOVER-3: SEC_150] 4.00 0.05    4   4   4   4     4     4036       NA    1 #> rank[UNCOVER-3: SEC_300] 2.77 0.42    2   3   3   3     3     4493     4031    1 plot(pso_ranks_FE) (pso_rankprobs_FE <- posterior_rank_probs(pso_fit_FE, lower_better = FALSE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             0      0.00      0.00         0         0         1 #> d[FIXTURE: ETN]             0      0.00      0.00         0         1         0 #> d[FIXTURE: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[FIXTURE: IXE_Q4W]         0      0.77      0.23         0         0         0 #> d[FIXTURE: SEC_150]         0      0.00      0.00         1         0         0 #> d[FIXTURE: SEC_300]         0      0.23      0.77         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-1: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-1: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-1: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-1: IXE_Q4W]         0      0.77      0.23         0         0         0 #> d[UNCOVER-1: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-1: SEC_300]         0      0.23      0.77         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-2: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-2: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-2: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-2: IXE_Q4W]         0      0.77      0.23         0         0         0 #> d[UNCOVER-2: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-2: SEC_300]         0      0.23      0.77         0         0         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-3: PBO]             0      0.00      0.00         0         0         1 #> d[UNCOVER-3: ETN]             0      0.00      0.00         0         1         0 #> d[UNCOVER-3: IXE_Q2W]         1      0.00      0.00         0         0         0 #> d[UNCOVER-3: IXE_Q4W]         0      0.77      0.23         0         0         0 #> d[UNCOVER-3: SEC_150]         0      0.00      0.00         1         0         0 #> d[UNCOVER-3: SEC_300]         0      0.23      0.77         0         0         0 plot(pso_rankprobs_FE) (pso_cumrankprobs_FE <- posterior_rank_probs(pso_fit_FE, lower_better = FALSE, cumulative = TRUE)) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             0      0.00         0         0         0         1 #> d[FIXTURE: ETN]             0      0.00         0         0         1         1 #> d[FIXTURE: IXE_Q2W]         1      1.00         1         1         1         1 #> d[FIXTURE: IXE_Q4W]         0      0.77         1         1         1         1 #> d[FIXTURE: SEC_150]         0      0.00         0         1         1         1 #> d[FIXTURE: SEC_300]         0      0.23         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-1: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-1: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-1: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-1: IXE_Q4W]         0      0.77         1         1         1         1 #> d[UNCOVER-1: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-1: SEC_300]         0      0.23         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-2: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-2: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-2: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-2: IXE_Q4W]         0      0.77         1         1         1         1 #> d[UNCOVER-2: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-2: SEC_300]         0      0.23         1         1         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[UNCOVER-3: PBO]             0      0.00         0         0         0         1 #> d[UNCOVER-3: ETN]             0      0.00         0         0         1         1 #> d[UNCOVER-3: IXE_Q2W]         1      1.00         1         1         1         1 #> d[UNCOVER-3: IXE_Q4W]         0      0.77         1         1         1         1 #> d[UNCOVER-3: SEC_150]         0      0.00         0         1         1         1 #> d[UNCOVER-3: SEC_300]         0      0.23         1         1         1         1 plot(pso_cumrankprobs_FE) new_agd_means <- tibble(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3) (pso_releff_FE_new <- relative_effects(pso_fit_FE, newdata = new_agd_means)) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[New 1: ETN]     1.25 0.23 0.81 1.10 1.25 1.40  1.70     5697     3466    1 #> d[New 1: IXE_Q2W] 2.89 0.22 2.46 2.73 2.88 3.04  3.33     6903     2955    1 #> d[New 1: IXE_Q4W] 2.47 0.22 2.05 2.32 2.47 2.62  2.92     6738     2894    1 #> d[New 1: SEC_150] 2.08 0.23 1.63 1.92 2.08 2.23  2.51     7219     3348    1 #> d[New 1: SEC_300] 2.38 0.23 1.94 2.22 2.38 2.54  2.83     6764     3004    1 plot(pso_releff_FE_new, ref_line = 0) new_agd_int <- tibble(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1 ) new_agd_int <- add_integration(new_agd_int,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   cor = pso_net$int_cor,   n_int = 64) (pso_pred_FE_new <- predict(pso_fit_FE,                              type = \"response\",                             newdata = new_agd_int,                             baseline = distr(qnorm, -1.75, 0.08))) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: PBO]     0.06 0.03 0.03 0.04 0.06 0.08  0.12     4860     3543    1 #> pred[New 1: ETN]     0.37 0.06 0.26 0.33 0.37 0.41  0.49     6288     3432    1 #> pred[New 1: IXE_Q2W] 0.90 0.03 0.84 0.88 0.90 0.92  0.94     5208     3390    1 #> pred[New 1: IXE_Q4W] 0.81 0.04 0.73 0.78 0.81 0.83  0.87     5295     3546    1 #> pred[New 1: SEC_150] 0.68 0.05 0.57 0.64 0.68 0.72  0.78     4861     3316    1 #> pred[New 1: SEC_300] 0.78 0.05 0.68 0.75 0.78 0.81  0.86     5510     3582    1 plot(pso_pred_FE_new, ref_line = c(0, 1))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"extended_analysis","dir":"Articles","previous_headings":"","what":"Extended analysis","title":"Example: Plaque psoriasis ML-NMR","text":"now extend network include five studies (four AgD one IPD), recreating analysis Phillippo et al. (2022). larger network allows us assess key assumptions underlying population adjustment.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"preparing-the-data-1","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Preparing the data","title":"Example: Plaque psoriasis ML-NMR","text":"begin, , data transformations covariates set treatment class variable trtclass. small number individuals missing values IPD, simply exclude analysis.","code":"# IPD studies pso_ipd <- plaque_psoriasis_ipd %>%    mutate(     # Variable transformations     bsa = bsa / 100,     weight = weight / 10,     durnpso = durnpso / 10,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL-17 blocker\",                          trtn == 4 ~ \"TNFa blocker\",                          trtn == 7 ~ \"IL-12/23 blocker\"),     # Check complete cases for covariates of interest     is_complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   ) %>%    arrange(studyc, trtn)  # AgD studies pso_agd <- plaque_psoriasis_agd %>%    mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,      bsa_sd = bsa_sd / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     prevsys = prevsys / 100,     psa = psa / 100,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL-17 blocker\",                          trtn == 4 ~ \"TNFa blocker\",                          trtn == 7 ~ \"IL-12/23 blocker\")     ) %>%    arrange(studyc, trtn) pso_ipd %>%    group_by(studyc) %>%    summarise(n_total = n(),             n_missing = sum(!is_complete),              pct_missing = mean(!is_complete) * 100) #> # A tibble: 4 × 4 #>   studyc    n_total n_missing pct_missing #>   <chr>       <int>     <int>       <dbl> #> 1 IXORA-S       260         0       0     #> 2 UNCOVER-1    1296         0       0     #> 3 UNCOVER-2    1221         2       0.164 #> 4 UNCOVER-3    1341         2       0.149  pso_ipd <- filter(pso_ipd, is_complete)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"creating-the-network-1","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Creating the network","title":"Example: Plaque psoriasis ML-NMR","text":"Next set network. set IPD set_ipd() AgD (arm-based) set_agd_arm(), combine together using combine_network(). specify ordered categorical (multinomial) outcome using multi() helper function. outcome data “inclusive” format, .e. lowest category sample size (1 IPD), second category counts achieving PASI 75 greater (≥75%\\ge 75\\% reduction symptoms), third counts achieving PASI 90 greater (≥90%\\ge 90\\% reduction), final category counts achieving PASI 100 (100%100\\% reduction).2 specify treatment classes trt_class = trtclass. create network plot using plot() function applied pso_net network object, choosing scale edges nodes number studies/sample size (weight_edges weight_nodes = TRUE), colour treatment nodes class (show_trt_class = TRUE), nudge treatment names away nodes (nudge = 0.1). customise plot using ggplot syntax alter colour scheme.","code":"pso_net <- combine_network(   set_ipd(pso_ipd,     study = studyc,     trt = trtc,     r = multi(r0 = 1,                PASI75 = pasi75,               PASI90 = pasi90,               PASI100 = pasi100,               type = \"ordered\", inclusive = TRUE),     trt_class = trtclass),   set_agd_arm(pso_agd,     study = studyc,     trt = trtc,     r = multi(r0 = pasi75_n,                PASI75 = pasi75_r,               PASI90 = pasi90_r,               PASI100 = pasi100_r,               type = \"ordered\", inclusive = TRUE),     trt_class = trtclass) )  pso_net #> A network with 4 IPD studies, and 5 AgD studies (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: PBO | IXE_Q2W | IXE_Q4W       #>  UNCOVER-2 4: PBO | IXE_Q2W | IXE_Q4W | ETN #>  UNCOVER-3 4: PBO | IXE_Q2W | IXE_Q4W | ETN #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study    Treatment arms                   #>  CLEAR    2: SEC_300 | UST                 #>  ERASURE  3: PBO | SEC_150 | SEC_300       #>  FEATURE  3: PBO | SEC_150 | SEC_300       #>  FIXTURE  4: PBO | ETN | SEC_150 | SEC_300 #>  JUNCTURE 3: PBO | SEC_150 | SEC_300       #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 7, in 4 classes #> Total number of studies: 9 #> Reference treatment is: PBO #> Network is connected class_pal <- c(\"#D95F02\", \"#7570B3\", \"#E7298A\", \"#E6AB02\")  plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE, nudge = 0.1) +   ggraph::scale_edge_colour_manual(\"Data\",                                     values = c(AgD = \"#113259\", IPD = \"#55A480\")) +   scale_fill_manual(\"Treatment class\",                      values = class_pal,                     aesthetics = c(\"fill\", \"colour\")) +   guides(edge_colour = guide_legend(override.aes = list(edge_width = 2)),          fill = guide_legend(override.aes = list(size = 2))) #> Scale for edge_colour is already present. #> Adding another scale for edge_colour, which will replace the existing scale. #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"numerical-integration-for-ml-nmr-models","dir":"Articles","previous_headings":"Extended analysis > Setup","what":"Numerical integration for ML-NMR models","title":"Example: Plaque psoriasis ML-NMR","text":"add integration points AgD studies network using add_integration() function, specifying chosen marginal distribution covariate using distr() function. , specify Gamma distributions weight duration psoriasis, logit-Normal distribution body surface area, Bernoulli distributions previous systemic treatment psoriatic arthritis binary covariates. Since know correlations covariates AgD studies, impute weighted mean correlations IPD studies (default option).","code":"pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"ml-nmr-model","dir":"Articles","previous_headings":"Extended analysis","what":"ML-NMR model","title":"Example: Plaque psoriasis ML-NMR","text":"Using nma() function, fit (fixed effect) ML-NMR model includes main effects (prognostic terms) covariate-treatment interactions (effect-modifying terms) five covariates. Ideally, fit independent interaction terms treatment; however, requires either IPD several AgD studies range covariate values treatment. data insufficient fit independent interaction terms treatment, make shared effect modifier assumption within class treatments (Phillippo et al. 2016) specify common interaction terms within treatment class (class_interactions = \"common\"). , specify N(0,102)\\mathrm{N}(0, 10^2) prior distributions study-specific intercepts, treatment effects, regression parameters. However, since now ordered multinomial likelihood also need specify priors differences latent cutoffs outcome category; choose improper flat prior U(−∞,∞)\\mathrm{U}(-\\infty,\\infty) automatically truncated meet ordering constraints (prior_aux = flat()).","code":"pso_fit_FE <- nma(pso_net,                    trt_effects = \"fixed\",                   link = \"probit\",                    regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_aux = flat(),                   QR = TRUE,                   init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit_FE #> A fixed effects ML-NMR with a ordered likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.7947485 0.6504375 0.2973544 8.9165934 0.2074278  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.03    0.00 0.06    -0.09    -0.01     0.03     0.08 #> beta[prevsys]                              -0.17    0.00 0.15    -0.46    -0.28    -0.18    -0.07 #> beta[bsa]                                  -0.12    0.01 0.44    -1.02    -0.40    -0.11     0.18 #> beta[weight]                                0.04    0.00 0.03    -0.01     0.03     0.04     0.06 #> beta[psa]                                  -0.07    0.00 0.17    -0.43    -0.20    -0.07     0.04 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.16    -0.07    -0.02     0.03 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.06    0.00 0.10    -0.26    -0.13    -0.07     0.01 #> beta[durnpso:.trtclassIL-17 blocker]       -0.02    0.00 0.06    -0.15    -0.07    -0.02     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.20    0.00 0.18    -0.16     0.08     0.20     0.32 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.45    0.00 0.32    -0.20     0.24     0.46     0.68 #> beta[prevsys:.trtclassIL-17 blocker]        0.17    0.00 0.16    -0.15     0.06     0.17     0.28 #> beta[bsa:.trtclassTNFa blocker]             0.26    0.01 0.51    -0.71    -0.08     0.25     0.59 #> beta[bsa:.trtclassIL-12/23 blocker]         0.61    0.01 0.66    -0.65     0.17     0.61     1.06 #> beta[bsa:.trtclassIL-17 blocker]            0.29    0.01 0.46    -0.60    -0.02     0.28     0.58 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.18    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.18    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.06    0.00 0.20    -0.46    -0.19    -0.05     0.08 #> beta[psa:.trtclassIL-12/23 blocker]         0.13    0.01 0.34    -0.53    -0.10     0.12     0.35 #> beta[psa:.trtclassIL-17 blocker]            0.09    0.00 0.18    -0.26    -0.03     0.09     0.22 #> d[ETN]                                      1.58    0.00 0.07     1.44     1.53     1.58     1.63 #> d[IXE_Q2W]                                  2.91    0.00 0.07     2.77     2.86     2.91     2.96 #> d[IXE_Q4W]                                  2.69    0.00 0.08     2.55     2.64     2.69     2.74 #> d[SEC_150]                                  2.19    0.00 0.08     2.03     2.13     2.19     2.25 #> d[SEC_300]                                  2.60    0.00 0.08     2.44     2.54     2.60     2.65 #> d[UST]                                      2.13    0.00 0.11     1.91     2.06     2.13     2.21 #> lp__                                    -7752.94    0.10 4.30 -7762.02 -7755.80 -7752.63 -7749.89 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.65     0.68     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.49     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.15  3278    1 #> beta[prevsys]                               0.13  3239    1 #> beta[bsa]                                   0.73  2993    1 #> beta[weight]                                0.10  2717    1 #> beta[psa]                                   0.25  3200    1 #> beta[durnpso:.trtclassTNFa blocker]         0.12  3645    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.14  3762    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.11  3711    1 #> beta[prevsys:.trtclassTNFa blocker]         0.55  3330    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.05  4366    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.47  3593    1 #> beta[bsa:.trtclassTNFa blocker]             1.30  3147    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.89  3386    1 #> beta[bsa:.trtclassIL-17 blocker]            1.22  3490    1 #> beta[weight:.trtclassTNFa blocker]         -0.10  3342    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.00  4100    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  3080    1 #> beta[psa:.trtclassTNFa blocker]             0.34  3511    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.80  3769    1 #> beta[psa:.trtclassIL-17 blocker]            0.46  3732    1 #> d[ETN]                                      1.72  2114    1 #> d[IXE_Q2W]                                  3.06  2708    1 #> d[IXE_Q4W]                                  2.84  2949    1 #> d[SEC_150]                                  2.36  2357    1 #> d[SEC_300]                                  2.76  2456    1 #> d[UST]                                      2.36  3349    1 #> lp__                                    -7745.56  1701    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  4016    1 #> cc[PASI100]                                 1.58  3777    1 #>  #> Samples were drawn using NUTS(diag_e) at Tue Jan  9 11:53:40 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1)."},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-assumptions","dir":"Articles","previous_headings":"Extended analysis","what":"Assessing assumptions","title":"Example: Plaque psoriasis ML-NMR","text":"first analysis, small network made assessing assumptions difficult. larger network (although still nine studies) greater opportunity assess key assumptions. key assumption made ML-NMR (indeed population adjustment methods connected networks) conditional constancy relative effects assumption (Phillippo et al. 2016). means unobserved effect modifiers, relative effects constant given included effect-modifying covariates. assumption implies residual heterogeneity inconsistency, can assessed using standard network meta-analysis techniques. assess residual heterogeneity using random effects model, residual inconsistency using unrelated mean effects (UME) model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-residual-heterogeneity-with-a-random-effects-ml-nmr","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Assessing residual heterogeneity with a random effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"First, fit random effects model assess residual heterogeneity. call nma() function identical fixed effect model , except now specify trt_effects = \"random\" need provide prior -study heterogeneity (choose half-N(0,2.52)\\textrm{half-N}(0, 2.5^2) prior prior_het = half_normal(scale = 2.5). estimated -study heterogeneity standard deviation tau small compared relative treatment effects. compare model fit using DIC: DIC lower RE model, indicating may residual heterogeneity network conditional constancy relative effects assumption may invalid—may additional effect modifiers accounted . result different actual analysis reported Phillippo et al. (2022), since using synthetic IPD simulated closely resemble original IPD. actual analysis DIC similar FE RE models, might choose parsimonious FE model based DIC alone, evidence residual heterogeneity network.","code":"pso_fit_RE <- nma(pso_net,                    trt_effects = \"random\",                   link = \"probit\",                    regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                   class_interactions = \"common\",                   prior_intercept = normal(scale = 10),                   prior_trt = normal(scale = 10),                   prior_reg = normal(scale = 10),                   prior_aux = flat(),                   prior_het = half_normal(scale = 2.5),                   QR = TRUE,                   init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. #> Warning: There were 1 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems pso_fit_RE #> A random effects ML-NMR with a ordered likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.7947485 0.6504375 0.2973544 8.9165934 0.2074278  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.04    0.00 0.06    -0.09     0.00     0.04     0.08 #> beta[prevsys]                              -0.16    0.00 0.16    -0.47    -0.27    -0.16    -0.05 #> beta[bsa]                                  -0.13    0.01 0.47    -1.09    -0.43    -0.11     0.20 #> beta[weight]                                0.05    0.00 0.03    -0.01     0.03     0.05     0.07 #> beta[psa]                                  -0.07    0.00 0.18    -0.41    -0.19    -0.07     0.05 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.17    -0.07    -0.03     0.03 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.07    0.00 0.10    -0.26    -0.14    -0.07     0.00 #> beta[durnpso:.trtclassIL-17 blocker]       -0.03    0.00 0.07    -0.16    -0.07    -0.03     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.19    0.00 0.18    -0.16     0.07     0.19     0.31 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.44    0.00 0.33    -0.22     0.22     0.44     0.67 #> beta[prevsys:.trtclassIL-17 blocker]        0.16    0.00 0.17    -0.17     0.05     0.16     0.27 #> beta[bsa:.trtclassTNFa blocker]             0.25    0.01 0.53    -0.75    -0.12     0.24     0.59 #> beta[bsa:.trtclassIL-12/23 blocker]         0.63    0.01 0.66    -0.65     0.18     0.62     1.07 #> beta[bsa:.trtclassIL-17 blocker]            0.30    0.01 0.48    -0.60    -0.04     0.30     0.62 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.19    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.19    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.06    0.00 0.21    -0.47    -0.20    -0.06     0.08 #> beta[psa:.trtclassIL-12/23 blocker]         0.11    0.00 0.34    -0.55    -0.12     0.11     0.34 #> beta[psa:.trtclassIL-17 blocker]            0.08    0.00 0.19    -0.29    -0.04     0.08     0.21 #> d[ETN]                                      1.59    0.00 0.11     1.38     1.52     1.59     1.65 #> d[IXE_Q2W]                                  2.93    0.00 0.11     2.72     2.86     2.93     3.00 #> d[IXE_Q4W]                                  2.71    0.00 0.11     2.48     2.64     2.71     2.78 #> d[SEC_150]                                  2.22    0.00 0.12     2.00     2.14     2.21     2.29 #> d[SEC_300]                                  2.64    0.00 0.12     2.42     2.56     2.63     2.71 #> d[UST]                                      2.17    0.00 0.17     1.85     2.06     2.16     2.27 #> lp__                                    -7761.18    0.20 6.16 -7774.24 -7765.11 -7760.94 -7756.88 #> tau                                         0.14    0.00 0.07     0.03     0.09     0.13     0.17 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.65     0.68     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.49     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.16  4028    1 #> beta[prevsys]                               0.15  3931    1 #> beta[bsa]                                   0.75  3963    1 #> beta[weight]                                0.10  4005    1 #> beta[psa]                                   0.28  3835    1 #> beta[durnpso:.trtclassTNFa blocker]         0.12  4080    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.13  4244    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.10  4440    1 #> beta[prevsys:.trtclassTNFa blocker]         0.54  4143    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.07  4555    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.48  4517    1 #> beta[bsa:.trtclassTNFa blocker]             1.33  4333    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.96  4933    1 #> beta[bsa:.trtclassIL-17 blocker]            1.30  4329    1 #> beta[weight:.trtclassTNFa blocker]         -0.10  4309    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.00  4940    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  4681    1 #> beta[psa:.trtclassTNFa blocker]             0.35  3883    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.78  4810    1 #> beta[psa:.trtclassIL-17 blocker]            0.44  4230    1 #> d[ETN]                                      1.81  2539    1 #> d[IXE_Q2W]                                  3.16  2657    1 #> d[IXE_Q4W]                                  2.93  2394    1 #> d[SEC_150]                                  2.47  2433    1 #> d[SEC_300]                                  2.90  2193    1 #> d[UST]                                      2.50  3305    1 #> lp__                                    -7750.02   985    1 #> tau                                         0.30   622    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  5611    1 #> cc[PASI100]                                 1.58  5856    1 #>  #> Samples were drawn using NUTS(diag_e) at Tue Jan  9 12:36:43 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). (pso_dic_FE <- dic(pso_fit_FE)) #> Residual deviance: 8811.2 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.3 (pso_dic_RE <- dic(pso_fit_RE)) #> Residual deviance: 8799.8 (on 12387 data points) #>                pD: 42.3 #>               DIC: 8842.1"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"assessing-residual-inconsistency-with-an-unrelated-mean-effects-ml-nmr","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Assessing residual inconsistency with an unrelated mean effects ML-NMR","title":"Example: Plaque psoriasis ML-NMR","text":"assess residual inconsistency using unrelated mean effects model (Dias et al. 2011). , call nma() function identical, except time specify consistency = \"ume\". Node-splitting also possibility (consistency = \"nodesplit\"), takes substantially longer since model re-run node-split comparison. proceed analysis Phillippo et al. (2022) fit fixed effect UME model (since evidence heterogeneity actual analysis); however, recreated analysis using synthetic IPD evidence heterogeneity really fit random effects UME model instead. compare model fit FE ML-NMR model using DIC. DIC values similar FE model (assuming consistency) UME (inconsistency) model, suggests evidence inconsistency overall. also important compare residual deviance contributions model see whether points fit better UME model, can also indicate inconsistency. Using plot() function produces “dev-dev” plot residual deviance contributions either model.  points lie line equality, evidence inconsistency. random effects models fitted heterogeneity estimates also compared drop tau UME model can also indicate inconsistency.","code":"pso_fit_UME <- nma(pso_net,                     trt_effects = \"fixed\",                    consistency = \"ume\",                    link = \"probit\",                     regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt,                    class_interactions = \"common\",                    prior_intercept = normal(scale = 10),                    prior_trt = normal(scale = 10),                    prior_reg = normal(scale = 10),                    prior_aux = flat(),                    QR = TRUE,                    init_r = 0.5) #> Note: Setting \"PBO\" as the network reference treatment. pso_fit_UME #> A fixed effects ML-NMR with a ordered likelihood (probit link). #> An inconsistency model ('ume') was fitted. #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.7947485 0.6504375 0.2973544 8.9165934 0.2074278  #> Inference for Stan model: ordered_multinomial. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                             mean se_mean   sd     2.5%      25%      50%      75% #> beta[durnpso]                               0.04    0.00 0.06    -0.08     0.00     0.04     0.08 #> beta[prevsys]                              -0.18    0.00 0.16    -0.48    -0.28    -0.18    -0.07 #> beta[bsa]                                  -0.10    0.01 0.44    -0.99    -0.38    -0.09     0.20 #> beta[weight]                                0.04    0.00 0.03    -0.01     0.03     0.04     0.06 #> beta[psa]                                  -0.08    0.00 0.16    -0.40    -0.19    -0.08     0.03 #> beta[durnpso:.trtclassTNFa blocker]        -0.02    0.00 0.07    -0.16    -0.07    -0.02     0.02 #> beta[durnpso:.trtclassIL-12/23 blocker]    -0.06    0.00 0.10    -0.26    -0.13    -0.07     0.00 #> beta[durnpso:.trtclassIL-17 blocker]       -0.02    0.00 0.06    -0.14    -0.07    -0.02     0.02 #> beta[prevsys:.trtclassTNFa blocker]         0.20    0.00 0.18    -0.15     0.09     0.20     0.33 #> beta[prevsys:.trtclassIL-12/23 blocker]     0.45    0.01 0.35    -0.28     0.23     0.47     0.70 #> beta[prevsys:.trtclassIL-17 blocker]        0.17    0.00 0.16    -0.15     0.06     0.18     0.29 #> beta[bsa:.trtclassTNFa blocker]             0.24    0.01 0.50    -0.74    -0.10     0.23     0.58 #> beta[bsa:.trtclassIL-12/23 blocker]         0.60    0.01 0.66    -0.71     0.17     0.60     1.04 #> beta[bsa:.trtclassIL-17 blocker]            0.27    0.01 0.46    -0.61    -0.05     0.26     0.57 #> beta[weight:.trtclassTNFa blocker]         -0.16    0.00 0.03    -0.23    -0.19    -0.16    -0.14 #> beta[weight:.trtclassIL-12/23 blocker]     -0.09    0.00 0.05    -0.18    -0.12    -0.09    -0.06 #> beta[weight:.trtclassIL-17 blocker]        -0.13    0.00 0.03    -0.19    -0.15    -0.13    -0.11 #> beta[psa:.trtclassTNFa blocker]            -0.05    0.00 0.19    -0.44    -0.18    -0.05     0.08 #> beta[psa:.trtclassIL-12/23 blocker]         0.12    0.00 0.34    -0.53    -0.11     0.13     0.36 #> beta[psa:.trtclassIL-17 blocker]            0.10    0.00 0.17    -0.24    -0.02     0.10     0.21 #> d[ETN vs. PBO]                              1.58    0.00 0.07     1.44     1.53     1.58     1.63 #> d[IXE_Q2W vs. PBO]                          2.91    0.00 0.07     2.77     2.86     2.91     2.96 #> d[IXE_Q4W vs. PBO]                          2.69    0.00 0.07     2.55     2.64     2.69     2.74 #> d[SEC_150 vs. PBO]                          2.19    0.00 0.08     2.03     2.14     2.19     2.25 #> d[SEC_300 vs. PBO]                          2.60    0.00 0.08     2.43     2.54     2.60     2.66 #> d[UST vs. IXE_Q2W]                         -0.79    0.00 0.16    -1.10    -0.90    -0.79    -0.68 #> d[UST vs. SEC_300]                         -0.47    0.00 0.09    -0.65    -0.53    -0.47    -0.40 #> lp__                                    -7756.43    0.11 4.32 -7765.88 -7759.08 -7756.13 -7753.33 #> cc[PASI75]                                  0.00     NaN 0.00     0.00     0.00     0.00     0.00 #> cc[PASI90]                                  0.69    0.00 0.02     0.65     0.67     0.69     0.70 #> cc[PASI100]                                 1.53    0.00 0.02     1.48     1.52     1.53     1.55 #>                                            97.5% n_eff Rhat #> beta[durnpso]                               0.15  3284    1 #> beta[prevsys]                               0.12  3119    1 #> beta[bsa]                                   0.74  3357    1 #> beta[weight]                                0.10  3195    1 #> beta[psa]                                   0.25  3296    1 #> beta[durnpso:.trtclassTNFa blocker]         0.11  3451    1 #> beta[durnpso:.trtclassIL-12/23 blocker]     0.14  4341    1 #> beta[durnpso:.trtclassIL-17 blocker]        0.10  3853    1 #> beta[prevsys:.trtclassTNFa blocker]         0.55  3201    1 #> beta[prevsys:.trtclassIL-12/23 blocker]     1.08  4743    1 #> beta[prevsys:.trtclassIL-17 blocker]        0.48  3578    1 #> beta[bsa:.trtclassTNFa blocker]             1.23  3593    1 #> beta[bsa:.trtclassIL-12/23 blocker]         1.85  4364    1 #> beta[bsa:.trtclassIL-17 blocker]            1.20  3941    1 #> beta[weight:.trtclassTNFa blocker]         -0.09  3555    1 #> beta[weight:.trtclassIL-12/23 blocker]      0.00  4746    1 #> beta[weight:.trtclassIL-17 blocker]        -0.07  3758    1 #> beta[psa:.trtclassTNFa blocker]             0.32  3727    1 #> beta[psa:.trtclassIL-12/23 blocker]         0.77  4746    1 #> beta[psa:.trtclassIL-17 blocker]            0.45  3793    1 #> d[ETN vs. PBO]                              1.73  2605    1 #> d[IXE_Q2W vs. PBO]                          3.05  2642    1 #> d[IXE_Q4W vs. PBO]                          2.84  2998    1 #> d[SEC_150 vs. PBO]                          2.36  2650    1 #> d[SEC_300 vs. PBO]                          2.77  2861    1 #> d[UST vs. IXE_Q2W]                         -0.47  5596    1 #> d[UST vs. SEC_300]                         -0.29  6888    1 #> lp__                                    -7749.04  1498    1 #> cc[PASI75]                                  0.00   NaN  NaN #> cc[PASI90]                                  0.72  3023    1 #> cc[PASI100]                                 1.58  3164    1 #>  #> Samples were drawn using NUTS(diag_e) at Tue Jan  9 12:47:42 2024. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). pso_dic_FE #> Residual deviance: 8811.2 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.3 (pso_dic_UME <- dic(pso_fit_UME)) #> Residual deviance: 8811.8 (on 12387 data points) #>                pD: 36.5 #>               DIC: 8848.4 plot(pso_dic_FE, pso_dic_UME, show_uncertainty = FALSE) +   xlab(\"Residual deviance - consistency model\") +   ylab(\"Residual deviance - inconsistency (UME) model\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"relaxing-the-shared-effect-modifier-assumption","dir":"Articles","previous_headings":"Extended analysis > Assessing assumptions","what":"Relaxing the shared effect modifier assumption","title":"Example: Plaque psoriasis ML-NMR","text":"treatment classes network follows: fitted common interaction terms within treatment class, shared effect modifier assumption, order make model estimable available data. Note interleukin-17 blocker class one treatment; etanercept ustekinumab classes unaffected specifying class_interactions = \"common\". assess assumption simply fit independent interaction terms treatments effect modifiers sufficient data. Instead, relax assumption one covariate time, estimating independent interactions one covariate whilst keeping shared effect modifier assumption (common interactions within treatment class) covariates. specify relaxed models, need somehow mix class_interactions = \"common\" class_interactions = \"independent\" different covariates. way .trt .trtclass specials specifying regression model. see works, first note model making shared effect modifiers assumption can written equivalently using .trtclass special .trtclass special essentially factor variable containing treatment classes, available time treatment classes specified network; regression formula therefore single interaction term covariate within treatment class (result specifying class_interactions = \"common\" ). Finally, fit independent interactions single covariate, say durnpso, split using .trt special class_interactions = \"independent\" (.e. telling model combine interactions .trt within classes): Since fitting several models, let us set list model specifications iterate . Comparing model fit using DIC models similar higher DIC original model making shared effect modifier assumption covariates, exception model independent interactions weight slightly lower DIC. also visually examine differences estimated interaction terms original model (shared effect modifier assumption covariates) relaxed models (independent interactions, one covariate time).  independent interaction estimates similar common interaction estimates, much uncertainty—particularly secukinumab regimens estimated aggregate data. exception weight, suggestion covariate may interact differently secukinumab treatment regimens ixekizumab regimens. However, credible intervals secukinumab interactions wide overlap ixekizumab regimens common interaction. Overall, weak evidence shared effect modifier assumption (class interleukin-17 blockers) may invalid weight. Since fitting multiple models mindful multiple testing possibility differences occurred chance. hand, approach likely low power detect violations shared effect modifier assumption, particularly data lacking. case, results model relaxing shared effect modifier assumption weight similar original model (see Phillippo et al. 2022).","code":"data.frame(classes = pso_net$classes, treatments = pso_net$treatments) #>            classes treatments #> 1          Placebo        PBO #> 2     TNFa blocker        ETN #> 3    IL-17 blocker    IXE_Q2W #> 4    IL-17 blocker    IXE_Q4W #> 5    IL-17 blocker    SEC_150 #> 6    IL-17 blocker    SEC_300 #> 7 IL-12/23 blocker        UST regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt, class_interactions = \"common\" regression = ~(durnpso + prevsys + bsa + weight + psa)*.trtclass regression = ~(prevsys + bsa + weight + psa)*.trtclass + durnpso*.trt, class_interactions = \"independent\" noSEM_mods <- list(   durnpso = ~(prevsys + bsa + weight + psa)*.trtclass + durnpso*.trt,   prevsys = ~(durnpso + bsa + weight + psa)*.trtclass + prevsys*.trt,   bsa = ~(durnpso + prevsys + weight + psa)*.trtclass + bsa*.trt,   weight = ~(durnpso + prevsys + bsa + psa)*.trtclass + weight*.trt,   psa = ~(durnpso + prevsys + bsa + weight)*.trtclass + psa*.trt   )  noSEM_fits <- noSEM_mods  for (m in 1:length(noSEM_mods)) {   cat(\"Fitting model with independent interactions for\", names(noSEM_mods)[m], \"\\n\")      noSEM_fits[[m]] <-      nma(pso_net,          trt_effects = \"fixed\",         link = \"probit\",          regression = noSEM_mods[[m]],         class_interactions = \"independent\",         prior_intercept = normal(scale = 10),         prior_trt = normal(scale = 10),         prior_reg = normal(scale = 10),         prior_aux = flat(),         QR = TRUE,         init_r = 0.5,         # Using save_warmup = FALSE reduces memory footprint when          # fitting many models in one session         save_warmup = FALSE) } #> Fitting model with independent interactions for durnpso #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for prevsys #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for bsa #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for weight #> Note: Setting \"PBO\" as the network reference treatment. #> Fitting model with independent interactions for psa #> Note: Setting \"PBO\" as the network reference treatment. pso_dic_FE #> Residual deviance: 8811.2 (on 12387 data points) #>                pD: 36 #>               DIC: 8847.3 lapply(noSEM_fits, dic) #> $durnpso #> Residual deviance: 8812.4 (on 12387 data points) #>                pD: 37.7 #>               DIC: 8850.1 #>  #> $prevsys #> Residual deviance: 8813 (on 12387 data points) #>                pD: 37.6 #>               DIC: 8850.6 #>  #> $bsa #> Residual deviance: 8812.8 (on 12387 data points) #>                pD: 37.7 #>               DIC: 8850.6 #>  #> $weight #> Residual deviance: 8807.3 (on 12387 data points) #>                pD: 38 #>               DIC: 8845.3 #>  #> $psa #> Residual deviance: 8812 (on 12387 data points) #>                pD: 38.5 #>               DIC: 8850.5 library(purrr) library(stringr) library(forcats)  # Extract draws from relaxed models imap_dfr(noSEM_fits,         ~as_tibble(as.matrix(.x, pars = \"beta\")) %>%             pivot_longer(cols = everything(), names_to = \"parameter\", values_to = \"value\") %>%             filter(str_detect(parameter, paste0(\"(IXE|SEC).+:\", .y))) %>%             mutate(model = .y)) %>%       # Add in draws from the original model   bind_rows(     as_tibble(as.matrix(pso_fit_FE, pars = \"beta\")) %>%      pivot_longer(cols = everything(), names_to = \"parameter\", values_to = \"value\") %>%      filter(str_detect(parameter, \":.+IL\\\\-17 blocker\")) %>%      mutate(model = \"all\")   ) %>%       mutate(     # Rescale BSA to per 10%      value = if_else(str_detect(parameter, \"bsa\"), value / 10, value),     # Create labels     covariate = str_extract(parameter, \"durnpso|prevsys|bsa|weight|psa\"),     covariatef = recode_factor(covariate,                                durnpso = \"Duration of psoriasis, per 10 years\",                                prevsys = \"Previous systemic use\",                                bsa = \"Body surface area, per 10%\",                                weight = \"Weight, per 10 kg\",                                psa = \"Psoriatic arthritis\"),     treatment = str_remove(str_extract(parameter, \"\\\\.trt(class)?.+?(?=[\\\\]:])\"),                            \"\\\\.trt(class)?\"),     Interactions = fct_collapse(factor(model),                                  Common = \"all\",                                  other_level = \"Independent\")) %>%     # Plot ggplot(aes(x = value, y = fct_rev(treatment), colour = Interactions, fill = Interactions)) +   geom_vline(xintercept = 0, colour = \"grey70\") +   ggdist::stat_halfeye(normalize = \"panels\", slab_alpha = 0.3, .width = c(0, 0.95)) +   facet_wrap(\"covariatef\", scales = \"free\") +   xlab(\"Interaction effect (SMD)\") +    ylab(\"Treatment / Class\") +   scale_colour_manual(values = c(Common = \"#7B3294\", Independent = \"#91D388\"),                       aesthetics = c(\"colour\", \"fill\")) +   theme_multinma() +   theme(legend.position = c(0.85, 0.2))"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"study-populations-included-in-the-network","dir":"Articles","previous_headings":"Extended analysis > Producing relative effects and event probabilities","what":"Study populations included in the network","title":"Example: Plaque psoriasis ML-NMR","text":"Population-average treatment effects can produced study populations represented network using relative_effects() function. relative effects can plotted using plot() function.  Similarly, average response probabilities treatment, study population, PASI cutoff can produced using predict() function. specify type = \"response\" produce predicted probabilities (rather probit-probabilities). , can plotted using plot() function.","code":"(pso_releff_FE <- relative_effects(pso_fit_FE)) #> ------------------------------------------------------------------ Study: CLEAR ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.73    0.66 0.32   8.74 0.16 #>  #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[CLEAR: ETN]     1.62 0.08 1.47 1.57 1.62 1.67  1.77     2191     2895    1 #> d[CLEAR: IXE_Q2W] 2.94 0.08 2.78 2.89 2.94 2.99  3.10     2745     2706    1 #> d[CLEAR: IXE_Q4W] 2.72 0.08 2.57 2.67 2.72 2.78  2.88     2975     2682    1 #> d[CLEAR: SEC_150] 2.22 0.09 2.05 2.16 2.22 2.28  2.39     2365     2528    1 #> d[CLEAR: SEC_300] 2.63 0.08 2.46 2.57 2.63 2.68  2.80     2411     2959    1 #> d[CLEAR: UST]     2.17 0.11 1.95 2.09 2.16 2.24  2.38     3207     2921    1 #>  #> ---------------------------------------------------------------- Study: ERASURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.69    0.61 0.32   8.86 0.23 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[ERASURE: ETN]     1.59 0.07 1.44 1.54 1.59 1.64  1.73     2244     2968    1 #> d[ERASURE: IXE_Q2W] 2.92 0.08 2.77 2.87 2.92 2.97  3.08     2777     2821    1 #> d[ERASURE: IXE_Q4W] 2.70 0.08 2.56 2.65 2.70 2.75  2.86     3019     2884    1 #> d[ERASURE: SEC_150] 2.20 0.08 2.04 2.14 2.20 2.26  2.37     2411     2749    1 #> d[ERASURE: SEC_300] 2.61 0.08 2.45 2.55 2.61 2.66  2.77     2508     2891    1 #> d[ERASURE: UST]     2.14 0.12 1.91 2.06 2.14 2.22  2.37     3493     3081    1 #>  #> ---------------------------------------------------------------- Study: FEATURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.9    0.67 0.32   9.17 0.15 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[FEATURE: ETN]     1.55 0.07 1.41 1.50 1.55 1.60  1.70     2253     3017    1 #> d[FEATURE: IXE_Q2W] 2.88 0.08 2.73 2.83 2.88 2.93  3.04     2881     2641    1 #> d[FEATURE: IXE_Q4W] 2.66 0.08 2.51 2.61 2.66 2.71  2.82     3121     3016    1 #> d[FEATURE: SEC_150] 2.16 0.08 2.00 2.10 2.16 2.22  2.33     2421     2566    1 #> d[FEATURE: SEC_300] 2.57 0.08 2.41 2.51 2.57 2.62  2.73     2530     2830    1 #> d[FEATURE: UST]     2.12 0.11 1.90 2.05 2.12 2.19  2.34     3432     3215    1 #>  #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[FIXTURE: ETN]     1.69 0.08 1.53 1.63 1.68 1.74  1.85     2382     2730    1 #> d[FIXTURE: IXE_Q2W] 2.99 0.09 2.82 2.93 2.99 3.05  3.17     2834     2794    1 #> d[FIXTURE: IXE_Q4W] 2.77 0.09 2.61 2.72 2.77 2.83  2.95     3045     2875    1 #> d[FIXTURE: SEC_150] 2.27 0.09 2.10 2.21 2.27 2.33  2.45     2406     2615    1 #> d[FIXTURE: SEC_300] 2.68 0.09 2.51 2.62 2.68 2.74  2.86     2408     2992    1 #> d[FIXTURE: UST]     2.20 0.12 1.97 2.12 2.20 2.28  2.43     3246     3097    1 #>  #> ---------------------------------------------------------------- Study: IXORA-S ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.67    0.92 0.32   8.78 0.13 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[IXORA-S: ETN]     1.67 0.10 1.48 1.60 1.67 1.73  1.86     2140     2711    1 #> d[IXORA-S: IXE_Q2W] 2.98 0.10 2.79 2.91 2.97 3.04  3.17     2546     2835    1 #> d[IXORA-S: IXE_Q4W] 2.76 0.10 2.57 2.69 2.76 2.82  2.96     2763     2864    1 #> d[IXORA-S: SEC_150] 2.25 0.10 2.05 2.18 2.25 2.33  2.46     2373     3009    1 #> d[IXORA-S: SEC_300] 2.66 0.10 2.47 2.59 2.66 2.73  2.87     2418     3124    1 #> d[IXORA-S: UST]     2.28 0.13 2.04 2.19 2.27 2.36  2.53     2946     2530    1 #>  #> --------------------------------------------------------------- Study: JUNCTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.99    0.55 0.27   9.17 0.23 #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[JUNCTURE: ETN]     1.51 0.07 1.37 1.46 1.51 1.56  1.65     2419     3021    1 #> d[JUNCTURE: IXE_Q2W] 2.85 0.07 2.71 2.80 2.85 2.90  3.00     3004     2766    1 #> d[JUNCTURE: IXE_Q4W] 2.63 0.07 2.49 2.59 2.63 2.68  2.78     3295     3225    1 #> d[JUNCTURE: SEC_150] 2.13 0.08 1.97 2.07 2.13 2.18  2.30     2559     2584    1 #> d[JUNCTURE: SEC_300] 2.54 0.08 2.38 2.48 2.54 2.59  2.70     2737     2431    1 #> d[JUNCTURE: UST]     2.04 0.13 1.78 1.94 2.03 2.12  2.31     3874     3205    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-1: ETN]     1.53 0.08 1.38 1.48 1.53 1.58  1.68     2019     2694    1 #> d[UNCOVER-1: IXE_Q2W] 2.88 0.08 2.74 2.83 2.88 2.93  3.03     2590     2963    1 #> d[UNCOVER-1: IXE_Q4W] 2.66 0.08 2.51 2.61 2.66 2.71  2.81     2771     2664    1 #> d[UNCOVER-1: SEC_150] 2.16 0.09 1.99 2.10 2.16 2.22  2.33     2325     2735    1 #> d[UNCOVER-1: SEC_300] 2.57 0.09 2.40 2.51 2.57 2.63  2.74     2452     2753    1 #> d[UNCOVER-1: UST]     2.12 0.12 1.88 2.04 2.12 2.20  2.36     3351     3318    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-2: ETN]     1.53 0.07 1.39 1.48 1.53 1.58  1.67     2151     2749    1 #> d[UNCOVER-2: IXE_Q2W] 2.87 0.07 2.73 2.82 2.87 2.92  3.01     2708     2688    1 #> d[UNCOVER-2: IXE_Q4W] 2.65 0.07 2.51 2.60 2.65 2.70  2.79     2977     2739    1 #> d[UNCOVER-2: SEC_150] 2.15 0.08 1.99 2.09 2.15 2.20  2.31     2451     2480    1 #> d[UNCOVER-2: SEC_300] 2.56 0.08 2.40 2.50 2.56 2.61  2.72     2566     2563    1 #> d[UNCOVER-2: UST]     2.08 0.12 1.85 2.00 2.08 2.17  2.33     3490     3316    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[UNCOVER-3: ETN]     1.55 0.07 1.41 1.50 1.55 1.60  1.69     2315     2954    1 #> d[UNCOVER-3: IXE_Q2W] 2.88 0.07 2.74 2.83 2.88 2.93  3.03     2846     2790    1 #> d[UNCOVER-3: IXE_Q4W] 2.67 0.07 2.52 2.62 2.67 2.72  2.81     3132     2866    1 #> d[UNCOVER-3: SEC_150] 2.16 0.08 2.01 2.11 2.16 2.22  2.32     2481     2445    1 #> d[UNCOVER-3: SEC_300] 2.57 0.08 2.41 2.52 2.57 2.62  2.73     2603     2581    1 #> d[UNCOVER-3: UST]     2.08 0.12 1.85 2.00 2.08 2.16  2.33     3588     3148    1 plot(pso_releff_FE, ref_line = 0) (pso_pred_FE <- predict(pso_fit_FE, type = \"response\")) #> ------------------------------------------------------------------ Study: CLEAR ----  #>  #>                               mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[CLEAR: PBO, PASI75]      0.09 0.02 0.07 0.08 0.09 0.10  0.13     3226     2898    1 #> pred[CLEAR: PBO, PASI90]      0.02 0.01 0.01 0.02 0.02 0.03  0.04     3516     3005    1 #> pred[CLEAR: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3935     2940    1 #> pred[CLEAR: ETN, PASI75]      0.61 0.03 0.54 0.58 0.61 0.63  0.67     6487     2944    1 #> pred[CLEAR: ETN, PASI90]      0.35 0.03 0.29 0.32 0.35 0.37  0.41     6826     2581    1 #> pred[CLEAR: ETN, PASI100]     0.11 0.02 0.08 0.10 0.11 0.12  0.15     7281     2823    1 #> pred[CLEAR: IXE_Q2W, PASI75]  0.94 0.01 0.92 0.93 0.94 0.95  0.96     5425     3102    1 #> pred[CLEAR: IXE_Q2W, PASI90]  0.81 0.02 0.76 0.80 0.81 0.83  0.86     5686     3102    1 #> pred[CLEAR: IXE_Q2W, PASI100] 0.52 0.04 0.45 0.50 0.52 0.55  0.60     6050     3334    1 #> pred[CLEAR: IXE_Q4W, PASI75]  0.91 0.02 0.88 0.90 0.91 0.92  0.94     5650     3038    1 #> pred[CLEAR: IXE_Q4W, PASI90]  0.75 0.03 0.69 0.73 0.75 0.77  0.81     5883     2991    1 #> pred[CLEAR: IXE_Q4W, PASI100] 0.44 0.04 0.37 0.41 0.44 0.46  0.51     6236     2898    1 #> pred[CLEAR: SEC_150, PASI75]  0.80 0.02 0.76 0.79 0.80 0.82  0.85     6974     3030    1 #> pred[CLEAR: SEC_150, PASI90]  0.57 0.03 0.51 0.55 0.57 0.59  0.63     7522     2931    1 #> pred[CLEAR: SEC_150, PASI100] 0.26 0.03 0.21 0.24 0.26 0.28  0.31     7795     3102    1 #> pred[CLEAR: SEC_300, PASI75]  0.90 0.01 0.87 0.89 0.90 0.90  0.92     7070     3340    1 #> pred[CLEAR: SEC_300, PASI90]  0.72 0.02 0.68 0.71 0.72 0.73  0.76     8084     3407    1 #> pred[CLEAR: SEC_300, PASI100] 0.40 0.02 0.36 0.39 0.40 0.42  0.45     9002     3557    1 #> pred[CLEAR: UST, PASI75]      0.78 0.02 0.75 0.77 0.78 0.80  0.82     6525     3460    1 #> pred[CLEAR: UST, PASI90]      0.55 0.02 0.51 0.54 0.55 0.57  0.59     7217     2959    1 #> pred[CLEAR: UST, PASI100]     0.25 0.02 0.21 0.23 0.25 0.26  0.28     6991     3323    1 #>  #> ---------------------------------------------------------------- Study: ERASURE ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[ERASURE: PBO, PASI75]      0.05 0.01 0.03 0.04 0.05 0.05  0.06     2649     2638    1 #> pred[ERASURE: PBO, PASI90]      0.01 0.00 0.01 0.01 0.01 0.01  0.01     2816     2731    1 #> pred[ERASURE: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3172     2552    1 #> pred[ERASURE: ETN, PASI75]      0.45 0.03 0.40 0.43 0.45 0.47  0.51     5025     2755    1 #> pred[ERASURE: ETN, PASI90]      0.22 0.02 0.18 0.20 0.22 0.23  0.27     4758     3003    1 #> pred[ERASURE: ETN, PASI100]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     5151     3063    1 #> pred[ERASURE: IXE_Q2W, PASI75]  0.88 0.02 0.85 0.87 0.88 0.89  0.91     4393     3184    1 #> pred[ERASURE: IXE_Q2W, PASI90]  0.70 0.03 0.64 0.68 0.70 0.72  0.75     4403     3212    1 #> pred[ERASURE: IXE_Q2W, PASI100] 0.38 0.03 0.32 0.36 0.38 0.40  0.44     4520     3034    1 #> pred[ERASURE: IXE_Q4W, PASI75]  0.83 0.02 0.79 0.82 0.84 0.85  0.87     4583     3113    1 #> pred[ERASURE: IXE_Q4W, PASI90]  0.62 0.03 0.55 0.60 0.62 0.64  0.68     4622     3175    1 #> pred[ERASURE: IXE_Q4W, PASI100] 0.30 0.03 0.24 0.28 0.30 0.32  0.36     4734     3180    1 #> pred[ERASURE: SEC_150, PASI75]  0.68 0.02 0.65 0.67 0.69 0.70  0.72     6563     2962    1 #> pred[ERASURE: SEC_150, PASI90]  0.42 0.02 0.38 0.41 0.42 0.44  0.47     7123     3203    1 #> pred[ERASURE: SEC_150, PASI100] 0.15 0.01 0.13 0.14 0.15 0.16  0.18     6746     3046    1 #> pred[ERASURE: SEC_300, PASI75]  0.81 0.02 0.78 0.80 0.81 0.82  0.84     5243     2986    1 #> pred[ERASURE: SEC_300, PASI90]  0.58 0.02 0.54 0.57 0.58 0.60  0.62     5377     2999    1 #> pred[ERASURE: SEC_300, PASI100] 0.27 0.02 0.23 0.25 0.27 0.28  0.31     5602     2968    1 #> pred[ERASURE: UST, PASI75]      0.66 0.04 0.58 0.63 0.66 0.68  0.73     7153     2959    1 #> pred[ERASURE: UST, PASI90]      0.40 0.04 0.33 0.38 0.40 0.43  0.48     6931     3035    1 #> pred[ERASURE: UST, PASI100]     0.15 0.02 0.11 0.13 0.15 0.16  0.20     6275     3460    1 #>  #> ---------------------------------------------------------------- Study: FEATURE ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[FEATURE: PBO, PASI75]      0.05 0.01 0.03 0.04 0.05 0.06  0.08     3528     3111    1 #> pred[FEATURE: PBO, PASI90]      0.01 0.00 0.01 0.01 0.01 0.01  0.02     3573     2996    1 #> pred[FEATURE: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3744     3288    1 #> pred[FEATURE: ETN, PASI75]      0.45 0.04 0.37 0.42 0.45 0.48  0.54     4758     2641    1 #> pred[FEATURE: ETN, PASI90]      0.22 0.03 0.16 0.20 0.22 0.24  0.29     4716     2394    1 #> pred[FEATURE: ETN, PASI100]     0.06 0.01 0.04 0.05 0.06 0.06  0.08     4908     2778    1 #> pred[FEATURE: IXE_Q2W, PASI75]  0.88 0.02 0.83 0.86 0.88 0.90  0.92     4349     2947    1 #> pred[FEATURE: IXE_Q2W, PASI90]  0.69 0.04 0.61 0.67 0.69 0.72  0.77     4378     2871    1 #> pred[FEATURE: IXE_Q2W, PASI100] 0.38 0.04 0.29 0.34 0.37 0.41  0.47     4556     2931    1 #> pred[FEATURE: IXE_Q4W, PASI75]  0.83 0.03 0.77 0.81 0.83 0.85  0.89     4688     3086    1 #> pred[FEATURE: IXE_Q4W, PASI90]  0.62 0.05 0.53 0.59 0.62 0.65  0.70     4720     3044    1 #> pred[FEATURE: IXE_Q4W, PASI100] 0.30 0.04 0.22 0.27 0.30 0.33  0.38     4944     3268    1 #> pred[FEATURE: SEC_150, PASI75]  0.68 0.03 0.61 0.66 0.68 0.71  0.75     5407     3219    1 #> pred[FEATURE: SEC_150, PASI90]  0.42 0.04 0.35 0.40 0.42 0.45  0.50     5530     3094    1 #> pred[FEATURE: SEC_150, PASI100] 0.15 0.02 0.11 0.14 0.15 0.17  0.20     5714     3379    1 #> pred[FEATURE: SEC_300, PASI75]  0.81 0.03 0.75 0.79 0.81 0.83  0.86     5144     2976    1 #> pred[FEATURE: SEC_300, PASI90]  0.58 0.04 0.51 0.55 0.58 0.61  0.65     5230     2987    1 #> pred[FEATURE: SEC_300, PASI100] 0.27 0.03 0.21 0.24 0.27 0.29  0.33     5420     3102    1 #> pred[FEATURE: UST, PASI75]      0.66 0.04 0.58 0.63 0.66 0.70  0.75     6147     3316    1 #> pred[FEATURE: UST, PASI90]      0.41 0.05 0.32 0.38 0.41 0.44  0.50     5953     3395    1 #> pred[FEATURE: UST, PASI100]     0.15 0.03 0.10 0.13 0.15 0.17  0.21     5912     3341    1 #>  #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[FIXTURE: PBO, PASI75]      0.04 0.01 0.03 0.03 0.04 0.04  0.05     2405     2526    1 #> pred[FIXTURE: PBO, PASI90]      0.01 0.00 0.00 0.01 0.01 0.01  0.01     2573     2779    1 #> pred[FIXTURE: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     2939     2784    1 #> pred[FIXTURE: ETN, PASI75]      0.44 0.02 0.40 0.43 0.44 0.46  0.49     5779     2950    1 #> pred[FIXTURE: ETN, PASI90]      0.21 0.02 0.18 0.20 0.21 0.22  0.24     5838     3063    1 #> pred[FIXTURE: ETN, PASI100]     0.05 0.01 0.04 0.05 0.05 0.06  0.07     6526     3466    1 #> pred[FIXTURE: IXE_Q2W, PASI75]  0.87 0.02 0.84 0.86 0.87 0.88  0.90     4706     3270    1 #> pred[FIXTURE: IXE_Q2W, PASI90]  0.68 0.03 0.63 0.66 0.68 0.70  0.73     4756     3306    1 #> pred[FIXTURE: IXE_Q2W, PASI100] 0.36 0.03 0.31 0.34 0.36 0.37  0.41     5019     3429    1 #> pred[FIXTURE: IXE_Q4W, PASI75]  0.82 0.02 0.78 0.81 0.82 0.84  0.86     4960     3445    1 #> pred[FIXTURE: IXE_Q4W, PASI90]  0.60 0.03 0.54 0.58 0.60 0.62  0.65     5125     3367    1 #> pred[FIXTURE: IXE_Q4W, PASI100] 0.28 0.03 0.23 0.26 0.28 0.30  0.33     5495     3586    1 #> pred[FIXTURE: SEC_150, PASI75]  0.67 0.02 0.63 0.65 0.67 0.68  0.70     6709     2896    1 #> pred[FIXTURE: SEC_150, PASI90]  0.40 0.02 0.36 0.39 0.40 0.42  0.44     7792     2801    1 #> pred[FIXTURE: SEC_150, PASI100] 0.14 0.01 0.12 0.13 0.14 0.15  0.16     7645     2984    1 #> pred[FIXTURE: SEC_300, PASI75]  0.80 0.01 0.77 0.79 0.80 0.81  0.82     7048     3072    1 #> pred[FIXTURE: SEC_300, PASI90]  0.56 0.02 0.52 0.55 0.56 0.58  0.60     8080     2971    1 #> pred[FIXTURE: SEC_300, PASI100] 0.25 0.02 0.22 0.24 0.25 0.26  0.28     8438     2901    1 #> pred[FIXTURE: UST, PASI75]      0.64 0.03 0.57 0.61 0.64 0.66  0.70     8702     3157    1 #> pred[FIXTURE: UST, PASI90]      0.38 0.03 0.31 0.36 0.38 0.40  0.45     8574     3069    1 #> pred[FIXTURE: UST, PASI100]     0.13 0.02 0.10 0.12 0.13 0.14  0.17     7713     3267    1 #>  #> ---------------------------------------------------------------- Study: IXORA-S ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[IXORA-S: PBO, PASI75]      0.05 0.01 0.03 0.04 0.05 0.05  0.07     3061     3007    1 #> pred[IXORA-S: PBO, PASI90]      0.01 0.00 0.00 0.01 0.01 0.01  0.02     3191     2842    1 #> pred[IXORA-S: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3332     3061    1 #> pred[IXORA-S: ETN, PASI75]      0.48 0.04 0.41 0.46 0.48 0.51  0.56     5617     3325    1 #> pred[IXORA-S: ETN, PASI90]      0.24 0.03 0.19 0.22 0.24 0.26  0.30     5603     3080    1 #> pred[IXORA-S: ETN, PASI100]     0.06 0.01 0.04 0.06 0.06 0.07  0.09     5527     3041    1 #> pred[IXORA-S: IXE_Q2W, PASI75]  0.89 0.02 0.86 0.88 0.89 0.90  0.92     5451     3254    1 #> pred[IXORA-S: IXE_Q2W, PASI90]  0.71 0.03 0.65 0.69 0.71 0.73  0.77     5597     3197    1 #> pred[IXORA-S: IXE_Q2W, PASI100] 0.40 0.03 0.33 0.37 0.40 0.42  0.46     5615     3013    1 #> pred[IXORA-S: IXE_Q4W, PASI75]  0.85 0.02 0.80 0.83 0.85 0.86  0.89     5613     2964    1 #> pred[IXORA-S: IXE_Q4W, PASI90]  0.64 0.04 0.57 0.61 0.64 0.66  0.70     5772     2967    1 #> pred[IXORA-S: IXE_Q4W, PASI100] 0.32 0.03 0.25 0.29 0.32 0.34  0.39     5831     2973    1 #> pred[IXORA-S: SEC_150, PASI75]  0.70 0.04 0.63 0.68 0.70 0.73  0.77     4994     3394    1 #> pred[IXORA-S: SEC_150, PASI90]  0.44 0.04 0.36 0.42 0.44 0.47  0.53     5162     3501    1 #> pred[IXORA-S: SEC_150, PASI100] 0.17 0.03 0.12 0.15 0.16 0.18  0.22     5044     3639    1 #> pred[IXORA-S: SEC_300, PASI75]  0.82 0.03 0.77 0.81 0.82 0.84  0.87     5587     3690    1 #> pred[IXORA-S: SEC_300, PASI90]  0.60 0.04 0.53 0.58 0.60 0.63  0.67     5773     3365    1 #> pred[IXORA-S: SEC_300, PASI100] 0.28 0.03 0.22 0.26 0.28 0.31  0.35     5646     3690    1 #> pred[IXORA-S: UST, PASI75]      0.71 0.03 0.65 0.69 0.71 0.73  0.76     5639     2992    1 #> pred[IXORA-S: UST, PASI90]      0.45 0.03 0.39 0.43 0.45 0.47  0.51     5732     2939    1 #> pred[IXORA-S: UST, PASI100]     0.17 0.02 0.13 0.16 0.17 0.19  0.22     5739     3114    1 #>  #> --------------------------------------------------------------- Study: JUNCTURE ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[JUNCTURE: PBO, PASI75]      0.06 0.01 0.03 0.05 0.05 0.06  0.08     4273     3268    1 #> pred[JUNCTURE: PBO, PASI90]      0.01 0.00 0.01 0.01 0.01 0.01  0.02     4356     3124    1 #> pred[JUNCTURE: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     4530     3119    1 #> pred[JUNCTURE: ETN, PASI75]      0.45 0.04 0.37 0.42 0.45 0.48  0.54     5721     3097    1 #> pred[JUNCTURE: ETN, PASI90]      0.22 0.03 0.16 0.20 0.22 0.24  0.29     5719     3291    1 #> pred[JUNCTURE: ETN, PASI100]     0.06 0.01 0.03 0.05 0.06 0.06  0.09     5795     3200    1 #> pred[JUNCTURE: IXE_Q2W, PASI75]  0.88 0.02 0.83 0.87 0.88 0.90  0.92     5095     3287    1 #> pred[JUNCTURE: IXE_Q2W, PASI90]  0.70 0.04 0.61 0.67 0.70 0.72  0.77     5150     3371    1 #> pred[JUNCTURE: IXE_Q2W, PASI100] 0.38 0.04 0.29 0.35 0.38 0.41  0.47     5350     3448    1 #> pred[JUNCTURE: IXE_Q4W, PASI75]  0.83 0.03 0.77 0.81 0.84 0.85  0.88     5341     3326    1 #> pred[JUNCTURE: IXE_Q4W, PASI90]  0.62 0.04 0.53 0.59 0.62 0.65  0.70     5399     3365    1 #> pred[JUNCTURE: IXE_Q4W, PASI100] 0.30 0.04 0.22 0.27 0.30 0.33  0.39     5618     3134    1 #> pred[JUNCTURE: SEC_150, PASI75]  0.68 0.03 0.61 0.66 0.68 0.71  0.75     5890     3193    1 #> pred[JUNCTURE: SEC_150, PASI90]  0.42 0.04 0.35 0.40 0.42 0.45  0.50     6104     3324    1 #> pred[JUNCTURE: SEC_150, PASI100] 0.16 0.02 0.11 0.14 0.15 0.17  0.20     6257     3386    1 #> pred[JUNCTURE: SEC_300, PASI75]  0.81 0.03 0.75 0.79 0.81 0.83  0.86     6201     3114    1 #> pred[JUNCTURE: SEC_300, PASI90]  0.58 0.04 0.51 0.56 0.58 0.61  0.65     6395     3145    1 #> pred[JUNCTURE: SEC_300, PASI100] 0.27 0.03 0.21 0.25 0.27 0.29  0.33     6578     2844    1 #> pred[JUNCTURE: UST, PASI75]      0.65 0.05 0.54 0.61 0.65 0.68  0.75     6638     3078    1 #> pred[JUNCTURE: UST, PASI90]      0.39 0.05 0.29 0.36 0.39 0.43  0.50     6572     3031    1 #> pred[JUNCTURE: UST, PASI100]     0.14 0.03 0.09 0.12 0.14 0.16  0.21     6285     3384    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #>                                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-1: PBO, PASI75]      0.06 0.01 0.04 0.05 0.06 0.06  0.07     2932     2882    1 #> pred[UNCOVER-1: PBO, PASI90]      0.01 0.00 0.01 0.01 0.01 0.01  0.02     3181     2654    1 #> pred[UNCOVER-1: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3470     2886    1 #> pred[UNCOVER-1: ETN, PASI75]      0.47 0.02 0.42 0.45 0.47 0.48  0.51     4589     2900    1 #> pred[UNCOVER-1: ETN, PASI90]      0.23 0.02 0.20 0.22 0.23 0.24  0.26     4645     3166    1 #> pred[UNCOVER-1: ETN, PASI100]     0.06 0.01 0.05 0.06 0.06 0.06  0.08     4571     2859    1 #> pred[UNCOVER-1: IXE_Q2W, PASI75]  0.89 0.01 0.87 0.88 0.89 0.90  0.91     6322     3068    1 #> pred[UNCOVER-1: IXE_Q2W, PASI90]  0.71 0.01 0.68 0.70 0.71 0.72  0.74     7204     3180    1 #> pred[UNCOVER-1: IXE_Q2W, PASI100] 0.39 0.02 0.36 0.38 0.39 0.40  0.43     7586     3358    1 #> pred[UNCOVER-1: IXE_Q4W, PASI75]  0.84 0.01 0.82 0.84 0.84 0.85  0.86     6326     3169    1 #> pred[UNCOVER-1: IXE_Q4W, PASI90]  0.63 0.02 0.60 0.62 0.63 0.65  0.66     7231     3067    1 #> pred[UNCOVER-1: IXE_Q4W, PASI100] 0.31 0.02 0.28 0.30 0.31 0.33  0.35     7674     3322    1 #> pred[UNCOVER-1: SEC_150, PASI75]  0.70 0.03 0.64 0.68 0.70 0.72  0.75     4573     2962    1 #> pred[UNCOVER-1: SEC_150, PASI90]  0.44 0.03 0.37 0.42 0.44 0.46  0.51     4631     3137    1 #> pred[UNCOVER-1: SEC_150, PASI100] 0.17 0.02 0.13 0.15 0.16 0.18  0.21     4574     2811    1 #> pred[UNCOVER-1: SEC_300, PASI75]  0.82 0.02 0.78 0.81 0.82 0.84  0.86     4833     3200    1 #> pred[UNCOVER-1: SEC_300, PASI90]  0.60 0.03 0.54 0.58 0.60 0.62  0.66     4991     3389    1 #> pred[UNCOVER-1: SEC_300, PASI100] 0.28 0.03 0.23 0.26 0.28 0.30  0.34     4873     3424    1 #> pred[UNCOVER-1: UST, PASI75]      0.68 0.04 0.60 0.66 0.68 0.71  0.76     5260     3088    1 #> pred[UNCOVER-1: UST, PASI90]      0.43 0.04 0.35 0.40 0.43 0.46  0.51     5378     3504    1 #> pred[UNCOVER-1: UST, PASI100]     0.16 0.03 0.12 0.14 0.16 0.18  0.22     5219     3385    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #>                                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-2: PBO, PASI75]      0.05 0.01 0.04 0.05 0.05 0.06  0.06     3122     2522    1 #> pred[UNCOVER-2: PBO, PASI90]      0.01 0.00 0.01 0.01 0.01 0.01  0.01     3356     2912    1 #> pred[UNCOVER-2: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3626     3266    1 #> pred[UNCOVER-2: ETN, PASI75]      0.44 0.02 0.40 0.43 0.44 0.45  0.48     4685     3191    1 #> pred[UNCOVER-2: ETN, PASI90]      0.21 0.01 0.18 0.20 0.21 0.22  0.24     5049     3053    1 #> pred[UNCOVER-2: ETN, PASI100]     0.05 0.01 0.04 0.05 0.05 0.06  0.06     5048     3316    1 #> pred[UNCOVER-2: IXE_Q2W, PASI75]  0.88 0.01 0.86 0.87 0.88 0.88  0.90     5035     2716    1 #> pred[UNCOVER-2: IXE_Q2W, PASI90]  0.69 0.02 0.66 0.68 0.69 0.70  0.72     5739     2934    1 #> pred[UNCOVER-2: IXE_Q2W, PASI100] 0.37 0.02 0.34 0.36 0.37 0.38  0.40     6147     3060    1 #> pred[UNCOVER-2: IXE_Q4W, PASI75]  0.83 0.01 0.81 0.82 0.83 0.84  0.85     5474     2962    1 #> pred[UNCOVER-2: IXE_Q4W, PASI90]  0.61 0.02 0.58 0.60 0.61 0.62  0.64     6371     3437    1 #> pred[UNCOVER-2: IXE_Q4W, PASI100] 0.29 0.02 0.26 0.28 0.29 0.30  0.32     6973     3554    1 #> pred[UNCOVER-2: SEC_150, PASI75]  0.68 0.03 0.61 0.66 0.68 0.70  0.73     5016     3385    1 #> pred[UNCOVER-2: SEC_150, PASI90]  0.41 0.03 0.35 0.39 0.41 0.44  0.48     5125     3421    1 #> pred[UNCOVER-2: SEC_150, PASI100] 0.15 0.02 0.11 0.13 0.15 0.16  0.19     5019     3539    1 #> pred[UNCOVER-2: SEC_300, PASI75]  0.80 0.02 0.76 0.79 0.81 0.82  0.84     5077     3048    1 #> pred[UNCOVER-2: SEC_300, PASI90]  0.57 0.03 0.51 0.55 0.57 0.60  0.63     5322     2906    1 #> pred[UNCOVER-2: SEC_300, PASI100] 0.26 0.03 0.21 0.24 0.26 0.28  0.31     5359     3285    1 #> pred[UNCOVER-2: UST, PASI75]      0.65 0.04 0.56 0.62 0.65 0.68  0.73     5584     3209    1 #> pred[UNCOVER-2: UST, PASI90]      0.39 0.04 0.31 0.36 0.39 0.42  0.48     5564     3136    1 #> pred[UNCOVER-2: UST, PASI100]     0.14 0.02 0.10 0.12 0.14 0.16  0.19     5238     3227    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #>                                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[UNCOVER-3: PBO, PASI75]      0.07 0.01 0.05 0.06 0.07 0.07  0.09     3408     2896    1 #> pred[UNCOVER-3: PBO, PASI90]      0.02 0.00 0.01 0.01 0.01 0.02  0.02     3699     2795    1 #> pred[UNCOVER-3: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     4199     3282    1 #> pred[UNCOVER-3: ETN, PASI75]      0.51 0.02 0.47 0.49 0.51 0.52  0.54     5141     3015    1 #> pred[UNCOVER-3: ETN, PASI90]      0.26 0.01 0.23 0.25 0.26 0.27  0.29     5478     3035    1 #> pred[UNCOVER-3: ETN, PASI100]     0.07 0.01 0.06 0.07 0.07 0.08  0.09     5733     3307    1 #> pred[UNCOVER-3: IXE_Q2W, PASI75]  0.91 0.01 0.89 0.90 0.91 0.91  0.92     4495     3217    1 #> pred[UNCOVER-3: IXE_Q2W, PASI90]  0.74 0.01 0.71 0.73 0.74 0.75  0.77     5272     2943    1 #> pred[UNCOVER-3: IXE_Q2W, PASI100] 0.43 0.02 0.40 0.42 0.43 0.44  0.46     5853     2938    1 #> pred[UNCOVER-3: IXE_Q4W, PASI75]  0.87 0.01 0.85 0.86 0.87 0.87  0.88     5666     3558    1 #> pred[UNCOVER-3: IXE_Q4W, PASI90]  0.67 0.02 0.64 0.66 0.67 0.68  0.70     6671     3608    1 #> pred[UNCOVER-3: IXE_Q4W, PASI100] 0.35 0.02 0.32 0.34 0.35 0.36  0.38     8120     3670    1 #> pred[UNCOVER-3: SEC_150, PASI75]  0.73 0.03 0.67 0.71 0.73 0.75  0.78     5136     3029    1 #> pred[UNCOVER-3: SEC_150, PASI90]  0.48 0.03 0.41 0.46 0.48 0.50  0.54     5367     2968    1 #> pred[UNCOVER-3: SEC_150, PASI100] 0.19 0.02 0.15 0.17 0.19 0.20  0.23     5276     2947    1 #> pred[UNCOVER-3: SEC_300, PASI75]  0.84 0.02 0.80 0.83 0.84 0.86  0.88     5481     3182    1 #> pred[UNCOVER-3: SEC_300, PASI90]  0.63 0.03 0.57 0.61 0.63 0.65  0.69     5782     2938    1 #> pred[UNCOVER-3: SEC_300, PASI100] 0.31 0.03 0.26 0.29 0.31 0.33  0.37     5694     3154    1 #> pred[UNCOVER-3: UST, PASI75]      0.70 0.04 0.62 0.67 0.70 0.73  0.77     5694     3534    1 #> pred[UNCOVER-3: UST, PASI90]      0.45 0.04 0.37 0.42 0.45 0.48  0.53     5692     3345    1 #> pred[UNCOVER-3: UST, PASI100]     0.17 0.03 0.13 0.16 0.17 0.19  0.23     5399     3632    1 plot(pso_pred_FE, ref_line = c(0, 1))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_plaque_psoriasis.html","id":"external-target-populations","dir":"Articles","previous_headings":"Extended analysis > Producing relative effects and event probabilities","what":"External target populations","title":"Example: Plaque psoriasis ML-NMR","text":"purposes decision-making crucial population-average estimates produced decision target population interest. decision target population may represented study populations network, indeed likely best represented external registry cohort study, perhaps expert knowledge (Phillippo et al. 2016). example, Phillippo et al. (2022) produce estimates three external target populations represented PsoBest registry (Reich et al. 2015; Augustin et al. 2014), PROSPECT (Thaçi et al. 2019) Chiricozzi 2019 (Chiricozzi et al. 2019) cohort studies. First , need covariate means standard deviations populations: produce estimates population-average treatment effects, use relative_effects() function data frame covariate means target populations newdata argument. need covariate means, variable names matching regression. estimates plotted using plot() function.  Estimates average event probabilities produced integrating predictions joint covariate distribution population. Since marginal summary statistics available, rather full IPD, create integration points using add_integration() function specifying forms marginal distributions correlation matrix. choose use forms marginal distributions used specifying integration points AgD studies network, weighted correlation matrix IPD studies. use predict() function produce average event probabilities (type = \"response\", level = \"aggregate\" default) target populations. , also need specify distribution baseline event probabilities (.e. probability achieving PASI 75 response) target populations. PASI 75 event counts individuals receiving secukinumab 300 mg treatment available PROSPECT (1156 achieved PASI 75 1509) Chiricozzi 2019 (243 330), use construct beta distributions baseline average response probabilities (specify baseline_level = \"aggregate\" population averages, rather specific reference individual, baseline_type = \"response\" probabilities rather transformed probit probabilities). information baseline response available PsoBest, predictions absolute response rates made. , plot estimates using plot() function, customisation using ggplot syntax.","code":"new_agd_means <- tibble::tribble(              ~study, ~covariate,  ~mean,   ~sd,           \"PsoBest\",      \"bsa\",     24,  20.5,           \"PsoBest\",  \"durnpso\",   18.2,  14.1,           \"PsoBest\",  \"prevsys\",   0.54,    NA,           \"PsoBest\",      \"psa\",  0.207,    NA,           \"PsoBest\",   \"weight\",     85,  19.1,          \"PROSPECT\",      \"bsa\",   18.7,  18.4,          \"PROSPECT\",  \"durnpso\",   19.6,  13.5,          \"PROSPECT\",  \"prevsys\", 0.9095,    NA,          \"PROSPECT\",      \"psa\",  0.202,    NA,          \"PROSPECT\",   \"weight\",   87.5,  20.3,   \"Chiricozzi 2019\",      \"bsa\",     23, 16.79,   \"Chiricozzi 2019\",  \"durnpso\",  16.93, 10.82,   \"Chiricozzi 2019\",  \"prevsys\", 0.9061,    NA,   \"Chiricozzi 2019\",      \"psa\", 0.2152,    NA,   \"Chiricozzi 2019\",   \"weight\",   78.3, 15.87   ) %>%   # Tidy up   pivot_wider(id_cols = study,                names_from = covariate,                values_from = c(mean, sd),               names_glue = \"{covariate}_{.value}\") %>%    # Rescale as per analysis   transmute(study,             bsa_mean = bsa_mean / 100,              bsa_sd = bsa_sd / 100,             weight_mean = weight_mean / 10,             weight_sd = weight_sd / 10,             durnpso_mean = durnpso_mean / 10,             durnpso_sd = durnpso_sd / 10,             prevsys = prevsys_mean,             psa = psa_mean) (pso_releff_FE_new <- relative_effects(pso_fit_FE,                                         newdata = transmute(new_agd_means,                                                            study,                                                            bsa = bsa_mean,                                                            weight = weight_mean,                                                            durnpso = durnpso_mean,                                                            prevsys,                                                            psa),                                        study = study)) #> -------------------------------------------------------- Study: Chiricozzi 2019 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.69    0.91 0.23   7.83 0.22 #>  #>                             mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Chiricozzi 2019: ETN]     1.79 0.11 1.59 1.72 1.79 1.86  2.01     2269     2766    1 #> d[Chiricozzi 2019: IXE_Q2W] 3.08 0.10 2.88 3.01 3.08 3.15  3.28     2520     2614    1 #> d[Chiricozzi 2019: IXE_Q4W] 2.86 0.10 2.65 2.79 2.86 2.93  3.07     2693     2604    1 #> d[Chiricozzi 2019: SEC_150] 2.36 0.11 2.14 2.28 2.36 2.43  2.58     2435     2679    1 #> d[Chiricozzi 2019: SEC_300] 2.77 0.11 2.55 2.69 2.77 2.84  2.99     2479     2858    1 #> d[Chiricozzi 2019: UST]     2.31 0.15 2.02 2.21 2.31 2.41  2.60     3003     2920    1 #>  #> --------------------------------------------------------------- Study: PROSPECT ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.96    0.91 0.19   8.75 0.2 #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[PROSPECT: ETN]     1.63 0.11 1.42 1.56 1.63 1.70  1.84     2256     2690    1 #> d[PROSPECT: IXE_Q2W] 2.94 0.10 2.74 2.87 2.94 3.01  3.14     2650     2950    1 #> d[PROSPECT: IXE_Q4W] 2.72 0.10 2.53 2.66 2.72 2.79  2.92     2829     2750    1 #> d[PROSPECT: SEC_150] 2.22 0.11 2.00 2.14 2.22 2.29  2.44     2590     3014    1 #> d[PROSPECT: SEC_300] 2.63 0.11 2.41 2.55 2.63 2.70  2.85     2679     2654    1 #> d[PROSPECT: UST]     2.18 0.15 1.90 2.08 2.18 2.29  2.48     3181     3182    1 #>  #> ---------------------------------------------------------------- Study: PsoBest ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.82    0.54 0.24    8.5 0.21 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[PsoBest: ETN]     1.61 0.08 1.46 1.56 1.61 1.66  1.77     2455     2879    1 #> d[PsoBest: IXE_Q2W] 2.93 0.08 2.78 2.88 2.93 2.98  3.09     2824     2943    1 #> d[PsoBest: IXE_Q4W] 2.71 0.08 2.56 2.66 2.71 2.77  2.87     3100     2982    1 #> d[PsoBest: SEC_150] 2.21 0.09 2.04 2.15 2.21 2.27  2.38     2533     2357    1 #> d[PsoBest: SEC_300] 2.62 0.09 2.45 2.56 2.62 2.67  2.79     2647     2672    1 #> d[PsoBest: UST]     2.08 0.14 1.82 1.99 2.08 2.17  2.35     3616     3150    1 plot(pso_releff_FE_new, ref_line = 0) + facet_wrap(\"Study\") new_agd_int <- add_integration(filter(new_agd_means, study != \"PsoBest\"),                                durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),                                prevsys = distr(qbern, prob = prevsys),                                bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),                                weight = distr(qgamma, mean = weight_mean, sd = weight_sd),                                psa = distr(qbern, prob = psa),                                n_int = 64,                                cor = pso_net$int_cor) (pso_pred_FE_new <- predict(pso_fit_FE,          type = \"response\",          newdata = new_agd_int,         study = study,         baseline = list(PROSPECT = distr(qbeta, 1156, 1509-1156),                         \"Chiricozzi 2019\" = distr(qbeta, 243, 330-243)),         baseline_type = \"response\",         baseline_level = \"aggregate\",         baseline_trt = \"SEC_300\")) #> -------------------------------------------------------- Study: Chiricozzi 2019 ----  #>  #>                                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[Chiricozzi 2019: PBO, PASI75]      0.02 0.01 0.01 0.01 0.02 0.02  0.03     2774     2898    1 #> pred[Chiricozzi 2019: PBO, PASI90]      0.00 0.00 0.00 0.00 0.00 0.00  0.01     2838     3324    1 #> pred[Chiricozzi 2019: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     2893     3086    1 #> pred[Chiricozzi 2019: ETN, PASI75]      0.37 0.04 0.29 0.35 0.37 0.40  0.46     4735     3515    1 #> pred[Chiricozzi 2019: ETN, PASI90]      0.16 0.03 0.11 0.14 0.16 0.18  0.22     4671     3820    1 #> pred[Chiricozzi 2019: ETN, PASI100]     0.03 0.01 0.02 0.03 0.03 0.04  0.05     4874     3910    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI75]  0.83 0.03 0.77 0.81 0.83 0.85  0.88     3937     4088    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI90]  0.60 0.04 0.52 0.57 0.60 0.63  0.69     3975     3974    1 #> pred[Chiricozzi 2019: IXE_Q2W, PASI100] 0.28 0.04 0.21 0.26 0.28 0.31  0.36     4029     3977    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI75]  0.77 0.03 0.69 0.74 0.77 0.79  0.83     4139     3729    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI90]  0.52 0.05 0.43 0.49 0.52 0.55  0.61     4171     4113    1 #> pred[Chiricozzi 2019: IXE_Q4W, PASI100] 0.22 0.03 0.16 0.19 0.22 0.24  0.29     4273     4046    1 #> pred[Chiricozzi 2019: SEC_150, PASI75]  0.59 0.04 0.51 0.57 0.59 0.62  0.66     4475     4038    1 #> pred[Chiricozzi 2019: SEC_150, PASI90]  0.33 0.04 0.26 0.30 0.33 0.35  0.40     4604     4025    1 #> pred[Chiricozzi 2019: SEC_150, PASI100] 0.10 0.02 0.07 0.09 0.10 0.11  0.14     4509     3701    1 #> pred[Chiricozzi 2019: SEC_300, PASI75]  0.74 0.02 0.68 0.72 0.74 0.75  0.78     3565     3798    1 #> pred[Chiricozzi 2019: SEC_300, PASI90]  0.48 0.03 0.42 0.46 0.48 0.50  0.54     3838     3636    1 #> pred[Chiricozzi 2019: SEC_300, PASI100] 0.19 0.02 0.15 0.17 0.19 0.20  0.23     3745     3395    1 #> pred[Chiricozzi 2019: UST, PASI75]      0.57 0.05 0.47 0.54 0.57 0.61  0.68     4619     3313    1 #> pred[Chiricozzi 2019: UST, PASI90]      0.32 0.05 0.23 0.28 0.32 0.35  0.42     4616     3415    1 #> pred[Chiricozzi 2019: UST, PASI100]     0.10 0.02 0.06 0.08 0.10 0.11  0.15     4635     3362    1 #>  #> --------------------------------------------------------------- Study: PROSPECT ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[PROSPECT: PBO, PASI75]      0.03 0.01 0.02 0.03 0.03 0.04  0.05     2934     2914    1 #> pred[PROSPECT: PBO, PASI90]      0.01 0.00 0.00 0.00 0.01 0.01  0.01     2952     2943    1 #> pred[PROSPECT: PBO, PASI100]     0.00 0.00 0.00 0.00 0.00 0.00  0.00     3041     3053    1 #> pred[PROSPECT: ETN, PASI75]      0.40 0.04 0.33 0.38 0.40 0.43  0.47     5801     3330    1 #> pred[PROSPECT: ETN, PASI90]      0.18 0.02 0.14 0.16 0.18 0.20  0.23     5572     3383    1 #> pred[PROSPECT: ETN, PASI100]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     5504     3323    1 #> pred[PROSPECT: IXE_Q2W, PASI75]  0.85 0.02 0.81 0.84 0.85 0.86  0.89     5040     3313    1 #> pred[PROSPECT: IXE_Q2W, PASI90]  0.64 0.03 0.57 0.62 0.64 0.66  0.70     5008     3529    1 #> pred[PROSPECT: IXE_Q2W, PASI100] 0.32 0.03 0.26 0.30 0.32 0.34  0.38     5095     3461    1 #> pred[PROSPECT: IXE_Q4W, PASI75]  0.79 0.03 0.74 0.78 0.79 0.81  0.84     5273     3203    1 #> pred[PROSPECT: IXE_Q4W, PASI90]  0.56 0.04 0.49 0.53 0.56 0.58  0.63     5255     3293    1 #> pred[PROSPECT: IXE_Q4W, PASI100] 0.25 0.03 0.19 0.23 0.24 0.27  0.31     5121     3195    1 #> pred[PROSPECT: SEC_150, PASI75]  0.63 0.03 0.57 0.61 0.63 0.64  0.68     6002     3692    1 #> pred[PROSPECT: SEC_150, PASI90]  0.36 0.03 0.31 0.34 0.36 0.38  0.42     5902     3841    1 #> pred[PROSPECT: SEC_150, PASI100] 0.12 0.01 0.09 0.11 0.12 0.13  0.15     5461     3642    1 #> pred[PROSPECT: SEC_300, PASI75]  0.77 0.01 0.74 0.76 0.77 0.77  0.79     3985     3918    1 #> pred[PROSPECT: SEC_300, PASI90]  0.52 0.02 0.49 0.51 0.52 0.53  0.55     4033     3889    1 #> pred[PROSPECT: SEC_300, PASI100] 0.22 0.01 0.19 0.21 0.22 0.22  0.24     3920     3878    1 #> pred[PROSPECT: UST, PASI75]      0.61 0.05 0.52 0.58 0.62 0.65  0.70     5757     3516    1 #> pred[PROSPECT: UST, PASI90]      0.36 0.05 0.27 0.32 0.35 0.39  0.45     5644     3496    1 #> pred[PROSPECT: UST, PASI100]     0.12 0.02 0.07 0.10 0.12 0.13  0.17     5586     3549    1 plot(pso_pred_FE_new, ref_line = c(0, 1)) +    facet_grid(rows = \"Study\") +    aes(colour = Category) +   scale_colour_brewer(palette = \"Blues\")"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Smoking cessation","text":"begin setting network. arm-level count data giving number quitting smoking (r) total (n) arm, use function set_agd_arm(). Treatment “intervention” set network reference treatment. Plot network structure.","code":"smknet <- set_agd_arm(smoking,                        study = studyn,                       trt = trtc,                       r = r,                        n = n,                       trt_ref = \"No intervention\") smknet #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected plot(smknet, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"random-effects-nma","dir":"Articles","previous_headings":"","what":"Random effects NMA","title":"Example: Smoking cessation","text":"Following TSD 4, fit random effects NMA model, using nma() function trt_effects = \"random\". use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k study-specific intercepts μj\\mu_j, half-N(52)\\textrm{half-N}(5^2) prior distribution -study heterogeneity standard deviation τ\\tau. can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  default, displays model parameters given prior distributions (case dkd_k, μj\\mu_j, τ\\tau), may changed using prior argument:  Model fit can checked using dic() function residual deviance contributions examined corresponding plot() method  Overall model fit seems adequate, almost points showing good fit (mean residual deviance contribution 1). two points higher residual deviance (.e. worse fit) correspond two zero counts data:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. smkfit <- nma(smknet,                trt_effects = \"random\",               prior_intercept = normal(scale = 100),               prior_trt = normal(scale = 100),               prior_het = normal(scale = 5)) #>  2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.605 seconds (Warm-up) #> Chain 1:                0.489 seconds (Sampling) #> Chain 1:                1.094 seconds (Total) #> Chain 1:  #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.631 seconds (Warm-up) #> Chain 2:                0.472 seconds (Sampling) #> Chain 2:                1.103 seconds (Total) #> Chain 2:  #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.604 seconds (Warm-up) #> Chain 3:                0.527 seconds (Sampling) #> Chain 3:                1.131 seconds (Total) #> Chain 3: smkfit #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50%      75%    97.5% #> d[Group counselling]          1.11    0.01 0.45     0.22     0.82     1.10     1.40     2.05 #> d[Individual counselling]     0.85    0.01 0.25     0.39     0.68     0.83     1.00     1.36 #> d[Self-help]                  0.49    0.01 0.42    -0.32     0.23     0.48     0.75     1.34 #> lp__                      -5767.58    0.19 6.30 -5781.19 -5771.58 -5767.27 -5763.13 -5756.26 #> tau                           0.85    0.01 0.18     0.56     0.72     0.82     0.96     1.26 #>                           n_eff Rhat #> d[Group counselling]       1582 1.00 #> d[Individual counselling]   889 1.01 #> d[Self-help]               1751 1.00 #> lp__                       1137 1.01 #> tau                        1067 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:43:41 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(smkfit, pars = c(\"d\", \"tau\", \"mu\", \"delta\")) plot_prior_posterior(smkfit) plot_prior_posterior(smkfit, prior = \"het\") (dic_consistency <- dic(smkfit)) #> Residual deviance: 53.5 (on 50 data points) #>                pD: 43.5 #>               DIC: 97 plot(dic_consistency) smoking[smoking$r == 0, ] #>    studyn trtn            trtc r  n #> 13      6    1 No intervention 0 33 #> 31     15    1 No intervention 0 20"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"checking-for-inconsistency","dir":"Articles","previous_headings":"","what":"Checking for inconsistency","title":"Example: Smoking cessation","text":"Note: results inconsistency models slightly different Dias et al. (2010, 2011), although overall conclusions . due presence multi-arm trials different ordering treatments, meaning inconsistency parameterised differently within multi-arm trials. results Dias et al. obtained network instead set trtn treatment variable.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"unrelated-mean-effects","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Unrelated mean effects","title":"Example: Smoking cessation","text":"first fit unrelated mean effects (UME) model (Dias et al. 2011) assess consistency assumption. , use function nma(), now argument consistency = \"ume\". Comparing model fit statistics see little choose two models. However, also important examine individual contributions model fit data point two models (-called “dev-dev” plot). Passing two nma_dic objects produced dic() function plot() method produces dev-dev plot:  points lie roughly line equality, evidence inconsistency .","code":"smkfit_ume <- nma(smknet,                    consistency = \"ume\",                   trt_effects = \"random\",                   prior_intercept = normal(scale = 100),                   prior_trt = normal(scale = 100),                   prior_het = normal(scale = 5)) #>  2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.755 seconds (Warm-up) #> Chain 3:                0.598 seconds (Sampling) #> Chain 3:                1.353 seconds (Total) #> Chain 3:  #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.91 seconds (Warm-up) #> Chain 2:                0.631 seconds (Sampling) #> Chain 2:                1.541 seconds (Total) #> Chain 2:  #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.881 seconds (Warm-up) #> Chain 1:                0.832 seconds (Sampling) #> Chain 1:                1.713 seconds (Total) #> Chain 1: smkfit_ume dic_consistency #> Residual deviance: 53.5 (on 50 data points) #>                pD: 43.5 #>               DIC: 97 (dic_ume <- dic(smkfit_ume)) #> Residual deviance: 53.9 (on 50 data points) #>                pD: 45.1 #>               DIC: 99 plot(dic_consistency, dic_ume, point_alpha = 0.5, interval_alpha = 0.2)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"node-splitting","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Node-splitting","title":"Example: Smoking cessation","text":"Another method assessing inconsistency node-splitting (Dias et al. 2011, 2010). Whereas UME model assesses inconsistency globally, node-splitting assesses inconsistency locally potentially inconsistent comparison (direct indirect evidence) turn. Node-splitting can performed using nma() function argument consistency = \"nodesplit\". default, possible comparisons split (determined get_nodesplits() function). Alternatively, specific comparison comparisons split can provided nodesplit argument. summary() method summarises node-splitting results, displaying direct indirect estimates ddird_\\mathrm{dir} dindd_\\mathrm{ind} node-split model, network estimate dnetd_\\mathrm{net} consistency model, inconsistency factor ω=ddir−dind\\omega = d_\\mathrm{dir} - d_\\mathrm{ind}, Bayesian pp-value inconsistency comparison. Since random effects models fitted, heterogeneity standard deviation τ\\tau node-split model consistency model also displayed. DIC model fit statistics also provided. DIC inconsistency model unchanged consistency model, node-splits result reduced heterogeneity standard deviation τ\\tau compared consistency model, Bayesian pp-values large. evidence inconsistency. can visually compare posterior distributions direct, indirect, network estimates using plot() method. agreement; posterior densities direct indirect estimates overlap. Notice much indirect information Individual counselling vs. intervention comparison, network (consistency) estimate similar direct estimate comparison.","code":"smk_nodesplit <- nma(smknet,                       consistency = \"nodesplit\",                      trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = normal(scale = 5)) #> Fitting model 1 of 7, node-split: Group counselling vs. No intervention #> Fitting model 2 of 7, node-split: Individual counselling vs. No intervention #> Fitting model 3 of 7, node-split: Self-help vs. No intervention #> Fitting model 4 of 7, node-split: Individual counselling vs. Group counselling #> Fitting model 5 of 7, node-split: Self-help vs. Group counselling #> Fitting model 6 of 7, node-split: Self-help vs. Individual counselling #> Fitting model 7 of 7, consistency model summary(smk_nodesplit) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.08 0.43  0.25  0.80  1.07 1.35  1.98     2179     2443    1 #> d_dir            1.07 0.75 -0.40  0.58  1.04 1.54  2.62     3496     2691    1 #> d_ind            1.17 0.56  0.08  0.79  1.15 1.53  2.28     1500     1802    1 #> omega           -0.09 0.91 -1.81 -0.70 -0.11 0.50  1.77     2383     2719    1 #> tau              0.88 0.20  0.55  0.73  0.85 0.99  1.35      997     1524    1 #> tau_consistency  0.83 0.18  0.54  0.70  0.81 0.94  1.25     1430     2327    1 #>  #> Residual deviance: 53.8 (on 50 data points) #>                pD: 44.1 #>               DIC: 97.9 #>  #> Bayesian p-value: 0.89 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.84 0.24  0.40  0.68 0.83 0.98  1.33     1247     2061    1 #> d_dir           0.87 0.24  0.43  0.71 0.87 1.02  1.37     1917     2370    1 #> d_ind           0.55 0.63 -0.65  0.13 0.54 0.96  1.80     1385     2313    1 #> omega           0.32 0.65 -0.95 -0.10 0.33 0.76  1.55     1541     2365    1 #> tau             0.85 0.19  0.55  0.71 0.82 0.95  1.29     1090     1658    1 #> tau_consistency 0.83 0.18  0.54  0.70 0.81 0.94  1.25     1430     2327    1 #>  #> Residual deviance: 54.7 (on 50 data points) #>                pD: 44.5 #>               DIC: 99.1 #>  #> Bayesian p-value: 0.59 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.49 0.40 -0.29  0.23  0.48 0.75  1.30     1895     2212    1 #> d_dir            0.34 0.55 -0.75 -0.01  0.33 0.68  1.42     3074     2991    1 #> d_ind            0.70 0.61 -0.47  0.30  0.70 1.09  1.90     2235     2495    1 #> omega           -0.36 0.83 -2.04 -0.90 -0.36 0.18  1.28     2294     2366    1 #> tau              0.88 0.20  0.57  0.74  0.85 0.99  1.32     1098     2054    1 #> tau_consistency  0.83 0.18  0.54  0.70  0.81 0.94  1.25     1430     2327    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44.2 #>               DIC: 97.8 #>  #> Bayesian p-value: 0.66 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.24 0.40 -1.05 -0.51 -0.24  0.02  0.53     3229     2694    1 #> d_dir           -0.10 0.48 -1.05 -0.42 -0.10  0.20  0.84     3440     3085    1 #> d_ind           -0.54 0.61 -1.74 -0.94 -0.53 -0.13  0.68     1684     2247    1 #> omega            0.43 0.68 -0.87 -0.02  0.43  0.87  1.78     1826     2417    1 #> tau              0.87 0.19  0.55  0.73  0.84  0.98  1.31      981     1828    1 #> tau_consistency  0.83 0.18  0.54  0.70  0.81  0.94  1.25     1430     2327    1 #>  #> Residual deviance: 53.9 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.2 #>  #> Bayesian p-value: 0.52 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.59 0.47 -1.53 -0.90 -0.59 -0.28  0.31     2833     2619    1 #> d_dir           -0.62 0.64 -1.91 -1.05 -0.61 -0.19  0.62     3445     2767    1 #> d_ind           -0.61 0.67 -1.96 -1.04 -0.60 -0.16  0.65     1852     2014    1 #> omega           -0.01 0.86 -1.70 -0.58 -0.01  0.55  1.74     1873     2755    1 #> tau              0.87 0.19  0.57  0.74  0.85  0.98  1.30     1043     1830    1 #> tau_consistency  0.83 0.18  0.54  0.70  0.81  0.94  1.25     1430     2327    1 #>  #> Residual deviance: 53.7 (on 50 data points) #>                pD: 44 #>               DIC: 97.6 #>  #> Bayesian p-value: 0.99 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.35 0.41 -1.17 -0.61 -0.35 -0.09  0.46     2293     2588    1 #> d_dir            0.07 0.66 -1.19 -0.35  0.07  0.49  1.39     3070     2653    1 #> d_ind           -0.63 0.52 -1.72 -0.96 -0.62 -0.28  0.37     1740     2022    1 #> omega            0.70 0.82 -0.85  0.16  0.69  1.21  2.34     2261     2662    1 #> tau              0.86 0.20  0.54  0.72  0.83  0.97  1.30     1122     1750    1 #> tau_consistency  0.83 0.18  0.54  0.70  0.81  0.94  1.25     1430     2327    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 43.9 #>               DIC: 97.5 #>  #> Bayesian p-value: 0.39 plot(smk_nodesplit) +   ggplot2::theme(legend.position = \"bottom\", legend.direction = \"horizontal\")"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_smoking.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Smoking cessation","text":"Pairwise relative effects, pairwise contrasts all_contrasts = TRUE.  Treatment rankings, rank probabilities, cumulative rank probabilities. set lower_better = FALSE since higher log odds cessation better (outcome positive).","code":"(smk_releff <- relative_effects(smkfit, all_contrasts = TRUE)) #>                                                  mean   sd  2.5%   25%   50%   75% 97.5% #> d[Group counselling vs. No intervention]         1.11 0.45  0.22  0.82  1.10  1.40  2.05 #> d[Individual counselling vs. No intervention]    0.85 0.25  0.39  0.68  0.83  1.00  1.36 #> d[Self-help vs. No intervention]                 0.49 0.42 -0.32  0.23  0.48  0.75  1.34 #> d[Individual counselling vs. Group counselling] -0.26 0.43 -1.10 -0.55 -0.26  0.02  0.56 #> d[Self-help vs. Group counselling]              -0.62 0.49 -1.60 -0.93 -0.61 -0.30  0.35 #> d[Self-help vs. Individual counselling]         -0.36 0.42 -1.21 -0.62 -0.35 -0.09  0.47 #>                                                 Bulk_ESS Tail_ESS Rhat #> d[Group counselling vs. No intervention]            1736     1873 1.00 #> d[Individual counselling vs. No intervention]        901     1593 1.01 #> d[Self-help vs. No intervention]                    1822     2102 1.00 #> d[Individual counselling vs. Group counselling]     2768     2704 1.00 #> d[Self-help vs. Group counselling]                  3048     3098 1.00 #> d[Self-help vs. Individual counselling]             2360     2533 1.00 plot(smk_releff, ref_line = 0) (smk_ranks <- posterior_ranks(smkfit, lower_better = FALSE)) #>                              mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[No intervention]        3.88 0.33    3   4   4   4     4     2240       NA    1 #> rank[Group counselling]      1.37 0.62    1   1   1   2     3     3157     2727    1 #> rank[Individual counselling] 1.92 0.63    1   2   2   2     3     2937     3132    1 #> rank[Self-help]              2.82 0.70    1   3   3   3     4     2612       NA    1 plot(smk_ranks) (smk_rankprobs <- posterior_rank_probs(smkfit, lower_better = FALSE)) #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.11      0.88 #> d[Group counselling]           0.70      0.23      0.07      0.00 #> d[Individual counselling]      0.24      0.60      0.16      0.00 #> d[Self-help]                   0.06      0.18      0.65      0.11 plot(smk_rankprobs) (smk_cumrankprobs <- posterior_rank_probs(smkfit, lower_better = FALSE, cumulative = TRUE)) #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.12         1 #> d[Group counselling]           0.70      0.93      1.00         1 #> d[Individual counselling]      0.24      0.84      1.00         1 #> d[Self-help]                   0.06      0.23      0.89         1 plot(smk_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Statins for cholesterol lowering","text":"data giving number deaths (r) total (n) arm, use function set_agd_arm() set network. set placebo network reference treatment. prevention variable statins data frame automatically available use meta-regression model.","code":"statin_net <- set_agd_arm(statins,                            study = studyc,                           trt = trtc,                           r = r,                            n = n,                           trt_ref = \"Placebo\") statin_net #> A network with 19 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study     Treatment arms      #>  4S        2: Placebo | Statin #>  Bestehorn 2: Placebo | Statin #>  Brown     2: Placebo | Statin #>  CCAIT     2: Placebo | Statin #>  Downs     2: Placebo | Statin #>  EXCEL     2: Placebo | Statin #>  Furberg   2: Placebo | Statin #>  Haskell   2: Placebo | Statin #>  Jones     2: Placebo | Statin #>  KAPS      2: Placebo | Statin #>  ... plus 9 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 19 #> Reference treatment is: Placebo #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: Statins for cholesterol lowering","text":"fit fixed effect (FE) random effects (RE) models, meta-regression binary covariate prevention.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"fixed-effect-meta-regression","dir":"Articles","previous_headings":"Meta-analysis models","what":"Fixed effect meta-regression","title":"Example: Statins for cholesterol lowering","text":"start fitting FE model. use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effect dStatind_\\mathrm{Statin}, study-specific intercepts μj\\mu_j, regression coefficient β\\beta. can examine range parameter values implied prior distributions summary() method: model fitted nma() function, fixed effect model specified trt_effects = \"fixed\". regression formula ~ .trt:prevention means interaction primary/secondary prevention treatment included; .trt special variable indicates treatment, prevention original data set. Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. statin_fit_FE <- nma(statin_net,                       trt_effects = \"fixed\",                      regression = ~.trt:prevention,                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_reg = normal(scale = 100)) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. statin_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:prevention. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                          mean se_mean   sd     2.5%      25%      50%      75% #> beta[.trtStatin:preventionSecondary]    -0.21    0.00 0.11    -0.43    -0.28    -0.21    -0.13 #> d[Statin]                               -0.10    0.00 0.10    -0.29    -0.17    -0.10    -0.04 #> lp__                                 -7246.65    0.09 3.40 -7254.24 -7248.77 -7246.33 -7244.14 #>                                         97.5% n_eff Rhat #> beta[.trtStatin:preventionSecondary]     0.01  2522    1 #> d[Statin]                                0.09  2463    1 #> lp__                                 -7241.06  1543    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:44:43 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(statin_fit_FE, pars = c(\"d\", \"beta\", \"mu\")) plot_prior_posterior(statin_fit_FE, prior = c(\"trt\", \"reg\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"random-effects-meta-regression","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-regression","title":"Example: Statins for cholesterol lowering","text":"now fit RE model. use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effect dStatind_\\mathrm{Statin}, study-specific intercepts μj\\mu_j, regression coefficient β\\beta. use half-N(0,52)\\textrm{half-N}(0, 5^2) prior distribution heterogeneity standard deviation τ\\tau. can examine range parameter values implied prior distributions summary() method: , model fitted nma() function, now trt_effects = \"random\". increase adapt_delta 0.99 remove small number divergent transition errors (default RE models set 0.95). Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. statin_fit_RE <- nma(statin_net,                       trt_effects = \"random\",                      regression = ~.trt:prevention,                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_reg = normal(scale = 100),                      prior_het = half_normal(scale = 5),                      adapt_delta = 0.99) #> Note: No treatment classes specified in network, any interactions in `regression` formula will be separate (independent) for each treatment. #> Use set_*() argument `trt_class` and nma() argument `class_interactions` to change this. statin_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Regression model: ~.trt:prevention. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                          mean se_mean   sd     2.5%      25%      50%      75% #> beta[.trtStatin:preventionSecondary]    -0.30    0.01 0.26    -0.90    -0.43    -0.27    -0.15 #> d[Statin]                               -0.06    0.01 0.21    -0.46    -0.18    -0.07     0.04 #> lp__                                 -7255.75    0.18 5.35 -7266.83 -7259.27 -7255.51 -7252.11 #> tau                                      0.25    0.01 0.21     0.01     0.09     0.19     0.34 #>                                         97.5% n_eff Rhat #> beta[.trtStatin:preventionSecondary]     0.19   970 1.01 #> d[Statin]                                0.39  1080 1.01 #> lp__                                 -7246.03   863 1.01 #> tau                                      0.77   667 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:44:47 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(statin_fit_RE, pars = c(\"d\", \"beta\", \"mu\", \"delta\")) plot_prior_posterior(statin_fit_RE, prior = c(\"trt\", \"reg\", \"het\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"model-fit-and-comparison","dir":"Articles","previous_headings":"","what":"Model fit and comparison","title":"Example: Statins for cholesterol lowering","text":"Model fit can checked using dic() function: DIC similar FE RE models, might choose FE model based parsimony. residual deviance statistics larger number data points, suggesting data points fit well. can also examine residual deviance contributions corresponding plot() method.   number studies fit well either model, posterior mean residual deviance contributions greater 1, investigated see substantive differences studies.","code":"(statin_dic_FE <- dic(statin_fit_FE)) #> Residual deviance: 45.9 (on 38 data points) #>                pD: 21.6 #>               DIC: 67.5 (statin_dic_RE <- dic(statin_fit_RE)) #> Residual deviance: 42.5 (on 38 data points) #>                pD: 25 #>               DIC: 67.4 plot(statin_dic_FE) plot(statin_dic_RE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_statins.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Statins for cholesterol lowering","text":"can produce estimates relative effect statins vs. placebo either primary secondary prevention, using relative_effects() function. newdata argument specifies data frame containing levels covariate prevention interested , study argument used specify column newdata informative label. plot() method may used visually compare estimates:  Model parameters may plotted corresponding plot() method:  Whilst 95% Credible Interval includes zero, suggestion statins effective secondary prevention.","code":"statin_releff_FE <- relative_effects(statin_fit_FE,                                      newdata = data.frame(prevention = c(\"Primary\", \"Secondary\")),                                      study = prevention)  statin_releff_FE #> ---------------------------------------------------------------- Study: Primary ----  #>  #> Covariate values: #>  prevention #>     Primary #>  #>                    mean  sd  2.5%   25%  50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Primary: Statin] -0.1 0.1 -0.29 -0.17 -0.1 -0.04  0.09     2476     2633    1 #>  #> -------------------------------------------------------------- Study: Secondary ----  #>  #> Covariate values: #>  prevention #>   Secondary #>  #>                       mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Secondary: Statin] -0.31 0.05 -0.42 -0.35 -0.31 -0.28 -0.21     4856     3721    1 plot(statin_releff_FE,       ref_line = 0) plot(statin_fit_FE,       pars = \"beta\",       ref_line = 0,      stat = \"halfeye\")"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: Thrombolytic treatments","text":"begin setting network. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). default, SK set network reference treatment. Plot network structure.","code":"thrombo_net <- set_agd_arm(thrombolytics,                             study = studyn,                            trt = trtc,                            r = r,                             n = n) thrombo_net #> A network with 50 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms               #>  1     3: SK | Acc t-PA | SK + t-PA #>  2     2: SK | t-PA                 #>  3     2: SK | t-PA                 #>  4     2: SK | t-PA                 #>  5     2: SK | t-PA                 #>  6     3: SK | ASPAC | t-PA         #>  7     2: SK | t-PA                 #>  8     2: SK | t-PA                 #>  9     2: SK | t-PA                 #>  10    2: SK | SK + t-PA            #>  ... plus 40 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 9 #> Total number of studies: 50 #> Reference treatment is: SK #> Network is connected plot(thrombo_net, weight_edges = TRUE, weight_nodes = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"fixed-effects-nma","dir":"Articles","previous_headings":"","what":"Fixed effects NMA","title":"Example: Thrombolytic treatments","text":"Following TSD 4 (Dias et al. 2011), fit fixed effects NMA model, using nma() function trt_effects = \"fixed\". use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k study-specific intercepts μj\\mu_j. can examine range parameter values implied prior distributions summary() method: model fitted using nma() function. default, use Binomial likelihood logit link function, auto-detected data. Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Model fit can checked using dic() function residual deviance contributions examined corresponding plot() method.  number points well fit model, posterior mean residual deviance contributions greater 1.","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. thrombo_fit <- nma(thrombo_net,                     trt_effects = \"fixed\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100)) #> Note: Setting \"SK\" as the network reference treatment. thrombo_fit #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd      2.5%       25%       50%       75%     97.5% n_eff #> d[Acc t-PA]      -0.18    0.00 0.04     -0.26     -0.21     -0.18     -0.15     -0.09  2282 #> d[ASPAC]          0.02    0.00 0.04     -0.06     -0.01      0.02      0.04      0.09  6274 #> d[PTCA]          -0.48    0.00 0.10     -0.68     -0.54     -0.48     -0.41     -0.29  3674 #> d[r-PA]          -0.12    0.00 0.06     -0.24     -0.16     -0.12     -0.08     -0.01  3136 #> d[SK + t-PA]     -0.05    0.00 0.05     -0.14     -0.08     -0.05     -0.02      0.04  4511 #> d[t-PA]           0.00    0.00 0.03     -0.05     -0.02      0.00      0.02      0.06  4702 #> d[TNK]           -0.17    0.00 0.08     -0.33     -0.23     -0.17     -0.12     -0.02  3049 #> d[UK]            -0.20    0.00 0.22     -0.62     -0.35     -0.20     -0.05      0.24  4542 #> lp__         -43042.86    0.14 5.45 -43054.42 -43046.43 -43042.59 -43038.91 -43033.24  1459 #>              Rhat #> d[Acc t-PA]     1 #> d[ASPAC]        1 #> d[PTCA]         1 #> d[r-PA]         1 #> d[SK + t-PA]    1 #> d[t-PA]         1 #> d[TNK]          1 #> d[UK]           1 #> lp__            1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:44:59 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(thrombo_fit, pars = c(\"d\", \"mu\")) plot_prior_posterior(thrombo_fit, prior = \"trt\") (dic_consistency <- dic(thrombo_fit)) #> Residual deviance: 105.9 (on 102 data points) #>                pD: 58.7 #>               DIC: 164.6 plot(dic_consistency)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"checking-for-inconsistency","dir":"Articles","previous_headings":"","what":"Checking for inconsistency","title":"Example: Thrombolytic treatments","text":"Note: results inconsistency models slightly different Dias et al. (2010, 2011), although overall conclusions . due presence multi-arm trials different ordering treatments, meaning inconsistency parameterised differently within multi-arm trials. results Dias et al. obtained network instead set trtn treatment variable.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"unrelated-mean-effects-model","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Unrelated mean effects model","title":"Example: Thrombolytic treatments","text":"first fit unrelated mean effects (UME) model (Dias et al. 2011) assess consistency assumption. , use function nma(), now argument consistency = \"ume\". Comparing model fit statistics Whilst UME model fits data better, lower residual deviance, additional parameters UME model mean DIC similar models. However, also important examine individual contributions model fit data point two models (-called “dev-dev” plot). Passing two nma_dic objects produced dic() function plot() method produces dev-dev plot:  four points lying lower right corner plot much lower posterior mean residual deviance UME model, indicating data potentially inconsistent. points correspond trials 44 45, two trials comparing Acc t-PA ASPAC. ASPAC vs. Acc t-PA estimates different consistency model inconsistency (UME) model, suggesting two trials may systematically different others network.","code":"thrombo_fit_ume <- nma(thrombo_net,                         consistency = \"ume\",                        trt_effects = \"fixed\",                        prior_intercept = normal(scale = 100),                        prior_trt = normal(scale = 100)) #> Note: Setting \"SK\" as the network reference treatment. thrombo_fit_ume #> vs. Acc t-PA]      1.41    0.01 0.42      0.62      1.12      1.39      1.69      2.23 #> d[PTCA vs. Acc t-PA]      -0.21    0.00 0.12     -0.44     -0.29     -0.22     -0.13      0.01 #> d[r-PA vs. Acc t-PA]       0.02    0.00 0.07     -0.11     -0.03      0.02      0.06      0.16 #> d[TNK vs. Acc t-PA]        0.00    0.00 0.06     -0.12     -0.04      0.01      0.05      0.13 #> d[UK vs. Acc t-PA]         0.15    0.01 0.35     -0.53     -0.09      0.15      0.38      0.84 #> d[t-PA vs. ASPAC]          0.29    0.01 0.36     -0.41      0.06      0.29      0.53      1.02 #> d[t-PA vs. PTCA]           0.54    0.01 0.41     -0.25      0.26      0.53      0.82      1.36 #> d[UK vs. t-PA]            -0.30    0.01 0.34     -0.98     -0.52     -0.29     -0.07      0.38 #> lp__                  -43039.71    0.14 5.73 -43051.68 -43043.41 -43039.38 -43035.70 -43029.33 #>                       n_eff Rhat #> d[Acc t-PA vs. SK]     4922    1 #> d[ASPAC vs. SK]        4156    1 #> d[PTCA vs. SK]         4903    1 #> d[r-PA vs. SK]         5564    1 #> d[SK + t-PA vs. SK]    5284    1 #> d[t-PA vs. SK]         3442    1 #> d[UK vs. SK]           4330    1 #> d[ASPAC vs. Acc t-PA]  3406    1 #> d[PTCA vs. Acc t-PA]   4038    1 #> d[r-PA vs. Acc t-PA]   4655    1 #> d[TNK vs. Acc t-PA]    5642    1 #> d[UK vs. Acc t-PA]     4389    1 #> d[t-PA vs. ASPAC]      3816    1 #> d[t-PA vs. PTCA]       3505    1 #> d[UK vs. t-PA]         4645    1 #> lp__                   1655    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:45:06 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). dic_consistency #> Residual deviance: 105.9 (on 102 data points) #>                pD: 58.7 #>               DIC: 164.6 (dic_ume <- dic(thrombo_fit_ume)) #> Residual deviance: 99.6 (on 102 data points) #>                pD: 65.9 #>               DIC: 165.4 plot(dic_consistency, dic_ume, show_uncertainty = FALSE)"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"node-splitting","dir":"Articles","previous_headings":"Checking for inconsistency","what":"Node-splitting","title":"Example: Thrombolytic treatments","text":"Another method assessing inconsistency node-splitting (Dias et al. 2011, 2010). Whereas UME model assesses inconsistency globally, node-splitting assesses inconsistency locally potentially inconsistent comparison (direct indirect evidence) turn. Node-splitting can performed using nma() function argument consistency = \"nodesplit\". default, possible comparisons split (determined get_nodesplits() function). Alternatively, specific comparison comparisons split can provided nodesplit argument. summary() method summarises node-splitting results, displaying direct indirect estimates ddird_\\mathrm{dir} dindd_\\mathrm{ind} node-split model, network estimate dnetd_\\mathrm{net} consistency model, inconsistency factor ω=ddir−dind\\omega = d_\\mathrm{dir} - d_\\mathrm{ind}, Bayesian pp-value inconsistency comparison. DIC model fit statistics also provided. (random effects model fitted, heterogeneity standard deviation τ\\tau node-split model consistency model also displayed.) Node-splitting ASPAC vs. Acc t-PA comparison results lowest DIC, lower consistency model. posterior distribution inconsistency factor ω\\omega comparison lies far 0 Bayesian pp-value inconsistency small (< 0.01), meaning substantial disagreement direct indirect evidence comparison. can visually compare direct, indirect, network estimates using plot() method.  can also plot posterior distributions inconsistency factors ω\\omega, using plot() method. , specify “halfeye” plot posterior density median credible intervals, customise plot layout standard ggplot2 functions.  Notice posterior distribution inconsistency factor ASPAC vs. Acc t-PA comparison lies far 0, indicating substantial inconsistency direct indirect evidence comparison.","code":"thrombo_nodesplit <- nma(thrombo_net,                           consistency = \"nodesplit\",                          trt_effects = \"fixed\",                          prior_intercept = normal(scale = 100),                          prior_trt = normal(scale = 100)) #> Fitting model 1 of 15, node-split: Acc t-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 2 of 15, node-split: ASPAC vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 3 of 15, node-split: PTCA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 4 of 15, node-split: r-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 5 of 15, node-split: t-PA vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 6 of 15, node-split: UK vs. SK #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 7 of 15, node-split: ASPAC vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 8 of 15, node-split: PTCA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 9 of 15, node-split: r-PA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 10 of 15, node-split: SK + t-PA vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 11 of 15, node-split: UK vs. Acc t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 12 of 15, node-split: t-PA vs. ASPAC #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 13 of 15, node-split: t-PA vs. PTCA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 14 of 15, node-split: UK vs. t-PA #> Note: Setting \"SK\" as the network reference treatment. #> Fitting model 15 of 15, consistency model #> Note: Setting \"SK\" as the network reference treatment. summary(thrombo_nodesplit) #> Node-splitting models fitted for 14 comparisons. #>  #> ---------------------------------------------------- Node-split Acc t-PA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.18 0.04 -0.26 -0.21 -0.18 -0.15 -0.09     2829     3285    1 #> d_dir -0.16 0.05 -0.25 -0.19 -0.16 -0.12 -0.06     3611     3629    1 #> d_ind -0.25 0.09 -0.42 -0.31 -0.25 -0.18 -0.06      781     1281    1 #> omega  0.09 0.10 -0.12  0.02  0.09  0.16  0.29      897     1821    1 #>  #> Residual deviance: 106.1 (on 102 data points) #>                pD: 59.7 #>               DIC: 165.8 #>  #> Bayesian p-value: 0.39 #>  #> ------------------------------------------------------- Node-split ASPAC vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.02 0.04 -0.06 -0.01  0.02  0.04  0.09     4921     3272    1 #> d_dir  0.01 0.04 -0.06 -0.02  0.01  0.03  0.08     4413     3279    1 #> d_ind  0.43 0.26 -0.06  0.26  0.43  0.61  0.93     2412     2650    1 #> omega -0.42 0.26 -0.93 -0.60 -0.42 -0.25  0.07     2466     2237    1 #>  #> Residual deviance: 104.6 (on 102 data points) #>                pD: 60.1 #>               DIC: 164.7 #>  #> Bayesian p-value: 0.096 #>  #> -------------------------------------------------------- Node-split PTCA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.47 0.10 -0.68 -0.54 -0.47 -0.40 -0.28     4278     3561    1 #> d_dir -0.66 0.19 -1.03 -0.78 -0.66 -0.54 -0.30     5008     3177    1 #> d_ind -0.39 0.12 -0.62 -0.47 -0.39 -0.31 -0.16     3479     3476    1 #> omega -0.27 0.22 -0.72 -0.42 -0.27 -0.12  0.15     4281     3302    1 #>  #> Residual deviance: 105.5 (on 102 data points) #>                pD: 59.8 #>               DIC: 165.3 #>  #> Bayesian p-value: 0.23 #>  #> -------------------------------------------------------- Node-split r-PA vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.12 0.06 -0.24 -0.16 -0.12 -0.08  0.00     3934     3728    1 #> d_dir -0.06 0.09 -0.23 -0.12 -0.06  0.00  0.11     5317     3758    1 #> d_ind -0.18 0.08 -0.34 -0.23 -0.18 -0.13 -0.02     2616     2797    1 #> omega  0.12 0.12 -0.11  0.04  0.12  0.20  0.35     3166     3404    1 #>  #> Residual deviance: 105.8 (on 102 data points) #>                pD: 59.5 #>               DIC: 165.3 #>  #> Bayesian p-value: 0.3 #>  #> -------------------------------------------------------- Node-split t-PA vs. SK ----  #>  #>        mean   sd  2.5%   25%  50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.00 0.03 -0.06 -0.02  0.0  0.02  0.06     4247     3428    1 #> d_dir  0.00 0.03 -0.06 -0.02  0.0  0.02  0.06     3766     3236    1 #> d_ind  0.20 0.24 -0.28  0.03  0.2  0.36  0.67     1188     1674    1 #> omega -0.19 0.24 -0.67 -0.36 -0.2 -0.03  0.28     1192     1627    1 #>  #> Residual deviance: 106.1 (on 102 data points) #>                pD: 59.5 #>               DIC: 165.6 #>  #> Bayesian p-value: 0.42 #>  #> ---------------------------------------------------------- Node-split UK vs. SK ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.20 0.22 -0.63 -0.35 -0.20 -0.05  0.23     5086     3492    1 #> d_dir -0.37 0.53 -1.45 -0.71 -0.36 -0.02  0.64     5967     3383    1 #> d_ind -0.16 0.25 -0.64 -0.34 -0.17  0.00  0.33     4475     3188    1 #> omega -0.21 0.59 -1.39 -0.60 -0.18  0.19  0.90     5313     3072    1 #>  #> Residual deviance: 107.1 (on 102 data points) #>                pD: 60 #>               DIC: 167.1 #>  #> Bayesian p-value: 0.75 #>  #> ------------------------------------------------- Node-split ASPAC vs. Acc t-PA ----  #>  #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net 0.19 0.06 0.08 0.15 0.19 0.23  0.30     3578     3457    1 #> d_dir 1.41 0.42 0.63 1.12 1.40 1.68  2.29     3819     2946    1 #> d_ind 0.16 0.06 0.05 0.13 0.16 0.20  0.28     2801     2977    1 #> omega 1.25 0.42 0.44 0.95 1.23 1.52  2.15     3567     3100    1 #>  #> Residual deviance: 96.6 (on 102 data points) #>                pD: 59.4 #>               DIC: 156 #>  #> Bayesian p-value: <0.01 #>  #> -------------------------------------------------- Node-split PTCA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.30 0.10 -0.49 -0.36 -0.30 -0.23 -0.10     5146     3648    1 #> d_dir -0.22 0.12 -0.46 -0.30 -0.22 -0.14  0.01     4205     3251    1 #> d_ind -0.47 0.17 -0.82 -0.59 -0.47 -0.36 -0.12     2983     2689    1 #> omega  0.25 0.21 -0.16  0.11  0.25  0.39  0.67     2791     2653    1 #>  #> Residual deviance: 105.3 (on 102 data points) #>                pD: 59.7 #>               DIC: 165 #>  #> Bayesian p-value: 0.22 #>  #> -------------------------------------------------- Node-split r-PA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.05 0.06 -0.05  0.02  0.05  0.09  0.17     6384     3753    1 #> d_dir  0.02 0.07 -0.11 -0.02  0.02  0.07  0.15     5499     3773    1 #> d_ind  0.14 0.10 -0.06  0.07  0.14  0.21  0.34     2200     2558    1 #> omega -0.12 0.12 -0.35 -0.20 -0.11 -0.03  0.12     2284     2744    1 #>  #> Residual deviance: 106 (on 102 data points) #>                pD: 59.7 #>               DIC: 165.7 #>  #> Bayesian p-value: 0.33 #>  #> --------------------------------------------- Node-split SK + t-PA vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net  0.13 0.05  0.02  0.09  0.13  0.16  0.23     5546     3319    1 #> d_dir  0.13 0.05  0.02  0.09  0.13  0.16  0.23     3859     3320    1 #> d_ind  0.64 0.70 -0.66  0.16  0.61  1.08  2.09     3244     2285    1 #> omega -0.51 0.70 -1.96 -0.95 -0.49 -0.03  0.81     3266     2399    1 #>  #> Residual deviance: 106.6 (on 102 data points) #>                pD: 59.9 #>               DIC: 166.6 #>  #> Bayesian p-value: 0.46 #>  #> ---------------------------------------------------- Node-split UK vs. Acc t-PA ----  #>  #>        mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.02 0.22 -0.45 -0.18 -0.03 0.13  0.41     5173     3586    1 #> d_dir  0.14 0.36 -0.55 -0.10  0.14 0.38  0.86     5105     3461    1 #> d_ind -0.13 0.29 -0.71 -0.32 -0.13 0.07  0.42     4119     2829    1 #> omega  0.27 0.46 -0.60 -0.04  0.27 0.58  1.21     3884     2684    1 #>  #> Residual deviance: 106.7 (on 102 data points) #>                pD: 59.8 #>               DIC: 166.5 #>  #> Bayesian p-value: 0.55 #>  #> ----------------------------------------------------- Node-split t-PA vs. ASPAC ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.01 0.04 -0.08 -0.04 -0.01  0.01  0.06     6939     3338    1 #> d_dir -0.02 0.04 -0.10 -0.05 -0.02  0.00  0.05     4488     3651    1 #> d_ind  0.03 0.06 -0.09 -0.01  0.03  0.07  0.15     3471     3236    1 #> omega -0.05 0.06 -0.17 -0.09 -0.05 -0.01  0.07     3519     3264    1 #>  #> Residual deviance: 106.6 (on 102 data points) #>                pD: 60 #>               DIC: 166.6 #>  #> Bayesian p-value: 0.42 #>  #> ------------------------------------------------------ Node-split t-PA vs. PTCA ----  #>  #>       mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net 0.48 0.11  0.27  0.40 0.48 0.55  0.69     4341     3407    1 #> d_dir 0.53 0.41 -0.22  0.25 0.53 0.80  1.36     4940     3163    1 #> d_ind 0.48 0.11  0.27  0.40 0.48 0.55  0.69     4014     3519    1 #> omega 0.06 0.43 -0.75 -0.24 0.05 0.34  0.90     4453     3145    1 #>  #> Residual deviance: 106.6 (on 102 data points) #>                pD: 59.4 #>               DIC: 166 #>  #> Bayesian p-value: 0.9 #>  #> -------------------------------------------------------- Node-split UK vs. t-PA ----  #>  #>        mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net -0.20 0.22 -0.64 -0.36 -0.21 -0.06  0.23     5258     3628    1 #> d_dir -0.30 0.35 -0.98 -0.53 -0.29 -0.07  0.37     4838     3525    1 #> d_ind -0.14 0.29 -0.70 -0.33 -0.15  0.05  0.43     3982     3187    1 #> omega -0.16 0.45 -1.03 -0.47 -0.15  0.14  0.75     4112     3155    1 #>  #> Residual deviance: 106.7 (on 102 data points) #>                pD: 59.6 #>               DIC: 166.3 #>  #> Bayesian p-value: 0.72 plot(thrombo_nodesplit) plot(thrombo_nodesplit, pars = \"omega\", stat = \"halfeye\", ref_line = 0) +   ggplot2::aes(y = comparison) +   ggplot2::facet_null()"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_thrombolytics.html","id":"further-results","dir":"Articles","previous_headings":"","what":"Further results","title":"Example: Thrombolytic treatments","text":"Relative effects pairwise contrasts treatments can produced using relative_effects() function, all_contrasts = TRUE.  Treatment rankings, rank probabilities, cumulative rank probabilities.","code":"(thrombo_releff <- relative_effects(thrombo_fit, all_contrasts = TRUE)) #>                            mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[Acc t-PA vs. SK]        -0.18 0.04 -0.26 -0.21 -0.18 -0.15 -0.09     2297     2890    1 #> d[ASPAC vs. SK]            0.02 0.04 -0.06 -0.01  0.02  0.04  0.09     6306     3122    1 #> d[PTCA vs. SK]            -0.48 0.10 -0.68 -0.54 -0.48 -0.41 -0.29     3707     2941    1 #> d[r-PA vs. SK]            -0.12 0.06 -0.24 -0.16 -0.12 -0.08 -0.01     3155     3054    1 #> d[SK + t-PA vs. SK]       -0.05 0.05 -0.14 -0.08 -0.05 -0.02  0.04     4626     3134    1 #> d[t-PA vs. SK]             0.00 0.03 -0.05 -0.02  0.00  0.02  0.06     4738     3740    1 #> d[TNK vs. SK]             -0.17 0.08 -0.33 -0.23 -0.17 -0.12 -0.02     3102     3056    1 #> d[UK vs. SK]              -0.20 0.22 -0.62 -0.35 -0.20 -0.05  0.24     4587     3185    1 #> d[ASPAC vs. Acc t-PA]      0.19 0.06  0.08  0.16  0.19  0.23  0.30     2991     3249    1 #> d[PTCA vs. Acc t-PA]      -0.30 0.10 -0.50 -0.37 -0.30 -0.23 -0.11     5470     3119    1 #> d[r-PA vs. Acc t-PA]       0.05 0.05 -0.05  0.02  0.05  0.09  0.16     5337     3122    1 #> d[SK + t-PA vs. Acc t-PA]  0.13 0.05  0.02  0.09  0.13  0.16  0.23     5625     3490    1 #> d[t-PA vs. Acc t-PA]       0.18 0.05  0.07  0.14  0.18  0.22  0.29     2778     3132    1 #> d[TNK vs. Acc t-PA]        0.00 0.06 -0.13 -0.04  0.01  0.05  0.13     5569     3440    1 #> d[UK vs. Acc t-PA]        -0.02 0.22 -0.45 -0.18 -0.02  0.12  0.42     4777     3139    1 #> d[PTCA vs. ASPAC]         -0.49 0.11 -0.71 -0.56 -0.49 -0.42 -0.29     3813     2868    1 #> d[r-PA vs. ASPAC]         -0.14 0.07 -0.28 -0.19 -0.14 -0.09  0.00     3739     3517    1 #> d[SK + t-PA vs. ASPAC]    -0.07 0.06 -0.18 -0.11 -0.07 -0.03  0.05     5913     3605    1 #> d[t-PA vs. ASPAC]         -0.01 0.04 -0.09 -0.04 -0.01  0.01  0.06     8004     3118    1 #> d[TNK vs. ASPAC]          -0.19 0.09 -0.36 -0.25 -0.19 -0.13 -0.02     3388     3468    1 #> d[UK vs. ASPAC]           -0.22 0.22 -0.66 -0.37 -0.22 -0.07  0.23     4701     3155    1 #> d[r-PA vs. PTCA]           0.35 0.11  0.14  0.28  0.35  0.43  0.57     5165     3169    1 #> d[SK + t-PA vs. PTCA]      0.43 0.11  0.22  0.36  0.43  0.50  0.64     5069     3705    1 #> d[t-PA vs. PTCA]           0.48 0.10  0.28  0.41  0.48  0.55  0.69     3723     2692    1 #> d[TNK vs. PTCA]            0.30 0.12  0.08  0.23  0.31  0.38  0.53     5869     3409    1 #> d[UK vs. PTCA]             0.28 0.24 -0.20  0.11  0.28  0.44  0.76     4930     3276    1 #> d[SK + t-PA vs. r-PA]      0.07 0.07 -0.06  0.03  0.07  0.12  0.21     5588     3336    1 #> d[t-PA vs. r-PA]           0.13 0.07  0.00  0.08  0.13  0.17  0.26     3351     3015    1 #> d[TNK vs. r-PA]           -0.05 0.08 -0.21 -0.10 -0.05  0.01  0.12     6617     3188    1 #> d[UK vs. r-PA]            -0.08 0.23 -0.51 -0.23 -0.08  0.07  0.37     4906     3153    1 #> d[t-PA vs. SK + t-PA]      0.05 0.06 -0.06  0.02  0.05  0.09  0.16     5193     3110    1 #> d[TNK vs. SK + t-PA]      -0.12 0.09 -0.29 -0.18 -0.12 -0.06  0.04     5361     3211    1 #> d[UK vs. SK + t-PA]       -0.15 0.22 -0.59 -0.31 -0.15  0.00  0.29     4783     3208    1 #> d[TNK vs. t-PA]           -0.18 0.08 -0.34 -0.23 -0.17 -0.12 -0.02     3205     3243    1 #> d[UK vs. t-PA]            -0.20 0.22 -0.63 -0.35 -0.20 -0.06  0.23     4686     3328    1 #> d[UK vs. TNK]             -0.03 0.23 -0.47 -0.19 -0.03  0.13  0.42     4894     3502    1 plot(thrombo_releff, ref_line = 0) (thrombo_ranks <- posterior_ranks(thrombo_fit)) #>                 mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[SK]        7.44 0.96    6   7   7   8     9     3745       NA    1 #> rank[Acc t-PA]  3.20 0.81    2   3   3   4     5     3992     3614    1 #> rank[ASPAC]     7.99 1.14    5   7   8   9     9     5171       NA    1 #> rank[PTCA]      1.13 0.34    1   1   1   1     2     3792     2868    1 #> rank[r-PA]      4.38 1.15    2   4   4   5     7     4593     3572    1 #> rank[SK + t-PA] 5.97 1.24    4   5   6   6     9     5264       NA    1 #> rank[t-PA]      7.50 1.09    5   7   8   8     9     4634       NA    1 #> rank[TNK]       3.47 1.25    2   3   3   4     6     5166     3851    1 #> rank[UK]        3.92 2.69    1   2   3   6     9     4645       NA    1 plot(thrombo_ranks) (thrombo_rankprobs <- posterior_rank_probs(thrombo_fit)) #>              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] p_rank[8] #> d[SK]             0.00      0.00      0.00      0.00      0.02      0.14      0.39      0.32 #> d[Acc t-PA]       0.00      0.20      0.45      0.30      0.05      0.00      0.00      0.00 #> d[ASPAC]          0.00      0.00      0.00      0.01      0.03      0.09      0.17      0.26 #> d[PTCA]           0.87      0.13      0.00      0.00      0.00      0.00      0.00      0.00 #> d[r-PA]           0.00      0.06      0.14      0.30      0.39      0.08      0.01      0.01 #> d[SK + t-PA]      0.00      0.00      0.01      0.07      0.25      0.45      0.09      0.07 #> d[t-PA]           0.00      0.00      0.00      0.00      0.03      0.15      0.30      0.32 #> d[TNK]            0.00      0.24      0.32      0.23      0.15      0.04      0.01      0.00 #> d[UK]             0.13      0.37      0.07      0.08      0.10      0.06      0.03      0.02 #>              p_rank[9] #> d[SK]             0.15 #> d[Acc t-PA]       0.00 #> d[ASPAC]          0.44 #> d[PTCA]           0.00 #> d[r-PA]           0.00 #> d[SK + t-PA]      0.05 #> d[t-PA]           0.20 #> d[TNK]            0.00 #> d[UK]             0.15 plot(thrombo_rankprobs) (thrombo_cumrankprobs <- posterior_rank_probs(thrombo_fit, cumulative = TRUE)) #>              p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] p_rank[7] p_rank[8] #> d[SK]             0.00      0.00      0.00      0.00      0.02      0.15      0.54      0.85 #> d[Acc t-PA]       0.00      0.20      0.65      0.95      1.00      1.00      1.00      1.00 #> d[ASPAC]          0.00      0.00      0.00      0.01      0.03      0.12      0.30      0.56 #> d[PTCA]           0.87      1.00      1.00      1.00      1.00      1.00      1.00      1.00 #> d[r-PA]           0.00      0.06      0.20      0.51      0.89      0.97      0.99      1.00 #> d[SK + t-PA]      0.00      0.00      0.01      0.08      0.33      0.78      0.88      0.95 #> d[t-PA]           0.00      0.00      0.00      0.00      0.03      0.18      0.48      0.80 #> d[TNK]            0.00      0.24      0.56      0.80      0.95      0.99      0.99      1.00 #> d[UK]             0.13      0.50      0.57      0.65      0.75      0.81      0.83      0.85 #>              p_rank[9] #> d[SK]                1 #> d[Acc t-PA]          1 #> d[ASPAC]             1 #> d[PTCA]              1 #> d[r-PA]              1 #> d[SK + t-PA]         1 #> d[t-PA]              1 #> d[TNK]               1 #> d[UK]                1 plot(thrombo_cumrankprobs)"},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"setting-up-the-network","dir":"Articles","previous_headings":"","what":"Setting up the network","title":"Example: White blood cell transfusion","text":"begin setting network - just pairwise meta-analysis. arm-level count data giving number deaths (r) total (n) arm, use function set_agd_arm(). set “Control” reference treatment.","code":"tr_net <- set_agd_arm(transfusion,                             study = studyc,                            trt = trtc,                            r = r,                             n = n,                            trt_ref = \"Control\") tr_net #> A network with 6 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms           #>  Bow 1984      2: Control | Transfusion #>  Herzig 1977   2: Control | Transfusion #>  Higby 1975    2: Control | Transfusion #>  Scali 1978    2: Control | Transfusion #>  Vogler 1977   2: Control | Transfusion #>  Winston 1982a 2: Control | Transfusion #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 2 #> Total number of studies: 6 #> Reference treatment is: Control #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"meta-analysis-models","dir":"Articles","previous_headings":"","what":"Meta-analysis models","title":"Example: White blood cell transfusion","text":"fit two random effects models, first non-informative prior heterogeneity, using informative prior described Turner et al. (2012).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"random-effects-meta-analysis-with-non-informative-heterogeneity-prior","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis with non-informative heterogeneity prior","title":"Example: White blood cell transfusion","text":"fit random effects model using nma() function trt_effects = \"random\". use N(0,1002)\\mathrm{N}(0, 100^2) prior distributions treatment effects dkd_k study-specific intercepts μj\\mu_j, non-informative half-N(52)\\textrm{half-N}(5^2) prior heterogeneity standard deviation τ\\tau. can examine range parameter values implied prior distributions summary() method: Fitting RE model Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  posterior distribution heterogeneity variance τ2\\tau^2 summarised ","code":"summary(normal(scale = 100)) #> A Normal prior distribution: location = 0, scale = 100. #> 50% of the prior density lies between -67.45 and 67.45. #> 95% of the prior density lies between -196 and 196. summary(half_normal(scale = 5)) #> A half-Normal prior distribution: location = 0, scale = 5. #> 50% of the prior density lies between 0 and 3.37. #> 95% of the prior density lies between 0 and 9.8. tr_fit_RE_noninf <- nma(tr_net,                          trt_effects = \"random\",                         prior_intercept = normal(scale = 100),                         prior_trt = normal(scale = 100),                         prior_het = half_normal(scale = 5)) #> 00 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.237 seconds (Warm-up) #> Chain 3:                0.196 seconds (Sampling) #> Chain 3:                0.433 seconds (Total) #> Chain 3:  #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.208 seconds (Warm-up) #> Chain 1:                0.276 seconds (Sampling) #> Chain 1:                0.484 seconds (Total) #> Chain 1:  #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.224 seconds (Warm-up) #> Chain 2:                0.274 seconds (Sampling) #> Chain 2:                0.498 seconds (Total) #> Chain 2: tr_fit_RE_noninf #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Transfusion]   -1.17    0.05 1.06   -3.34   -1.67   -1.10   -0.56    0.68   538    1 #> lp__           -134.50    0.09 3.11 -141.53 -136.37 -134.16 -132.24 -129.53  1098    1 #> tau               1.87    0.04 1.09    0.56    1.16    1.63    2.29    4.73   650    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:46:13 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(tr_fit_RE_noninf, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(tr_fit_RE_noninf, prior = \"het\") noninf_tau <- as.array(tr_fit_RE_noninf, pars = \"tau\") noninf_tausq <- noninf_tau^2 names(noninf_tausq) <- \"tausq\" summary(noninf_tausq) #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq  4.7 7.02 0.31 1.34 2.64 5.26 22.34      883      941    1"},{"path":"https://dmphillippo.github.io/multinma/dev/articles/example_transfusion.html","id":"random-effects-meta-analysis-with-informative-heterogeneity-prior","dir":"Articles","previous_headings":"Meta-analysis models","what":"Random effects meta-analysis with informative heterogeneity prior","title":"Example: White blood cell transfusion","text":"Keeping rest model setup , now use informative log-N(−3.93,1.512)\\textrm{log-N}(-3.93, 1.51^2) prior heterogeneity variance τ2\\tau^2. can examine range parameter values implied prior distribution summary() method: Fitting RE model, specify log_normal prior distribution prior_het argument, set prior_het_type = \"var\" indicate prior distribution variance scale (instead standard deviation, default). Basic parameter summaries given print() method: default, summaries study-specific intercepts μj\\mu_j study-specific relative effects δjk\\delta_{jk} hidden, examined changing pars argument: prior posterior distributions can compared visually using plot_prior_posterior() function:  Note: heterogeneity variance τ2\\tau^2 plotted since prior specified τ2\\tau^2. posterior distribution heterogeneity variance τ2\\tau^2 summarised ","code":"summary(log_normal(-3.93, 1.51)) #> A log-Normal prior distribution: location = -3.93, scale = 1.51. #> 50% of the prior density lies between 0.01 and 0.05. #> 95% of the prior density lies between 0 and 0.38. tr_fit_RE_inf <- nma(tr_net,                       trt_effects = \"random\",                      prior_intercept = normal(scale = 100),                      prior_trt = normal(scale = 100),                      prior_het = log_normal(-3.93, 1.51),                      prior_het_type = \"var\") #> / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.127 seconds (Warm-up) #> Chain 1:                0.135 seconds (Sampling) #> Chain 1:                0.262 seconds (Total) #> Chain 1:  #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.116 seconds (Warm-up) #> Chain 3:                0.131 seconds (Sampling) #> Chain 3:                0.247 seconds (Total) #> Chain 3:  #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.14 seconds (Warm-up) #> Chain 2:                0.142 seconds (Sampling) #> Chain 2:                0.282 seconds (Total) #> Chain 2: tr_fit_RE_inf #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                   mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat #> d[Transfusion]   -0.78    0.01 0.44   -1.76   -1.03   -0.74   -0.49    0.01  2308    1 #> lp__           -140.97    0.07 2.77 -147.30 -142.63 -140.64 -138.91 -136.61  1385    1 #> tau               0.50    0.01 0.36    0.05    0.21    0.44    0.70    1.38  1654    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:46:16 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). # Not run print(tr_fit_RE_inf, pars = c(\"d\", \"mu\", \"delta\")) plot_prior_posterior(tr_fit_RE_inf, prior = \"het\") inf_tau <- as.array(tr_fit_RE_inf, pars = \"tau\") inf_tausq <- inf_tau^2 names(inf_tausq) <- \"tausq\" summary(inf_tausq) #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq 0.38 0.55    0 0.05 0.19 0.49  1.92     1553     2904    1"},{"path":[]},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David M. Phillippo. Author, maintainer.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Phillippo DM (2024). multinma: Bayesian Network Meta-Analysis Individual Aggregate Data. doi:10.5281/zenodo.3904454, R package version 0.7.2.9007, https://dmphillippo.github.io/multinma/. Phillippo DM, Dias S, Ades AE, Belger M, Brnabic , Schacht , Saure D, Kadziola Z, Welton NJ (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3), 1189-1210. doi:10.1111/rssa.12579.","code":"@Manual{,   title = {multinma: Bayesian Network Meta-Analysis of Individual and Aggregate Data},   author = {David M. Phillippo},   year = {2024},   note = {R package version 0.7.2.9007},   url = {https://dmphillippo.github.io/multinma/},   doi = {10.5281/zenodo.3904454}, } @Article{,   title = {Multilevel Network Meta-Regression for population-adjusted treatment comparisons},   author = {David M. Phillippo and Sofia Dias and A. E. Ades and Mark Belger and Alan Brnabic and Alexander Schacht and Daniel Saure and Zbigniew Kadziola and Nicky J. Welton},   year = {2020},   doi = {10.1111/rssa.12579},   journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},   volume = {183},   number = {3},   pages = {1189-1210}, }"},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"multinma-network-meta-analysis-of-individual-and-aggregate-data-in-stan-","dir":"","previous_headings":"","what":"Bayesian network meta-analysis of individual and aggregate data","title":"Bayesian network meta-analysis of individual and aggregate data","text":"multinma package implements network meta-analysis, network meta-regression, multilevel network meta-regression models combine evidence network studies treatments using either aggregate data individual patient data study (Phillippo et al. 2020; Phillippo 2019). Models estimated Bayesian framework using Stan (Carpenter et al. 2017).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian network meta-analysis of individual and aggregate data","text":"can install released version multinma CRAN : development version can installed R-universe : source GitHub : Installing source requires rstan package installed configured. See installation guide .","code":"install.packages(\"multinma\") install.packages(\"multinma\", repos = c(\"https://dmphillippo.r-universe.dev\", getOption(\"repos\"))) # install.packages(\"devtools\") devtools::install_github(\"dmphillippo/multinma\")"},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting started","title":"Bayesian network meta-analysis of individual and aggregate data","text":"good place start package vignettes walk example analyses, see vignette(\"vignette_overview\") overview. series NICE Technical Support Documents evidence synthesis gives detailed introduction network meta-analysis: Dias, S. et al. (2011). “NICE DSU Technical Support Documents 1-7: Evidence Synthesis Decision Making.” National Institute Health Care Excellence. Available https://www.sheffield.ac.uk/nice-dsu/tsds. Multilevel network meta-regression set following methods papers: Phillippo, D. M. et al. (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3):1189-1210. doi: 10.1111/rssa.12579. Phillippo, D. M. et al. (2024). “Multilevel network meta-regression general likelihoods: synthesis individual aggregate data applications survival analysis”. arXiv:2401.12640.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/index.html","id":"citing-multinma","dir":"","previous_headings":"","what":"Citing multinma","title":"Bayesian network meta-analysis of individual and aggregate data","text":"multinma package can cited follows: Phillippo, D. M. (2024). multinma: Bayesian Network Meta-Analysis Individual Aggregate Data. R package version 0.7.2.9000, doi: 10.5281/zenodo.3904454. fitting ML-NMR models, please cite methods paper: Phillippo, D. M. et al. (2020). “Multilevel Network Meta-Regression population-adjusted treatment comparisons.” Journal Royal Statistical Society: Series (Statistics Society), 183(3):1189-1210. doi: 10.1111/rssa.12579. ML-NMR models time--event outcomes, please cite: Phillippo, D. M. et al. (2024). “Multilevel network meta-regression general likelihoods: synthesis individual aggregate data applications survival analysis”. arXiv:2401.12640.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":null,"dir":"Reference","previous_headings":"","what":"The Bernoulli Distribution — qbern","title":"The Bernoulli Distribution — qbern","text":"density function dbern(), distribution function pbern(), quantile function qbern() Bernoulli distribution, success probability prob. equivalent dbinom(p, 1, prob), pbinom(p, 1, prob) qbinom(p, 1, prob).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Bernoulli Distribution — qbern","text":"","code":"qbern(p, prob, lower.tail = TRUE, log.p = FALSE)  pbern(q, prob, lower.tail = TRUE, log.p = FALSE)  dbern(x, prob, log = FALSE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Bernoulli Distribution — qbern","text":"p vector probabilities prob probability success lower.tail, log.p, log see stats::Binomial x, q vector quantiles","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/Bernoulli.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Bernoulli Distribution — qbern","text":"Numeric vector length equal maximum lengths input arguments.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":null,"dir":"Reference","previous_headings":"","what":"The Gamma distribution — qgamma","title":"The Gamma distribution — qgamma","text":"provide convenient extensions [dpq]gamma functions, allow distribution specified terms mean standard deviation, instead shape rate/scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Gamma distribution — qgamma","text":"","code":"qgamma(   p,   shape,   rate = 1,   scale = 1/rate,   lower.tail = TRUE,   log.p = FALSE,   mean,   sd )  dgamma(x, shape, rate = 1, scale = 1/rate, log = FALSE, mean, sd)  pgamma(   q,   shape,   rate = 1,   scale = 1/rate,   lower.tail = TRUE,   log.p = FALSE,   mean,   sd )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Gamma distribution — qgamma","text":"p vector probabilities shape, rate, scale, log, lower.tail, log.p see stats::GammaDist mean, sd mean standard deviation, overriding shape rate scale specified x, q vector quantiles","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/GammaDist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Gamma distribution — qgamma","text":"Numeric vector length equal maximum lengths input arguments.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_ndmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Example newly-diagnosed multiple myeloma — example_ndmm","title":"Example newly-diagnosed multiple myeloma — example_ndmm","text":"Calling example(\"example_ndmm\") run proportional hazards Weibull NMA model newly-diagnosed multiple myeloma data, using code Examples section . resulting stan_nma object ndmm_fit available global environment.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_pso_mlnmr.html","id":null,"dir":"Reference","previous_headings":"","what":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","title":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","text":"Calling example(\"example_pso_mlnmr\") run ML-NMR model plaque psoriasis IPD AgD, using code Examples section . resulting stan_nma object pso_fit available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_pso_mlnmr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example plaque psoriasis ML-NMR — example_pso_mlnmr","text":"Plaque psoriasis ML-NMR use examples.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_fe.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking FE NMA — example_smk_fe","title":"Example smoking FE NMA — example_smk_fe","text":"Calling example(\"example_smk_fe\") run fixed effects NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_FE available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_fe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking FE NMA — example_smk_fe","text":"Smoking FE NMA use examples.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_nodesplit.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking node-splitting — example_smk_nodesplit","title":"Example smoking node-splitting — example_smk_nodesplit","text":"Calling example(\"example_smk_nodesplit\") run node-splitting models smoking cessation data, using code Examples section . resulting nma_nodesplit_df object smk_fit_RE_nodesplit available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_nodesplit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking node-splitting — example_smk_nodesplit","text":"Smoking node-splitting use examples.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_re.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking RE NMA — example_smk_re","title":"Example smoking RE NMA — example_smk_re","text":"Calling example(\"example_smk_re\") run random effects NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_RE available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_re.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking RE NMA — example_smk_re","text":"Smoking RE NMA use examples.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_ume.html","id":null,"dir":"Reference","previous_headings":"","what":"Example smoking UME NMA — example_smk_ume","title":"Example smoking UME NMA — example_smk_ume","text":"Calling example(\"example_smk_ume\") run unrelated mean effects (inconsistency) NMA model smoking cessation data, using code Examples section . resulting stan_nma object smk_fit_RE_UME available global environment.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/aa_example_smk_ume.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example smoking UME NMA — example_smk_ume","text":"Smoking UME NMA use examples.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/adapt_delta.html","id":null,"dir":"Reference","previous_headings":"","what":"Target average acceptance probability — adapt_delta","title":"Target average acceptance probability — adapt_delta","text":"Stan control argument adapt_delta sets target average acceptance probability -U-Turn Sampler (NUTS) used Stan.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/adapt_delta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Target average acceptance probability — adapt_delta","text":"default value adapt_delta used nma() 0.8 fixed effect models, 0.95 random effects models. need change adapt_delta unless see warning message divergent transitions. Increasing adapt_delta default value closer 1 means Stan use smaller step size, making sampling slower robust, resulting fewer divergent transitions. details see Stan documentation available https://mc-stan.org/users/documentation/.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":null,"dir":"Reference","previous_headings":"","what":"Add numerical integration points to aggregate data — add_integration","title":"Add numerical integration points to aggregate data — add_integration","text":"add_integration() generic creates Quasi-Monte Carlo numerical integration points using Gaussian copula Sobol' sequences, described methods_paper;textualmultinma. Methods available networks stored nma_data objects, data frames. function unnest_integration() unnests integration points stored data frame, aid plotting exploration.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add numerical integration points to aggregate data — add_integration","text":"","code":"add_integration(x, ...)  # Default S3 method add_integration(x, ...)  # S3 method for class 'data.frame' add_integration(   x,   ...,   cor = NULL,   cor_adjust = NULL,   n_int = 64L,   int_args = list() )  # S3 method for class 'nma_data' add_integration(   x,   ...,   cor = NULL,   cor_adjust = NULL,   n_int = 64L,   int_args = list() )  unnest_integration(data)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add numerical integration points to aggregate data — add_integration","text":"x nma_data object, created set_*() functions combine_network(), data frame ... Distributions covariates, see \"Details\" cor Correlation matrix use generating integration points. default, takes weighted correlation matrix IPD studies. Rows columns match order covariates specified .... cor_adjust Adjustment apply correlation matrix given cor (computed IPD cor = NULL) obtain Gaussian copula correlations, either \"spearman\", \"pearson\", \"none\", see \"Details\". default cor = NULL \"spearman\", otherwise default \"pearson\". n_int Number integration points generate, default 64. Powers 2 recommended, expected particularly efficient QMC integration. int_args named list arguments pass sobol() data Data frame nested integration points, stored list columns .int_<variable name>","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add numerical integration points to aggregate data — add_integration","text":"nma_data method, object class nma_data. data.frame method, input data frame returned (tibble) added column covariate (prefixed \".int_\"), containing numerical integration points nested length-n_int vectors within row. unnest_integration(), data frame integration points unnested.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add numerical integration points to aggregate data — add_integration","text":"arguments passed ... specify distributions covariates. Argument names specify name covariate, match covariate name IPD (IPD present). required marginal distribution specified using function distr(). argument cor_adjust specifies correlation matrix given cor (computed IPD cor = NULL) adjusted obtain correlation matrix Gaussian copula, using formulae Xiao2018;textualmultinma. cor_adjust = \"spearman\" used correlations cor computed using Spearman's rank correlation. Correlations continuous covariates reproduced exactly integration points. Correlations discrete covariates reproduced approximately. default cor = NULL correlations calculated IPD studies. cor_adjust = \"pearson\" used correlations cor computed using Pearson's product-moment correlation. Correlations Normal covariates reproduced exactly integration points, others reproduced approximately. Correlations discrete covariates reproduced approximately (identically cor_adjust   = \"spearman\"). default cor provided user, since cor() defaults method = \"pearson\" Pearson correlations likely reported published data. However, recommend providing Spearman correlations (e.g. cor(., method = \"spearman\")) using cor_adjust = \"spearman\" possible. cor_adjust = \"none\" allows user specify correlation matrix Gaussian copula directly; adjustment applied. cor_adjust = \"legacy\" also available, reproduces exactly behaviour version 0.3.0 earlier. similar cor_adjust =   \"none\", unadjusted Spearman correlations used cor = NULL. adding integration points network object correlation matrix used stored $int_cor, copula correlation matrix adjustment used stored attributes $int_cor. correlation matrix passed add_integration() (e.g. reuse correlations external target population) detected, correct setting cor_adjust automatically applied.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/add_integration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add numerical integration points to aggregate data — add_integration","text":"","code":"## Plaque psoriasis ML-NMR - network setup and adding integration points # Set up plaque psoriasis network combining IPD and AgD library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected  # Add integration points to the network pso_net <- add_integration(pso_net,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies.   ## Adding integration points to a data frame, e.g. for prediction # Define a data frame of covariate summaries new_agd_int <- data.frame(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1)  # Adding integration points, using the weighted average correlation matrix # computed for the plaque psoriasis network new_agd_int <- add_integration(new_agd_int,   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),   prevsys = distr(qbern, prob = prevsys),   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),   weight = distr(qgamma, mean = weight_mean, sd = weight_sd),   psa = distr(qbern, prob = psa),   cor = pso_net$int_cor,   n_int = 64)  # Here, since we reused the correlation matrix pso_net$int_cor from the # network, the correct setting of cor_adjust = \"spearman\" is automatically # applied  new_agd_int #> # A tibble: 1 × 13 #>   bsa_mean bsa_sd prevsys   psa weight_mean weight_sd durnpso_mean durnpso_sd #>      <dbl>  <dbl>   <dbl> <dbl>       <dbl>     <dbl>        <dbl>      <dbl> #> 1      0.6    0.3     0.1   0.2          10         1            3          1 #> # ℹ 5 more variables: .int_durnpso <list>, .int_prevsys <list>, #> #   .int_bsa <list>, .int_weight <list>, .int_psa <list>"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"Samples (post warm-) stan_nma model object can coerced array, matrix, data frame.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"","code":"# S3 method for class 'stan_nma' as.array(x, ..., pars, include = TRUE)  # S3 method for class 'stan_nma' as.data.frame(x, ..., pars, include = TRUE)  # S3 method for class 'stan_nma' as_tibble(x, ..., pars, include = TRUE)  # S3 method for class 'stan_nma' as.tibble(x, ..., pars, include = TRUE)  # S3 method for class 'stan_nma' as.matrix(x, ..., pars, include = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":"x stan_nma object ... Additional arguments passed .array.stanfit() pars Optional character vector parameter names include output. specified, parameters used. include Logical, parameters pars included (TRUE, default) excluded (FALSE)?","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.array.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert samples into arrays, matrices, or data frames — as.array.stan_nma","text":".array() method produces 3D array [Iteration, Chain, Parameter] containing posterior samples parameter (class mcmc_array). side effect enabling bayesplot functions seamlessly work stan_nma objects. .data.frame() method produces data frame containing posterior samples parameter, combined chains. .matrix() method produces matrix containing posterior samples parameter, combined chains.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":null,"dir":"Reference","previous_headings":"","what":"as.stanfit — as.stanfit","title":"as.stanfit — as.stanfit","text":"Attempt turn object stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"as.stanfit — as.stanfit","text":"","code":"as.stanfit(x, ...)  # S3 method for class 'stan_nma' as.stanfit(x, ...)  # Default S3 method as.stanfit(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"as.stanfit — as.stanfit","text":"x object ... additional arguments","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/as.stanfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"as.stanfit — as.stanfit","text":"stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":null,"dir":"Reference","previous_headings":"","what":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"Data frame containing results 26 trials comparing 17 treatments 4 classes prevention stroke patients atrial fibrillation Cooper2009multinma. data corrected versions given gemtc;textualmultinma.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"","code":"atrial_fibrillation"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/atrial_fibrillation.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Stroke prevention in atrial fibrillation patients — atrial_fibrillation","text":"data frame 63 rows 11 variables: studyc study name studyn numeric study ID trtc treatment name trtn numeric treatment code trt_class treatment class r number events n sample size E person-years risk stroke proportion individuals prior stroke year year study publication followup mean length follow-(years)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":null,"dir":"Reference","previous_headings":"","what":"BCG vaccination — bcg_vaccine","title":"BCG vaccination — bcg_vaccine","text":"Data frame containing results 13 trials comparing BCG vaccination vaccination preventing tuberculosis (TB) TSD3,Berkey1995multinma. numbers individuals diagnosed TB arm study follow-period recorded. absolute degrees latitude study conducted also recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BCG vaccination — bcg_vaccine","text":"","code":"bcg_vaccine"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/bcg_vaccine.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"BCG vaccination — bcg_vaccine","text":"data frame 26 rows 6 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name latitude absolute degrees latitude r number diagnosed TB n sample size","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":null,"dir":"Reference","previous_headings":"","what":"Beta blockers to prevent mortality after MI — blocker","title":"Beta blockers to prevent mortality after MI — blocker","text":"Data frame containing number deaths 22 trials comparing beta blockers vs. control preventing mortality myocardial infarction Carlin1992,TSD2multinma.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Beta blockers to prevent mortality after MI — blocker","text":"","code":"blocker"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/blocker.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Beta blockers to prevent mortality after MI — blocker","text":"data frame 44 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine multiple data sources into one network — combine_network","title":"Combine multiple data sources into one network — combine_network","text":"Multiple data sources created using set_ipd(), set_agd_arm(), set_agd_contrast() can combined single network analysis.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine multiple data sources into one network — combine_network","text":"","code":"combine_network(..., trt_ref)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine multiple data sources into one network — combine_network","text":"... multiple data sources, defined using set_* functions trt_ref reference treatment entire network, string (coerced ) referring levels treatment factor variable","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine multiple data sources into one network — combine_network","text":"object class nma_data","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/combine_network.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine multiple data sources into one network — combine_network","text":"","code":"## Parkinson's - combining contrast- and arm-based data studies <- parkinsons$studyn (parkinsons_arm <- parkinsons[studies %in% 1:3, ]) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718 #> 7      3    4 -1.20 0.478  81 -0.90   0.695 (parkinsons_contr <- parkinsons[studies %in% 4:7, ]) #>    studyn trtn     y    se   n  diff se_diff #> 8       4    3 -0.24 0.265 128    NA   0.265 #> 9       4    4 -0.59 0.354  72 -0.35   0.442 #> 10      5    3 -0.73 0.335  80    NA   0.335 #> 11      5    4 -0.18 0.442  46  0.55   0.555 #> 12      6    4 -2.20 0.197 137    NA   0.197 #> 13      6    5 -2.50 0.190 131 -0.30   0.274 #> 14      7    4 -1.80 0.200 154    NA   0.200 #> 15      7    5 -2.10 0.250 143 -0.30   0.320  park_arm_net <- set_agd_arm(parkinsons_arm,                             study = studyn,                             trt = trtn,                             y = y,                             se = se,                             sample_size = n)  park_contr_net <- set_agd_contrast(parkinsons_contr,                                    study = studyn,                                    trt = trtn,                                    y = diff,                                    se = se_diff,                                    sample_size = n)  park_net <- combine_network(park_arm_net, park_contr_net)  # Print network details park_net #> A network with 3 AgD studies (arm-based), and 4 AgD studies (contrast-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  #>  Outcome type: continuous #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected  # Plot network plot(park_net, weight_edges = TRUE, weight_nodes = TRUE)   ## Plaque Psoriasis - combining IPD and AgD in a network # Set up plaque psoriasis network combining IPD and AgD library(dplyr) pso_ipd <- filter(plaque_psoriasis_ipd,                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\"))  pso_agd <- filter(plaque_psoriasis_agd,                   studyc == \"FIXTURE\")  head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3  pso_ipd <- pso_ipd %>%   mutate(# Variable transformations     bsa = bsa / 100,     prevsys = as.numeric(prevsys),     psa = as.numeric(psa),     weight = weight / 10,     durnpso = durnpso / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\"),     # Check complete cases for covariates of interest     complete = complete.cases(durnpso, prevsys, bsa, weight, psa)   )  pso_agd <- pso_agd %>%   mutate(     # Variable transformations     bsa_mean = bsa_mean / 100,     bsa_sd = bsa_sd / 100,     prevsys = prevsys / 100,     psa = psa / 100,     weight_mean = weight_mean / 10,     weight_sd = weight_sd / 10,     durnpso_mean = durnpso_mean / 10,     durnpso_sd = durnpso_sd / 10,     # Treatment classes     trtclass = case_when(trtn == 1 ~ \"Placebo\",                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\",                          trtn == 4 ~ \"TNFa blocker\")   )  # Exclude small number of individuals with missing covariates pso_ipd <- filter(pso_ipd, complete)  pso_net <- combine_network(   set_ipd(pso_ipd,           study = studyc,           trt = trtc,           r = pasi75,           trt_class = trtclass),   set_agd_arm(pso_agd,               study = studyc,               trt = trtc,               r = pasi75_r,               n = pasi75_n,               trt_class = trtclass) )  # Print network details pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected   # Plot network plot(pso_net, weight_nodes = TRUE, weight_edges = TRUE, show_trt_class = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Set default values — .default","title":"Set default values — .default","text":".default() function used internally mark certain values default, user may notified default values used. example, choosing default reference treatment network, using default prior distributions. function .is_default() checks whether argument/object set default value. Neither functions intended called user.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set default values — .default","text":"","code":".default(x = list())  .is_default(x)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set default values — .default","text":"x object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/default_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set default values — .default","text":".default(), identical object additional attribute .default. .is_default(), logical value (TRUE FALSE).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":null,"dir":"Reference","previous_headings":"","what":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"Data frame containing number new cases diabetes 22 trials 6 antihypertensive drugs Elliott2007,TSD2multinma. trial duration (years) also recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"","code":"diabetes"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/diabetes.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Incidence of diabetes in trials of antihypertensive drugs — diabetes","text":"data frame 48 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name r total number events n total number individuals time trial follow-(years)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Deviance Information Criterion (DIC) — dic","title":"Deviance Information Criterion (DIC) — dic","text":"Calculate DIC model fitted using nma() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deviance Information Criterion (DIC) — dic","text":"","code":"dic(x, penalty = c(\"pD\", \"pV\"), ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deviance Information Criterion (DIC) — dic","text":"x fitted model object, inheriting class stan_nma penalty method estimating effective number parameters, used penalise model fit DIC. Either \"pD\" (default), \"pV\". survival likelihoods \"pV\" currently available. ... arguments (used)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deviance Information Criterion (DIC) — dic","text":"nma_dic object.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deviance Information Criterion (DIC) — dic","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking FE NMA example if not already available if (!exists(\"smk_fit_FE\")) example(\"example_smk_fe\", run.donttest = TRUE) #>  #> exmp__> # Set up network of smoking cessation data #> exmp__> head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170 #>  #> exmp__> smk_net <- set_agd_arm(smoking, #> exmp__+                        study = studyn, #> exmp__+                        trt = trtc, #> exmp__+                        r = r, #> exmp__+                        n = n, #> exmp__+                        trt_ref = \"No intervention\") #>  #> exmp__> # Print details #> exmp__> smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected #>  #> exmp__> ## No test:  #> exmp__> # Fitting a fixed effect model #> exmp__> smk_fit_FE <- nma(smk_net, ## Don't show:  #> exmp__+ refresh = if (interactive()) 200 else 0, #> exmp__+ ## End(Don't show) #> exmp__+                   trt_effects = \"fixed\", #> exmp__+                   prior_intercept = normal(scale = 100), #> exmp__+                   prior_trt = normal(scale = 100)) #>  #> exmp__> smk_fit_FE #> A fixed effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          0.84    0.00 0.17     0.50     0.72     0.84 #> d[Individual counselling]     0.77    0.00 0.06     0.65     0.73     0.76 #> d[Self-help]                  0.23    0.00 0.13    -0.02     0.14     0.23 #> lp__                      -5859.37    0.09 3.75 -5867.83 -5861.63 -5859.06 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          0.95     1.17  2321    1 #> d[Individual counselling]     0.80     0.88  1744    1 #> d[Self-help]                  0.31     0.47  2622    1 #> lp__                      -5856.74 -5853.06  1894    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:24:01 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #>  #> exmp__> ## End(No test) #> exmp__>  #> exmp__> ## Don't show:  #> exmp__> if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) { #> exmp__+   assign(\"smk_net\", smk_net, .GlobalEnv) #> exmp__+   assign(\"smk_fit_FE\", smk_fit_FE, .GlobalEnv) #> exmp__+ } #>  #> exmp__> ## End(Don't show) #> exmp__>  #> exmp__>  #> exmp__>  # } # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) #>  #> exmp__> # Set up network of smoking cessation data #> exmp__> head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170 #>  #> exmp__> smk_net <- set_agd_arm(smoking, #> exmp__+                        study = studyn, #> exmp__+                        trt = trtc, #> exmp__+                        r = r, #> exmp__+                        n = n, #> exmp__+                        trt_ref = \"No intervention\") #>  #> exmp__> # Print details #> exmp__> smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected #>  #> exmp__> ## No test:  #> exmp__> # Fitting a random effects model #> exmp__> smk_fit_RE <- nma(smk_net, ## Don't show:  #> exmp__+ refresh = if (interactive()) 200 else 0, #> exmp__+ ## End(Don't show) #> exmp__+                   trt_effects = \"random\", #> exmp__+                   prior_intercept = normal(scale = 100), #> exmp__+                   prior_trt = normal(scale = 100), #> exmp__+                   prior_het = normal(scale = 5)) #>  #> exmp__> smk_fit_RE #> A random effects NMA with a binomial likelihood (logit link). #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                               mean se_mean   sd     2.5%      25%      50% #> d[Group counselling]          1.11    0.01 0.44     0.28     0.81     1.10 #> d[Individual counselling]     0.85    0.01 0.24     0.38     0.69     0.84 #> d[Self-help]                  0.48    0.01 0.40    -0.29     0.23     0.48 #> lp__                      -5767.81    0.19 6.30 -5781.15 -5771.84 -5767.54 #> tau                           0.84    0.00 0.18     0.55     0.71     0.82 #>                                75%    97.5% n_eff Rhat #> d[Group counselling]          1.39     1.99  2259    1 #> d[Individual counselling]     1.00     1.34  1413    1 #> d[Self-help]                  0.74     1.24  1985    1 #> lp__                      -5763.33 -5756.53  1114    1 #> tau                           0.94     1.26  1343    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:24:08 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #>  #> exmp__> ## End(No test) #> exmp__>  #> exmp__> ## Don't show:  #> exmp__> if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) { #> exmp__+   assign(\"smk_net\", smk_net, .GlobalEnv) #> exmp__+   assign(\"smk_fit_RE\", smk_fit_RE, .GlobalEnv) #> exmp__+ } #>  #> exmp__> ## End(Don't show) #> exmp__>  #> exmp__>  #> exmp__>  # } # \\donttest{ # Compare DIC of FE and RE models (smk_dic_FE <- dic(smk_fit_FE)) #> Residual deviance: 267.2 (on 50 data points) #>                pD: 27.1 #>               DIC: 294.2 (smk_dic_RE <- dic(smk_fit_RE))   # substantially better fit #> Residual deviance: 53.8 (on 50 data points) #>                pD: 43.7 #>               DIC: 97.5  # Plot residual deviance contributions under RE model plot(smk_dic_RE)   # Check for inconsistency using UME model # } # \\donttest{ # Run smoking UME NMA example if not already available if (!exists(\"smk_fit_RE_UME\")) example(\"example_smk_ume\", run.donttest = TRUE) #>  #> exmp__> # Set up network of smoking cessation data #> exmp__> head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170 #>  #> exmp__> smk_net <- set_agd_arm(smoking, #> exmp__+                        study = studyn, #> exmp__+                        trt = trtc, #> exmp__+                        r = r, #> exmp__+                        n = n, #> exmp__+                        trt_ref = \"No intervention\") #>  #> exmp__> # Print details #> exmp__> smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected #>  #> exmp__> ## No test:  #> exmp__> # Fitting an unrelated mean effects (inconsistency) model #> exmp__> smk_fit_RE_UME <- nma(smk_net, ## Don't show:  #> exmp__+ refresh = if (interactive()) 200 else 0, #> exmp__+ ## End(Don't show) #> exmp__+                       consistency = \"ume\", #> exmp__+                       trt_effects = \"random\", #> exmp__+                       prior_intercept = normal(scale = 100), #> exmp__+                       prior_trt = normal(scale = 100), #> exmp__+                       prior_het = normal(scale = 5)) #>  #> exmp__> smk_fit_RE_UME #> A random effects NMA with a binomial likelihood (logit link). #> An inconsistency model ('ume') was fitted. #> Inference for Stan model: binomial_1par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                                     mean se_mean   sd     2.5% #> d[Group counselling vs. No intervention]            1.12    0.02 0.80    -0.39 #> d[Individual counselling vs. No intervention]       0.91    0.01 0.27     0.39 #> d[Self-help vs. No intervention]                    0.33    0.01 0.61    -0.87 #> d[Individual counselling vs. Group counselling]    -0.31    0.01 0.60    -1.47 #> d[Self-help vs. Group counselling]                 -0.63    0.02 0.72    -2.06 #> d[Self-help vs. Individual counselling]             0.16    0.02 1.08    -2.00 #> lp__                                            -5765.22    0.22 6.48 -5779.03 #> tau                                                 0.94    0.01 0.24     0.57 #>                                                      25%      50%      75% #> d[Group counselling vs. No intervention]            0.59     1.07     1.61 #> d[Individual counselling vs. No intervention]       0.73     0.89     1.08 #> d[Self-help vs. No intervention]                   -0.05     0.33     0.70 #> d[Individual counselling vs. Group counselling]    -0.69    -0.31     0.07 #> d[Self-help vs. Group counselling]                 -1.09    -0.63    -0.18 #> d[Self-help vs. Individual counselling]            -0.52     0.17     0.85 #> lp__                                            -5769.23 -5764.85 -5760.70 #> tau                                                 0.78     0.90     1.06 #>                                                    97.5% n_eff Rhat #> d[Group counselling vs. No intervention]            2.79  2108    1 #> d[Individual counselling vs. No intervention]       1.47  1069    1 #> d[Self-help vs. No intervention]                    1.54  1858    1 #> d[Individual counselling vs. Group counselling]     0.88  2104    1 #> d[Self-help vs. Group counselling]                  0.83  2226    1 #> d[Self-help vs. Individual counselling]             2.28  2896    1 #> lp__                                            -5753.82   906    1 #> tau                                                 1.47   949    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:24:16 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #>  #> exmp__> ## End(No test) #> exmp__>  #> exmp__> ## Don't show:  #> exmp__> if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) { #> exmp__+   assign(\"smk_net\", smk_net, .GlobalEnv) #> exmp__+   assign(\"smk_fit_RE_UME\", smk_fit_RE_UME, .GlobalEnv) #> exmp__+ } #>  #> exmp__> ## End(Don't show) #> exmp__>  #> exmp__>  #> exmp__>  # } # \\donttest{ # Compare DIC smk_dic_RE #> Residual deviance: 53.8 (on 50 data points) #>                pD: 43.7 #>               DIC: 97.5 (smk_dic_RE_UME <- dic(smk_fit_RE_UME))  # no difference in fit #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44.8 #>               DIC: 98.4  # Compare residual deviance contributions plot(smk_dic_RE, smk_dic_RE_UME, show_uncertainty = FALSE)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduced dietary fat to prevent mortality — dietary_fat","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"Data frame containing number deaths person-years risk 10 trials comparing reduced fat diets vs. control (non-reduced fat diet) preventing mortality Hooper2000,TSD2multinma.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"","code":"dietary_fat"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/dietary_fat.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Reduced dietary fat to prevent mortality — dietary_fat","text":"data frame 21 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name r number events n number randomised E person-years risk","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":null,"dir":"Reference","previous_headings":"","what":"Specify a general marginal distribution — distr","title":"Specify a general marginal distribution — distr","text":"distr() used within function add_integration() specify marginal distributions covariates, via corresponding inverse CDF. also used predict.stan_nma() specify distribution baseline response (intercept) predicting absolute outcomes.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specify a general marginal distribution — distr","text":"","code":"distr(qfun, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specify a general marginal distribution — distr","text":"qfun inverse CDF, either function name string ... parameters distribution arguments qfun, quoted evaluated later context aggregate data sources","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specify a general marginal distribution — distr","text":"object class distr.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Specify a general marginal distribution — distr","text":"function qfun formal argument called p. restriction serves crude check inverse CDFs (e.g. error given dnorm used instead qnorm). user-written CDF supplied, must argument p takes vector probabilities.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/distr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Specify a general marginal distribution — distr","text":"","code":"## Specifying marginal distributions for integration  df <- data.frame(x1_mean = 2, x1_sd = 0.5, x2 = 0.8)  # Distribution parameters are evaluated in the context of the data frame add_integration(df,                 x1 = distr(qnorm, mean = x1_mean, sd = x1_sd),                 x2 = distr(qbern, prob = x2),                 cor = diag(2)) #> # A tibble: 1 × 5 #>   x1_mean x1_sd    x2 .int_x1    .int_x2    #>     <dbl> <dbl> <dbl> <list>     <list>     #> 1       2   0.5   0.8 <dbl [64]> <dbl [64]>"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalised Student's t distribution (with location and scale) — dgent","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"Density, distribution, quantile function generalised t distribution degrees freedom df, shifted location scaled scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"","code":"dgent(x, df, location = 0, scale = 1)  pgent(q, df, location = 0, scale = 1)  qgent(p, df, location = 0, scale = 1)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"x, q Vector quantiles df Degrees freedom, greater zero location Location parameter scale Scale parameter, greater zero p Vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/generalised_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalised Student's t distribution (with location and scale) — dgent","text":"dgent() gives density, pgent() gives distribution function, qgent() gives quantile function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":null,"dir":"Reference","previous_headings":"","what":"Kaplan-Meier curves of survival data — geom_km","title":"Kaplan-Meier curves of survival data — geom_km","text":"helper function constructs ggplot2 geom plot Kaplan-Meier curves network containing survival time--event outcomes. useful overlaying \"raw\" survival data estimated survival functions created plotted plot.surv_nma_summary(), can also used standalone plot Kaplan-Meier curves fitting model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kaplan-Meier curves of survival data — geom_km","text":"","code":"geom_km(   network,   ...,   transform = c(\"identity\", \"cloglog\", \"log\", \"cumhaz\"),   curve_args = list(),   cens_args = list() )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kaplan-Meier curves of survival data — geom_km","text":"network nma_data network object containing survival outcomes ... Additional arguments passed survival::survfit() transform Character string giving transformation apply KM curves plotting. default \"identity\" transformation; options \"cloglog\" \\(\\log(-\\log(S))\\), \"log\" \\(\\log(S)\\), \"cumhaz\" cumulative hazard \\(-\\log(S)\\). curve_args Optional list arguments customise curves plotted ggplot2::geom_step() cens_args Optional list arguments customise censoring marks plotted ggplot2::geom_point()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kaplan-Meier curves of survival data — geom_km","text":"ggplot2 geom list can added ggplot2 plot object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/geom_km.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kaplan-Meier curves of survival data — geom_km","text":"","code":"# Set up newly-diagnosed multiple myeloma network  head(ndmm_ipd) #>          study trt       studyf trtf      age iss_stage3 response_cr_vgpr male #> 1 McCarthy2012 Pbo McCarthy2012  Pbo 50.81625          0                1    0 #> 2 McCarthy2012 Pbo McCarthy2012  Pbo 62.18165          0                0    0 #> 3 McCarthy2012 Pbo McCarthy2012  Pbo 51.53762          1                1    1 #> 4 McCarthy2012 Pbo McCarthy2012  Pbo 46.74128          0                1    1 #> 5 McCarthy2012 Pbo McCarthy2012  Pbo 62.62561          0                1    1 #> 6 McCarthy2012 Pbo McCarthy2012  Pbo 49.24520          1                1    0 #>   eventtime status #> 1 31.106516      1 #> 2  3.299623      0 #> 3 57.400000      0 #> 4 57.400000      0 #> 5 57.400000      0 #> 6 30.714460      0 head(ndmm_agd) #>        study     studyf trt trtf eventtime status #> 1 Morgan2012 Morgan2012 Pbo  Pbo  18.72575      1 #> 2 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 3 Morgan2012 Morgan2012 Pbo  Pbo  34.35726      1 #> 4 Morgan2012 Morgan2012 Pbo  Pbo  10.77826      1 #> 5 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 6 Morgan2012 Morgan2012 Pbo  Pbo  14.52966      1  ndmm_net <- combine_network(   set_ipd(ndmm_ipd,           study, trt,           Surv = Surv(eventtime / 12, status)),   set_agd_surv(ndmm_agd,                study, trt,                Surv = Surv(eventtime / 12, status),                covariates = ndmm_agd_covs)) # Plot KM curves using ggplot2 library(ggplot2)  # We need to create an empty ggplot object to add the curves to ggplot() + geom_km(ndmm_net)   # Adding plotting options, facets, axis labels, and a plot theme ggplot() +   geom_km(ndmm_net,           curve_args = list(linewidth = 0.5),           cens_args = list(size = 3, shape = 124)) +   facet_wrap(vars(Study)) +   labs(xlab = \"Time\", ylab = \"Survival Probability\") +   theme_multinma()   # Using the transform argument to produce log-log plots (e.g. to assess the # proportional hazards assumption) ggplot() +   geom_km(ndmm_net, transform = \"cloglog\") +   facet_wrap(vars(Study)) +   theme_multinma()   # Using the transform argument to produce cumulative hazard plots ggplot() +   geom_km(ndmm_net, transform = \"cumhaz\") +   facet_wrap(vars(Study)) +   theme_multinma()   # This function can also be used to add KM data to plots of estimated survival # curves from a fitted model, in a similar manner # \\donttest{ # Run newly-diagnosed multiple myeloma example if not already available if (!exists(\"ndmm_fit\")) example(\"example_ndmm\", run.donttest = TRUE) #>  #> exmpl_> # Set up newly-diagnosed multiple myeloma network #> exmpl_>  #> exmpl_> head(ndmm_ipd) #>          study trt       studyf trtf      age iss_stage3 response_cr_vgpr male #> 1 McCarthy2012 Pbo McCarthy2012  Pbo 50.81625          0                1    0 #> 2 McCarthy2012 Pbo McCarthy2012  Pbo 62.18165          0                0    0 #> 3 McCarthy2012 Pbo McCarthy2012  Pbo 51.53762          1                1    1 #> 4 McCarthy2012 Pbo McCarthy2012  Pbo 46.74128          0                1    1 #> 5 McCarthy2012 Pbo McCarthy2012  Pbo 62.62561          0                1    1 #> 6 McCarthy2012 Pbo McCarthy2012  Pbo 49.24520          1                1    0 #>   eventtime status #> 1 31.106516      1 #> 2  3.299623      0 #> 3 57.400000      0 #> 4 57.400000      0 #> 5 57.400000      0 #> 6 30.714460      0 #>  #> exmpl_> head(ndmm_agd) #>        study     studyf trt trtf eventtime status #> 1 Morgan2012 Morgan2012 Pbo  Pbo  18.72575      1 #> 2 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 3 Morgan2012 Morgan2012 Pbo  Pbo  34.35726      1 #> 4 Morgan2012 Morgan2012 Pbo  Pbo  10.77826      1 #> 5 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 6 Morgan2012 Morgan2012 Pbo  Pbo  14.52966      1 #>  #> exmpl_> ndmm_net <- combine_network( #> exmpl_+   set_ipd(ndmm_ipd, #> exmpl_+           study, trt, #> exmpl_+           Surv = Surv(eventtime / 12, status)), #> exmpl_+   set_agd_surv(ndmm_agd, #> exmpl_+                study, trt, #> exmpl_+                Surv = Surv(eventtime / 12, status), #> exmpl_+                covariates = ndmm_agd_covs)) #>  #> exmpl_> ## No test:  #> exmpl_> # Fit Weibull (PH) model #> exmpl_> ndmm_fit <- nma(ndmm_net, ## Don't show:  #> exmpl_+ refresh = if (interactive()) 200 else 0, #> exmpl_+ ## End(Don't show) #> exmpl_+                 likelihood = \"weibull\", #> exmpl_+                 prior_intercept = normal(scale = 100), #> exmpl_+                 prior_trt = normal(scale = 10), #> exmpl_+                 prior_aux = half_normal(scale = 10)) #> Note: Setting \"Pbo\" as the network reference treatment. #>  #> exmpl_> ndmm_fit #> A fixed effects NMA with a weibull likelihood (log link). #> Inference for Stan model: survival_param. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                         mean se_mean   sd     2.5%      25%      50%      75% #> d[Len]                 -0.54    0.00 0.05    -0.63    -0.57    -0.54    -0.51 #> d[Thal]                -0.11    0.00 0.09    -0.29    -0.17    -0.11    -0.05 #> lp__                -6229.99    0.06 2.49 -6235.81 -6231.42 -6229.61 -6228.18 #> shape[Attal2012]        1.30    0.00 0.06     1.18     1.25     1.30     1.34 #> shape[Jackson2019]      0.93    0.00 0.02     0.89     0.92     0.93     0.95 #> shape[McCarthy2012]     1.30    0.00 0.07     1.17     1.25     1.29     1.34 #> shape[Morgan2012]       0.88    0.00 0.03     0.82     0.86     0.88     0.90 #> shape[Palumbo2014]      1.02    0.00 0.07     0.88     0.97     1.02     1.06 #>                        97.5% n_eff Rhat #> d[Len]                 -0.45  5031    1 #> d[Thal]                 0.06  4915    1 #> lp__                -6226.16  1548    1 #> shape[Attal2012]        1.42  4275    1 #> shape[Jackson2019]      0.98  4679    1 #> shape[McCarthy2012]     1.43  4275    1 #> shape[Morgan2012]       0.94  5574    1 #> shape[Palumbo2014]      1.16  4304    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:25:17 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #>  #> exmpl_> ## End(No test) #> exmpl_> ## Don't show:  #> exmpl_> if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) { #> exmpl_+   assign(\"ndmm_net\", ndmm_net, .GlobalEnv) #> exmpl_+   assign(\"ndmm_fit\", ndmm_fit, .GlobalEnv) #> exmpl_+ } #>  #> exmpl_> ## End(Don't show) #> exmpl_>  #> exmpl_>  #> exmpl_>  # } # Plot estimated survival curves, and overlay the KM data # \\donttest{ plot(predict(ndmm_fit, type = \"survival\")) + geom_km(ndmm_net)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":null,"dir":"Reference","previous_headings":"","what":"Direct and indirect evidence — get_nodesplits","title":"Direct and indirect evidence — get_nodesplits","text":"Determine whether two treatments network connected direct /indirect evidence, generate list comparisons direct indirect evidence (.e. potential inconsistency) node-splitting.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Direct and indirect evidence — get_nodesplits","text":"","code":"get_nodesplits(network, include_consistency = FALSE)  has_direct(network, trt1, trt2)  has_indirect(network, trt1, trt2)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Direct and indirect evidence — get_nodesplits","text":"network nma_data object, created functions set_*() combine_network(). include_consistency Logical, whether include row NAs indicate consistency model (.e. model node-splitting) also fitted nma() function. Default FALSE calling get_nodesplits() hand, nma() sets TRUE default. trt1, trt2 Treatments, single integer, string, factor","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Direct and indirect evidence — get_nodesplits","text":"has_direct() has_indirect(), single logical value. get_nodesplits(), data frame two columns giving comparisons node-splitting.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Direct and indirect evidence — get_nodesplits","text":"list comparisons node-splitting generated following algorithm Valkenhoef2016;textualmultinma. comparison two treatments potential inconsistency, thus considered node-splitting, comparison direct evidence independent indirect evidence. notion independent indirect evidence necessary multi-arm trials present, since design trials internally consistent. comparison two treatments independent indirect evidence , removing studies comparing two treatments network, two treatments still connected path evidence. criterion considered has_indirect() function.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/get_nodesplits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Direct and indirect evidence — get_nodesplits","text":"","code":"# Parkinsons example park_net <- set_agd_arm(parkinsons,                         study = studyn,                         trt = trtn,                         y = y,                         se = se,                         trt_ref = 1) #> Note: Optional argument `sample_size` not provided, some features may not be available (see ?set_agd_arm).  # View the network plot plot(park_net)   # The 4 vs. 5 comparison is a spur on the network has_direct(park_net, 4, 5) #> [1] TRUE has_indirect(park_net, 4, 5) #> [1] FALSE  # 1 and 5 are not directly connected has_direct(park_net, 1, 5) #> [1] FALSE has_indirect(park_net, 1, 5) #> [1] TRUE  # The 1 vs. 2 comparison does not have independent indirect evidence, since # the 1-2-4 loop is a multi-arm study has_indirect(park_net, 1, 2) #> [1] FALSE  # Get a list of comparisons with potential inconsistency for node-splitting get_nodesplits(park_net) #> # A tibble: 4 × 2 #>   trt1  trt2  #>   <fct> <fct> #> 1 1     3     #> 2 1     4     #> 3 2     4     #> 4 3     4      # See van Valkenhoef (2016) for a discussion of this example"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert networks to graph objects — as.igraph.nma_data","title":"Convert networks to graph objects — as.igraph.nma_data","text":"method .igraph() converts nma_data objects form used igraph package. method as_tbl_graph() converts nma_data objects form used ggraph tidygraph packages.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert networks to graph objects — as.igraph.nma_data","text":"","code":"# S3 method for class 'nma_data' as.igraph(x, ..., collapse = TRUE)  # S3 method for class 'nma_data' as_tbl_graph(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert networks to graph objects — as.igraph.nma_data","text":"x nma_data object convert ... Additional arguments collapse Logical, collapse edges studies? Default TRUE, one edge produced comparison (IPD AgD study type) .nstudy attribute giving number studies making comparison. FALSE, repeated edges added study making comparison.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert networks to graph objects — as.igraph.nma_data","text":"igraph object .igraph(), tbl_graph object as_tbl_graph().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/graph_conversion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert networks to graph objects — as.igraph.nma_data","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  # Convert to igraph object igraph::as.igraph(smk_net)  # Edges combined by default #> IGRAPH 2db2611 UN-- 4 6 --  #> + attr: name (v/c), .sample_size (v/n), .nstudy (e/n), .type (e/c) #> + edges from 2db2611 (vertex names): #> [1] No intervention       --Group counselling      #> [2] No intervention       --Individual counselling #> [3] Group counselling     --Individual counselling #> [4] No intervention       --Self-help              #> [5] Group counselling     --Self-help              #> [6] Individual counselling--Self-help              igraph::as.igraph(smk_net, collapse = FALSE)  # Without combining edges #> IGRAPH d703462 UN-- 4 28 --  #> + attr: name (v/c), .sample_size (v/n), .study (e/c), .type (e/c) #> + edges from d703462 (vertex names): #>  [1] No intervention       --Group counselling      #>  [2] No intervention       --Individual counselling #>  [3] Group counselling     --Individual counselling #>  [4] Group counselling     --Individual counselling #>  [5] Group counselling     --Self-help              #>  [6] Individual counselling--Self-help              #>  [7] No intervention       --Individual counselling #>  [8] No intervention       --Individual counselling #> + ... omitted several edges  # Convert to tbl_graph object tidygraph::as_tbl_graph(smk_net)  # Edges combined by default #> # A tbl_graph: 4 nodes and 6 edges #> # #> # An undirected simple graph with 1 component #> # #> # Node Data: 4 × 2 (active) #>   name                   .sample_size #>   <chr>                         <dbl> #> 1 No intervention                7231 #> 2 Group counselling               555 #> 3 Individual counselling         7383 #> 4 Self-help                      1571 #> # #> # Edge Data: 6 × 4 #>    from    to .nstudy .type #>   <int> <int>   <int> <chr> #> 1     1     2       2 AgD   #> 2     1     3      15 AgD   #> 3     2     3       4 AgD   #> # ℹ 3 more rows tidygraph::as_tbl_graph(smk_net, collapse = FALSE)  # Without combining edges #> # A tbl_graph: 4 nodes and 28 edges #> # #> # An undirected multigraph with 1 component #> # #> # Node Data: 4 × 2 (active) #>   name                   .sample_size #>   <chr>                         <dbl> #> 1 No intervention                7231 #> 2 Group counselling               555 #> 3 Individual counselling         7383 #> 4 Self-help                      1571 #> # #> # Edge Data: 28 × 4 #>    from    to .study .type #>   <int> <int> <chr>  <chr> #> 1     1     2 1      AgD   #> 2     1     3 1      AgD   #> 3     2     3 1      AgD   #> # ℹ 25 more rows"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":null,"dir":"Reference","previous_headings":"","what":"HTA Plaque Psoriasis — hta_psoriasis","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"Data frame containing results 16 trials comparing 8 treatments moderate--severe plaque psoriasis HTA report Woolacott2006multinma, analysed TSD2 TSD2multinma. Outcomes success/failure achieve 50%, 75%, 90% reduction symptoms Psoriasis Area Severity Index (PASI) scale. studies report three ordered outcomes, others one two. latter coded missing values (see details).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"","code":"hta_psoriasis"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"data frame 36 rows 9 variables: studyn numeric study ID studyc study name year year publication trtn numeric treatment code trtc treatment name sample_size sample size arm PASI50, PASI75, PASI90 ordered multinomial outcome counts (exclusive, see details)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/hta_psoriasis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"HTA Plaque Psoriasis — hta_psoriasis","text":"Outcome counts \"exclusive\"; , study reporting outcomes, counts represent categories 50 < PASI < 75, 75 < PASI < 90, 90 < PASI < 100, named lower end interval. (opposed \"inclusive\" counts, represent overlapping categories PASI > 50, PASI > 70, PASI > 90.) count fourth category (lowest), 0 < PASI < 50, equal sample_size - PASI50 - PASI75 - PASI90. Missing values used studies report subset outcomes. study reporting two outcomes, say 50 75, counts represent 50 < PASI < 75 75 < PASI < 100. study reporting one outcome, say PASI 75, count represents 75 < PASI < 100.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":null,"dir":"Reference","previous_headings":"","what":"Check network connectedness — is_network_connected","title":"Check network connectedness — is_network_connected","text":"Check whether network connected - whether path study evidence linking every pair treatments network.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check network connectedness — is_network_connected","text":"","code":"is_network_connected(network)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check network connectedness — is_network_connected","text":"network nma_data object, created functions set_*() combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check network connectedness — is_network_connected","text":"Logical TRUE FALSE","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check network connectedness — is_network_connected","text":"Models still run disconnected networks. However, estimated relative effects treatments across disconnected parts network entirely based prior distribution (typically uncertain), information update prior distribution. Relative effects within connected sub-network estimated sub-network analysed separately.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/is_network_connected.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check network connectedness — is_network_connected","text":"","code":"## Smoking cessation # Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected  is_network_connected(smk_net)  # TRUE, network is connected #> [1] TRUE ## A disconnected network disc_net <- set_agd_arm(smoking[smoking$studyn %in% c(15, 21), ],                         study = studyn,                         trt = trtc,                         r = r,                         n = n) is_network_connected(disc_net)  # FALSE, network is disconnected #> [1] FALSE disc_net #> A network with 2 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                         #>  15    2: Group counselling | No intervention #>  21    2: Individual counselling | Self-help  #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 2 #> Reference treatment is: Group counselling #> Network is disconnected plot(disc_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Student's t distribution — dlogt","title":"Log Student's t distribution — dlogt","text":"Density, distribution, quantile function log t distribution, whose logarithm degrees freedom df, mean location, standard deviation scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Student's t distribution — dlogt","text":"","code":"dlogt(x, df, location = 0, scale = 1)  plogt(q, df, location = 0, scale = 1)  qlogt(p, df, location = 0, scale = 1)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Student's t distribution — dlogt","text":"x, q Vector quantiles df Degrees freedom, greater zero location Location parameter scale Scale parameter, greater zero p Vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Student's t distribution — dlogt","text":"dlogt() gives density, plogt() gives distribution function, qlogt() gives quantile function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/log_t.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log Student's t distribution — dlogt","text":"\\(\\log(Y) \\sim t_\\nu(\\mu, \\sigma^2)\\), \\(Y\\) log t distribution location \\(\\mu\\), scale \\(\\sigma\\), df \\(\\nu\\). mean higher moments log t distribution undefined infinite. df = 1 distribution log Cauchy distribution. df tends infinity, approaches log Normal distribution.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":null,"dir":"Reference","previous_headings":"","what":"The logit Normal distribution — qlogitnorm","title":"The logit Normal distribution — qlogitnorm","text":"provide convenient extensions [dpq]logitnorm functions package logitnorm, allow distribution specified terms mean standard deviation, instead logit-mean logit-sd.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The logit Normal distribution — qlogitnorm","text":"","code":"qlogitnorm(p, mu = 0, sigma = 1, ..., mean, sd)  dlogitnorm(x, mu = 0, sigma = 1, ..., mean, sd)  plogitnorm(q, mu = 0, sigma = 1, ..., mean, sd)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The logit Normal distribution — qlogitnorm","text":"p, x vector quantiles mu, sigma, ... see logitnorm mean, sd mean standard deviation, overriding mu sigma specified q vector probabilities","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/logitNormal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The logit Normal distribution — qlogitnorm","text":"Numeric vector length equal maximum lengths input arguments.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":null,"dir":"Reference","previous_headings":"","what":"Model comparison using the loo package — loo.stan_nma","title":"Model comparison using the loo package — loo.stan_nma","text":"loo() waic() functions loo package may called directly stan_nma stan_mlnmr objects.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model comparison using the loo package — loo.stan_nma","text":"","code":"# S3 method for class 'stan_nma' loo(x, ...)  # S3 method for class 'stan_nma' waic(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/loo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model comparison using the loo package — loo.stan_nma","text":"x object class stan_nma stan_mlnmr ... arguments loo() waic()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/make_knots.html","id":null,"dir":"Reference","previous_headings":"","what":"Knot locations for M-spline baseline hazard models — make_knots","title":"Knot locations for M-spline baseline hazard models — make_knots","text":"Several different algorithms provided calculate knot locations M-spline baseline hazard models. function called internally within nma() function, may called directly user control.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/make_knots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Knot locations for M-spline baseline hazard models — make_knots","text":"","code":"make_knots(   network,   n_knots = 7,   type = c(\"quantile\", \"quantile_common\", \"quantile_lumped\", \"quantile_longest\", \"equal\",     \"equal_common\") )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/make_knots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Knot locations for M-spline baseline hazard models — make_knots","text":"network network object, containing survival outcomes n_knots Non-negative integer giving number internal knots (default 7) type String specifying knot location algorithm use (see details). default used nma() \"quantile\", except regression model specified (using aux_regression) case default \"quantile_common\".","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/make_knots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Knot locations for M-spline baseline hazard models — make_knots","text":"named list vectors giving knot locations study.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/make_knots.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Knot locations for M-spline baseline hazard models — make_knots","text":"type argument can used choose different algorithms placing knots: \"quantile\" Creates separate knot locations study, internal knots placed evenly-spaced quantiles observed event times within study. \"quantile_lumped\" Creates common set knots studies, calculated evenly-spaced quantiles observed event times studies lumped together. \"quantile_common\" Creates common set knots studies, taking quantiles quantiles observed event times within study. often seems result even knot spacing \"quantile_lumped\", particularly follow-uneven across studies, may handle differing behaviour baseline hazard across studies better \"quantile_longest\". \"quantile_longest\" Creates common set knots studies, using evenly-spaced quantiles observed event times longest study. \"equal\" Creates separate knot locations study, evenly-spaced times boundary knots study. \"equal_common\" Creates common set knots studies, evenly-spaced times earliest entry time last event/censoring time network. Boundary knots calculated follows: separate knot locations study, boundary knots placed earliest entry time last event/censoring time study. common set knots across studies, boundary knots placed earliest entry time last event/censoring time across studies. Models regression spline coefficients (.e. aux_regression specified) require common set knots across studies. Provided sufficient number knots used, model fit largely unaffected knot locations. However, sampling difficulties can sometimes occur knot placement poor, example knot placed just last follow-time study.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/make_knots.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Knot locations for M-spline baseline hazard models — make_knots","text":"","code":"# Set up newly-diagnosed multiple myeloma network  head(ndmm_ipd) #>          study trt       studyf trtf      age iss_stage3 response_cr_vgpr male #> 1 McCarthy2012 Pbo McCarthy2012  Pbo 50.81625          0                1    0 #> 2 McCarthy2012 Pbo McCarthy2012  Pbo 62.18165          0                0    0 #> 3 McCarthy2012 Pbo McCarthy2012  Pbo 51.53762          1                1    1 #> 4 McCarthy2012 Pbo McCarthy2012  Pbo 46.74128          0                1    1 #> 5 McCarthy2012 Pbo McCarthy2012  Pbo 62.62561          0                1    1 #> 6 McCarthy2012 Pbo McCarthy2012  Pbo 49.24520          1                1    0 #>   eventtime status #> 1 31.106516      1 #> 2  3.299623      0 #> 3 57.400000      0 #> 4 57.400000      0 #> 5 57.400000      0 #> 6 30.714460      0 head(ndmm_agd) #>        study     studyf trt trtf eventtime status #> 1 Morgan2012 Morgan2012 Pbo  Pbo  18.72575      1 #> 2 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 3 Morgan2012 Morgan2012 Pbo  Pbo  34.35726      1 #> 4 Morgan2012 Morgan2012 Pbo  Pbo  10.77826      1 #> 5 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 6 Morgan2012 Morgan2012 Pbo  Pbo  14.52966      1  ndmm_net <- combine_network(   set_ipd(ndmm_ipd,           study, trt,           Surv = Surv(eventtime / 12, status)),   set_agd_surv(ndmm_agd,                study, trt,                Surv = Surv(eventtime / 12, status),                covariates = ndmm_agd_covs))  # The default knot locations make_knots(ndmm_net, type = \"quantile\") #> $Attal2012 #>               12.5%       25%     37.5%       50%     62.5%       75%     87.5%  #> 0.0000000 0.5934115 0.9482775 1.3534460 1.7149769 2.1791543 2.6156006 3.3067856  #>            #> 4.0144924  #>  #> $Jackson2019 #>               12.5%       25%     37.5%       50%     62.5%       75%     87.5%  #> 0.0000000 0.3764953 0.7013167 1.1208075 1.6061797 2.1894017 3.0797028 4.3685050  #>            #> 6.3743523  #>  #> $McCarthy2012 #>             12.5%      25%    37.5%      50%    62.5%      75%    87.5%  #> 0.000000 0.706951 1.051770 1.519605 2.067261 2.791005 3.383530 4.231690  #>           #> 5.833333  #>  #> $Morgan2012 #>               12.5%       25%     37.5%       50%     62.5%       75%     87.5%  #> 0.0000000 0.2730038 0.5063235 0.7761775 1.0551856 1.5629825 2.2663204 3.2201496  #>            #> 5.4000000  #>  #> $Palumbo2014 #>               12.5%       25%     37.5%       50%     62.5%       75%     87.5%  #> 0.0000000 0.3154367 0.5906098 0.9345159 1.1814523 1.7505439 2.1409332 3.1120086  #>            #> 4.5438931  #>   # Increasing the number of knots make_knots(ndmm_net, n_knots = 10) #> $Attal2012 #>           9.090909% 18.18182% 27.27273% 36.36364% 45.45455% 54.54545% 63.63636%  #> 0.0000000 0.4855970 0.7296991 1.0274442 1.3229218 1.5913659 1.9091936 2.2146202  #> 72.72727% 81.81818% 90.90909%            #> 2.4965883 2.9410168 3.5442040 4.0144924  #>  #> $Jackson2019 #>           9.090909% 18.18182% 27.27273% 36.36364% 45.45455% 54.54545% 63.63636%  #> 0.0000000 0.2850731 0.5160902 0.7852926 1.0889435 1.3955587 1.7796685 2.2724055  #> 72.72727% 81.81818% 90.90909%            #> 2.9445333 3.7260169 4.8115468 6.3743523  #>  #> $McCarthy2012 #>           9.090909% 18.18182% 27.27273% 36.36364% 45.45455% 54.54545% 63.63636%  #> 0.0000000 0.6217270 0.8054827 1.0820339 1.4854471 1.9165108 2.3385167 2.8373237  #> 72.72727% 81.81818% 90.90909%            #> 3.2475317 3.7700213 4.6931830 5.8333333  #>  #> $Morgan2012 #>           9.090909% 18.18182% 27.27273% 36.36364% 45.45455% 54.54545% 63.63636%  #> 0.0000000 0.2299352 0.3643555 0.5569621 0.7645674 0.9472899 1.1902067 1.6232784  #> 72.72727% 81.81818% 90.90909%            #> 2.0964056 2.7050749 3.8072636 5.4000000  #>  #> $Palumbo2014 #>           9.090909% 18.18182% 27.27273% 36.36364% 45.45455% 54.54545% 63.63636%  #> 0.0000000 0.2956157 0.4023159 0.6263514 0.9276731 1.0267498 1.2797050 1.7917861  #> 72.72727% 81.81818% 90.90909%            #> 2.0366305 2.5784913 3.4007800 4.5438931  #>   # Comparing alternative knot positioning algorithms # Visualise these with a quick function plot_knots <- function(network, knots) {   ggplot2::ggplot() +     geom_km(network) +     ggplot2::geom_vline(ggplot2::aes(xintercept = .data$knot),                         data = tidyr::pivot_longer(as.data.frame(knots), cols = dplyr::everything(),                                                    names_to = \"Study\", values_to = \"knot\"),                         linetype = 2, colour = \"grey60\") +     ggplot2::facet_wrap(~Study) +     theme_multinma() }  plot_knots(ndmm_net, make_knots(ndmm_net, type = \"quantile\"))  plot_knots(ndmm_net, make_knots(ndmm_net, type = \"quantile_common\"))  plot_knots(ndmm_net, make_knots(ndmm_net, type = \"quantile_lumped\"))  plot_knots(ndmm_net, make_knots(ndmm_net, type = \"quantile_longest\"))  plot_knots(ndmm_net, make_knots(ndmm_net, type = \"equal\"))  plot_knots(ndmm_net, make_knots(ndmm_net, type = \"equal_common\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/marginal_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Marginal treatment effects — marginal_effects","title":"Marginal treatment effects — marginal_effects","text":"Generate population-average marginal treatment effects. formed population-average absolute predictions, function wrapper around predict.stan_nma().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/marginal_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal treatment effects — marginal_effects","text":"","code":"marginal_effects(   object,   ...,   mtype = c(\"difference\", \"ratio\", \"link\"),   all_contrasts = FALSE,   trt_ref = NULL,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/marginal_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal treatment effects — marginal_effects","text":"object stan_nma object created nma(). ... Arguments passed predict.stan_nma(), example specify covariate distribution baseline risk target population, e.g. newdata, baseline, related arguments. survival outcomes, type can also specified determine quantity form marginal effect. example, type = \"hazard\" mtype = \"ratio\" produces marginal hazard ratios, type = \"median\" mtype = \"difference\" produces marginal median survival time differences, . mtype type marginal effect construct average absolute effects, either \"difference\" (default) difference absolute effects risk difference, \"ratio\" ratio absolute effects risk ratio, \"link\" difference scale link function used fitting model marginal log odds ratio. all_contrasts Logical, generate estimates contrasts (TRUE), just \"basic\" contrasts network reference treatment (FALSE)? Default FALSE. trt_ref Reference treatment construct relative effects , all_contrasts = FALSE. default, relative effects network reference treatment. Coerced character string. probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) predictive_distribution Logical, random effects model fitted, predictive distribution marginal effects new study returned? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/marginal_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Marginal treatment effects — marginal_effects","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/marginal_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marginal treatment effects — marginal_effects","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Marginal risk difference in each study population in the network marginal_effects(smk_fit_RE, mtype = \"difference\") #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[1: Group counselling]      0.11 0.06  0.02 0.06 0.10 0.14  0.27     2538 #> marg[1: Individual counselling] 0.07 0.03  0.02 0.05 0.07 0.09  0.15     1820 #> marg[1: Self-help]              0.04 0.04 -0.02 0.01 0.03 0.06  0.13     2042 #>                                 Tail_ESS Rhat #> marg[1: Group counselling]          2603    1 #> marg[1: Individual counselling]     2438    1 #> marg[1: Self-help]                  2359    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[2: Group counselling]      0.12 0.08  0.02 0.07 0.11 0.17  0.33     3197 #> marg[2: Individual counselling] 0.09 0.05  0.02 0.05 0.08 0.11  0.21     2631 #> marg[2: Self-help]              0.04 0.05 -0.02 0.01 0.03 0.07  0.16     2385 #>                                 Tail_ESS Rhat #> marg[2: Group counselling]          3182    1 #> marg[2: Individual counselling]     2915    1 #> marg[2: Self-help]                  2405    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[3: Group counselling]      0.16 0.09  0.03 0.10 0.16 0.21  0.36     2319 #> marg[3: Individual counselling] 0.11 0.04  0.04 0.08 0.11 0.14  0.20     1497 #> marg[3: Self-help]              0.06 0.05 -0.02 0.02 0.05 0.09  0.19     2005 #>                                 Tail_ESS Rhat #> marg[3: Group counselling]          2809    1 #> marg[3: Individual counselling]     2184    1 #> marg[3: Self-help]                  2418    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[4: Group counselling]      0.04 0.03 0.00 0.02 0.03 0.05  0.13     2972 #> marg[4: Individual counselling] 0.03 0.02 0.01 0.01 0.02 0.03  0.07     2910 #> marg[4: Self-help]              0.01 0.02 0.00 0.00 0.01 0.02  0.06     2314 #>                                 Tail_ESS Rhat #> marg[4: Group counselling]          3066    1 #> marg[4: Individual counselling]     2858    1 #> marg[4: Self-help]                  2389    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[5: Group counselling]      0.16 0.09  0.03 0.10 0.15 0.21  0.36     2294 #> marg[5: Individual counselling] 0.11 0.04  0.04 0.08 0.11 0.14  0.21     1483 #> marg[5: Self-help]              0.06 0.05 -0.02 0.02 0.05 0.09  0.19     2045 #>                                 Tail_ESS Rhat #> marg[5: Group counselling]          2734    1 #> marg[5: Individual counselling]     2181    1 #> marg[5: Self-help]                  2433    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[6: Group counselling]      0.07 0.06  0.01 0.03 0.06 0.09  0.22     3213 #> marg[6: Individual counselling] 0.04 0.03  0.01 0.02 0.04 0.06  0.12     2958 #> marg[6: Self-help]              0.02 0.03 -0.01 0.01 0.02 0.03  0.10     2297 #>                                 Tail_ESS Rhat #> marg[6: Group counselling]          2763    1 #> marg[6: Individual counselling]     2588    1 #> marg[6: Self-help]                  2566    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[7: Group counselling]      0.09 0.06  0.01 0.05 0.08 0.12  0.24     2794 #> marg[7: Individual counselling] 0.06 0.03  0.02 0.04 0.06 0.07  0.13     1815 #> marg[7: Self-help]              0.03 0.03 -0.01 0.01 0.03 0.05  0.11     2133 #>                                 Tail_ESS Rhat #> marg[7: Group counselling]          2904    1 #> marg[7: Individual counselling]     2686    1 #> marg[7: Self-help]                  2419    1 #>  #> ---------------------------------------------------------------------- Study: 8 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[8: Group counselling]      0.12 0.08  0.01 0.06 0.10 0.16  0.31     2988 #> marg[8: Individual counselling] 0.08 0.04  0.02 0.05 0.07 0.10  0.17     2505 #> marg[8: Self-help]              0.04 0.04 -0.02 0.01 0.03 0.06  0.15     2323 #>                                 Tail_ESS Rhat #> marg[8: Group counselling]          2840    1 #> marg[8: Individual counselling]     2606    1 #> marg[8: Self-help]                  2331    1 #>  #> ---------------------------------------------------------------------- Study: 9 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[9: Group counselling]      0.19 0.10  0.03 0.12 0.18 0.25  0.41     2520 #> marg[9: Individual counselling] 0.14 0.05  0.05 0.10 0.13 0.17  0.26     1856 #> marg[9: Self-help]              0.07 0.07 -0.03 0.03 0.06 0.11  0.23     2100 #>                                 Tail_ESS Rhat #> marg[9: Group counselling]          2790    1 #> marg[9: Individual counselling]     2303    1 #> marg[9: Self-help]                  2388    1 #>  #> --------------------------------------------------------------------- Study: 10 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[10: Group counselling]      0.17 0.09  0.03 0.11 0.16 0.22  0.37     2311 #> marg[10: Individual counselling] 0.12 0.04  0.04 0.09 0.11 0.14  0.22     1514 #> marg[10: Self-help]              0.06 0.06 -0.03 0.02 0.06 0.10  0.19     2002 #>                                  Tail_ESS Rhat #> marg[10: Group counselling]          2820    1 #> marg[10: Individual counselling]     2076    1 #> marg[10: Self-help]                  2403    1 #>  #> --------------------------------------------------------------------- Study: 11 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[11: Group counselling]      0.06 0.04  0.01 0.03 0.05 0.07  0.15     2470 #> marg[11: Individual counselling] 0.03 0.02  0.01 0.02 0.03 0.04  0.07     1785 #> marg[11: Self-help]              0.02 0.02 -0.01 0.01 0.02 0.03  0.06     2041 #>                                  Tail_ESS Rhat #> marg[11: Group counselling]          2794    1 #> marg[11: Individual counselling]     2364    1 #> marg[11: Self-help]                  2330    1 #>  #> --------------------------------------------------------------------- Study: 12 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[12: Group counselling]      0.16 0.08  0.03 0.10 0.15 0.21  0.35     2295 #> marg[12: Individual counselling] 0.11 0.04  0.04 0.08 0.10 0.13  0.20     1516 #> marg[12: Self-help]              0.06 0.05 -0.02 0.02 0.05 0.09  0.18     2027 #>                                  Tail_ESS Rhat #> marg[12: Group counselling]          2672    1 #> marg[12: Individual counselling]     2230    1 #> marg[12: Self-help]                  2381    1 #>  #> --------------------------------------------------------------------- Study: 13 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[13: Group counselling]      0.12 0.08  0.02 0.06 0.10 0.16  0.31     2686 #> marg[13: Individual counselling] 0.08 0.04  0.02 0.05 0.07 0.10  0.17     2207 #> marg[13: Self-help]              0.04 0.04 -0.02 0.01 0.03 0.06  0.15     2126 #>                                  Tail_ESS Rhat #> marg[13: Group counselling]          3027    1 #> marg[13: Individual counselling]     2796    1 #> marg[13: Self-help]                  2500    1 #>  #> --------------------------------------------------------------------- Study: 14 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[14: Group counselling]      0.14 0.08  0.02 0.08 0.13 0.18  0.32     2414 #> marg[14: Individual counselling] 0.09 0.04  0.03 0.07 0.09 0.12  0.18     1617 #> marg[14: Self-help]              0.05 0.05 -0.02 0.02 0.04 0.08  0.16     2089 #>                                  Tail_ESS Rhat #> marg[14: Group counselling]          2606    1 #> marg[14: Individual counselling]     2459    1 #> marg[14: Self-help]                  2435    1 #>  #> --------------------------------------------------------------------- Study: 15 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[15: Group counselling]      0.11 0.07  0.01 0.06 0.10 0.16  0.28     2998 #> marg[15: Individual counselling] 0.08 0.05  0.01 0.05 0.07 0.11  0.19     2639 #> marg[15: Self-help]              0.04 0.05 -0.02 0.01 0.03 0.06  0.16     2247 #>                                  Tail_ESS Rhat #> marg[15: Group counselling]          2926    1 #> marg[15: Individual counselling]     2775    1 #> marg[15: Self-help]                  2343    1 #>  #> --------------------------------------------------------------------- Study: 16 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[16: Group counselling]      0.12 0.07  0.02 0.07 0.11 0.16  0.29     2506 #> marg[16: Individual counselling] 0.08 0.04  0.03 0.05 0.08 0.10  0.17     1854 #> marg[16: Self-help]              0.04 0.04 -0.02 0.02 0.04 0.06  0.14     2054 #>                                  Tail_ESS Rhat #> marg[16: Group counselling]          2783    1 #> marg[16: Individual counselling]     2411    1 #> marg[16: Self-help]                  2481    1 #>  #> --------------------------------------------------------------------- Study: 17 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[17: Group counselling]      0.14 0.08  0.02 0.09 0.13 0.19  0.32     2287 #> marg[17: Individual counselling] 0.10 0.04  0.03 0.07 0.09 0.12  0.18     1482 #> marg[17: Self-help]              0.05 0.05 -0.02 0.02 0.05 0.08  0.16     2028 #>                                  Tail_ESS Rhat #> marg[17: Group counselling]          2757    1 #> marg[17: Individual counselling]     2231    1 #> marg[17: Self-help]                  2373    1 #>  #> --------------------------------------------------------------------- Study: 18 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[18: Group counselling]      0.13 0.07  0.02 0.07 0.11 0.16  0.31     2497 #> marg[18: Individual counselling] 0.08 0.04  0.03 0.06 0.08 0.10  0.17     1669 #> marg[18: Self-help]              0.05 0.04 -0.02 0.02 0.04 0.07  0.15     2040 #>                                  Tail_ESS Rhat #> marg[18: Group counselling]          2869    1 #> marg[18: Individual counselling]     2051    1 #> marg[18: Self-help]                  2360    1 #>  #> --------------------------------------------------------------------- Study: 19 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[19: Group counselling]      0.19 0.09  0.03 0.12 0.18 0.24  0.40     2292 #> marg[19: Individual counselling] 0.13 0.05  0.05 0.10 0.13 0.16  0.24     1488 #> marg[19: Self-help]              0.07 0.06 -0.03 0.03 0.06 0.11  0.21     2033 #>                                  Tail_ESS Rhat #> marg[19: Group counselling]          2771    1 #> marg[19: Individual counselling]     2052    1 #> marg[19: Self-help]                  2388    1 #>  #> --------------------------------------------------------------------- Study: 20 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[20: Group counselling]      0.11 0.06  0.02 0.06 0.10 0.14  0.25     2286 #> marg[20: Individual counselling] 0.07 0.03  0.02 0.05 0.07 0.09  0.13     1517 #> marg[20: Self-help]              0.04 0.04 -0.01 0.01 0.03 0.06  0.12     2021 #>                                  Tail_ESS Rhat #> marg[20: Group counselling]          2691    1 #> marg[20: Individual counselling]     2081    1 #> marg[20: Self-help]                  2404    1 #>  #> --------------------------------------------------------------------- Study: 21 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[21: Group counselling]      0.22 0.10  0.04 0.15 0.22 0.29  0.43     2659 #> marg[21: Individual counselling] 0.17 0.06  0.06 0.13 0.17 0.21  0.29     1897 #> marg[21: Self-help]              0.09 0.08 -0.05 0.04 0.09 0.14  0.26     2349 #>                                  Tail_ESS Rhat #> marg[21: Group counselling]          2974    1 #> marg[21: Individual counselling]     2487    1 #> marg[21: Self-help]                  2345    1 #>  #> --------------------------------------------------------------------- Study: 22 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[22: Group counselling]      0.14 0.08  0.02 0.08 0.12 0.18  0.33     3145 #> marg[22: Individual counselling] 0.10 0.06  0.02 0.06 0.09 0.13  0.24     2517 #> marg[22: Self-help]              0.05 0.05 -0.03 0.02 0.04 0.07  0.18     2337 #>                                  Tail_ESS Rhat #> marg[22: Group counselling]          3033    1 #> marg[22: Individual counselling]     2809    1 #> marg[22: Self-help]                  2301    1 #>  #> --------------------------------------------------------------------- Study: 23 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[23: Group counselling]      0.14 0.08  0.02 0.08 0.13 0.19  0.34     3054 #> marg[23: Individual counselling] 0.10 0.06  0.02 0.06 0.09 0.13  0.24     2826 #> marg[23: Self-help]              0.06 0.06 -0.02 0.02 0.04 0.08  0.21     2360 #>                                  Tail_ESS Rhat #> marg[23: Group counselling]          2507    1 #> marg[23: Individual counselling]     2771    1 #> marg[23: Self-help]                  2298    1 #>  #> --------------------------------------------------------------------- Study: 24 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[24: Group counselling]      0.11 0.08  0.01 0.05 0.09 0.15  0.31     3668 #> marg[24: Individual counselling] 0.08 0.05  0.01 0.04 0.06 0.10  0.20     3482 #> marg[24: Self-help]              0.04 0.05 -0.02 0.01 0.03 0.06  0.17     2411 #>                                  Tail_ESS Rhat #> marg[24: Group counselling]          3145    1 #> marg[24: Individual counselling]     2660    1 #> marg[24: Self-help]                  2639    1 #>   # Since there are no covariates in the model, the marginal and conditional # (log) odds ratios here coincide marginal_effects(smk_fit_RE, mtype = \"link\") #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[1: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[1: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[1: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                 Tail_ESS Rhat #> marg[1: Group counselling]          2783    1 #> marg[1: Individual counselling]     2018    1 #> marg[1: Self-help]                  2344    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[2: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[2: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[2: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                 Tail_ESS Rhat #> marg[2: Group counselling]          2783    1 #> marg[2: Individual counselling]     2018    1 #> marg[2: Self-help]                  2344    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[3: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[3: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[3: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                 Tail_ESS Rhat #> marg[3: Group counselling]          2783    1 #> marg[3: Individual counselling]     2018    1 #> marg[3: Self-help]                  2344    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[4: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[4: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[4: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                 Tail_ESS Rhat #> marg[4: Group counselling]          2783    1 #> marg[4: Individual counselling]     2018    1 #> marg[4: Self-help]                  2344    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[5: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[5: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[5: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                 Tail_ESS Rhat #> marg[5: Group counselling]          2783    1 #> marg[5: Individual counselling]     2018    1 #> marg[5: Self-help]                  2344    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[6: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[6: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[6: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                 Tail_ESS Rhat #> marg[6: Group counselling]          2783    1 #> marg[6: Individual counselling]     2018    1 #> marg[6: Self-help]                  2344    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[7: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[7: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[7: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                 Tail_ESS Rhat #> marg[7: Group counselling]          2783    1 #> marg[7: Individual counselling]     2018    1 #> marg[7: Self-help]                  2344    1 #>  #> ---------------------------------------------------------------------- Study: 8 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[8: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[8: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[8: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                 Tail_ESS Rhat #> marg[8: Group counselling]          2783    1 #> marg[8: Individual counselling]     2018    1 #> marg[8: Self-help]                  2344    1 #>  #> ---------------------------------------------------------------------- Study: 9 ----  #>  #>                                 mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[9: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[9: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[9: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                 Tail_ESS Rhat #> marg[9: Group counselling]          2783    1 #> marg[9: Individual counselling]     2018    1 #> marg[9: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 10 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[10: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[10: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[10: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[10: Group counselling]          2783    1 #> marg[10: Individual counselling]     2018    1 #> marg[10: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 11 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[11: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[11: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[11: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[11: Group counselling]          2783    1 #> marg[11: Individual counselling]     2018    1 #> marg[11: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 12 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[12: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[12: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[12: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[12: Group counselling]          2783    1 #> marg[12: Individual counselling]     2018    1 #> marg[12: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 13 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[13: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[13: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[13: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[13: Group counselling]          2783    1 #> marg[13: Individual counselling]     2018    1 #> marg[13: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 14 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[14: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[14: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[14: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[14: Group counselling]          2783    1 #> marg[14: Individual counselling]     2018    1 #> marg[14: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 15 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[15: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[15: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[15: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[15: Group counselling]          2783    1 #> marg[15: Individual counselling]     2018    1 #> marg[15: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 16 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[16: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[16: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[16: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[16: Group counselling]          2783    1 #> marg[16: Individual counselling]     2018    1 #> marg[16: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 17 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[17: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[17: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[17: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[17: Group counselling]          2783    1 #> marg[17: Individual counselling]     2018    1 #> marg[17: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 18 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[18: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[18: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[18: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[18: Group counselling]          2783    1 #> marg[18: Individual counselling]     2018    1 #> marg[18: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 19 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[19: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[19: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[19: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[19: Group counselling]          2783    1 #> marg[19: Individual counselling]     2018    1 #> marg[19: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 20 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[20: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[20: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[20: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[20: Group counselling]          2783    1 #> marg[20: Individual counselling]     2018    1 #> marg[20: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 21 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[21: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[21: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[21: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[21: Group counselling]          2783    1 #> marg[21: Individual counselling]     2018    1 #> marg[21: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 22 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[22: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[22: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[22: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[22: Group counselling]          2783    1 #> marg[22: Individual counselling]     2018    1 #> marg[22: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 23 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[23: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[23: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[23: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[23: Group counselling]          2783    1 #> marg[23: Individual counselling]     2018    1 #> marg[23: Self-help]                  2344    1 #>  #> --------------------------------------------------------------------- Study: 24 ----  #>  #>                                  mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[24: Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> marg[24: Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> marg[24: Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                                  Tail_ESS Rhat #> marg[24: Group counselling]          2783    1 #> marg[24: Individual counselling]     2018    1 #> marg[24: Self-help]                  2344    1 #>  relative_effects(smk_fit_RE) #>                           mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> d[Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> d[Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> d[Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                           Tail_ESS Rhat #> d[Group counselling]          2783    1 #> d[Individual counselling]     2018    1 #> d[Self-help]                  2344    1  # Marginal risk differences in a population with 67 observed events out of # 566 individuals on No Intervention, corresponding to a Beta(67, 566 - 67) # distribution on the baseline probability of response (smk_rd_RE <- marginal_effects(smk_fit_RE,                                baseline = distr(qbeta, 67, 566 - 67),                                baseline_type = \"response\",                                mtype = \"difference\")) #>                              mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[Group counselling]      0.18 0.09  0.03 0.11 0.17 0.23  0.38     2276 #> marg[Individual counselling] 0.12 0.05  0.04 0.09 0.12 0.15  0.23     1513 #> marg[Self-help]              0.07 0.06 -0.03 0.03 0.06 0.10  0.20     2032 #>                              Tail_ESS Rhat #> marg[Group counselling]          2743    1 #> marg[Individual counselling]     2019    1 #> marg[Self-help]                  2373    1 plot(smk_rd_RE)  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) #>  #> exmp__> # Set up plaque psoriasis network combining IPD and AgD #> exmp__> library(dplyr) #>  #> exmp__> pso_ipd <- filter(plaque_psoriasis_ipd, #> exmp__+                   studyc %in% c(\"UNCOVER-1\", \"UNCOVER-2\", \"UNCOVER-3\")) #>  #> exmp__> pso_agd <- filter(plaque_psoriasis_agd, #> exmp__+                   studyc == \"FIXTURE\") #>  #> exmp__> head(pso_ipd) #>      studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  34 32.2    18.2 #> 2 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  64 41.9    23.4 #> 3 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       0  42 26.2    12.8 #> 4 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      0      0       0  45 52.9    36.0 #> 5 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      0       0  67 22.9    20.9 #> 6 UNCOVER-1 Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 22.4    18.2 #>    male bsa weight durnpso prevsys   psa #> 1  TRUE  18   98.1     6.7    TRUE  TRUE #> 2  TRUE  33  129.6    14.5   FALSE  TRUE #> 3  TRUE  33   78.0    26.5    TRUE FALSE #> 4 FALSE  50  139.9    25.0    TRUE  TRUE #> 5 FALSE  35   54.2    11.9    TRUE FALSE #> 6  TRUE  29   67.5    15.2    TRUE FALSE #>  #> exmp__> head(pso_agd) #>    studyc          trtc_long    trtc trtn pasi75_r pasi75_n pasi90_r pasi90_n #> 1 FIXTURE         Etanercept     ETN    4      142      323       67      323 #> 2 FIXTURE            Placebo     PBO    1       16      324        5      324 #> 3 FIXTURE Secukinumab 150 mg SEC_150    5      219      327      137      327 #> 4 FIXTURE Secukinumab 300 mg SEC_300    6      249      323      175      323 #>   pasi100_r pasi100_n sample_size_w0 age_mean age_sd bmi_mean bmi_sd #> 1        14       323            326     43.8   13.0     28.7    5.9 #> 2         0       324            326     44.1   12.6     27.9    6.1 #> 3        47       327            327     45.4   12.9     28.4    5.9 #> 4        78       323            327     44.5   13.2     28.4    6.4 #>   pasi_w0_mean pasi_w0_sd male bsa_mean bsa_sd weight_mean weight_sd #> 1         23.2        9.8 71.2     33.6   18.0        84.6      20.5 #> 2         24.1       10.5 72.7     35.2   19.1        82.0      20.4 #> 3         23.7       10.5 72.2     34.5   19.4        83.6      20.8 #> 4         23.9        9.9 68.5     34.3   19.2        83.0      21.6 #>   durnpso_mean durnpso_sd prevsys  psa #> 1         16.4       12.0    65.6 13.5 #> 2         16.6       11.6    62.6 15.0 #> 3         17.3       12.2    64.8 15.0 #> 4         15.8       12.3    63.0 15.3 #>  #> exmp__> pso_ipd <- pso_ipd %>% #> exmp__+   mutate(# Variable transformations #> exmp__+     bsa = bsa / 100, #> exmp__+     prevsys = as.numeric(prevsys), #> exmp__+     psa = as.numeric(psa), #> exmp__+     weight = weight / 10, #> exmp__+     durnpso = durnpso / 10, #> exmp__+     # Treatment classes #> exmp__+     trtclass = case_when(trtn == 1 ~ \"Placebo\", #> exmp__+                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\", #> exmp__+                          trtn == 4 ~ \"TNFa blocker\"), #> exmp__+     # Check complete cases for covariates of interest #> exmp__+     complete = complete.cases(durnpso, prevsys, bsa, weight, psa) #> exmp__+   ) #>  #> exmp__> pso_agd <- pso_agd %>% #> exmp__+   mutate( #> exmp__+     # Variable transformations #> exmp__+     bsa_mean = bsa_mean / 100, #> exmp__+     bsa_sd = bsa_sd / 100, #> exmp__+     prevsys = prevsys / 100, #> exmp__+     psa = psa / 100, #> exmp__+     weight_mean = weight_mean / 10, #> exmp__+     weight_sd = weight_sd / 10, #> exmp__+     durnpso_mean = durnpso_mean / 10, #> exmp__+     durnpso_sd = durnpso_sd / 10, #> exmp__+     # Treatment classes #> exmp__+     trtclass = case_when(trtn == 1 ~ \"Placebo\", #> exmp__+                          trtn %in% c(2, 3, 5, 6) ~ \"IL blocker\", #> exmp__+                          trtn == 4 ~ \"TNFa blocker\") #> exmp__+   ) #>  #> exmp__> # Exclude small number of individuals with missing covariates #> exmp__> pso_ipd <- filter(pso_ipd, complete) #>  #> exmp__> pso_net <- combine_network( #> exmp__+   set_ipd(pso_ipd, #> exmp__+           study = studyc, #> exmp__+           trt = trtc, #> exmp__+           r = pasi75, #> exmp__+           trt_class = trtclass), #> exmp__+   set_agd_arm(pso_agd, #> exmp__+               study = studyc, #> exmp__+               trt = trtc, #> exmp__+               r = pasi75_r, #> exmp__+               n = pasi75_n, #> exmp__+               trt_class = trtclass) #> exmp__+ ) #>  #> exmp__> # Print network details #> exmp__> pso_net #> A network with 3 IPD studies, and 1 AgD study (arm-based). #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study   Treatment arms                   #>  FIXTURE 4: PBO | ETN | SEC_150 | SEC_300 #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 6, in 3 classes #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected #>  #> exmp__> # Add integration points to the network #> exmp__> pso_net <- add_integration(pso_net, #> exmp__+   durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd), #> exmp__+   prevsys = distr(qbern, prob = prevsys), #> exmp__+   bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd), #> exmp__+   weight = distr(qgamma, mean = weight_mean, sd = weight_sd), #> exmp__+   psa = distr(qbern, prob = psa), #> exmp__+   n_int = 64) #> Using weighted average correlation matrix computed from IPD studies. #>  #> exmp__> ## No test:  #> exmp__> # Fitting a ML-NMR model. #> exmp__> # Specify a regression model to include effect modifier interactions for five #> exmp__> # covariates, along with main (prognostic) effects. We use a probit link and #> exmp__> # specify that the two-parameter Binomial approximation for the aggregate-level #> exmp__> # likelihood should be used. We set treatment-covariate interactions to be equal #> exmp__> # within each class. We narrow the possible range for random initial values with #> exmp__> # init_r = 0.1, since probit models in particular are often hard to initialise. #> exmp__> # Using the QR decomposition greatly improves sampling efficiency here, as is #> exmp__> # often the case for regression models. #> exmp__> pso_fit <- nma(pso_net, ## Don't show:  #> exmp__+ refresh = if (interactive()) 200 else 0, #> exmp__+ ## End(Don't show) #> exmp__+                trt_effects = \"fixed\", #> exmp__+                link = \"probit\", #> exmp__+                likelihood = \"bernoulli2\", #> exmp__+                regression = ~(durnpso + prevsys + bsa + weight + psa)*.trt, #> exmp__+                class_interactions = \"common\", #> exmp__+                prior_intercept = normal(scale = 10), #> exmp__+                prior_trt = normal(scale = 10), #> exmp__+                prior_reg = normal(scale = 10), #> exmp__+                init_r = 0.1, #> exmp__+                QR = TRUE) #> Note: Setting \"PBO\" as the network reference treatment. #>  #> exmp__> pso_fit #> A fixed effects ML-NMR with a bernoulli2 likelihood (probit link). #> Regression model: ~(durnpso + prevsys + bsa + weight + psa) * .trt. #> Centred covariates at the following overall mean values: #>   durnpso   prevsys       bsa    weight       psa  #> 1.8134535 0.6450416 0.2909089 8.9369318 0.2147914  #> Inference for Stan model: binomial_2par. #> 4 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=4000. #>  #>                                         mean se_mean   sd     2.5%      25% #> beta[durnpso]                           0.04    0.00 0.06    -0.08     0.00 #> beta[prevsys]                          -0.14    0.00 0.16    -0.46    -0.25 #> beta[bsa]                              -0.07    0.01 0.45    -0.98    -0.35 #> beta[weight]                            0.04    0.00 0.03    -0.02     0.02 #> beta[psa]                              -0.08    0.00 0.16    -0.41    -0.18 #> beta[durnpso:.trtclassTNFa blocker]    -0.03    0.00 0.07    -0.17    -0.08 #> beta[durnpso:.trtclassIL blocker]      -0.01    0.00 0.07    -0.15    -0.06 #> beta[prevsys:.trtclassTNFa blocker]     0.20    0.00 0.19    -0.17     0.07 #> beta[prevsys:.trtclassIL blocker]       0.07    0.00 0.18    -0.28    -0.05 #> beta[bsa:.trtclassTNFa blocker]         0.06    0.01 0.53    -0.97    -0.30 #> beta[bsa:.trtclassIL blocker]           0.29    0.01 0.50    -0.68    -0.05 #> beta[weight:.trtclassTNFa blocker]     -0.17    0.00 0.04    -0.24    -0.19 #> beta[weight:.trtclassIL blocker]       -0.10    0.00 0.03    -0.16    -0.12 #> beta[psa:.trtclassTNFa blocker]        -0.06    0.00 0.21    -0.45    -0.19 #> beta[psa:.trtclassIL blocker]           0.01    0.00 0.18    -0.35    -0.11 #> d[ETN]                                  1.55    0.00 0.08     1.40     1.50 #> d[IXE_Q2W]                              2.96    0.00 0.08     2.80     2.90 #> d[IXE_Q4W]                              2.54    0.00 0.08     2.39     2.49 #> d[SEC_150]                              2.15    0.00 0.11     1.92     2.07 #> d[SEC_300]                              2.45    0.00 0.12     2.22     2.37 #> lp__                                -1576.35    0.09 3.45 -1583.92 -1578.51 #>                                          50%      75%    97.5% n_eff Rhat #> beta[durnpso]                           0.04     0.08     0.16  6799    1 #> beta[prevsys]                          -0.14    -0.03     0.17  5745    1 #> beta[bsa]                              -0.06     0.23     0.79  5796    1 #> beta[weight]                            0.04     0.06     0.10  5287    1 #> beta[psa]                              -0.08     0.03     0.24  6214    1 #> beta[durnpso:.trtclassTNFa blocker]    -0.03     0.02     0.11  6691    1 #> beta[durnpso:.trtclassIL blocker]      -0.01     0.03     0.12  8571    1 #> beta[prevsys:.trtclassTNFa blocker]     0.20     0.33     0.56  6223    1 #> beta[prevsys:.trtclassIL blocker]       0.07     0.19     0.42  6663    1 #> beta[bsa:.trtclassTNFa blocker]         0.05     0.40     1.14  6426    1 #> beta[bsa:.trtclassIL blocker]           0.28     0.61     1.29  7358    1 #> beta[weight:.trtclassTNFa blocker]     -0.17    -0.14    -0.09  5855    1 #> beta[weight:.trtclassIL blocker]       -0.10    -0.08    -0.03  5963    1 #> beta[psa:.trtclassTNFa blocker]        -0.06     0.07     0.35  6991    1 #> beta[psa:.trtclassIL blocker]           0.01     0.13     0.36  7264    1 #> d[ETN]                                  1.55     1.61     1.71  4242    1 #> d[IXE_Q2W]                              2.96     3.01     3.12  4706    1 #> d[IXE_Q4W]                              2.54     2.60     2.71  4702    1 #> d[SEC_150]                              2.15     2.22     2.37  4966    1 #> d[SEC_300]                              2.45     2.53     2.68  5856    1 #> lp__                                -1576.05 -1573.87 -1570.42  1628    1 #>  #> Samples were drawn using NUTS(diag_e) at Thu Mar 13 15:28:34 2025. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #>  #> exmp__> ## End(No test) #> exmp__>  #> exmp__> ## Don't show:  #> exmp__> if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) { #> exmp__+   assign(\"pso_net\", pso_net, .GlobalEnv) #> exmp__+   assign(\"pso_fit\", pso_fit, .GlobalEnv) #> exmp__+ } #>  #> exmp__> ## End(Don't show) #> exmp__>  #> exmp__>  #> exmp__>  # } # \\donttest{ # Population-average marginal probit differences in each study in the network (pso_marg <- marginal_effects(pso_fit, mtype = \"link\")) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> marg[FIXTURE: ETN]     1.63 0.08 1.47 1.58 1.63 1.69  1.80     4576     3324 #> marg[FIXTURE: IXE_Q2W] 2.98 0.09 2.81 2.92 2.98 3.05  3.17     5142     2918 #> marg[FIXTURE: IXE_Q4W] 2.58 0.09 2.40 2.52 2.58 2.64  2.75     5462     3236 #> marg[FIXTURE: SEC_150] 2.18 0.11 1.96 2.11 2.19 2.26  2.40     4922     3514 #> marg[FIXTURE: SEC_300] 2.48 0.12 2.26 2.41 2.48 2.56  2.71     5748     3333 #>                        Rhat #> marg[FIXTURE: ETN]        1 #> marg[FIXTURE: IXE_Q2W]    1 #> marg[FIXTURE: IXE_Q4W]    1 #> marg[FIXTURE: SEC_150]    1 #> marg[FIXTURE: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> marg[UNCOVER-1: ETN]     1.48 0.08 1.33 1.43 1.49 1.54  1.64     4752     3400 #> marg[UNCOVER-1: IXE_Q2W] 2.87 0.08 2.71 2.81 2.87 2.93  3.04     5542     3392 #> marg[UNCOVER-1: IXE_Q4W] 2.47 0.08 2.31 2.41 2.47 2.52  2.62     5686     3334 #> marg[UNCOVER-1: SEC_150] 2.07 0.12 1.85 1.99 2.07 2.15  2.30     5671     3159 #> marg[UNCOVER-1: SEC_300] 2.37 0.12 2.14 2.29 2.37 2.46  2.61     6571     3451 #>                          Rhat #> marg[UNCOVER-1: ETN]        1 #> marg[UNCOVER-1: IXE_Q2W]    1 #> marg[UNCOVER-1: IXE_Q4W]    1 #> marg[UNCOVER-1: SEC_150]    1 #> marg[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> marg[UNCOVER-2: ETN]     1.48 0.08 1.33 1.43 1.49 1.54  1.64     4867     3454 #> marg[UNCOVER-2: IXE_Q2W] 2.87 0.08 2.72 2.82 2.87 2.93  3.03     5711     3358 #> marg[UNCOVER-2: IXE_Q4W] 2.47 0.08 2.31 2.41 2.47 2.52  2.62     5815     3385 #> marg[UNCOVER-2: SEC_150] 2.07 0.12 1.85 2.00 2.07 2.15  2.30     5807     3656 #> marg[UNCOVER-2: SEC_300] 2.37 0.12 2.14 2.30 2.37 2.45  2.61     6694     3355 #>                          Rhat #> marg[UNCOVER-2: ETN]        1 #> marg[UNCOVER-2: IXE_Q2W]    1 #> marg[UNCOVER-2: IXE_Q4W]    1 #> marg[UNCOVER-2: SEC_150]    1 #> marg[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> marg[UNCOVER-3: ETN]     1.50 0.08 1.35 1.45 1.50 1.55  1.65     4805     3496 #> marg[UNCOVER-3: IXE_Q2W] 2.89 0.08 2.73 2.84 2.89 2.95  3.05     5666     3298 #> marg[UNCOVER-3: IXE_Q4W] 2.49 0.08 2.33 2.43 2.49 2.54  2.64     5782     3289 #> marg[UNCOVER-3: SEC_150] 2.09 0.11 1.88 2.02 2.09 2.17  2.32     5657     3486 #> marg[UNCOVER-3: SEC_300] 2.39 0.12 2.16 2.32 2.39 2.47  2.62     6545     3046 #>                          Rhat #> marg[UNCOVER-3: ETN]        1 #> marg[UNCOVER-3: IXE_Q2W]    1 #> marg[UNCOVER-3: IXE_Q4W]    1 #> marg[UNCOVER-3: SEC_150]    1 #> marg[UNCOVER-3: SEC_300]    1 #>  plot(pso_marg, ref_line = c(0, 1))   # Population-average marginal probit differences in a new target population, # with means and SDs or proportions given by new_agd_int <- data.frame(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1 )  # We need to add integration points to this data frame of new data # We use the weighted mean correlation matrix computed from the IPD studies new_agd_int <- add_integration(new_agd_int,                                durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),                                prevsys = distr(qbern, prob = prevsys),                                bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),                                weight = distr(qgamma, mean = weight_mean, sd = weight_sd),                                psa = distr(qbern, prob = psa),                                cor = pso_net$int_cor,                                n_int = 64)  # Population-average marginal probit differences of achieving PASI 75 in this # target population, given a Normal(-1.75, 0.08^2) distribution on the # baseline probit-probability of response on Placebo (at the reference levels # of the covariates), are given by (pso_marg_new <- marginal_effects(pso_fit,                                   mtype = \"link\",                                   newdata = new_agd_int,                                   baseline = distr(qnorm, -1.75, 0.08))) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> marg[New 1: ETN]     1.23 0.22 0.79 1.09 1.23 1.38  1.66     7099     2873    1 #> marg[New 1: IXE_Q2W] 2.85 0.21 2.43 2.71 2.86 3.00  3.27     7324     3260    1 #> marg[New 1: IXE_Q4W] 2.44 0.21 2.02 2.31 2.45 2.59  2.84     7647     3090    1 #> marg[New 1: SEC_150] 2.05 0.22 1.61 1.89 2.05 2.20  2.47     7807     3072    1 #> marg[New 1: SEC_300] 2.35 0.22 1.91 2.20 2.36 2.50  2.78     7741     2912    1 #>  plot(pso_marg_new)  # }  ## Progression free survival with newly-diagnosed multiple myeloma # \\donttest{ # Run newly-diagnosed multiple myeloma example if not already available if (!exists(\"ndmm_fit\")) example(\"example_ndmm\", run.donttest = TRUE) # } # \\donttest{ # We can produce a range of marginal effects from models with survival # outcomes, specified with the mtype and type arguments. For example:  # Marginal survival probability difference at 5 years, all contrasts marginal_effects(ndmm_fit, type = \"survival\", mtype = \"difference\",                  times = 5, all_contrasts = TRUE) #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                                  .time  mean   sd  2.5%   25%   50%   75% 97.5% #> marg[Attal2012: Len vs. Pbo, 1]      5  0.19 0.02  0.16  0.18  0.19  0.20  0.22 #> marg[Attal2012: Thal vs. Pbo, 1]     5  0.04 0.03 -0.02  0.02  0.04  0.06  0.10 #> marg[Attal2012: Thal vs. Len, 1]     5 -0.15 0.03 -0.22 -0.17 -0.15 -0.13 -0.08 #>                                  Bulk_ESS Tail_ESS Rhat #> marg[Attal2012: Len vs. Pbo, 1]      4911     3221    1 #> marg[Attal2012: Thal vs. Pbo, 1]     4970     2945    1 #> marg[Attal2012: Thal vs. Len, 1]     5251     2761    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                                    .time  mean   sd  2.5%   25%   50%   75% #> marg[Jackson2019: Len vs. Pbo, 1]      5  0.19 0.02  0.16  0.18  0.19  0.21 #> marg[Jackson2019: Thal vs. Pbo, 1]     5  0.04 0.03 -0.02  0.02  0.04  0.06 #> marg[Jackson2019: Thal vs. Len, 1]     5 -0.15 0.04 -0.22 -0.18 -0.15 -0.13 #>                                    97.5% Bulk_ESS Tail_ESS Rhat #> marg[Jackson2019: Len vs. Pbo, 1]   0.23     5107     2909    1 #> marg[Jackson2019: Thal vs. Pbo, 1]  0.10     4960     2993    1 #> marg[Jackson2019: Thal vs. Len, 1] -0.08     5304     2802    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                                     .time  mean   sd  2.5%   25%   50%   75% #> marg[McCarthy2012: Len vs. Pbo, 1]      5  0.20 0.02  0.16  0.18  0.20  0.21 #> marg[McCarthy2012: Thal vs. Pbo, 1]     5  0.04 0.03 -0.02  0.02  0.04  0.06 #> marg[McCarthy2012: Thal vs. Len, 1]     5 -0.15 0.04 -0.22 -0.18 -0.15 -0.13 #>                                     97.5% Bulk_ESS Tail_ESS Rhat #> marg[McCarthy2012: Len vs. Pbo, 1]   0.23     5059     2842    1 #> marg[McCarthy2012: Thal vs. Pbo, 1]  0.10     4968     2993    1 #> marg[McCarthy2012: Thal vs. Len, 1] -0.08     5308     2650    1 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                                   .time  mean   sd  2.5%   25%   50%   75% #> marg[Morgan2012: Len vs. Pbo, 1]      5  0.19 0.02  0.16  0.18  0.19  0.21 #> marg[Morgan2012: Thal vs. Pbo, 1]     5  0.04 0.03 -0.02  0.02  0.04  0.06 #> marg[Morgan2012: Thal vs. Len, 1]     5 -0.15 0.04 -0.22 -0.18 -0.15 -0.13 #>                                   97.5% Bulk_ESS Tail_ESS Rhat #> marg[Morgan2012: Len vs. Pbo, 1]   0.23     5127     2948    1 #> marg[Morgan2012: Thal vs. Pbo, 1]  0.10     4935     2992    1 #> marg[Morgan2012: Thal vs. Len, 1] -0.08     5298     2764    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                                    .time  mean   sd  2.5%   25%   50%   75% #> marg[Palumbo2014: Len vs. Pbo, 1]      5  0.19 0.02  0.16  0.18  0.19  0.20 #> marg[Palumbo2014: Thal vs. Pbo, 1]     5  0.04 0.03 -0.02  0.02  0.04  0.06 #> marg[Palumbo2014: Thal vs. Len, 1]     5 -0.15 0.03 -0.22 -0.17 -0.15 -0.13 #>                                    97.5% Bulk_ESS Tail_ESS Rhat #> marg[Palumbo2014: Len vs. Pbo, 1]   0.22     4979     2916    1 #> marg[Palumbo2014: Thal vs. Pbo, 1]  0.10     4987     2968    1 #> marg[Palumbo2014: Thal vs. Len, 1] -0.08     5296     2906    1 #>   # Marginal difference in RMST up to 5 years marginal_effects(ndmm_fit, type = \"rmst\", mtype = \"difference\", times = 5) #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                          .time mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[Attal2012: Len, 1]      5 0.69 0.06  0.58 0.65 0.69 0.73  0.81     4895 #> marg[Attal2012: Thal, 1]     5 0.15 0.12 -0.09 0.07 0.16 0.23  0.38     4959 #>                          Tail_ESS Rhat #> marg[Attal2012: Len, 1]      2866    1 #> marg[Attal2012: Thal, 1]     2993    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                            .time mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[Jackson2019: Len, 1]      5 0.74 0.06  0.62 0.70 0.74 0.78  0.86     4860 #> marg[Jackson2019: Thal, 1]     5 0.16 0.13 -0.09 0.08 0.17 0.25  0.41     4929 #>                            Tail_ESS Rhat #> marg[Jackson2019: Len, 1]      2926    1 #> marg[Jackson2019: Thal, 1]     3016    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                             .time mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[McCarthy2012: Len, 1]      5 0.64 0.06  0.53 0.60 0.64 0.68  0.75     4937 #> marg[McCarthy2012: Thal, 1]     5 0.14 0.11 -0.08 0.07 0.15 0.22  0.36     4936 #>                             Tail_ESS Rhat #> marg[McCarthy2012: Len, 1]      3006    1 #> marg[McCarthy2012: Thal, 1]     2993    1 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                           .time mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[Morgan2012: Len, 1]      5 0.76 0.06  0.64 0.72 0.76 0.80  0.88     4941 #> marg[Morgan2012: Thal, 1]     5 0.17 0.13 -0.09 0.08 0.17 0.26  0.43     4953 #>                           Tail_ESS Rhat #> marg[Morgan2012: Len, 1]      2778    1 #> marg[Morgan2012: Thal, 1]     2993    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                            .time mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> marg[Palumbo2014: Len, 1]      5 0.75 0.07  0.63 0.71 0.75 0.80  0.89     4805 #> marg[Palumbo2014: Thal, 1]     5 0.17 0.13 -0.09 0.08 0.17 0.25  0.42     4973 #>                            Tail_ESS Rhat #> marg[Palumbo2014: Len, 1]      2995    1 #> marg[Palumbo2014: Thal, 1]     3016    1 #>   # Marginal median survival time ratios marginal_effects(ndmm_fit, type = \"median\", mtype = \"ratio\") #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> marg[Attal2012: Len]  1.52 0.06 1.41 1.48 1.51 1.56  1.64     4316     3166 #> marg[Attal2012: Thal] 1.09 0.07 0.95 1.04 1.09 1.14  1.25     4995     2959 #>                       Rhat #> marg[Attal2012: Len]     1 #> marg[Attal2012: Thal]    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> marg[Jackson2019: Len]  1.78 0.09 1.62 1.72 1.78 1.84  1.96     4625     2259 #> marg[Jackson2019: Thal] 1.13 0.11 0.94 1.06 1.13 1.20  1.36     4933     3016 #>                         Rhat #> marg[Jackson2019: Len]     1 #> marg[Jackson2019: Thal]    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> marg[McCarthy2012: Len]  1.52 0.06 1.41 1.48 1.51 1.56  1.64     4544     2944 #> marg[McCarthy2012: Thal] 1.09 0.07 0.95 1.04 1.09 1.14  1.25     4970     2992 #>                          Rhat #> marg[McCarthy2012: Len]     1 #> marg[McCarthy2012: Thal]    1 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> marg[Morgan2012: Len]  1.85 0.10 1.65 1.78 1.84 1.91  2.06     5283     2906 #> marg[Morgan2012: Thal] 1.14 0.12 0.93 1.06 1.14 1.21  1.39     4921     2883 #>                        Rhat #> marg[Morgan2012: Len]     1 #> marg[Morgan2012: Thal]    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                         mean  sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> marg[Palumbo2014: Len]  1.71 0.1 1.53 1.63 1.70 1.77  1.92     4344     2791 #> marg[Palumbo2014: Thal] 1.12 0.1 0.94 1.05 1.12 1.18  1.33     5015     2984 #>                         Rhat #> marg[Palumbo2014: Len]     1 #> marg[Palumbo2014: Thal]    1 #>   # Marginal log hazard ratios # With no covariates in the model, these are constant over time and study # populations, and are equal to the log hazard ratios from relative_effects() plot(marginal_effects(ndmm_fit, type = \"hazard\", mtype = \"link\"),      # The hazard is infinite at t=0 in some studies, giving undefined logHRs at t=0      na.rm = TRUE)   # The NDMM vignette demonstrates the production of time-varying marginal # hazard ratios from a ML-NMR model that includes covariates, see # `vignette(\"example_ndmm\")`  # Marginal survival difference over time plot(marginal_effects(ndmm_fit, type = \"survival\", mtype = \"difference\"))  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Working with 3D MCMC arrays — mcmc_array-class","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"3D MCMC arrays (Iterations, Chains, Parameters) produced .array() methods applied stan_nma nma_summary objects.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"","code":"# S3 method for class 'mcmc_array' summary(object, ..., probs = c(0.025, 0.25, 0.5, 0.75, 0.975))  # S3 method for class 'mcmc_array' print(x, ...)  # S3 method for class 'mcmc_array' plot(x, ...)  # S3 method for class 'mcmc_array' names(x)  # S3 method for class 'mcmc_array' names(x) <- value"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"... arguments passed methods probs Numeric vector quantiles interest x, object 3D MCMC array class mcmc_array value Character vector replacement parameter names","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"summary() method returns nma_summary object, print() method returns x invisibly. names() method returns character vector parameter names, names()<- returns object updated parameter names. plot() method shortcut plot(summary(x), ...), passing arguments plot.nma_summary().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mcmc_array-class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Working with 3D MCMC arrays — mcmc_array-class","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Working with arrays of posterior draws (as mcmc_array objects) is # convenient when transforming parameters  # Transforming log odds ratios to odds ratios LOR_array <- as.array(relative_effects(smk_fit_RE)) OR_array <- exp(LOR_array)  # mcmc_array objects can be summarised to produce a nma_summary object smk_OR_RE <- summary(OR_array)  # This can then be printed or plotted smk_OR_RE #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling]      3.33 1.60 1.32 2.25 3.00 4.00  7.33     2276     2783 #> d[Individual counselling] 2.40 0.60 1.46 1.99 2.33 2.73  3.80     1454     2018 #> d[Self-help]              1.75 0.73 0.75 1.25 1.61 2.10  3.46     2017     2344 #>                           Rhat #> d[Group counselling]         1 #> d[Individual counselling]    1 #> d[Self-help]                 1 plot(smk_OR_RE, ref_line = 1)   # Transforming heterogeneity SD to variance tau_array <- as.array(smk_fit_RE, pars = \"tau\") tausq_array <- tau_array^2  # Correct parameter names names(tausq_array) <- \"tausq\"  # Summarise summary(tausq_array) #>       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tausq 0.74 0.33 0.31 0.51 0.67 0.89   1.6     1368     2250    1 # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":null,"dir":"Reference","previous_headings":"","what":"Distribution functions for M-spline baseline hazards — dmspline","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"Density, distribution, quantile, hazard, cumulative hazard, restricted mean survival time functions M-spline baseline hazards model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"","code":"dmspline(x, basis, scoef, rate, log = FALSE)  pmspline(q, basis, scoef, rate, lower.tail = TRUE, log.p = FALSE)  qmspline(p, basis, scoef, rate, lower.tail = TRUE, log.p = FALSE)  hmspline(x, basis, scoef, rate, log = FALSE)  Hmspline(x, basis, scoef, rate, log = FALSE)  rmst_mspline(t, basis, scoef, rate, start = 0)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"x, q Vector quantiles basis M-spline basis produced splines2::mSpline() scoef Vector (matrix) spline coefficients length (number columns) equal dimension basis rate Vector rate parameters log, log.p Logical; TRUE, probabilities p given \\(\\log(p)\\) lower.tail Logical; TRUE (default), probabilities \\(P(X \\le x)\\), otherwise \\(P(X > x)\\) p Vector probabilities t Vector times restricted mean survival time calculated start Optional left-truncation time times. returned restricted mean survival conditioned survival time","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"dmspline() gives density, pmspline() gives distribution function (CDF), qmspline() gives quantile function (inverse-CDF), hmspline() gives hazard function, Hmspline() gives cumulative hazard function, rmst_mspline() gives restricted mean survival times.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/mspline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Distribution functions for M-spline baseline hazards — dmspline","text":"Survival models flexible M-spline baseline hazard described Brilleman2020;textualmultinma. Piecewise-exponential baseline hazards special case degree M-spline polynomial 0. d/p/h/H functions calculated definitions. qmspline() uses numerical inversion via flexsurv::qgeneric(). rmst_mspline()uses numerical integration via flexsurv::rmst_generic(), except special case piecewise-exponential hazard (.e. degree 0 M-splines) uses explicit formula Royston2013;textualmultinma. Beyond boundary knots, hazard assumed constant. (differs approach splines2::mSpline() extrapolates polynomial basis functions, numerically unstable highly dependent data just boundary knots.) extrapolation, care taken evaluating splines times beyond boundary knots (either directly d/p/h/H/rmst functions, indirectly requesting quantiles qmspline() correspond times beyond boundary knots). reason evaluating (unrestricted) mean survival time generally recommended requires integrating infinite time horizon (.e. rmst_mspline() t = Inf).","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial outcome data — multi","title":"Multinomial outcome data — multi","text":"function aids specification multinomial outcome data setting network set_agd_arm() set_ipd(). takes set columns (, generally, numeric vectors length) outcome counts category, binds together produce matrix.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multinomial outcome data — multi","text":"","code":"multi(..., inclusive = FALSE, type = c(\"ordered\", \"competing\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multinomial outcome data — multi","text":"... Two numeric columns (vectors) category counts. Argument names (optional) used label categories. inclusive Logical, ordered category counts inclusive (TRUE) exclusive (FALSE)? Default FALSE. used type = \"ordered\". See details. type String, indicating whether categories \"ordered\" \"competing\". Currently ordered categorical outcomes supported modelling functions package.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multinomial outcome data — multi","text":"matrix (exclusive) category counts","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multinomial outcome data — multi","text":"specifying ordered categorical counts, can either given exclusive counts (inclusive = FALSE, default) individuals counted highest category achieve, inclusive counts (inclusive = TRUE) individuals counted every category including highest category achieved. (Competing outcomes, nature, always specified exclusive counts.) NA values can used indicate categories/cutpoints measured.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multinomial outcome data — multi","text":"","code":"# These two data sets specify the same ordered categorical data for outcomes # r0 < r1 < r2, but the first uses the \"inclusive\" format and the second the # \"exclusive\" format. df_inclusive <- tibble::tribble(~r0, ~r1, ~r2,                                 1, 1, 1,                                 5, 4, 1,                                 5, 2, 2,                                 10, 5, 0,                                 5, 5, 0,                                 7, NA, 6,   # Achieved r2 or not (no r1)                                 10, 4, NA)  # Achieved r1 or not (no r2)  df_exclusive <- tibble::tribble(~r0, ~r1, ~r2,                                 0, 0, 1,                                 1, 3, 1,                                 3, 0, 2,                                 5, 5, 0,                                 0, 5, 0,                                 1, NA, 6,   # Achieved r2 or not (no r1)                                 6, 4, NA)   # Achieved r1 or not (no r2)  (r_inclusive <- with(df_inclusive, multi(r0, r1, r2, inclusive = TRUE))) #>      r0 r1 r2 #> [1,]  0  0  1 #> [2,]  1  3  1 #> [3,]  3  0  2 #> [4,]  5  5  0 #> [5,]  0  5  0 #> [6,]  1 NA  6 #> [7,]  6  4 NA #> attr(,\"class\") #> [1] \"multi_ordered\" \"matrix\"        \"array\"         (r_exclusive <- with(df_exclusive, multi(r0, r1, r2, inclusive = FALSE))) #>      r0 r1 r2 #> [1,]  0  0  1 #> [2,]  1  3  1 #> [3,]  3  0  2 #> [4,]  5  5  0 #> [5,]  0  5  0 #> [6,]  1 NA  6 #> [7,]  6  4 NA #> attr(,\"class\") #> [1] \"multi_ordered\" \"matrix\"        \"array\"          # Counts are always stored in exclusive format stopifnot(isTRUE(all.equal(r_inclusive, r_exclusive)))   ## HTA Plaque Psoriasis library(dplyr)  # Ordered outcomes here are given as \"exclusive\" counts head(hta_psoriasis) #>   studyn   studyc year trtn             trtc sample_size PASI50 PASI75 PASI90 #> 1      1  Elewski 2004    1  Supportive care         193     12      5      1 #> 2      1  Elewski 2004    2 Etanercept 25 mg         196     59     46     21 #> 3      1  Elewski 2004    3 Etanercept 50 mg         194     54     56     40 #> 4      2 Gottlieb 2003    1  Supportive care          55      5      1      0 #> 5      2 Gottlieb 2003    2 Etanercept 25 mg          57     23     11      6 #> 6      3  Lebwohl 2003    1  Supportive care         122     13      5      1  # Calculate lowest category count (failure to achieve PASI 50) pso_dat <- hta_psoriasis %>%   mutate(`PASI<50` = sample_size - rowSums(cbind(PASI50, PASI75, PASI90), na.rm = TRUE))  # Set up network pso_net <- set_agd_arm(pso_dat,                        study = paste(studyc, year),                        trt = trtc,                        r = multi(`PASI<50`, PASI50, PASI75, PASI90,                                  inclusive = FALSE,                                  type = \"ordered\"))  pso_net #> A network with 16 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                                           #>  ACD2058g 2004 2: Supportive care | Efalizumab                          #>  ACD2600g 2004 2: Supportive care | Efalizumab                          #>  Altmeyer 1994 2: Supportive care | Fumaderm                            #>  Chaudari 2001 2: Supportive care | Infliximab                          #>  Elewski 2004  3: Supportive care | Etanercept 25 mg | Etanercept 50 mg #>  Ellis 1991    3: Supportive care | Ciclosporin | Ciclosporin           #>  Gordon 2003   2: Supportive care | Efalizumab                          #>  Gottlieb 2003 2: Supportive care | Etanercept 25 mg                    #>  Gottlieb 2004 3: Supportive care | Infliximab | Infliximab             #>  Guenther 1991 2: Supportive care | Ciclosporin                         #>  ... plus 6 more studies #>  #>  Outcome type: ordered (4 categories) #> ------------------------------------------------------------------------------------ #> Total number of treatments: 8 #> Total number of studies: 16 #> Reference treatment is: Supportive care #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":null,"dir":"Reference","previous_headings":"","what":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate Data in Stan — multinma-package","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate Data in Stan — multinma-package","text":"R package performing network meta-analysis network meta-regression aggregate data, individual patient data, mixtures .","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate Data in Stan — multinma-package","text":"Network meta-analysis (NMA) combines (aggregate) data multiple studies multiple treatments order produce consistent estimates relative treatment effects pair treatments network TSD2multinma. Network meta-regression (NMR) extends NMA include covariates, allowing adjustment differences effect-modifying variables studies TSD3multinma. NMR typically performed using aggregate data (AgD), lacks power prone ecological bias. NMR individual patient data (IPD) gold standard, data available. Multilevel network meta-regression (ML-NMR) allows IPD AgD incorporated together network meta-regression methods_paper,Phillippo_thesismultinma. IPD NMR, individual-level regression model defined. AgD studies fitted integrating individual-level model respective covariate distributions. correctly links two levels model (instead \"plugging \" mean covariate values), avoiding aggregation bias. Population-adjusted treatment effects TSD18multinma can produced study population network, external target population. Models estimated Bayesian framework using Stan Carpenter2017multinma. Quasi-Monte Carlo numerical integration based Sobol' sequences used integration ML-NMR models, Gaussian copula account correlations covariates methods_paper,Phillippo_thesismultinma.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"getting-started","dir":"Reference","previous_headings":"","what":"Getting Started","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate Data in Stan — multinma-package","text":"good place start package vignettes walk example analyses, see vignette(\"vignette_overview\") overview. series NICE Technical Support Documents evidence synthesis gives detailed introduction network meta-analysis: TSD_evsynthmultinma Multilevel network meta-regression set following methods paper: methods_papermultinma","code":""},{"path":[]},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/multinma-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"multinma: A Package for Network Meta-Analysis of Individual and Aggregate Data in Stan — multinma-package","text":"Maintainer: David M. Phillippo david.phillippo@bristol.ac.uk (ORCID)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Newly diagnosed multiple myeloma — ndmm_ipd","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"Three data frames, ndmm_ipd, ndmm_agd, ndmm_agd_covs containing (simulated) individual patient data (IPD) three studies aggregate data (AgD) two studies newly diagnosed multiple myeloma. outcome interest progression-free survival autologous stem cell transplant. IPD studies ndmm_ipd provide event/censoring times covariate values individual. AgD studies provide reconstructed event/censoring times digitized Kaplan-Meier curves ndmm_agd covariate summaries ndmm_agd_covs, obtained published trial reports. data constructed resemble used Leahy2019;textualmultinma.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"","code":"ndmm_ipd  ndmm_agd  ndmm_agd_covs"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/ndmm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Newly diagnosed multiple myeloma — ndmm_ipd","text":"individual patient data contained data frame ndmm_ipd 1325 rows, one per individual, 10 variables: study, studyf study name trt, trtf treatment name eventtime event/censoring time status censoring indicator (0 = censored, 1 = event) age age (years) iss_stage3 ISS stage 3 (0 = , 1 = yes) response_cr_vgpr complete good partial response (0 = , 1 = yes) male male sex (0 = , 1 = yes) reconstructed Kaplan-Meier data aggregate studies contained data frame ndmm_agd 2819 rows 6 variables: study, studyf study name trt, trtf treatment name eventtime event/censoring time status censoring indicator (0 = censored, 1 = event) covariate summaries extracted published reportes aggregate studies contained data frame ndmm_agd_covs 4 rows, one per study arm, 15 columns: study, studyf study name trt, trtf treatment name sample_size sample size arm age_min, age_iqr_l, age_median, age_iqr_h, age_max, age_mean, age_sd summary statistics age (years) iss_stage3 proportion participants ISS stage 3 response_cr_vgpr proportion participants complete good partial response male proportion male participants","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Network meta-analysis models — nma","title":"Network meta-analysis models — nma","text":"nma function fits network meta-analysis (multilevel) network meta-regression models Stan.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Network meta-analysis models — nma","text":"","code":"nma(   network,   consistency = c(\"consistency\", \"ume\", \"nodesplit\"),   trt_effects = c(\"fixed\", \"random\"),   regression = NULL,   class_interactions = c(\"common\", \"exchangeable\", \"independent\"),   likelihood = NULL,   link = NULL,   ...,   nodesplit = get_nodesplits(network, include_consistency = TRUE),   prior_intercept = .default(normal(scale = 100)),   prior_trt = .default(normal(scale = 10)),   prior_het = .default(half_normal(scale = 5)),   prior_het_type = c(\"sd\", \"var\", \"prec\"),   prior_reg = .default(normal(scale = 10)),   prior_aux = .default(),   prior_aux_reg = .default(),   aux_by = NULL,   aux_regression = NULL,   QR = FALSE,   center = TRUE,   adapt_delta = NULL,   int_thin = 0,   int_check = TRUE,   mspline_degree = 3,   n_knots = 7,   knots = NULL,   mspline_basis = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Network meta-analysis models — nma","text":"network nma_data object, created functions set_*(), combine_network(), add_integration() consistency Character string specifying type ()consistency model fit, either \"consistency\", \"ume\", \"nodesplit\" trt_effects Character string specifying either \"fixed\" \"random\" effects regression one-sided model formula, specifying prognostic effect-modifying terms regression model. references treatment use .trt special variable, example specifying effect modifier interactions variable:.trt (see details). class_interactions Character string specifying whether effect modifier interactions specified \"common\", \"exchangeable\", \"independent\". likelihood Character string specifying likelihood, unspecified inferred data (see details) link Character string specifying link function, unspecified default canonical link (see details) ... arguments passed sampling(), iter, chains, cores, etc. nodesplit consistency = \"nodesplit\", comparison(s) split node-splitting model(s). Either length 2 vector giving treatments single comparison, 2 column data frame listing multiple treatment comparisons split turn. default, possible comparisons chosen (see get_nodesplits()). prior_intercept Specification prior distribution intercept prior_trt Specification prior distribution treatment effects prior_het Specification prior distribution heterogeneity (trt_effects = \"random\") prior_het_type Character string specifying whether prior distribution prior_het placed heterogeneity standard deviation \\(\\tau\\) (\"sd\", default), variance \\(\\tau^2\\) (\"var\"), precision \\(1/\\tau^2\\) (\"prec\"). prior_reg Specification prior distribution regression coefficients (regression formula specified) prior_aux Specification prior distribution auxiliary parameter, applicable (see details). likelihood = \"gengamma\" list prior distributions elements sigma k. prior_aux_reg Specification prior distribution auxiliary regression parameters, aux_regression specified (see details). aux_by Vector variable names listing variables stratify auxiliary parameters . Currently used survival models, see details. used aux_regression. aux_regression one-sided model formula giving regression model auxiliary parameters. Currently used survival models, see details. used aux_by. QR Logical scalar (default FALSE), whether apply QR decomposition model design matrix center Logical scalar (default TRUE), whether center (numeric) regression terms overall means adapt_delta See adapt_delta details int_thin single integer value, thinning factor returning cumulative estimates integration error. Saving cumulative estimates disabled int_thin = 0, default. int_check Logical, check sufficient accuracy numerical integration fitting half chains n_int/2? TRUE, Rhat n_eff diagnostic warnings given numerical integration sufficiently converged (suggesting increasing n_int add_integration()). Default TRUE, disabled (FALSE) int_thin > 0. mspline_degree Non-negative integer giving degree M-spline polynomial likelihood = \"mspline\". Piecewise exponential hazards (likelihood = \"pexp\") special case mspline_degree = 0. n_knots mspline pexp likelihoods, non-negative integer giving number internal knots partitioning baseline hazard intervals. knot locations within study determined corresponding quantiles observed event times, plus boundary knots earliest entry time (0 delayed entry) maximum event/censoring time. example, n_knots = 3, internal knot locations 25%, 50%, 75% quantiles observed event times. default n_knots = 7; overfitting avoided shrinking towards constant hazard random walk prior (see details). aux_regression specified single set knot locations calculated across studies network. See make_knots() details knot positioning algorithms. Ignored knots specified. knots mspline pexp likelihoods, named list numeric vectors knot locations (including boundary knots) studies network. Currently, vector must length (.e. study must use number knots). Alternatively, single numeric vector knot locations can provided shared across studies network. unspecified (default), knots chosen based n_knots described . aux_regression specified knots single numeric vector knot locations shared across studies network. make_knots() can used help specify knots directly, investigate knot placement prior model fitting. mspline_basis Instead specifying mspline_degree n_knots knots, named list M-spline bases (one study) can provided mspline_basis used directly. case, M-spline options ignored.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Network meta-analysis models — nma","text":"nma() returns stan_nma object, except consistency = \"nodesplit\" nma_nodesplit nma_nodesplit_df object returned. nma.fit() returns stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Network meta-analysis models — nma","text":"specifying model formula regression argument, usual formula syntax available (interpreted model.matrix()). additional requirement special variable .trt used refer treatment. example, effect modifier interactions specified variable:.trt. Prognostic (main) effects interactions can included together compactly variable*.trt, expands variable + variable:.trt (plus .trt, already NMA model). advanced user, additional specials .study .trtclass also available, refer studies (specified) treatment classes respectively. node-splitting models fitted (consistency = \"nodesplit\") special .omega available, indicating arms node-splitting inconsistency factor added. See ?priors details prior specification. Default prior distributions available, may appropriate particular setting raise warning used. attempt made tailor defaults data provided. Please consider appropriate prior distributions particular setting, accounting scales outcomes covariates, etc. function plot_prior_posterior() may useful examining influence chosen prior distributions posterior distributions, summary() method nma_prior objects prints prior intervals.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"likelihoods-and-link-functions","dir":"Reference","previous_headings":"","what":"Likelihoods and link functions","title":"Network meta-analysis models — nma","text":"Currently, following likelihoods link functions supported data type: bernoulli2 binomial2 likelihoods correspond two-parameter Binomial likelihood arm-based AgD, closely matches underlying Poisson Binomial distribution summarised aggregate outcomes ML-NMR model typical (one parameter) Binomial distribution @see @methods_papermultinma. cloglog link used, including offset log follow-time (.e. regression = ~offset(log(time))) results model log hazard @see @TSD2multinma. survival data, accelerated failure time models (exponential-aft, weibull-aft, lognormal, loglogistic, gamma, gengamma) parameterised treatment effects regression parameters log Survival Time Ratios (.e. coefficient \\(\\log(2)\\) means treatment covariate associated doubling expected survival time). can converted log Acceleration Factors using relation \\(\\log(\\mathrm{AF}) = -\\log(\\mathrm{STR})\\) (equivalently \\(\\mathrm{AF} = 1/\\mathrm{STR}\\)). details likelihood link function given TSD2;textualmultinma.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"auxiliary-parameters","dir":"Reference","previous_headings":"","what":"Auxiliary parameters","title":"Network meta-analysis models — nma","text":"Auxiliary parameters present following models.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"normal-likelihood-with-ipd","dir":"Reference","previous_headings":"","what":"Normal likelihood with IPD","title":"Network meta-analysis models — nma","text":"Normal likelihood fitted IPD, auxiliary parameters arm-level standard deviations \\(\\sigma_{jk}\\) treatment \\(k\\) study \\(j\\).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"ordered-multinomial-likelihood","dir":"Reference","previous_headings":"","what":"Ordered multinomial likelihood","title":"Network meta-analysis models — nma","text":"fitting model \\(M\\) ordered outcomes, auxiliary parameters latent cutoffs category, \\(c_0 < c_1 < \\dots <   c_M\\). \\(c_2\\) \\(c_{M-1}\\) estimated; fix \\(c_0 =   -\\infty\\), \\(c_1 = 0\\), \\(c_M = \\infty\\). specifying priors latent cutoffs, choose specify priors differences \\(c_{m+1} - c_m\\). Stan automatically truncates priors ordering constraints satisfied.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma.html","id":"survival-time-to-event-likelihoods","dir":"Reference","previous_headings":"","what":"Survival (time-to-event) likelihoods","title":"Network meta-analysis models — nma","text":"survival likelihoods except exponential exponential-aft likelihoods auxiliary parameters. typically study-specific shape parameters \\(\\gamma_j>0\\), except lognormal likelihood auxiliary parameters study-specific standard deviations log scale \\(\\sigma_j>0\\). gengamma likelihood two sets auxiliary parameters, study-specific scale parameters \\(\\sigma_j>0\\) shape parameters \\(k_j\\), following parameterisation Lawless1980;textualmultinma, permits range behaviours baseline hazard including increasing, decreasing, bathtub arc-shaped hazards. parameterisation related discussed Cox2007;textualmultinma implemented flexsurv package \\(Q = k^{-0.5}\\). parameterisation used effectively bounds shape parameter \\(k\\) away numerical instabilities \\(k \\rightarrow \\infty\\) (.e. away \\(Q   \\rightarrow 0\\), log-Normal distribution) via prior distribution. Implicitly, parameterisation restricted \\(Q > 0\\) certain survival distributions like inverse-Gamma inverse-Weibull part parameter space; however, \\(Q > 0\\) still encompasses survival distributions implemented package. mspline pexp likelihoods, auxiliary parameters spline coefficients study. form unit simplex (.e. lie 0 1, sum 1), given random walk prior distribution. prior_aux specifies hyperprior random walk standard deviation \\(\\sigma\\) controls level smoothing baseline hazard, \\(\\sigma = 0\\) corresponding constant baseline hazard. auxiliary parameters can stratified additional factors aux_by argument. example, allow shape baseline hazard vary treatment arms well studies, use aux_by = c(\".study\", \".trt\"). (Technically, .study always included stratification even omitted aux_by, choose make stratification explicit.) common way relaxing proportional hazards assumption. default equivalent aux_by = \".study\" stratifies auxiliary parameters study, described . regression model may specified auxiliary parameters using aux_regression. useful wish model departures non-proportionality, rather allowing baseline hazards completely independent using aux_by. necessary absolute predictions (e.g. survival curves) required population unobserved combinations covariates; example, aux_by = .trt absolute predictions may produced observed treatment arms study population, whereas aux_regression = ~.trt absolute predictions can produced treatments population. mspline pexp likelihoods, regression coefficients smoothed time using random walk prior avoid overfitting: prior_aux_reg specifies hyperprior random walk standard deviation. parametric likelihoods, prior_aux_reg specifies prior auxiliary regression coefficients.","code":""},{"path":[]},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_data-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_data class — nma_data-class","title":"The nma_data class — nma_data-class","text":"nma_data class contains data NMA standard format, created using functions set_ipd(), set_agd_arm(), set_agd_contrast(), set_agd_surv(), combine_network(). sub-class mlnmr_data created function add_integration(), contains numerical integration points aggregate data.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_data-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_data class — nma_data-class","text":"Objects class nma_data following components: agd_arm data studies aggregate data (arm format) agd_contrast data studies aggregate data (contrast format) ipd data studies individual patient data treatments treatment coding factor entire network classes treatment class coding factor (length treatments entire network) studies study coding factor entire network outcome outcome type data source, named list agd_arm, agd_contrast, ipd components tibbles following columns: .study study (factor) .trt treatment (factor) .trtclass treatment class (factor), specified .y continuous outcome .se standard error (continuous) .r event count (discrete) .n event count denominator (discrete, agd_arm ) .E time risk (discrete) .Surv survival outcome type Surv (time--event), nested study arm .sample_size sample size (agd_* ) ... columns (typically covariates) original data frame Objects class mlnmr_data additionally components: n_int number numerical integration points int_names names covariates numerical integration points int_cor correlation matrix covariates used generate numerical integration points agd_arm agd_contrast tibbles additional list columns prefix .int_, one covariate, contain numerical integration points nested length-n_int vectors within row.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_dic-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_dic class — nma_dic-class","title":"The nma_dic class — nma_dic-class","text":"nma_dic class contains details Deviance Information Criterion (DIC), produced using dic() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_dic-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_dic class — nma_dic-class","text":"Objects class nma_dic following components: dic DIC value pd, pv effective number parameters resdev total residual deviance pointwise list data frames containing pointwise contributions IPD AgD. resdev_array 3D MCMC array [Iterations, Chains, Parameters] posterior residual deviance samples.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_nodesplit-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_nodesplit class — nma_nodesplit-class","title":"The nma_nodesplit class — nma_nodesplit-class","text":"nma_nodesplit nma_nodesplit_df classes contains results running node-splitting model function nma().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_nodesplit-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_nodesplit class — nma_nodesplit-class","text":"Objects class nma_nodesplit inherit stan_nma class, contain results fitting single node-split model. one additional component, nodesplit, gives comparison node-split length 2 vector. Objects class nma_nodesplit_df tibble data frames one row node-split comparison columns: trt1, trt2 Treatments forming comparison model list column containing results model nma_nodesplit object Optionally, additional row consistency model fitted (e.g. get_nodesplits(., include_consistency = TRUE)) trt1 trt2 NA.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_prior-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_prior class — nma_prior-class","title":"The nma_prior class — nma_prior-class","text":"nma_prior class used specify prior distributions.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_prior-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_prior class — nma_prior-class","text":"Objects class nma_prior following components: dist Distribution name fun Name constructor function, string (e.g. \"normal\") ... Parameters distribution distribution parameters, specified named components ..., match constructor functions (see priors).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nma_summary class — nma_summary-class","title":"The nma_summary class — nma_summary-class","text":"nma_summary class contains posterior summary statistics model parameters quantities interest, draws used obtain statistics.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nma_summary class — nma_summary-class","text":"Objects class nma_summary following components: summary data frame containing computed summary statistics. Column .trt indicates corresponding treatment, columns .trta .trtb indicate corresponding contrast (.trtb vs. .trta). regression model fitted effect modifier interactions treatment, summaries study-specific. case, corresponding study population indicated .study column. multinomial model fitted, .category column indicates corresponding category. sims 3D array [Iteration, Chain, Parameter] MCMC simulations studies (Optional) data frame containing study information, printed along corresponding summary statistics summary contains .study column. matching .study column. following attributes may also set: xlab Label x axis plots, usually either \"Treatment\" \"Contrast\". ylab Label y axis plots, usually used scale e.g. \"log Odds Ratio\". subclass nma_rank_probs used function posterior_rank_probs(), contains posterior rank probabilities. subclass sims component, rank probabilities posterior summaries ranks (.e. posterior distribution). posterior ranks rank probabilities calculated may obtained posterior_ranks().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for nma_summary objects — print.nma_summary","title":"Methods for nma_summary objects — print.nma_summary","text":".data.frame(), as_tibble(), .tibble() methods return posterior summary statistics data frame tibble. .matrix() method returns matrix posterior draws. .array() method returns 3D array [Iteration, Chain, Parameter] posterior draws (class mcmc_array).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for nma_summary objects — print.nma_summary","text":"","code":"# S3 method for class 'nma_summary' print(x, ..., digits = 2, pars, include = TRUE)  # S3 method for class 'nma_summary' as.data.frame(x, ...)  # S3 method for class 'nma_summary' as.tibble(x, ...)  # S3 method for class 'nma_summary' as_tibble(x, ...)  # S3 method for class 'nma_summary' as.array(x, ...)  # S3 method for class 'nma_summary' as.matrix(x, ...)  # S3 method for class 'nma_rank_probs' as.array(x, ...)  # S3 method for class 'nma_rank_probs' as.matrix(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for nma_summary objects — print.nma_summary","text":"x nma_summary object ... Additional arguments passed methods digits Integer number digits display pars Character vector parameters display printed summary include Logical, parameters named pars included (TRUE) excluded (FALSE)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nma_summary-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for nma_summary objects — print.nma_summary","text":"data.frame .data.frame(), tbl_df .tibble() as_tibble(), matrix .matrix(), mcmc_array .array(). print() method returns x invisibly.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The nodesplit_summary class — nodesplit_summary-class","title":"The nodesplit_summary class — nodesplit_summary-class","text":"nodesplit_summary class contains posterior summary statistics node-splitting models, result calling summary() nma_nodesplit nma_nodesplit_df object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The nodesplit_summary class — nodesplit_summary-class","text":"Objects class nodesplit_summary tibble data frames, one row node-split comparison columns: trt1, trt2 Treatments forming comparison summary list column containing nma_summary objects posterior summaries draws node-splitting parameters p_value Bayesian p-value inconsistency dic list column containing nma_dic objects, giving model fit statistics parameters included summary : d_net Network estimate corresponding consistency model, available d_dir Direct estimate node-splitting model d_ind Indirect estimate node-splitting model omega Inconsistency factor \\(\\omega = d_\\mathrm{dir} -   d_\\mathrm{ind}\\) tau Heterogeneity standard deviation node-splitting model, random effects model fitted tau_consistency Heterogeneity standard deviation corresponding consistency model, available random effects model fitted","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for nodesplit_summary objects — print.nodesplit_summary","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":".data.frame(), as_tibble(), .tibble() methods return node-splitting summaries data frame tibble.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"","code":"# S3 method for class 'nodesplit_summary' print(x, ..., digits = 2)  # S3 method for class 'nodesplit_summary' as_tibble(x, ..., nest = FALSE)  as.tibble.nodesplit_summary(x, ..., nest = FALSE)  # S3 method for class 'nodesplit_summary' as.data.frame(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"x nodesplit_summary object ... Additional arguments passed methods digits Integer number digits display nest Whether return nested tibble, full nma_summary nma_dic objects, unnest summaries, default FALSE","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/nodesplit_summary-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for nodesplit_summary objects — print.nodesplit_summary","text":"data.frame .data.frame(), tbl_df .tibble() as_tibble(). print() method returns x invisibly.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix of plots for a stan_nma object — pairs.stan_nma","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"pairs() method stan_nma objects, calls bayesplot::mcmc_pairs() underlying stanfit object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"","code":"# S3 method for class 'stan_nma' pairs(x, ..., pars, include = TRUE)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"x object class stan_nma ... arguments passed bayesplot::mcmc_pairs() pars Optional character vector parameter names include output. specified, parameters used. include Logical, parameters pars included (TRUE, default) excluded (FALSE)?","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"grid ggplot objects produced bayesplot::mcmc_pairs().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/pairs.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix of plots for a stan_nma object — pairs.stan_nma","text":"","code":"if (FALSE) { # \\dontrun{ ## Parkinson's mean off time reduction park_net <- set_agd_arm(parkinsons,                         study = studyn,                         trt = trtn,                         y = y,                         se = se,                         sample_size = n)  # Fitting a RE model park_fit_RE <- nma(park_net,                    trt_effects = \"random\",                    prior_intercept = normal(scale = 100),                    prior_trt = normal(scale = 100),                    prior_het = half_normal(scale = 5))  # We see a small number of divergent transition errors # These do not go away entirely when adapt_delta is increased  # Try to diagnose with a pairs plot pairs(park_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\"))  # Transforming tau onto log scale pairs(park_fit_RE, pars = c(\"mu[4]\", \"d[3]\", \"delta[4: 3]\", \"tau\"),       transformations = list(tau = \"log\"))  # The divergent transitions occur in the upper tail of the heterogeneity # standard deviation. In this case, with only a small number of studies, there # is not very much information to estimate the heterogeneity standard deviation # and the prior distribution may be too heavy-tailed. We could consider a more # informative prior distribution for the heterogeneity variance to aid # estimation. } # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean off-time reduction in Parkison's disease — parkinsons","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"Data frame containing mean -time reduction patients given dopamine agonists adjunct therapy Parkinson's disease, 7 trials comparing four active drugs placebo TSD2multinma.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"","code":"parkinsons"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"data frame 15 rows 7 variables: studyn numeric study ID trtn numeric treatment code (placebo = 1) y mean -time reduction se standard error n sample size diff mean difference vs. treatment reference arm se_diff standard error mean difference, see details","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/parkinsons.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean off-time reduction in Parkison's disease — parkinsons","text":"dataset may analysed using either arm-based likelihood using y se, contrast-based likelihood using diff se_diff (combination two across different studies). contrast-based data formatted described set_agd_contrast(). , chosen reference arm study, mean difference diff set NA, se_diff set standard error se outcome reference arm.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":null,"dir":"Reference","previous_headings":"","what":"Plaque psoriasis data — plaque_psoriasis_ipd","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"Two data frames, plaque_psoriasis_ipd plaque_psoriasis_agd, containing (simulated) individual patient data four studies aggregate data five studies Phillippo_thesismultinma. Outcomes binary success/failure achieve 75%, 90%, 100% reduction symptoms Psoriasis Area Severity Index (PASI) scale.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"","code":"plaque_psoriasis_ipd  plaque_psoriasis_agd"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plaque_psoriasis.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Plaque psoriasis data — plaque_psoriasis_ipd","text":"individual patient data contained data frame plaque_psoriasis_ipd 4118 rows, one per individual, 16 variables: studyc study name trtc_long treatment name (long format) trtc treatment name trtn numeric treatment code pasi75 binary PASI 75 outcome pasi90 binary PASI 90 outcome pasi100 binary PASI 100 outcome age age (years) bmi body mass index (BMI) pasi_w0 PASI score week 0 male male sex (TRUE FALSE) bsa body surface area (percent) weight weight (kilograms) durnpso duration psoriasis (years) prevsys previous systemic treatment (TRUE FALSE) psa psoriatic arthritis (TRUE FALSE) aggregate data contained data frame plaque_psoriasis_agd 15 rows, one per study arm, 26 variables: studyc study name trtc_long treatment name (long format) trtc treatment name trtn numeric treatment code pasi75_r, pasi75_n PASI 75 outcome count denominator pasi90_r, pasi90_n PASI 75 outcome count denominator pasi100_r, pasi100_n PASI 75 outcome count denominator sample_size_w0 sample size week zero age_mean, age_sd mean standard deviation age (years) bmi_mean, bmi_sd mean standard deviation BMI pasi_w0_mean, pasi_w0_sd mean standard deviation PASI score week 0 male percentage males bsa_mean, bsa_sd mean standard deviation body surface area (percent) weight_mean, weight_sd mean standard deviation weight (kilograms) durnpso_mean, durnpso_sd mean standard deviation duration psoriasis (years) prevsys percentage individuals previous systemic treatment psa percentage individuals psoriatic arthritis object class data.frame 15 rows 26 columns.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Network plots — plot.nma_data","title":"Network plots — plot.nma_data","text":"Create network plot nma_data network object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Network plots — plot.nma_data","text":"","code":"# S3 method for class 'nma_data' plot(   x,   ...,   layout,   circular,   weight_edges = TRUE,   weight_nodes = FALSE,   show_trt_class = FALSE,   nudge = 0 )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Network plots — plot.nma_data","text":"x nma_data object plot ... Additional arguments passed ggraph() layout function layout type layout create. layout accepted ggraph() may used, including layout functions provided igraph. circular Whether use circular representation. See ggraph(). weight_edges Weight edges number studies? Default TRUE. weight_nodes Weight nodes total sample size? Default FALSE. show_trt_class Colour treatment nodes class, trt_class set? Default FALSE. nudge Numeric value nudge treatment labels away nodes weight_nodes = TRUE. Default 0 (adjustment label position). small value like 0.1 usually sufficient.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Network plots — plot.nma_data","text":"ggplot object, produced ggraph().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Network plots — plot.nma_data","text":"default equivalent layout = \"linear\" circular = TRUE, places treatment nodes circle order defined treatment factor variable. alternative layout may give good results simple networks \"sugiyama\", attempts minimise number edge crossings. weight_nodes = TRUE requires sample sizes specified aggregate data network, using sample_size option set_agd_*().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Network plots — plot.nma_data","text":"","code":"## Stroke prevention in atrial fibrillation # Setting up the network af_net <- set_agd_arm(atrial_fibrillation,                       study = studyc,                       trt = abbreviate(trtc, minlength = 3),                       r = r,                       n = n,                       trt_class = trt_class) af_net #> A network with 26 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study         Treatment arms                #>  ACTIVE-W      2: Sada | Lda+c               #>  AFASAK 1      3: Sada | Lda | P/c           #>  AFASAK 2      4: Sada | Fdw | Fdw+mda | Mda #>  BAATAF        2: Lada | P/c                 #>  BAFTA         2: Sada | Lda                 #>  CAFA          2: Sada | P/c                 #>  Chinese ATAFS 2: Sada | Lda                 #>  EAFT          3: Sada | Mda | P/c           #>  ESPS 2        4: Dpy | Lda | Lda+d | P/c    #>  JAST          2: Lda | P/c                  #>  ... plus 16 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 17, in 4 classes #> Total number of studies: 26 #> Reference treatment is: Sada #> Network is connected  # Basic plot plot(af_net)   # Turn off weighting edges by number of studies plot(af_net, weight_edges = FALSE)   # Turn on weighting nodes by sample size plot(af_net, weight_nodes = TRUE)   # Colour treatment nodes by class plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE)   # Nudge the treatment labels away from the nodes plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE, nudge = 0.1)   # Output may be customised using standard ggplot commands # For example, to display the legends below the plot: plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE) +   ggplot2::theme(legend.position = \"bottom\",                  legend.box = \"vertical\",                  legend.margin = ggplot2::margin(0, 0, 0, 0),                  legend.spacing = ggplot2::unit(0.5, \"lines\"))   # Choosing a different ggraph layout, hiding some legends plot(af_net, weight_nodes = TRUE, show_trt_class = TRUE,      layout = \"star\") +   ggplot2::guides(edge_width = \"none\", size = \"none\")"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of model fit diagnostics — plot.nma_dic","title":"Plots of model fit diagnostics — plot.nma_dic","text":"plot() method nma_dic objects produced dic() produces several useful diagnostic plots checking model fit model comparison. detail plots interpretation given TSD2;textualmultinma.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of model fit diagnostics — plot.nma_dic","text":"","code":"# S3 method for class 'nma_dic' plot(   x,   y,   ...,   type = c(\"resdev\", \"leverage\"),   show_uncertainty = TRUE,   stat = \"pointinterval\",   orientation = c(\"vertical\", \"horizontal\", \"x\", \"y\"),   dic_contours = 1:4 )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of model fit diagnostics — plot.nma_dic","text":"x nma_dic object y (Optional) second nma_dic object, produce \"dev-dev\" plots model comparison. ... Additional arguments passed methods type single nma_dic object, whether show residual deviance contribution data point (\"resdev\", default), leverage plot (\"leverage\"). show_uncertainty Logical, show uncertainty ggdist plot stat? Default TRUE. Ignored type = \"leverage\". stat Character string specifying ggdist plot stat use show_uncertainty = TRUE, default \"pointinterval\". y provided, currently \"pointinterval\" supported. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"). used residual deviance plots, default \"vertical\". dic_contours Numeric vector DIC contribution contours show leverage plots, default 1:4.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of model fit diagnostics — plot.nma_dic","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of model fit diagnostics — plot.nma_dic","text":"single nma_dic object given, default plot (type = \"resdev\") shows residual deviance contribution data point. good fitting model, data point expected residual deviance equal degrees freedom (typically 1, except multi-arm trials contrast format multinomial outcomes); larger values indicate data points fit poorly model. leverage plot can produced type = \"leverage\", plotting leverages (contributions \\(p_D\\)) signed square root residual deviance, standardised degrees freedom. Contours different DIC contribution cutoffs also shown; points lie outside DIC=3 contour generally identified contributing model's poor fit. two nma_dic objects given, \"dev-dev\" plot comparing residual deviance contributions model produced. Data points residual deviance contributions lying line equality fit equally well either model. Data points lying line equality indicate better fit second model (y); conversely, data points lying line equality indicate better fit first model (x). common use case compare standard consistency model (fitted using nma() consistency = \"consistency\") unrelated mean effects (UME) inconsistency model (fitted using nma() consistency = \"ume\"), check potential inconsistency. See TSD2;textualmultinma details.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_dic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of model fit diagnostics — plot.nma_dic","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking FE NMA example if not already available if (!exists(\"smk_fit_FE\")) example(\"example_smk_fe\", run.donttest = TRUE) # } # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC of FE and RE models (smk_dic_FE <- dic(smk_fit_FE)) #> Residual deviance: 267.2 (on 50 data points) #>                pD: 27.1 #>               DIC: 294.2 (smk_dic_RE <- dic(smk_fit_RE))   # substantially better fit #> Residual deviance: 53.8 (on 50 data points) #>                pD: 43.7 #>               DIC: 97.5  # Plot residual deviance contributions under RE model plot(smk_dic_RE)   # Further customisation is possible using ggplot commands # For example, highlighting data points with residual deviance above a certain threshold plot(smk_dic_RE) +   ggplot2::aes(colour = ggplot2::after_stat(ifelse(y > 1.5, \"darkorange\", \"black\"))) +   ggplot2::scale_colour_identity()   # Or by posterior probability, for example here a central probability of 0.6 # corresponds to a lower tail probability of (1 - 0.6)/2 = 0.2 plot(smk_dic_RE, .width = c(0.6, 0.95)) +   ggplot2::aes(colour = ggplot2::after_stat(ifelse(ymin > 1, \"darkorange\", \"black\"))) +   ggplot2::scale_colour_identity()   # Leverage plot for RE model plot(smk_dic_RE, type = \"leverage\")   # Check for inconsistency using UME model # } # \\donttest{ # Run smoking UME NMA example if not already available if (!exists(\"smk_fit_RE_UME\")) example(\"example_smk_ume\", run.donttest = TRUE) # } # \\donttest{ # Compare DIC smk_dic_RE #> Residual deviance: 53.8 (on 50 data points) #>                pD: 43.7 #>               DIC: 97.5 (smk_dic_RE_UME <- dic(smk_fit_RE_UME))  # no difference in fit #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44.8 #>               DIC: 98.4  # Compare residual deviance contributions with a \"dev-dev\" plot plot(smk_dic_RE, smk_dic_RE_UME)   # By default the dev-dev plot can be a little cluttered # Hiding the credible intervals plot(smk_dic_RE, smk_dic_RE_UME, show_uncertainty = FALSE)   # Changing transparency plot(smk_dic_RE, smk_dic_RE_UME, point_alpha = 0.5, interval_alpha = 0.1)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of summary results — plot.nma_summary","title":"Plots of summary results — plot.nma_summary","text":"plot method nma_summary objects used produce plots parameter estimates (called stan_nma object summary), relative effects (called output relative_effects()), absolute predictions (called output predict.stan_nma()), posterior ranks rank probabilities (called output posterior_ranks() posterior_rank_probs()).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of summary results — plot.nma_summary","text":"","code":"# S3 method for class 'nma_summary' plot(   x,   ...,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )  # S3 method for class 'nma_parameter_summary' plot(   x,   ...,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )  # S3 method for class 'nma_rank_probs' plot(x, ...)  # S3 method for class 'surv_nma_summary' plot(x, ..., stat = \"lineribbon\")"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of summary results — plot.nma_summary","text":"x nma_summary object ... Additional arguments passed underlying ggdist plot stat, see Details stat Character string specifying ggdist plot stat use, default \"pointinterval\", except plotting estimated survival/hazard/cumulative hazard curves survival models default \"lineribbon\" orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\" ref_line Numeric vector positions reference lines, default reference lines drawn","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of summary results — plot.nma_summary","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of summary results — plot.nma_summary","text":"Plotting handled ggplot2 stats geoms provided ggdist package. result, output flexible. plotting stats provided ggdist may used, via argument stat. default uses ggdist::stat_pointinterval(), produce medians 95% Credible Intervals 66% inner bands. Additional arguments ... passed ggdist stat, customise output. example, produce means Credible Intervals, specify point_interval = \"mean_qi\". produce 80% Credible Interval inner band, specify .width = c(0, 0.8). Alternative stats can specified produce different summaries. example, specify stat = \"[half]eye\" produce (half) eye plots, stat = \"histinterval\" produce histograms intervals. full list options examples found ggdist vignette vignette(\"slabinterval\", package = \"ggdist\"). survival/hazard/cumulative hazard curves estimated survival models, default uses ggdist::stat_lineribbon() produces curves posterior medians 50%, 80%, 95% Credible Interval bands. , additional arguments ... passed ggdist stat. example, produce posterior means 95% Credible bands, specify point_interval = \"mean_qi\" .width = 0.95. ggplot object returned can modified usual ggplot2 functions add aesthetics, geoms, themes, etc.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nma_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of summary results — plot.nma_summary","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce relative effects smk_releff_RE <- relative_effects(smk_fit_RE) plot(smk_releff_RE, ref_line = 0)   # Customise plot options plot(smk_releff_RE, ref_line = 0, stat = \"halfeye\")   # Further customisation is possible with ggplot commands plot(smk_releff_RE, ref_line = 0, stat = \"halfeye\", slab_alpha = 0.6) +   ggplot2::aes(slab_fill = ggplot2::after_stat(ifelse(x < 0, \"darkred\", \"grey60\")))   # Produce posterior ranks smk_rank_RE <- posterior_ranks(smk_fit_RE, lower_better = FALSE) plot(smk_rank_RE)   # Produce rank probabilities smk_rankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE) plot(smk_rankprob_RE)   # Produce cumulative rank probabilities smk_cumrankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE,                                            cumulative = TRUE) plot(smk_cumrankprob_RE)   # Further customisation is possible with ggplot commands plot(smk_cumrankprob_RE) +   ggplot2::facet_null() +   ggplot2::aes(colour = Treatment)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of node-splitting models — plot.nodesplit_summary","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"Produce summary plots node-splitting models","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"","code":"# S3 method for class 'nodesplit_summary' plot(   x,   ...,   pars = \"d\",   stat = \"dens_overlay\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"x nodesplit_summary object. ... Additional arguments passed underlying ggdist plot stat, see Details. pars Character vector specifying parameters include plot, choices include \"d\" direct, indirect, network estimates relative effects, \"omega\" inconsistency factor, \"tau\" heterogeneity standard deviation random effects models. Default \"d\". stat Character string specifying ggdist plot stat use. default \"dens_overlay\" special case, producing overlaid density plot. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\". ref_line Numeric vector positions reference lines, default reference lines drawn.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"Plotting handled ggplot2 stats geoms provided ggdist package. result, output flexible. plotting stats provided ggdist may used, via argument stat. default \"dens_overlay\" special exception, uses ggplot2::geom_density(), plot overlaid densities. Additional arguments ... passed ggdist stat, customise output. Alternative stats can specified produce different summaries. example, specify stat = \"[half]eye\" produce (half) eye plots, stat = \"pointinterval\" produce point estimates credible intervals. full list options examples found ggdist vignette vignette(\"slabinterval\", package = \"ggdist\"). ggplot object returned can modified usual ggplot2 functions add aesthetics, geoms, themes, etc.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot.nodesplit_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of node-splitting models — plot.nodesplit_summary","text":"","code":"# \\donttest{ # Run smoking node-splitting example if not already available if (!exists(\"smk_fit_RE_nodesplit\")) example(\"example_smk_nodesplit\", run.donttest = TRUE) #>  #> exmp__> # Set up network of smoking cessation data #> exmp__> head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170 #>  #> exmp__> smk_net <- set_agd_arm(smoking, #> exmp__+                        study = studyn, #> exmp__+                        trt = trtc, #> exmp__+                        r = r, #> exmp__+                        n = n, #> exmp__+                        trt_ref = \"No intervention\") #>  #> exmp__> # Print details #> exmp__> smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected #>  #> exmp__> ## No test:  #> exmp__> # Fitting all possible node-splitting models #> exmp__> smk_fit_RE_nodesplit <- nma(smk_net, ## Don't show:  #> exmp__+ refresh = if (interactive()) 200 else 0, #> exmp__+ ## End(Don't show) #> exmp__+                             consistency = \"nodesplit\", #> exmp__+                             trt_effects = \"random\", #> exmp__+                             prior_intercept = normal(scale = 100), #> exmp__+                             prior_trt = normal(scale = 100), #> exmp__+                             prior_het = normal(scale = 5)) #> Fitting model 1 of 7, node-split: Group counselling vs. No intervention #> Fitting model 2 of 7, node-split: Individual counselling vs. No intervention #> Fitting model 3 of 7, node-split: Self-help vs. No intervention #> Fitting model 4 of 7, node-split: Individual counselling vs. Group counselling #> Fitting model 5 of 7, node-split: Self-help vs. Group counselling #> Fitting model 6 of 7, node-split: Self-help vs. Individual counselling #> Fitting model 7 of 7, consistency model #>  #> exmp__> ## End(No test) #> exmp__>  #> exmp__> ## Don't show:  #> exmp__> if (requireNamespace(\"pkgdown\", quietly = TRUE) && pkgdown::in_pkgdown()) { #> exmp__+   assign(\"smk_net\", smk_net, .GlobalEnv) #> exmp__+   assign(\"smk_fit_RE_nodesplit\", smk_fit_RE_nodesplit, .GlobalEnv) #> exmp__+ } #>  #> exmp__> ## End(Don't show) #> exmp__>  #> exmp__>  #> exmp__>  # } # \\donttest{ # Summarise the node-splitting results (smk_nodesplit_summary <- summary(smk_fit_RE_nodesplit)) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.11 0.44  0.30  0.82  1.10 1.38  2.00     2000     2306    1 #> d_dir            1.08 0.74 -0.31  0.58  1.05 1.55  2.58     3392     2712    1 #> d_ind            1.12 0.55  0.07  0.77  1.12 1.48  2.17     1637     2163    1 #> omega           -0.05 0.90 -1.79 -0.65 -0.07 0.53  1.83     2205     2310    1 #> tau              0.87 0.20  0.55  0.73  0.85 0.99  1.34     1171     1658    1 #> tau_consistency  0.84 0.19  0.55  0.71  0.82 0.95  1.29     1314     1713    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 43.8 #>               DIC: 97.4 #>  #> Bayesian p-value: 0.94 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.84 0.24  0.38  0.69 0.84 1.00  1.32     1237     1718    1 #> d_dir           0.88 0.26  0.39  0.70 0.87 1.04  1.40     1371     1797    1 #> d_ind           0.56 0.69 -0.78  0.09 0.55 0.99  1.95     1345     1649    1 #> omega           0.31 0.71 -1.09 -0.14 0.33 0.78  1.74     1411     1773    1 #> tau             0.87 0.20  0.55  0.72 0.84 0.98  1.33     1143     2092    1 #> tau_consistency 0.84 0.19  0.55  0.71 0.82 0.95  1.29     1314     1713    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.4 #>  #> Bayesian p-value: 0.64 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.51 0.40 -0.26  0.25  0.50 0.75  1.30     2087     2276 1.00 #> d_dir            0.33 0.54 -0.76 -0.01  0.32 0.66  1.43     3295     2569 1.00 #> d_ind            0.71 0.62 -0.52  0.30  0.72 1.12  1.94     2329     2835 1.00 #> omega           -0.38 0.82 -1.94 -0.92 -0.39 0.15  1.27     2479     2626 1.00 #> tau              0.88 0.20  0.57  0.74  0.85 0.99  1.33     1114     1538 1.01 #> tau_consistency  0.84 0.19  0.55  0.71  0.82 0.95  1.29     1314     1713 1.00 #>  #> Residual deviance: 53.7 (on 50 data points) #>                pD: 44.2 #>               DIC: 98 #>  #> Bayesian p-value: 0.62 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.26 0.41 -1.09 -0.53 -0.26  0.01  0.54     2760     2738    1 #> d_dir           -0.10 0.50 -1.09 -0.44 -0.10  0.23  0.87     3180     3177    1 #> d_ind           -0.55 0.61 -1.78 -0.95 -0.55 -0.15  0.64     1707     2182    1 #> omega            0.45 0.68 -0.89  0.00  0.45  0.89  1.80     1631     1984    1 #> tau              0.87 0.20  0.57  0.73  0.84  0.98  1.33     1275     1693    1 #> tau_consistency  0.84 0.19  0.55  0.71  0.82  0.95  1.29     1314     1713    1 #>  #> Residual deviance: 53.4 (on 50 data points) #>                pD: 43.9 #>               DIC: 97.3 #>  #> Bayesian p-value: 0.5 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.60 0.48 -1.57 -0.90 -0.60 -0.28  0.30     2989     2245    1 #> d_dir           -0.60 0.65 -1.90 -1.02 -0.60 -0.18  0.72     3690     3112    1 #> d_ind           -0.63 0.66 -1.92 -1.07 -0.64 -0.20  0.67     1966     2537    1 #> omega            0.02 0.87 -1.66 -0.54  0.02  0.58  1.72     1983     1936    1 #> tau              0.87 0.20  0.56  0.73  0.84  0.98  1.32     1077     1882    1 #> tau_consistency  0.84 0.19  0.55  0.71  0.82  0.95  1.29     1314     1713    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.5 #>  #> Bayesian p-value: 0.97 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.34 0.40 -1.11 -0.60 -0.33 -0.08  0.48     2355     2418    1 #> d_dir            0.05 0.64 -1.24 -0.37  0.05  0.46  1.33     3370     2887    1 #> d_ind           -0.64 0.53 -1.70 -0.98 -0.63 -0.29  0.37     1939     2329    1 #> omega            0.70 0.81 -0.83  0.15  0.68  1.21  2.33     2371     2334    1 #> tau              0.86 0.20  0.56  0.72  0.83  0.96  1.33     1182     1691    1 #> tau_consistency  0.84 0.19  0.55  0.71  0.82  0.95  1.29     1314     1713    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44 #>               DIC: 97.6 #>  #> Bayesian p-value: 0.38  # Plot the node-splitting results plot(smk_nodesplit_summary)   # Plot the inconsistency factors instead, change the plot stat to half-eye, # and add a reference line at 0 plot(smk_nodesplit_summary, pars = \"omega\", stat = \"halfeye\", ref_line = 0)   # Plot a comparison of the heterogeneity under the node-split models vs. # the consistency model plot(smk_nodesplit_summary, pars = \"tau\")  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot numerical integration error — plot_integration_error","title":"Plot numerical integration error — plot_integration_error","text":"ML-NMR models, plot estimated numerical integration error entire posterior distribution, number integration points increases. See methods_paper,Phillippo_thesismultinma details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot numerical integration error — plot_integration_error","text":"","code":"plot_integration_error(   x,   ...,   stat = \"violin\",   orientation = c(\"vertical\", \"horizontal\", \"x\", \"y\"),   show_expected_rate = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot numerical integration error — plot_integration_error","text":"x object type stan_mlnmr ... Additional arguments passed ggdist plot stat. stat Character string specifying ggdist plot stat used summarise integration error posterior. Default \"violin\", equivalent \"eye\" cosmetic tweaks. orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"vertical\" show_expected_rate Logical, show typical convergence rate \\(1/N\\)? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot numerical integration error — plot_integration_error","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot numerical integration error — plot_integration_error","text":"total number integration points set n_int argument add_integration(), intervals integration error estimated set int_thin argument nma(). typical convergence rate Quasi-Monte Carlo integration (used ) \\(1/N\\), default displayed plot output. integration error thinning interval \\(N_\\mathrm{thin}\\) estimated point posterior distribution subtracting final estimate (using n_int points) estimate using first \\(N_\\mathrm{thin}\\) points.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_integration_error.html","id":"note-for-survival-models","dir":"Reference","previous_headings":"","what":"Note for survival models","title":"Plot numerical integration error — plot_integration_error","text":"function supported survival/time--event models. save cumulative integration points efficiency reasons (time memory).","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot prior vs posterior distribution — plot_prior_posterior","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"Produce plots comparing prior posterior distributions model parameters.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"","code":"plot_prior_posterior(   x,   ...,   prior = NULL,   post_args = list(),   prior_args = list(),   overlay = c(\"prior\", \"posterior\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"x stan_nma object ... Additional arguments passed methods prior Character vector selecting prior posterior distribution(s) plot. May include \"intercept\", \"trt\", \"het\", \"reg\", \"aux\", appropriate. post_args List arguments passed ggplot2::geom_histogram control plot output posterior distribution prior_args List arguments passed ggplot2::geom_path control plot output prior distribution. Additionally, n controls number points density curve evaluated (default 500), p_limits controls endpoints curve quantiles (default c(.001, .999)). overlay String, prior posterior shown top? Default \"prior\". ref_line Numeric vector positions reference lines, default reference lines drawn","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"ggplot object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"Prior distributions displayed lines, posterior distributions displayed histograms.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/plot_prior_posterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot prior vs posterior distribution — plot_prior_posterior","text":"","code":"## Smoking cessation NMA # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Plot prior vs. posterior, by default all parameters are plotted plot_prior_posterior(smk_fit_RE)   # Plot prior vs. posterior for heterogeneity SD only plot_prior_posterior(smk_fit_RE, prior = \"het\")   # Customise plot plot_prior_posterior(smk_fit_RE, prior = \"het\",                      prior_args = list(colour = \"darkred\", size = 2),                      post_args = list(alpha = 0.6))  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":null,"dir":"Reference","previous_headings":"","what":"Treatment rankings and rank probabilities — posterior_ranks","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"Produce posterior treatment rankings rank probabilities fitted NMA model. meta-regression fitted effect modifier interactions treatment, differ study population.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"","code":"posterior_ranks(   x,   newdata = NULL,   study = NULL,   lower_better = TRUE,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   sucra = FALSE,   summary = TRUE )  posterior_rank_probs(   x,   newdata = NULL,   study = NULL,   lower_better = TRUE,   cumulative = FALSE,   sucra = FALSE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"x stan_nma object created nma() newdata used regression model fitted. data frame study details, one row per study, giving covariate values produce relative effects. Column names must match variables regression model. NULL, relative effects produced studies network. study Column newdata specifies study names, otherwise studies labelled row number. lower_better Logical, lower treatment effects better (TRUE; default) higher better (FALSE)? See details. probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) sucra Logical, calculate surface cumulative ranking curve (SUCRA) treatment? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE. cumulative Logical, return cumulative rank probabilities? Default FALSE, return posterior probabilities treatment given rank. TRUE, cumulative posterior rank probabilities returned treatment given rank better.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"function posterior_ranks() produces posterior rankings, distribution (e.g. mean/median rank 95% Credible Interval). function posterior_rank_probs() produces rank probabilities, give posterior probabilities ranked first, second, etc. treatments. argument lower_better specifies whether lower treatment effects higher treatment effects preferred. example, negative binary outcome lower (negative) log odds ratios preferred, lower_better = TRUE. Conversely, example, treatments aim increase rate positive outcome lower_better = FALSE.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/posterior_ranks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Treatment rankings and rank probabilities — posterior_ranks","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce posterior ranks smk_rank_RE <- posterior_ranks(smk_fit_RE, lower_better = FALSE) smk_rank_RE #>                              mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[No intervention]        3.89 0.32    3   4   4   4     4     2434       NA #> rank[Group counselling]      1.37 0.63    1   1   1   2     3     3066     3101 #> rank[Individual counselling] 1.91 0.62    1   2   2   2     3     2635     2915 #> rank[Self-help]              2.83 0.68    1   3   3   3     4     2447       NA #>                              Rhat #> rank[No intervention]           1 #> rank[Group counselling]         1 #> rank[Individual counselling]    1 #> rank[Self-help]                 1 plot(smk_rank_RE)   # Produce rank probabilities smk_rankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE) smk_rankprob_RE #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.10      0.89 #> d[Group counselling]           0.71      0.22      0.07      0.00 #> d[Individual counselling]      0.24      0.61      0.15      0.00 #> d[Self-help]                   0.06      0.17      0.68      0.10 plot(smk_rankprob_RE)   # Produce cumulative rank probabilities smk_cumrankprob_RE <- posterior_rank_probs(smk_fit_RE, lower_better = FALSE,                                            cumulative = TRUE) smk_cumrankprob_RE #>                           p_rank[1] p_rank[2] p_rank[3] p_rank[4] #> d[No intervention]             0.00      0.00      0.11         1 #> d[Group counselling]           0.71      0.93      1.00         1 #> d[Individual counselling]      0.24      0.85      1.00         1 #> d[Self-help]                   0.06      0.22      0.90         1 plot(smk_cumrankprob_RE)   # Further customisation is possible with ggplot commands plot(smk_cumrankprob_RE) +   ggplot2::facet_null() +   ggplot2::aes(colour = Treatment)  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Produce population-adjusted rankings for all study populations in # the network  # Ranks pso_rank <- posterior_ranks(pso_fit) pso_rank #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                        mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[FIXTURE: PBO]     1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[FIXTURE: ETN]     2.00 0.00    2   2   2   2     2       NA       NA   NA #> rank[FIXTURE: IXE_Q2W] 6.00 0.02    6   6   6   6     6     4016       NA    1 #> rank[FIXTURE: IXE_Q4W] 4.78 0.41    4   5   5   5     5     4442       NA    1 #> rank[FIXTURE: SEC_150] 3.00 0.06    3   3   3   3     3     3188     3188    1 #> rank[FIXTURE: SEC_300] 4.21 0.42    4   4   4   4     5     4643     4016    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-1: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-1: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-1: IXE_Q2W] 6.00 0.02    6   6   6   6     6     4016       NA #> rank[UNCOVER-1: IXE_Q4W] 4.78 0.41    4   5   5   5     5     4442       NA #> rank[UNCOVER-1: SEC_150] 3.00 0.06    3   3   3   3     3     3188     3188 #> rank[UNCOVER-1: SEC_300] 4.21 0.42    4   4   4   4     5     4643     4016 #>                          Rhat #> rank[UNCOVER-1: PBO]       NA #> rank[UNCOVER-1: ETN]       NA #> rank[UNCOVER-1: IXE_Q2W]    1 #> rank[UNCOVER-1: IXE_Q4W]    1 #> rank[UNCOVER-1: SEC_150]    1 #> rank[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-2: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-2: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-2: IXE_Q2W] 6.00 0.02    6   6   6   6     6     4016       NA #> rank[UNCOVER-2: IXE_Q4W] 4.78 0.41    4   5   5   5     5     4442       NA #> rank[UNCOVER-2: SEC_150] 3.00 0.06    3   3   3   3     3     3188     3188 #> rank[UNCOVER-2: SEC_300] 4.21 0.42    4   4   4   4     5     4643     4016 #>                          Rhat #> rank[UNCOVER-2: PBO]       NA #> rank[UNCOVER-2: ETN]       NA #> rank[UNCOVER-2: IXE_Q2W]    1 #> rank[UNCOVER-2: IXE_Q4W]    1 #> rank[UNCOVER-2: SEC_150]    1 #> rank[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                          mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS #> rank[UNCOVER-3: PBO]     1.00 0.00    1   1   1   1     1       NA       NA #> rank[UNCOVER-3: ETN]     2.00 0.00    2   2   2   2     2       NA       NA #> rank[UNCOVER-3: IXE_Q2W] 6.00 0.02    6   6   6   6     6     4016       NA #> rank[UNCOVER-3: IXE_Q4W] 4.78 0.41    4   5   5   5     5     4442       NA #> rank[UNCOVER-3: SEC_150] 3.00 0.06    3   3   3   3     3     3188     3188 #> rank[UNCOVER-3: SEC_300] 4.21 0.42    4   4   4   4     5     4643     4016 #>                          Rhat #> rank[UNCOVER-3: PBO]       NA #> rank[UNCOVER-3: ETN]       NA #> rank[UNCOVER-3: IXE_Q2W]    1 #> rank[UNCOVER-3: IXE_Q4W]    1 #> rank[UNCOVER-3: SEC_150]    1 #> rank[UNCOVER-3: SEC_300]    1 #>  plot(pso_rank)   # Rank probabilities pso_rankprobs <- posterior_rank_probs(pso_fit) pso_rankprobs #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             1         0         0      0.00      0.00         0 #> d[FIXTURE: ETN]             0         1         0      0.00      0.00         0 #> d[FIXTURE: IXE_Q2W]         0         0         0      0.00      0.00         1 #> d[FIXTURE: IXE_Q4W]         0         0         0      0.22      0.78         0 #> d[FIXTURE: SEC_150]         0         0         1      0.00      0.00         0 #> d[FIXTURE: SEC_300]         0         0         0      0.78      0.22         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-1: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-1: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-1: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-1: IXE_Q4W]         0         0         0      0.22      0.78 #> d[UNCOVER-1: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-1: SEC_300]         0         0         0      0.78      0.22 #>                       p_rank[6] #> d[UNCOVER-1: PBO]             0 #> d[UNCOVER-1: ETN]             0 #> d[UNCOVER-1: IXE_Q2W]         1 #> d[UNCOVER-1: IXE_Q4W]         0 #> d[UNCOVER-1: SEC_150]         0 #> d[UNCOVER-1: SEC_300]         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-2: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-2: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-2: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-2: IXE_Q4W]         0         0         0      0.22      0.78 #> d[UNCOVER-2: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-2: SEC_300]         0         0         0      0.78      0.22 #>                       p_rank[6] #> d[UNCOVER-2: PBO]             0 #> d[UNCOVER-2: ETN]             0 #> d[UNCOVER-2: IXE_Q2W]         1 #> d[UNCOVER-2: IXE_Q4W]         0 #> d[UNCOVER-2: SEC_150]         0 #> d[UNCOVER-2: SEC_300]         0 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-3: PBO]             1         0         0      0.00      0.00 #> d[UNCOVER-3: ETN]             0         1         0      0.00      0.00 #> d[UNCOVER-3: IXE_Q2W]         0         0         0      0.00      0.00 #> d[UNCOVER-3: IXE_Q4W]         0         0         0      0.22      0.78 #> d[UNCOVER-3: SEC_150]         0         0         1      0.00      0.00 #> d[UNCOVER-3: SEC_300]         0         0         0      0.78      0.22 #>                       p_rank[6] #> d[UNCOVER-3: PBO]             0 #> d[UNCOVER-3: ETN]             0 #> d[UNCOVER-3: IXE_Q2W]         1 #> d[UNCOVER-3: IXE_Q4W]         0 #> d[UNCOVER-3: SEC_150]         0 #> d[UNCOVER-3: SEC_300]         0 #>  plot(pso_rankprobs)   # Cumulative rank probabilities pso_cumrankprobs <- posterior_rank_probs(pso_fit, cumulative = TRUE) pso_cumrankprobs #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[FIXTURE: PBO]             1         1         1      1.00         1         1 #> d[FIXTURE: ETN]             0         1         1      1.00         1         1 #> d[FIXTURE: IXE_Q2W]         0         0         0      0.00         0         1 #> d[FIXTURE: IXE_Q4W]         0         0         0      0.22         1         1 #> d[FIXTURE: SEC_150]         0         0         1      1.00         1         1 #> d[FIXTURE: SEC_300]         0         0         0      0.78         1         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-1: PBO]             1         1         1      1.00         1 #> d[UNCOVER-1: ETN]             0         1         1      1.00         1 #> d[UNCOVER-1: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-1: IXE_Q4W]         0         0         0      0.22         1 #> d[UNCOVER-1: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-1: SEC_300]         0         0         0      0.78         1 #>                       p_rank[6] #> d[UNCOVER-1: PBO]             1 #> d[UNCOVER-1: ETN]             1 #> d[UNCOVER-1: IXE_Q2W]         1 #> d[UNCOVER-1: IXE_Q4W]         1 #> d[UNCOVER-1: SEC_150]         1 #> d[UNCOVER-1: SEC_300]         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-2: PBO]             1         1         1      1.00         1 #> d[UNCOVER-2: ETN]             0         1         1      1.00         1 #> d[UNCOVER-2: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-2: IXE_Q4W]         0         0         0      0.22         1 #> d[UNCOVER-2: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-2: SEC_300]         0         0         0      0.78         1 #>                       p_rank[6] #> d[UNCOVER-2: PBO]             1 #> d[UNCOVER-2: ETN]             1 #> d[UNCOVER-2: IXE_Q2W]         1 #> d[UNCOVER-2: IXE_Q4W]         1 #> d[UNCOVER-2: SEC_150]         1 #> d[UNCOVER-2: SEC_300]         1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] #> d[UNCOVER-3: PBO]             1         1         1      1.00         1 #> d[UNCOVER-3: ETN]             0         1         1      1.00         1 #> d[UNCOVER-3: IXE_Q2W]         0         0         0      0.00         0 #> d[UNCOVER-3: IXE_Q4W]         0         0         0      0.22         1 #> d[UNCOVER-3: SEC_150]         0         0         1      1.00         1 #> d[UNCOVER-3: SEC_300]         0         0         0      0.78         1 #>                       p_rank[6] #> d[UNCOVER-3: PBO]             1 #> d[UNCOVER-3: ETN]             1 #> d[UNCOVER-3: IXE_Q2W]         1 #> d[UNCOVER-3: IXE_Q4W]         1 #> d[UNCOVER-3: SEC_150]         1 #> d[UNCOVER-3: SEC_300]         1 #>  plot(pso_cumrankprobs)   # Produce population-adjusted rankings for a different target # population new_agd_means <- data.frame(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3)  # Ranks posterior_ranks(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                      mean   sd 2.5% 25% 50% 75% 97.5% Bulk_ESS Tail_ESS Rhat #> rank[New 1: PBO]     1.00 0.00    1   1   1   1     1       NA       NA   NA #> rank[New 1: ETN]     2.00 0.00    2   2   2   2     2       NA       NA   NA #> rank[New 1: IXE_Q2W] 6.00 0.02    6   6   6   6     6     4016       NA    1 #> rank[New 1: IXE_Q4W] 4.78 0.41    4   5   5   5     5     4442       NA    1 #> rank[New 1: SEC_150] 3.00 0.06    3   3   3   3     3     3188     3188    1 #> rank[New 1: SEC_300] 4.21 0.42    4   4   4   4     5     4643     4016    1 #>   # Rank probabilities posterior_rank_probs(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[New 1: PBO]             1         0         0      0.00      0.00         0 #> d[New 1: ETN]             0         1         0      0.00      0.00         0 #> d[New 1: IXE_Q2W]         0         0         0      0.00      0.00         1 #> d[New 1: IXE_Q4W]         0         0         0      0.22      0.78         0 #> d[New 1: SEC_150]         0         0         1      0.00      0.00         0 #> d[New 1: SEC_300]         0         0         0      0.78      0.22         0 #>   # Cumulative rank probabilities posterior_rank_probs(pso_fit, newdata = new_agd_means,                      cumulative = TRUE) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   p_rank[1] p_rank[2] p_rank[3] p_rank[4] p_rank[5] p_rank[6] #> d[New 1: PBO]             1         1         1      1.00         1         1 #> d[New 1: ETN]             0         1         1      1.00         1         1 #> d[New 1: IXE_Q2W]         0         0         0      0.00         0         1 #> d[New 1: IXE_Q4W]         0         0         0      0.22         1         1 #> d[New 1: SEC_150]         0         0         1      1.00         1         1 #> d[New 1: SEC_300]         0         0         0      0.78         1         1 #>  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions of absolute effects from NMA models — predict.stan_nma","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Obtain predictions absolute effects NMA models fitted nma(). example, model fitted binary data logit link, predicted outcome probabilities log odds can produced. survival models, predictions can made survival probabilities, (cumulative) hazards, (restricted) mean survival times, quantiles including median survival times. IPD NMA ML-NMR model fitted, predictions can produced either individual level aggregate level. Aggregate-level predictions population-average absolute effects; marginalised standardised population. example, average event probabilities logistic regression, marginal (standardised) survival probabilities survival model.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"","code":"# S3 method for class 'stan_nma' predict(   object,   ...,   baseline = NULL,   newdata = NULL,   study = NULL,   type = c(\"link\", \"response\"),   level = c(\"aggregate\", \"individual\"),   baseline_trt = NULL,   baseline_type = c(\"link\", \"response\"),   baseline_level = c(\"individual\", \"aggregate\"),   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE,   progress = FALSE,   trt_ref = NULL )  # S3 method for class 'stan_nma_surv' predict(   object,   times = NULL,   ...,   baseline_trt = NULL,   baseline = NULL,   aux = NULL,   newdata = NULL,   study = NULL,   type = c(\"survival\", \"hazard\", \"cumhaz\", \"mean\", \"median\", \"quantile\", \"rmst\", \"link\"),   quantiles = c(0.25, 0.5, 0.75),   level = c(\"aggregate\", \"individual\"),   times_seq = NULL,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE,   progress = interactive(),   trt_ref = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"object stan_nma object created nma(). ... Additional arguments, passed uniroot() regression models baseline_level = \"aggregate\". baseline optional distr() distribution baseline response (.e. intercept), produce absolute effects. Can also character string naming study network take estimated baseline response distribution . NULL, predictions produced using baseline response study network IPD arm-based AgD. regression models, may list distr() distributions (study names network use baseline distributions ) length number studies newdata, possibly named studies newdata otherwise order appearance newdata. Use baseline_type baseline_level arguments specify whether distribution response linear predictor scale, (ML-NMR models including IPD) whether applies individual reference level covariates entire newdata population, respectively. example, model logit link baseline_type = \"link\", distribution baseline log odds event. survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_type always \"link\", baseline_level \"individual\" IPD NMA ML-NMR, \"aggregate\" AgD NMA). Use baseline_trt argument specify treatment distribution applies . newdata required regression model fitted baseline specified. data frame covariate details, produce predictions. Column names must match variables regression model. level = \"aggregate\" either data frame integration points produced add_integration() (one row per study), data frame individual covariate values (one row per individual) summarised . level = \"individual\" data frame individual covariate values, one row per individual. NULL, predictions produced studies IPD /arm-based AgD network, depending value level. study Column newdata specifies study names IDs. specified: newdata contains integration points produced add_integration(), studies labelled sequentially row; otherwise data assumed come single study. type Whether produce predictions \"link\" scale (default, e.g. log odds) \"response\" scale (e.g. probabilities). survival models, options \"survival\" survival probabilities (default), \"hazard\" hazards, \"cumhaz\" cumulative hazards, \"mean\" mean survival times, \"quantile\" quantiles survival time distribution, \"median\" median survival times (equivalent type = \"quantile\" quantiles = 0.5), \"rmst\" restricted mean survival times, \"link\" linear predictor. type = \"survival\", \"hazard\" \"cumhaz\", predictions given times specified times event/censoring times network times = NULL. type = \"rmst\", restricted time horizon specified times, times = NULL earliest last follow-time amongst studies network used. level = \"aggregate\", correspond standardised survival function (see details). level level predictions produced, either \"aggregate\" (default), \"individual\". baseline specified, predictions produced IPD studies network level \"individual\" \"aggregate\", arm-based AgD studies network level \"aggregate\". baseline_trt Treatment baseline response distribution refers, baseline specified. default, baseline response distribution refer network reference treatment. Coerced character string. baseline_type baseline distribution given, specifies whether corresponds \"link\" scale (default, e.g. log odds) \"response\" scale (e.g. probabilities). survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_type always \"link\"). baseline_level baseline distribution given, specifies whether corresponds individual reference level covariates (\"individual\", default), (unadjusted) average outcome reference treatment newdata population (\"aggregate\"). Ignored AgD NMA, since option \"aggregate\" instance. survival models, baseline always corresponds intercept parameters linear predictor (.e. baseline_level \"individual\" IPD NMA ML-NMR, \"aggregate\" AgD NMA). probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) predictive_distribution Logical, random effects model fitted, predictive distribution absolute effects new study returned? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE. progress Logical, display progress potentially long-running calculations? Population-average predictions ML-NMR models computationally intensive, especially survival outcomes. Currently default display progress running interactively producing predictions survival ML-NMR model. trt_ref Deprecated, renamed baseline_trt. times numeric vector times evaluate predictions . Alternatively, newdata specified, times can name column newdata contains times. NULL (default) predictions made event/censoring times studies included network (according times_seq). used type \"survival\", \"hazard\", \"cumhaz\" \"rmst\". aux optional distr() distribution auxiliary parameter(s) baseline hazard (e.g. shapes). Can also character string naming study network take estimated auxiliary parameter distribution . NULL, predictions produced using parameter estimates study network IPD arm-based AgD. regression models, may list distr() distributions (study names network use auxiliary parameters ) length number studies newdata, possibly named study names otherwise order appearance newdata. quantiles numeric vector quantiles survival time distribution produce estimates type = \"quantile\". times_seq positive integer, specified evaluate predictions many evenly-spaced event times 0 latest follow-time study, instead every observed event/censoring time. used newdata = NULL type \"survival\", \"hazard\" \"cumhaz\". can useful plotting survival (cumulative) hazard curves, prediction every observed even/censoring time unnecessary can slow. call within plot() detected, e.g. like plot(predict(fit, type = \"survival\")), times_seq default 50.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"aggregate-level-predictions-from-ipd-nma-and-ml-nmr-models","dir":"Reference","previous_headings":"","what":"Aggregate-level predictions from IPD NMA and ML-NMR models","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Population-average absolute effects can produced IPD NMA ML-NMR models level = \"aggregate\". Predictions averaged target population (.e. standardised/marginalised), either (numerical) integration joint covariate distribution (AgD studies network ML-NMR, AgD newdata integration points created add_integration()), averaging predictions sample individuals (IPD studies network IPD NMA/ML-NMR, IPD newdata). example, binary outcome, population-average event probabilities treatment \\(k\\) study/population \\(j\\) $$\\bar{p}_{jk} = \\int_\\mathfrak{X} p_{jk}(\\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x}$$ joint covariate distribution \\(f_{jk}(\\mathbf{x})\\) support \\(\\mathfrak{X}\\) $$\\bar{p}_{jk} = \\sum_i p_{jk}(\\mathbf{x}_i)$$ sample individuals covariates \\(\\mathbf{x}_i\\). Population-average absolute predictions follow similarly types outcomes, however survival outcomes specific considerations.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"standardised-survival-predictions","dir":"Reference","previous_headings":"","what":"Standardised survival predictions","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"Different types population-average survival predictions, often called standardised survival predictions, follow standardised survival function created integrating (equivalently averaging) individual-level survival functions time \\(t\\): $$\\bar{S}_{jk}(t) = \\int_\\mathfrak{X} S_{jk}(t | \\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x}$$ produced using type = \"survival\". standardised hazard function corresponding standardised survival function weighted average individual-level hazard functions $$\\bar{h}_{jk}(t) = \\frac{\\int_\\mathfrak{X} S_{jk}(t | \\mathbf{x}) h_{jk}(t | \\mathbf{x}) f_{jk}(\\mathbf{x}) d\\mathbf{x} }{\\bar{S}_{jk}(t)}$$ weighted probability surviving time \\(t\\). produced using type = \"hazard\". corresponding standardised cumulative hazard function $$\\bar{H}_{jk}(t) = -\\log(\\bar{S}_{jk}(t))$$ produced using type = \"cumhaz\". Quantiles medians standardised survival times found solving $$\\bar{S}_{jk}(t) = 1-\\alpha$$ \\(\\alpha\\%\\) quantile, using numerical root finding. produced using type = \"quantile\" \"median\". (Restricted) means standardised survival times found integrating $$\\mathrm{RMST}_{jk}(t^*) = \\int_0^{t^*} \\bar{S}_{jk}(t) dt$$ restricted time horizon \\(t^*\\), \\(t^*=\\infty\\) mean standardised survival time. produced using type = \"rmst\" \"mean\".","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/predict.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions of absolute effects from NMA models — predict.stan_nma","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Predicted log odds of success in each study in the network predict(smk_fit_RE) #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[1: No intervention]        -2.79 0.33 -3.50 -3.00 -2.78 -2.56 -2.19 #> pred[1: Group counselling]      -1.68 0.51 -2.66 -2.02 -1.68 -1.35 -0.65 #> pred[1: Individual counselling] -1.94 0.39 -2.72 -2.20 -1.94 -1.68 -1.20 #> pred[1: Self-help]              -2.31 0.49 -3.30 -2.62 -2.30 -1.97 -1.36 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[1: No intervention]            5003     3082    1 #> pred[1: Group counselling]          2964     2989    1 #> pred[1: Individual counselling]     2645     2582    1 #> pred[1: Self-help]                  2666     2832    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[2: No intervention]        -2.57 0.76 -4.14 -3.06 -2.57 -2.08 -1.05 #> pred[2: Group counselling]      -1.46 0.76 -2.95 -1.95 -1.47 -0.98  0.06 #> pred[2: Individual counselling] -1.72 0.75 -3.23 -2.20 -1.73 -1.24 -0.23 #> pred[2: Self-help]              -2.08 0.77 -3.61 -2.59 -2.08 -1.59 -0.56 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[2: No intervention]            2781     2596    1 #> pred[2: Group counselling]          3518     2580    1 #> pred[2: Individual counselling]     3012     2722    1 #> pred[2: Self-help]                  3534     2695    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[3: No intervention]        -2.14 0.12 -2.39 -2.22 -2.14 -2.06 -1.91 #> pred[3: Group counselling]      -1.04 0.45 -1.91 -1.34 -1.04 -0.74 -0.12 #> pred[3: Individual counselling] -1.29 0.26 -1.81 -1.47 -1.29 -1.13 -0.77 #> pred[3: Self-help]              -1.66 0.41 -2.47 -1.93 -1.66 -1.39 -0.85 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[3: No intervention]            7734     2393    1 #> pred[3: Group counselling]          2427     2923    1 #> pred[3: Individual counselling]     1718     2516    1 #> pred[3: Self-help]                  2131     2467    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[4: No intervention]        -4.05 0.57 -5.26 -4.41 -4.01 -3.66 -3.04 #> pred[4: Group counselling]      -2.95 0.70 -4.36 -3.41 -2.94 -2.47 -1.63 #> pred[4: Individual counselling] -3.21 0.58 -4.42 -3.58 -3.19 -2.81 -2.12 #> pred[4: Self-help]              -3.57 0.68 -5.01 -4.01 -3.54 -3.10 -2.31 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[4: No intervention]            3832     2586    1 #> pred[4: Group counselling]          3465     3191    1 #> pred[4: Individual counselling]     3953     2837    1 #> pred[4: Self-help]                  3272     2919    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[5: No intervention]        -2.16 0.14 -2.44 -2.25 -2.15 -2.06 -1.89 #> pred[5: Group counselling]      -1.05 0.46 -1.93 -1.35 -1.06 -0.76 -0.13 #> pred[5: Individual counselling] -1.31 0.27 -1.84 -1.48 -1.31 -1.13 -0.76 #> pred[5: Self-help]              -1.67 0.42 -2.49 -1.95 -1.68 -1.40 -0.85 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[5: No intervention]            8858     2612    1 #> pred[5: Group counselling]          2410     2609    1 #> pred[5: Individual counselling]     1740     2415    1 #> pred[5: Self-help]                  2217     2640    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[6: No intervention]        -3.44 0.74 -5.03 -3.89 -3.39 -2.93 -2.15 #> pred[6: Group counselling]      -2.33 0.81 -4.05 -2.84 -2.28 -1.79 -0.83 #> pred[6: Individual counselling] -2.59 0.72 -4.12 -3.04 -2.56 -2.11 -1.30 #> pred[6: Self-help]              -2.96 0.82 -4.70 -3.47 -2.91 -2.41 -1.44 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[6: No intervention]            3675     2769    1 #> pred[6: Group counselling]          3684     2733    1 #> pred[6: Individual counselling]     3861     2646    1 #> pred[6: Self-help]                  3346     2389    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[7: No intervention]        -3.03 0.45 -4.00 -3.31 -2.99 -2.71 -2.25 #> pred[7: Group counselling]      -1.93 0.60 -3.17 -2.30 -1.90 -1.51 -0.80 #> pred[7: Individual counselling] -2.18 0.47 -3.16 -2.49 -2.15 -1.86 -1.34 #> pred[7: Self-help]              -2.55 0.58 -3.74 -2.91 -2.52 -2.15 -1.49 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[7: No intervention]            4033     2673    1 #> pred[7: Group counselling]          3385     3139    1 #> pred[7: Individual counselling]     2771     2546    1 #> pred[7: Self-help]                  2816     2333    1 #>  #> ---------------------------------------------------------------------- Study: 8 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[8: No intervention]        -2.71 0.60 -4.00 -3.07 -2.68 -2.28 -1.69 #> pred[8: Group counselling]      -1.61 0.71 -3.08 -2.05 -1.57 -1.15 -0.28 #> pred[8: Individual counselling] -1.87 0.60 -3.11 -2.24 -1.85 -1.44 -0.83 #> pred[8: Self-help]              -2.23 0.71 -3.77 -2.65 -2.20 -1.74 -0.95 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[8: No intervention]            3644     2633    1 #> pred[8: Group counselling]          3605     2693    1 #> pred[8: Individual counselling]     3705     2602    1 #> pred[8: Self-help]                  3304     2677    1 #>  #> ---------------------------------------------------------------------- Study: 9 ----  #>  #>                                  mean   sd  2.5%   25%   50%   75% 97.5% #> pred[9: No intervention]        -1.84 0.41 -2.67 -2.11 -1.82 -1.56 -1.10 #> pred[9: Group counselling]      -0.73 0.59 -1.91 -1.12 -0.73 -0.35  0.41 #> pred[9: Individual counselling] -0.99 0.45 -1.88 -1.30 -0.98 -0.68 -0.11 #> pred[9: Self-help]              -1.36 0.56 -2.49 -1.73 -1.36 -0.97 -0.28 #>                                 Bulk_ESS Tail_ESS Rhat #> pred[9: No intervention]            4487     2960    1 #> pred[9: Group counselling]          3076     2695    1 #> pred[9: Individual counselling]     3016     2823    1 #> pred[9: Self-help]                  2866     2937    1 #>  #> --------------------------------------------------------------------- Study: 10 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[10: No intervention]        -2.08 0.12 -2.32 -2.16 -2.08 -2.00 -1.86 #> pred[10: Group counselling]      -0.97 0.46 -1.82 -1.28 -0.99 -0.69 -0.06 #> pred[10: Individual counselling] -1.23 0.27 -1.76 -1.41 -1.24 -1.05 -0.70 #> pred[10: Self-help]              -1.60 0.40 -2.39 -1.86 -1.60 -1.34 -0.81 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[10: No intervention]            9817     3071    1 #> pred[10: Group counselling]          2404     2858    1 #> pred[10: Individual counselling]     1767     2390    1 #> pred[10: Self-help]                  2092     2497    1 #>  #> --------------------------------------------------------------------- Study: 11 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[11: No intervention]        -3.62 0.23 -4.10 -3.77 -3.62 -3.46 -3.18 #> pred[11: Group counselling]      -2.52 0.49 -3.44 -2.84 -2.53 -2.19 -1.52 #> pred[11: Individual counselling] -2.77 0.33 -3.43 -2.99 -2.78 -2.56 -2.11 #> pred[11: Self-help]              -3.14 0.44 -4.01 -3.42 -3.14 -2.85 -2.28 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[11: No intervention]            6578     2799    1 #> pred[11: Group counselling]          2752     2993    1 #> pred[11: Individual counselling]     2500     3013    1 #> pred[11: Self-help]                  2374     2710    1 #>  #> --------------------------------------------------------------------- Study: 12 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[12: No intervention]        -2.22 0.13 -2.49 -2.31 -2.22 -2.13 -1.97 #> pred[12: Group counselling]      -1.11 0.46 -2.00 -1.42 -1.12 -0.82 -0.18 #> pred[12: Individual counselling] -1.37 0.27 -1.91 -1.55 -1.37 -1.19 -0.83 #> pred[12: Self-help]              -1.74 0.42 -2.57 -2.02 -1.74 -1.46 -0.90 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[12: No intervention]            7819     2793    1 #> pred[12: Group counselling]          2386     2539    1 #> pred[12: Individual counselling]     1786     2510    1 #> pred[12: Self-help]                  2144     2733    1 #>  #> --------------------------------------------------------------------- Study: 13 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[13: No intervention]        -2.67 0.44 -3.59 -2.96 -2.65 -2.37 -1.88 #> pred[13: Group counselling]      -1.57 0.61 -2.75 -1.98 -1.57 -1.15 -0.36 #> pred[13: Individual counselling] -1.82 0.48 -2.82 -2.14 -1.80 -1.51 -0.90 #> pred[13: Self-help]              -2.19 0.58 -3.33 -2.57 -2.18 -1.81 -1.06 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[13: No intervention]            4921     3014    1 #> pred[13: Group counselling]          3275     2981    1 #> pred[13: Individual counselling]     3588     3297    1 #> pred[13: Self-help]                  2998     3093    1 #>  #> --------------------------------------------------------------------- Study: 14 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[14: No intervention]        -2.41 0.23 -2.89 -2.56 -2.41 -2.25 -1.98 #> pred[14: Group counselling]      -1.31 0.49 -2.26 -1.64 -1.32 -0.99 -0.30 #> pred[14: Individual counselling] -1.57 0.32 -2.19 -1.78 -1.57 -1.35 -0.94 #> pred[14: Self-help]              -1.93 0.45 -2.85 -2.23 -1.93 -1.63 -1.05 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[14: No intervention]            6608     3029    1 #> pred[14: Group counselling]          2719     2953    1 #> pred[14: Individual counselling]     2309     2995    1 #> pred[14: Self-help]                  2508     2540    1 #>  #> --------------------------------------------------------------------- Study: 15 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[15: No intervention]        -2.70 0.76 -4.41 -3.16 -2.64 -2.18 -1.41 #> pred[15: Group counselling]      -1.59 0.75 -3.21 -2.05 -1.55 -1.08 -0.26 #> pred[15: Individual counselling] -1.85 0.76 -3.52 -2.31 -1.81 -1.33 -0.54 #> pred[15: Self-help]              -2.22 0.83 -4.05 -2.70 -2.16 -1.64 -0.78 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[15: No intervention]            3740     2685    1 #> pred[15: Group counselling]          3887     2827    1 #> pred[15: Individual counselling]     3633     2730    1 #> pred[15: Self-help]                  3424     2783    1 #>  #> --------------------------------------------------------------------- Study: 16 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[16: No intervention]        -2.61 0.34 -3.35 -2.83 -2.60 -2.38 -1.99 #> pred[16: Group counselling]      -1.51 0.54 -2.53 -1.87 -1.52 -1.16 -0.46 #> pred[16: Individual counselling] -1.77 0.41 -2.58 -2.04 -1.77 -1.50 -0.96 #> pred[16: Self-help]              -2.13 0.47 -3.08 -2.45 -2.14 -1.82 -1.21 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[16: No intervention]            6219     3013    1 #> pred[16: Group counselling]          2969     2932    1 #> pred[16: Individual counselling]     2907     2710    1 #> pred[16: Self-help]                  2734     2596    1 #>  #> --------------------------------------------------------------------- Study: 17 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[17: No intervention]        -2.38 0.11 -2.59 -2.45 -2.38 -2.30 -2.18 #> pred[17: Group counselling]      -1.27 0.45 -2.12 -1.57 -1.29 -0.98 -0.35 #> pred[17: Individual counselling] -1.53 0.26 -2.02 -1.70 -1.54 -1.36 -1.01 #> pred[17: Self-help]              -1.90 0.41 -2.69 -2.16 -1.89 -1.62 -1.11 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[17: No intervention]            8002     3309    1 #> pred[17: Group counselling]          2340     2861    1 #> pred[17: Individual counselling]     1633     2632    1 #> pred[17: Self-help]                  2121     2745    1 #>  #> --------------------------------------------------------------------- Study: 18 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[18: No intervention]        -2.57 0.27 -3.14 -2.74 -2.56 -2.38 -2.05 #> pred[18: Group counselling]      -1.46 0.50 -2.44 -1.79 -1.48 -1.13 -0.41 #> pred[18: Individual counselling] -1.72 0.35 -2.40 -1.95 -1.73 -1.48 -1.04 #> pred[18: Self-help]              -2.08 0.47 -3.02 -2.40 -2.09 -1.77 -1.14 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[18: No intervention]            4727     2897    1 #> pred[18: Group counselling]          2865     2844    1 #> pred[18: Individual counselling]     2401     2756    1 #> pred[18: Self-help]                  2552     2770    1 #>  #> --------------------------------------------------------------------- Study: 19 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[19: No intervention]        -1.90 0.12 -2.15 -1.97 -1.89 -1.82 -1.67 #> pred[19: Group counselling]      -0.79 0.45 -1.65 -1.10 -0.80 -0.51  0.13 #> pred[19: Individual counselling] -1.05 0.27 -1.56 -1.23 -1.05 -0.88 -0.52 #> pred[19: Self-help]              -1.42 0.41 -2.22 -1.69 -1.41 -1.14 -0.61 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[19: No intervention]            7251     2631    1 #> pred[19: Group counselling]          2378     2773    1 #> pred[19: Individual counselling]     1662     2331    1 #> pred[19: Self-help]                  2181     2508    1 #>  #> --------------------------------------------------------------------- Study: 20 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[20: No intervention]        -2.80 0.12 -3.04 -2.88 -2.80 -2.72 -2.57 #> pred[20: Group counselling]      -1.70 0.46 -2.56 -2.00 -1.70 -1.40 -0.78 #> pred[20: Individual counselling] -1.95 0.27 -2.48 -2.13 -1.95 -1.78 -1.41 #> pred[20: Self-help]              -2.32 0.41 -3.12 -2.59 -2.32 -2.05 -1.52 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[20: No intervention]            7276     3281    1 #> pred[20: Group counselling]          2339     2768    1 #> pred[20: Individual counselling]     1711     2198    1 #> pred[20: Self-help]                  2095     2428    1 #>  #> --------------------------------------------------------------------- Study: 21 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[21: No intervention]        -1.13 0.81 -2.77 -1.64 -1.12 -0.60  0.41 #> pred[21: Group counselling]      -0.02 0.87 -1.74 -0.58 -0.03  0.54  1.68 #> pred[21: Individual counselling] -0.28 0.79 -1.82 -0.80 -0.28  0.23  1.27 #> pred[21: Self-help]              -0.65 0.78 -2.19 -1.13 -0.64 -0.15  0.91 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[21: No intervention]            3122     2788    1 #> pred[21: Group counselling]          3606     2628    1 #> pred[21: Individual counselling]     3670     2769    1 #> pred[21: Self-help]                  4213     3050    1 #>  #> --------------------------------------------------------------------- Study: 22 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[22: No intervention]        -2.40 0.86 -4.13 -2.94 -2.37 -1.84 -0.73 #> pred[22: Group counselling]      -1.30 0.82 -2.96 -1.81 -1.29 -0.76  0.34 #> pred[22: Individual counselling] -1.55 0.85 -3.27 -2.08 -1.53 -1.01  0.10 #> pred[22: Self-help]              -1.92 0.84 -3.62 -2.44 -1.90 -1.37 -0.33 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[22: No intervention]            2629     2496    1 #> pred[22: Group counselling]          3171     2474    1 #> pred[22: Individual counselling]     2794     2489    1 #> pred[22: Self-help]                  3028     2729    1 #>  #> --------------------------------------------------------------------- Study: 23 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[23: No intervention]        -2.31 0.83 -3.99 -2.84 -2.31 -1.76 -0.69 #> pred[23: Group counselling]      -1.21 0.80 -2.76 -1.71 -1.19 -0.71  0.41 #> pred[23: Individual counselling] -1.46 0.81 -3.05 -1.99 -1.46 -0.94  0.13 #> pred[23: Self-help]              -1.83 0.89 -3.60 -2.40 -1.83 -1.26 -0.11 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[23: No intervention]            3212     2805    1 #> pred[23: Group counselling]          3527     2358    1 #> pred[23: Individual counselling]     3496     2962    1 #> pred[23: Self-help]                  3373     2615    1 #>  #> --------------------------------------------------------------------- Study: 24 ----  #>  #>                                   mean   sd  2.5%   25%   50%   75% 97.5% #> pred[24: No intervention]        -2.79 0.86 -4.45 -3.36 -2.79 -2.21 -1.14 #> pred[24: Group counselling]      -1.69 0.85 -3.34 -2.27 -1.68 -1.11 -0.06 #> pred[24: Individual counselling] -1.94 0.84 -3.59 -2.50 -1.96 -1.38 -0.32 #> pred[24: Self-help]              -2.31 0.91 -4.13 -2.90 -2.29 -1.72 -0.51 #>                                  Bulk_ESS Tail_ESS Rhat #> pred[24: No intervention]            3263     2717    1 #> pred[24: Group counselling]          3928     3123    1 #> pred[24: Individual counselling]     3762     3101    1 #> pred[24: Self-help]                  3386     2787    1 #>   # Predicted probabilities of success in each study in the network predict(smk_fit_RE, type = \"response\") #> ---------------------------------------------------------------------- Study: 1 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[1: No intervention]        0.06 0.02 0.03 0.05 0.06 0.07  0.10     5003 #> pred[1: Group counselling]      0.17 0.07 0.07 0.12 0.16 0.21  0.34     2964 #> pred[1: Individual counselling] 0.13 0.04 0.06 0.10 0.13 0.16  0.23     2645 #> pred[1: Self-help]              0.10 0.04 0.04 0.07 0.09 0.12  0.20     2666 #>                                 Tail_ESS Rhat #> pred[1: No intervention]            3082    1 #> pred[1: Group counselling]          2989    1 #> pred[1: Individual counselling]     2582    1 #> pred[1: Self-help]                  2832    1 #>  #> ---------------------------------------------------------------------- Study: 2 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[2: No intervention]        0.09 0.06 0.02 0.04 0.07 0.11  0.26     2781 #> pred[2: Group counselling]      0.21 0.12 0.05 0.12 0.19 0.27  0.52     3518 #> pred[2: Individual counselling] 0.18 0.11 0.04 0.10 0.15 0.22  0.44     3012 #> pred[2: Self-help]              0.13 0.09 0.03 0.07 0.11 0.17  0.36     3534 #>                                 Tail_ESS Rhat #> pred[2: No intervention]            2596    1 #> pred[2: Group counselling]          2580    1 #> pred[2: Individual counselling]     2722    1 #> pred[2: Self-help]                  2695    1 #>  #> ---------------------------------------------------------------------- Study: 3 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[3: No intervention]        0.11 0.01 0.08 0.10 0.11 0.11  0.13     7734 #> pred[3: Group counselling]      0.27 0.09 0.13 0.21 0.26 0.32  0.47     2427 #> pred[3: Individual counselling] 0.22 0.04 0.14 0.19 0.22 0.24  0.32     1718 #> pred[3: Self-help]              0.17 0.06 0.08 0.13 0.16 0.20  0.30     2131 #>                                 Tail_ESS Rhat #> pred[3: No intervention]            2393    1 #> pred[3: Group counselling]          2923    1 #> pred[3: Individual counselling]     2516    1 #> pred[3: Self-help]                  2467    1 #>  #> ---------------------------------------------------------------------- Study: 4 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[4: No intervention]        0.02 0.01 0.01 0.01 0.02 0.02  0.05     3832 #> pred[4: Group counselling]      0.06 0.04 0.01 0.03 0.05 0.08  0.16     3465 #> pred[4: Individual counselling] 0.04 0.02 0.01 0.03 0.04 0.06  0.11     3953 #> pred[4: Self-help]              0.03 0.02 0.01 0.02 0.03 0.04  0.09     3272 #>                                 Tail_ESS Rhat #> pred[4: No intervention]            2586    1 #> pred[4: Group counselling]          3191    1 #> pred[4: Individual counselling]     2837    1 #> pred[4: Self-help]                  2919    1 #>  #> ---------------------------------------------------------------------- Study: 5 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[5: No intervention]        0.10 0.01 0.08 0.10 0.10 0.11  0.13     8858 #> pred[5: Group counselling]      0.27 0.09 0.13 0.21 0.26 0.32  0.47     2410 #> pred[5: Individual counselling] 0.22 0.05 0.14 0.18 0.21 0.24  0.32     1740 #> pred[5: Self-help]              0.17 0.06 0.08 0.13 0.16 0.20  0.30     2217 #>                                 Tail_ESS Rhat #> pred[5: No intervention]            2612    1 #> pred[5: Group counselling]          2609    1 #> pred[5: Individual counselling]     2415    1 #> pred[5: Self-help]                  2640    1 #>  #> ---------------------------------------------------------------------- Study: 6 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[6: No intervention]        0.04 0.03 0.01 0.02 0.03 0.05  0.10     3675 #> pred[6: Group counselling]      0.11 0.07 0.02 0.06 0.09 0.14  0.30     3684 #> pred[6: Individual counselling] 0.08 0.05 0.02 0.05 0.07 0.11  0.21     3861 #> pred[6: Self-help]              0.06 0.05 0.01 0.03 0.05 0.08  0.19     3346 #>                                 Tail_ESS Rhat #> pred[6: No intervention]            2769    1 #> pred[6: Group counselling]          2733    1 #> pred[6: Individual counselling]     2646    1 #> pred[6: Self-help]                  2389    1 #>  #> ---------------------------------------------------------------------- Study: 7 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[7: No intervention]        0.05 0.02 0.02 0.04 0.05 0.06  0.10     4033 #> pred[7: Group counselling]      0.14 0.07 0.04 0.09 0.13 0.18  0.31     3385 #> pred[7: Individual counselling] 0.11 0.04 0.04 0.08 0.10 0.13  0.21     2771 #> pred[7: Self-help]              0.08 0.04 0.02 0.05 0.07 0.10  0.18     2816 #>                                 Tail_ESS Rhat #> pred[7: No intervention]            2673    1 #> pred[7: Group counselling]          3139    1 #> pred[7: Individual counselling]     2546    1 #> pred[7: Self-help]                  2333    1 #>  #> ---------------------------------------------------------------------- Study: 8 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[8: No intervention]        0.07 0.04 0.02 0.04 0.06 0.09  0.16     3644 #> pred[8: Group counselling]      0.19 0.10 0.04 0.11 0.17 0.24  0.43     3605 #> pred[8: Individual counselling] 0.15 0.07 0.04 0.10 0.14 0.19  0.30     3705 #> pred[8: Self-help]              0.11 0.07 0.02 0.07 0.10 0.15  0.28     3304 #>                                 Tail_ESS Rhat #> pred[8: No intervention]            2633    1 #> pred[8: Group counselling]          2693    1 #> pred[8: Individual counselling]     2602    1 #> pred[8: Self-help]                  2677    1 #>  #> ---------------------------------------------------------------------- Study: 9 ----  #>  #>                                 mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[9: No intervention]        0.14 0.05 0.06 0.11 0.14 0.17  0.25     4487 #> pred[9: Group counselling]      0.34 0.12 0.13 0.25 0.32 0.41  0.60     3076 #> pred[9: Individual counselling] 0.28 0.09 0.13 0.21 0.27 0.34  0.47     3016 #> pred[9: Self-help]              0.22 0.09 0.08 0.15 0.20 0.27  0.43     2866 #>                                 Tail_ESS Rhat #> pred[9: No intervention]            2960    1 #> pred[9: Group counselling]          2695    1 #> pred[9: Individual counselling]     2823    1 #> pred[9: Self-help]                  2937    1 #>  #> --------------------------------------------------------------------- Study: 10 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[10: No intervention]        0.11 0.01 0.09 0.10 0.11 0.12  0.14     9817 #> pred[10: Group counselling]      0.28 0.09 0.14 0.22 0.27 0.33  0.49     2404 #> pred[10: Individual counselling] 0.23 0.05 0.15 0.20 0.23 0.26  0.33     1767 #> pred[10: Self-help]              0.18 0.06 0.08 0.13 0.17 0.21  0.31     2092 #>                                  Tail_ESS Rhat #> pred[10: No intervention]            3071    1 #> pred[10: Group counselling]          2858    1 #> pred[10: Individual counselling]     2390    1 #> pred[10: Self-help]                  2497    1 #>  #> --------------------------------------------------------------------- Study: 11 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[11: No intervention]        0.03 0.01 0.02 0.02 0.03 0.03  0.04     6578 #> pred[11: Group counselling]      0.08 0.04 0.03 0.06 0.07 0.10  0.18     2752 #> pred[11: Individual counselling] 0.06 0.02 0.03 0.05 0.06 0.07  0.11     2500 #> pred[11: Self-help]              0.05 0.02 0.02 0.03 0.04 0.05  0.09     2374 #>                                  Tail_ESS Rhat #> pred[11: No intervention]            2799    1 #> pred[11: Group counselling]          2993    1 #> pred[11: Individual counselling]     3013    1 #> pred[11: Self-help]                  2710    1 #>  #> --------------------------------------------------------------------- Study: 12 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[12: No intervention]        0.10 0.01 0.08 0.09 0.10 0.11  0.12     7819 #> pred[12: Group counselling]      0.26 0.09 0.12 0.19 0.25 0.31  0.46     2386 #> pred[12: Individual counselling] 0.21 0.04 0.13 0.17 0.20 0.23  0.30     1786 #> pred[12: Self-help]              0.16 0.06 0.07 0.12 0.15 0.19  0.29     2144 #>                                  Tail_ESS Rhat #> pred[12: No intervention]            2793    1 #> pred[12: Group counselling]          2539    1 #> pred[12: Individual counselling]     2510    1 #> pred[12: Self-help]                  2733    1 #>  #> --------------------------------------------------------------------- Study: 13 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[13: No intervention]        0.07 0.03 0.03 0.05 0.07 0.09  0.13     4921 #> pred[13: Group counselling]      0.19 0.09 0.06 0.12 0.17 0.24  0.41     3275 #> pred[13: Individual counselling] 0.15 0.06 0.06 0.11 0.14 0.18  0.29     3588 #> pred[13: Self-help]              0.11 0.06 0.03 0.07 0.10 0.14  0.26     2998 #>                                  Tail_ESS Rhat #> pred[13: No intervention]            3014    1 #> pred[13: Group counselling]          2981    1 #> pred[13: Individual counselling]     3297    1 #> pred[13: Self-help]                  3093    1 #>  #> --------------------------------------------------------------------- Study: 14 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[14: No intervention]        0.08 0.02 0.05 0.07 0.08 0.10  0.12     6608 #> pred[14: Group counselling]      0.22 0.08 0.09 0.16 0.21 0.27  0.43     2719 #> pred[14: Individual counselling] 0.18 0.05 0.10 0.14 0.17 0.21  0.28     2309 #> pred[14: Self-help]              0.13 0.05 0.05 0.10 0.13 0.16  0.26     2508 #>                                  Tail_ESS Rhat #> pred[14: No intervention]            3029    1 #> pred[14: Group counselling]          2953    1 #> pred[14: Individual counselling]     2995    1 #> pred[14: Self-help]                  2540    1 #>  #> --------------------------------------------------------------------- Study: 15 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[15: No intervention]        0.08 0.05 0.01 0.04 0.07 0.10  0.20     3740 #> pred[15: Group counselling]      0.19 0.10 0.04 0.11 0.17 0.25  0.43     3887 #> pred[15: Individual counselling] 0.16 0.09 0.03 0.09 0.14 0.21  0.37     3633 #> pred[15: Self-help]              0.12 0.08 0.02 0.06 0.10 0.16  0.32     3424 #>                                  Tail_ESS Rhat #> pred[15: No intervention]            2685    1 #> pred[15: Group counselling]          2827    1 #> pred[15: Individual counselling]     2730    1 #> pred[15: Self-help]                  2783    1 #>  #> --------------------------------------------------------------------- Study: 16 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[16: No intervention]        0.07 0.02 0.03 0.06 0.07 0.08  0.12     6219 #> pred[16: Group counselling]      0.19 0.08 0.07 0.13 0.18 0.24  0.39     2969 #> pred[16: Individual counselling] 0.15 0.05 0.07 0.12 0.15 0.18  0.28     2907 #> pred[16: Self-help]              0.11 0.05 0.04 0.08 0.11 0.14  0.23     2734 #>                                  Tail_ESS Rhat #> pred[16: No intervention]            3013    1 #> pred[16: Group counselling]          2932    1 #> pred[16: Individual counselling]     2710    1 #> pred[16: Self-help]                  2596    1 #>  #> --------------------------------------------------------------------- Study: 17 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[17: No intervention]        0.09 0.01 0.07 0.08 0.09 0.09  0.10     8002 #> pred[17: Group counselling]      0.23 0.08 0.11 0.17 0.22 0.27  0.41     2340 #> pred[17: Individual counselling] 0.18 0.04 0.12 0.15 0.18 0.20  0.27     1633 #> pred[17: Self-help]              0.14 0.05 0.06 0.10 0.13 0.16  0.25     2121 #>                                  Tail_ESS Rhat #> pred[17: No intervention]            3309    1 #> pred[17: Group counselling]          2861    1 #> pred[17: Individual counselling]     2632    1 #> pred[17: Self-help]                  2745    1 #>  #> --------------------------------------------------------------------- Study: 18 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[18: No intervention]        0.07 0.02 0.04 0.06 0.07 0.08  0.11     4727 #> pred[18: Group counselling]      0.20 0.08 0.08 0.14 0.19 0.24  0.40     2865 #> pred[18: Individual counselling] 0.16 0.05 0.08 0.12 0.15 0.18  0.26     2401 #> pred[18: Self-help]              0.12 0.05 0.05 0.08 0.11 0.15  0.24     2552 #>                                  Tail_ESS Rhat #> pred[18: No intervention]            2897    1 #> pred[18: Group counselling]          2844    1 #> pred[18: Individual counselling]     2756    1 #> pred[18: Self-help]                  2770    1 #>  #> --------------------------------------------------------------------- Study: 19 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[19: No intervention]        0.13 0.01 0.10 0.12 0.13 0.14  0.16     7251 #> pred[19: Group counselling]      0.32 0.10 0.16 0.25 0.31 0.38  0.53     2378 #> pred[19: Individual counselling] 0.26 0.05 0.17 0.23 0.26 0.29  0.37     1662 #> pred[19: Self-help]              0.20 0.07 0.10 0.16 0.20 0.24  0.35     2181 #>                                  Tail_ESS Rhat #> pred[19: No intervention]            2631    1 #> pred[19: Group counselling]          2773    1 #> pred[19: Individual counselling]     2331    1 #> pred[19: Self-help]                  2508    1 #>  #> --------------------------------------------------------------------- Study: 20 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[20: No intervention]        0.06 0.01 0.05 0.05 0.06 0.06  0.07     7276 #> pred[20: Group counselling]      0.16 0.06 0.07 0.12 0.15 0.20  0.32     2339 #> pred[20: Individual counselling] 0.13 0.03 0.08 0.11 0.12 0.14  0.20     1711 #> pred[20: Self-help]              0.10 0.04 0.04 0.07 0.09 0.11  0.18     2095 #>                                  Tail_ESS Rhat #> pred[20: No intervention]            3281    1 #> pred[20: Group counselling]          2768    1 #> pred[20: Individual counselling]     2198    1 #> pred[20: Self-help]                  2428    1 #>  #> --------------------------------------------------------------------- Study: 21 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[21: No intervention]        0.27 0.14 0.06 0.16 0.25 0.35  0.60     3122 #> pred[21: Group counselling]      0.49 0.18 0.15 0.36 0.49 0.63  0.84     3606 #> pred[21: Individual counselling] 0.44 0.17 0.14 0.31 0.43 0.56  0.78     3670 #> pred[21: Self-help]              0.36 0.16 0.10 0.24 0.35 0.46  0.71     4213 #>                                  Tail_ESS Rhat #> pred[21: No intervention]            2788    1 #> pred[21: Group counselling]          2628    1 #> pred[21: Individual counselling]     2769    1 #> pred[21: Self-help]                  3050    1 #>  #> --------------------------------------------------------------------- Study: 22 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[22: No intervention]        0.11 0.08 0.02 0.05 0.09 0.14  0.32     2629 #> pred[22: Group counselling]      0.24 0.14 0.05 0.14 0.22 0.32  0.58     3171 #> pred[22: Individual counselling] 0.20 0.13 0.04 0.11 0.18 0.27  0.52     2794 #> pred[22: Self-help]              0.15 0.10 0.03 0.08 0.13 0.20  0.42     3028 #>                                  Tail_ESS Rhat #> pred[22: No intervention]            2496    1 #> pred[22: Group counselling]          2474    1 #> pred[22: Individual counselling]     2489    1 #> pred[22: Self-help]                  2729    1 #>  #> --------------------------------------------------------------------- Study: 23 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[23: No intervention]        0.11 0.08 0.02 0.06 0.09 0.15  0.33     3212 #> pred[23: Group counselling]      0.26 0.14 0.06 0.15 0.23 0.33  0.60     3527 #> pred[23: Individual counselling] 0.21 0.13 0.05 0.12 0.19 0.28  0.53     3496 #> pred[23: Self-help]              0.17 0.12 0.03 0.08 0.14 0.22  0.47     3373 #>                                  Tail_ESS Rhat #> pred[23: No intervention]            2805    1 #> pred[23: Group counselling]          2358    1 #> pred[23: Individual counselling]     2962    1 #> pred[23: Self-help]                  2615    1 #>  #> --------------------------------------------------------------------- Study: 24 ----  #>  #>                                  mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[24: No intervention]        0.08 0.06 0.01 0.03 0.06 0.10  0.24     3263 #> pred[24: Group counselling]      0.19 0.12 0.03 0.09 0.16 0.25  0.48     3928 #> pred[24: Individual counselling] 0.15 0.10 0.03 0.08 0.12 0.20  0.42     3762 #> pred[24: Self-help]              0.12 0.09 0.02 0.05 0.09 0.15  0.38     3386 #>                                  Tail_ESS Rhat #> pred[24: No intervention]            2717    1 #> pred[24: Group counselling]          3123    1 #> pred[24: Individual counselling]     3101    1 #> pred[24: Self-help]                  2787    1 #>   # Predicted probabilities in a population with 67 observed events out of 566 # individuals on No Intervention, corresponding to a Beta(67, 566 - 67) # distribution on the baseline probability of response, using # `baseline_type = \"response\"` (smk_pred_RE <- predict(smk_fit_RE,                         baseline = distr(qbeta, 67, 566 - 67),                         baseline_type = \"response\",                         type = \"response\")) #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[No intervention]        0.12 0.01 0.09 0.11 0.12 0.13  0.15     4265 #> pred[Group counselling]      0.30 0.09 0.14 0.23 0.28 0.35  0.51     2397 #> pred[Individual counselling] 0.24 0.05 0.15 0.21 0.24 0.27  0.35     1842 #> pred[Self-help]              0.19 0.06 0.09 0.14 0.18 0.22  0.33     2126 #>                              Tail_ESS Rhat #> pred[No intervention]            4101    1 #> pred[Group counselling]          2946    1 #> pred[Individual counselling]     2704    1 #> pred[Self-help]                  2676    1 plot(smk_pred_RE, ref_line = c(0, 1))   # Predicted probabilities in a population with a baseline log odds of # response on No Intervention given a Normal distribution with mean -2 # and SD 0.13, using `baseline_type = \"link\"` (the default) # Note: this is approximately equivalent to the above Beta distribution on # the baseline probability (smk_pred_RE2 <- predict(smk_fit_RE,                          baseline = distr(qnorm, mean = -2, sd = 0.13),                          type = \"response\")) #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[No intervention]        0.12 0.01 0.10 0.11 0.12 0.13  0.15     3952 #> pred[Group counselling]      0.30 0.09 0.15 0.23 0.29 0.35  0.51     2401 #> pred[Individual counselling] 0.24 0.05 0.16 0.21 0.24 0.27  0.35     1681 #> pred[Self-help]              0.19 0.06 0.09 0.14 0.18 0.22  0.33     2197 #>                              Tail_ESS Rhat #> pred[No intervention]            3841    1 #> pred[Group counselling]          2754    1 #> pred[Individual counselling]     2193    1 #> pred[Self-help]                  2555    1 plot(smk_pred_RE2, ref_line = c(0, 1))  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Predicted probabilities of response in each study in the network (pso_pred <- predict(pso_fit, type = \"response\")) #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[FIXTURE: PBO]     0.04 0.01 0.03 0.04 0.04 0.05  0.06     4117     3252 #> pred[FIXTURE: ETN]     0.46 0.03 0.41 0.44 0.46 0.47  0.51     8929     3349 #> pred[FIXTURE: IXE_Q2W] 0.89 0.02 0.85 0.88 0.89 0.90  0.92     6696     3224 #> pred[FIXTURE: IXE_Q4W] 0.80 0.03 0.74 0.78 0.80 0.81  0.84     7107     3476 #> pred[FIXTURE: SEC_150] 0.67 0.03 0.62 0.65 0.67 0.69  0.72    10540     2996 #> pred[FIXTURE: SEC_300] 0.77 0.02 0.72 0.75 0.77 0.79  0.81    10147     3344 #>                        Rhat #> pred[FIXTURE: PBO]        1 #> pred[FIXTURE: ETN]        1 #> pred[FIXTURE: IXE_Q2W]    1 #> pred[FIXTURE: IXE_Q4W]    1 #> pred[FIXTURE: SEC_150]    1 #> pred[FIXTURE: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-1: PBO]     0.06 0.01 0.04 0.05 0.06 0.06  0.07     4389     2445 #> pred[UNCOVER-1: ETN]     0.46 0.03 0.40 0.44 0.46 0.48  0.52     6519     3163 #> pred[UNCOVER-1: IXE_Q2W] 0.90 0.01 0.88 0.89 0.90 0.91  0.92     7696     3057 #> pred[UNCOVER-1: IXE_Q4W] 0.81 0.02 0.78 0.80 0.81 0.82  0.84     8811     3232 #> pred[UNCOVER-1: SEC_150] 0.69 0.04 0.60 0.66 0.69 0.72  0.77     7334     3201 #> pred[UNCOVER-1: SEC_300] 0.78 0.04 0.71 0.76 0.79 0.81  0.85     7307     3236 #>                          Rhat #> pred[UNCOVER-1: PBO]        1 #> pred[UNCOVER-1: ETN]        1 #> pred[UNCOVER-1: IXE_Q2W]    1 #> pred[UNCOVER-1: IXE_Q4W]    1 #> pred[UNCOVER-1: SEC_150]    1 #> pred[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-2: PBO]     0.05 0.01 0.03 0.04 0.05 0.05  0.06     5023     2686 #> pred[UNCOVER-2: ETN]     0.42 0.02 0.38 0.41 0.42 0.43  0.46     7860     2923 #> pred[UNCOVER-2: IXE_Q2W] 0.88 0.01 0.86 0.87 0.88 0.89  0.90     6705     3232 #> pred[UNCOVER-2: IXE_Q4W] 0.78 0.02 0.75 0.77 0.78 0.79  0.81     8970     3179 #> pred[UNCOVER-2: SEC_150] 0.65 0.04 0.57 0.62 0.65 0.68  0.73     8272     3016 #> pred[UNCOVER-2: SEC_300] 0.75 0.04 0.68 0.73 0.75 0.78  0.82     8812     3510 #>                          Rhat #> pred[UNCOVER-2: PBO]        1 #> pred[UNCOVER-2: ETN]        1 #> pred[UNCOVER-2: IXE_Q2W]    1 #> pred[UNCOVER-2: IXE_Q4W]    1 #> pred[UNCOVER-2: SEC_150]    1 #> pred[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[UNCOVER-3: PBO]     0.08 0.01 0.06 0.07 0.08 0.08  0.10     5375     3151 #> pred[UNCOVER-3: ETN]     0.53 0.02 0.49 0.51 0.53 0.54  0.57     6790     3011 #> pred[UNCOVER-3: IXE_Q2W] 0.93 0.01 0.91 0.92 0.93 0.93  0.94     7828     3336 #> pred[UNCOVER-3: IXE_Q4W] 0.85 0.01 0.83 0.85 0.85 0.86  0.88     8539     2781 #> pred[UNCOVER-3: SEC_150] 0.75 0.03 0.68 0.72 0.75 0.77  0.81     7568     3022 #> pred[UNCOVER-3: SEC_300] 0.83 0.03 0.77 0.81 0.83 0.85  0.88     8615     3359 #>                          Rhat #> pred[UNCOVER-3: PBO]        1 #> pred[UNCOVER-3: ETN]        1 #> pred[UNCOVER-3: IXE_Q2W]    1 #> pred[UNCOVER-3: IXE_Q4W]    1 #> pred[UNCOVER-3: SEC_150]    1 #> pred[UNCOVER-3: SEC_300]    1 #>  plot(pso_pred, ref_line = c(0, 1))   # Predicted probabilites of response in a new target population, with means # and SDs or proportions given by new_agd_int <- data.frame(   bsa_mean = 0.6,   bsa_sd = 0.3,   prevsys = 0.1,   psa = 0.2,   weight_mean = 10,   weight_sd = 1,   durnpso_mean = 3,   durnpso_sd = 1 )  # We need to add integration points to this data frame of new data # We use the weighted mean correlation matrix computed from the IPD studies new_agd_int <- add_integration(new_agd_int,                                durnpso = distr(qgamma, mean = durnpso_mean, sd = durnpso_sd),                                prevsys = distr(qbern, prob = prevsys),                                bsa = distr(qlogitnorm, mean = bsa_mean, sd = bsa_sd),                                weight = distr(qgamma, mean = weight_mean, sd = weight_sd),                                psa = distr(qbern, prob = psa),                                cor = pso_net$int_cor,                                n_int = 64)  # Predicted probabilities of achieving PASI 75 in this target population, given # a Normal(-1.75, 0.08^2) distribution on the baseline probit-probability of # response on Placebo (at the reference levels of the covariates), are given by (pso_pred_new <- predict(pso_fit,                          type = \"response\",                          newdata = new_agd_int,                          baseline = distr(qnorm, -1.75, 0.08))) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #>                      mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> pred[New 1: PBO]     0.06 0.02 0.03 0.04 0.06 0.07  0.12     5829     3444    1 #> pred[New 1: ETN]     0.37 0.06 0.26 0.33 0.37 0.41  0.49     6096     3533    1 #> pred[New 1: IXE_Q2W] 0.90 0.02 0.84 0.88 0.90 0.92  0.94     4822     3628    1 #> pred[New 1: IXE_Q4W] 0.81 0.04 0.73 0.78 0.81 0.83  0.87     4928     3848    1 #> pred[New 1: SEC_150] 0.68 0.06 0.57 0.64 0.68 0.72  0.79     5317     4083    1 #> pred[New 1: SEC_300] 0.78 0.05 0.68 0.75 0.78 0.81  0.86     5837     3646    1 #>  plot(pso_pred_new, ref_line = c(0, 1))  # }  ## Progression free survival with newly-diagnosed multiple myeloma # \\donttest{ # Run newly-diagnosed multiple myeloma example if not already available if (!exists(\"ndmm_fit\")) example(\"example_ndmm\", run.donttest = TRUE) # } # \\donttest{ # We can produce a range of predictions from models with survival outcomes, # chosen with the type argument to predict  # Predicted survival probabilities at 5 years predict(ndmm_fit, type = \"survival\", times = 5) #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                          .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Attal2012: Pbo, 1]      5 0.19 0.02 0.15 0.18 0.19 0.21  0.23     5822 #> pred[Attal2012: Len, 1]      5 0.38 0.02 0.33 0.36 0.38 0.40  0.43     5145 #> pred[Attal2012: Thal, 1]     5 0.23 0.04 0.16 0.20 0.23 0.25  0.30     5647 #>                          Tail_ESS Rhat #> pred[Attal2012: Pbo, 1]      2788    1 #> pred[Attal2012: Len, 1]      3188    1 #> pred[Attal2012: Thal, 1]     3218    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                            .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Jackson2019: Pbo, 1]      5 0.25 0.01 0.22 0.24 0.25 0.26  0.28     5100 #> pred[Jackson2019: Len, 1]      5 0.45 0.01 0.42 0.44 0.45 0.45  0.47     5571 #> pred[Jackson2019: Thal, 1]     5 0.29 0.03 0.22 0.27 0.29 0.31  0.36     5286 #>                            Tail_ESS Rhat #> pred[Jackson2019: Pbo, 1]      3508    1 #> pred[Jackson2019: Len, 1]      3143    1 #> pred[Jackson2019: Thal, 1]     3017    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                             .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[McCarthy2012: Pbo, 1]      5 0.27 0.02 0.22 0.25 0.27 0.28  0.31     4902 #> pred[McCarthy2012: Len, 1]      5 0.46 0.02 0.42 0.45 0.46 0.48  0.51     4800 #> pred[McCarthy2012: Thal, 1]     5 0.31 0.04 0.23 0.28 0.31 0.33  0.38     5197 #>                             Tail_ESS Rhat #> pred[McCarthy2012: Pbo, 1]      3146    1 #> pred[McCarthy2012: Len, 1]      3225    1 #> pred[McCarthy2012: Thal, 1]     3275    1 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                           .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Morgan2012: Pbo, 1]      5 0.24 0.02 0.20 0.22 0.24 0.25  0.28     5218 #> pred[Morgan2012: Len, 1]      5 0.43 0.03 0.38 0.41 0.43 0.45  0.49     5517 #> pred[Morgan2012: Thal, 1]     5 0.28 0.02 0.23 0.26 0.28 0.29  0.33     5605 #>                           Tail_ESS Rhat #> pred[Morgan2012: Pbo, 1]      3085    1 #> pred[Morgan2012: Len, 1]      3165    1 #> pred[Morgan2012: Thal, 1]     2756    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                            .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Palumbo2014: Pbo, 1]      5 0.20 0.03 0.14 0.17 0.19 0.22  0.26     4788 #> pred[Palumbo2014: Len, 1]      5 0.38 0.04 0.32 0.36 0.38 0.41  0.45     4630 #> pred[Palumbo2014: Thal, 1]     5 0.23 0.04 0.15 0.20 0.23 0.26  0.32     4865 #>                            Tail_ESS Rhat #> pred[Palumbo2014: Pbo, 1]      2993    1 #> pred[Palumbo2014: Len, 1]      2971    1 #> pred[Palumbo2014: Thal, 1]     3241    1 #>   # Survival curves plot(predict(ndmm_fit, type = \"survival\"))   # Hazard curves # Here we specify a vector of times to avoid attempting to plot infinite # hazards for some studies at t=0 plot(predict(ndmm_fit, type = \"hazard\", times = seq(0.001, 6, length.out = 50)))   # Cumulative hazard curves plot(predict(ndmm_fit, type = \"cumhaz\"))   # Survival time quantiles and median survival predict(ndmm_fit, type = \"quantile\", quantiles = c(0.2, 0.5, 0.8)) #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                            mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Attal2012: Pbo, 0.2]  1.07 0.07 0.93 1.02 1.07 1.11  1.21     4068 #> pred[Attal2012: Pbo, 0.5]  2.56 0.12 2.34 2.48 2.56 2.63  2.79     4946 #> pred[Attal2012: Pbo, 0.8]  4.90 0.25 4.46 4.73 4.89 5.06  5.42     5829 #> pred[Attal2012: Len, 0.2]  1.61 0.09 1.44 1.55 1.61 1.68  1.80     4660 #> pred[Attal2012: Len, 0.5]  3.88 0.19 3.54 3.75 3.86 3.99  4.27     5174 #> pred[Attal2012: Len, 0.8]  7.44 0.46 6.61 7.11 7.40 7.73  8.43     4964 #> pred[Attal2012: Thal, 0.2] 1.17 0.11 0.97 1.09 1.16 1.24  1.39     4315 #> pred[Attal2012: Thal, 0.5] 2.80 0.23 2.37 2.64 2.79 2.94  3.26     5035 #> pred[Attal2012: Thal, 0.8] 5.37 0.46 4.52 5.05 5.34 5.66  6.35     5625 #>                            Tail_ESS Rhat #> pred[Attal2012: Pbo, 0.2]      3111    1 #> pred[Attal2012: Pbo, 0.5]      3120    1 #> pred[Attal2012: Pbo, 0.8]      2732    1 #> pred[Attal2012: Len, 0.2]      3115    1 #> pred[Attal2012: Len, 0.5]      3001    1 #> pred[Attal2012: Len, 0.8]      3028    1 #> pred[Attal2012: Thal, 0.2]     2838    1 #> pred[Attal2012: Thal, 0.5]     3231    1 #> pred[Attal2012: Thal, 0.8]     3246    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                               mean   sd 2.5%   25%   50%   75% 97.5% Bulk_ESS #> pred[Jackson2019: Pbo, 0.2]   0.71 0.04 0.63  0.68  0.71  0.74  0.78     4161 #> pred[Jackson2019: Pbo, 0.5]   2.38 0.10 2.19  2.32  2.38  2.45  2.58     4516 #> pred[Jackson2019: Pbo, 0.8]   5.88 0.25 5.40  5.71  5.87  6.04  6.40     5207 #> pred[Jackson2019: Len, 0.2]   1.26 0.06 1.14  1.22  1.26  1.30  1.38     5722 #> pred[Jackson2019: Len, 0.5]   4.24 0.16 3.95  4.13  4.24  4.35  4.56     5649 #> pred[Jackson2019: Len, 0.8]  10.46 0.46 9.62 10.14 10.45 10.76 11.42     5195 #> pred[Jackson2019: Thal, 0.2]  0.80 0.09 0.64  0.74  0.80  0.86  0.99     4929 #> pred[Jackson2019: Thal, 0.5]  2.70 0.28 2.19  2.51  2.69  2.88  3.30     5176 #> pred[Jackson2019: Thal, 0.8]  6.67 0.70 5.40  6.18  6.63  7.09  8.12     5301 #>                              Tail_ESS Rhat #> pred[Jackson2019: Pbo, 0.2]      2692    1 #> pred[Jackson2019: Pbo, 0.5]      3071    1 #> pred[Jackson2019: Pbo, 0.8]      3496    1 #> pred[Jackson2019: Len, 0.2]      3289    1 #> pred[Jackson2019: Len, 0.5]      3229    1 #> pred[Jackson2019: Len, 0.8]      2915    1 #> pred[Jackson2019: Thal, 0.2]     2598    1 #> pred[Jackson2019: Thal, 0.5]     3007    1 #> pred[Jackson2019: Thal, 0.8]     2923    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                               mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[McCarthy2012: Pbo, 0.2]  1.26 0.10 1.08 1.20 1.26 1.33  1.45     4101 #> pred[McCarthy2012: Pbo, 0.5]  3.03 0.15 2.74 2.93 3.03 3.13  3.35     4419 #> pred[McCarthy2012: Pbo, 0.8]  5.82 0.31 5.25 5.60 5.80 6.02  6.48     4962 #> pred[McCarthy2012: Len, 0.2]  1.91 0.12 1.67 1.83 1.91 1.99  2.16     4427 #> pred[McCarthy2012: Len, 0.5]  4.60 0.23 4.17 4.44 4.58 4.74  5.08     4790 #> pred[McCarthy2012: Len, 0.8]  8.83 0.57 7.81 8.44 8.79 9.18 10.03     4702 #> pred[McCarthy2012: Thal, 0.2] 1.38 0.14 1.12 1.28 1.38 1.47  1.66     4619 #> pred[McCarthy2012: Thal, 0.5] 3.32 0.28 2.80 3.12 3.31 3.51  3.89     5022 #> pred[McCarthy2012: Thal, 0.8] 6.37 0.56 5.35 5.97 6.34 6.74  7.55     5230 #>                               Tail_ESS Rhat #> pred[McCarthy2012: Pbo, 0.2]      3445    1 #> pred[McCarthy2012: Pbo, 0.5]      3572    1 #> pred[McCarthy2012: Pbo, 0.8]      3289    1 #> pred[McCarthy2012: Len, 0.2]      2973    1 #> pred[McCarthy2012: Len, 0.5]      3152    1 #> pred[McCarthy2012: Len, 0.8]      3520    1 #> pred[McCarthy2012: Thal, 0.2]     3039    1 #> pred[McCarthy2012: Thal, 0.5]     3171    1 #> pred[McCarthy2012: Thal, 0.8]     3394    1 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                              mean   sd 2.5%  25%   50%   75% 97.5% Bulk_ESS #> pred[Morgan2012: Pbo, 0.2]   0.61 0.06 0.50 0.57  0.61  0.64  0.72     4903 #> pred[Morgan2012: Pbo, 0.5]   2.20 0.16 1.90 2.09  2.19  2.30  2.52     4979 #> pred[Morgan2012: Pbo, 0.8]   5.72 0.43 4.94 5.43  5.69  6.00  6.65     5317 #> pred[Morgan2012: Len, 0.2]   1.12 0.11 0.92 1.05  1.11  1.19  1.34     5103 #> pred[Morgan2012: Len, 0.5]   4.06 0.37 3.39 3.80  4.04  4.29  4.82     5457 #> pred[Morgan2012: Len, 0.8]  10.57 1.07 8.67 9.83 10.48 11.26 12.90     5789 #> pred[Morgan2012: Thal, 0.2]  0.69 0.06 0.58 0.65  0.69  0.73  0.82     6229 #> pred[Morgan2012: Thal, 0.5]  2.50 0.18 2.17 2.37  2.49  2.61  2.89     6042 #> pred[Morgan2012: Thal, 0.8]  6.51 0.50 5.63 6.16  6.48  6.82  7.62     5520 #>                             Tail_ESS Rhat #> pred[Morgan2012: Pbo, 0.2]      2990    1 #> pred[Morgan2012: Pbo, 0.5]      3022    1 #> pred[Morgan2012: Pbo, 0.8]      2922    1 #> pred[Morgan2012: Len, 0.2]      2419    1 #> pred[Morgan2012: Len, 0.5]      3138    1 #> pred[Morgan2012: Len, 0.8]      3054    1 #> pred[Morgan2012: Thal, 0.2]     3312    1 #> pred[Morgan2012: Thal, 0.5]     2714    1 #> pred[Morgan2012: Thal, 0.8]     2485    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                              mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Palumbo2014: Pbo, 0.2]  0.71 0.09 0.53 0.64 0.70 0.76  0.89     4558 #> pred[Palumbo2014: Pbo, 0.5]  2.15 0.19 1.79 2.02 2.14 2.28  2.56     4757 #> pred[Palumbo2014: Pbo, 0.8]  4.95 0.48 4.14 4.60 4.91 5.25  6.00     4857 #> pred[Palumbo2014: Len, 0.2]  1.20 0.13 0.96 1.11 1.19 1.28  1.46     4932 #> pred[Palumbo2014: Len, 0.5]  3.66 0.33 3.09 3.43 3.64 3.88  4.36     4831 #> pred[Palumbo2014: Len, 0.8]  8.45 1.00 6.83 7.73 8.34 9.05 10.68     4484 #> pred[Palumbo2014: Thal, 0.2] 0.79 0.12 0.57 0.71 0.79 0.87  1.04     4351 #> pred[Palumbo2014: Thal, 0.5] 2.42 0.30 1.87 2.21 2.40 2.61  3.06     4714 #> pred[Palumbo2014: Thal, 0.8] 5.56 0.75 4.31 5.03 5.48 6.02  7.24     4830 #>                              Tail_ESS Rhat #> pred[Palumbo2014: Pbo, 0.2]      2872    1 #> pred[Palumbo2014: Pbo, 0.5]      3340    1 #> pred[Palumbo2014: Pbo, 0.8]      3016    1 #> pred[Palumbo2014: Len, 0.2]      3246    1 #> pred[Palumbo2014: Len, 0.5]      2880    1 #> pred[Palumbo2014: Len, 0.8]      3027    1 #> pred[Palumbo2014: Thal, 0.2]     2969    1 #> pred[Palumbo2014: Thal, 0.5]     3147    1 #> pred[Palumbo2014: Thal, 0.8]     3359    1 #>  plot(predict(ndmm_fit, type = \"median\"))   # Mean survival time predict(ndmm_fit, type = \"mean\") #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[Attal2012: Pbo]  3.14 0.15 2.87 3.04 3.13 3.24  3.45     5832     2775 #> pred[Attal2012: Len]  4.76 0.27 4.28 4.57 4.74 4.93  5.35     5044     3354 #> pred[Attal2012: Thal] 3.43 0.29 2.91 3.23 3.42 3.62  4.04     5507     3183 #>                       Rhat #> pred[Attal2012: Pbo]     1 #> pred[Attal2012: Len]     1 #> pred[Attal2012: Thal]    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[Jackson2019: Pbo]  3.65 0.16 3.35 3.54 3.64 3.74  3.96     5196     3464 #> pred[Jackson2019: Len]  6.49 0.29 5.97 6.29 6.48 6.67  7.08     5194     3130 #> pred[Jackson2019: Thal] 4.13 0.43 3.35 3.83 4.11 4.40  5.04     5300     2901 #>                         Rhat #> pred[Jackson2019: Pbo]     1 #> pred[Jackson2019: Len]     1 #> pred[Jackson2019: Thal]    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                          mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[McCarthy2012: Pbo]  3.72 0.19 3.38 3.59 3.72 3.85  4.12     4903     3264 #> pred[McCarthy2012: Len]  5.65 0.34 5.05 5.42 5.63 5.86  6.36     4734     3518 #> pred[McCarthy2012: Thal] 4.08 0.35 3.43 3.82 4.06 4.30  4.81     5219     3276 #>                          Rhat #> pred[McCarthy2012: Pbo]     1 #> pred[McCarthy2012: Len]     1 #> pred[McCarthy2012: Thal]    1 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                        mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[Morgan2012: Pbo]  3.55 0.27 3.07 3.37 3.53 3.73  4.14     5330     2856 #> pred[Morgan2012: Len]  6.57 0.67 5.38 6.10 6.51 6.99  8.02     5800     3057 #> pred[Morgan2012: Thal] 4.04 0.32 3.49 3.82 4.02 4.23  4.73     5505     2535 #>                        Rhat #> pred[Morgan2012: Pbo]     1 #> pred[Morgan2012: Len]     1 #> pred[Morgan2012: Thal]    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                         mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> pred[Palumbo2014: Pbo]  3.08 0.30 2.58 2.87 3.06 3.26  3.73     4917     2946 #> pred[Palumbo2014: Len]  5.26 0.61 4.27 4.82 5.19 5.62  6.62     4513     3076 #> pred[Palumbo2014: Thal] 3.46 0.47 2.69 3.13 3.42 3.75  4.50     4847     3359 #>                         Rhat #> pred[Palumbo2014: Pbo]     1 #> pred[Palumbo2014: Len]     1 #> pred[Palumbo2014: Thal]    1 #>   # Restricted mean survival time # By default, the time horizon is the shortest follow-up time in the network predict(ndmm_fit, type = \"rmst\") #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                       .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Attal2012: Pbo]   4.01 2.49 0.06 2.37 2.45 2.49 2.53  2.61     4713 #> pred[Attal2012: Len]   4.01 2.99 0.05 2.89 2.96 2.99 3.03  3.09     4959 #> pred[Attal2012: Thal]  4.01 2.61 0.11 2.39 2.54 2.61 2.68  2.81     4855 #>                       Tail_ESS Rhat #> pred[Attal2012: Pbo]      3254    1 #> pred[Attal2012: Len]      3288    1 #> pred[Attal2012: Thal]     3179    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                         .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Jackson2019: Pbo]   4.01 2.36 0.04 2.27 2.33 2.36 2.39  2.44     4412 #> pred[Jackson2019: Len]   4.01 2.91 0.03 2.84 2.88 2.91 2.93  2.97     5802 #> pred[Jackson2019: Thal]  4.01 2.48 0.11 2.27 2.41 2.49 2.55  2.69     5142 #>                         Tail_ESS Rhat #> pred[Jackson2019: Pbo]      3109    1 #> pred[Jackson2019: Len]      3483    1 #> pred[Jackson2019: Thal]     2912    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                          .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[McCarthy2012: Pbo]   4.01 2.71 0.07 2.57 2.66 2.71 2.76  2.84     4251 #> pred[McCarthy2012: Len]   4.01 3.16 0.05 3.05 3.13 3.16 3.19  3.26     4504 #> pred[McCarthy2012: Thal]  4.01 2.81 0.10 2.60 2.74 2.82 2.89  3.01     4873 #>                          Tail_ESS Rhat #> pred[McCarthy2012: Pbo]      3723    1 #> pred[McCarthy2012: Len]      3253    1 #> pred[McCarthy2012: Thal]     3048    1 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                        .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Morgan2012: Pbo]   4.01 2.26 0.07 2.12 2.21 2.26 2.31  2.41     4956 #> pred[Morgan2012: Len]   4.01 2.83 0.07 2.68 2.79 2.84 2.88  2.98     5228 #> pred[Morgan2012: Thal]  4.01 2.39 0.07 2.25 2.34 2.39 2.44  2.54     6134 #>                        Tail_ESS Rhat #> pred[Morgan2012: Pbo]      3241    1 #> pred[Morgan2012: Len]      2553    1 #> pred[Morgan2012: Thal]     3064    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                         .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Palumbo2014: Pbo]   4.01 2.25 0.10 2.04 2.18 2.25 2.32  2.46     4809 #> pred[Palumbo2014: Len]   4.01 2.81 0.08 2.65 2.76 2.81 2.87  2.97     4974 #> pred[Palumbo2014: Thal]  4.01 2.38 0.14 2.09 2.28 2.38 2.47  2.64     4699 #>                         Tail_ESS Rhat #> pred[Palumbo2014: Pbo]      3360    1 #> pred[Palumbo2014: Len]      3376    1 #> pred[Palumbo2014: Thal]     3125    1 #>   # An alternative restriction time can be set using the times argument predict(ndmm_fit, type = \"rmst\", times = 5)  # 5-year RMST #> -------------------------------------------------------------- Study: Attal2012 ----  #>  #>                       .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Attal2012: Pbo]      5 2.73 0.08 2.57 2.67 2.73 2.78  2.88     5032 #> pred[Attal2012: Len]      5 3.42 0.07 3.28 3.37 3.42 3.47  3.56     5097 #> pred[Attal2012: Thal]     5 2.88 0.14 2.59 2.78 2.88 2.98  3.15     5041 #>                       Tail_ESS Rhat #> pred[Attal2012: Pbo]      2986    1 #> pred[Attal2012: Len]      3238    1 #> pred[Attal2012: Thal]     3205    1 #>  #> ------------------------------------------------------------ Study: Jackson2019 ----  #>  #>                         .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Jackson2019: Pbo]      5 2.64 0.06 2.52 2.60 2.64 2.68  2.75     4541 #> pred[Jackson2019: Len]      5 3.38 0.05 3.29 3.35 3.38 3.41  3.47     5794 #> pred[Jackson2019: Thal]     5 2.80 0.14 2.52 2.71 2.81 2.90  3.08     5184 #>                         Tail_ESS Rhat #> pred[Jackson2019: Pbo]      3184    1 #> pred[Jackson2019: Len]      3654    1 #> pred[Jackson2019: Thal]     2963    1 #>  #> ----------------------------------------------------------- Study: McCarthy2012 ----  #>  #>                          .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[McCarthy2012: Pbo]      5 3.02 0.09 2.85 2.96 3.02 3.08  3.19     4353 #> pred[McCarthy2012: Len]      5 3.66 0.07 3.52 3.61 3.66 3.71  3.80     4592 #> pred[McCarthy2012: Thal]     5 3.16 0.14 2.88 3.07 3.17 3.26  3.43     4961 #>                          Tail_ESS Rhat #> pred[McCarthy2012: Pbo]      3578    1 #> pred[McCarthy2012: Len]      3107    1 #> pred[McCarthy2012: Thal]     3022    1 #>  #> ------------------------------------------------------------- Study: Morgan2012 ----  #>  #>                        .time mean  sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Morgan2012: Pbo]      5 2.53 0.1 2.34 2.47 2.53 2.59  2.72     4997 #> pred[Morgan2012: Len]      5 3.29 0.1 3.09 3.23 3.30 3.36  3.48     5289 #> pred[Morgan2012: Thal]     5 2.70 0.1 2.52 2.64 2.70 2.76  2.89     6062 #>                        Tail_ESS Rhat #> pred[Morgan2012: Pbo]      3022    1 #> pred[Morgan2012: Len]      3022    1 #> pred[Morgan2012: Thal]     2971    1 #>  #> ------------------------------------------------------------ Study: Palumbo2014 ----  #>  #>                         .time mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS #> pred[Palumbo2014: Pbo]      5 2.48 0.13 2.22 2.39 2.48 2.56  2.74     4837 #> pred[Palumbo2014: Len]      5 3.23 0.11 3.01 3.15 3.23 3.31  3.45     4983 #> pred[Palumbo2014: Thal]     5 2.64 0.18 2.28 2.52 2.64 2.77  2.99     4783 #>                         Tail_ESS Rhat #> pred[Palumbo2014: Pbo]      3285    1 #> pred[Palumbo2014: Len]      3266    1 #> pred[Palumbo2014: Thal]     3318    1 #>  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Print nma_data objects — print.nma_data","title":"Print nma_data objects — print.nma_data","text":"Print details networks stored nma_data objects, created set_ipd(), set_agd_arm(), set_agd_contrast(), set_agd_surv(), combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print nma_data objects — print.nma_data","text":"","code":"# S3 method for class 'nma_data' print(x, ..., n = 10)  # S3 method for class 'mlnmr_data' print(x, ..., n = 10)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print nma_data objects — print.nma_data","text":"x nma_data object ... options (used) n number studies type print","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print nma_data objects — print.nma_data","text":"x returned invisibly.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Print DIC details — print.nma_dic","title":"Print DIC details — print.nma_dic","text":"Print details DIC model fit statistics, computed dic() function.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print DIC details — print.nma_dic","text":"","code":"# S3 method for class 'nma_dic' print(x, digits = 1, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print DIC details — print.nma_dic","text":"x object class nma_dic digits integer passed round() ... Ignored","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print DIC details — print.nma_dic","text":"x returned invisibly.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"Print nma_nodesplit_df objects","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"","code":"# S3 method for class 'nma_nodesplit_df' print(x, ...)  # S3 method for class 'nma_nodesplit' print(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"x nma_nodesplit_df object ... arguments passed print.stanfit()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.nma_nodesplit_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print nma_nodesplit_df objects — print.nma_nodesplit_df","text":"x returned invisibly.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Print stan_nma objects — print.stan_nma","title":"Print stan_nma objects — print.stan_nma","text":"Print stan_nma objects","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print stan_nma objects — print.stan_nma","text":"","code":"# S3 method for class 'stan_nma' print(x, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print stan_nma objects — print.stan_nma","text":"x stan_nma object ... arguments passed print.stanfit()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/print.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print stan_nma objects — print.stan_nma","text":"x returned invisibly.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":null,"dir":"Reference","previous_headings":"","what":"Prior distributions — priors","title":"Prior distributions — priors","text":"functions used specify prior distributions model parameters.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prior distributions — priors","text":"","code":"normal(location = 0, scale)  half_normal(scale)  log_normal(location, scale)  cauchy(location = 0, scale)  half_cauchy(scale)  student_t(location = 0, scale, df)  half_student_t(scale, df)  log_student_t(location, scale, df)  exponential(scale = 1/rate, rate = 1/scale)  flat()"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prior distributions — priors","text":"location Prior location. Typically prior mean (see details). scale Prior scale. Typically prior standard deviation (see details). df Prior degrees freedom. rate Prior rate.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prior distributions — priors","text":"Object class nma_prior.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prior distributions — priors","text":"location scale parameters typically prior mean standard deviation, following exceptions: Cauchy distribution location prior median scale prior scale. log-Normal distribution, location scale prior mean standard deviation logarithm.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/priors.html","id":"compatibility-with-model-parameters","dir":"Reference","previous_headings":"","what":"Compatibility with model parameters","title":"Prior distributions — priors","text":"following table summarises prior distributions may used model parameters. Essentially, priors take non-negative values (e.g. half-Normal) may used non-negative parameters (heterogeneity SD/variance/precision, auxiliary parameter). real-valued prior distribution specified non-negative parameter, truncated 0 non-negative. flat() prior special case prior information added model, resulting implicit flat uniform prior distribution entire support parameter. improper prior parameter unbounded, generally advised. See Stan user's guide details.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Random effects structure — RE_cor","title":"Random effects structure — RE_cor","text":"Use RE_cor generate random effects correlation matrix, assumption common heterogeneity variance (.e. within-study correlations 0.5). Use which_RE return vector IDs RE deltas (0 means RE delta arm).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random effects structure — RE_cor","text":"","code":"RE_cor(study, trt, contrast, type = c(\"reftrt\", \"blshift\"))  which_RE(study, trt, contrast, type = c(\"reftrt\", \"blshift\"))"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random effects structure — RE_cor","text":"study vector study IDs (integer, character, factor) trt factor vector treatment codes (coercible ), first level indicating reference treatment contrast logical vector, length study trt, indicating whether corresponding data contrast rather arm format. type Character string, whether generate RE structure \"reference treatment\" parameterisation, \"baseline shift\" parameterisation.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random effects structure — RE_cor","text":"RE_cor(), correlation matrix dimension equal number random effects deltas (excluding set equal zero). which_RE(), integer vector IDs indexing rows columns correlation matrix returned RE_cor().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/random_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random effects structure — RE_cor","text":"","code":"RE_cor(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking))) #> Coerced `trt` to factor. #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #>  [1,]  1.0  0.5  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>  [2,]  0.5  1.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>  [3,]  0.0  0.0  1.0  0.5  0.5    0    0    0    0     0     0     0     0 #>  [4,]  0.0  0.0  0.5  1.0  0.5    0    0    0    0     0     0     0     0 #>  [5,]  0.0  0.0  0.5  0.5  1.0    0    0    0    0     0     0     0     0 #>  [6,]  0.0  0.0  0.0  0.0  0.0    1    0    0    0     0     0     0     0 #>  [7,]  0.0  0.0  0.0  0.0  0.0    0    1    0    0     0     0     0     0 #>  [8,]  0.0  0.0  0.0  0.0  0.0    0    0    1    0     0     0     0     0 #>  [9,]  0.0  0.0  0.0  0.0  0.0    0    0    0    1     0     0     0     0 #> [10,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     1     0     0     0 #> [11,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     1     0     0 #> [12,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     1     0 #> [13,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     1 #> [14,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [15,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [16,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [17,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [18,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [19,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [20,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [21,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [22,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [23,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [24,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [25,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [26,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [27,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [28,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [29,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [30,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #> [31,]  0.0  0.0  0.0  0.0  0.0    0    0    0    0     0     0     0     0 #>       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] #>  [1,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [2,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [3,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [4,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [5,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [6,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [7,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [8,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>  [9,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [10,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [11,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [12,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [13,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [14,]     1     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [15,]     0     1     0     0     0     0     0     0     0     0   0.0   0.0 #> [16,]     0     0     1     0     0     0     0     0     0     0   0.0   0.0 #> [17,]     0     0     0     1     0     0     0     0     0     0   0.0   0.0 #> [18,]     0     0     0     0     1     0     0     0     0     0   0.0   0.0 #> [19,]     0     0     0     0     0     1     0     0     0     0   0.0   0.0 #> [20,]     0     0     0     0     0     0     1     0     0     0   0.0   0.0 #> [21,]     0     0     0     0     0     0     0     1     0     0   0.0   0.0 #> [22,]     0     0     0     0     0     0     0     0     1     0   0.0   0.0 #> [23,]     0     0     0     0     0     0     0     0     0     1   0.0   0.0 #> [24,]     0     0     0     0     0     0     0     0     0     0   1.0   0.5 #> [25,]     0     0     0     0     0     0     0     0     0     0   0.5   1.0 #> [26,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [27,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [28,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [29,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [30,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #> [31,]     0     0     0     0     0     0     0     0     0     0   0.0   0.0 #>       [,26] [,27] [,28] [,29] [,30] [,31] #>  [1,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [2,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [3,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [4,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [5,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [6,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [7,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [8,]   0.0   0.0   0.0   0.0   0.0   0.0 #>  [9,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [10,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [11,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [12,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [13,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [14,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [15,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [16,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [17,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [18,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [19,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [20,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [21,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [22,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [23,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [24,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [25,]   0.0   0.0   0.0   0.0   0.0   0.0 #> [26,]   1.0   0.5   0.0   0.0   0.0   0.0 #> [27,]   0.5   1.0   0.0   0.0   0.0   0.0 #> [28,]   0.0   0.0   1.0   0.5   0.0   0.0 #> [29,]   0.0   0.0   0.5   1.0   0.0   0.0 #> [30,]   0.0   0.0   0.0   0.0   1.0   0.5 #> [31,]   0.0   0.0   0.0   0.0   0.5   1.0 RE_cor(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking)), type = \"blshift\") #> Coerced `trt` to factor. #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #>  [1,]  1.0  0.5  0.0  0.0    0    0    0    0    0     0     0     0     0 #>  [2,]  0.5  1.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #>  [3,]  0.0  0.0  1.0  0.5    0    0    0    0    0     0     0     0     0 #>  [4,]  0.0  0.0  0.5  1.0    0    0    0    0    0     0     0     0     0 #>  [5,]  0.0  0.0  0.0  0.0    1    0    0    0    0     0     0     0     0 #>  [6,]  0.0  0.0  0.0  0.0    0    1    0    0    0     0     0     0     0 #>  [7,]  0.0  0.0  0.0  0.0    0    0    1    0    0     0     0     0     0 #>  [8,]  0.0  0.0  0.0  0.0    0    0    0    1    0     0     0     0     0 #>  [9,]  0.0  0.0  0.0  0.0    0    0    0    0    1     0     0     0     0 #> [10,]  0.0  0.0  0.0  0.0    0    0    0    0    0     1     0     0     0 #> [11,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     1     0     0 #> [12,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     1     0 #> [13,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     1 #> [14,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [15,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [16,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [17,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [18,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [19,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [20,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [21,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [22,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [23,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [24,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [25,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #> [26,]  0.0  0.0  0.0  0.0    0    0    0    0    0     0     0     0     0 #>       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] #>  [1,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [2,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [3,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [4,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [5,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [6,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [7,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [8,]     0     0     0     0     0     0     0     0     0     0     0     0 #>  [9,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [10,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [11,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [12,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [13,]     0     0     0     0     0     0     0     0     0     0     0     0 #> [14,]     1     0     0     0     0     0     0     0     0     0     0     0 #> [15,]     0     1     0     0     0     0     0     0     0     0     0     0 #> [16,]     0     0     1     0     0     0     0     0     0     0     0     0 #> [17,]     0     0     0     1     0     0     0     0     0     0     0     0 #> [18,]     0     0     0     0     1     0     0     0     0     0     0     0 #> [19,]     0     0     0     0     0     1     0     0     0     0     0     0 #> [20,]     0     0     0     0     0     0     1     0     0     0     0     0 #> [21,]     0     0     0     0     0     0     0     1     0     0     0     0 #> [22,]     0     0     0     0     0     0     0     0     1     0     0     0 #> [23,]     0     0     0     0     0     0     0     0     0     1     0     0 #> [24,]     0     0     0     0     0     0     0     0     0     0     1     0 #> [25,]     0     0     0     0     0     0     0     0     0     0     0     1 #> [26,]     0     0     0     0     0     0     0     0     0     0     0     0 #>       [,26] #>  [1,]     0 #>  [2,]     0 #>  [3,]     0 #>  [4,]     0 #>  [5,]     0 #>  [6,]     0 #>  [7,]     0 #>  [8,]     0 #>  [9,]     0 #> [10,]     0 #> [11,]     0 #> [12,]     0 #> [13,]     0 #> [14,]     0 #> [15,]     0 #> [16,]     0 #> [17,]     0 #> [18,]     0 #> [19,]     0 #> [20,]     0 #> [21,]     0 #> [22,]     0 #> [23,]     0 #> [24,]     0 #> [25,]     0 #> [26,]     1 which_RE(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking))) #> Coerced `trt` to factor. #>  [1]  0  1  2  3  4  5  0  6  0  7  0  8  0  9  0 10  0 11  0 12  0 13  0 14  0 #> [26] 15  0 16  0 17  0 18  0 19  0 20  0 21  0 22  0 23 24 25 26 27 28 29 30 31 which_RE(smoking$studyn, smoking$trtn, contrast = rep(FALSE, nrow(smoking)), type = \"blshift\") #> Coerced `trt` to factor. #>  [1]  0  1  2  0  3  4  0  5  0  6  0  7  0  8  0  9  0 10  0 11  0 12  0 13  0 #> [26] 14  0 15  0 16  0 17  0 18  0 19  0 20  0 21  0 22  0 23  0 24  0 25  0 26"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. survival Surv","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Relative treatment effects — relative_effects","title":"Relative treatment effects — relative_effects","text":"Generate (population-average) relative treatment effects. ML-NMR meta-regression model fitted, specific study population.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relative treatment effects — relative_effects","text":"","code":"relative_effects(   x,   newdata = NULL,   study = NULL,   all_contrasts = FALSE,   trt_ref = NULL,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975),   predictive_distribution = FALSE,   summary = TRUE )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relative treatment effects — relative_effects","text":"x stan_nma object created nma() newdata used regression model fitted. data frame study details, one row per study, giving covariate values produce relative effects. Column names must match variables regression model. NULL, relative effects produced studies network. study Column newdata specifies study names, otherwise studies labelled row number. all_contrasts Logical, generate estimates contrasts (TRUE), just \"basic\" contrasts network reference treatment (FALSE)? Default FALSE. trt_ref Reference treatment construct relative effects , all_contrasts = FALSE. default, relative effects network reference treatment. Coerced character string. probs Numeric vector quantiles interest present computed summary, default c(0.025, 0.25, 0.5, 0.75, 0.975) predictive_distribution Logical, random effects model fitted, predictive distribution relative effects new study returned? Default FALSE. summary Logical, calculate posterior summaries? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relative treatment effects — relative_effects","text":"nma_summary object summary = TRUE, otherwise list containing 3D MCMC array samples (regression models) data frame study information.","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/relative_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Relative treatment effects — relative_effects","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Produce relative effects smk_releff_RE <- relative_effects(smk_fit_RE) smk_releff_RE #>                           mean   sd  2.5%  25%  50%  75% 97.5% Bulk_ESS #> d[Group counselling]      1.11 0.44  0.28 0.81 1.10 1.39  1.99     2276 #> d[Individual counselling] 0.85 0.24  0.38 0.69 0.84 1.00  1.34     1454 #> d[Self-help]              0.48 0.40 -0.29 0.23 0.48 0.74  1.24     2017 #>                           Tail_ESS Rhat #> d[Group counselling]          2783    1 #> d[Individual counselling]     2018    1 #> d[Self-help]                  2344    1 plot(smk_releff_RE, ref_line = 0)   # Relative effects for all pairwise comparisons relative_effects(smk_fit_RE, all_contrasts = TRUE) #>                                                  mean   sd  2.5%   25%   50% #> d[Group counselling vs. No intervention]         1.11 0.44  0.28  0.81  1.10 #> d[Individual counselling vs. No intervention]    0.85 0.24  0.38  0.69  0.84 #> d[Self-help vs. No intervention]                 0.48 0.40 -0.29  0.23  0.48 #> d[Individual counselling vs. Group counselling] -0.26 0.42 -1.09 -0.53 -0.26 #> d[Self-help vs. Group counselling]              -0.62 0.49 -1.62 -0.93 -0.62 #> d[Self-help vs. Individual counselling]         -0.37 0.41 -1.21 -0.62 -0.36 #>                                                   75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling vs. No intervention]         1.39  1.99     2276     2783 #> d[Individual counselling vs. No intervention]    1.00  1.34     1454     2018 #> d[Self-help vs. No intervention]                 0.74  1.24     2017     2344 #> d[Individual counselling vs. Group counselling]  0.02  0.54     2804     2901 #> d[Self-help vs. Group counselling]              -0.30  0.33     2901     2223 #> d[Self-help vs. Individual counselling]         -0.10  0.42     2369     2658 #>                                                 Rhat #> d[Group counselling vs. No intervention]           1 #> d[Individual counselling vs. No intervention]      1 #> d[Self-help vs. No intervention]                   1 #> d[Individual counselling vs. Group counselling]    1 #> d[Self-help vs. Group counselling]                 1 #> d[Self-help vs. Individual counselling]            1  # Relative effects against a different reference treatment relative_effects(smk_fit_RE, trt_ref = \"Self-help\") #>                            mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS #> d[No intervention]        -0.48 0.40 -1.24 -0.74 -0.48 -0.23  0.29     2017 #> d[Group counselling]       0.62 0.49 -0.33  0.30  0.62  0.93  1.62     2901 #> d[Individual counselling]  0.37 0.41 -0.42  0.10  0.36  0.62  1.21     2369 #>                           Tail_ESS Rhat #> d[No intervention]            2344    1 #> d[Group counselling]          2223    1 #> d[Individual counselling]     2658    1  # Transforming to odds ratios # We work with the array of relative effects samples LOR_array <- as.array(smk_releff_RE) OR_array <- exp(LOR_array)  # mcmc_array objects can be summarised to produce a nma_summary object smk_OR_RE <- summary(OR_array)  # This can then be printed or plotted smk_OR_RE #>                           mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[Group counselling]      3.33 1.60 1.32 2.25 3.00 4.00  7.33     2276     2783 #> d[Individual counselling] 2.40 0.60 1.46 1.99 2.33 2.73  3.80     1454     2018 #> d[Self-help]              1.75 0.73 0.75 1.25 1.61 2.10  3.46     2017     2344 #>                           Rhat #> d[Group counselling]         1 #> d[Individual counselling]    1 #> d[Self-help]                 1 plot(smk_OR_RE, ref_line = 1)  # }  ## Plaque psoriasis ML-NMR # \\donttest{ # Run plaque psoriasis ML-NMR example if not already available if (!exists(\"pso_fit\")) example(\"example_pso_mlnmr\", run.donttest = TRUE) # } # \\donttest{ # Produce population-adjusted relative effects for all study populations in # the network pso_releff <- relative_effects(pso_fit) pso_releff #> ---------------------------------------------------------------- Study: FIXTURE ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>      1.6    0.62 0.34   8.34 0.14 #>  #>                     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[FIXTURE: ETN]     1.66 0.09 1.49 1.60 1.66 1.72  1.84     4126     3465    1 #> d[FIXTURE: IXE_Q2W] 3.03 0.10 2.84 2.96 3.03 3.10  3.22     4743     3161    1 #> d[FIXTURE: IXE_Q4W] 2.62 0.09 2.44 2.55 2.62 2.68  2.81     4789     3156    1 #> d[FIXTURE: SEC_150] 2.22 0.12 1.99 2.14 2.22 2.30  2.45     4515     3651    1 #> d[FIXTURE: SEC_300] 2.52 0.12 2.29 2.44 2.52 2.61  2.76     5273     3387    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-1 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>        2    0.73 0.28   9.24 0.28 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-1: ETN]     1.51 0.09 1.34 1.45 1.51 1.56  1.68     4385     3251 #> d[UNCOVER-1: IXE_Q2W] 2.93 0.08 2.76 2.87 2.93 2.98  3.10     4976     3293 #> d[UNCOVER-1: IXE_Q4W] 2.51 0.08 2.36 2.46 2.51 2.57  2.68     4906     3423 #> d[UNCOVER-1: SEC_150] 2.11 0.12 1.89 2.03 2.11 2.20  2.35     5221     3546 #> d[UNCOVER-1: SEC_300] 2.42 0.12 2.18 2.34 2.42 2.50  2.66     6081     3687 #>                       Rhat #> d[UNCOVER-1: ETN]        1 #> d[UNCOVER-1: IXE_Q2W]    1 #> d[UNCOVER-1: IXE_Q4W]    1 #> d[UNCOVER-1: SEC_150]    1 #> d[UNCOVER-1: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-2 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight  psa #>     1.87    0.64 0.27   9.17 0.24 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-2: ETN]     1.51 0.08 1.35 1.45 1.51 1.56  1.67     4393     3154 #> d[UNCOVER-2: IXE_Q2W] 2.92 0.08 2.77 2.87 2.92 2.98  3.09     5093     3454 #> d[UNCOVER-2: IXE_Q4W] 2.51 0.08 2.36 2.46 2.51 2.56  2.67     5009     3328 #> d[UNCOVER-2: SEC_150] 2.11 0.12 1.89 2.03 2.12 2.19  2.35     5263     3449 #> d[UNCOVER-2: SEC_300] 2.42 0.12 2.18 2.34 2.42 2.50  2.65     6168     3723 #>                       Rhat #> d[UNCOVER-2: ETN]        1 #> d[UNCOVER-2: IXE_Q2W]    1 #> d[UNCOVER-2: IXE_Q4W]    1 #> d[UNCOVER-2: SEC_150]    1 #> d[UNCOVER-2: SEC_300]    1 #>  #> -------------------------------------------------------------- Study: UNCOVER-3 ----  #>  #> Covariate values: #>  durnpso prevsys  bsa weight psa #>     1.78    0.59 0.28   9.01 0.2 #>  #>                       mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS #> d[UNCOVER-3: ETN]     1.53 0.08 1.37 1.48 1.53 1.58  1.69     4312     3328 #> d[UNCOVER-3: IXE_Q2W] 2.94 0.08 2.78 2.89 2.94 3.00  3.11     5021     3515 #> d[UNCOVER-3: IXE_Q4W] 2.53 0.08 2.37 2.48 2.53 2.58  2.69     5014     3420 #> d[UNCOVER-3: SEC_150] 2.13 0.11 1.91 2.05 2.13 2.21  2.36     5137     3554 #> d[UNCOVER-3: SEC_300] 2.44 0.12 2.21 2.36 2.43 2.51  2.67     6070     3595 #>                       Rhat #> d[UNCOVER-3: ETN]        1 #> d[UNCOVER-3: IXE_Q2W]    1 #> d[UNCOVER-3: IXE_Q4W]    1 #> d[UNCOVER-3: SEC_150]    1 #> d[UNCOVER-3: SEC_300]    1 #>  plot(pso_releff, ref_line = 0)   # Produce population-adjusted relative effects for a different target # population new_agd_means <- data.frame(   bsa = 0.6,   prevsys = 0.1,   psa = 0.2,   weight = 10,   durnpso = 3)  relative_effects(pso_fit, newdata = new_agd_means) #> ------------------------------------------------------------------ Study: New 1 ----  #>  #> Covariate values: #>  durnpso prevsys bsa weight psa #>        3     0.1 0.6     10 0.2 #>  #>                   mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d[New 1: ETN]     1.25 0.22 0.81 1.10 1.25 1.40  1.71     7016     2903    1 #> d[New 1: IXE_Q2W] 2.89 0.22 2.47 2.74 2.89 3.04  3.33     7537     3302    1 #> d[New 1: IXE_Q4W] 2.48 0.22 2.05 2.33 2.47 2.62  2.90     7736     3098    1 #> d[New 1: SEC_150] 2.08 0.23 1.64 1.92 2.08 2.23  2.53     7796     2943    1 #> d[New 1: SEC_300] 2.38 0.23 1.94 2.23 2.38 2.53  2.84     7727     2935    1 #>  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up arm-based aggregate data — set_agd_arm","title":"Set up arm-based aggregate data — set_agd_arm","text":"Set network containing arm-based aggregate data (AgD), event counts mean outcomes arm. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up arm-based aggregate data — set_agd_arm","text":"","code":"set_agd_arm(   data,   study,   trt,   y = NULL,   se = NULL,   r = NULL,   n = NULL,   E = NULL,   sample_size = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up arm-based aggregate data — set_agd_arm","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome se column data specifying standard error continuous outcome r column data specifying binary Binomial outcome count n column data specifying Binomial outcome numerator E column data specifying total time risk Poisson outcomes sample_size column data giving sample size arm. Optional, see details. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up arm-based aggregate data — set_agd_arm","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up arm-based aggregate data — set_agd_arm","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). sample_size argument optional, specified: Enables automatic centering predictors (center = TRUE) nma() regression model given network combining IPD AgD Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Nodes plot.nma_data() may weighted sample size Binomial outcome specified sample_size omitted, n used sample size default. Multinomial outcome specified sample_size omitted, sample size determined automatically supplied counts default. arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_arm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up arm-based aggregate data — set_agd_arm","text":"","code":"# Set up network of smoking cessation data head(smoking) #>   studyn trtn                   trtc  r   n #> 1      1    1        No intervention  9 140 #> 2      1    3 Individual counselling 23 140 #> 3      1    4      Group counselling 10 138 #> 4      2    2              Self-help 11  78 #> 5      2    3 Individual counselling 12  85 #> 6      2    4      Group counselling 29 170  smk_net <- set_agd_arm(smoking,                        study = studyn,                        trt = trtc,                        r = r,                        n = n,                        trt_ref = \"No intervention\")  # Print details smk_net #> A network with 24 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study Treatment arms                                                  #>  1     3: No intervention | Group counselling | Individual counselling #>  2     3: Group counselling | Individual counselling | Self-help       #>  3     2: No intervention | Individual counselling                     #>  4     2: No intervention | Individual counselling                     #>  5     2: No intervention | Individual counselling                     #>  6     2: No intervention | Individual counselling                     #>  7     2: No intervention | Individual counselling                     #>  8     2: No intervention | Individual counselling                     #>  9     2: No intervention | Individual counselling                     #>  10    2: No intervention | Self-help                                  #>  ... plus 14 more studies #>  #>  Outcome type: count #> ------------------------------------------------------------------------------------ #> Total number of treatments: 4 #> Total number of studies: 24 #> Reference treatment is: No intervention #> Network is connected   # Plot network plot(smk_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up contrast-based aggregate data — set_agd_contrast","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"Set network containing contrast-based aggregate data (AgD), .e. summaries relative effects treatments log Odds Ratios. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"","code":"set_agd_contrast(   data,   study,   trt,   y = NULL,   se = NULL,   sample_size = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome se column data specifying standard error continuous outcome sample_size column data giving sample size arm. Optional, see details. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"study single reference/baseline treatment, relative effects arm(s) given. reference arm, include data row continuous outcome y equal NA. study three arms (two relative effects), set standard error se reference arm data row equal standard error mean outcome reference arm (determines covariance relative effects, expressed differences mean outcomes arms). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year) default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). sample_size argument optional, specified: Enables automatic centering predictors (center = TRUE) nma() regression model given network combining IPD AgD Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Nodes plot.nma_data() may weighted sample size","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_contrast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up contrast-based aggregate data — set_agd_contrast","text":"","code":"# Set up network of Parkinson's contrast data head(parkinsons) #>   studyn trtn     y    se   n  diff se_diff #> 1      1    1 -1.22 0.504  54    NA   0.504 #> 2      1    3 -1.53 0.439  95 -0.31   0.668 #> 3      2    1 -0.70 0.282 172    NA   0.282 #> 4      2    2 -2.40 0.258 173 -1.70   0.382 #> 5      3    1 -0.30 0.505  76    NA   0.505 #> 6      3    2 -2.60 0.510  71 -2.30   0.718  park_net <- set_agd_contrast(parkinsons,                              study = studyn,                              trt = trtn,                              y = diff,                              se = se_diff,                              sample_size = n)  # Print details park_net #> A network with 7 AgD studies (contrast-based). #>  #> -------------------------------------------------- AgD studies (contrast-based) ----  #>  Study Treatment arms #>  1     2: 1 | 3       #>  2     2: 1 | 2       #>  3     3: 4 | 1 | 2   #>  4     2: 4 | 3       #>  5     2: 4 | 3       #>  6     2: 4 | 5       #>  7     2: 4 | 5       #>  #>  Outcome type: continuous #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 7 #> Reference treatment is: 4 #> Network is connected  # Plot network plot(park_net)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up aggregate survival data — set_agd_surv","title":"Set up aggregate survival data — set_agd_surv","text":"Set network containing aggregate survival data (AgD) form event/censoring times (e.g. reconstructed digitized Kaplan-Meier curves) covariate summary statistics study. Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up aggregate survival data — set_agd_surv","text":"","code":"set_agd_surv(   data,   study,   trt,   Surv,   covariates = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up aggregate survival data — set_agd_surv","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors Surv column data specifying survival time--event outcome, using Surv() function. Right/left/interval censoring left truncation (delayed entry) supported. covariates data frame covariate summary statistics study study arm, corresponding study trt columns match data trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up aggregate survival data — set_agd_surv","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up aggregate survival data — set_agd_surv","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_agd_surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up aggregate survival data — set_agd_surv","text":"","code":"## Newly diagnosed multiple myeloma  head(ndmm_agd)  # Reconstructed Kaplan-Meier data #>        study     studyf trt trtf eventtime status #> 1 Morgan2012 Morgan2012 Pbo  Pbo  18.72575      1 #> 2 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 3 Morgan2012 Morgan2012 Pbo  Pbo  34.35726      1 #> 4 Morgan2012 Morgan2012 Pbo  Pbo  10.77826      1 #> 5 Morgan2012 Morgan2012 Pbo  Pbo  63.36000      0 #> 6 Morgan2012 Morgan2012 Pbo  Pbo  14.52966      1 ndmm_agd_covs   # Summary covariate information on each arm #>         study      studyf  trt trtf sample_size  age_min age_iqr_l age_median #> 1 Jackson2019 Jackson2019  Len  Len        1137 17.28246  59.13164   65.76766 #> 2 Jackson2019 Jackson2019  Pbo  Pbo         864 21.18572  58.30991   65.47402 #> 3  Morgan2012  Morgan2012  Pbo  Pbo         410 33.88979  58.05696   64.15999 #> 4  Morgan2012  Morgan2012 Thal Thal         408 38.45127  59.30022   65.48736 #>   age_iqr_h  age_max age_mean   age_sd iss_stage3 response_cr_vgpr      male #> 1  72.00756 85.76095 65.16867 8.936962  0.2480211        0.8258575 0.6165347 #> 2  71.80261 86.23080 64.62894 9.399272  0.1921296        0.8310185 0.6215278 #> 3  70.44791 84.79372 63.92360 9.006311  0.3634146        0.7170732 0.6195122 #> 4  71.73597 84.69365 65.59387 8.384686  0.3186275        0.7450980 0.6151961  set_agd_surv(ndmm_agd,              study = studyf,              trt = trtf,              Surv = Surv(eventtime, status),              covariates = ndmm_agd_covs) #> A network with 2 AgD studies (arm-based). #>  #> ------------------------------------------------------- AgD studies (arm-based) ----  #>  Study       Treatment arms #>  Jackson2019 2: Pbo | Len   #>  Morgan2012  2: Pbo | Thal  #>  #>  Outcome type: survival #> ------------------------------------------------------------------------------------ #> Total number of treatments: 3 #> Total number of studies: 2 #> Reference treatment is: Pbo #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up individual patient data — set_ipd","title":"Set up individual patient data — set_ipd","text":"Set network containing individual patient data (IPD). Multiple data sources may combined created using combine_network().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up individual patient data — set_ipd","text":"","code":"set_ipd(   data,   study,   trt,   y = NULL,   r = NULL,   E = NULL,   Surv = NULL,   trt_ref = NULL,   trt_class = NULL )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up individual patient data — set_ipd","text":"data data frame study column data specifying studies, coded using integers, strings, factors trt column data specifying treatments, coded using integers, strings, factors y column data specifying continuous outcome r column data specifying binary outcome Poisson outcome count E column data specifying total time risk Poisson outcomes Surv column data specifying survival time--event outcome, using Surv() function. Right/left/interval censoring left truncation (delayed entry) supported. trt_ref reference treatment network, single integer, string, factor. specified, reasonable well-connected default chosen (see details). trt_class column data specifying treatment classes, coded using integers, strings, factors. default, classes specified.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up individual patient data — set_ipd","text":"object class nma_data","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set up individual patient data — set_ipd","text":"default, trt_ref = NULL network reference treatment chosen attempts maximise computational efficiency stability. alternative reference treatment chosen model runs slowly low effective sample size (ESS) may cause - try letting default reference treatment used instead. Regardless treatment used network reference model fitting stage, results can transformed afterwards: see trt_ref argument relative_effects() predict.stan_nma(). arguments specifying columns data accept following: column name character string, e.g. study = \"studyc\" bare column name, e.g. study = studyc dplyr::mutate() style semantics inline variable transformations, e.g. study = paste(author, year)","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/set_ipd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up individual patient data — set_ipd","text":"","code":"# Set up network of plaque psoriasis IPD head(plaque_psoriasis_ipd) #>    studyc      trtc_long    trtc trtn pasi75 pasi90 pasi100 age  bmi pasi_w0 #> 1 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  62 38.6    15.8 #> 2 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  38 23.2    28.2 #> 3 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  54 27.5    13.2 #> 4 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  44 24.6    41.0 #> 5 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       0  44 28.3    15.2 #> 6 IXORA-S Ixekizumab Q2W IXE_Q2W    2      1      1       1  57 23.6    30.4 #>    male bsa weight durnpso prevsys   psa #> 1 FALSE  13  111.2       8    TRUE  TRUE #> 2 FALSE  37   62.0       1    TRUE FALSE #> 3  TRUE  13   83.5      38    TRUE FALSE #> 4 FALSE  67   66.0       1    TRUE FALSE #> 5 FALSE  10   92.7      23    TRUE FALSE #> 6 FALSE  75   73.5      21    TRUE FALSE  pso_net <- set_ipd(plaque_psoriasis_ipd,                    study = studyc,                    trt = trtc,                    r = pasi75)  # Print network details pso_net #> A network with 4 IPD studies. #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 4 #> Reference treatment is: IXE_Q2W #> Network is connected  # Plot network plot(pso_net)   # Setting a different reference treatment set_ipd(plaque_psoriasis_ipd,         study = studyc,         trt = trtc,         r = pasi75,         trt_ref = \"PBO\") #> A network with 4 IPD studies. #>  #> ------------------------------------------------------------------- IPD studies ----  #>  Study     Treatment arms                   #>  IXORA-S   2: IXE_Q2W | UST                 #>  UNCOVER-1 3: IXE_Q2W | IXE_Q4W | PBO       #>  UNCOVER-2 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  UNCOVER-3 4: ETN | IXE_Q2W | IXE_Q4W | PBO #>  #>  Outcome type: binary #> ------------------------------------------------------------------------------------ #> Total number of treatments: 5 #> Total number of studies: 4 #> Reference treatment is: PBO #> Network is connected"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":null,"dir":"Reference","previous_headings":"","what":"Smoking cessation data — smoking","title":"Smoking cessation data — smoking","text":"Data frame containing results 24 trials 4 smoking cessation treatments Hasselblad1998,TSD4multinma.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smoking cessation data — smoking","text":"","code":"smoking"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/smoking.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Smoking cessation data — smoking","text":"data frame 50 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/stan_nma-class.html","id":null,"dir":"Reference","previous_headings":"","what":"The stan_nma class — stan_nma-class","title":"The stan_nma class — stan_nma-class","text":"stan_nma stan_mlnmr classes contains results running model function nma().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/stan_nma-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The stan_nma class — stan_nma-class","text":"Objects class stan_nma stan_mlnmr following components: network network data model run (class nma_data stan_nma, class mlnmr_data stan_mlnmr) stanfit stanfit object returned calling sampling() model trt_effects Whether fixed random effects used (character string) consistency consistency/inconsistency model used (character string) regression regression model used (formula) class_interactions treatment classes regression model specified, model used interactions within class (common, exchangeable, independent) xbar named vector values used centering likelihood likelihood used (character string) link link function used (character string) priors list containing priors used (nma_prior objects) basis mspline pexp models, named list spline bases study stan_mlnmr sub-class inherits stan_nma, differs class network object.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":null,"dir":"Reference","previous_headings":"","what":"Statins for cholesterol lowering — statins","title":"Statins for cholesterol lowering — statins","text":"Data frame containing results 19 trials comparing statins placebo usual care TSD3multinma. number deaths (-cause mortality) recorded. studies aim primary prevention (patients previous heart disease), others aim secondary prevention (patients previous heart disease).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statins for cholesterol lowering — statins","text":"","code":"statins"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/statins.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Statins for cholesterol lowering — statins","text":"data frame 38 rows 7 variables: studyn numeric study ID studyc study name trtn numeric treatment code trtc treatment name prevention primary secondary prevention study r number deaths n sample size","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"Posterior summaries node-splitting models (nma_nodesplit nma_nodesplit_df objects) can produced using summary() method, plotted using plot() method.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"","code":"# S3 method for class 'nma_nodesplit_df' summary(   object,   consistency = NULL,   ...,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975) )  # S3 method for class 'nma_nodesplit' summary(   object,   consistency = NULL,   ...,   probs = c(0.025, 0.25, 0.5, 0.75, 0.975) )  # S3 method for class 'nma_nodesplit' plot(x, consistency = NULL, ...)  # S3 method for class 'nma_nodesplit_df' plot(x, consistency = NULL, ...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"consistency Optional, stan_nma object corresponding fitted consistency model, display network estimates alongside direct indirect estimates. fitted consistency model present nma_nodesplit_df object used present (see get_nodesplits()). ... Additional arguments passed methods probs Numeric vector specifying quantiles interest, default c(0.025, 0.25, 0.5, 0.75, 0.975) x, object nma_nodesplit nma_nodesplit_df object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"nodesplit_summary object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"plot() method shortcut plot(summary(nma_nodesplit)). details plotting options, see plot.nodesplit_summary().","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_nodesplit_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise the results of node-splitting models — summary.nma_nodesplit_df","text":"","code":"# \\donttest{ # Run smoking node-splitting example if not already available if (!exists(\"smk_fit_RE_nodesplit\")) example(\"example_smk_nodesplit\", run.donttest = TRUE) # } # \\donttest{ # Summarise the node-splitting results summary(smk_fit_RE_nodesplit) #> Node-splitting models fitted for 6 comparisons. #>  #> ------------------------------ Node-split Group counselling vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            1.11 0.44  0.30  0.82  1.10 1.38  2.00     2000     2306    1 #> d_dir            1.08 0.74 -0.31  0.58  1.05 1.55  2.58     3392     2712    1 #> d_ind            1.12 0.55  0.07  0.77  1.12 1.48  2.17     1637     2163    1 #> omega           -0.05 0.90 -1.79 -0.65 -0.07 0.53  1.83     2205     2310    1 #> tau              0.87 0.20  0.55  0.73  0.85 0.99  1.34     1171     1658    1 #> tau_consistency  0.84 0.19  0.55  0.71  0.82 0.95  1.29     1314     1713    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 43.8 #>               DIC: 97.4 #>  #> Bayesian p-value: 0.94 #>  #> ------------------------- Node-split Individual counselling vs. No intervention ----  #>  #>                 mean   sd  2.5%   25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           0.84 0.24  0.38  0.69 0.84 1.00  1.32     1237     1718    1 #> d_dir           0.88 0.26  0.39  0.70 0.87 1.04  1.40     1371     1797    1 #> d_ind           0.56 0.69 -0.78  0.09 0.55 0.99  1.95     1345     1649    1 #> omega           0.31 0.71 -1.09 -0.14 0.33 0.78  1.74     1411     1773    1 #> tau             0.87 0.20  0.55  0.72 0.84 0.98  1.33     1143     2092    1 #> tau_consistency 0.84 0.19  0.55  0.71 0.82 0.95  1.29     1314     1713    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.4 #>  #> Bayesian p-value: 0.64 #>  #> -------------------------------------- Node-split Self-help vs. No intervention ----  #>  #>                  mean   sd  2.5%   25%   50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net            0.51 0.40 -0.26  0.25  0.50 0.75  1.30     2087     2276 1.00 #> d_dir            0.33 0.54 -0.76 -0.01  0.32 0.66  1.43     3295     2569 1.00 #> d_ind            0.71 0.62 -0.52  0.30  0.72 1.12  1.94     2329     2835 1.00 #> omega           -0.38 0.82 -1.94 -0.92 -0.39 0.15  1.27     2479     2626 1.00 #> tau              0.88 0.20  0.57  0.74  0.85 0.99  1.33     1114     1538 1.01 #> tau_consistency  0.84 0.19  0.55  0.71  0.82 0.95  1.29     1314     1713 1.00 #>  #> Residual deviance: 53.7 (on 50 data points) #>                pD: 44.2 #>               DIC: 98 #>  #> Bayesian p-value: 0.62 #>  #> ----------------------- Node-split Individual counselling vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.26 0.41 -1.09 -0.53 -0.26  0.01  0.54     2760     2738    1 #> d_dir           -0.10 0.50 -1.09 -0.44 -0.10  0.23  0.87     3180     3177    1 #> d_ind           -0.55 0.61 -1.78 -0.95 -0.55 -0.15  0.64     1707     2182    1 #> omega            0.45 0.68 -0.89  0.00  0.45  0.89  1.80     1631     1984    1 #> tau              0.87 0.20  0.57  0.73  0.84  0.98  1.33     1275     1693    1 #> tau_consistency  0.84 0.19  0.55  0.71  0.82  0.95  1.29     1314     1713    1 #>  #> Residual deviance: 53.4 (on 50 data points) #>                pD: 43.9 #>               DIC: 97.3 #>  #> Bayesian p-value: 0.5 #>  #> ------------------------------------ Node-split Self-help vs. Group counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.60 0.48 -1.57 -0.90 -0.60 -0.28  0.30     2989     2245    1 #> d_dir           -0.60 0.65 -1.90 -1.02 -0.60 -0.18  0.72     3690     3112    1 #> d_ind           -0.63 0.66 -1.92 -1.07 -0.64 -0.20  0.67     1966     2537    1 #> omega            0.02 0.87 -1.66 -0.54  0.02  0.58  1.72     1983     1936    1 #> tau              0.87 0.20  0.56  0.73  0.84  0.98  1.32     1077     1882    1 #> tau_consistency  0.84 0.19  0.55  0.71  0.82  0.95  1.29     1314     1713    1 #>  #> Residual deviance: 54.1 (on 50 data points) #>                pD: 44.3 #>               DIC: 98.5 #>  #> Bayesian p-value: 0.97 #>  #> ------------------------------- Node-split Self-help vs. Individual counselling ----  #>  #>                  mean   sd  2.5%   25%   50%   75% 97.5% Bulk_ESS Tail_ESS Rhat #> d_net           -0.34 0.40 -1.11 -0.60 -0.33 -0.08  0.48     2355     2418    1 #> d_dir            0.05 0.64 -1.24 -0.37  0.05  0.46  1.33     3370     2887    1 #> d_ind           -0.64 0.53 -1.70 -0.98 -0.63 -0.29  0.37     1939     2329    1 #> omega            0.70 0.81 -0.83  0.15  0.68  1.21  2.33     2371     2334    1 #> tau              0.86 0.20  0.56  0.72  0.83  0.96  1.33     1182     1691    1 #> tau_consistency  0.84 0.19  0.55  0.71  0.82  0.95  1.29     1314     1713    1 #>  #> Residual deviance: 53.6 (on 50 data points) #>                pD: 44 #>               DIC: 97.6 #>  #> Bayesian p-value: 0.38  # Plot the node-splitting results plot(smk_fit_RE_nodesplit)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of prior distributions — summary.nma_prior","title":"Summary of prior distributions — summary.nma_prior","text":"Print summary prior distribution details.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of prior distributions — summary.nma_prior","text":"","code":"# S3 method for class 'nma_prior' summary(object, ..., probs = c(0.5, 0.95), digits = 2, trunc = NULL)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of prior distributions — summary.nma_prior","text":"object Prior distribution nma_prior object ... Additional arguments, used probs Numeric vector probabilities calculate prior intervals digits Number digits display trunc Optional numeric vector length 2, giving truncation limits prior distribution. Useful real-valued prior assigned positive-valued parameter, trunc = c(0, Inf) give correct prior intervals. default, truncation used.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of prior distributions — summary.nma_prior","text":"data frame returned invisibly, giving prior intervals","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.nma_prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of prior distributions — summary.nma_prior","text":"","code":"summary(normal(location = 0, scale = 1)) #> A Normal prior distribution: location = 0, scale = 1. #> 50% of the prior density lies between -0.67 and 0.67. #> 95% of the prior density lies between -1.96 and 1.96. summary(half_normal(scale = 1)) #> A half-Normal prior distribution: location = 0, scale = 1. #> 50% of the prior density lies between 0 and 0.67. #> 95% of the prior density lies between 0 and 1.96. summary(log_normal(location = -3.93, scale = 1.51)) #> A log-Normal prior distribution: location = -3.93, scale = 1.51. #> 50% of the prior density lies between 0.01 and 0.05. #> 95% of the prior density lies between 0 and 0.38.  # Truncation limits may be set, for example to restrict a prior to positive values summary(normal(location = 0.5, scale = 1), trunc = c(0, Inf)) #> A Normal prior distribution: location = 0.5, scale = 1. #> 50% of the prior density lies between 0.45 and 1.44. #> 95% of the prior density lies between 0.05 and 2.61."},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior summaries from stan_nma objects — summary.stan_nma","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"Posterior summaries model parameters stan_nma objects may produced using summary() method plotted plot() method. NOTE: produce relative effects, absolute predictions, posterior ranks, see relative_effects(), predict.stan_nma(), posterior_ranks(), posterior_rank_probs().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"","code":"# S3 method for class 'stan_nma' summary(object, ..., pars, include, probs = c(0.025, 0.25, 0.5, 0.75, 0.975))  # S3 method for class 'stan_nma' plot(   x,   ...,   pars,   include,   stat = \"pointinterval\",   orientation = c(\"horizontal\", \"vertical\", \"y\", \"x\"),   ref_line = NA_real_ )"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"... Additional arguments passed methods pars, include See rstan::extract() probs Numeric vector specifying quantiles interest, default c(0.025, 0.25, 0.5, 0.75, 0.975) x, object stan_nma object stat Character string specifying ggdist plot stat use, default \"pointinterval\" orientation Whether ggdist geom drawn horizontally (\"horizontal\") vertically (\"vertical\"), default \"horizontal\" ref_line Numeric vector positions reference lines, default reference lines drawn summary Logical, calculate posterior summaries? Default TRUE.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"nma_summary object","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"plot() method shortcut plot(summary(stan_nma)). details plotting options, see plot.nma_summary().","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/summary.stan_nma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posterior summaries from stan_nma objects — summary.stan_nma","text":"","code":"## Smoking cessation # \\donttest{ # Run smoking RE NMA example if not already available if (!exists(\"smk_fit_RE\")) example(\"example_smk_re\", run.donttest = TRUE) # } # \\donttest{ # Summary and plot of all model parameters summary(smk_fit_RE) #>                                    mean   sd  2.5%   25%   50%   75% 97.5% #> mu[1]                             -2.79 0.33 -3.50 -3.00 -2.78 -2.56 -2.19 #> mu[2]                             -2.57 0.76 -4.14 -3.06 -2.57 -2.08 -1.05 #> mu[3]                             -2.14 0.12 -2.39 -2.22 -2.14 -2.06 -1.91 #> mu[4]                             -4.05 0.57 -5.26 -4.41 -4.01 -3.66 -3.04 #> mu[5]                             -2.16 0.14 -2.44 -2.25 -2.15 -2.06 -1.89 #> mu[6]                             -3.44 0.74 -5.03 -3.89 -3.39 -2.93 -2.15 #> mu[7]                             -3.03 0.45 -4.00 -3.31 -2.99 -2.71 -2.25 #> mu[8]                             -2.71 0.60 -4.00 -3.07 -2.68 -2.28 -1.69 #> mu[9]                             -1.84 0.41 -2.67 -2.11 -1.82 -1.56 -1.10 #> mu[10]                            -2.08 0.12 -2.32 -2.16 -2.08 -2.00 -1.86 #> mu[11]                            -3.62 0.23 -4.10 -3.77 -3.62 -3.46 -3.18 #> mu[12]                            -2.22 0.13 -2.49 -2.31 -2.22 -2.13 -1.97 #> mu[13]                            -2.67 0.44 -3.59 -2.96 -2.65 -2.37 -1.88 #> mu[14]                            -2.41 0.23 -2.89 -2.56 -2.41 -2.25 -1.98 #> mu[15]                            -2.70 0.76 -4.41 -3.16 -2.64 -2.18 -1.41 #> mu[16]                            -2.61 0.34 -3.35 -2.83 -2.60 -2.38 -1.99 #> mu[17]                            -2.38 0.11 -2.59 -2.45 -2.38 -2.30 -2.18 #> mu[18]                            -2.57 0.27 -3.14 -2.74 -2.56 -2.38 -2.05 #> mu[19]                            -1.90 0.12 -2.15 -1.97 -1.89 -1.82 -1.67 #> mu[20]                            -2.80 0.12 -3.04 -2.88 -2.80 -2.72 -2.57 #> mu[21]                            -1.13 0.81 -2.77 -1.64 -1.12 -0.60  0.41 #> mu[22]                            -2.40 0.86 -4.13 -2.94 -2.37 -1.84 -0.73 #> mu[23]                            -2.31 0.83 -3.99 -2.84 -2.31 -1.76 -0.69 #> mu[24]                            -2.79 0.86 -4.45 -3.36 -2.79 -2.21 -1.14 #> d[Group counselling]               1.11 0.44  0.28  0.81  1.10  1.39  1.99 #> d[Individual counselling]          0.85 0.24  0.38  0.69  0.84  1.00  1.34 #> d[Self-help]                       0.48 0.40 -0.29  0.23  0.48  0.74  1.24 #> tau                                0.84 0.18  0.55  0.71  0.82  0.94  1.26 #> delta[1: Individual counselling]   1.08 0.39  0.33  0.82  1.07  1.33  1.88 #> delta[1: Group counselling]        0.38 0.42 -0.45  0.10  0.37  0.67  1.21 #> delta[2: Self-help]                0.67 0.79 -0.86  0.16  0.65  1.18  2.26 #> delta[2: Individual counselling]   0.76 0.77 -0.77  0.28  0.76  1.24  2.34 #> delta[2: Group counselling]        0.99 0.77 -0.56  0.50  1.00  1.47  2.56 #> delta[3: Individual counselling]   2.17 0.14  1.90  2.07  2.17  2.26  2.45 #> delta[4: Individual counselling]   0.91 0.59 -0.18  0.52  0.89  1.29  2.14 #> delta[5: Individual counselling]   0.44 0.16  0.13  0.33  0.43  0.54  0.75 #> delta[6: Individual counselling]   1.75 0.73  0.47  1.24  1.70  2.21  3.30 #> delta[7: Individual counselling]   2.15 0.49  1.29  1.81  2.12  2.45  3.18 #> delta[8: Individual counselling]   1.66 0.62  0.60  1.22  1.61  2.03  2.99 #> delta[9: Individual counselling]   0.59 0.45 -0.27  0.29  0.59  0.90  1.49 #> delta[10: Self-help]               0.00 0.16 -0.31 -0.11  0.00  0.11  0.33 #> delta[11: Self-help]               0.41 0.31 -0.21  0.19  0.41  0.62  1.01 #> delta[12: Individual counselling]  0.41 0.16  0.09  0.30  0.41  0.52  0.74 #> delta[13: Individual counselling]  0.38 0.49 -0.57  0.05  0.38  0.71  1.36 #> delta[14: Individual counselling]  0.63 0.29  0.07  0.44  0.62  0.82  1.22 #> delta[15: Group counselling]       2.15 0.79  0.75  1.60  2.11  2.63  3.90 #> delta[16: Self-help]               0.66 0.40 -0.10  0.39  0.65  0.92  1.48 #> delta[17: Individual counselling]  0.55 0.14  0.28  0.46  0.55  0.65  0.81 #> delta[18: Individual counselling]  0.03 0.31 -0.57 -0.19  0.02  0.23  0.64 #> delta[19: Individual counselling] -0.19 0.17 -0.51 -0.30 -0.19 -0.08  0.14 #> delta[20: Individual counselling]  0.08 0.18 -0.27 -0.05  0.08  0.20  0.42 #> delta[21: Self-help]               0.70 0.81 -0.83  0.16  0.68  1.22  2.36 #> delta[21: Individual counselling]  0.66 0.80 -0.94  0.14  0.65  1.17  2.25 #> delta[22: Self-help]               0.31 0.85 -1.38 -0.23  0.29  0.86  2.03 #> delta[22: Group counselling]       1.28 0.86 -0.37  0.72  1.25  1.81  3.02 #> delta[23: Individual counselling]  0.66 0.81 -0.91  0.14  0.64  1.18  2.27 #> delta[23: Group counselling]       1.27 0.83 -0.37  0.73  1.26  1.78  2.95 #> delta[24: Individual counselling]  1.03 0.82 -0.55  0.48  1.01  1.56  2.68 #> delta[24: Group counselling]       0.88 0.85 -0.75  0.32  0.87  1.43  2.58 #>                                   Bulk_ESS Tail_ESS Rhat #> mu[1]                                 5003     3082    1 #> mu[2]                                 2781     2596    1 #> mu[3]                                 7734     2393    1 #> mu[4]                                 3832     2586    1 #> mu[5]                                 8858     2612    1 #> mu[6]                                 3675     2769    1 #> mu[7]                                 4033     2673    1 #> mu[8]                                 3644     2633    1 #> mu[9]                                 4487     2960    1 #> mu[10]                                9817     3071    1 #> mu[11]                                6578     2799    1 #> mu[12]                                7819     2793    1 #> mu[13]                                4921     3014    1 #> mu[14]                                6608     3029    1 #> mu[15]                                3740     2685    1 #> mu[16]                                6219     3013    1 #> mu[17]                                8002     3309    1 #> mu[18]                                4727     2897    1 #> mu[19]                                7251     2631    1 #> mu[20]                                7276     3281    1 #> mu[21]                                3122     2788    1 #> mu[22]                                2629     2496    1 #> mu[23]                                3212     2805    1 #> mu[24]                                3263     2717    1 #> d[Group counselling]                  2276     2783    1 #> d[Individual counselling]             1454     2018    1 #> d[Self-help]                          2017     2344    1 #> tau                                   1368     2250    1 #> delta[1: Individual counselling]      5147     3349    1 #> delta[1: Group counselling]           5223     3597    1 #> delta[2: Self-help]                   2877     2653    1 #> delta[2: Individual counselling]      2856     2880    1 #> delta[2: Group counselling]           2863     2623    1 #> delta[3: Individual counselling]      5690     2911    1 #> delta[4: Individual counselling]      3701     2854    1 #> delta[5: Individual counselling]      7221     2955    1 #> delta[6: Individual counselling]      3276     2707    1 #> delta[7: Individual counselling]      3762     2562    1 #> delta[8: Individual counselling]      3365     2603    1 #> delta[9: Individual counselling]      3952     3131    1 #> delta[10: Self-help]                  6163     3761    1 #> delta[11: Self-help]                  5875     3273    1 #> delta[12: Individual counselling]     6289     3407    1 #> delta[13: Individual counselling]     4465     2947    1 #> delta[14: Individual counselling]     5646     2992    1 #> delta[15: Group counselling]          3316     2742    1 #> delta[16: Self-help]                  5617     3071    1 #> delta[17: Individual counselling]     6375     3777    1 #> delta[18: Individual counselling]     4935     3131    1 #> delta[19: Individual counselling]     5607     3637    1 #> delta[20: Individual counselling]     5427     3634    1 #> delta[21: Self-help]                  3074     2859    1 #> delta[21: Individual counselling]     3220     2811    1 #> delta[22: Self-help]                  2727     2774    1 #> delta[22: Group counselling]          2542     2456    1 #> delta[23: Individual counselling]     3338     3084    1 #> delta[23: Group counselling]          3141     2894    1 #> delta[24: Individual counselling]     3530     3386    1 #> delta[24: Group counselling]          3316     2881    1 plot(smk_fit_RE)   # Summary and plot of heterogeneity tau only summary(smk_fit_RE, pars = \"tau\") #>     mean   sd 2.5%  25%  50%  75% 97.5% Bulk_ESS Tail_ESS Rhat #> tau 0.84 0.18 0.55 0.71 0.82 0.94  1.26     1368     2250    1 plot(smk_fit_RE, pars = \"tau\")   # Customising plot output plot(smk_fit_RE,      pars = c(\"d\", \"tau\"),      stat = \"halfeye\",      ref_line = 0)  # }"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot theme for multinma plots — theme_multinma","title":"Plot theme for multinma plots — theme_multinma","text":"simple ggplot2 theme plots multinma package.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot theme for multinma plots — theme_multinma","text":"","code":"theme_multinma(...)"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot theme for multinma plots — theme_multinma","text":"... Arguments passed ggplot2::theme_light()","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot theme for multinma plots — theme_multinma","text":"ggplot2 theme","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/theme_multinma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot theme for multinma plots — theme_multinma","text":"","code":"library(ggplot2) theme_set(theme_multinma())"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":null,"dir":"Reference","previous_headings":"","what":"Thrombolytic treatments data — thrombolytics","title":"Thrombolytic treatments data — thrombolytics","text":"Data frame containing results 50 trials 8 thrombolytic drugs (streptokinase, SK; alteplase, t-PA; accelerated alteplase, Acc t-PA; streptokinase plus alteplase, SK+tPA; reteplase, r-PA; tenocteplase, TNK; urokinase, UK; anistreptilase, ASPAC) plus per-cutaneous transluminal coronary angioplasty (PTCA) Boland2003,Lu2006,TSD4multinma. number deaths 30 35 days following acute myocardial infarction recorded.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Thrombolytic treatments data — thrombolytics","text":"","code":"thrombolytics"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/thrombolytics.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Thrombolytic treatments data — thrombolytics","text":"data frame 102 rows 5 variables: studyn numeric study ID trtn numeric treatment code trtc treatment name r total number events n total number individuals","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":null,"dir":"Reference","previous_headings":"","what":"Granulocyte transfusion in patients with neutropenia or neutrophil dysfunction — transfusion","title":"Granulocyte transfusion in patients with neutropenia or neutrophil dysfunction — transfusion","text":"Data frame containing number deaths 6 trials comparing transfusion granulocytes (white blood cells) control Stanworth2005multinma. Previously used demonstrate informative prior distributions heterogeneity variance Turner2012;textualmultinma.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Granulocyte transfusion in patients with neutropenia or neutrophil dysfunction — transfusion","text":"","code":"transfusion"},{"path":"https://dmphillippo.github.io/multinma/dev/reference/transfusion.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Granulocyte transfusion in patients with neutropenia or neutrophil dysfunction — transfusion","text":"data frame 12 rows 4 variables: studyc study name trtc treatment name r total number deaths n total number individuals","code":""},{"path":[]},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-0729000","dir":"Changelog","previous_headings":"","what":"multinma 0.7.2.9000","title":"multinma 0.7.2.9000","text":"Feature: Leverage plots can now produced plot.nma_dic(), option type = \"leverage\". Feature: Networks integration points can now combined combine_network(), previously discarded. One potential use case specify different types marginal distributions correlation structures different AgD studies network, setting separately add_integration() combining combine_network(). Fix: Resolved bug trying fit meta-regression models discrete covariates sometimes result misspecified inestimable model, due inclusion additional columns design matrix reference level covariates. Fix: IPD Poisson models broken due incorrect offset log time risk (thanks @n8thangreen spotting ). Fix: Binomial model, studies everyone experienced outcome (r = n arms) longer give NaN residual deviance.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-072","dir":"Changelog","previous_headings":"","what":"multinma 0.7.2","title":"multinma 0.7.2","text":"CRAN release: 2024-09-16 Fix: Predictions non-proportional hazards IPD NMA ML-NMR survival models using aux_regression = ~.trt incorrectly omitting treatment effects auxiliary parameter(s) cases (#43). Fix: Calling marginal_effects() survival outcomes single target population previously gave error. Fix: Predictions exponential models aux_regression specified giving error (#44). aux_regression aux_by effect exponential models since auxiliary (shape) parameters ignored, now warning. Fix: Avoid error trying fit M-spline models combining IPD AgD R versions prior 4.1.0, due integer coercion factors c().","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-071","dir":"Changelog","previous_headings":"","what":"multinma 0.7.1","title":"multinma 0.7.1","text":"CRAN release: 2024-06-11 Fix: Producing survival/hazard/cumulative hazard predictions survival models predict() outside plot() call longer gives error (#40). Fix: Increased StanHeaders version requirement version 2.32.9 later, avoid CRAN sanitizer warnings (caused stan-dev/rstan#1111).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-070","dir":"Changelog","previous_headings":"","what":"multinma 0.7.0","title":"multinma 0.7.0","text":"CRAN release: 2024-05-07 Feature: new marginal_effects() function produces marginal treatment effects, wrapper around absolute predictions predict(). example, analysis binary outcome marginal odds ratios, risk ratios, risk differences may produced. survival outcomes, marginal effects may based full range predictions produced predict(), marginal differences restricted mean survival times, time-varying marginal hazard ratios. Feature: Progress bars now displayed running interactively calculations predict() marginal_effects() ML-NMR models may take longer run. can controlled new progress argument. Deprecation: trt_ref argument predict() renamed baseline_ref; using trt_ref now soft-deprecated. Renaming argument baseline_ref follows naming convention arguments (baseline_type, baseline_level) specify details provided baseline distribution. also makes way new marginal_effects() functionality. Fix: Fallback formatting used print methods crayon package installed now works properly, rather giving errors. Fix: Small bug caused predict() AgD meta-regression models new data baseline_type = \"response\" fail error. Fix: number studies contrast network plot plot.nma_data() weight_edges = TRUE incorrect study multiple arms treatment. now correctly counts number studies making comparison, rather number arms.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-061","dir":"Changelog","previous_headings":"","what":"multinma 0.6.1","title":"multinma 0.6.1","text":"CRAN release: 2024-03-06 Fix: Piecewise exponential hazard models longer give errors set-. Calculation RW1 prior weights needed handled special case.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-060","dir":"Changelog","previous_headings":"","what":"multinma 0.6.0","title":"multinma 0.6.0","text":"CRAN release: 2024-01-24","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"feature-survivaltime-to-event-models-are-now-supported-0-6-0","dir":"Changelog","previous_headings":"","what":"Feature: Survival/time-to-event models are now supported","title":"multinma 0.6.0","text":"set_ipd() now Surv argument specifying survival outcomes using survival::Surv(), new function set_agd_surv() sets aggregate data form event/censoring times (e.g. digitized Kaplan-Meier curves) overall covariate summaries. Left, right, interval censoring well left truncation (delayed entry) supported. available likelihoods Exponential (PH AFT forms), Weibull (PH AFT forms), Gompertz, log-Normal, log-Logistic, Gamma, Generalised Gamma, flexible M-splines baseline hazard, piecewise exponential hazards. Auxiliary parameters (e.g. shapes, spline coefficients) always stratified study respect randomisation, may stratified treatment (e.g. relax proportional hazards assumption) /additional factors using aux_by argument nma(). regression model may defined auxiliary parameters using aux_regression argument nma(), allowing non-proportionality modelled treatment /covariate effects shapes spline coefficients. predict() method produces estimates survival probabilities, hazards, cumulative hazards, mean survival times, restricted mean survival times, quantiles survival time distribution, median survival times. predictions can plotted using plot() method. geom_km() function assists plotting Kaplan-Meier curves network object, example overlay estimated survival curves. transform argument can used produce log-log plots assessing proportional hazards assumption, along cumulative hazards log survival curves. new vignette demonstrates ML-NMR survival analysis example progression-free survival autologous stem cell transplant newly diagnosed multiple myeloma, corresponding datasets ndmm_ipd, ndmm_agd, ndmm_agd_covs.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"feature-automatic-checking-of-numerical-integration-for-ml-nmr-models-0-6-0","dir":"Changelog","previous_headings":"","what":"Feature: Automatic checking of numerical integration for ML-NMR models","title":"multinma 0.6.0","text":"accuracy numerical integration ML-NMR models can now checked automatically, default. , half chains run n_int half n_int/2 integration points. Rhat effective sample size warnings can ascribed either: non-convergence MCMC chains, requiring increased number iterations iter nma(), ; insufficient accuracy numerical integration, requiring increased number integration points n_int add_integration(). Descriptive warning messages indicate case. feature controlled new int_check argument nma(), enabled (TRUE) default. Saving thinned cumulative integration points can now disabled int_thin = 0, now disabled default. previous default int_thin = max(n_int %/% 10, 1). can now check sufficient accuracy automatically, default number integration points n_int add_integration() lowered 64. still conservative choice, sufficient many cases; previous default 1000 excessive. result, ML-NMR models now much faster run default, due lower n_int disabling saving cumulative integration points.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"other-updates-0-6-0","dir":"Changelog","previous_headings":"","what":"Other updates","title":"multinma 0.6.0","text":"Feature: dic() now includes option use pV penalty instead pD. Feature: baseline aux arguments predict() can now specified name study network, use parameter estimates study prediction. Improvement: predict() now produce aggregate-level predictions sample individuals newdata ML-NMR models (previously newdata include integration points). Improvement: Compatibility future rstan versions (PR #25). Improvement: Added plot.mcmc_array() method, shortcut plot(summary(x), ...). Fix: plot.nma_data(), using custom layout string (e.g.  data frame layout coordinates) now works expected nudge > 0. Fix: Documentation corrections (PR #24). Fix: Added missing .tibble.stan_nma() as_tibble.stan_nma() methods, complement existing .data.frame.stan_nma(). Fix: Bug ordered multinomial models data studies missing categories assigned wrong category (#28).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-051","dir":"Changelog","previous_headings":"","what":"multinma 0.5.1","title":"multinma 0.5.1","text":"CRAN release: 2023-05-24 Fix: Now compatible latest StanHeaders v2.26.25 (fixes #23) Fix: Dealt various tidyverse deprecations Fix: Updated TSD URLs (thanks @ndunnewind)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-050","dir":"Changelog","previous_headings":"","what":"multinma 0.5.0","title":"multinma 0.5.0","text":"CRAN release: 2022-08-29 Feature: Treatment labels network plots can now nudged away nodes weight_nodes = TRUE, using new nudge argument plot.nma_data() (#15). Feature: data frame returned calling as_tibble() .data.frame() nma_summary object (relative effects predictions) now includes columns corresponding treatment (.trt) contrast (.trta .trtb), .category column may included multinomial models. Previously details present part parameter column Feature: Added log t prior distribution log_student_t(), can used positive-valued parameters (e.g. heterogeneity variance). Improvement: set_agd_contrast() now produces informative error message covariance matrix implied se column positive definite. Previously checked Stan calling nma() function. Improvement: Updated plaque psoriasis ML-NMR vignette include new analyses, including assessing assumptions population adjustment synthesising multinomial outcomes. Improvement: Improved behaviour .trtclass special regression formulas, now main effects .trtclass always removed since collinear .trt. allows expansion interactions * work properly, e.g. ~variable*.trtclass, whereas previously resulted -parametrised model. Fix: CRAN check note manual HTML5 compatibility. Fix: Residual deviance log likelihood parameters now named correctly contrast-based aggregate data present (PR #19).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-042","dir":"Changelog","previous_headings":"","what":"multinma 0.4.2","title":"multinma 0.4.2","text":"CRAN release: 2022-03-02 Fix: Error get_nodesplits() studies multiple arms treatment. Fix: print.nma_data() now prints repeated arms studies multiple arms treatment. Fix: CRAN warning regarding invalid img tag height attribute documentation.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-041","dir":"Changelog","previous_headings":"","what":"multinma 0.4.1","title":"multinma 0.4.1","text":"CRAN release: 2022-02-04 Fix: tidyr v1.2.0 breaks ordered multinomial models studies report categories (.e. multinomial category outcomes NA multi()) (PR #11)","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-040","dir":"Changelog","previous_headings":"","what":"multinma 0.4.0","title":"multinma 0.4.0","text":"CRAN release: 2022-01-18 Feature: Node-splitting models assessing inconsistency now available consistency = \"nodesplit\" nma(). Comparisons split can chosen using nodesplit argument, default possibly inconsistent comparisons chosen using get_nodesplits(). Node-splitting results can summarised summary.nma_nodesplit() plotted plot.nodesplit_summary(). Feature: correlation matrix generating integration points add_integration() ML-NMR models now adjusted underlying Gaussian copula, output correlations integration points better match requested input correlations. new argument cor_adjust controls behaviour, options \"spearman\", \"pearson\", \"none\". Although correlations typically little impact results, strict reproducibility old behaviour version 0.3.0 available cor_adjust = \"legacy\". Feature: random effects models, predictive distribution relative/absolute effects new study can now obtained relative_effects() predict.stan_nma() respectively, using new argument predictive_distribution = TRUE. Feature: Added option calculate SUCRA values summarising posterior treatment ranks posterior_ranks() posterior_rank_probs(), argument sucra = TRUE. Improvement: Factor order now respected trt, study, trt_class factors, previously order levels reset natural sort order. Improvement: Update package website Bootstrap 5 release pkgdown 2.0.0 Fix: Model fitting now robust non-default settings options(\"contrasts\"). Fix: plot.nma_data() longer gives ggplot deprecation warning (PR #6). Fix: Bug predict.stan_nma() single covariate newdata data.frame (PR #7). Fix: Attempting call predict.stan_nma() regression model contrast data newdata baseline specified now throws descriptive error message.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-030","dir":"Changelog","previous_headings":"","what":"multinma 0.3.0","title":"multinma 0.3.0","text":"CRAN release: 2021-03-18 Feature: Added baseline_type baseline_level arguments predict.stan_nma(), allow baseline distributions specified response linear predictor scale, individual aggregate level. Feature: baseline argument predict.stan_nma() can now accept (named) list baseline distributions newdata contains multiple studies. Improvement: Misspecified newdata arguments functions like relative_effects() predict.stan_nma() now give informative error messages. Fix: Constructing models contrast-based data previously gave errors scenarios (ML-NMR models, UME models, cases AgD meta-regression models). Fix: Ensure CRAN additional checks --run-donttest run correctly.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-021","dir":"Changelog","previous_headings":"","what":"multinma 0.2.1","title":"multinma 0.2.1","text":"CRAN release: 2021-01-09 Fix: Producing relative effect estimates contrasts using relative_effects() all_contrasts = TRUE longer gives error regression models. Fix: Specifying covariate correlation matrix cor add_integration() required one covariate present. Improvement: Added detailed documentation likelihoods link functions available data type (likelihood link arguments nma()).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-020","dir":"Changelog","previous_headings":"","what":"multinma 0.2.0","title":"multinma 0.2.0","text":"CRAN release: 2020-12-04 Feature: set_*() functions now accept dplyr::mutate() style semantics, allowing inline variable transformations. Feature: Added ordered multinomial models, helper function multi() specifying outcomes. Accompanied new data set hta_psoriasis vignette. Feature: Implicit flat priors can now specified, parameter, using flat(). Improvement: .array.stan_nma() now much efficient, meaning many post-estimation functions also now much efficient. Improvement: plot.nma_dic() now efficient, particularly large numbers data points. Improvement: layering points producing “dev-dev” plots using plot.nma_dic() multiple data types reversed improved clarity (now AgD top IPD). Improvement: Aggregate-level predictions predict() ML-NMR / IPD regression models now calculated much memory-efficient manner. Improvement: Added overview examples given vignettes. Improvement: Network plots weight_edges = TRUE longer produce legends non-integer values number studies. Fix: plot.nma_dic() longer gives error attempting specify .width argument producing “dev-dev” plots.","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-013","dir":"Changelog","previous_headings":"","what":"multinma 0.1.3","title":"multinma 0.1.3","text":"CRAN release: 2020-06-30 Format DESCRIPTION CRAN requirements","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-012","dir":"Changelog","previous_headings":"","what":"multinma 0.1.2","title":"multinma 0.1.2","text":"Wrapped long-running examples \\donttest{} instead \\dontrun{}","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-011","dir":"Changelog","previous_headings":"","what":"multinma 0.1.1","title":"multinma 0.1.1","text":"Reduced size vignettes Added methods paper reference DESCRIPTION Added zenodo DOI","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-010","dir":"Changelog","previous_headings":"","what":"multinma 0.1.0","title":"multinma 0.1.0","text":"Feature: Network plots, using plot() method nma_data objects. Feature: .igraph(), as_tbl_graph() methods nma_data objects. Feature: Produce relative effect estimates relative_effects(), posterior ranks posterior_ranks(), posterior rank probabilities posterior_rank_probs(). study-specific regression model given. Feature: Produce predictions absolute effects predict() method stan_nma objects. Feature: Plots relative effects, ranks, predictions, parameter estimates via plot.nma_summary(). Enables centering predictors (center = TRUE) nma() regression model given, replacing agd_sample_size argument nma() Enables production study-specific relative effects, rank probabilities, etc. studies network regression model given Allows nodes network plots weighted sample size Feature: Plots residual deviance contributions model “dev-dev” plots comparing residual deviance contributions two models, using plot() method nma_dic objects produced dic(). Feature: Complementary log-log (cloglog) link function link = \"cloglog\" binomial likelihoods. Feature: Option specify priors heterogeneity standard deviation, variance, precision, argument prior_het_type. Feature: Added log-Normal prior distribution. Feature: Plots prior distributions vs. posterior distributions plot_prior_posterior(). Feature: Pairs plot method pairs(). Feature: Added vignettes example analyses NICE TSDs . Fix: Random effects models even moderate numbers studies slow. now run much quickly, using sparse representation RE correlation matrix automatically enabled sparsity 90% (roughly equivalent 10 studies).","code":""},{"path":"https://dmphillippo.github.io/multinma/dev/news/index.html","id":"multinma-001","dir":"Changelog","previous_headings":"","what":"multinma 0.0.1","title":"multinma 0.0.1","text":"Initial release.","code":""}]
